I0902 13:08:23.027225      19 test_context.go:358] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-041707028
I0902 13:08:23.027421      19 e2e.go:224] Starting e2e run "bdc259f4-cd82-11e9-b90e-8ed318f3d3c6" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1567429702 - Will randomize all specs
Will run 201 of 1946 specs

Sep  2 13:08:23.167: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
Sep  2 13:08:23.169: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Sep  2 13:08:23.182: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Sep  2 13:08:23.209: INFO: 11 / 11 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Sep  2 13:08:23.209: INFO: expected 3 pod replicas in namespace 'kube-system', 3 are Running and Ready.
Sep  2 13:08:23.209: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Sep  2 13:08:23.218: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'aws-node' (0 seconds elapsed)
Sep  2 13:08:23.218: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Sep  2 13:08:23.218: INFO: e2e test version: v1.13.0
Sep  2 13:08:23.219: INFO: kube-apiserver version: v1.13.8-eks-a977ba
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:08:23.219: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename emptydir
Sep  2 13:08:23.275: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Sep  2 13:08:23.282: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-s8fzs
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Sep  2 13:08:23.399: INFO: Waiting up to 5m0s for pod "pod-be50cba2-cd82-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-emptydir-s8fzs" to be "success or failure"
Sep  2 13:08:23.401: INFO: Pod "pod-be50cba2-cd82-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.312768ms
Sep  2 13:08:25.404: INFO: Pod "pod-be50cba2-cd82-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005613077s
STEP: Saw pod success
Sep  2 13:08:25.404: INFO: Pod "pod-be50cba2-cd82-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 13:08:25.407: INFO: Trying to get logs from node ip-192-168-77-237.us-west-2.compute.internal pod pod-be50cba2-cd82-11e9-b90e-8ed318f3d3c6 container test-container: <nil>
STEP: delete the pod
Sep  2 13:08:25.424: INFO: Waiting for pod pod-be50cba2-cd82-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 13:08:25.427: INFO: Pod pod-be50cba2-cd82-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:08:25.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-s8fzs" for this suite.
Sep  2 13:08:31.447: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:08:31.475: INFO: namespace: e2e-tests-emptydir-s8fzs, resource: bindings, ignored listing per whitelist
Sep  2 13:08:31.542: INFO: namespace e2e-tests-emptydir-s8fzs deletion completed in 6.111138165s

• [SLOW TEST:8.323 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:08:31.542: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-cbsr5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Sep  2 13:08:31.707: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep  2 13:08:31.714: INFO: Waiting for terminating namespaces to be deleted...
Sep  2 13:08:31.718: INFO: 
Logging pods the kubelet thinks is on node ip-192-168-185-95.us-west-2.compute.internal before test
Sep  2 13:08:31.728: INFO: sonobuoy-systemd-logs-daemon-set-f7d9f222843a4872-xv7pn from heptio-sonobuoy started at 2019-09-02 13:08:20 +0000 UTC (2 container statuses recorded)
Sep  2 13:08:31.728: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep  2 13:08:31.728: INFO: 	Container systemd-logs ready: true, restart count 0
Sep  2 13:08:31.728: INFO: aws-node-h72bs from kube-system started at 2019-09-02 12:25:13 +0000 UTC (1 container statuses recorded)
Sep  2 13:08:31.728: INFO: 	Container aws-node ready: true, restart count 0
Sep  2 13:08:31.728: INFO: kube-proxy-w76hj from kube-system started at 2019-09-02 12:25:13 +0000 UTC (1 container statuses recorded)
Sep  2 13:08:31.728: INFO: 	Container kube-proxy ready: true, restart count 0
Sep  2 13:08:31.728: INFO: 
Logging pods the kubelet thinks is on node ip-192-168-55-191.us-west-2.compute.internal before test
Sep  2 13:08:31.734: INFO: aws-node-cssxg from kube-system started at 2019-09-02 07:20:24 +0000 UTC (1 container statuses recorded)
Sep  2 13:08:31.734: INFO: 	Container aws-node ready: true, restart count 0
Sep  2 13:08:31.734: INFO: kube-proxy-gpz5v from kube-system started at 2019-09-02 07:20:24 +0000 UTC (1 container statuses recorded)
Sep  2 13:08:31.734: INFO: 	Container kube-proxy ready: true, restart count 0
Sep  2 13:08:31.734: INFO: coredns-79d667b89f-fbrdn from kube-system started at 2019-09-02 07:27:30 +0000 UTC (1 container statuses recorded)
Sep  2 13:08:31.734: INFO: 	Container coredns ready: true, restart count 0
Sep  2 13:08:31.734: INFO: sonobuoy-systemd-logs-daemon-set-f7d9f222843a4872-4p5pk from heptio-sonobuoy started at 2019-09-02 13:08:20 +0000 UTC (2 container statuses recorded)
Sep  2 13:08:31.734: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep  2 13:08:31.734: INFO: 	Container systemd-logs ready: true, restart count 0
Sep  2 13:08:31.734: INFO: 
Logging pods the kubelet thinks is on node ip-192-168-6-156.us-west-2.compute.internal before test
Sep  2 13:08:31.740: INFO: kube-proxy-wvzsh from kube-system started at 2019-09-02 07:28:57 +0000 UTC (1 container statuses recorded)
Sep  2 13:08:31.740: INFO: 	Container kube-proxy ready: true, restart count 0
Sep  2 13:08:31.740: INFO: sonobuoy from heptio-sonobuoy started at 2019-09-02 13:08:19 +0000 UTC (1 container statuses recorded)
Sep  2 13:08:31.740: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep  2 13:08:31.740: INFO: aws-node-d25qt from kube-system started at 2019-09-02 07:28:57 +0000 UTC (1 container statuses recorded)
Sep  2 13:08:31.740: INFO: 	Container aws-node ready: true, restart count 0
Sep  2 13:08:31.740: INFO: sonobuoy-systemd-logs-daemon-set-f7d9f222843a4872-hppz8 from heptio-sonobuoy started at 2019-09-02 13:08:20 +0000 UTC (2 container statuses recorded)
Sep  2 13:08:31.740: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep  2 13:08:31.740: INFO: 	Container systemd-logs ready: true, restart count 0
Sep  2 13:08:31.740: INFO: 
Logging pods the kubelet thinks is on node ip-192-168-77-237.us-west-2.compute.internal before test
Sep  2 13:08:31.745: INFO: sonobuoy-systemd-logs-daemon-set-f7d9f222843a4872-7g5md from heptio-sonobuoy started at 2019-09-02 13:08:20 +0000 UTC (2 container statuses recorded)
Sep  2 13:08:31.745: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep  2 13:08:31.745: INFO: 	Container systemd-logs ready: true, restart count 0
Sep  2 13:08:31.745: INFO: coredns-79d667b89f-thvvk from kube-system started at 2019-09-02 10:12:03 +0000 UTC (1 container statuses recorded)
Sep  2 13:08:31.745: INFO: 	Container coredns ready: true, restart count 0
Sep  2 13:08:31.745: INFO: kube-proxy-84977 from kube-system started at 2019-09-02 07:35:32 +0000 UTC (1 container statuses recorded)
Sep  2 13:08:31.745: INFO: 	Container kube-proxy ready: true, restart count 0
Sep  2 13:08:31.745: INFO: spotinst-kubernetes-cluster-controller-5456664d9b-ljj66 from kube-system started at 2019-09-02 10:12:33 +0000 UTC (1 container statuses recorded)
Sep  2 13:08:31.745: INFO: 	Container spotinst-kubernetes-cluster-controller ready: true, restart count 0
Sep  2 13:08:31.745: INFO: aws-node-zh7fs from kube-system started at 2019-09-02 07:35:32 +0000 UTC (1 container statuses recorded)
Sep  2 13:08:31.745: INFO: 	Container aws-node ready: true, restart count 0
Sep  2 13:08:31.745: INFO: sonobuoy-e2e-job-1216ef12ccbc49ed from heptio-sonobuoy started at 2019-09-02 13:08:20 +0000 UTC (2 container statuses recorded)
Sep  2 13:08:31.745: INFO: 	Container e2e ready: true, restart count 0
Sep  2 13:08:31.745: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15c0a104ac251590], Reason = [FailedScheduling], Message = [0/4 nodes are available: 4 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:08:32.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-cbsr5" for this suite.
Sep  2 13:08:38.788: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:08:38.872: INFO: namespace: e2e-tests-sched-pred-cbsr5, resource: bindings, ignored listing per whitelist
Sep  2 13:08:38.887: INFO: namespace e2e-tests-sched-pred-cbsr5 deletion completed in 6.11488704s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.345 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:08:38.888: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replicaset-rdh4l
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Sep  2 13:08:39.051: INFO: Creating ReplicaSet my-hostname-basic-c7a6370d-cd82-11e9-b90e-8ed318f3d3c6
Sep  2 13:08:39.057: INFO: Pod name my-hostname-basic-c7a6370d-cd82-11e9-b90e-8ed318f3d3c6: Found 0 pods out of 1
Sep  2 13:08:44.060: INFO: Pod name my-hostname-basic-c7a6370d-cd82-11e9-b90e-8ed318f3d3c6: Found 1 pods out of 1
Sep  2 13:08:44.060: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-c7a6370d-cd82-11e9-b90e-8ed318f3d3c6" is running
Sep  2 13:08:44.063: INFO: Pod "my-hostname-basic-c7a6370d-cd82-11e9-b90e-8ed318f3d3c6-h9wdf" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-02 13:08:39 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-02 13:08:41 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-02 13:08:41 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-02 13:08:39 +0000 UTC Reason: Message:}])
Sep  2 13:08:44.063: INFO: Trying to dial the pod
Sep  2 13:08:49.078: INFO: Controller my-hostname-basic-c7a6370d-cd82-11e9-b90e-8ed318f3d3c6: Got expected result from replica 1 [my-hostname-basic-c7a6370d-cd82-11e9-b90e-8ed318f3d3c6-h9wdf]: "my-hostname-basic-c7a6370d-cd82-11e9-b90e-8ed318f3d3c6-h9wdf", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:08:49.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-rdh4l" for this suite.
Sep  2 13:08:55.096: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:08:55.172: INFO: namespace: e2e-tests-replicaset-rdh4l, resource: bindings, ignored listing per whitelist
Sep  2 13:08:55.190: INFO: namespace e2e-tests-replicaset-rdh4l deletion completed in 6.108696883s

• [SLOW TEST:16.302 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:08:55.190: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-bhknv
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-bhknv
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep  2 13:08:55.356: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep  2 13:09:19.432: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 192.168.37.168 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-bhknv PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  2 13:09:19.432: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
Sep  2 13:09:20.509: INFO: Found all expected endpoints: [netserver-0]
Sep  2 13:09:20.512: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 192.168.94.2 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-bhknv PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  2 13:09:20.512: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
Sep  2 13:09:21.585: INFO: Found all expected endpoints: [netserver-1]
Sep  2 13:09:21.593: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 192.168.169.129 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-bhknv PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  2 13:09:21.594: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
Sep  2 13:09:22.666: INFO: Found all expected endpoints: [netserver-2]
Sep  2 13:09:22.669: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 192.168.20.219 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-bhknv PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  2 13:09:22.669: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
Sep  2 13:09:23.753: INFO: Found all expected endpoints: [netserver-3]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:09:23.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-bhknv" for this suite.
Sep  2 13:09:45.773: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:09:45.825: INFO: namespace: e2e-tests-pod-network-test-bhknv, resource: bindings, ignored listing per whitelist
Sep  2 13:09:45.868: INFO: namespace e2e-tests-pod-network-test-bhknv deletion completed in 22.11138172s

• [SLOW TEST:50.678 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:09:45.869: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-d5g4m
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Sep  2 13:09:52.072: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  2 13:09:52.075: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  2 13:09:54.075: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  2 13:09:54.084: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  2 13:09:56.075: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  2 13:09:56.078: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  2 13:09:58.075: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  2 13:09:58.078: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  2 13:10:00.075: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  2 13:10:00.078: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  2 13:10:02.075: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  2 13:10:02.078: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  2 13:10:04.075: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  2 13:10:04.078: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  2 13:10:06.075: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  2 13:10:06.084: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  2 13:10:08.075: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  2 13:10:08.078: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  2 13:10:10.075: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  2 13:10:10.078: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  2 13:10:12.075: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  2 13:10:12.078: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  2 13:10:14.075: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  2 13:10:14.078: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:10:14.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-d5g4m" for this suite.
Sep  2 13:10:36.105: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:10:36.169: INFO: namespace: e2e-tests-container-lifecycle-hook-d5g4m, resource: bindings, ignored listing per whitelist
Sep  2 13:10:36.198: INFO: namespace e2e-tests-container-lifecycle-hook-d5g4m deletion completed in 22.109353437s

• [SLOW TEST:50.329 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:10:36.198: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-jpmgj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Sep  2 13:10:36.372: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0d92c53f-cd83-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-projected-jpmgj" to be "success or failure"
Sep  2 13:10:36.374: INFO: Pod "downwardapi-volume-0d92c53f-cd83-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.228973ms
Sep  2 13:10:38.384: INFO: Pod "downwardapi-volume-0d92c53f-cd83-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011338938s
STEP: Saw pod success
Sep  2 13:10:38.384: INFO: Pod "downwardapi-volume-0d92c53f-cd83-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 13:10:38.386: INFO: Trying to get logs from node ip-192-168-77-237.us-west-2.compute.internal pod downwardapi-volume-0d92c53f-cd83-11e9-b90e-8ed318f3d3c6 container client-container: <nil>
STEP: delete the pod
Sep  2 13:10:38.403: INFO: Waiting for pod downwardapi-volume-0d92c53f-cd83-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 13:10:38.405: INFO: Pod downwardapi-volume-0d92c53f-cd83-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:10:38.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jpmgj" for this suite.
Sep  2 13:10:44.426: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:10:44.452: INFO: namespace: e2e-tests-projected-jpmgj, resource: bindings, ignored listing per whitelist
Sep  2 13:10:44.518: INFO: namespace e2e-tests-projected-jpmgj deletion completed in 6.10872398s

• [SLOW TEST:8.320 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:10:44.518: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-5dr44
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-5dr44
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep  2 13:10:44.677: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep  2 13:11:10.756: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.188.44:8080/dial?request=hostName&protocol=udp&host=192.168.2.194&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-5dr44 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  2 13:11:10.756: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
Sep  2 13:11:10.851: INFO: Waiting for endpoints: map[]
Sep  2 13:11:10.853: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.188.44:8080/dial?request=hostName&protocol=udp&host=192.168.169.92&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-5dr44 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  2 13:11:10.853: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
Sep  2 13:11:10.937: INFO: Waiting for endpoints: map[]
Sep  2 13:11:10.939: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.188.44:8080/dial?request=hostName&protocol=udp&host=192.168.42.25&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-5dr44 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  2 13:11:10.939: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
Sep  2 13:11:11.021: INFO: Waiting for endpoints: map[]
Sep  2 13:11:11.023: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.188.44:8080/dial?request=hostName&protocol=udp&host=192.168.88.39&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-5dr44 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  2 13:11:11.023: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
Sep  2 13:11:11.105: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:11:11.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-5dr44" for this suite.
Sep  2 13:11:33.130: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:11:33.174: INFO: namespace: e2e-tests-pod-network-test-5dr44, resource: bindings, ignored listing per whitelist
Sep  2 13:11:33.224: INFO: namespace e2e-tests-pod-network-test-5dr44 deletion completed in 22.115124167s

• [SLOW TEST:48.706 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:11:33.224: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-z288z
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-2f90cd50-cd83-11e9-b90e-8ed318f3d3c6
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:11:37.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-z288z" for this suite.
Sep  2 13:11:59.448: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:11:59.483: INFO: namespace: e2e-tests-configmap-z288z, resource: bindings, ignored listing per whitelist
Sep  2 13:11:59.541: INFO: namespace e2e-tests-configmap-z288z deletion completed in 22.108583292s

• [SLOW TEST:26.317 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:11:59.541: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-jplnc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Sep  2 13:11:59.719: INFO: Waiting up to 5m0s for pod "pod-3f40994c-cd83-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-emptydir-jplnc" to be "success or failure"
Sep  2 13:11:59.721: INFO: Pod "pod-3f40994c-cd83-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.26636ms
Sep  2 13:12:01.725: INFO: Pod "pod-3f40994c-cd83-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00580234s
Sep  2 13:12:03.728: INFO: Pod "pod-3f40994c-cd83-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009007087s
STEP: Saw pod success
Sep  2 13:12:03.728: INFO: Pod "pod-3f40994c-cd83-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 13:12:03.730: INFO: Trying to get logs from node ip-192-168-77-237.us-west-2.compute.internal pod pod-3f40994c-cd83-11e9-b90e-8ed318f3d3c6 container test-container: <nil>
STEP: delete the pod
Sep  2 13:12:03.747: INFO: Waiting for pod pod-3f40994c-cd83-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 13:12:03.749: INFO: Pod pod-3f40994c-cd83-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:12:03.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-jplnc" for this suite.
Sep  2 13:12:09.769: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:12:09.787: INFO: namespace: e2e-tests-emptydir-jplnc, resource: bindings, ignored listing per whitelist
Sep  2 13:12:09.864: INFO: namespace e2e-tests-emptydir-jplnc deletion completed in 6.110822442s

• [SLOW TEST:10.323 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:12:09.864: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-mm6fw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Sep  2 13:12:10.038: INFO: Waiting up to 5m0s for pod "client-containers-4567254f-cd83-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-containers-mm6fw" to be "success or failure"
Sep  2 13:12:10.041: INFO: Pod "client-containers-4567254f-cd83-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.235707ms
Sep  2 13:12:12.044: INFO: Pod "client-containers-4567254f-cd83-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005406391s
Sep  2 13:12:14.047: INFO: Pod "client-containers-4567254f-cd83-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008411165s
STEP: Saw pod success
Sep  2 13:12:14.047: INFO: Pod "client-containers-4567254f-cd83-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 13:12:14.049: INFO: Trying to get logs from node ip-192-168-77-237.us-west-2.compute.internal pod client-containers-4567254f-cd83-11e9-b90e-8ed318f3d3c6 container test-container: <nil>
STEP: delete the pod
Sep  2 13:12:14.065: INFO: Waiting for pod client-containers-4567254f-cd83-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 13:12:14.067: INFO: Pod client-containers-4567254f-cd83-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:12:14.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-mm6fw" for this suite.
Sep  2 13:12:20.087: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:12:20.140: INFO: namespace: e2e-tests-containers-mm6fw, resource: bindings, ignored listing per whitelist
Sep  2 13:12:20.179: INFO: namespace e2e-tests-containers-mm6fw deletion completed in 6.108574019s

• [SLOW TEST:10.315 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:12:20.179: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-cp92x
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Sep  2 13:12:20.357: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4b8d9eb5-cd83-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-downward-api-cp92x" to be "success or failure"
Sep  2 13:12:20.360: INFO: Pod "downwardapi-volume-4b8d9eb5-cd83-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.261294ms
Sep  2 13:12:22.363: INFO: Pod "downwardapi-volume-4b8d9eb5-cd83-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005509379s
STEP: Saw pod success
Sep  2 13:12:22.363: INFO: Pod "downwardapi-volume-4b8d9eb5-cd83-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 13:12:22.365: INFO: Trying to get logs from node ip-192-168-77-237.us-west-2.compute.internal pod downwardapi-volume-4b8d9eb5-cd83-11e9-b90e-8ed318f3d3c6 container client-container: <nil>
STEP: delete the pod
Sep  2 13:12:22.382: INFO: Waiting for pod downwardapi-volume-4b8d9eb5-cd83-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 13:12:22.384: INFO: Pod downwardapi-volume-4b8d9eb5-cd83-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:12:22.384: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-cp92x" for this suite.
Sep  2 13:12:28.403: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:12:28.483: INFO: namespace: e2e-tests-downward-api-cp92x, resource: bindings, ignored listing per whitelist
Sep  2 13:12:28.494: INFO: namespace e2e-tests-downward-api-cp92x deletion completed in 6.106496557s

• [SLOW TEST:8.315 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:12:28.494: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-ln5b9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Sep  2 13:12:28.661: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-ln5b9,SelfLink:/api/v1/namespaces/e2e-tests-watch-ln5b9/configmaps/e2e-watch-test-configmap-a,UID:508157b1-cd83-11e9-a575-0a854009c708,ResourceVersion:2087273,Generation:0,CreationTimestamp:2019-09-02 13:12:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep  2 13:12:28.661: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-ln5b9,SelfLink:/api/v1/namespaces/e2e-tests-watch-ln5b9/configmaps/e2e-watch-test-configmap-a,UID:508157b1-cd83-11e9-a575-0a854009c708,ResourceVersion:2087273,Generation:0,CreationTimestamp:2019-09-02 13:12:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Sep  2 13:12:38.676: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-ln5b9,SelfLink:/api/v1/namespaces/e2e-tests-watch-ln5b9/configmaps/e2e-watch-test-configmap-a,UID:508157b1-cd83-11e9-a575-0a854009c708,ResourceVersion:2087290,Generation:0,CreationTimestamp:2019-09-02 13:12:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Sep  2 13:12:38.676: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-ln5b9,SelfLink:/api/v1/namespaces/e2e-tests-watch-ln5b9/configmaps/e2e-watch-test-configmap-a,UID:508157b1-cd83-11e9-a575-0a854009c708,ResourceVersion:2087290,Generation:0,CreationTimestamp:2019-09-02 13:12:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Sep  2 13:12:48.692: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-ln5b9,SelfLink:/api/v1/namespaces/e2e-tests-watch-ln5b9/configmaps/e2e-watch-test-configmap-a,UID:508157b1-cd83-11e9-a575-0a854009c708,ResourceVersion:2087307,Generation:0,CreationTimestamp:2019-09-02 13:12:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep  2 13:12:48.692: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-ln5b9,SelfLink:/api/v1/namespaces/e2e-tests-watch-ln5b9/configmaps/e2e-watch-test-configmap-a,UID:508157b1-cd83-11e9-a575-0a854009c708,ResourceVersion:2087307,Generation:0,CreationTimestamp:2019-09-02 13:12:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Sep  2 13:12:58.708: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-ln5b9,SelfLink:/api/v1/namespaces/e2e-tests-watch-ln5b9/configmaps/e2e-watch-test-configmap-a,UID:508157b1-cd83-11e9-a575-0a854009c708,ResourceVersion:2087324,Generation:0,CreationTimestamp:2019-09-02 13:12:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep  2 13:12:58.708: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-ln5b9,SelfLink:/api/v1/namespaces/e2e-tests-watch-ln5b9/configmaps/e2e-watch-test-configmap-a,UID:508157b1-cd83-11e9-a575-0a854009c708,ResourceVersion:2087324,Generation:0,CreationTimestamp:2019-09-02 13:12:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Sep  2 13:13:08.723: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-ln5b9,SelfLink:/api/v1/namespaces/e2e-tests-watch-ln5b9/configmaps/e2e-watch-test-configmap-b,UID:6861bb06-cd83-11e9-a575-0a854009c708,ResourceVersion:2087341,Generation:0,CreationTimestamp:2019-09-02 13:13:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep  2 13:13:08.723: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-ln5b9,SelfLink:/api/v1/namespaces/e2e-tests-watch-ln5b9/configmaps/e2e-watch-test-configmap-b,UID:6861bb06-cd83-11e9-a575-0a854009c708,ResourceVersion:2087341,Generation:0,CreationTimestamp:2019-09-02 13:13:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Sep  2 13:13:18.740: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-ln5b9,SelfLink:/api/v1/namespaces/e2e-tests-watch-ln5b9/configmaps/e2e-watch-test-configmap-b,UID:6861bb06-cd83-11e9-a575-0a854009c708,ResourceVersion:2087358,Generation:0,CreationTimestamp:2019-09-02 13:13:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep  2 13:13:18.740: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-ln5b9,SelfLink:/api/v1/namespaces/e2e-tests-watch-ln5b9/configmaps/e2e-watch-test-configmap-b,UID:6861bb06-cd83-11e9-a575-0a854009c708,ResourceVersion:2087358,Generation:0,CreationTimestamp:2019-09-02 13:13:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:13:28.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-ln5b9" for this suite.
Sep  2 13:13:34.765: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:13:34.802: INFO: namespace: e2e-tests-watch-ln5b9, resource: bindings, ignored listing per whitelist
Sep  2 13:13:34.858: INFO: namespace e2e-tests-watch-ln5b9 deletion completed in 6.108681579s

• [SLOW TEST:66.364 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:13:34.859: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-hzrm7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Sep  2 13:13:35.046: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-hzrm7,SelfLink:/api/v1/namespaces/e2e-tests-watch-hzrm7/configmaps/e2e-watch-test-label-changed,UID:78108f2e-cd83-11e9-a575-0a854009c708,ResourceVersion:2087395,Generation:0,CreationTimestamp:2019-09-02 13:13:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep  2 13:13:35.046: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-hzrm7,SelfLink:/api/v1/namespaces/e2e-tests-watch-hzrm7/configmaps/e2e-watch-test-label-changed,UID:78108f2e-cd83-11e9-a575-0a854009c708,ResourceVersion:2087396,Generation:0,CreationTimestamp:2019-09-02 13:13:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Sep  2 13:13:35.046: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-hzrm7,SelfLink:/api/v1/namespaces/e2e-tests-watch-hzrm7/configmaps/e2e-watch-test-label-changed,UID:78108f2e-cd83-11e9-a575-0a854009c708,ResourceVersion:2087397,Generation:0,CreationTimestamp:2019-09-02 13:13:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Sep  2 13:13:45.084: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-hzrm7,SelfLink:/api/v1/namespaces/e2e-tests-watch-hzrm7/configmaps/e2e-watch-test-label-changed,UID:78108f2e-cd83-11e9-a575-0a854009c708,ResourceVersion:2087415,Generation:0,CreationTimestamp:2019-09-02 13:13:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep  2 13:13:45.084: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-hzrm7,SelfLink:/api/v1/namespaces/e2e-tests-watch-hzrm7/configmaps/e2e-watch-test-label-changed,UID:78108f2e-cd83-11e9-a575-0a854009c708,ResourceVersion:2087416,Generation:0,CreationTimestamp:2019-09-02 13:13:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Sep  2 13:13:45.084: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-hzrm7,SelfLink:/api/v1/namespaces/e2e-tests-watch-hzrm7/configmaps/e2e-watch-test-label-changed,UID:78108f2e-cd83-11e9-a575-0a854009c708,ResourceVersion:2087417,Generation:0,CreationTimestamp:2019-09-02 13:13:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:13:45.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-hzrm7" for this suite.
Sep  2 13:13:51.103: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:13:51.130: INFO: namespace: e2e-tests-watch-hzrm7, resource: bindings, ignored listing per whitelist
Sep  2 13:13:51.198: INFO: namespace e2e-tests-watch-hzrm7 deletion completed in 6.110178663s

• [SLOW TEST:16.340 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:13:51.198: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-nhqvp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-81cdc00f-cd83-11e9-b90e-8ed318f3d3c6
STEP: Creating a pod to test consume secrets
Sep  2 13:13:51.378: INFO: Waiting up to 5m0s for pod "pod-secrets-81ce709a-cd83-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-secrets-nhqvp" to be "success or failure"
Sep  2 13:13:51.381: INFO: Pod "pod-secrets-81ce709a-cd83-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.204145ms
Sep  2 13:13:53.384: INFO: Pod "pod-secrets-81ce709a-cd83-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005389269s
STEP: Saw pod success
Sep  2 13:13:53.384: INFO: Pod "pod-secrets-81ce709a-cd83-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 13:13:53.386: INFO: Trying to get logs from node ip-192-168-77-237.us-west-2.compute.internal pod pod-secrets-81ce709a-cd83-11e9-b90e-8ed318f3d3c6 container secret-volume-test: <nil>
STEP: delete the pod
Sep  2 13:13:53.404: INFO: Waiting for pod pod-secrets-81ce709a-cd83-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 13:13:53.406: INFO: Pod pod-secrets-81ce709a-cd83-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:13:53.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-nhqvp" for this suite.
Sep  2 13:13:59.425: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:13:59.493: INFO: namespace: e2e-tests-secrets-nhqvp, resource: bindings, ignored listing per whitelist
Sep  2 13:13:59.520: INFO: namespace e2e-tests-secrets-nhqvp deletion completed in 6.110665013s

• [SLOW TEST:8.322 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:13:59.520: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replication-controller-bgwd8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-86c2c9c3-cd83-11e9-b90e-8ed318f3d3c6
Sep  2 13:13:59.689: INFO: Pod name my-hostname-basic-86c2c9c3-cd83-11e9-b90e-8ed318f3d3c6: Found 0 pods out of 1
Sep  2 13:14:04.693: INFO: Pod name my-hostname-basic-86c2c9c3-cd83-11e9-b90e-8ed318f3d3c6: Found 1 pods out of 1
Sep  2 13:14:04.693: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-86c2c9c3-cd83-11e9-b90e-8ed318f3d3c6" are running
Sep  2 13:14:04.695: INFO: Pod "my-hostname-basic-86c2c9c3-cd83-11e9-b90e-8ed318f3d3c6-bn4k5" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-02 13:13:59 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-02 13:14:02 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-02 13:14:02 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-02 13:13:59 +0000 UTC Reason: Message:}])
Sep  2 13:14:04.695: INFO: Trying to dial the pod
Sep  2 13:14:09.714: INFO: Controller my-hostname-basic-86c2c9c3-cd83-11e9-b90e-8ed318f3d3c6: Got expected result from replica 1 [my-hostname-basic-86c2c9c3-cd83-11e9-b90e-8ed318f3d3c6-bn4k5]: "my-hostname-basic-86c2c9c3-cd83-11e9-b90e-8ed318f3d3c6-bn4k5", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:14:09.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-bgwd8" for this suite.
Sep  2 13:14:15.733: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:14:15.819: INFO: namespace: e2e-tests-replication-controller-bgwd8, resource: bindings, ignored listing per whitelist
Sep  2 13:14:15.828: INFO: namespace e2e-tests-replication-controller-bgwd8 deletion completed in 6.110573647s

• [SLOW TEST:16.308 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:14:15.828: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-events-92xcv
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Sep  2 13:14:18.013: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-907bc02d-cd83-11e9-b90e-8ed318f3d3c6,GenerateName:,Namespace:e2e-tests-events-92xcv,SelfLink:/api/v1/namespaces/e2e-tests-events-92xcv/pods/send-events-907bc02d-cd83-11e9-b90e-8ed318f3d3c6,UID:907c716e-cd83-11e9-a575-0a854009c708,ResourceVersion:2087551,Generation:0,CreationTimestamp:2019-09-02 13:14:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 994993698,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-5wczq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5wczq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-5wczq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-192-168-77-237.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00224d9d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00224d9f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:14:16 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:14:17 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:14:17 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:14:16 +0000 UTC  }],Message:,Reason:,HostIP:192.168.77.237,PodIP:192.168.75.155,StartTime:2019-09-02 13:14:16 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-09-02 13:14:17 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://615c7bf3e24b3793d95829190ac824a4d494070afe7be6917260dbb8892c72a3}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Sep  2 13:14:20.024: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Sep  2 13:14:22.029: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:14:22.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-92xcv" for this suite.
Sep  2 13:15:00.055: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:15:00.076: INFO: namespace: e2e-tests-events-92xcv, resource: bindings, ignored listing per whitelist
Sep  2 13:15:00.150: INFO: namespace e2e-tests-events-92xcv deletion completed in 38.111410065s

• [SLOW TEST:44.322 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:15:00.150: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svc-latency-7r6kn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-7r6kn
I0902 13:15:00.327760      19 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-7r6kn, replica count: 1
I0902 13:15:01.378221      19 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0902 13:15:02.378466      19 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0902 13:15:03.378706      19 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep  2 13:15:03.491: INFO: Created: latency-svc-jmdzm
Sep  2 13:15:03.505: INFO: Got endpoints: latency-svc-jmdzm [26.243415ms]
Sep  2 13:15:03.517: INFO: Created: latency-svc-98gfb
Sep  2 13:15:03.524: INFO: Got endpoints: latency-svc-98gfb [18.863891ms]
Sep  2 13:15:03.526: INFO: Created: latency-svc-8d8rm
Sep  2 13:15:03.532: INFO: Got endpoints: latency-svc-8d8rm [26.631104ms]
Sep  2 13:15:03.535: INFO: Created: latency-svc-c5t7h
Sep  2 13:15:03.542: INFO: Got endpoints: latency-svc-c5t7h [37.166254ms]
Sep  2 13:15:03.546: INFO: Created: latency-svc-6dtnn
Sep  2 13:15:03.552: INFO: Got endpoints: latency-svc-6dtnn [46.212771ms]
Sep  2 13:15:03.555: INFO: Created: latency-svc-h8q85
Sep  2 13:15:03.562: INFO: Got endpoints: latency-svc-h8q85 [56.377414ms]
Sep  2 13:15:03.564: INFO: Created: latency-svc-qdf6x
Sep  2 13:15:03.569: INFO: Got endpoints: latency-svc-qdf6x [64.021614ms]
Sep  2 13:15:03.572: INFO: Created: latency-svc-5kmp2
Sep  2 13:15:03.578: INFO: Got endpoints: latency-svc-5kmp2 [72.638983ms]
Sep  2 13:15:03.581: INFO: Created: latency-svc-9hl2h
Sep  2 13:15:03.586: INFO: Got endpoints: latency-svc-9hl2h [81.383494ms]
Sep  2 13:15:03.592: INFO: Created: latency-svc-8t5lf
Sep  2 13:15:03.599: INFO: Got endpoints: latency-svc-8t5lf [93.55003ms]
Sep  2 13:15:03.603: INFO: Created: latency-svc-z7nxg
Sep  2 13:15:03.609: INFO: Got endpoints: latency-svc-z7nxg [103.42889ms]
Sep  2 13:15:03.610: INFO: Created: latency-svc-frzp8
Sep  2 13:15:03.616: INFO: Got endpoints: latency-svc-frzp8 [110.731819ms]
Sep  2 13:15:03.619: INFO: Created: latency-svc-hb8jm
Sep  2 13:15:03.626: INFO: Got endpoints: latency-svc-hb8jm [120.365118ms]
Sep  2 13:15:03.630: INFO: Created: latency-svc-f62v7
Sep  2 13:15:03.636: INFO: Got endpoints: latency-svc-f62v7 [130.443186ms]
Sep  2 13:15:03.640: INFO: Created: latency-svc-lzrs5
Sep  2 13:15:03.646: INFO: Got endpoints: latency-svc-lzrs5 [141.115135ms]
Sep  2 13:15:03.649: INFO: Created: latency-svc-h7788
Sep  2 13:15:03.655: INFO: Got endpoints: latency-svc-h7788 [149.6238ms]
Sep  2 13:15:03.658: INFO: Created: latency-svc-9sw49
Sep  2 13:15:03.664: INFO: Got endpoints: latency-svc-9sw49 [139.90644ms]
Sep  2 13:15:03.667: INFO: Created: latency-svc-7xb49
Sep  2 13:15:03.673: INFO: Got endpoints: latency-svc-7xb49 [141.502192ms]
Sep  2 13:15:03.677: INFO: Created: latency-svc-p5958
Sep  2 13:15:03.683: INFO: Got endpoints: latency-svc-p5958 [140.834925ms]
Sep  2 13:15:03.687: INFO: Created: latency-svc-kxq8b
Sep  2 13:15:03.692: INFO: Got endpoints: latency-svc-kxq8b [140.566309ms]
Sep  2 13:15:03.695: INFO: Created: latency-svc-9slqr
Sep  2 13:15:03.702: INFO: Got endpoints: latency-svc-9slqr [140.15721ms]
Sep  2 13:15:03.705: INFO: Created: latency-svc-bpjb8
Sep  2 13:15:03.712: INFO: Got endpoints: latency-svc-bpjb8 [142.325963ms]
Sep  2 13:15:03.714: INFO: Created: latency-svc-flsmj
Sep  2 13:15:03.720: INFO: Got endpoints: latency-svc-flsmj [141.782885ms]
Sep  2 13:15:03.723: INFO: Created: latency-svc-m6tql
Sep  2 13:15:03.730: INFO: Got endpoints: latency-svc-m6tql [143.327941ms]
Sep  2 13:15:03.733: INFO: Created: latency-svc-lspkc
Sep  2 13:15:03.740: INFO: Got endpoints: latency-svc-lspkc [140.807069ms]
Sep  2 13:15:03.742: INFO: Created: latency-svc-7cqp9
Sep  2 13:15:03.748: INFO: Got endpoints: latency-svc-7cqp9 [139.115261ms]
Sep  2 13:15:03.751: INFO: Created: latency-svc-f9x2p
Sep  2 13:15:03.759: INFO: Got endpoints: latency-svc-f9x2p [142.49874ms]
Sep  2 13:15:03.761: INFO: Created: latency-svc-bbm5c
Sep  2 13:15:03.768: INFO: Got endpoints: latency-svc-bbm5c [142.412792ms]
Sep  2 13:15:03.770: INFO: Created: latency-svc-hmpg9
Sep  2 13:15:03.776: INFO: Got endpoints: latency-svc-hmpg9 [140.066706ms]
Sep  2 13:15:03.779: INFO: Created: latency-svc-jrkn8
Sep  2 13:15:03.787: INFO: Got endpoints: latency-svc-jrkn8 [140.433501ms]
Sep  2 13:15:03.788: INFO: Created: latency-svc-rd845
Sep  2 13:15:03.794: INFO: Got endpoints: latency-svc-rd845 [139.274045ms]
Sep  2 13:15:03.799: INFO: Created: latency-svc-knd52
Sep  2 13:15:03.805: INFO: Got endpoints: latency-svc-knd52 [141.797599ms]
Sep  2 13:15:03.809: INFO: Created: latency-svc-4q45l
Sep  2 13:15:03.815: INFO: Got endpoints: latency-svc-4q45l [142.003859ms]
Sep  2 13:15:03.819: INFO: Created: latency-svc-m6qmb
Sep  2 13:15:03.832: INFO: Got endpoints: latency-svc-m6qmb [148.956903ms]
Sep  2 13:15:03.835: INFO: Created: latency-svc-rmp5s
Sep  2 13:15:03.840: INFO: Got endpoints: latency-svc-rmp5s [148.236529ms]
Sep  2 13:15:03.843: INFO: Created: latency-svc-7cqq4
Sep  2 13:15:03.849: INFO: Got endpoints: latency-svc-7cqq4 [146.665896ms]
Sep  2 13:15:03.853: INFO: Created: latency-svc-qr7pj
Sep  2 13:15:03.861: INFO: Got endpoints: latency-svc-qr7pj [148.906605ms]
Sep  2 13:15:03.866: INFO: Created: latency-svc-9kghz
Sep  2 13:15:03.873: INFO: Created: latency-svc-v9jrj
Sep  2 13:15:03.882: INFO: Created: latency-svc-zpds5
Sep  2 13:15:03.892: INFO: Created: latency-svc-7h5nq
Sep  2 13:15:03.898: INFO: Got endpoints: latency-svc-9kghz [178.296748ms]
Sep  2 13:15:03.902: INFO: Created: latency-svc-x6zd8
Sep  2 13:15:03.912: INFO: Created: latency-svc-5q7hx
Sep  2 13:15:03.921: INFO: Created: latency-svc-zfhwp
Sep  2 13:15:03.929: INFO: Created: latency-svc-s4tv9
Sep  2 13:15:03.938: INFO: Created: latency-svc-xhqz7
Sep  2 13:15:03.947: INFO: Created: latency-svc-sstlj
Sep  2 13:15:03.948: INFO: Got endpoints: latency-svc-v9jrj [218.464855ms]
Sep  2 13:15:03.957: INFO: Created: latency-svc-psh8k
Sep  2 13:15:03.967: INFO: Created: latency-svc-b4l5p
Sep  2 13:15:03.975: INFO: Created: latency-svc-kfbz6
Sep  2 13:15:03.984: INFO: Created: latency-svc-tv4vq
Sep  2 13:15:03.993: INFO: Created: latency-svc-lbdgv
Sep  2 13:15:03.999: INFO: Got endpoints: latency-svc-zpds5 [259.423093ms]
Sep  2 13:15:04.008: INFO: Created: latency-svc-8wfhf
Sep  2 13:15:04.016: INFO: Created: latency-svc-w7zhj
Sep  2 13:15:04.027: INFO: Created: latency-svc-jzmj5
Sep  2 13:15:04.047: INFO: Got endpoints: latency-svc-7h5nq [299.667036ms]
Sep  2 13:15:04.061: INFO: Created: latency-svc-29m9x
Sep  2 13:15:04.098: INFO: Got endpoints: latency-svc-x6zd8 [339.581516ms]
Sep  2 13:15:04.118: INFO: Created: latency-svc-rhv7k
Sep  2 13:15:04.147: INFO: Got endpoints: latency-svc-5q7hx [379.304686ms]
Sep  2 13:15:04.160: INFO: Created: latency-svc-sk9s2
Sep  2 13:15:04.197: INFO: Got endpoints: latency-svc-zfhwp [421.566552ms]
Sep  2 13:15:04.211: INFO: Created: latency-svc-rrqfn
Sep  2 13:15:04.247: INFO: Got endpoints: latency-svc-s4tv9 [460.371411ms]
Sep  2 13:15:04.262: INFO: Created: latency-svc-6mmqd
Sep  2 13:15:04.297: INFO: Got endpoints: latency-svc-xhqz7 [503.387215ms]
Sep  2 13:15:04.310: INFO: Created: latency-svc-hw7xv
Sep  2 13:15:04.347: INFO: Got endpoints: latency-svc-sstlj [541.87966ms]
Sep  2 13:15:04.361: INFO: Created: latency-svc-s9zqt
Sep  2 13:15:04.397: INFO: Got endpoints: latency-svc-psh8k [582.294271ms]
Sep  2 13:15:04.411: INFO: Created: latency-svc-zbhg8
Sep  2 13:15:04.447: INFO: Got endpoints: latency-svc-b4l5p [615.139582ms]
Sep  2 13:15:04.460: INFO: Created: latency-svc-cvc8r
Sep  2 13:15:04.498: INFO: Got endpoints: latency-svc-kfbz6 [657.203962ms]
Sep  2 13:15:04.511: INFO: Created: latency-svc-5wn2v
Sep  2 13:15:04.548: INFO: Got endpoints: latency-svc-tv4vq [699.161685ms]
Sep  2 13:15:04.562: INFO: Created: latency-svc-bng94
Sep  2 13:15:04.597: INFO: Got endpoints: latency-svc-lbdgv [736.491472ms]
Sep  2 13:15:04.610: INFO: Created: latency-svc-dhtmp
Sep  2 13:15:04.647: INFO: Got endpoints: latency-svc-8wfhf [748.875818ms]
Sep  2 13:15:04.660: INFO: Created: latency-svc-c6mdh
Sep  2 13:15:04.697: INFO: Got endpoints: latency-svc-w7zhj [749.107153ms]
Sep  2 13:15:04.711: INFO: Created: latency-svc-xcj2g
Sep  2 13:15:04.747: INFO: Got endpoints: latency-svc-jzmj5 [747.988362ms]
Sep  2 13:15:04.760: INFO: Created: latency-svc-7tdfm
Sep  2 13:15:04.797: INFO: Got endpoints: latency-svc-29m9x [749.626349ms]
Sep  2 13:15:04.810: INFO: Created: latency-svc-h5k4c
Sep  2 13:15:04.848: INFO: Got endpoints: latency-svc-rhv7k [749.5907ms]
Sep  2 13:15:04.861: INFO: Created: latency-svc-ws22p
Sep  2 13:15:04.897: INFO: Got endpoints: latency-svc-sk9s2 [749.564332ms]
Sep  2 13:15:04.910: INFO: Created: latency-svc-hplk2
Sep  2 13:15:04.948: INFO: Got endpoints: latency-svc-rrqfn [750.298468ms]
Sep  2 13:15:04.960: INFO: Created: latency-svc-fz9s8
Sep  2 13:15:04.998: INFO: Got endpoints: latency-svc-6mmqd [750.886245ms]
Sep  2 13:15:05.011: INFO: Created: latency-svc-bklbc
Sep  2 13:15:05.048: INFO: Got endpoints: latency-svc-hw7xv [750.038196ms]
Sep  2 13:15:05.061: INFO: Created: latency-svc-5ktvm
Sep  2 13:15:05.098: INFO: Got endpoints: latency-svc-s9zqt [751.113236ms]
Sep  2 13:15:05.114: INFO: Created: latency-svc-rnm75
Sep  2 13:15:05.148: INFO: Got endpoints: latency-svc-zbhg8 [750.586465ms]
Sep  2 13:15:05.162: INFO: Created: latency-svc-mnq9f
Sep  2 13:15:05.197: INFO: Got endpoints: latency-svc-cvc8r [750.284262ms]
Sep  2 13:15:05.210: INFO: Created: latency-svc-gdjqw
Sep  2 13:15:05.248: INFO: Got endpoints: latency-svc-5wn2v [750.136266ms]
Sep  2 13:15:05.263: INFO: Created: latency-svc-65t2w
Sep  2 13:15:05.298: INFO: Got endpoints: latency-svc-bng94 [750.170244ms]
Sep  2 13:15:05.312: INFO: Created: latency-svc-8mllz
Sep  2 13:15:05.347: INFO: Got endpoints: latency-svc-dhtmp [750.276375ms]
Sep  2 13:15:05.360: INFO: Created: latency-svc-dgqwh
Sep  2 13:15:05.398: INFO: Got endpoints: latency-svc-c6mdh [750.712479ms]
Sep  2 13:15:05.411: INFO: Created: latency-svc-nv24n
Sep  2 13:15:05.448: INFO: Got endpoints: latency-svc-xcj2g [750.330665ms]
Sep  2 13:15:05.462: INFO: Created: latency-svc-jdxx4
Sep  2 13:15:05.497: INFO: Got endpoints: latency-svc-7tdfm [750.173256ms]
Sep  2 13:15:05.511: INFO: Created: latency-svc-2wlbv
Sep  2 13:15:05.548: INFO: Got endpoints: latency-svc-h5k4c [750.857809ms]
Sep  2 13:15:05.561: INFO: Created: latency-svc-sc6cb
Sep  2 13:15:05.598: INFO: Got endpoints: latency-svc-ws22p [750.329226ms]
Sep  2 13:15:05.611: INFO: Created: latency-svc-rt7jz
Sep  2 13:15:05.647: INFO: Got endpoints: latency-svc-hplk2 [750.085888ms]
Sep  2 13:15:05.660: INFO: Created: latency-svc-2rhmq
Sep  2 13:15:05.698: INFO: Got endpoints: latency-svc-fz9s8 [750.299034ms]
Sep  2 13:15:05.712: INFO: Created: latency-svc-sfr6r
Sep  2 13:15:05.747: INFO: Got endpoints: latency-svc-bklbc [749.124256ms]
Sep  2 13:15:05.760: INFO: Created: latency-svc-8t2ht
Sep  2 13:15:05.798: INFO: Got endpoints: latency-svc-5ktvm [750.075853ms]
Sep  2 13:15:05.811: INFO: Created: latency-svc-qtsc8
Sep  2 13:15:05.847: INFO: Got endpoints: latency-svc-rnm75 [748.781366ms]
Sep  2 13:15:05.863: INFO: Created: latency-svc-5xc57
Sep  2 13:15:05.897: INFO: Got endpoints: latency-svc-mnq9f [748.956913ms]
Sep  2 13:15:05.910: INFO: Created: latency-svc-mhwn5
Sep  2 13:15:05.947: INFO: Got endpoints: latency-svc-gdjqw [749.533331ms]
Sep  2 13:15:05.960: INFO: Created: latency-svc-sl5l7
Sep  2 13:15:05.997: INFO: Got endpoints: latency-svc-65t2w [747.606232ms]
Sep  2 13:15:06.011: INFO: Created: latency-svc-tsmw6
Sep  2 13:15:06.047: INFO: Got endpoints: latency-svc-8mllz [749.084826ms]
Sep  2 13:15:06.061: INFO: Created: latency-svc-rl4zq
Sep  2 13:15:06.097: INFO: Got endpoints: latency-svc-dgqwh [749.884523ms]
Sep  2 13:15:06.110: INFO: Created: latency-svc-2tpgf
Sep  2 13:15:06.147: INFO: Got endpoints: latency-svc-nv24n [749.139195ms]
Sep  2 13:15:06.161: INFO: Created: latency-svc-pvs6g
Sep  2 13:15:06.197: INFO: Got endpoints: latency-svc-jdxx4 [749.258784ms]
Sep  2 13:15:06.211: INFO: Created: latency-svc-qmxrn
Sep  2 13:15:06.247: INFO: Got endpoints: latency-svc-2wlbv [750.231604ms]
Sep  2 13:15:06.260: INFO: Created: latency-svc-4ddlf
Sep  2 13:15:06.297: INFO: Got endpoints: latency-svc-sc6cb [749.297286ms]
Sep  2 13:15:06.311: INFO: Created: latency-svc-6p9h6
Sep  2 13:15:06.348: INFO: Got endpoints: latency-svc-rt7jz [749.394574ms]
Sep  2 13:15:06.361: INFO: Created: latency-svc-rwmpt
Sep  2 13:15:06.398: INFO: Got endpoints: latency-svc-2rhmq [750.387692ms]
Sep  2 13:15:06.411: INFO: Created: latency-svc-6wwkf
Sep  2 13:15:06.448: INFO: Got endpoints: latency-svc-sfr6r [749.815448ms]
Sep  2 13:15:06.463: INFO: Created: latency-svc-kfrmv
Sep  2 13:15:06.497: INFO: Got endpoints: latency-svc-8t2ht [750.107318ms]
Sep  2 13:15:06.511: INFO: Created: latency-svc-tgrrv
Sep  2 13:15:06.547: INFO: Got endpoints: latency-svc-qtsc8 [749.665459ms]
Sep  2 13:15:06.560: INFO: Created: latency-svc-tjvxg
Sep  2 13:15:06.598: INFO: Got endpoints: latency-svc-5xc57 [750.290061ms]
Sep  2 13:15:06.611: INFO: Created: latency-svc-xknfj
Sep  2 13:15:06.648: INFO: Got endpoints: latency-svc-mhwn5 [750.518873ms]
Sep  2 13:15:06.662: INFO: Created: latency-svc-wlp6g
Sep  2 13:15:06.698: INFO: Got endpoints: latency-svc-sl5l7 [750.335818ms]
Sep  2 13:15:06.710: INFO: Created: latency-svc-qtplr
Sep  2 13:15:06.747: INFO: Got endpoints: latency-svc-tsmw6 [750.057714ms]
Sep  2 13:15:06.762: INFO: Created: latency-svc-jjtft
Sep  2 13:15:06.798: INFO: Got endpoints: latency-svc-rl4zq [750.33826ms]
Sep  2 13:15:06.811: INFO: Created: latency-svc-7zxmz
Sep  2 13:15:06.848: INFO: Got endpoints: latency-svc-2tpgf [750.095754ms]
Sep  2 13:15:06.861: INFO: Created: latency-svc-lxxsf
Sep  2 13:15:06.898: INFO: Got endpoints: latency-svc-pvs6g [750.3036ms]
Sep  2 13:15:06.911: INFO: Created: latency-svc-wlnkv
Sep  2 13:15:06.947: INFO: Got endpoints: latency-svc-qmxrn [749.946886ms]
Sep  2 13:15:06.960: INFO: Created: latency-svc-wx9d6
Sep  2 13:15:06.998: INFO: Got endpoints: latency-svc-4ddlf [750.937696ms]
Sep  2 13:15:07.011: INFO: Created: latency-svc-7dwkq
Sep  2 13:15:07.048: INFO: Got endpoints: latency-svc-6p9h6 [750.153234ms]
Sep  2 13:15:07.061: INFO: Created: latency-svc-wnhbt
Sep  2 13:15:07.097: INFO: Got endpoints: latency-svc-rwmpt [749.764398ms]
Sep  2 13:15:07.111: INFO: Created: latency-svc-slzvd
Sep  2 13:15:07.147: INFO: Got endpoints: latency-svc-6wwkf [749.604733ms]
Sep  2 13:15:07.161: INFO: Created: latency-svc-xzzd2
Sep  2 13:15:07.197: INFO: Got endpoints: latency-svc-kfrmv [749.259141ms]
Sep  2 13:15:07.210: INFO: Created: latency-svc-pzs5d
Sep  2 13:15:07.248: INFO: Got endpoints: latency-svc-tgrrv [750.109449ms]
Sep  2 13:15:07.261: INFO: Created: latency-svc-jjd4w
Sep  2 13:15:07.297: INFO: Got endpoints: latency-svc-tjvxg [750.005422ms]
Sep  2 13:15:07.311: INFO: Created: latency-svc-qf2v7
Sep  2 13:15:07.347: INFO: Got endpoints: latency-svc-xknfj [749.812315ms]
Sep  2 13:15:07.361: INFO: Created: latency-svc-vrhdl
Sep  2 13:15:07.397: INFO: Got endpoints: latency-svc-wlp6g [749.24849ms]
Sep  2 13:15:07.410: INFO: Created: latency-svc-d848m
Sep  2 13:15:07.447: INFO: Got endpoints: latency-svc-qtplr [749.645225ms]
Sep  2 13:15:07.461: INFO: Created: latency-svc-t8dcp
Sep  2 13:15:07.497: INFO: Got endpoints: latency-svc-jjtft [749.621755ms]
Sep  2 13:15:07.511: INFO: Created: latency-svc-vl4fg
Sep  2 13:15:07.547: INFO: Got endpoints: latency-svc-7zxmz [749.38573ms]
Sep  2 13:15:07.560: INFO: Created: latency-svc-nl9sd
Sep  2 13:15:07.598: INFO: Got endpoints: latency-svc-lxxsf [749.983853ms]
Sep  2 13:15:07.610: INFO: Created: latency-svc-6kcbg
Sep  2 13:15:07.647: INFO: Got endpoints: latency-svc-wlnkv [749.566067ms]
Sep  2 13:15:07.661: INFO: Created: latency-svc-4knsr
Sep  2 13:15:07.697: INFO: Got endpoints: latency-svc-wx9d6 [750.030453ms]
Sep  2 13:15:07.710: INFO: Created: latency-svc-p46tn
Sep  2 13:15:07.747: INFO: Got endpoints: latency-svc-7dwkq [748.521489ms]
Sep  2 13:15:07.760: INFO: Created: latency-svc-hbrlc
Sep  2 13:15:07.797: INFO: Got endpoints: latency-svc-wnhbt [749.515102ms]
Sep  2 13:15:07.810: INFO: Created: latency-svc-jjvzt
Sep  2 13:15:07.847: INFO: Got endpoints: latency-svc-slzvd [749.680484ms]
Sep  2 13:15:07.860: INFO: Created: latency-svc-4x7r4
Sep  2 13:15:07.897: INFO: Got endpoints: latency-svc-xzzd2 [749.591618ms]
Sep  2 13:15:07.910: INFO: Created: latency-svc-4tjjf
Sep  2 13:15:07.947: INFO: Got endpoints: latency-svc-pzs5d [749.862289ms]
Sep  2 13:15:07.961: INFO: Created: latency-svc-8d4nh
Sep  2 13:15:07.997: INFO: Got endpoints: latency-svc-jjd4w [749.392902ms]
Sep  2 13:15:08.011: INFO: Created: latency-svc-8tzfn
Sep  2 13:15:08.047: INFO: Got endpoints: latency-svc-qf2v7 [749.497773ms]
Sep  2 13:15:08.060: INFO: Created: latency-svc-26nsg
Sep  2 13:15:08.098: INFO: Got endpoints: latency-svc-vrhdl [750.12559ms]
Sep  2 13:15:08.110: INFO: Created: latency-svc-xqrdq
Sep  2 13:15:08.147: INFO: Got endpoints: latency-svc-d848m [750.111836ms]
Sep  2 13:15:08.160: INFO: Created: latency-svc-krkkk
Sep  2 13:15:08.198: INFO: Got endpoints: latency-svc-t8dcp [750.619195ms]
Sep  2 13:15:08.211: INFO: Created: latency-svc-h6lv9
Sep  2 13:15:08.248: INFO: Got endpoints: latency-svc-vl4fg [750.621422ms]
Sep  2 13:15:08.260: INFO: Created: latency-svc-c4d65
Sep  2 13:15:08.297: INFO: Got endpoints: latency-svc-nl9sd [750.099986ms]
Sep  2 13:15:08.310: INFO: Created: latency-svc-pf6g8
Sep  2 13:15:08.348: INFO: Got endpoints: latency-svc-6kcbg [750.141786ms]
Sep  2 13:15:08.360: INFO: Created: latency-svc-pfznm
Sep  2 13:15:08.399: INFO: Got endpoints: latency-svc-4knsr [751.754862ms]
Sep  2 13:15:08.411: INFO: Created: latency-svc-d4xrr
Sep  2 13:15:08.447: INFO: Got endpoints: latency-svc-p46tn [749.400579ms]
Sep  2 13:15:08.461: INFO: Created: latency-svc-7tnh4
Sep  2 13:15:08.498: INFO: Got endpoints: latency-svc-hbrlc [750.733552ms]
Sep  2 13:15:08.510: INFO: Created: latency-svc-dv75m
Sep  2 13:15:08.548: INFO: Got endpoints: latency-svc-jjvzt [750.942475ms]
Sep  2 13:15:08.560: INFO: Created: latency-svc-wn4wx
Sep  2 13:15:08.597: INFO: Got endpoints: latency-svc-4x7r4 [750.255661ms]
Sep  2 13:15:08.610: INFO: Created: latency-svc-mpv9s
Sep  2 13:15:08.648: INFO: Got endpoints: latency-svc-4tjjf [751.098177ms]
Sep  2 13:15:08.661: INFO: Created: latency-svc-6bs7z
Sep  2 13:15:08.698: INFO: Got endpoints: latency-svc-8d4nh [750.524242ms]
Sep  2 13:15:08.710: INFO: Created: latency-svc-7hp7x
Sep  2 13:15:08.747: INFO: Got endpoints: latency-svc-8tzfn [749.664311ms]
Sep  2 13:15:08.760: INFO: Created: latency-svc-hbcgn
Sep  2 13:15:08.798: INFO: Got endpoints: latency-svc-26nsg [751.12937ms]
Sep  2 13:15:08.811: INFO: Created: latency-svc-t9kdl
Sep  2 13:15:08.847: INFO: Got endpoints: latency-svc-xqrdq [749.223391ms]
Sep  2 13:15:08.860: INFO: Created: latency-svc-nf9nv
Sep  2 13:15:08.898: INFO: Got endpoints: latency-svc-krkkk [750.574263ms]
Sep  2 13:15:08.911: INFO: Created: latency-svc-m4dsp
Sep  2 13:15:08.947: INFO: Got endpoints: latency-svc-h6lv9 [749.054416ms]
Sep  2 13:15:08.960: INFO: Created: latency-svc-wx8kh
Sep  2 13:15:08.997: INFO: Got endpoints: latency-svc-c4d65 [749.209801ms]
Sep  2 13:15:09.010: INFO: Created: latency-svc-6lkxs
Sep  2 13:15:09.047: INFO: Got endpoints: latency-svc-pf6g8 [749.831324ms]
Sep  2 13:15:09.060: INFO: Created: latency-svc-wdp6b
Sep  2 13:15:09.097: INFO: Got endpoints: latency-svc-pfznm [749.077064ms]
Sep  2 13:15:09.109: INFO: Created: latency-svc-6st96
Sep  2 13:15:09.147: INFO: Got endpoints: latency-svc-d4xrr [747.984075ms]
Sep  2 13:15:09.160: INFO: Created: latency-svc-t9k2w
Sep  2 13:15:09.197: INFO: Got endpoints: latency-svc-7tnh4 [750.151121ms]
Sep  2 13:15:09.210: INFO: Created: latency-svc-ngq87
Sep  2 13:15:09.247: INFO: Got endpoints: latency-svc-dv75m [749.074372ms]
Sep  2 13:15:09.259: INFO: Created: latency-svc-svtmr
Sep  2 13:15:09.297: INFO: Got endpoints: latency-svc-wn4wx [749.254162ms]
Sep  2 13:15:09.310: INFO: Created: latency-svc-4tzgr
Sep  2 13:15:09.347: INFO: Got endpoints: latency-svc-mpv9s [749.91111ms]
Sep  2 13:15:09.360: INFO: Created: latency-svc-fkglc
Sep  2 13:15:09.397: INFO: Got endpoints: latency-svc-6bs7z [749.046413ms]
Sep  2 13:15:09.411: INFO: Created: latency-svc-g2sml
Sep  2 13:15:09.447: INFO: Got endpoints: latency-svc-7hp7x [749.326628ms]
Sep  2 13:15:09.460: INFO: Created: latency-svc-hf2gb
Sep  2 13:15:09.497: INFO: Got endpoints: latency-svc-hbcgn [750.170987ms]
Sep  2 13:15:09.510: INFO: Created: latency-svc-s577v
Sep  2 13:15:09.547: INFO: Got endpoints: latency-svc-t9kdl [748.884843ms]
Sep  2 13:15:09.561: INFO: Created: latency-svc-k7wx6
Sep  2 13:15:09.597: INFO: Got endpoints: latency-svc-nf9nv [750.274421ms]
Sep  2 13:15:09.610: INFO: Created: latency-svc-2q8n5
Sep  2 13:15:09.648: INFO: Got endpoints: latency-svc-m4dsp [749.587799ms]
Sep  2 13:15:09.661: INFO: Created: latency-svc-rb6l2
Sep  2 13:15:09.698: INFO: Got endpoints: latency-svc-wx8kh [751.242816ms]
Sep  2 13:15:09.712: INFO: Created: latency-svc-gdthv
Sep  2 13:15:09.747: INFO: Got endpoints: latency-svc-6lkxs [750.351431ms]
Sep  2 13:15:09.760: INFO: Created: latency-svc-c5dpg
Sep  2 13:15:09.797: INFO: Got endpoints: latency-svc-wdp6b [750.2017ms]
Sep  2 13:15:09.811: INFO: Created: latency-svc-4pfl9
Sep  2 13:15:09.847: INFO: Got endpoints: latency-svc-6st96 [750.18537ms]
Sep  2 13:15:09.861: INFO: Created: latency-svc-p8lvf
Sep  2 13:15:09.897: INFO: Got endpoints: latency-svc-t9k2w [749.758587ms]
Sep  2 13:15:09.911: INFO: Created: latency-svc-l5785
Sep  2 13:15:09.947: INFO: Got endpoints: latency-svc-ngq87 [749.686391ms]
Sep  2 13:15:09.960: INFO: Created: latency-svc-jf4bz
Sep  2 13:15:09.998: INFO: Got endpoints: latency-svc-svtmr [750.959205ms]
Sep  2 13:15:10.013: INFO: Created: latency-svc-sp48t
Sep  2 13:15:10.047: INFO: Got endpoints: latency-svc-4tzgr [750.000771ms]
Sep  2 13:15:10.060: INFO: Created: latency-svc-gdv26
Sep  2 13:15:10.099: INFO: Got endpoints: latency-svc-fkglc [751.610072ms]
Sep  2 13:15:10.113: INFO: Created: latency-svc-r2q2k
Sep  2 13:15:10.148: INFO: Got endpoints: latency-svc-g2sml [750.648736ms]
Sep  2 13:15:10.161: INFO: Created: latency-svc-rzppp
Sep  2 13:15:10.197: INFO: Got endpoints: latency-svc-hf2gb [750.112063ms]
Sep  2 13:15:10.210: INFO: Created: latency-svc-nsst4
Sep  2 13:15:10.247: INFO: Got endpoints: latency-svc-s577v [750.283457ms]
Sep  2 13:15:10.260: INFO: Created: latency-svc-2qsff
Sep  2 13:15:10.298: INFO: Got endpoints: latency-svc-k7wx6 [750.592037ms]
Sep  2 13:15:10.311: INFO: Created: latency-svc-8spxw
Sep  2 13:15:10.348: INFO: Got endpoints: latency-svc-2q8n5 [750.674066ms]
Sep  2 13:15:10.361: INFO: Created: latency-svc-bchdx
Sep  2 13:15:10.397: INFO: Got endpoints: latency-svc-rb6l2 [749.660776ms]
Sep  2 13:15:10.410: INFO: Created: latency-svc-hd9md
Sep  2 13:15:10.448: INFO: Got endpoints: latency-svc-gdthv [750.040335ms]
Sep  2 13:15:10.462: INFO: Created: latency-svc-ms8rl
Sep  2 13:15:10.498: INFO: Got endpoints: latency-svc-c5dpg [750.637924ms]
Sep  2 13:15:10.511: INFO: Created: latency-svc-9nkr9
Sep  2 13:15:10.547: INFO: Got endpoints: latency-svc-4pfl9 [749.827529ms]
Sep  2 13:15:10.560: INFO: Created: latency-svc-r587z
Sep  2 13:15:10.598: INFO: Got endpoints: latency-svc-p8lvf [750.907077ms]
Sep  2 13:15:10.611: INFO: Created: latency-svc-22nst
Sep  2 13:15:10.648: INFO: Got endpoints: latency-svc-l5785 [750.714913ms]
Sep  2 13:15:10.660: INFO: Created: latency-svc-rpmn7
Sep  2 13:15:10.697: INFO: Got endpoints: latency-svc-jf4bz [750.159958ms]
Sep  2 13:15:10.710: INFO: Created: latency-svc-p4znk
Sep  2 13:15:10.748: INFO: Got endpoints: latency-svc-sp48t [749.838529ms]
Sep  2 13:15:10.760: INFO: Created: latency-svc-rvv6l
Sep  2 13:15:10.798: INFO: Got endpoints: latency-svc-gdv26 [750.490674ms]
Sep  2 13:15:10.810: INFO: Created: latency-svc-n5plc
Sep  2 13:15:10.848: INFO: Got endpoints: latency-svc-r2q2k [748.546346ms]
Sep  2 13:15:10.861: INFO: Created: latency-svc-kkfrk
Sep  2 13:15:10.898: INFO: Got endpoints: latency-svc-rzppp [749.753089ms]
Sep  2 13:15:10.911: INFO: Created: latency-svc-dd9ql
Sep  2 13:15:10.947: INFO: Got endpoints: latency-svc-nsst4 [750.043376ms]
Sep  2 13:15:10.961: INFO: Created: latency-svc-972ms
Sep  2 13:15:10.998: INFO: Got endpoints: latency-svc-2qsff [750.630869ms]
Sep  2 13:15:11.012: INFO: Created: latency-svc-97gl5
Sep  2 13:15:11.047: INFO: Got endpoints: latency-svc-8spxw [749.319467ms]
Sep  2 13:15:11.060: INFO: Created: latency-svc-lrgdd
Sep  2 13:15:11.097: INFO: Got endpoints: latency-svc-bchdx [749.140827ms]
Sep  2 13:15:11.110: INFO: Created: latency-svc-bg559
Sep  2 13:15:11.148: INFO: Got endpoints: latency-svc-hd9md [750.604111ms]
Sep  2 13:15:11.161: INFO: Created: latency-svc-mdkbg
Sep  2 13:15:11.197: INFO: Got endpoints: latency-svc-ms8rl [748.746735ms]
Sep  2 13:15:11.210: INFO: Created: latency-svc-pgq7j
Sep  2 13:15:11.247: INFO: Got endpoints: latency-svc-9nkr9 [748.789484ms]
Sep  2 13:15:11.260: INFO: Created: latency-svc-m47bb
Sep  2 13:15:11.297: INFO: Got endpoints: latency-svc-r587z [749.963372ms]
Sep  2 13:15:11.311: INFO: Created: latency-svc-t2glm
Sep  2 13:15:11.347: INFO: Got endpoints: latency-svc-22nst [748.88906ms]
Sep  2 13:15:11.398: INFO: Got endpoints: latency-svc-rpmn7 [750.434734ms]
Sep  2 13:15:11.447: INFO: Got endpoints: latency-svc-p4znk [750.134118ms]
Sep  2 13:15:11.497: INFO: Got endpoints: latency-svc-rvv6l [749.572394ms]
Sep  2 13:15:11.547: INFO: Got endpoints: latency-svc-n5plc [749.297759ms]
Sep  2 13:15:11.598: INFO: Got endpoints: latency-svc-kkfrk [750.344419ms]
Sep  2 13:15:11.648: INFO: Got endpoints: latency-svc-dd9ql [749.940891ms]
Sep  2 13:15:11.697: INFO: Got endpoints: latency-svc-972ms [749.879617ms]
Sep  2 13:15:11.748: INFO: Got endpoints: latency-svc-97gl5 [750.014257ms]
Sep  2 13:15:11.797: INFO: Got endpoints: latency-svc-lrgdd [750.144879ms]
Sep  2 13:15:11.847: INFO: Got endpoints: latency-svc-bg559 [749.807355ms]
Sep  2 13:15:11.897: INFO: Got endpoints: latency-svc-mdkbg [749.495134ms]
Sep  2 13:15:11.948: INFO: Got endpoints: latency-svc-pgq7j [750.589017ms]
Sep  2 13:15:11.998: INFO: Got endpoints: latency-svc-m47bb [750.536156ms]
Sep  2 13:15:12.048: INFO: Got endpoints: latency-svc-t2glm [750.434028ms]
Sep  2 13:15:12.048: INFO: Latencies: [18.863891ms 26.631104ms 37.166254ms 46.212771ms 56.377414ms 64.021614ms 72.638983ms 81.383494ms 93.55003ms 103.42889ms 110.731819ms 120.365118ms 130.443186ms 139.115261ms 139.274045ms 139.90644ms 140.066706ms 140.15721ms 140.433501ms 140.566309ms 140.807069ms 140.834925ms 141.115135ms 141.502192ms 141.782885ms 141.797599ms 142.003859ms 142.325963ms 142.412792ms 142.49874ms 143.327941ms 146.665896ms 148.236529ms 148.906605ms 148.956903ms 149.6238ms 178.296748ms 218.464855ms 259.423093ms 299.667036ms 339.581516ms 379.304686ms 421.566552ms 460.371411ms 503.387215ms 541.87966ms 582.294271ms 615.139582ms 657.203962ms 699.161685ms 736.491472ms 747.606232ms 747.984075ms 747.988362ms 748.521489ms 748.546346ms 748.746735ms 748.781366ms 748.789484ms 748.875818ms 748.884843ms 748.88906ms 748.956913ms 749.046413ms 749.054416ms 749.074372ms 749.077064ms 749.084826ms 749.107153ms 749.124256ms 749.139195ms 749.140827ms 749.209801ms 749.223391ms 749.24849ms 749.254162ms 749.258784ms 749.259141ms 749.297286ms 749.297759ms 749.319467ms 749.326628ms 749.38573ms 749.392902ms 749.394574ms 749.400579ms 749.495134ms 749.497773ms 749.515102ms 749.533331ms 749.564332ms 749.566067ms 749.572394ms 749.587799ms 749.5907ms 749.591618ms 749.604733ms 749.621755ms 749.626349ms 749.645225ms 749.660776ms 749.664311ms 749.665459ms 749.680484ms 749.686391ms 749.753089ms 749.758587ms 749.764398ms 749.807355ms 749.812315ms 749.815448ms 749.827529ms 749.831324ms 749.838529ms 749.862289ms 749.879617ms 749.884523ms 749.91111ms 749.940891ms 749.946886ms 749.963372ms 749.983853ms 750.000771ms 750.005422ms 750.014257ms 750.030453ms 750.038196ms 750.040335ms 750.043376ms 750.057714ms 750.075853ms 750.085888ms 750.095754ms 750.099986ms 750.107318ms 750.109449ms 750.111836ms 750.112063ms 750.12559ms 750.134118ms 750.136266ms 750.141786ms 750.144879ms 750.151121ms 750.153234ms 750.159958ms 750.170244ms 750.170987ms 750.173256ms 750.18537ms 750.2017ms 750.231604ms 750.255661ms 750.274421ms 750.276375ms 750.283457ms 750.284262ms 750.290061ms 750.298468ms 750.299034ms 750.3036ms 750.329226ms 750.330665ms 750.335818ms 750.33826ms 750.344419ms 750.351431ms 750.387692ms 750.434028ms 750.434734ms 750.490674ms 750.518873ms 750.524242ms 750.536156ms 750.574263ms 750.586465ms 750.589017ms 750.592037ms 750.604111ms 750.619195ms 750.621422ms 750.630869ms 750.637924ms 750.648736ms 750.674066ms 750.712479ms 750.714913ms 750.733552ms 750.857809ms 750.886245ms 750.907077ms 750.937696ms 750.942475ms 750.959205ms 751.098177ms 751.113236ms 751.12937ms 751.242816ms 751.610072ms 751.754862ms]
Sep  2 13:15:12.048: INFO: 50 %ile: 749.660776ms
Sep  2 13:15:12.048: INFO: 90 %ile: 750.621422ms
Sep  2 13:15:12.048: INFO: 99 %ile: 751.610072ms
Sep  2 13:15:12.048: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:15:12.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-7r6kn" for this suite.
Sep  2 13:15:32.074: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:15:32.173: INFO: namespace: e2e-tests-svc-latency-7r6kn, resource: bindings, ignored listing per whitelist
Sep  2 13:15:32.173: INFO: namespace e2e-tests-svc-latency-7r6kn deletion completed in 20.120140598s

• [SLOW TEST:32.023 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:15:32.174: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-lhk7h
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-bdfd647e-cd83-11e9-b90e-8ed318f3d3c6
STEP: Creating a pod to test consume configMaps
Sep  2 13:15:32.354: INFO: Waiting up to 5m0s for pod "pod-configmaps-bdfe1572-cd83-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-configmap-lhk7h" to be "success or failure"
Sep  2 13:15:32.356: INFO: Pod "pod-configmaps-bdfe1572-cd83-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.356786ms
Sep  2 13:15:34.359: INFO: Pod "pod-configmaps-bdfe1572-cd83-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005695709s
STEP: Saw pod success
Sep  2 13:15:34.359: INFO: Pod "pod-configmaps-bdfe1572-cd83-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 13:15:34.362: INFO: Trying to get logs from node ip-192-168-185-95.us-west-2.compute.internal pod pod-configmaps-bdfe1572-cd83-11e9-b90e-8ed318f3d3c6 container configmap-volume-test: <nil>
STEP: delete the pod
Sep  2 13:15:34.380: INFO: Waiting for pod pod-configmaps-bdfe1572-cd83-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 13:15:34.382: INFO: Pod pod-configmaps-bdfe1572-cd83-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:15:34.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-lhk7h" for this suite.
Sep  2 13:15:40.403: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:15:40.408: INFO: namespace: e2e-tests-configmap-lhk7h, resource: bindings, ignored listing per whitelist
Sep  2 13:15:40.502: INFO: namespace e2e-tests-configmap-lhk7h deletion completed in 6.115581103s

• [SLOW TEST:8.328 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:15:40.502: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-bfx6j
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Sep  2 13:15:40.671: INFO: Waiting up to 5m0s for pod "pod-c2f33327-cd83-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-emptydir-bfx6j" to be "success or failure"
Sep  2 13:15:40.674: INFO: Pod "pod-c2f33327-cd83-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.268458ms
Sep  2 13:15:42.676: INFO: Pod "pod-c2f33327-cd83-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005153659s
STEP: Saw pod success
Sep  2 13:15:42.677: INFO: Pod "pod-c2f33327-cd83-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 13:15:42.679: INFO: Trying to get logs from node ip-192-168-77-237.us-west-2.compute.internal pod pod-c2f33327-cd83-11e9-b90e-8ed318f3d3c6 container test-container: <nil>
STEP: delete the pod
Sep  2 13:15:42.695: INFO: Waiting for pod pod-c2f33327-cd83-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 13:15:42.697: INFO: Pod pod-c2f33327-cd83-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:15:42.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-bfx6j" for this suite.
Sep  2 13:15:48.723: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:15:48.747: INFO: namespace: e2e-tests-emptydir-bfx6j, resource: bindings, ignored listing per whitelist
Sep  2 13:15:48.819: INFO: namespace e2e-tests-emptydir-bfx6j deletion completed in 6.118765627s

• [SLOW TEST:8.318 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:15:48.820: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-7kgb4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Sep  2 13:15:49.009: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
Sep  2 13:15:49.018: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-7kgb4/daemonsets","resourceVersion":"2089070"},"items":null}

Sep  2 13:15:49.021: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-7kgb4/pods","resourceVersion":"2089070"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:15:49.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-7kgb4" for this suite.
Sep  2 13:15:55.052: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:15:55.075: INFO: namespace: e2e-tests-daemonsets-7kgb4, resource: bindings, ignored listing per whitelist
Sep  2 13:15:55.148: INFO: namespace e2e-tests-daemonsets-7kgb4 deletion completed in 6.112156634s

S [SKIPPING] [6.328 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Sep  2 13:15:49.009: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:15:55.148: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-7whgm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1358
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep  2 13:15:55.308: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-7whgm'
Sep  2 13:15:55.666: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep  2 13:15:55.666: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Sep  2 13:15:55.670: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Sep  2 13:15:55.681: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Sep  2 13:15:55.691: INFO: scanned /root for discovery docs: <nil>
Sep  2 13:15:55.691: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-7whgm'
Sep  2 13:16:11.448: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Sep  2 13:16:11.448: INFO: stdout: "Created e2e-test-nginx-rc-0573ecbd86442d9b21dfaaad0e39bdbb\nScaling up e2e-test-nginx-rc-0573ecbd86442d9b21dfaaad0e39bdbb from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-0573ecbd86442d9b21dfaaad0e39bdbb up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-0573ecbd86442d9b21dfaaad0e39bdbb to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Sep  2 13:16:11.448: INFO: stdout: "Created e2e-test-nginx-rc-0573ecbd86442d9b21dfaaad0e39bdbb\nScaling up e2e-test-nginx-rc-0573ecbd86442d9b21dfaaad0e39bdbb from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-0573ecbd86442d9b21dfaaad0e39bdbb up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-0573ecbd86442d9b21dfaaad0e39bdbb to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Sep  2 13:16:11.449: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-7whgm'
Sep  2 13:16:11.519: INFO: stderr: ""
Sep  2 13:16:11.519: INFO: stdout: "e2e-test-nginx-rc-0573ecbd86442d9b21dfaaad0e39bdbb-9257s e2e-test-nginx-rc-vtkcw "
STEP: Replicas for run=e2e-test-nginx-rc: expected=1 actual=2
Sep  2 13:16:16.519: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-7whgm'
Sep  2 13:16:16.588: INFO: stderr: ""
Sep  2 13:16:16.588: INFO: stdout: "e2e-test-nginx-rc-0573ecbd86442d9b21dfaaad0e39bdbb-9257s "
Sep  2 13:16:16.588: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 get pods e2e-test-nginx-rc-0573ecbd86442d9b21dfaaad0e39bdbb-9257s -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7whgm'
Sep  2 13:16:16.654: INFO: stderr: ""
Sep  2 13:16:16.654: INFO: stdout: "true"
Sep  2 13:16:16.654: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 get pods e2e-test-nginx-rc-0573ecbd86442d9b21dfaaad0e39bdbb-9257s -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7whgm'
Sep  2 13:16:16.716: INFO: stderr: ""
Sep  2 13:16:16.716: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Sep  2 13:16:16.716: INFO: e2e-test-nginx-rc-0573ecbd86442d9b21dfaaad0e39bdbb-9257s is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1364
Sep  2 13:16:16.717: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-7whgm'
Sep  2 13:16:16.786: INFO: stderr: ""
Sep  2 13:16:16.786: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:16:16.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-7whgm" for this suite.
Sep  2 13:16:22.814: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:16:22.834: INFO: namespace: e2e-tests-kubectl-7whgm, resource: bindings, ignored listing per whitelist
Sep  2 13:16:22.909: INFO: namespace e2e-tests-kubectl-7whgm deletion completed in 6.118877734s

• [SLOW TEST:27.761 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:16:22.909: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-46pzb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Sep  2 13:16:23.083: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:16:26.961: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-46pzb" for this suite.
Sep  2 13:16:32.987: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:16:32.992: INFO: namespace: e2e-tests-init-container-46pzb, resource: bindings, ignored listing per whitelist
Sep  2 13:16:33.084: INFO: namespace e2e-tests-init-container-46pzb deletion completed in 6.118859349s

• [SLOW TEST:10.175 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:16:33.084: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-2lh6r
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Sep  2 13:16:33.259: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e24b73c7-cd83-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-downward-api-2lh6r" to be "success or failure"
Sep  2 13:16:33.261: INFO: Pod "downwardapi-volume-e24b73c7-cd83-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.399066ms
Sep  2 13:16:35.265: INFO: Pod "downwardapi-volume-e24b73c7-cd83-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005858099s
Sep  2 13:16:37.268: INFO: Pod "downwardapi-volume-e24b73c7-cd83-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009060883s
STEP: Saw pod success
Sep  2 13:16:37.268: INFO: Pod "downwardapi-volume-e24b73c7-cd83-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 13:16:37.270: INFO: Trying to get logs from node ip-192-168-185-95.us-west-2.compute.internal pod downwardapi-volume-e24b73c7-cd83-11e9-b90e-8ed318f3d3c6 container client-container: <nil>
STEP: delete the pod
Sep  2 13:16:37.287: INFO: Waiting for pod downwardapi-volume-e24b73c7-cd83-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 13:16:37.289: INFO: Pod downwardapi-volume-e24b73c7-cd83-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:16:37.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-2lh6r" for this suite.
Sep  2 13:16:43.314: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:16:43.390: INFO: namespace: e2e-tests-downward-api-2lh6r, resource: bindings, ignored listing per whitelist
Sep  2 13:16:43.414: INFO: namespace e2e-tests-downward-api-2lh6r deletion completed in 6.121011879s

• [SLOW TEST:10.330 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:16:43.414: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-28l7p
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Sep  2 13:16:43.589: INFO: Waiting up to 5m0s for pod "var-expansion-e873a3a3-cd83-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-var-expansion-28l7p" to be "success or failure"
Sep  2 13:16:43.591: INFO: Pod "var-expansion-e873a3a3-cd83-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.295118ms
Sep  2 13:16:45.594: INFO: Pod "var-expansion-e873a3a3-cd83-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005377608s
Sep  2 13:16:47.597: INFO: Pod "var-expansion-e873a3a3-cd83-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008679859s
STEP: Saw pod success
Sep  2 13:16:47.597: INFO: Pod "var-expansion-e873a3a3-cd83-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 13:16:47.600: INFO: Trying to get logs from node ip-192-168-185-95.us-west-2.compute.internal pod var-expansion-e873a3a3-cd83-11e9-b90e-8ed318f3d3c6 container dapi-container: <nil>
STEP: delete the pod
Sep  2 13:16:47.620: INFO: Waiting for pod var-expansion-e873a3a3-cd83-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 13:16:47.622: INFO: Pod var-expansion-e873a3a3-cd83-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:16:47.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-28l7p" for this suite.
Sep  2 13:16:53.647: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:16:53.691: INFO: namespace: e2e-tests-var-expansion-28l7p, resource: bindings, ignored listing per whitelist
Sep  2 13:16:53.749: INFO: namespace e2e-tests-var-expansion-28l7p deletion completed in 6.123380941s

• [SLOW TEST:10.335 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:16:53.749: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-5vd4h
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Sep  2 13:16:53.926: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ee9cfc46-cd83-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-downward-api-5vd4h" to be "success or failure"
Sep  2 13:16:53.929: INFO: Pod "downwardapi-volume-ee9cfc46-cd83-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.800178ms
Sep  2 13:16:55.932: INFO: Pod "downwardapi-volume-ee9cfc46-cd83-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006182513s
STEP: Saw pod success
Sep  2 13:16:55.932: INFO: Pod "downwardapi-volume-ee9cfc46-cd83-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 13:16:55.934: INFO: Trying to get logs from node ip-192-168-77-237.us-west-2.compute.internal pod downwardapi-volume-ee9cfc46-cd83-11e9-b90e-8ed318f3d3c6 container client-container: <nil>
STEP: delete the pod
Sep  2 13:16:55.950: INFO: Waiting for pod downwardapi-volume-ee9cfc46-cd83-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 13:16:55.952: INFO: Pod downwardapi-volume-ee9cfc46-cd83-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:16:55.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-5vd4h" for this suite.
Sep  2 13:17:01.972: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:17:02.014: INFO: namespace: e2e-tests-downward-api-5vd4h, resource: bindings, ignored listing per whitelist
Sep  2 13:17:02.073: INFO: namespace e2e-tests-downward-api-5vd4h deletion completed in 6.117110546s

• [SLOW TEST:8.324 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:17:02.074: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-xnn65
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Sep  2 13:17:06.257: INFO: Pod pod-hostip-f39281d4-cd83-11e9-b90e-8ed318f3d3c6 has hostIP: 192.168.185.95
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:17:06.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-xnn65" for this suite.
Sep  2 13:17:28.276: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:17:28.315: INFO: namespace: e2e-tests-pods-xnn65, resource: bindings, ignored listing per whitelist
Sep  2 13:17:28.373: INFO: namespace e2e-tests-pods-xnn65 deletion completed in 22.113123576s

• [SLOW TEST:26.300 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:17:28.374: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-sflhm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Sep  2 13:17:28.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 create -f - --namespace=e2e-tests-kubectl-sflhm'
Sep  2 13:17:28.779: INFO: stderr: ""
Sep  2 13:17:28.779: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep  2 13:17:28.779: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-sflhm'
Sep  2 13:17:28.857: INFO: stderr: ""
Sep  2 13:17:28.857: INFO: stdout: "update-demo-nautilus-mhh28 update-demo-nautilus-wp9mq "
Sep  2 13:17:28.857: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 get pods update-demo-nautilus-mhh28 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sflhm'
Sep  2 13:17:28.923: INFO: stderr: ""
Sep  2 13:17:28.923: INFO: stdout: ""
Sep  2 13:17:28.923: INFO: update-demo-nautilus-mhh28 is created but not running
Sep  2 13:17:33.924: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-sflhm'
Sep  2 13:17:33.992: INFO: stderr: ""
Sep  2 13:17:33.992: INFO: stdout: "update-demo-nautilus-mhh28 update-demo-nautilus-wp9mq "
Sep  2 13:17:33.992: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 get pods update-demo-nautilus-mhh28 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sflhm'
Sep  2 13:17:34.059: INFO: stderr: ""
Sep  2 13:17:34.059: INFO: stdout: "true"
Sep  2 13:17:34.059: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 get pods update-demo-nautilus-mhh28 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sflhm'
Sep  2 13:17:34.121: INFO: stderr: ""
Sep  2 13:17:34.121: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  2 13:17:34.121: INFO: validating pod update-demo-nautilus-mhh28
Sep  2 13:17:34.125: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  2 13:17:34.125: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  2 13:17:34.125: INFO: update-demo-nautilus-mhh28 is verified up and running
Sep  2 13:17:34.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 get pods update-demo-nautilus-wp9mq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sflhm'
Sep  2 13:17:34.194: INFO: stderr: ""
Sep  2 13:17:34.194: INFO: stdout: "true"
Sep  2 13:17:34.194: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 get pods update-demo-nautilus-wp9mq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sflhm'
Sep  2 13:17:34.254: INFO: stderr: ""
Sep  2 13:17:34.254: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  2 13:17:34.254: INFO: validating pod update-demo-nautilus-wp9mq
Sep  2 13:17:34.260: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  2 13:17:34.260: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  2 13:17:34.260: INFO: update-demo-nautilus-wp9mq is verified up and running
STEP: using delete to clean up resources
Sep  2 13:17:34.260: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-sflhm'
Sep  2 13:17:34.330: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  2 13:17:34.330: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Sep  2 13:17:34.330: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-sflhm'
Sep  2 13:17:34.419: INFO: stderr: "No resources found.\n"
Sep  2 13:17:34.419: INFO: stdout: ""
Sep  2 13:17:34.419: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 get pods -l name=update-demo --namespace=e2e-tests-kubectl-sflhm -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep  2 13:17:34.492: INFO: stderr: ""
Sep  2 13:17:34.492: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:17:34.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-sflhm" for this suite.
Sep  2 13:17:56.511: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:17:56.596: INFO: namespace: e2e-tests-kubectl-sflhm, resource: bindings, ignored listing per whitelist
Sep  2 13:17:56.607: INFO: namespace e2e-tests-kubectl-sflhm deletion completed in 22.111060659s

• [SLOW TEST:28.234 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:17:56.607: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-hbqth
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Sep  2 13:17:59.306: INFO: Successfully updated pod "pod-update-activedeadlineseconds-14140882-cd84-11e9-b90e-8ed318f3d3c6"
Sep  2 13:17:59.306: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-14140882-cd84-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-pods-hbqth" to be "terminated due to deadline exceeded"
Sep  2 13:17:59.308: INFO: Pod "pod-update-activedeadlineseconds-14140882-cd84-11e9-b90e-8ed318f3d3c6": Phase="Running", Reason="", readiness=true. Elapsed: 2.469235ms
Sep  2 13:18:01.312: INFO: Pod "pod-update-activedeadlineseconds-14140882-cd84-11e9-b90e-8ed318f3d3c6": Phase="Running", Reason="", readiness=true. Elapsed: 2.006147045s
Sep  2 13:18:03.315: INFO: Pod "pod-update-activedeadlineseconds-14140882-cd84-11e9-b90e-8ed318f3d3c6": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.009401967s
Sep  2 13:18:03.315: INFO: Pod "pod-update-activedeadlineseconds-14140882-cd84-11e9-b90e-8ed318f3d3c6" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:18:03.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-hbqth" for this suite.
Sep  2 13:18:09.343: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:18:09.411: INFO: namespace: e2e-tests-pods-hbqth, resource: bindings, ignored listing per whitelist
Sep  2 13:18:09.438: INFO: namespace e2e-tests-pods-hbqth deletion completed in 6.118448813s

• [SLOW TEST:12.831 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:18:09.438: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-stgm7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-1bba260f-cd84-11e9-b90e-8ed318f3d3c6
STEP: Creating a pod to test consume configMaps
Sep  2 13:18:09.619: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-1bbad82a-cd84-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-projected-stgm7" to be "success or failure"
Sep  2 13:18:09.621: INFO: Pod "pod-projected-configmaps-1bbad82a-cd84-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.263549ms
Sep  2 13:18:11.625: INFO: Pod "pod-projected-configmaps-1bbad82a-cd84-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005752415s
STEP: Saw pod success
Sep  2 13:18:11.625: INFO: Pod "pod-projected-configmaps-1bbad82a-cd84-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 13:18:11.628: INFO: Trying to get logs from node ip-192-168-185-95.us-west-2.compute.internal pod pod-projected-configmaps-1bbad82a-cd84-11e9-b90e-8ed318f3d3c6 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep  2 13:18:11.644: INFO: Waiting for pod pod-projected-configmaps-1bbad82a-cd84-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 13:18:11.647: INFO: Pod pod-projected-configmaps-1bbad82a-cd84-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:18:11.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-stgm7" for this suite.
Sep  2 13:18:17.668: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:18:17.720: INFO: namespace: e2e-tests-projected-stgm7, resource: bindings, ignored listing per whitelist
Sep  2 13:18:17.766: INFO: namespace e2e-tests-projected-stgm7 deletion completed in 6.112978178s

• [SLOW TEST:8.327 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:18:17.766: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-rt4l6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Sep  2 13:18:17.959: INFO: Number of nodes with available pods: 0
Sep  2 13:18:17.959: INFO: Node ip-192-168-185-95.us-west-2.compute.internal is running more than one daemon pod
Sep  2 13:18:18.967: INFO: Number of nodes with available pods: 0
Sep  2 13:18:18.967: INFO: Node ip-192-168-185-95.us-west-2.compute.internal is running more than one daemon pod
Sep  2 13:18:19.972: INFO: Number of nodes with available pods: 0
Sep  2 13:18:19.972: INFO: Node ip-192-168-185-95.us-west-2.compute.internal is running more than one daemon pod
Sep  2 13:18:20.966: INFO: Number of nodes with available pods: 4
Sep  2 13:18:20.966: INFO: Number of running nodes: 4, number of available pods: 4
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Sep  2 13:18:20.982: INFO: Number of nodes with available pods: 4
Sep  2 13:18:20.982: INFO: Number of running nodes: 4, number of available pods: 4
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-rt4l6, will wait for the garbage collector to delete the pods
Sep  2 13:18:22.051: INFO: Deleting DaemonSet.extensions daemon-set took: 6.190922ms
Sep  2 13:18:22.151: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.217645ms
Sep  2 13:19:02.759: INFO: Number of nodes with available pods: 0
Sep  2 13:19:02.759: INFO: Number of running nodes: 0, number of available pods: 0
Sep  2 13:19:02.763: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-rt4l6/daemonsets","resourceVersion":"2089821"},"items":null}

Sep  2 13:19:02.765: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-rt4l6/pods","resourceVersion":"2089821"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:19:02.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-rt4l6" for this suite.
Sep  2 13:19:08.798: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:19:08.851: INFO: namespace: e2e-tests-daemonsets-rt4l6, resource: bindings, ignored listing per whitelist
Sep  2 13:19:08.894: INFO: namespace e2e-tests-daemonsets-rt4l6 deletion completed in 6.113350545s

• [SLOW TEST:51.128 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:19:08.895: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-s42ft
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-3f2a4adb-cd84-11e9-b90e-8ed318f3d3c6
STEP: Creating secret with name secret-projected-all-test-volume-3f2a4aad-cd84-11e9-b90e-8ed318f3d3c6
STEP: Creating a pod to test Check all projections for projected volume plugin
Sep  2 13:19:09.079: INFO: Waiting up to 5m0s for pod "projected-volume-3f2a4a5e-cd84-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-projected-s42ft" to be "success or failure"
Sep  2 13:19:09.081: INFO: Pod "projected-volume-3f2a4a5e-cd84-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.282084ms
Sep  2 13:19:11.084: INFO: Pod "projected-volume-3f2a4a5e-cd84-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00552265s
STEP: Saw pod success
Sep  2 13:19:11.084: INFO: Pod "projected-volume-3f2a4a5e-cd84-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 13:19:11.087: INFO: Trying to get logs from node ip-192-168-185-95.us-west-2.compute.internal pod projected-volume-3f2a4a5e-cd84-11e9-b90e-8ed318f3d3c6 container projected-all-volume-test: <nil>
STEP: delete the pod
Sep  2 13:19:11.103: INFO: Waiting for pod projected-volume-3f2a4a5e-cd84-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 13:19:11.105: INFO: Pod projected-volume-3f2a4a5e-cd84-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:19:11.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-s42ft" for this suite.
Sep  2 13:19:17.125: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:19:17.188: INFO: namespace: e2e-tests-projected-s42ft, resource: bindings, ignored listing per whitelist
Sep  2 13:19:17.219: INFO: namespace e2e-tests-projected-s42ft deletion completed in 6.110309291s

• [SLOW TEST:8.325 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:19:17.220: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-lqgr7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-5q79
STEP: Creating a pod to test atomic-volume-subpath
Sep  2 13:19:17.397: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-5q79" in namespace "e2e-tests-subpath-lqgr7" to be "success or failure"
Sep  2 13:19:17.399: INFO: Pod "pod-subpath-test-configmap-5q79": Phase="Pending", Reason="", readiness=false. Elapsed: 2.358582ms
Sep  2 13:19:19.402: INFO: Pod "pod-subpath-test-configmap-5q79": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005118381s
Sep  2 13:19:21.405: INFO: Pod "pod-subpath-test-configmap-5q79": Phase="Running", Reason="", readiness=false. Elapsed: 4.007977155s
Sep  2 13:19:23.414: INFO: Pod "pod-subpath-test-configmap-5q79": Phase="Running", Reason="", readiness=false. Elapsed: 6.016596966s
Sep  2 13:19:25.417: INFO: Pod "pod-subpath-test-configmap-5q79": Phase="Running", Reason="", readiness=false. Elapsed: 8.020305228s
Sep  2 13:19:27.421: INFO: Pod "pod-subpath-test-configmap-5q79": Phase="Running", Reason="", readiness=false. Elapsed: 10.023759801s
Sep  2 13:19:29.424: INFO: Pod "pod-subpath-test-configmap-5q79": Phase="Running", Reason="", readiness=false. Elapsed: 12.027316835s
Sep  2 13:19:31.428: INFO: Pod "pod-subpath-test-configmap-5q79": Phase="Running", Reason="", readiness=false. Elapsed: 14.030847453s
Sep  2 13:19:33.437: INFO: Pod "pod-subpath-test-configmap-5q79": Phase="Running", Reason="", readiness=false. Elapsed: 16.039935741s
Sep  2 13:19:35.440: INFO: Pod "pod-subpath-test-configmap-5q79": Phase="Running", Reason="", readiness=false. Elapsed: 18.043464705s
Sep  2 13:19:37.444: INFO: Pod "pod-subpath-test-configmap-5q79": Phase="Running", Reason="", readiness=false. Elapsed: 20.047071298s
Sep  2 13:19:39.447: INFO: Pod "pod-subpath-test-configmap-5q79": Phase="Running", Reason="", readiness=false. Elapsed: 22.050458355s
Sep  2 13:19:41.451: INFO: Pod "pod-subpath-test-configmap-5q79": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.0540419s
STEP: Saw pod success
Sep  2 13:19:41.451: INFO: Pod "pod-subpath-test-configmap-5q79" satisfied condition "success or failure"
Sep  2 13:19:41.454: INFO: Trying to get logs from node ip-192-168-185-95.us-west-2.compute.internal pod pod-subpath-test-configmap-5q79 container test-container-subpath-configmap-5q79: <nil>
STEP: delete the pod
Sep  2 13:19:41.472: INFO: Waiting for pod pod-subpath-test-configmap-5q79 to disappear
Sep  2 13:19:41.475: INFO: Pod pod-subpath-test-configmap-5q79 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-5q79
Sep  2 13:19:41.475: INFO: Deleting pod "pod-subpath-test-configmap-5q79" in namespace "e2e-tests-subpath-lqgr7"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:19:41.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-lqgr7" for this suite.
Sep  2 13:19:47.496: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:19:47.565: INFO: namespace: e2e-tests-subpath-lqgr7, resource: bindings, ignored listing per whitelist
Sep  2 13:19:47.597: INFO: namespace e2e-tests-subpath-lqgr7 deletion completed in 6.116101101s

• [SLOW TEST:30.377 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:19:47.597: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-9srmt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-hcrgb in namespace e2e-tests-proxy-9srmt
I0902 13:19:47.780173      19 runners.go:184] Created replication controller with name: proxy-service-hcrgb, namespace: e2e-tests-proxy-9srmt, replica count: 1
I0902 13:19:48.830630      19 runners.go:184] proxy-service-hcrgb Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0902 13:19:49.830861      19 runners.go:184] proxy-service-hcrgb Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0902 13:19:50.831093      19 runners.go:184] proxy-service-hcrgb Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0902 13:19:51.831315      19 runners.go:184] proxy-service-hcrgb Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep  2 13:19:51.835: INFO: setup took 4.071834145s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Sep  2 13:19:51.841: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:160/proxy/: foo (200; 5.144593ms)
Sep  2 13:19:51.841: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:160/proxy/: foo (200; 5.38058ms)
Sep  2 13:19:51.841: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:1080/proxy/... (200; 5.317638ms)
Sep  2 13:19:51.841: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:162/proxy/: bar (200; 5.466751ms)
Sep  2 13:19:51.841: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr/proxy/rewriteme"... (200; 5.715106ms)
Sep  2 13:19:51.842: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:1080/proxy/rewri... (200; 5.847868ms)
Sep  2 13:19:51.842: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:162/proxy/: bar (200; 6.119061ms)
Sep  2 13:19:51.845: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/proxy-service-hcrgb:portname2/proxy/: bar (200; 9.002566ms)
Sep  2 13:19:51.845: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/proxy-service-hcrgb:portname1/proxy/: foo (200; 9.330916ms)
Sep  2 13:19:51.845: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/http:proxy-service-hcrgb:portname1/proxy/: foo (200; 9.196937ms)
Sep  2 13:19:51.846: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/http:proxy-service-hcrgb:portname2/proxy/: bar (200; 10.835262ms)
Sep  2 13:19:51.850: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:460/proxy/: tls baz (200; 14.427744ms)
Sep  2 13:19:51.850: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/https:proxy-service-hcrgb:tlsportname1/proxy/: tls baz (200; 14.345332ms)
Sep  2 13:19:51.850: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:462/proxy/: tls qux (200; 14.729984ms)
Sep  2 13:19:51.852: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/https:proxy-service-hcrgb:tlsportname2/proxy/: tls qux (200; 16.862125ms)
Sep  2 13:19:51.853: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:443/proxy/... (200; 17.243455ms)
Sep  2 13:19:51.856: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:462/proxy/: tls qux (200; 2.989337ms)
Sep  2 13:19:51.857: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:160/proxy/: foo (200; 3.253195ms)
Sep  2 13:19:51.857: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:1080/proxy/... (200; 3.779379ms)
Sep  2 13:19:51.857: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:443/proxy/... (200; 3.842469ms)
Sep  2 13:19:51.857: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:162/proxy/: bar (200; 4.086933ms)
Sep  2 13:19:51.858: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:160/proxy/: foo (200; 3.827395ms)
Sep  2 13:19:51.858: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:162/proxy/: bar (200; 4.175129ms)
Sep  2 13:19:51.858: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:460/proxy/: tls baz (200; 4.343253ms)
Sep  2 13:19:51.858: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:1080/proxy/rewri... (200; 4.33893ms)
Sep  2 13:19:51.858: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr/proxy/rewriteme"... (200; 4.466658ms)
Sep  2 13:19:51.859: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/https:proxy-service-hcrgb:tlsportname2/proxy/: tls qux (200; 5.802389ms)
Sep  2 13:19:51.860: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/proxy-service-hcrgb:portname2/proxy/: bar (200; 6.836319ms)
Sep  2 13:19:51.861: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/proxy-service-hcrgb:portname1/proxy/: foo (200; 7.609589ms)
Sep  2 13:19:51.861: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/https:proxy-service-hcrgb:tlsportname1/proxy/: tls baz (200; 7.687123ms)
Sep  2 13:19:51.861: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/http:proxy-service-hcrgb:portname2/proxy/: bar (200; 7.91118ms)
Sep  2 13:19:51.861: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/http:proxy-service-hcrgb:portname1/proxy/: foo (200; 7.952082ms)
Sep  2 13:19:51.864: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:1080/proxy/... (200; 2.880489ms)
Sep  2 13:19:51.865: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:443/proxy/... (200; 3.505632ms)
Sep  2 13:19:51.866: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:162/proxy/: bar (200; 4.107441ms)
Sep  2 13:19:51.866: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:160/proxy/: foo (200; 4.114071ms)
Sep  2 13:19:51.866: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:460/proxy/: tls baz (200; 3.956998ms)
Sep  2 13:19:51.866: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr/proxy/rewriteme"... (200; 4.008709ms)
Sep  2 13:19:51.866: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:162/proxy/: bar (200; 4.345251ms)
Sep  2 13:19:51.866: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:160/proxy/: foo (200; 4.255921ms)
Sep  2 13:19:51.866: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:462/proxy/: tls qux (200; 4.332481ms)
Sep  2 13:19:51.866: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:1080/proxy/rewri... (200; 4.669607ms)
Sep  2 13:19:51.867: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/https:proxy-service-hcrgb:tlsportname1/proxy/: tls baz (200; 5.646444ms)
Sep  2 13:19:51.868: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/proxy-service-hcrgb:portname1/proxy/: foo (200; 6.839059ms)
Sep  2 13:19:51.869: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/proxy-service-hcrgb:portname2/proxy/: bar (200; 7.500863ms)
Sep  2 13:19:51.869: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/http:proxy-service-hcrgb:portname1/proxy/: foo (200; 7.822142ms)
Sep  2 13:19:51.870: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/https:proxy-service-hcrgb:tlsportname2/proxy/: tls qux (200; 7.949338ms)
Sep  2 13:19:51.870: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/http:proxy-service-hcrgb:portname2/proxy/: bar (200; 7.837088ms)
Sep  2 13:19:51.872: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:443/proxy/... (200; 2.721707ms)
Sep  2 13:19:51.873: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:160/proxy/: foo (200; 3.53223ms)
Sep  2 13:19:51.873: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:162/proxy/: bar (200; 3.343648ms)
Sep  2 13:19:51.874: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr/proxy/rewriteme"... (200; 3.891833ms)
Sep  2 13:19:51.874: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:462/proxy/: tls qux (200; 4.050906ms)
Sep  2 13:19:51.874: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:1080/proxy/rewri... (200; 4.305422ms)
Sep  2 13:19:51.874: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:160/proxy/: foo (200; 4.208604ms)
Sep  2 13:19:51.874: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:1080/proxy/... (200; 4.513562ms)
Sep  2 13:19:51.875: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:162/proxy/: bar (200; 5.465669ms)
Sep  2 13:19:51.875: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/http:proxy-service-hcrgb:portname1/proxy/: foo (200; 5.828911ms)
Sep  2 13:19:51.876: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:460/proxy/: tls baz (200; 5.56045ms)
Sep  2 13:19:51.877: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/https:proxy-service-hcrgb:tlsportname1/proxy/: tls baz (200; 7.152041ms)
Sep  2 13:19:51.878: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/proxy-service-hcrgb:portname1/proxy/: foo (200; 8.090444ms)
Sep  2 13:19:51.878: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/proxy-service-hcrgb:portname2/proxy/: bar (200; 7.948588ms)
Sep  2 13:19:51.878: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/https:proxy-service-hcrgb:tlsportname2/proxy/: tls qux (200; 7.862843ms)
Sep  2 13:19:51.878: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/http:proxy-service-hcrgb:portname2/proxy/: bar (200; 7.99128ms)
Sep  2 13:19:51.881: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:160/proxy/: foo (200; 2.936104ms)
Sep  2 13:19:51.882: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:162/proxy/: bar (200; 3.912069ms)
Sep  2 13:19:51.882: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:160/proxy/: foo (200; 4.098298ms)
Sep  2 13:19:51.882: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:460/proxy/: tls baz (200; 4.203383ms)
Sep  2 13:19:51.882: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr/proxy/rewriteme"... (200; 4.311237ms)
Sep  2 13:19:51.882: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:443/proxy/... (200; 4.325904ms)
Sep  2 13:19:51.883: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:162/proxy/: bar (200; 4.728797ms)
Sep  2 13:19:51.883: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:1080/proxy/rewri... (200; 5.13815ms)
Sep  2 13:19:51.883: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:462/proxy/: tls qux (200; 5.100388ms)
Sep  2 13:19:51.883: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:1080/proxy/... (200; 5.264748ms)
Sep  2 13:19:51.884: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/proxy-service-hcrgb:portname2/proxy/: bar (200; 6.241236ms)
Sep  2 13:19:51.884: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/http:proxy-service-hcrgb:portname1/proxy/: foo (200; 6.578858ms)
Sep  2 13:19:51.885: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/http:proxy-service-hcrgb:portname2/proxy/: bar (200; 7.14367ms)
Sep  2 13:19:51.886: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/https:proxy-service-hcrgb:tlsportname1/proxy/: tls baz (200; 7.421431ms)
Sep  2 13:19:51.886: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/https:proxy-service-hcrgb:tlsportname2/proxy/: tls qux (200; 7.558516ms)
Sep  2 13:19:51.886: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/proxy-service-hcrgb:portname1/proxy/: foo (200; 7.743356ms)
Sep  2 13:19:51.889: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:1080/proxy/rewri... (200; 2.893759ms)
Sep  2 13:19:51.889: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:460/proxy/: tls baz (200; 3.255693ms)
Sep  2 13:19:51.890: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:443/proxy/... (200; 3.954353ms)
Sep  2 13:19:51.890: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:162/proxy/: bar (200; 4.092341ms)
Sep  2 13:19:51.890: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:162/proxy/: bar (200; 3.816474ms)
Sep  2 13:19:51.891: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:160/proxy/: foo (200; 4.251179ms)
Sep  2 13:19:51.891: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:462/proxy/: tls qux (200; 4.038337ms)
Sep  2 13:19:51.891: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:1080/proxy/... (200; 4.314457ms)
Sep  2 13:19:51.891: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:160/proxy/: foo (200; 4.282334ms)
Sep  2 13:19:51.892: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr/proxy/rewriteme"... (200; 4.722674ms)
Sep  2 13:19:51.892: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/proxy-service-hcrgb:portname2/proxy/: bar (200; 6.122628ms)
Sep  2 13:19:51.893: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/http:proxy-service-hcrgb:portname1/proxy/: foo (200; 6.215586ms)
Sep  2 13:19:51.894: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/http:proxy-service-hcrgb:portname2/proxy/: bar (200; 7.181234ms)
Sep  2 13:19:51.894: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/https:proxy-service-hcrgb:tlsportname1/proxy/: tls baz (200; 7.592025ms)
Sep  2 13:19:51.894: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/https:proxy-service-hcrgb:tlsportname2/proxy/: tls qux (200; 7.55118ms)
Sep  2 13:19:51.894: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/proxy-service-hcrgb:portname1/proxy/: foo (200; 7.941084ms)
Sep  2 13:19:51.897: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:162/proxy/: bar (200; 2.888678ms)
Sep  2 13:19:51.898: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:1080/proxy/... (200; 3.491854ms)
Sep  2 13:19:51.899: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:460/proxy/: tls baz (200; 4.122553ms)
Sep  2 13:19:51.899: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:1080/proxy/rewri... (200; 4.005179ms)
Sep  2 13:19:51.899: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:160/proxy/: foo (200; 4.182023ms)
Sep  2 13:19:51.899: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:160/proxy/: foo (200; 4.059764ms)
Sep  2 13:19:51.899: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:162/proxy/: bar (200; 4.486844ms)
Sep  2 13:19:51.900: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:443/proxy/... (200; 5.0574ms)
Sep  2 13:19:51.900: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr/proxy/rewriteme"... (200; 5.495545ms)
Sep  2 13:19:51.900: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:462/proxy/: tls qux (200; 5.811318ms)
Sep  2 13:19:51.905: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/https:proxy-service-hcrgb:tlsportname2/proxy/: tls qux (200; 10.838564ms)
Sep  2 13:19:51.906: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/https:proxy-service-hcrgb:tlsportname1/proxy/: tls baz (200; 11.354024ms)
Sep  2 13:19:51.906: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/http:proxy-service-hcrgb:portname1/proxy/: foo (200; 11.499593ms)
Sep  2 13:19:51.907: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/http:proxy-service-hcrgb:portname2/proxy/: bar (200; 12.103382ms)
Sep  2 13:19:51.907: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/proxy-service-hcrgb:portname1/proxy/: foo (200; 12.478805ms)
Sep  2 13:19:51.907: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/proxy-service-hcrgb:portname2/proxy/: bar (200; 11.611495ms)
Sep  2 13:19:51.910: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr/proxy/rewriteme"... (200; 3.08959ms)
Sep  2 13:19:51.911: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:462/proxy/: tls qux (200; 3.602845ms)
Sep  2 13:19:51.911: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:162/proxy/: bar (200; 4.473626ms)
Sep  2 13:19:51.912: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:443/proxy/... (200; 4.74461ms)
Sep  2 13:19:51.912: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:162/proxy/: bar (200; 4.703175ms)
Sep  2 13:19:51.912: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:160/proxy/: foo (200; 4.834741ms)
Sep  2 13:19:51.912: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:160/proxy/: foo (200; 4.810551ms)
Sep  2 13:19:51.912: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:460/proxy/: tls baz (200; 4.774477ms)
Sep  2 13:19:51.912: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:1080/proxy/... (200; 4.863135ms)
Sep  2 13:19:51.912: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:1080/proxy/rewri... (200; 5.303298ms)
Sep  2 13:19:51.913: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/https:proxy-service-hcrgb:tlsportname1/proxy/: tls baz (200; 6.006103ms)
Sep  2 13:19:51.914: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/https:proxy-service-hcrgb:tlsportname2/proxy/: tls qux (200; 6.826037ms)
Sep  2 13:19:51.914: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/proxy-service-hcrgb:portname2/proxy/: bar (200; 7.591185ms)
Sep  2 13:19:51.915: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/http:proxy-service-hcrgb:portname2/proxy/: bar (200; 7.657697ms)
Sep  2 13:19:51.915: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/http:proxy-service-hcrgb:portname1/proxy/: foo (200; 7.77437ms)
Sep  2 13:19:51.915: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/proxy-service-hcrgb:portname1/proxy/: foo (200; 8.031291ms)
Sep  2 13:19:51.918: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:162/proxy/: bar (200; 2.765989ms)
Sep  2 13:19:51.919: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:1080/proxy/rewri... (200; 3.617556ms)
Sep  2 13:19:51.919: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:462/proxy/: tls qux (200; 3.66062ms)
Sep  2 13:19:51.919: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:460/proxy/: tls baz (200; 4.03849ms)
Sep  2 13:19:51.919: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr/proxy/rewriteme"... (200; 3.911132ms)
Sep  2 13:19:51.919: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:443/proxy/... (200; 4.424289ms)
Sep  2 13:19:51.920: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:162/proxy/: bar (200; 4.304154ms)
Sep  2 13:19:51.920: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:1080/proxy/... (200; 4.283121ms)
Sep  2 13:19:51.920: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:160/proxy/: foo (200; 4.623336ms)
Sep  2 13:19:51.920: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:160/proxy/: foo (200; 4.677131ms)
Sep  2 13:19:51.921: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/https:proxy-service-hcrgb:tlsportname2/proxy/: tls qux (200; 5.837635ms)
Sep  2 13:19:51.922: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/proxy-service-hcrgb:portname2/proxy/: bar (200; 6.824545ms)
Sep  2 13:19:51.923: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/proxy-service-hcrgb:portname1/proxy/: foo (200; 7.552021ms)
Sep  2 13:19:51.923: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/http:proxy-service-hcrgb:portname1/proxy/: foo (200; 7.72522ms)
Sep  2 13:19:51.923: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/http:proxy-service-hcrgb:portname2/proxy/: bar (200; 7.715045ms)
Sep  2 13:19:51.923: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/https:proxy-service-hcrgb:tlsportname1/proxy/: tls baz (200; 7.638678ms)
Sep  2 13:19:51.926: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr/proxy/rewriteme"... (200; 2.997693ms)
Sep  2 13:19:51.926: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:162/proxy/: bar (200; 2.979795ms)
Sep  2 13:19:51.927: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:160/proxy/: foo (200; 3.544945ms)
Sep  2 13:19:51.927: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:460/proxy/: tls baz (200; 3.696814ms)
Sep  2 13:19:51.927: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:160/proxy/: foo (200; 4.150627ms)
Sep  2 13:19:51.927: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:1080/proxy/... (200; 4.061593ms)
Sep  2 13:19:51.927: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:162/proxy/: bar (200; 4.03669ms)
Sep  2 13:19:51.927: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:1080/proxy/rewri... (200; 4.172992ms)
Sep  2 13:19:51.928: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:462/proxy/: tls qux (200; 4.383705ms)
Sep  2 13:19:51.928: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:443/proxy/... (200; 4.434591ms)
Sep  2 13:19:51.929: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/https:proxy-service-hcrgb:tlsportname1/proxy/: tls baz (200; 5.575822ms)
Sep  2 13:19:51.930: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/proxy-service-hcrgb:portname1/proxy/: foo (200; 6.54114ms)
Sep  2 13:19:51.931: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/http:proxy-service-hcrgb:portname1/proxy/: foo (200; 7.49448ms)
Sep  2 13:19:51.931: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/proxy-service-hcrgb:portname2/proxy/: bar (200; 7.433328ms)
Sep  2 13:19:51.931: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/https:proxy-service-hcrgb:tlsportname2/proxy/: tls qux (200; 7.700789ms)
Sep  2 13:19:51.931: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/http:proxy-service-hcrgb:portname2/proxy/: bar (200; 7.671204ms)
Sep  2 13:19:51.934: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:160/proxy/: foo (200; 2.751132ms)
Sep  2 13:19:51.935: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:162/proxy/: bar (200; 3.546554ms)
Sep  2 13:19:51.935: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:1080/proxy/... (200; 3.835526ms)
Sep  2 13:19:51.935: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:160/proxy/: foo (200; 3.872702ms)
Sep  2 13:19:51.935: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:443/proxy/... (200; 3.798835ms)
Sep  2 13:19:51.935: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr/proxy/rewriteme"... (200; 3.665232ms)
Sep  2 13:19:51.935: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:460/proxy/: tls baz (200; 3.95959ms)
Sep  2 13:19:51.935: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:462/proxy/: tls qux (200; 4.007149ms)
Sep  2 13:19:51.935: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:162/proxy/: bar (200; 4.238981ms)
Sep  2 13:19:51.935: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:1080/proxy/rewri... (200; 4.299331ms)
Sep  2 13:19:51.937: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/proxy-service-hcrgb:portname1/proxy/: foo (200; 5.600175ms)
Sep  2 13:19:51.938: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/https:proxy-service-hcrgb:tlsportname1/proxy/: tls baz (200; 7.095562ms)
Sep  2 13:19:51.939: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/proxy-service-hcrgb:portname2/proxy/: bar (200; 8.103423ms)
Sep  2 13:19:51.939: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/http:proxy-service-hcrgb:portname2/proxy/: bar (200; 7.905719ms)
Sep  2 13:19:51.939: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/http:proxy-service-hcrgb:portname1/proxy/: foo (200; 7.954252ms)
Sep  2 13:19:51.939: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/https:proxy-service-hcrgb:tlsportname2/proxy/: tls qux (200; 8.132463ms)
Sep  2 13:19:51.942: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:162/proxy/: bar (200; 2.709021ms)
Sep  2 13:19:51.943: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:160/proxy/: foo (200; 3.463935ms)
Sep  2 13:19:51.943: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:443/proxy/... (200; 3.613439ms)
Sep  2 13:19:51.943: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr/proxy/rewriteme"... (200; 3.638138ms)
Sep  2 13:19:51.945: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:1080/proxy/rewri... (200; 4.834969ms)
Sep  2 13:19:51.945: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:460/proxy/: tls baz (200; 4.698776ms)
Sep  2 13:19:51.945: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:1080/proxy/... (200; 5.042127ms)
Sep  2 13:19:51.945: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:162/proxy/: bar (200; 5.117419ms)
Sep  2 13:19:51.945: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:462/proxy/: tls qux (200; 5.108445ms)
Sep  2 13:19:51.945: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/http:proxy-service-hcrgb:portname2/proxy/: bar (200; 5.556608ms)
Sep  2 13:19:51.945: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:160/proxy/: foo (200; 5.269503ms)
Sep  2 13:19:51.947: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/https:proxy-service-hcrgb:tlsportname2/proxy/: tls qux (200; 7.019465ms)
Sep  2 13:19:51.947: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/proxy-service-hcrgb:portname1/proxy/: foo (200; 6.981139ms)
Sep  2 13:19:51.947: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/http:proxy-service-hcrgb:portname1/proxy/: foo (200; 7.501781ms)
Sep  2 13:19:51.947: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/proxy-service-hcrgb:portname2/proxy/: bar (200; 7.625012ms)
Sep  2 13:19:51.947: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/https:proxy-service-hcrgb:tlsportname1/proxy/: tls baz (200; 7.723016ms)
Sep  2 13:19:51.950: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:160/proxy/: foo (200; 3.015713ms)
Sep  2 13:19:51.951: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:462/proxy/: tls qux (200; 3.658756ms)
Sep  2 13:19:51.951: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:460/proxy/: tls baz (200; 3.629357ms)
Sep  2 13:19:51.952: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:1080/proxy/... (200; 3.923773ms)
Sep  2 13:19:51.953: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:162/proxy/: bar (200; 4.571675ms)
Sep  2 13:19:51.953: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:162/proxy/: bar (200; 5.360665ms)
Sep  2 13:19:51.953: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:160/proxy/: foo (200; 4.93436ms)
Sep  2 13:19:51.953: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:1080/proxy/rewri... (200; 5.183573ms)
Sep  2 13:19:51.953: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:443/proxy/... (200; 4.949591ms)
Sep  2 13:19:51.953: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr/proxy/rewriteme"... (200; 5.12907ms)
Sep  2 13:19:51.953: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/https:proxy-service-hcrgb:tlsportname2/proxy/: tls qux (200; 5.89864ms)
Sep  2 13:19:51.954: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/https:proxy-service-hcrgb:tlsportname1/proxy/: tls baz (200; 6.857549ms)
Sep  2 13:19:51.956: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/http:proxy-service-hcrgb:portname2/proxy/: bar (200; 7.849077ms)
Sep  2 13:19:51.956: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/proxy-service-hcrgb:portname2/proxy/: bar (200; 8.671463ms)
Sep  2 13:19:51.957: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/http:proxy-service-hcrgb:portname1/proxy/: foo (200; 8.888957ms)
Sep  2 13:19:51.957: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/proxy-service-hcrgb:portname1/proxy/: foo (200; 8.657331ms)
Sep  2 13:19:51.960: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:160/proxy/: foo (200; 2.897387ms)
Sep  2 13:19:51.960: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:462/proxy/: tls qux (200; 3.382552ms)
Sep  2 13:19:51.960: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:162/proxy/: bar (200; 3.435384ms)
Sep  2 13:19:51.961: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:1080/proxy/... (200; 3.978929ms)
Sep  2 13:19:51.961: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:1080/proxy/rewri... (200; 4.134302ms)
Sep  2 13:19:51.961: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:160/proxy/: foo (200; 4.206295ms)
Sep  2 13:19:51.961: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr/proxy/rewriteme"... (200; 4.29337ms)
Sep  2 13:19:51.961: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:162/proxy/: bar (200; 4.175159ms)
Sep  2 13:19:51.962: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:443/proxy/... (200; 4.390308ms)
Sep  2 13:19:51.962: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:460/proxy/: tls baz (200; 4.53536ms)
Sep  2 13:19:51.962: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/https:proxy-service-hcrgb:tlsportname1/proxy/: tls baz (200; 5.652021ms)
Sep  2 13:19:51.964: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/https:proxy-service-hcrgb:tlsportname2/proxy/: tls qux (200; 7.31993ms)
Sep  2 13:19:51.965: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/http:proxy-service-hcrgb:portname1/proxy/: foo (200; 7.645778ms)
Sep  2 13:19:51.965: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/http:proxy-service-hcrgb:portname2/proxy/: bar (200; 7.621965ms)
Sep  2 13:19:51.965: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/proxy-service-hcrgb:portname2/proxy/: bar (200; 7.566872ms)
Sep  2 13:19:51.965: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/proxy-service-hcrgb:portname1/proxy/: foo (200; 7.549228ms)
Sep  2 13:19:51.968: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:443/proxy/... (200; 2.840008ms)
Sep  2 13:19:51.968: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:1080/proxy/rewri... (200; 3.268453ms)
Sep  2 13:19:51.968: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:162/proxy/: bar (200; 3.640116ms)
Sep  2 13:19:51.969: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:460/proxy/: tls baz (200; 3.698442ms)
Sep  2 13:19:51.969: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:160/proxy/: foo (200; 3.992764ms)
Sep  2 13:19:51.970: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:462/proxy/: tls qux (200; 4.59001ms)
Sep  2 13:19:51.970: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:162/proxy/: bar (200; 4.38857ms)
Sep  2 13:19:51.970: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:1080/proxy/... (200; 4.687634ms)
Sep  2 13:19:51.970: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:160/proxy/: foo (200; 4.498419ms)
Sep  2 13:19:51.970: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr/proxy/rewriteme"... (200; 4.716974ms)
Sep  2 13:19:51.971: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/http:proxy-service-hcrgb:portname1/proxy/: foo (200; 5.804748ms)
Sep  2 13:19:51.972: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/http:proxy-service-hcrgb:portname2/proxy/: bar (200; 6.492243ms)
Sep  2 13:19:51.972: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/proxy-service-hcrgb:portname2/proxy/: bar (200; 7.154633ms)
Sep  2 13:19:51.973: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/https:proxy-service-hcrgb:tlsportname1/proxy/: tls baz (200; 7.635357ms)
Sep  2 13:19:51.973: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/proxy-service-hcrgb:portname1/proxy/: foo (200; 7.717414ms)
Sep  2 13:19:51.973: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/https:proxy-service-hcrgb:tlsportname2/proxy/: tls qux (200; 7.663826ms)
Sep  2 13:19:51.976: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:443/proxy/... (200; 2.958661ms)
Sep  2 13:19:51.976: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr/proxy/rewriteme"... (200; 2.891127ms)
Sep  2 13:19:51.977: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:160/proxy/: foo (200; 4.050336ms)
Sep  2 13:19:51.977: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:1080/proxy/... (200; 4.204147ms)
Sep  2 13:19:51.977: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:162/proxy/: bar (200; 4.147786ms)
Sep  2 13:19:51.977: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:462/proxy/: tls qux (200; 4.3301ms)
Sep  2 13:19:51.977: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:160/proxy/: foo (200; 4.11418ms)
Sep  2 13:19:51.977: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:162/proxy/: bar (200; 4.2207ms)
Sep  2 13:19:51.978: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:1080/proxy/rewri... (200; 4.610435ms)
Sep  2 13:19:51.978: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:460/proxy/: tls baz (200; 4.816505ms)
Sep  2 13:19:51.979: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/https:proxy-service-hcrgb:tlsportname2/proxy/: tls qux (200; 5.799289ms)
Sep  2 13:19:51.980: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/http:proxy-service-hcrgb:portname2/proxy/: bar (200; 6.90324ms)
Sep  2 13:19:51.981: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/proxy-service-hcrgb:portname2/proxy/: bar (200; 7.698994ms)
Sep  2 13:19:51.981: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/proxy-service-hcrgb:portname1/proxy/: foo (200; 7.604565ms)
Sep  2 13:19:51.981: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/http:proxy-service-hcrgb:portname1/proxy/: foo (200; 7.814643ms)
Sep  2 13:19:51.981: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/https:proxy-service-hcrgb:tlsportname1/proxy/: tls baz (200; 7.734506ms)
Sep  2 13:19:51.984: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:1080/proxy/... (200; 2.959632ms)
Sep  2 13:19:51.984: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:160/proxy/: foo (200; 3.190535ms)
Sep  2 13:19:51.985: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:162/proxy/: bar (200; 3.829146ms)
Sep  2 13:19:51.985: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:462/proxy/: tls qux (200; 3.787487ms)
Sep  2 13:19:51.985: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:460/proxy/: tls baz (200; 3.705235ms)
Sep  2 13:19:51.985: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:160/proxy/: foo (200; 3.807628ms)
Sep  2 13:19:51.985: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr/proxy/rewriteme"... (200; 3.991494ms)
Sep  2 13:19:51.985: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:1080/proxy/rewri... (200; 4.007229ms)
Sep  2 13:19:51.985: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:162/proxy/: bar (200; 3.994542ms)
Sep  2 13:19:51.985: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:443/proxy/... (200; 4.083044ms)
Sep  2 13:19:51.987: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/proxy-service-hcrgb:portname1/proxy/: foo (200; 5.907537ms)
Sep  2 13:19:51.987: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/https:proxy-service-hcrgb:tlsportname2/proxy/: tls qux (200; 6.015431ms)
Sep  2 13:19:51.988: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/http:proxy-service-hcrgb:portname1/proxy/: foo (200; 6.787438ms)
Sep  2 13:19:51.989: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/http:proxy-service-hcrgb:portname2/proxy/: bar (200; 7.446398ms)
Sep  2 13:19:51.989: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/proxy-service-hcrgb:portname2/proxy/: bar (200; 7.387357ms)
Sep  2 13:19:51.989: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/https:proxy-service-hcrgb:tlsportname1/proxy/: tls baz (200; 7.682098ms)
Sep  2 13:19:51.992: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:1080/proxy/rewri... (200; 2.960891ms)
Sep  2 13:19:51.993: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:160/proxy/: foo (200; 3.579668ms)
Sep  2 13:19:51.994: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:162/proxy/: bar (200; 5.047413ms)
Sep  2 13:19:51.994: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:1080/proxy/... (200; 4.193931ms)
Sep  2 13:19:51.994: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:443/proxy/... (200; 5.044292ms)
Sep  2 13:19:51.994: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr/proxy/rewriteme"... (200; 4.330285ms)
Sep  2 13:19:51.994: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:460/proxy/: tls baz (200; 4.110007ms)
Sep  2 13:19:51.994: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:162/proxy/: bar (200; 4.692722ms)
Sep  2 13:19:51.994: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:462/proxy/: tls qux (200; 4.607296ms)
Sep  2 13:19:51.994: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:160/proxy/: foo (200; 4.273891ms)
Sep  2 13:19:51.994: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/http:proxy-service-hcrgb:portname1/proxy/: foo (200; 5.564783ms)
Sep  2 13:19:51.996: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/http:proxy-service-hcrgb:portname2/proxy/: bar (200; 5.974881ms)
Sep  2 13:19:52.001: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/https:proxy-service-hcrgb:tlsportname1/proxy/: tls baz (200; 10.843341ms)
Sep  2 13:19:52.001: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/https:proxy-service-hcrgb:tlsportname2/proxy/: tls qux (200; 11.089638ms)
Sep  2 13:19:52.001: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/proxy-service-hcrgb:portname2/proxy/: bar (200; 11.374481ms)
Sep  2 13:19:52.001: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/proxy-service-hcrgb:portname1/proxy/: foo (200; 11.223046ms)
Sep  2 13:19:52.004: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:462/proxy/: tls qux (200; 3.53039ms)
Sep  2 13:19:52.006: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:162/proxy/: bar (200; 4.147295ms)
Sep  2 13:19:52.006: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr/proxy/rewriteme"... (200; 5.177111ms)
Sep  2 13:19:52.006: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:460/proxy/: tls baz (200; 4.935005ms)
Sep  2 13:19:52.006: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:160/proxy/: foo (200; 5.129934ms)
Sep  2 13:19:52.006: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:1080/proxy/rewri... (200; 4.746236ms)
Sep  2 13:19:52.008: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:160/proxy/: foo (200; 6.510263ms)
Sep  2 13:19:52.008: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:162/proxy/: bar (200; 6.608044ms)
Sep  2 13:19:52.008: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/http:proxy-service-hcrgb:portname2/proxy/: bar (200; 7.490159ms)
Sep  2 13:19:52.008: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:1080/proxy/... (200; 7.364129ms)
Sep  2 13:19:52.008: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/http:proxy-service-hcrgb:portname1/proxy/: foo (200; 7.596469ms)
Sep  2 13:19:52.008: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:443/proxy/... (200; 6.905756ms)
Sep  2 13:19:52.009: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/proxy-service-hcrgb:portname2/proxy/: bar (200; 7.486582ms)
Sep  2 13:19:52.009: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/https:proxy-service-hcrgb:tlsportname1/proxy/: tls baz (200; 7.775736ms)
Sep  2 13:19:52.010: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/proxy-service-hcrgb:portname1/proxy/: foo (200; 8.373285ms)
Sep  2 13:19:52.010: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/https:proxy-service-hcrgb:tlsportname2/proxy/: tls qux (200; 8.637953ms)
Sep  2 13:19:52.013: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:160/proxy/: foo (200; 2.961374ms)
Sep  2 13:19:52.014: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:162/proxy/: bar (200; 3.486094ms)
Sep  2 13:19:52.014: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:1080/proxy/... (200; 3.68467ms)
Sep  2 13:19:52.015: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:162/proxy/: bar (200; 3.897041ms)
Sep  2 13:19:52.015: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/http:proxy-service-hcrgb-sw9rr:160/proxy/: foo (200; 4.383714ms)
Sep  2 13:19:52.015: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr/proxy/rewriteme"... (200; 4.437072ms)
Sep  2 13:19:52.015: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:460/proxy/: tls baz (200; 4.376775ms)
Sep  2 13:19:52.015: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:443/proxy/... (200; 4.617655ms)
Sep  2 13:19:52.015: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/https:proxy-service-hcrgb-sw9rr:462/proxy/: tls qux (200; 4.993486ms)
Sep  2 13:19:52.015: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9srmt/pods/proxy-service-hcrgb-sw9rr:1080/proxy/rewri... (200; 4.485728ms)
Sep  2 13:19:52.016: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/http:proxy-service-hcrgb:portname1/proxy/: foo (200; 5.850097ms)
Sep  2 13:19:52.017: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/https:proxy-service-hcrgb:tlsportname1/proxy/: tls baz (200; 6.974882ms)
Sep  2 13:19:52.018: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/http:proxy-service-hcrgb:portname2/proxy/: bar (200; 7.652818ms)
Sep  2 13:19:52.018: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/proxy-service-hcrgb:portname1/proxy/: foo (200; 7.468904ms)
Sep  2 13:19:52.018: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/https:proxy-service-hcrgb:tlsportname2/proxy/: tls qux (200; 7.903219ms)
Sep  2 13:19:52.018: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9srmt/services/proxy-service-hcrgb:portname2/proxy/: bar (200; 7.58375ms)
STEP: deleting ReplicationController proxy-service-hcrgb in namespace e2e-tests-proxy-9srmt, will wait for the garbage collector to delete the pods
Sep  2 13:19:52.078: INFO: Deleting ReplicationController proxy-service-hcrgb took: 6.363ms
Sep  2 13:19:52.178: INFO: Terminating ReplicationController proxy-service-hcrgb pods took: 100.238045ms
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:19:54.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-9srmt" for this suite.
Sep  2 13:20:00.203: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:20:00.281: INFO: namespace: e2e-tests-proxy-9srmt, resource: bindings, ignored listing per whitelist
Sep  2 13:20:00.303: INFO: namespace e2e-tests-proxy-9srmt deletion completed in 6.115307938s

• [SLOW TEST:12.705 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:20:00.303: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-fc4xm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-fc4xm
Sep  2 13:20:02.487: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-fc4xm
STEP: checking the pod's current state and verifying that restartCount is present
Sep  2 13:20:02.490: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:24:03.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-fc4xm" for this suite.
Sep  2 13:24:09.069: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:24:09.153: INFO: namespace: e2e-tests-container-probe-fc4xm, resource: bindings, ignored listing per whitelist
Sep  2 13:24:09.164: INFO: namespace e2e-tests-container-probe-fc4xm deletion completed in 6.110871668s

• [SLOW TEST:248.861 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:24:09.164: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-f5t58
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Sep  2 13:24:09.330: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:24:13.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-f5t58" for this suite.
Sep  2 13:24:35.251: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:24:35.315: INFO: namespace: e2e-tests-init-container-f5t58, resource: bindings, ignored listing per whitelist
Sep  2 13:24:35.344: INFO: namespace e2e-tests-init-container-f5t58 deletion completed in 22.108290813s

• [SLOW TEST:26.180 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:24:35.344: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-lhz7j
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-01beaf70-cd85-11e9-b90e-8ed318f3d3c6
STEP: Creating configMap with name cm-test-opt-upd-01beafb7-cd85-11e9-b90e-8ed318f3d3c6
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-01beaf70-cd85-11e9-b90e-8ed318f3d3c6
STEP: Updating configmap cm-test-opt-upd-01beafb7-cd85-11e9-b90e-8ed318f3d3c6
STEP: Creating configMap with name cm-test-opt-create-01beafe3-cd85-11e9-b90e-8ed318f3d3c6
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:25:47.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-lhz7j" for this suite.
Sep  2 13:26:09.976: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:26:10.038: INFO: namespace: e2e-tests-configmap-lhz7j, resource: bindings, ignored listing per whitelist
Sep  2 13:26:10.069: INFO: namespace e2e-tests-configmap-lhz7j deletion completed in 22.113794623s

• [SLOW TEST:94.725 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:26:10.069: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-8m62v
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-3a3551e0-cd85-11e9-b90e-8ed318f3d3c6
STEP: Creating a pod to test consume secrets
Sep  2 13:26:10.253: INFO: Waiting up to 5m0s for pod "pod-secrets-3a3606d1-cd85-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-secrets-8m62v" to be "success or failure"
Sep  2 13:26:10.255: INFO: Pod "pod-secrets-3a3606d1-cd85-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.332358ms
Sep  2 13:26:12.259: INFO: Pod "pod-secrets-3a3606d1-cd85-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005506153s
STEP: Saw pod success
Sep  2 13:26:12.259: INFO: Pod "pod-secrets-3a3606d1-cd85-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 13:26:12.261: INFO: Trying to get logs from node ip-192-168-185-95.us-west-2.compute.internal pod pod-secrets-3a3606d1-cd85-11e9-b90e-8ed318f3d3c6 container secret-volume-test: <nil>
STEP: delete the pod
Sep  2 13:26:12.280: INFO: Waiting for pod pod-secrets-3a3606d1-cd85-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 13:26:12.282: INFO: Pod pod-secrets-3a3606d1-cd85-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:26:12.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-8m62v" for this suite.
Sep  2 13:26:18.302: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:26:18.366: INFO: namespace: e2e-tests-secrets-8m62v, resource: bindings, ignored listing per whitelist
Sep  2 13:26:18.396: INFO: namespace e2e-tests-secrets-8m62v deletion completed in 6.110384231s

• [SLOW TEST:8.327 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:26:18.396: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-5w5b5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep  2 13:26:18.555: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-5w5b5'
Sep  2 13:26:18.750: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep  2 13:26:18.750: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1268
Sep  2 13:26:20.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-5w5b5'
Sep  2 13:26:20.839: INFO: stderr: ""
Sep  2 13:26:20.839: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:26:20.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-5w5b5" for this suite.
Sep  2 13:28:24.859: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:28:24.902: INFO: namespace: e2e-tests-kubectl-5w5b5, resource: bindings, ignored listing per whitelist
Sep  2 13:28:24.951: INFO: namespace e2e-tests-kubectl-5w5b5 deletion completed in 2m4.108532239s

• [SLOW TEST:126.555 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:28:24.951: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-jzfgz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Sep  2 13:28:25.115: INFO: PodSpec: initContainers in spec.initContainers
Sep  2 13:29:13.337: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-8a993bab-cd85-11e9-b90e-8ed318f3d3c6", GenerateName:"", Namespace:"e2e-tests-init-container-jzfgz", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-jzfgz/pods/pod-init-8a993bab-cd85-11e9-b90e-8ed318f3d3c6", UID:"8a99e0a0-cd85-11e9-a575-0a854009c708", ResourceVersion:"2091169", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63703027705, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"115340219"}, Annotations:map[string]string{"kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-57mjk", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001279580), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-57mjk", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-57mjk", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-57mjk", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc00196f3c8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-192-168-77-237.us-west-2.compute.internal", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0016be660), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00196f520)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00196f540)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc00196f548), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00196f54c)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703027705, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703027705, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703027705, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703027705, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.77.237", PodIP:"192.168.80.81", StartTime:(*v1.Time)(0xc001b57b20), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00015a3f0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00015a700)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://27e3cb251e8c8af34cc4b73de95b7eeddd9c77e39e0d50a3506ced96a6be7460"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001b57b60), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001b57b40), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:29:13.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-jzfgz" for this suite.
Sep  2 13:29:35.367: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:29:35.396: INFO: namespace: e2e-tests-init-container-jzfgz, resource: bindings, ignored listing per whitelist
Sep  2 13:29:35.462: INFO: namespace e2e-tests-init-container-jzfgz deletion completed in 22.115442611s

• [SLOW TEST:70.511 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:29:35.462: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-c4hqb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-b4a10d38-cd85-11e9-b90e-8ed318f3d3c6
STEP: Creating a pod to test consume configMaps
Sep  2 13:29:35.640: INFO: Waiting up to 5m0s for pod "pod-configmaps-b4a1900c-cd85-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-configmap-c4hqb" to be "success or failure"
Sep  2 13:29:35.642: INFO: Pod "pod-configmaps-b4a1900c-cd85-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.217875ms
Sep  2 13:29:37.646: INFO: Pod "pod-configmaps-b4a1900c-cd85-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005680674s
Sep  2 13:29:39.649: INFO: Pod "pod-configmaps-b4a1900c-cd85-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008889722s
STEP: Saw pod success
Sep  2 13:29:39.649: INFO: Pod "pod-configmaps-b4a1900c-cd85-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 13:29:39.652: INFO: Trying to get logs from node ip-192-168-77-237.us-west-2.compute.internal pod pod-configmaps-b4a1900c-cd85-11e9-b90e-8ed318f3d3c6 container configmap-volume-test: <nil>
STEP: delete the pod
Sep  2 13:29:39.669: INFO: Waiting for pod pod-configmaps-b4a1900c-cd85-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 13:29:39.671: INFO: Pod pod-configmaps-b4a1900c-cd85-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:29:39.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-c4hqb" for this suite.
Sep  2 13:29:45.695: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:29:45.780: INFO: namespace: e2e-tests-configmap-c4hqb, resource: bindings, ignored listing per whitelist
Sep  2 13:29:45.785: INFO: namespace e2e-tests-configmap-c4hqb deletion completed in 6.110957552s

• [SLOW TEST:10.323 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:29:45.786: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-xgt4x
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Sep  2 13:29:45.957: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bac7bc4e-cd85-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-downward-api-xgt4x" to be "success or failure"
Sep  2 13:29:45.959: INFO: Pod "downwardapi-volume-bac7bc4e-cd85-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.237235ms
Sep  2 13:29:47.963: INFO: Pod "downwardapi-volume-bac7bc4e-cd85-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005549054s
Sep  2 13:29:49.966: INFO: Pod "downwardapi-volume-bac7bc4e-cd85-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008770464s
STEP: Saw pod success
Sep  2 13:29:49.966: INFO: Pod "downwardapi-volume-bac7bc4e-cd85-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 13:29:49.969: INFO: Trying to get logs from node ip-192-168-185-95.us-west-2.compute.internal pod downwardapi-volume-bac7bc4e-cd85-11e9-b90e-8ed318f3d3c6 container client-container: <nil>
STEP: delete the pod
Sep  2 13:29:49.986: INFO: Waiting for pod downwardapi-volume-bac7bc4e-cd85-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 13:29:49.988: INFO: Pod downwardapi-volume-bac7bc4e-cd85-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:29:49.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-xgt4x" for this suite.
Sep  2 13:29:56.014: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:29:56.032: INFO: namespace: e2e-tests-downward-api-xgt4x, resource: bindings, ignored listing per whitelist
Sep  2 13:29:56.103: INFO: namespace e2e-tests-downward-api-xgt4x deletion completed in 6.111032257s

• [SLOW TEST:10.317 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:29:56.103: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-v8g5m
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Sep  2 13:29:56.268: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 cluster-info'
Sep  2 13:29:56.336: INFO: stderr: ""
Sep  2 13:29:56.336: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.100.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://10.100.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:29:56.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-v8g5m" for this suite.
Sep  2 13:30:02.355: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:30:02.360: INFO: namespace: e2e-tests-kubectl-v8g5m, resource: bindings, ignored listing per whitelist
Sep  2 13:30:02.447: INFO: namespace e2e-tests-kubectl-v8g5m deletion completed in 6.107729553s

• [SLOW TEST:6.344 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:30:02.447: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-dnkzr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-c4b57426-cd85-11e9-b90e-8ed318f3d3c6
STEP: Creating a pod to test consume configMaps
Sep  2 13:30:02.619: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c4b60b8a-cd85-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-projected-dnkzr" to be "success or failure"
Sep  2 13:30:02.621: INFO: Pod "pod-projected-configmaps-c4b60b8a-cd85-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.33463ms
Sep  2 13:30:04.625: INFO: Pod "pod-projected-configmaps-c4b60b8a-cd85-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006523096s
Sep  2 13:30:06.634: INFO: Pod "pod-projected-configmaps-c4b60b8a-cd85-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015637307s
STEP: Saw pod success
Sep  2 13:30:06.634: INFO: Pod "pod-projected-configmaps-c4b60b8a-cd85-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 13:30:06.637: INFO: Trying to get logs from node ip-192-168-185-95.us-west-2.compute.internal pod pod-projected-configmaps-c4b60b8a-cd85-11e9-b90e-8ed318f3d3c6 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep  2 13:30:06.655: INFO: Waiting for pod pod-projected-configmaps-c4b60b8a-cd85-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 13:30:06.657: INFO: Pod pod-projected-configmaps-c4b60b8a-cd85-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:30:06.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dnkzr" for this suite.
Sep  2 13:30:12.677: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:30:12.683: INFO: namespace: e2e-tests-projected-dnkzr, resource: bindings, ignored listing per whitelist
Sep  2 13:30:12.767: INFO: namespace e2e-tests-projected-dnkzr deletion completed in 6.106375772s

• [SLOW TEST:10.320 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:30:12.768: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-2ncp7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Sep  2 13:30:17.468: INFO: Successfully updated pod "labelsupdatecadcc9d4-cd85-11e9-b90e-8ed318f3d3c6"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:30:19.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-2ncp7" for this suite.
Sep  2 13:30:41.503: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:30:41.529: INFO: namespace: e2e-tests-downward-api-2ncp7, resource: bindings, ignored listing per whitelist
Sep  2 13:30:41.596: INFO: namespace e2e-tests-downward-api-2ncp7 deletion completed in 22.10989496s

• [SLOW TEST:28.829 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:30:41.596: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-prcms
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Sep  2 13:30:41.763: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:30:44.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-prcms" for this suite.
Sep  2 13:30:50.642: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:30:50.726: INFO: namespace: e2e-tests-init-container-prcms, resource: bindings, ignored listing per whitelist
Sep  2 13:30:50.734: INFO: namespace e2e-tests-init-container-prcms deletion completed in 6.114017781s

• [SLOW TEST:9.138 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:30:50.734: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-sq5d8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-sq5d8.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-sq5d8.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-sq5d8.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-sq5d8.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-sq5d8.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-sq5d8.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep  2 13:30:52.965: INFO: DNS probes using e2e-tests-dns-sq5d8/dns-test-e17d322f-cd85-11e9-b90e-8ed318f3d3c6 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:30:52.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-sq5d8" for this suite.
Sep  2 13:30:58.995: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:30:59.015: INFO: namespace: e2e-tests-dns-sq5d8, resource: bindings, ignored listing per whitelist
Sep  2 13:30:59.087: INFO: namespace e2e-tests-dns-sq5d8 deletion completed in 6.107667422s

• [SLOW TEST:8.353 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:30:59.088: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-x6s4r
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Sep  2 13:30:59.262: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Sep  2 13:31:04.271: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep  2 13:31:04.271: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Sep  2 13:31:04.291: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-x6s4r,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-x6s4r/deployments/test-cleanup-deployment,UID:e9771f0c-cd85-11e9-a575-0a854009c708,ResourceVersion:2091579,Generation:1,CreationTimestamp:2019-09-02 13:31:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Sep  2 13:31:04.295: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:31:04.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-x6s4r" for this suite.
Sep  2 13:31:10.322: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:31:10.352: INFO: namespace: e2e-tests-deployment-x6s4r, resource: bindings, ignored listing per whitelist
Sep  2 13:31:10.413: INFO: namespace e2e-tests-deployment-x6s4r deletion completed in 6.10990694s

• [SLOW TEST:11.325 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:31:10.413: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-vsznc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Sep  2 13:31:10.585: INFO: Waiting up to 5m0s for pod "downward-api-ed38f8f5-cd85-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-downward-api-vsznc" to be "success or failure"
Sep  2 13:31:10.588: INFO: Pod "downward-api-ed38f8f5-cd85-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.327157ms
Sep  2 13:31:12.591: INFO: Pod "downward-api-ed38f8f5-cd85-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005795744s
Sep  2 13:31:14.601: INFO: Pod "downward-api-ed38f8f5-cd85-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015183557s
STEP: Saw pod success
Sep  2 13:31:14.601: INFO: Pod "downward-api-ed38f8f5-cd85-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 13:31:14.603: INFO: Trying to get logs from node ip-192-168-77-237.us-west-2.compute.internal pod downward-api-ed38f8f5-cd85-11e9-b90e-8ed318f3d3c6 container dapi-container: <nil>
STEP: delete the pod
Sep  2 13:31:14.620: INFO: Waiting for pod downward-api-ed38f8f5-cd85-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 13:31:14.622: INFO: Pod downward-api-ed38f8f5-cd85-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:31:14.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-vsznc" for this suite.
Sep  2 13:31:20.644: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:31:20.675: INFO: namespace: e2e-tests-downward-api-vsznc, resource: bindings, ignored listing per whitelist
Sep  2 13:31:20.736: INFO: namespace e2e-tests-downward-api-vsznc deletion completed in 6.108331708s

• [SLOW TEST:10.323 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:31:20.736: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-z4xqs
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0902 13:31:26.930470      19 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep  2 13:31:26.930: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:31:26.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-z4xqs" for this suite.
Sep  2 13:31:32.949: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:31:33.025: INFO: namespace: e2e-tests-gc-z4xqs, resource: bindings, ignored listing per whitelist
Sep  2 13:31:33.045: INFO: namespace e2e-tests-gc-z4xqs deletion completed in 6.111131785s

• [SLOW TEST:12.309 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:31:33.045: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-mvj74
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-fab760cb-cd85-11e9-b90e-8ed318f3d3c6
STEP: Creating configMap with name cm-test-opt-upd-fab7612d-cd85-11e9-b90e-8ed318f3d3c6
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-fab760cb-cd85-11e9-b90e-8ed318f3d3c6
STEP: Updating configmap cm-test-opt-upd-fab7612d-cd85-11e9-b90e-8ed318f3d3c6
STEP: Creating configMap with name cm-test-opt-create-fab76160-cd85-11e9-b90e-8ed318f3d3c6
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:31:39.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mvj74" for this suite.
Sep  2 13:32:01.323: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:32:01.409: INFO: namespace: e2e-tests-projected-mvj74, resource: bindings, ignored listing per whitelist
Sep  2 13:32:01.422: INFO: namespace e2e-tests-projected-mvj74 deletion completed in 22.114747403s

• [SLOW TEST:28.377 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:32:01.422: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replication-controller-gfrmq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:32:14.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-gfrmq" for this suite.
Sep  2 13:32:36.694: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:32:36.718: INFO: namespace: e2e-tests-replication-controller-gfrmq, resource: bindings, ignored listing per whitelist
Sep  2 13:32:36.787: INFO: namespace e2e-tests-replication-controller-gfrmq deletion completed in 22.108549811s

• [SLOW TEST:35.365 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:32:36.787: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-lwfv8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-lwfv8
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-lwfv8 to expose endpoints map[]
Sep  2 13:32:36.967: INFO: Get endpoints failed (5.172022ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Sep  2 13:32:37.972: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-lwfv8 exposes endpoints map[] (1.009745881s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-lwfv8
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-lwfv8 to expose endpoints map[pod1:[100]]
Sep  2 13:32:39.998: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-lwfv8 exposes endpoints map[pod1:[100]] (2.020119081s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-lwfv8
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-lwfv8 to expose endpoints map[pod1:[100] pod2:[101]]
Sep  2 13:32:42.031: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-lwfv8 exposes endpoints map[pod1:[100] pod2:[101]] (2.028025431s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-lwfv8
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-lwfv8 to expose endpoints map[pod2:[101]]
Sep  2 13:32:43.055: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-lwfv8 exposes endpoints map[pod2:[101]] (1.018902587s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-lwfv8
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-lwfv8 to expose endpoints map[]
Sep  2 13:32:44.069: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-lwfv8 exposes endpoints map[] (1.008524927s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:32:44.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-lwfv8" for this suite.
Sep  2 13:33:06.121: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:33:06.137: INFO: namespace: e2e-tests-services-lwfv8, resource: bindings, ignored listing per whitelist
Sep  2 13:33:06.212: INFO: namespace e2e-tests-services-lwfv8 deletion completed in 22.113071379s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:29.425 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:33:06.212: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-vbcz5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Sep  2 13:33:06.384: INFO: Waiting up to 5m0s for pod "pod-323e9b83-cd86-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-emptydir-vbcz5" to be "success or failure"
Sep  2 13:33:06.387: INFO: Pod "pod-323e9b83-cd86-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.487195ms
Sep  2 13:33:08.390: INFO: Pod "pod-323e9b83-cd86-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005541526s
STEP: Saw pod success
Sep  2 13:33:08.390: INFO: Pod "pod-323e9b83-cd86-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 13:33:08.392: INFO: Trying to get logs from node ip-192-168-77-237.us-west-2.compute.internal pod pod-323e9b83-cd86-11e9-b90e-8ed318f3d3c6 container test-container: <nil>
STEP: delete the pod
Sep  2 13:33:08.408: INFO: Waiting for pod pod-323e9b83-cd86-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 13:33:08.411: INFO: Pod pod-323e9b83-cd86-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:33:08.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-vbcz5" for this suite.
Sep  2 13:33:14.431: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:33:14.511: INFO: namespace: e2e-tests-emptydir-vbcz5, resource: bindings, ignored listing per whitelist
Sep  2 13:33:14.525: INFO: namespace e2e-tests-emptydir-vbcz5 deletion completed in 6.111010322s

• [SLOW TEST:8.313 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:33:14.525: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-wtknl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Sep  2 13:33:14.682: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:33:16.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-wtknl" for this suite.
Sep  2 13:34:02.741: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:34:02.822: INFO: namespace: e2e-tests-pods-wtknl, resource: bindings, ignored listing per whitelist
Sep  2 13:34:02.833: INFO: namespace e2e-tests-pods-wtknl deletion completed in 46.112856391s

• [SLOW TEST:48.307 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:34:02.833: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-d4frm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-d4frm
Sep  2 13:34:05.011: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-d4frm
STEP: checking the pod's current state and verifying that restartCount is present
Sep  2 13:34:05.013: INFO: Initial restart count of pod liveness-http is 0
Sep  2 13:34:23.056: INFO: Restart count of pod e2e-tests-container-probe-d4frm/liveness-http is now 1 (18.042598413s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:34:23.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-d4frm" for this suite.
Sep  2 13:34:29.086: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:34:29.156: INFO: namespace: e2e-tests-container-probe-d4frm, resource: bindings, ignored listing per whitelist
Sep  2 13:34:29.179: INFO: namespace e2e-tests-container-probe-d4frm deletion completed in 6.108074684s

• [SLOW TEST:26.346 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:34:29.180: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-6xk86
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-63b293b9-cd86-11e9-b90e-8ed318f3d3c6
STEP: Creating a pod to test consume secrets
Sep  2 13:34:29.358: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-63b3475b-cd86-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-projected-6xk86" to be "success or failure"
Sep  2 13:34:29.360: INFO: Pod "pod-projected-secrets-63b3475b-cd86-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.26149ms
Sep  2 13:34:31.364: INFO: Pod "pod-projected-secrets-63b3475b-cd86-11e9-b90e-8ed318f3d3c6": Phase="Running", Reason="", readiness=true. Elapsed: 2.005578907s
Sep  2 13:34:33.373: INFO: Pod "pod-projected-secrets-63b3475b-cd86-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014680559s
STEP: Saw pod success
Sep  2 13:34:33.373: INFO: Pod "pod-projected-secrets-63b3475b-cd86-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 13:34:33.375: INFO: Trying to get logs from node ip-192-168-185-95.us-west-2.compute.internal pod pod-projected-secrets-63b3475b-cd86-11e9-b90e-8ed318f3d3c6 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep  2 13:34:33.393: INFO: Waiting for pod pod-projected-secrets-63b3475b-cd86-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 13:34:33.395: INFO: Pod pod-projected-secrets-63b3475b-cd86-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:34:33.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6xk86" for this suite.
Sep  2 13:34:39.415: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:34:39.451: INFO: namespace: e2e-tests-projected-6xk86, resource: bindings, ignored listing per whitelist
Sep  2 13:34:39.507: INFO: namespace e2e-tests-projected-6xk86 deletion completed in 6.108735756s

• [SLOW TEST:10.328 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:34:39.508: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-dbhld
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Sep  2 13:34:39.678: INFO: Waiting up to 5m0s for pod "downwardapi-volume-69da103c-cd86-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-downward-api-dbhld" to be "success or failure"
Sep  2 13:34:39.680: INFO: Pod "downwardapi-volume-69da103c-cd86-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.230724ms
Sep  2 13:34:41.684: INFO: Pod "downwardapi-volume-69da103c-cd86-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005487654s
Sep  2 13:34:43.692: INFO: Pod "downwardapi-volume-69da103c-cd86-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014345436s
STEP: Saw pod success
Sep  2 13:34:43.692: INFO: Pod "downwardapi-volume-69da103c-cd86-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 13:34:43.695: INFO: Trying to get logs from node ip-192-168-77-237.us-west-2.compute.internal pod downwardapi-volume-69da103c-cd86-11e9-b90e-8ed318f3d3c6 container client-container: <nil>
STEP: delete the pod
Sep  2 13:34:43.713: INFO: Waiting for pod downwardapi-volume-69da103c-cd86-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 13:34:43.715: INFO: Pod downwardapi-volume-69da103c-cd86-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:34:43.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-dbhld" for this suite.
Sep  2 13:34:49.735: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:34:49.793: INFO: namespace: e2e-tests-downward-api-dbhld, resource: bindings, ignored listing per whitelist
Sep  2 13:34:49.825: INFO: namespace e2e-tests-downward-api-dbhld deletion completed in 6.106554303s

• [SLOW TEST:10.318 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:34:49.826: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-hlfzp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Sep  2 13:34:49.999: INFO: Waiting up to 5m0s for pod "downwardapi-volume-700092a8-cd86-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-projected-hlfzp" to be "success or failure"
Sep  2 13:34:50.004: INFO: Pod "downwardapi-volume-700092a8-cd86-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.442722ms
Sep  2 13:34:52.007: INFO: Pod "downwardapi-volume-700092a8-cd86-11e9-b90e-8ed318f3d3c6": Phase="Running", Reason="", readiness=true. Elapsed: 2.007905726s
Sep  2 13:34:54.016: INFO: Pod "downwardapi-volume-700092a8-cd86-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016546267s
STEP: Saw pod success
Sep  2 13:34:54.016: INFO: Pod "downwardapi-volume-700092a8-cd86-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 13:34:54.018: INFO: Trying to get logs from node ip-192-168-77-237.us-west-2.compute.internal pod downwardapi-volume-700092a8-cd86-11e9-b90e-8ed318f3d3c6 container client-container: <nil>
STEP: delete the pod
Sep  2 13:34:54.034: INFO: Waiting for pod downwardapi-volume-700092a8-cd86-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 13:34:54.036: INFO: Pod downwardapi-volume-700092a8-cd86-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:34:54.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hlfzp" for this suite.
Sep  2 13:35:00.056: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:35:00.081: INFO: namespace: e2e-tests-projected-hlfzp, resource: bindings, ignored listing per whitelist
Sep  2 13:35:00.147: INFO: namespace e2e-tests-projected-hlfzp deletion completed in 6.10695972s

• [SLOW TEST:10.321 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:35:00.147: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-kkwmr
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-76284953-cd86-11e9-b90e-8ed318f3d3c6
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-76284953-cd86-11e9-b90e-8ed318f3d3c6
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:36:22.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-kkwmr" for this suite.
Sep  2 13:36:44.736: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:36:44.799: INFO: namespace: e2e-tests-configmap-kkwmr, resource: bindings, ignored listing per whitelist
Sep  2 13:36:44.827: INFO: namespace e2e-tests-configmap-kkwmr deletion completed in 22.107983066s

• [SLOW TEST:104.680 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:36:44.828: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-ksbcr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-b48cab8d-cd86-11e9-b90e-8ed318f3d3c6
STEP: Creating a pod to test consume secrets
Sep  2 13:36:45.005: INFO: Waiting up to 5m0s for pod "pod-secrets-b48d6b4c-cd86-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-secrets-ksbcr" to be "success or failure"
Sep  2 13:36:45.007: INFO: Pod "pod-secrets-b48d6b4c-cd86-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.265784ms
Sep  2 13:36:47.016: INFO: Pod "pod-secrets-b48d6b4c-cd86-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011033198s
STEP: Saw pod success
Sep  2 13:36:47.016: INFO: Pod "pod-secrets-b48d6b4c-cd86-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 13:36:47.019: INFO: Trying to get logs from node ip-192-168-185-95.us-west-2.compute.internal pod pod-secrets-b48d6b4c-cd86-11e9-b90e-8ed318f3d3c6 container secret-volume-test: <nil>
STEP: delete the pod
Sep  2 13:36:47.035: INFO: Waiting for pod pod-secrets-b48d6b4c-cd86-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 13:36:47.037: INFO: Pod pod-secrets-b48d6b4c-cd86-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:36:47.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-ksbcr" for this suite.
Sep  2 13:36:53.057: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:36:53.146: INFO: namespace: e2e-tests-secrets-ksbcr, resource: bindings, ignored listing per whitelist
Sep  2 13:36:53.148: INFO: namespace e2e-tests-secrets-ksbcr deletion completed in 6.10731122s

• [SLOW TEST:8.320 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:36:53.148: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-xs9xg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Sep  2 13:36:53.309: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 version --client'
Sep  2 13:36:53.359: INFO: stderr: ""
Sep  2 13:36:53.359: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Sep  2 13:36:53.360: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 create -f - --namespace=e2e-tests-kubectl-xs9xg'
Sep  2 13:36:53.632: INFO: stderr: ""
Sep  2 13:36:53.633: INFO: stdout: "replicationcontroller/redis-master created\n"
Sep  2 13:36:53.633: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 create -f - --namespace=e2e-tests-kubectl-xs9xg'
Sep  2 13:36:53.828: INFO: stderr: ""
Sep  2 13:36:53.828: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Sep  2 13:36:54.831: INFO: Selector matched 1 pods for map[app:redis]
Sep  2 13:36:54.831: INFO: Found 0 / 1
Sep  2 13:36:55.831: INFO: Selector matched 1 pods for map[app:redis]
Sep  2 13:36:55.831: INFO: Found 0 / 1
Sep  2 13:36:56.831: INFO: Selector matched 1 pods for map[app:redis]
Sep  2 13:36:56.831: INFO: Found 1 / 1
Sep  2 13:36:56.832: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Sep  2 13:36:56.834: INFO: Selector matched 1 pods for map[app:redis]
Sep  2 13:36:56.834: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep  2 13:36:56.834: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 describe pod redis-master-jrb7l --namespace=e2e-tests-kubectl-xs9xg'
Sep  2 13:36:56.916: INFO: stderr: ""
Sep  2 13:36:56.916: INFO: stdout: "Name:               redis-master-jrb7l\nNamespace:          e2e-tests-kubectl-xs9xg\nPriority:           0\nPriorityClassName:  <none>\nNode:               ip-192-168-185-95.us-west-2.compute.internal/192.168.185.95\nStart Time:         Mon, 02 Sep 2019 13:36:53 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        kubernetes.io/psp: e2e-test-privileged-psp\nStatus:             Running\nIP:                 192.168.188.44\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://6232498ddce1915fa204451574af84627cb87ab755cd23f0108b2826d3846abf\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 02 Sep 2019 13:36:56 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-x2rfc (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-x2rfc:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-x2rfc\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                                   Message\n  ----    ------     ----  ----                                                   -------\n  Normal  Scheduled  3s    default-scheduler                                      Successfully assigned e2e-tests-kubectl-xs9xg/redis-master-jrb7l to ip-192-168-185-95.us-west-2.compute.internal\n  Normal  Pulling    2s    kubelet, ip-192-168-185-95.us-west-2.compute.internal  pulling image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\"\n  Normal  Pulled     0s    kubelet, ip-192-168-185-95.us-west-2.compute.internal  Successfully pulled image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\"\n  Normal  Created    0s    kubelet, ip-192-168-185-95.us-west-2.compute.internal  Created container\n  Normal  Started    0s    kubelet, ip-192-168-185-95.us-west-2.compute.internal  Started container\n"
Sep  2 13:36:56.916: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 describe rc redis-master --namespace=e2e-tests-kubectl-xs9xg'
Sep  2 13:36:56.996: INFO: stderr: ""
Sep  2 13:36:56.996: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-xs9xg\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-jrb7l\n"
Sep  2 13:36:56.996: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 describe service redis-master --namespace=e2e-tests-kubectl-xs9xg'
Sep  2 13:36:57.080: INFO: stderr: ""
Sep  2 13:36:57.080: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-xs9xg\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.100.65.18\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         192.168.188.44:6379\nSession Affinity:  None\nEvents:            <none>\n"
Sep  2 13:36:57.084: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 describe node ip-192-168-185-95.us-west-2.compute.internal'
Sep  2 13:36:57.168: INFO: stderr: ""
Sep  2 13:36:57.168: INFO: stdout: "Name:               ip-192-168-185-95.us-west-2.compute.internal\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=r3.large\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=us-west-2\n                    failure-domain.beta.kubernetes.io/zone=us-west-2a\n                    kubernetes.io/hostname=ip-192-168-185-95.us-west-2.compute.internal\n                    spotinst.io/node-lifecycle=spot\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 02 Sep 2019 12:25:13 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Mon, 02 Sep 2019 13:36:51 +0000   Mon, 02 Sep 2019 12:25:12 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Mon, 02 Sep 2019 13:36:51 +0000   Mon, 02 Sep 2019 12:25:12 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Mon, 02 Sep 2019 13:36:51 +0000   Mon, 02 Sep 2019 12:25:12 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Mon, 02 Sep 2019 13:36:51 +0000   Mon, 02 Sep 2019 12:25:53 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:   192.168.185.95\n  ExternalIP:   34.215.100.214\n  Hostname:     ip-192-168-185-95.us-west-2.compute.internal\n  InternalDNS:  ip-192-168-185-95.us-west-2.compute.internal\n  ExternalDNS:  ec2-34-215-100-214.us-west-2.compute.amazonaws.com\nCapacity:\n attachable-volumes-aws-ebs:  39\n cpu:                         2\n ephemeral-storage:           20959212Ki\n hugepages-2Mi:               0\n memory:                      15657256Ki\n pods:                        29\nAllocatable:\n attachable-volumes-aws-ebs:  39\n cpu:                         2\n ephemeral-storage:           19316009748\n hugepages-2Mi:               0\n memory:                      15554856Ki\n pods:                        29\nSystem Info:\n Machine ID:                 b66dc5ca4c674f52b7f240793cc5150b\n System UUID:                EC24D5BE-D024-B643-80A6-B95DD278624C\n Boot ID:                    4ff24d20-4c16-46e3-9250-9219205ad75c\n Kernel Version:             4.14.133-113.112.amzn2.x86_64\n OS Image:                   Amazon Linux 2\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.1\n Kubelet Version:            v1.13.8-eks-cd3eb0\n Kube-Proxy Version:         v1.13.8-eks-cd3eb0\nProviderID:                  aws:///us-west-2a/i-03b032509e6176246\nNon-terminated Pods:         (4 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  e2e-tests-kubectl-xs9xg    redis-master-jrb7l                                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         4s\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-f7d9f222843a4872-xv7pn    0 (0%)        0 (0%)      0 (0%)           0 (0%)         28m\n  kube-system                aws-node-h72bs                                             10m (0%)      0 (0%)      0 (0%)           0 (0%)         71m\n  kube-system                kube-proxy-w76hj                                           100m (5%)     0 (0%)      0 (0%)           0 (0%)         71m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                    Requests   Limits\n  --------                    --------   ------\n  cpu                         110m (5%)  0 (0%)\n  memory                      0 (0%)     0 (0%)\n  ephemeral-storage           0 (0%)     0 (0%)\n  attachable-volumes-aws-ebs  0          0\nEvents:                       <none>\n"
Sep  2 13:36:57.168: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 describe namespace e2e-tests-kubectl-xs9xg'
Sep  2 13:36:57.246: INFO: stderr: ""
Sep  2 13:36:57.246: INFO: stdout: "Name:         e2e-tests-kubectl-xs9xg\nLabels:       e2e-framework=kubectl\n              e2e-run=bdc259f4-cd82-11e9-b90e-8ed318f3d3c6\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:36:57.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xs9xg" for this suite.
Sep  2 13:37:19.272: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:37:19.330: INFO: namespace: e2e-tests-kubectl-xs9xg, resource: bindings, ignored listing per whitelist
Sep  2 13:37:19.365: INFO: namespace e2e-tests-kubectl-xs9xg deletion completed in 22.11478284s

• [SLOW TEST:26.216 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:37:19.365: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-2cfzz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-2cfzz
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-2cfzz
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-2cfzz
Sep  2 13:37:19.543: INFO: Found 0 stateful pods, waiting for 1
Sep  2 13:37:29.552: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Sep  2 13:37:29.555: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-2cfzz ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  2 13:37:29.716: INFO: stderr: ""
Sep  2 13:37:29.716: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  2 13:37:29.716: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  2 13:37:29.719: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Sep  2 13:37:39.729: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep  2 13:37:39.729: INFO: Waiting for statefulset status.replicas updated to 0
Sep  2 13:37:39.740: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999998466s
Sep  2 13:37:40.743: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.997295009s
Sep  2 13:37:41.747: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.993584967s
Sep  2 13:37:42.750: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.990263927s
Sep  2 13:37:43.754: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.986736086s
Sep  2 13:37:44.757: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.983109269s
Sep  2 13:37:45.761: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.979688796s
Sep  2 13:37:46.764: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.976345968s
Sep  2 13:37:47.768: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.972779404s
Sep  2 13:37:48.771: INFO: Verifying statefulset ss doesn't scale past 1 for another 969.251474ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-2cfzz
Sep  2 13:37:49.780: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-2cfzz ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  2 13:37:49.948: INFO: stderr: ""
Sep  2 13:37:49.948: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  2 13:37:49.948: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  2 13:37:49.951: INFO: Found 1 stateful pods, waiting for 3
Sep  2 13:37:59.961: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Sep  2 13:37:59.961: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Sep  2 13:37:59.961: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Sep  2 13:37:59.965: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-2cfzz ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  2 13:38:00.122: INFO: stderr: ""
Sep  2 13:38:00.122: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  2 13:38:00.122: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  2 13:38:00.122: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-2cfzz ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  2 13:38:00.267: INFO: stderr: ""
Sep  2 13:38:00.267: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  2 13:38:00.267: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  2 13:38:00.267: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-2cfzz ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  2 13:38:00.412: INFO: stderr: ""
Sep  2 13:38:00.412: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  2 13:38:00.412: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  2 13:38:00.412: INFO: Waiting for statefulset status.replicas updated to 0
Sep  2 13:38:00.416: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Sep  2 13:38:10.428: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep  2 13:38:10.428: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Sep  2 13:38:10.428: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Sep  2 13:38:10.439: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999998478s
Sep  2 13:38:11.443: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.99554741s
Sep  2 13:38:12.447: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.991553166s
Sep  2 13:38:13.451: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.987677506s
Sep  2 13:38:14.455: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.983680599s
Sep  2 13:38:15.459: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.979818127s
Sep  2 13:38:16.462: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.976162709s
Sep  2 13:38:17.466: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.972497103s
Sep  2 13:38:18.470: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.968840106s
Sep  2 13:38:19.474: INFO: Verifying statefulset ss doesn't scale past 3 for another 965.112837ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-2cfzz
Sep  2 13:38:20.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-2cfzz ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  2 13:38:20.640: INFO: stderr: ""
Sep  2 13:38:20.640: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  2 13:38:20.640: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  2 13:38:20.640: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-2cfzz ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  2 13:38:20.792: INFO: stderr: ""
Sep  2 13:38:20.792: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  2 13:38:20.792: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  2 13:38:20.792: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-2cfzz ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  2 13:38:20.939: INFO: stderr: ""
Sep  2 13:38:20.939: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  2 13:38:20.939: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  2 13:38:20.939: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Sep  2 13:38:30.958: INFO: Deleting all statefulset in ns e2e-tests-statefulset-2cfzz
Sep  2 13:38:30.960: INFO: Scaling statefulset ss to 0
Sep  2 13:38:30.968: INFO: Waiting for statefulset status.replicas updated to 0
Sep  2 13:38:30.970: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:38:30.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-2cfzz" for this suite.
Sep  2 13:38:37.002: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:38:37.036: INFO: namespace: e2e-tests-statefulset-2cfzz, resource: bindings, ignored listing per whitelist
Sep  2 13:38:37.097: INFO: namespace e2e-tests-statefulset-2cfzz deletion completed in 6.111234334s

• [SLOW TEST:77.732 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:38:37.098: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-xtrbj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Sep  2 13:38:37.262: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:38:41.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-xtrbj" for this suite.
Sep  2 13:39:23.410: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:39:23.500: INFO: namespace: e2e-tests-pods-xtrbj, resource: bindings, ignored listing per whitelist
Sep  2 13:39:23.507: INFO: namespace e2e-tests-pods-xtrbj deletion completed in 42.11318096s

• [SLOW TEST:46.409 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:39:23.507: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-96mzb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Sep  2 13:39:24.192: INFO: created pod pod-service-account-defaultsa
Sep  2 13:39:24.192: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Sep  2 13:39:24.196: INFO: created pod pod-service-account-mountsa
Sep  2 13:39:24.196: INFO: pod pod-service-account-mountsa service account token volume mount: true
Sep  2 13:39:24.201: INFO: created pod pod-service-account-nomountsa
Sep  2 13:39:24.201: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Sep  2 13:39:24.206: INFO: created pod pod-service-account-defaultsa-mountspec
Sep  2 13:39:24.206: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Sep  2 13:39:24.212: INFO: created pod pod-service-account-mountsa-mountspec
Sep  2 13:39:24.212: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Sep  2 13:39:24.218: INFO: created pod pod-service-account-nomountsa-mountspec
Sep  2 13:39:24.218: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Sep  2 13:39:24.224: INFO: created pod pod-service-account-defaultsa-nomountspec
Sep  2 13:39:24.224: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Sep  2 13:39:24.229: INFO: created pod pod-service-account-mountsa-nomountspec
Sep  2 13:39:24.229: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Sep  2 13:39:24.234: INFO: created pod pod-service-account-nomountsa-nomountspec
Sep  2 13:39:24.234: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:39:24.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-96mzb" for this suite.
Sep  2 13:39:30.255: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:39:30.336: INFO: namespace: e2e-tests-svcaccounts-96mzb, resource: bindings, ignored listing per whitelist
Sep  2 13:39:30.350: INFO: namespace e2e-tests-svcaccounts-96mzb deletion completed in 6.112958139s

• [SLOW TEST:6.843 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:39:30.350: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-pldxc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Sep  2 13:39:36.556: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep  2 13:39:36.558: INFO: Pod pod-with-poststart-http-hook still exists
Sep  2 13:39:38.558: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep  2 13:39:38.562: INFO: Pod pod-with-poststart-http-hook still exists
Sep  2 13:39:40.558: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep  2 13:39:40.562: INFO: Pod pod-with-poststart-http-hook still exists
Sep  2 13:39:42.558: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep  2 13:39:42.562: INFO: Pod pod-with-poststart-http-hook still exists
Sep  2 13:39:44.558: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep  2 13:39:44.562: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:39:44.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-pldxc" for this suite.
Sep  2 13:40:06.581: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:40:06.659: INFO: namespace: e2e-tests-container-lifecycle-hook-pldxc, resource: bindings, ignored listing per whitelist
Sep  2 13:40:06.679: INFO: namespace e2e-tests-container-lifecycle-hook-pldxc deletion completed in 22.113574038s

• [SLOW TEST:36.329 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:40:06.679: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-nhs6q
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Sep  2 13:40:06.853: INFO: Waiting up to 5m0s for pod "pod-2cdd1b86-cd87-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-emptydir-nhs6q" to be "success or failure"
Sep  2 13:40:06.855: INFO: Pod "pod-2cdd1b86-cd87-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.318529ms
Sep  2 13:40:08.864: INFO: Pod "pod-2cdd1b86-cd87-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011270901s
Sep  2 13:40:10.868: INFO: Pod "pod-2cdd1b86-cd87-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014608545s
STEP: Saw pod success
Sep  2 13:40:10.868: INFO: Pod "pod-2cdd1b86-cd87-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 13:40:10.870: INFO: Trying to get logs from node ip-192-168-185-95.us-west-2.compute.internal pod pod-2cdd1b86-cd87-11e9-b90e-8ed318f3d3c6 container test-container: <nil>
STEP: delete the pod
Sep  2 13:40:10.890: INFO: Waiting for pod pod-2cdd1b86-cd87-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 13:40:10.892: INFO: Pod pod-2cdd1b86-cd87-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:40:10.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-nhs6q" for this suite.
Sep  2 13:40:16.911: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:40:16.952: INFO: namespace: e2e-tests-emptydir-nhs6q, resource: bindings, ignored listing per whitelist
Sep  2 13:40:17.008: INFO: namespace e2e-tests-emptydir-nhs6q deletion completed in 6.112367765s

• [SLOW TEST:10.329 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:40:17.008: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-6v894
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Sep  2 13:40:17.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 create -f - --namespace=e2e-tests-kubectl-6v894'
Sep  2 13:40:17.446: INFO: stderr: ""
Sep  2 13:40:17.446: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Sep  2 13:40:18.449: INFO: Selector matched 1 pods for map[app:redis]
Sep  2 13:40:18.449: INFO: Found 0 / 1
Sep  2 13:40:19.455: INFO: Selector matched 1 pods for map[app:redis]
Sep  2 13:40:19.455: INFO: Found 1 / 1
Sep  2 13:40:19.455: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Sep  2 13:40:19.458: INFO: Selector matched 1 pods for map[app:redis]
Sep  2 13:40:19.458: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep  2 13:40:19.458: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 patch pod redis-master-flhkj --namespace=e2e-tests-kubectl-6v894 -p {"metadata":{"annotations":{"x":"y"}}}'
Sep  2 13:40:19.539: INFO: stderr: ""
Sep  2 13:40:19.539: INFO: stdout: "pod/redis-master-flhkj patched\n"
STEP: checking annotations
Sep  2 13:40:19.542: INFO: Selector matched 1 pods for map[app:redis]
Sep  2 13:40:19.542: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:40:19.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6v894" for this suite.
Sep  2 13:40:41.567: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:40:41.615: INFO: namespace: e2e-tests-kubectl-6v894, resource: bindings, ignored listing per whitelist
Sep  2 13:40:41.664: INFO: namespace e2e-tests-kubectl-6v894 deletion completed in 22.118418968s

• [SLOW TEST:24.656 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:40:41.664: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-6bvx7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Sep  2 13:40:41.831: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep  2 13:40:41.838: INFO: Waiting for terminating namespaces to be deleted...
Sep  2 13:40:41.842: INFO: 
Logging pods the kubelet thinks is on node ip-192-168-185-95.us-west-2.compute.internal before test
Sep  2 13:40:41.846: INFO: kube-proxy-w76hj from kube-system started at 2019-09-02 12:25:13 +0000 UTC (1 container statuses recorded)
Sep  2 13:40:41.846: INFO: 	Container kube-proxy ready: true, restart count 0
Sep  2 13:40:41.846: INFO: sonobuoy-systemd-logs-daemon-set-f7d9f222843a4872-xv7pn from heptio-sonobuoy started at 2019-09-02 13:08:20 +0000 UTC (2 container statuses recorded)
Sep  2 13:40:41.846: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep  2 13:40:41.846: INFO: 	Container systemd-logs ready: true, restart count 0
Sep  2 13:40:41.846: INFO: aws-node-h72bs from kube-system started at 2019-09-02 12:25:13 +0000 UTC (1 container statuses recorded)
Sep  2 13:40:41.846: INFO: 	Container aws-node ready: true, restart count 0
Sep  2 13:40:41.846: INFO: 
Logging pods the kubelet thinks is on node ip-192-168-55-191.us-west-2.compute.internal before test
Sep  2 13:40:41.852: INFO: coredns-79d667b89f-fbrdn from kube-system started at 2019-09-02 07:27:30 +0000 UTC (1 container statuses recorded)
Sep  2 13:40:41.852: INFO: 	Container coredns ready: true, restart count 0
Sep  2 13:40:41.852: INFO: sonobuoy-systemd-logs-daemon-set-f7d9f222843a4872-4p5pk from heptio-sonobuoy started at 2019-09-02 13:08:20 +0000 UTC (2 container statuses recorded)
Sep  2 13:40:41.852: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep  2 13:40:41.852: INFO: 	Container systemd-logs ready: true, restart count 0
Sep  2 13:40:41.852: INFO: aws-node-cssxg from kube-system started at 2019-09-02 07:20:24 +0000 UTC (1 container statuses recorded)
Sep  2 13:40:41.852: INFO: 	Container aws-node ready: true, restart count 0
Sep  2 13:40:41.852: INFO: kube-proxy-gpz5v from kube-system started at 2019-09-02 07:20:24 +0000 UTC (1 container statuses recorded)
Sep  2 13:40:41.852: INFO: 	Container kube-proxy ready: true, restart count 0
Sep  2 13:40:41.852: INFO: 
Logging pods the kubelet thinks is on node ip-192-168-6-156.us-west-2.compute.internal before test
Sep  2 13:40:41.858: INFO: sonobuoy-systemd-logs-daemon-set-f7d9f222843a4872-hppz8 from heptio-sonobuoy started at 2019-09-02 13:08:20 +0000 UTC (2 container statuses recorded)
Sep  2 13:40:41.858: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep  2 13:40:41.858: INFO: 	Container systemd-logs ready: true, restart count 0
Sep  2 13:40:41.858: INFO: aws-node-d25qt from kube-system started at 2019-09-02 07:28:57 +0000 UTC (1 container statuses recorded)
Sep  2 13:40:41.858: INFO: 	Container aws-node ready: true, restart count 0
Sep  2 13:40:41.858: INFO: sonobuoy from heptio-sonobuoy started at 2019-09-02 13:08:19 +0000 UTC (1 container statuses recorded)
Sep  2 13:40:41.858: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep  2 13:40:41.858: INFO: kube-proxy-wvzsh from kube-system started at 2019-09-02 07:28:57 +0000 UTC (1 container statuses recorded)
Sep  2 13:40:41.858: INFO: 	Container kube-proxy ready: true, restart count 0
Sep  2 13:40:41.858: INFO: 
Logging pods the kubelet thinks is on node ip-192-168-77-237.us-west-2.compute.internal before test
Sep  2 13:40:41.864: INFO: coredns-79d667b89f-thvvk from kube-system started at 2019-09-02 10:12:03 +0000 UTC (1 container statuses recorded)
Sep  2 13:40:41.864: INFO: 	Container coredns ready: true, restart count 0
Sep  2 13:40:41.864: INFO: kube-proxy-84977 from kube-system started at 2019-09-02 07:35:32 +0000 UTC (1 container statuses recorded)
Sep  2 13:40:41.864: INFO: 	Container kube-proxy ready: true, restart count 0
Sep  2 13:40:41.864: INFO: spotinst-kubernetes-cluster-controller-5456664d9b-ljj66 from kube-system started at 2019-09-02 10:12:33 +0000 UTC (1 container statuses recorded)
Sep  2 13:40:41.864: INFO: 	Container spotinst-kubernetes-cluster-controller ready: true, restart count 0
Sep  2 13:40:41.864: INFO: sonobuoy-systemd-logs-daemon-set-f7d9f222843a4872-7g5md from heptio-sonobuoy started at 2019-09-02 13:08:20 +0000 UTC (2 container statuses recorded)
Sep  2 13:40:41.864: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep  2 13:40:41.864: INFO: 	Container systemd-logs ready: true, restart count 0
Sep  2 13:40:41.864: INFO: aws-node-zh7fs from kube-system started at 2019-09-02 07:35:32 +0000 UTC (1 container statuses recorded)
Sep  2 13:40:41.864: INFO: 	Container aws-node ready: true, restart count 0
Sep  2 13:40:41.864: INFO: sonobuoy-e2e-job-1216ef12ccbc49ed from heptio-sonobuoy started at 2019-09-02 13:08:20 +0000 UTC (2 container statuses recorded)
Sep  2 13:40:41.864: INFO: 	Container e2e ready: true, restart count 0
Sep  2 13:40:41.864: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-44222ae6-cd87-11e9-b90e-8ed318f3d3c6 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-44222ae6-cd87-11e9-b90e-8ed318f3d3c6 off the node ip-192-168-77-237.us-west-2.compute.internal
STEP: verifying the node doesn't have the label kubernetes.io/e2e-44222ae6-cd87-11e9-b90e-8ed318f3d3c6
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:40:51.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-6bvx7" for this suite.
Sep  2 13:41:21.945: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:41:22.043: INFO: namespace: e2e-tests-sched-pred-6bvx7, resource: bindings, ignored listing per whitelist
Sep  2 13:41:22.043: INFO: namespace e2e-tests-sched-pred-6bvx7 deletion completed in 30.11575221s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:40.379 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:41:22.043: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-hb8ff
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Sep  2 13:41:22.209: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 create -f - --namespace=e2e-tests-kubectl-hb8ff'
Sep  2 13:41:22.364: INFO: stderr: ""
Sep  2 13:41:22.364: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep  2 13:41:22.364: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-hb8ff'
Sep  2 13:41:22.433: INFO: stderr: ""
Sep  2 13:41:22.433: INFO: stdout: "update-demo-nautilus-pt4vq update-demo-nautilus-tzg2s "
Sep  2 13:41:22.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 get pods update-demo-nautilus-pt4vq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hb8ff'
Sep  2 13:41:22.498: INFO: stderr: ""
Sep  2 13:41:22.498: INFO: stdout: ""
Sep  2 13:41:22.498: INFO: update-demo-nautilus-pt4vq is created but not running
Sep  2 13:41:27.498: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-hb8ff'
Sep  2 13:41:27.568: INFO: stderr: ""
Sep  2 13:41:27.568: INFO: stdout: "update-demo-nautilus-pt4vq update-demo-nautilus-tzg2s "
Sep  2 13:41:27.568: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 get pods update-demo-nautilus-pt4vq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hb8ff'
Sep  2 13:41:27.633: INFO: stderr: ""
Sep  2 13:41:27.633: INFO: stdout: "true"
Sep  2 13:41:27.633: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 get pods update-demo-nautilus-pt4vq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hb8ff'
Sep  2 13:41:27.701: INFO: stderr: ""
Sep  2 13:41:27.701: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  2 13:41:27.701: INFO: validating pod update-demo-nautilus-pt4vq
Sep  2 13:41:27.705: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  2 13:41:27.705: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  2 13:41:27.705: INFO: update-demo-nautilus-pt4vq is verified up and running
Sep  2 13:41:27.705: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 get pods update-demo-nautilus-tzg2s -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hb8ff'
Sep  2 13:41:27.770: INFO: stderr: ""
Sep  2 13:41:27.770: INFO: stdout: "true"
Sep  2 13:41:27.770: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 get pods update-demo-nautilus-tzg2s -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hb8ff'
Sep  2 13:41:27.836: INFO: stderr: ""
Sep  2 13:41:27.836: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  2 13:41:27.836: INFO: validating pod update-demo-nautilus-tzg2s
Sep  2 13:41:27.840: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  2 13:41:27.840: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  2 13:41:27.840: INFO: update-demo-nautilus-tzg2s is verified up and running
STEP: scaling down the replication controller
Sep  2 13:41:27.841: INFO: scanned /root for discovery docs: <nil>
Sep  2 13:41:27.841: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-hb8ff'
Sep  2 13:41:28.934: INFO: stderr: ""
Sep  2 13:41:28.934: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep  2 13:41:28.934: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-hb8ff'
Sep  2 13:41:29.000: INFO: stderr: ""
Sep  2 13:41:29.000: INFO: stdout: "update-demo-nautilus-pt4vq update-demo-nautilus-tzg2s "
STEP: Replicas for name=update-demo: expected=1 actual=2
Sep  2 13:41:34.000: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-hb8ff'
Sep  2 13:41:34.068: INFO: stderr: ""
Sep  2 13:41:34.068: INFO: stdout: "update-demo-nautilus-pt4vq "
Sep  2 13:41:34.068: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 get pods update-demo-nautilus-pt4vq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hb8ff'
Sep  2 13:41:34.134: INFO: stderr: ""
Sep  2 13:41:34.134: INFO: stdout: "true"
Sep  2 13:41:34.134: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 get pods update-demo-nautilus-pt4vq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hb8ff'
Sep  2 13:41:34.196: INFO: stderr: ""
Sep  2 13:41:34.196: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  2 13:41:34.196: INFO: validating pod update-demo-nautilus-pt4vq
Sep  2 13:41:34.199: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  2 13:41:34.199: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  2 13:41:34.199: INFO: update-demo-nautilus-pt4vq is verified up and running
STEP: scaling up the replication controller
Sep  2 13:41:34.200: INFO: scanned /root for discovery docs: <nil>
Sep  2 13:41:34.200: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-hb8ff'
Sep  2 13:41:35.294: INFO: stderr: ""
Sep  2 13:41:35.294: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep  2 13:41:35.294: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-hb8ff'
Sep  2 13:41:35.361: INFO: stderr: ""
Sep  2 13:41:35.361: INFO: stdout: "update-demo-nautilus-pt4vq update-demo-nautilus-tkhmk "
Sep  2 13:41:35.361: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 get pods update-demo-nautilus-pt4vq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hb8ff'
Sep  2 13:41:35.423: INFO: stderr: ""
Sep  2 13:41:35.423: INFO: stdout: "true"
Sep  2 13:41:35.423: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 get pods update-demo-nautilus-pt4vq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hb8ff'
Sep  2 13:41:35.486: INFO: stderr: ""
Sep  2 13:41:35.486: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  2 13:41:35.486: INFO: validating pod update-demo-nautilus-pt4vq
Sep  2 13:41:35.489: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  2 13:41:35.489: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  2 13:41:35.489: INFO: update-demo-nautilus-pt4vq is verified up and running
Sep  2 13:41:35.489: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 get pods update-demo-nautilus-tkhmk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hb8ff'
Sep  2 13:41:35.554: INFO: stderr: ""
Sep  2 13:41:35.554: INFO: stdout: ""
Sep  2 13:41:35.554: INFO: update-demo-nautilus-tkhmk is created but not running
Sep  2 13:41:40.554: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-hb8ff'
Sep  2 13:41:40.622: INFO: stderr: ""
Sep  2 13:41:40.622: INFO: stdout: "update-demo-nautilus-pt4vq update-demo-nautilus-tkhmk "
Sep  2 13:41:40.622: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 get pods update-demo-nautilus-pt4vq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hb8ff'
Sep  2 13:41:40.690: INFO: stderr: ""
Sep  2 13:41:40.690: INFO: stdout: "true"
Sep  2 13:41:40.690: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 get pods update-demo-nautilus-pt4vq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hb8ff'
Sep  2 13:41:40.755: INFO: stderr: ""
Sep  2 13:41:40.755: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  2 13:41:40.755: INFO: validating pod update-demo-nautilus-pt4vq
Sep  2 13:41:40.758: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  2 13:41:40.758: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  2 13:41:40.758: INFO: update-demo-nautilus-pt4vq is verified up and running
Sep  2 13:41:40.758: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 get pods update-demo-nautilus-tkhmk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hb8ff'
Sep  2 13:41:40.823: INFO: stderr: ""
Sep  2 13:41:40.823: INFO: stdout: "true"
Sep  2 13:41:40.823: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 get pods update-demo-nautilus-tkhmk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hb8ff'
Sep  2 13:41:40.885: INFO: stderr: ""
Sep  2 13:41:40.885: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  2 13:41:40.885: INFO: validating pod update-demo-nautilus-tkhmk
Sep  2 13:41:40.889: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  2 13:41:40.889: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  2 13:41:40.889: INFO: update-demo-nautilus-tkhmk is verified up and running
STEP: using delete to clean up resources
Sep  2 13:41:40.889: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-hb8ff'
Sep  2 13:41:40.958: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  2 13:41:40.958: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Sep  2 13:41:40.958: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-hb8ff'
Sep  2 13:41:41.030: INFO: stderr: "No resources found.\n"
Sep  2 13:41:41.030: INFO: stdout: ""
Sep  2 13:41:41.030: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 get pods -l name=update-demo --namespace=e2e-tests-kubectl-hb8ff -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep  2 13:41:41.097: INFO: stderr: ""
Sep  2 13:41:41.097: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:41:41.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hb8ff" for this suite.
Sep  2 13:41:47.119: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:41:47.145: INFO: namespace: e2e-tests-kubectl-hb8ff, resource: bindings, ignored listing per whitelist
Sep  2 13:41:47.216: INFO: namespace e2e-tests-kubectl-hb8ff deletion completed in 6.114178057s

• [SLOW TEST:25.173 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:41:47.217: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-9tvbg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Sep  2 13:41:47.390: INFO: Waiting up to 5m0s for pod "pod-68c9cdb3-cd87-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-emptydir-9tvbg" to be "success or failure"
Sep  2 13:41:47.392: INFO: Pod "pod-68c9cdb3-cd87-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.178166ms
Sep  2 13:41:49.395: INFO: Pod "pod-68c9cdb3-cd87-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005264624s
STEP: Saw pod success
Sep  2 13:41:49.395: INFO: Pod "pod-68c9cdb3-cd87-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 13:41:49.397: INFO: Trying to get logs from node ip-192-168-77-237.us-west-2.compute.internal pod pod-68c9cdb3-cd87-11e9-b90e-8ed318f3d3c6 container test-container: <nil>
STEP: delete the pod
Sep  2 13:41:49.413: INFO: Waiting for pod pod-68c9cdb3-cd87-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 13:41:49.415: INFO: Pod pod-68c9cdb3-cd87-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:41:49.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-9tvbg" for this suite.
Sep  2 13:41:55.434: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:41:55.445: INFO: namespace: e2e-tests-emptydir-9tvbg, resource: bindings, ignored listing per whitelist
Sep  2 13:41:55.531: INFO: namespace e2e-tests-emptydir-9tvbg deletion completed in 6.113176536s

• [SLOW TEST:8.315 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:41:55.532: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-n6w8z
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:41:55.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-n6w8z" for this suite.
Sep  2 13:42:17.720: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:42:17.729: INFO: namespace: e2e-tests-pods-n6w8z, resource: bindings, ignored listing per whitelist
Sep  2 13:42:17.819: INFO: namespace e2e-tests-pods-n6w8z deletion completed in 22.114520635s

• [SLOW TEST:22.287 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:42:17.819: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-t96kc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Sep  2 13:42:17.997: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7b075e4e-cd87-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-downward-api-t96kc" to be "success or failure"
Sep  2 13:42:17.999: INFO: Pod "downwardapi-volume-7b075e4e-cd87-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.550722ms
Sep  2 13:42:20.003: INFO: Pod "downwardapi-volume-7b075e4e-cd87-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006059029s
Sep  2 13:42:22.006: INFO: Pod "downwardapi-volume-7b075e4e-cd87-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009357498s
STEP: Saw pod success
Sep  2 13:42:22.006: INFO: Pod "downwardapi-volume-7b075e4e-cd87-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 13:42:22.009: INFO: Trying to get logs from node ip-192-168-77-237.us-west-2.compute.internal pod downwardapi-volume-7b075e4e-cd87-11e9-b90e-8ed318f3d3c6 container client-container: <nil>
STEP: delete the pod
Sep  2 13:42:22.025: INFO: Waiting for pod downwardapi-volume-7b075e4e-cd87-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 13:42:22.027: INFO: Pod downwardapi-volume-7b075e4e-cd87-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:42:22.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-t96kc" for this suite.
Sep  2 13:42:28.046: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:42:28.127: INFO: namespace: e2e-tests-downward-api-t96kc, resource: bindings, ignored listing per whitelist
Sep  2 13:42:28.144: INFO: namespace e2e-tests-downward-api-t96kc deletion completed in 6.112762686s

• [SLOW TEST:10.325 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:42:28.144: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-zhxdd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Sep  2 13:42:28.315: INFO: Waiting up to 5m0s for pod "downwardapi-volume-812e8783-cd87-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-projected-zhxdd" to be "success or failure"
Sep  2 13:42:28.317: INFO: Pod "downwardapi-volume-812e8783-cd87-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.265062ms
Sep  2 13:42:30.321: INFO: Pod "downwardapi-volume-812e8783-cd87-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005588721s
STEP: Saw pod success
Sep  2 13:42:30.321: INFO: Pod "downwardapi-volume-812e8783-cd87-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 13:42:30.323: INFO: Trying to get logs from node ip-192-168-185-95.us-west-2.compute.internal pod downwardapi-volume-812e8783-cd87-11e9-b90e-8ed318f3d3c6 container client-container: <nil>
STEP: delete the pod
Sep  2 13:42:30.344: INFO: Waiting for pod downwardapi-volume-812e8783-cd87-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 13:42:30.347: INFO: Pod downwardapi-volume-812e8783-cd87-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:42:30.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zhxdd" for this suite.
Sep  2 13:42:36.366: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:42:36.464: INFO: namespace: e2e-tests-projected-zhxdd, resource: bindings, ignored listing per whitelist
Sep  2 13:42:36.464: INFO: namespace e2e-tests-projected-zhxdd deletion completed in 6.113467631s

• [SLOW TEST:8.320 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:42:36.464: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-fxckz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Sep  2 13:42:38.652: INFO: Waiting up to 5m0s for pod "client-envvars-87581ffd-cd87-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-pods-fxckz" to be "success or failure"
Sep  2 13:42:38.655: INFO: Pod "client-envvars-87581ffd-cd87-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.268174ms
Sep  2 13:42:40.658: INFO: Pod "client-envvars-87581ffd-cd87-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00539664s
STEP: Saw pod success
Sep  2 13:42:40.658: INFO: Pod "client-envvars-87581ffd-cd87-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 13:42:40.660: INFO: Trying to get logs from node ip-192-168-185-95.us-west-2.compute.internal pod client-envvars-87581ffd-cd87-11e9-b90e-8ed318f3d3c6 container env3cont: <nil>
STEP: delete the pod
Sep  2 13:42:40.677: INFO: Waiting for pod client-envvars-87581ffd-cd87-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 13:42:40.680: INFO: Pod client-envvars-87581ffd-cd87-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:42:40.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-fxckz" for this suite.
Sep  2 13:43:18.700: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:43:18.799: INFO: namespace: e2e-tests-pods-fxckz, resource: bindings, ignored listing per whitelist
Sep  2 13:43:18.806: INFO: namespace e2e-tests-pods-fxckz deletion completed in 38.121123221s

• [SLOW TEST:42.342 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:43:18.806: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-4fwsc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-9f60f668-cd87-11e9-b90e-8ed318f3d3c6
STEP: Creating a pod to test consume configMaps
Sep  2 13:43:18.981: INFO: Waiting up to 5m0s for pod "pod-configmaps-9f6171c6-cd87-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-configmap-4fwsc" to be "success or failure"
Sep  2 13:43:18.983: INFO: Pod "pod-configmaps-9f6171c6-cd87-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.244514ms
Sep  2 13:43:20.986: INFO: Pod "pod-configmaps-9f6171c6-cd87-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005296941s
Sep  2 13:43:22.990: INFO: Pod "pod-configmaps-9f6171c6-cd87-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008560738s
STEP: Saw pod success
Sep  2 13:43:22.990: INFO: Pod "pod-configmaps-9f6171c6-cd87-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 13:43:22.992: INFO: Trying to get logs from node ip-192-168-77-237.us-west-2.compute.internal pod pod-configmaps-9f6171c6-cd87-11e9-b90e-8ed318f3d3c6 container configmap-volume-test: <nil>
STEP: delete the pod
Sep  2 13:43:23.009: INFO: Waiting for pod pod-configmaps-9f6171c6-cd87-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 13:43:23.011: INFO: Pod pod-configmaps-9f6171c6-cd87-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:43:23.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-4fwsc" for this suite.
Sep  2 13:43:29.036: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:43:29.054: INFO: namespace: e2e-tests-configmap-4fwsc, resource: bindings, ignored listing per whitelist
Sep  2 13:43:29.132: INFO: namespace e2e-tests-configmap-4fwsc deletion completed in 6.117359519s

• [SLOW TEST:10.327 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:43:29.133: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-fq6g8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Sep  2 13:43:29.305: INFO: Waiting up to 5m0s for pod "downward-api-a588a3a0-cd87-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-downward-api-fq6g8" to be "success or failure"
Sep  2 13:43:29.307: INFO: Pod "downward-api-a588a3a0-cd87-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.518905ms
Sep  2 13:43:31.311: INFO: Pod "downward-api-a588a3a0-cd87-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005749483s
STEP: Saw pod success
Sep  2 13:43:31.311: INFO: Pod "downward-api-a588a3a0-cd87-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 13:43:31.313: INFO: Trying to get logs from node ip-192-168-185-95.us-west-2.compute.internal pod downward-api-a588a3a0-cd87-11e9-b90e-8ed318f3d3c6 container dapi-container: <nil>
STEP: delete the pod
Sep  2 13:43:31.333: INFO: Waiting for pod downward-api-a588a3a0-cd87-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 13:43:31.335: INFO: Pod downward-api-a588a3a0-cd87-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:43:31.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-fq6g8" for this suite.
Sep  2 13:43:37.355: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:43:37.371: INFO: namespace: e2e-tests-downward-api-fq6g8, resource: bindings, ignored listing per whitelist
Sep  2 13:43:37.453: INFO: namespace e2e-tests-downward-api-fq6g8 deletion completed in 6.113895982s

• [SLOW TEST:8.320 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:43:37.453: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-w5m7s
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Sep  2 13:43:37.617: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Sep  2 13:43:37.623: INFO: Pod name sample-pod: Found 0 pods out of 1
Sep  2 13:43:42.631: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep  2 13:43:42.631: INFO: Creating deployment "test-rolling-update-deployment"
Sep  2 13:43:42.636: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Sep  2 13:43:42.640: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Sep  2 13:43:44.645: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Sep  2 13:43:44.648: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Sep  2 13:43:44.654: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-w5m7s,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-w5m7s/deployments/test-rolling-update-deployment,UID:ad7b455d-cd87-11e9-a575-0a854009c708,ResourceVersion:2094295,Generation:1,CreationTimestamp:2019-09-02 13:43:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-09-02 13:43:42 +0000 UTC 2019-09-02 13:43:42 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-09-02 13:43:44 +0000 UTC 2019-09-02 13:43:42 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-68b55d7bc6" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Sep  2 13:43:44.657: INFO: New ReplicaSet "test-rolling-update-deployment-68b55d7bc6" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6,GenerateName:,Namespace:e2e-tests-deployment-w5m7s,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-w5m7s/replicasets/test-rolling-update-deployment-68b55d7bc6,UID:ad7e5192-cd87-11e9-96cb-060c8a2202ce,ResourceVersion:2094286,Generation:1,CreationTimestamp:2019-09-02 13:43:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment ad7b455d-cd87-11e9-a575-0a854009c708 0xc0019f12b7 0xc0019f12b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Sep  2 13:43:44.657: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Sep  2 13:43:44.657: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-w5m7s,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-w5m7s/replicasets/test-rolling-update-controller,UID:aa7e170a-cd87-11e9-a575-0a854009c708,ResourceVersion:2094294,Generation:2,CreationTimestamp:2019-09-02 13:43:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment ad7b455d-cd87-11e9-a575-0a854009c708 0xc0019f1067 0xc0019f1068}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep  2 13:43:44.659: INFO: Pod "test-rolling-update-deployment-68b55d7bc6-6gkj7" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6-6gkj7,GenerateName:test-rolling-update-deployment-68b55d7bc6-,Namespace:e2e-tests-deployment-w5m7s,SelfLink:/api/v1/namespaces/e2e-tests-deployment-w5m7s/pods/test-rolling-update-deployment-68b55d7bc6-6gkj7,UID:ad7f06e0-cd87-11e9-96cb-060c8a2202ce,ResourceVersion:2094285,Generation:0,CreationTimestamp:2019-09-02 13:43:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-68b55d7bc6 ad7e5192-cd87-11e9-96cb-060c8a2202ce 0xc0019f1ce7 0xc0019f1ce8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ndpp4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ndpp4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-ndpp4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-192-168-185-95.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0019f1d50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0019f1d70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:43:42 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:43:44 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:43:44 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:43:42 +0000 UTC  }],Message:,Reason:,HostIP:192.168.185.95,PodIP:192.168.183.109,StartTime:2019-09-02 13:43:42 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-09-02 13:43:43 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://8148f55f813387639c9b239d32cf2937b69079a4a459379eee0d502357b93af5}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:43:44.660: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-w5m7s" for this suite.
Sep  2 13:43:50.679: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:43:50.766: INFO: namespace: e2e-tests-deployment-w5m7s, resource: bindings, ignored listing per whitelist
Sep  2 13:43:50.777: INFO: namespace e2e-tests-deployment-w5m7s deletion completed in 6.114294443s

• [SLOW TEST:13.324 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:43:50.777: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-8h7wr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Sep  2 13:43:50.947: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 api-versions'
Sep  2 13:43:51.011: INFO: stderr: ""
Sep  2 13:43:51.011: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\ncrd.k8s.amazonaws.com/v1alpha1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:43:51.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-8h7wr" for this suite.
Sep  2 13:43:57.030: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:43:57.081: INFO: namespace: e2e-tests-kubectl-8h7wr, resource: bindings, ignored listing per whitelist
Sep  2 13:43:57.127: INFO: namespace e2e-tests-kubectl-8h7wr deletion completed in 6.112489239s

• [SLOW TEST:6.350 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:43:57.127: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-xdsrx
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Sep  2 13:43:57.296: INFO: Waiting up to 5m0s for pod "pod-b637e4e9-cd87-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-emptydir-xdsrx" to be "success or failure"
Sep  2 13:43:57.298: INFO: Pod "pod-b637e4e9-cd87-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.183046ms
Sep  2 13:43:59.301: INFO: Pod "pod-b637e4e9-cd87-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00534059s
STEP: Saw pod success
Sep  2 13:43:59.301: INFO: Pod "pod-b637e4e9-cd87-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 13:43:59.304: INFO: Trying to get logs from node ip-192-168-77-237.us-west-2.compute.internal pod pod-b637e4e9-cd87-11e9-b90e-8ed318f3d3c6 container test-container: <nil>
STEP: delete the pod
Sep  2 13:43:59.320: INFO: Waiting for pod pod-b637e4e9-cd87-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 13:43:59.322: INFO: Pod pod-b637e4e9-cd87-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:43:59.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-xdsrx" for this suite.
Sep  2 13:44:05.345: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:44:05.411: INFO: namespace: e2e-tests-emptydir-xdsrx, resource: bindings, ignored listing per whitelist
Sep  2 13:44:05.446: INFO: namespace e2e-tests-emptydir-xdsrx deletion completed in 6.119069991s

• [SLOW TEST:8.319 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:44:05.446: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-2s5lv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:44:09.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-2s5lv" for this suite.
Sep  2 13:44:55.655: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:44:55.718: INFO: namespace: e2e-tests-kubelet-test-2s5lv, resource: bindings, ignored listing per whitelist
Sep  2 13:44:55.752: INFO: namespace e2e-tests-kubelet-test-2s5lv deletion completed in 46.113676503s

• [SLOW TEST:50.306 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:44:55.753: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-mjn5c
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-d929f064-cd87-11e9-b90e-8ed318f3d3c6
STEP: Creating a pod to test consume configMaps
Sep  2 13:44:55.930: INFO: Waiting up to 5m0s for pod "pod-configmaps-d92a9227-cd87-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-configmap-mjn5c" to be "success or failure"
Sep  2 13:44:55.932: INFO: Pod "pod-configmaps-d92a9227-cd87-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.224535ms
Sep  2 13:44:57.935: INFO: Pod "pod-configmaps-d92a9227-cd87-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00553968s
STEP: Saw pod success
Sep  2 13:44:57.935: INFO: Pod "pod-configmaps-d92a9227-cd87-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 13:44:57.938: INFO: Trying to get logs from node ip-192-168-77-237.us-west-2.compute.internal pod pod-configmaps-d92a9227-cd87-11e9-b90e-8ed318f3d3c6 container configmap-volume-test: <nil>
STEP: delete the pod
Sep  2 13:44:57.954: INFO: Waiting for pod pod-configmaps-d92a9227-cd87-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 13:44:57.957: INFO: Pod pod-configmaps-d92a9227-cd87-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:44:57.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-mjn5c" for this suite.
Sep  2 13:45:03.976: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:45:04.044: INFO: namespace: e2e-tests-configmap-mjn5c, resource: bindings, ignored listing per whitelist
Sep  2 13:45:04.081: INFO: namespace e2e-tests-configmap-mjn5c deletion completed in 6.121350166s

• [SLOW TEST:8.329 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:45:04.082: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-dckb7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Sep  2 13:45:04.243: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep  2 13:45:04.250: INFO: Waiting for terminating namespaces to be deleted...
Sep  2 13:45:04.254: INFO: 
Logging pods the kubelet thinks is on node ip-192-168-185-95.us-west-2.compute.internal before test
Sep  2 13:45:04.258: INFO: kube-proxy-w76hj from kube-system started at 2019-09-02 12:25:13 +0000 UTC (1 container statuses recorded)
Sep  2 13:45:04.258: INFO: 	Container kube-proxy ready: true, restart count 0
Sep  2 13:45:04.258: INFO: sonobuoy-systemd-logs-daemon-set-f7d9f222843a4872-xv7pn from heptio-sonobuoy started at 2019-09-02 13:08:20 +0000 UTC (2 container statuses recorded)
Sep  2 13:45:04.258: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep  2 13:45:04.258: INFO: 	Container systemd-logs ready: true, restart count 0
Sep  2 13:45:04.258: INFO: aws-node-h72bs from kube-system started at 2019-09-02 12:25:13 +0000 UTC (1 container statuses recorded)
Sep  2 13:45:04.258: INFO: 	Container aws-node ready: true, restart count 0
Sep  2 13:45:04.258: INFO: 
Logging pods the kubelet thinks is on node ip-192-168-55-191.us-west-2.compute.internal before test
Sep  2 13:45:04.263: INFO: coredns-79d667b89f-fbrdn from kube-system started at 2019-09-02 07:27:30 +0000 UTC (1 container statuses recorded)
Sep  2 13:45:04.263: INFO: 	Container coredns ready: true, restart count 0
Sep  2 13:45:04.263: INFO: sonobuoy-systemd-logs-daemon-set-f7d9f222843a4872-4p5pk from heptio-sonobuoy started at 2019-09-02 13:08:20 +0000 UTC (2 container statuses recorded)
Sep  2 13:45:04.263: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep  2 13:45:04.263: INFO: 	Container systemd-logs ready: true, restart count 0
Sep  2 13:45:04.263: INFO: aws-node-cssxg from kube-system started at 2019-09-02 07:20:24 +0000 UTC (1 container statuses recorded)
Sep  2 13:45:04.263: INFO: 	Container aws-node ready: true, restart count 0
Sep  2 13:45:04.263: INFO: kube-proxy-gpz5v from kube-system started at 2019-09-02 07:20:24 +0000 UTC (1 container statuses recorded)
Sep  2 13:45:04.263: INFO: 	Container kube-proxy ready: true, restart count 0
Sep  2 13:45:04.263: INFO: 
Logging pods the kubelet thinks is on node ip-192-168-6-156.us-west-2.compute.internal before test
Sep  2 13:45:04.267: INFO: aws-node-d25qt from kube-system started at 2019-09-02 07:28:57 +0000 UTC (1 container statuses recorded)
Sep  2 13:45:04.267: INFO: 	Container aws-node ready: true, restart count 0
Sep  2 13:45:04.267: INFO: sonobuoy-systemd-logs-daemon-set-f7d9f222843a4872-hppz8 from heptio-sonobuoy started at 2019-09-02 13:08:20 +0000 UTC (2 container statuses recorded)
Sep  2 13:45:04.267: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep  2 13:45:04.267: INFO: 	Container systemd-logs ready: true, restart count 0
Sep  2 13:45:04.267: INFO: kube-proxy-wvzsh from kube-system started at 2019-09-02 07:28:57 +0000 UTC (1 container statuses recorded)
Sep  2 13:45:04.267: INFO: 	Container kube-proxy ready: true, restart count 0
Sep  2 13:45:04.267: INFO: sonobuoy from heptio-sonobuoy started at 2019-09-02 13:08:19 +0000 UTC (1 container statuses recorded)
Sep  2 13:45:04.267: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep  2 13:45:04.267: INFO: 
Logging pods the kubelet thinks is on node ip-192-168-77-237.us-west-2.compute.internal before test
Sep  2 13:45:04.272: INFO: kube-proxy-84977 from kube-system started at 2019-09-02 07:35:32 +0000 UTC (1 container statuses recorded)
Sep  2 13:45:04.272: INFO: 	Container kube-proxy ready: true, restart count 0
Sep  2 13:45:04.272: INFO: spotinst-kubernetes-cluster-controller-5456664d9b-ljj66 from kube-system started at 2019-09-02 10:12:33 +0000 UTC (1 container statuses recorded)
Sep  2 13:45:04.272: INFO: 	Container spotinst-kubernetes-cluster-controller ready: true, restart count 0
Sep  2 13:45:04.272: INFO: sonobuoy-systemd-logs-daemon-set-f7d9f222843a4872-7g5md from heptio-sonobuoy started at 2019-09-02 13:08:20 +0000 UTC (2 container statuses recorded)
Sep  2 13:45:04.272: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep  2 13:45:04.272: INFO: 	Container systemd-logs ready: true, restart count 0
Sep  2 13:45:04.272: INFO: coredns-79d667b89f-thvvk from kube-system started at 2019-09-02 10:12:03 +0000 UTC (1 container statuses recorded)
Sep  2 13:45:04.272: INFO: 	Container coredns ready: true, restart count 0
Sep  2 13:45:04.272: INFO: sonobuoy-e2e-job-1216ef12ccbc49ed from heptio-sonobuoy started at 2019-09-02 13:08:20 +0000 UTC (2 container statuses recorded)
Sep  2 13:45:04.272: INFO: 	Container e2e ready: true, restart count 0
Sep  2 13:45:04.272: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep  2 13:45:04.272: INFO: aws-node-zh7fs from kube-system started at 2019-09-02 07:35:32 +0000 UTC (1 container statuses recorded)
Sep  2 13:45:04.272: INFO: 	Container aws-node ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node ip-192-168-185-95.us-west-2.compute.internal
STEP: verifying the node has the label node ip-192-168-55-191.us-west-2.compute.internal
STEP: verifying the node has the label node ip-192-168-6-156.us-west-2.compute.internal
STEP: verifying the node has the label node ip-192-168-77-237.us-west-2.compute.internal
Sep  2 13:45:04.313: INFO: Pod sonobuoy requesting resource cpu=0m on Node ip-192-168-6-156.us-west-2.compute.internal
Sep  2 13:45:04.313: INFO: Pod sonobuoy-e2e-job-1216ef12ccbc49ed requesting resource cpu=0m on Node ip-192-168-77-237.us-west-2.compute.internal
Sep  2 13:45:04.313: INFO: Pod sonobuoy-systemd-logs-daemon-set-f7d9f222843a4872-4p5pk requesting resource cpu=0m on Node ip-192-168-55-191.us-west-2.compute.internal
Sep  2 13:45:04.313: INFO: Pod sonobuoy-systemd-logs-daemon-set-f7d9f222843a4872-7g5md requesting resource cpu=0m on Node ip-192-168-77-237.us-west-2.compute.internal
Sep  2 13:45:04.314: INFO: Pod sonobuoy-systemd-logs-daemon-set-f7d9f222843a4872-hppz8 requesting resource cpu=0m on Node ip-192-168-6-156.us-west-2.compute.internal
Sep  2 13:45:04.314: INFO: Pod sonobuoy-systemd-logs-daemon-set-f7d9f222843a4872-xv7pn requesting resource cpu=0m on Node ip-192-168-185-95.us-west-2.compute.internal
Sep  2 13:45:04.314: INFO: Pod aws-node-cssxg requesting resource cpu=10m on Node ip-192-168-55-191.us-west-2.compute.internal
Sep  2 13:45:04.314: INFO: Pod aws-node-d25qt requesting resource cpu=10m on Node ip-192-168-6-156.us-west-2.compute.internal
Sep  2 13:45:04.314: INFO: Pod aws-node-h72bs requesting resource cpu=10m on Node ip-192-168-185-95.us-west-2.compute.internal
Sep  2 13:45:04.314: INFO: Pod aws-node-zh7fs requesting resource cpu=10m on Node ip-192-168-77-237.us-west-2.compute.internal
Sep  2 13:45:04.314: INFO: Pod coredns-79d667b89f-fbrdn requesting resource cpu=100m on Node ip-192-168-55-191.us-west-2.compute.internal
Sep  2 13:45:04.314: INFO: Pod coredns-79d667b89f-thvvk requesting resource cpu=100m on Node ip-192-168-77-237.us-west-2.compute.internal
Sep  2 13:45:04.314: INFO: Pod kube-proxy-84977 requesting resource cpu=100m on Node ip-192-168-77-237.us-west-2.compute.internal
Sep  2 13:45:04.314: INFO: Pod kube-proxy-gpz5v requesting resource cpu=100m on Node ip-192-168-55-191.us-west-2.compute.internal
Sep  2 13:45:04.314: INFO: Pod kube-proxy-w76hj requesting resource cpu=100m on Node ip-192-168-185-95.us-west-2.compute.internal
Sep  2 13:45:04.314: INFO: Pod kube-proxy-wvzsh requesting resource cpu=100m on Node ip-192-168-6-156.us-west-2.compute.internal
Sep  2 13:45:04.314: INFO: Pod spotinst-kubernetes-cluster-controller-5456664d9b-ljj66 requesting resource cpu=0m on Node ip-192-168-77-237.us-west-2.compute.internal
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-de2add66-cd87-11e9-b90e-8ed318f3d3c6.15c0a3032afed3c1], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-dckb7/filler-pod-de2add66-cd87-11e9-b90e-8ed318f3d3c6 to ip-192-168-185-95.us-west-2.compute.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-de2add66-cd87-11e9-b90e-8ed318f3d3c6.15c0a303708be16e], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-de2add66-cd87-11e9-b90e-8ed318f3d3c6.15c0a303736f9c5b], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-de2add66-cd87-11e9-b90e-8ed318f3d3c6.15c0a3037cbeb983], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-de2bbc63-cd87-11e9-b90e-8ed318f3d3c6.15c0a3032b1c668d], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-dckb7/filler-pod-de2bbc63-cd87-11e9-b90e-8ed318f3d3c6 to ip-192-168-55-191.us-west-2.compute.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-de2bbc63-cd87-11e9-b90e-8ed318f3d3c6.15c0a3037a576376], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-de2bbc63-cd87-11e9-b90e-8ed318f3d3c6.15c0a3037ce6f7c4], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-de2bbc63-cd87-11e9-b90e-8ed318f3d3c6.15c0a3038623f3fa], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-de2ca095-cd87-11e9-b90e-8ed318f3d3c6.15c0a3032b71251a], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-dckb7/filler-pod-de2ca095-cd87-11e9-b90e-8ed318f3d3c6 to ip-192-168-6-156.us-west-2.compute.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-de2ca095-cd87-11e9-b90e-8ed318f3d3c6.15c0a3038386b2e0], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-de2ca095-cd87-11e9-b90e-8ed318f3d3c6.15c0a303a50354c2], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-de2ca095-cd87-11e9-b90e-8ed318f3d3c6.15c0a303add5c149], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-de2d7ede-cd87-11e9-b90e-8ed318f3d3c6.15c0a3032be35a27], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-dckb7/filler-pod-de2d7ede-cd87-11e9-b90e-8ed318f3d3c6 to ip-192-168-77-237.us-west-2.compute.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-de2d7ede-cd87-11e9-b90e-8ed318f3d3c6.15c0a3035b55bd92], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-de2d7ede-cd87-11e9-b90e-8ed318f3d3c6.15c0a3035ebfe723], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-de2d7ede-cd87-11e9-b90e-8ed318f3d3c6.15c0a30367c76b08], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15c0a3041b718f95], Reason = [FailedScheduling], Message = [0/4 nodes are available: 4 Insufficient cpu.]
STEP: removing the label node off the node ip-192-168-185-95.us-west-2.compute.internal
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node ip-192-168-55-191.us-west-2.compute.internal
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node ip-192-168-6-156.us-west-2.compute.internal
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node ip-192-168-77-237.us-west-2.compute.internal
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:45:09.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-dckb7" for this suite.
Sep  2 13:45:15.422: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:45:15.493: INFO: namespace: e2e-tests-sched-pred-dckb7, resource: bindings, ignored listing per whitelist
Sep  2 13:45:15.519: INFO: namespace e2e-tests-sched-pred-dckb7 deletion completed in 6.112230646s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:11.437 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:45:15.519: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-m4s9p
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Sep  2 13:45:15.692: INFO: Waiting up to 5m0s for pod "downward-api-e4f1fdf0-cd87-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-downward-api-m4s9p" to be "success or failure"
Sep  2 13:45:15.695: INFO: Pod "downward-api-e4f1fdf0-cd87-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.301366ms
Sep  2 13:45:17.698: INFO: Pod "downward-api-e4f1fdf0-cd87-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005819271s
Sep  2 13:45:19.702: INFO: Pod "downward-api-e4f1fdf0-cd87-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009254629s
STEP: Saw pod success
Sep  2 13:45:19.702: INFO: Pod "downward-api-e4f1fdf0-cd87-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 13:45:19.704: INFO: Trying to get logs from node ip-192-168-77-237.us-west-2.compute.internal pod downward-api-e4f1fdf0-cd87-11e9-b90e-8ed318f3d3c6 container dapi-container: <nil>
STEP: delete the pod
Sep  2 13:45:19.721: INFO: Waiting for pod downward-api-e4f1fdf0-cd87-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 13:45:19.724: INFO: Pod downward-api-e4f1fdf0-cd87-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:45:19.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-m4s9p" for this suite.
Sep  2 13:45:25.744: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:45:25.752: INFO: namespace: e2e-tests-downward-api-m4s9p, resource: bindings, ignored listing per whitelist
Sep  2 13:45:25.848: INFO: namespace e2e-tests-downward-api-m4s9p deletion completed in 6.120268874s

• [SLOW TEST:10.329 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:45:25.848: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-lnnqn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-lnnqn/configmap-test-eb1a150e-cd87-11e9-b90e-8ed318f3d3c6
STEP: Creating a pod to test consume configMaps
Sep  2 13:45:26.023: INFO: Waiting up to 5m0s for pod "pod-configmaps-eb1a9099-cd87-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-configmap-lnnqn" to be "success or failure"
Sep  2 13:45:26.025: INFO: Pod "pod-configmaps-eb1a9099-cd87-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.230994ms
Sep  2 13:45:28.028: INFO: Pod "pod-configmaps-eb1a9099-cd87-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00536505s
STEP: Saw pod success
Sep  2 13:45:28.028: INFO: Pod "pod-configmaps-eb1a9099-cd87-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 13:45:28.031: INFO: Trying to get logs from node ip-192-168-77-237.us-west-2.compute.internal pod pod-configmaps-eb1a9099-cd87-11e9-b90e-8ed318f3d3c6 container env-test: <nil>
STEP: delete the pod
Sep  2 13:45:28.046: INFO: Waiting for pod pod-configmaps-eb1a9099-cd87-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 13:45:28.048: INFO: Pod pod-configmaps-eb1a9099-cd87-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:45:28.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-lnnqn" for this suite.
Sep  2 13:45:34.067: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:45:34.074: INFO: namespace: e2e-tests-configmap-lnnqn, resource: bindings, ignored listing per whitelist
Sep  2 13:45:34.167: INFO: namespace e2e-tests-configmap-lnnqn deletion completed in 6.115161357s

• [SLOW TEST:8.319 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:45:34.167: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-e2e-kubelet-etc-hosts-zz7j7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Sep  2 13:45:40.357: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-zz7j7 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  2 13:45:40.357: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
Sep  2 13:45:40.439: INFO: Exec stderr: ""
Sep  2 13:45:40.439: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-zz7j7 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  2 13:45:40.439: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
Sep  2 13:45:40.526: INFO: Exec stderr: ""
Sep  2 13:45:40.526: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-zz7j7 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  2 13:45:40.526: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
Sep  2 13:45:40.607: INFO: Exec stderr: ""
Sep  2 13:45:40.607: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-zz7j7 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  2 13:45:40.607: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
Sep  2 13:45:40.687: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Sep  2 13:45:40.687: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-zz7j7 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  2 13:45:40.687: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
Sep  2 13:45:40.777: INFO: Exec stderr: ""
Sep  2 13:45:40.777: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-zz7j7 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  2 13:45:40.777: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
Sep  2 13:45:40.860: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Sep  2 13:45:40.860: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-zz7j7 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  2 13:45:40.860: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
Sep  2 13:45:40.960: INFO: Exec stderr: ""
Sep  2 13:45:40.960: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-zz7j7 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  2 13:45:40.960: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
Sep  2 13:45:41.050: INFO: Exec stderr: ""
Sep  2 13:45:41.051: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-zz7j7 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  2 13:45:41.051: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
Sep  2 13:45:41.139: INFO: Exec stderr: ""
Sep  2 13:45:41.139: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-zz7j7 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  2 13:45:41.139: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
Sep  2 13:45:41.224: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:45:41.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-zz7j7" for this suite.
Sep  2 13:46:27.245: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:46:27.338: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-zz7j7, resource: bindings, ignored listing per whitelist
Sep  2 13:46:27.341: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-zz7j7 deletion completed in 46.113579192s

• [SLOW TEST:53.174 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:46:27.342: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-g4pmh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Sep  2 13:46:27.517: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0fc1b352-cd88-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-downward-api-g4pmh" to be "success or failure"
Sep  2 13:46:27.520: INFO: Pod "downwardapi-volume-0fc1b352-cd88-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.365811ms
Sep  2 13:46:29.529: INFO: Pod "downwardapi-volume-0fc1b352-cd88-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011688648s
Sep  2 13:46:31.532: INFO: Pod "downwardapi-volume-0fc1b352-cd88-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014934079s
STEP: Saw pod success
Sep  2 13:46:31.532: INFO: Pod "downwardapi-volume-0fc1b352-cd88-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 13:46:31.535: INFO: Trying to get logs from node ip-192-168-77-237.us-west-2.compute.internal pod downwardapi-volume-0fc1b352-cd88-11e9-b90e-8ed318f3d3c6 container client-container: <nil>
STEP: delete the pod
Sep  2 13:46:31.553: INFO: Waiting for pod downwardapi-volume-0fc1b352-cd88-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 13:46:31.556: INFO: Pod downwardapi-volume-0fc1b352-cd88-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:46:31.556: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
Sep  2 13:46:31.559: INFO: Condition Ready of node ip-192-168-169-21.us-west-2.compute.internal is false, but Node is tainted by NodeController with [{node.kubernetes.io/not-ready  NoSchedule <nil>} {node.kubernetes.io/not-ready  NoExecute 2019-09-02 13:46:18 +0000 UTC}]. Failure
Sep  2 13:46:33.563: INFO: Condition Ready of node ip-192-168-169-21.us-west-2.compute.internal is false, but Node is tainted by NodeController with [{node.kubernetes.io/not-ready  NoSchedule <nil>} {node.kubernetes.io/not-ready  NoExecute 2019-09-02 13:46:18 +0000 UTC}]. Failure
Sep  2 13:46:35.564: INFO: Condition Ready of node ip-192-168-169-21.us-west-2.compute.internal is false, but Node is tainted by NodeController with [{node.kubernetes.io/not-ready  NoSchedule <nil>} {node.kubernetes.io/not-ready  NoExecute 2019-09-02 13:46:18 +0000 UTC}]. Failure
Sep  2 13:46:37.564: INFO: Condition Ready of node ip-192-168-169-21.us-west-2.compute.internal is false, but Node is tainted by NodeController with [{node.kubernetes.io/not-ready  NoSchedule <nil>} {node.kubernetes.io/not-ready  NoExecute 2019-09-02 13:46:18 +0000 UTC}]. Failure
Sep  2 13:46:39.570: INFO: Condition Ready of node ip-192-168-169-21.us-west-2.compute.internal is true, but Node is tainted by NodeController with [{node.kubernetes.io/not-ready  NoExecute 2019-09-02 13:46:18 +0000 UTC}]. Failure
STEP: Destroying namespace "e2e-tests-downward-api-g4pmh" for this suite.
Sep  2 13:46:47.580: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:46:47.642: INFO: namespace: e2e-tests-downward-api-g4pmh, resource: bindings, ignored listing per whitelist
Sep  2 13:46:47.677: INFO: namespace e2e-tests-downward-api-g4pmh deletion completed in 6.112902276s

• [SLOW TEST:20.335 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:46:47.677: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-h5t8w
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Sep  2 13:46:47.850: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1be02bfc-cd88-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-projected-h5t8w" to be "success or failure"
Sep  2 13:46:47.852: INFO: Pod "downwardapi-volume-1be02bfc-cd88-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.400045ms
Sep  2 13:46:49.861: INFO: Pod "downwardapi-volume-1be02bfc-cd88-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011033356s
STEP: Saw pod success
Sep  2 13:46:49.861: INFO: Pod "downwardapi-volume-1be02bfc-cd88-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 13:46:49.863: INFO: Trying to get logs from node ip-192-168-77-237.us-west-2.compute.internal pod downwardapi-volume-1be02bfc-cd88-11e9-b90e-8ed318f3d3c6 container client-container: <nil>
STEP: delete the pod
Sep  2 13:46:49.879: INFO: Waiting for pod downwardapi-volume-1be02bfc-cd88-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 13:46:49.881: INFO: Pod downwardapi-volume-1be02bfc-cd88-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:46:49.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-h5t8w" for this suite.
Sep  2 13:46:55.902: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:46:55.985: INFO: namespace: e2e-tests-projected-h5t8w, resource: bindings, ignored listing per whitelist
Sep  2 13:46:56.001: INFO: namespace e2e-tests-projected-h5t8w deletion completed in 6.116249192s

• [SLOW TEST:8.324 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:46:56.001: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-xq4pd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-20d58e74-cd88-11e9-b90e-8ed318f3d3c6
STEP: Creating a pod to test consume configMaps
Sep  2 13:46:56.171: INFO: Waiting up to 5m0s for pod "pod-configmaps-20d62170-cd88-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-configmap-xq4pd" to be "success or failure"
Sep  2 13:46:56.174: INFO: Pod "pod-configmaps-20d62170-cd88-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.361745ms
Sep  2 13:46:58.177: INFO: Pod "pod-configmaps-20d62170-cd88-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00556123s
Sep  2 13:47:00.186: INFO: Pod "pod-configmaps-20d62170-cd88-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014558839s
STEP: Saw pod success
Sep  2 13:47:00.186: INFO: Pod "pod-configmaps-20d62170-cd88-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 13:47:00.188: INFO: Trying to get logs from node ip-192-168-169-21.us-west-2.compute.internal pod pod-configmaps-20d62170-cd88-11e9-b90e-8ed318f3d3c6 container configmap-volume-test: <nil>
STEP: delete the pod
Sep  2 13:47:00.210: INFO: Waiting for pod pod-configmaps-20d62170-cd88-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 13:47:00.212: INFO: Pod pod-configmaps-20d62170-cd88-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:47:00.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-xq4pd" for this suite.
Sep  2 13:47:06.233: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:47:06.271: INFO: namespace: e2e-tests-configmap-xq4pd, resource: bindings, ignored listing per whitelist
Sep  2 13:47:06.330: INFO: namespace e2e-tests-configmap-xq4pd deletion completed in 6.114152405s

• [SLOW TEST:10.329 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:47:06.331: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-8sptv
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-26fec38f-cd88-11e9-b90e-8ed318f3d3c6
STEP: Creating a pod to test consume configMaps
Sep  2 13:47:06.508: INFO: Waiting up to 5m0s for pod "pod-configmaps-26ff3ae6-cd88-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-configmap-8sptv" to be "success or failure"
Sep  2 13:47:06.511: INFO: Pod "pod-configmaps-26ff3ae6-cd88-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.644449ms
Sep  2 13:47:08.514: INFO: Pod "pod-configmaps-26ff3ae6-cd88-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005956007s
STEP: Saw pod success
Sep  2 13:47:08.514: INFO: Pod "pod-configmaps-26ff3ae6-cd88-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 13:47:08.517: INFO: Trying to get logs from node ip-192-168-169-21.us-west-2.compute.internal pod pod-configmaps-26ff3ae6-cd88-11e9-b90e-8ed318f3d3c6 container configmap-volume-test: <nil>
STEP: delete the pod
Sep  2 13:47:08.534: INFO: Waiting for pod pod-configmaps-26ff3ae6-cd88-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 13:47:08.536: INFO: Pod pod-configmaps-26ff3ae6-cd88-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:47:08.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-8sptv" for this suite.
Sep  2 13:47:14.556: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:47:14.637: INFO: namespace: e2e-tests-configmap-8sptv, resource: bindings, ignored listing per whitelist
Sep  2 13:47:14.653: INFO: namespace e2e-tests-configmap-8sptv deletion completed in 6.112708165s

• [SLOW TEST:8.322 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:47:14.653: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-8wn4s
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Sep  2 13:47:14.819: INFO: Waiting up to 5m0s for pod "var-expansion-2bf383eb-cd88-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-var-expansion-8wn4s" to be "success or failure"
Sep  2 13:47:14.821: INFO: Pod "var-expansion-2bf383eb-cd88-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.306587ms
Sep  2 13:47:16.825: INFO: Pod "var-expansion-2bf383eb-cd88-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005530907s
Sep  2 13:47:18.828: INFO: Pod "var-expansion-2bf383eb-cd88-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008651865s
Sep  2 13:47:20.837: INFO: Pod "var-expansion-2bf383eb-cd88-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.017788795s
STEP: Saw pod success
Sep  2 13:47:20.837: INFO: Pod "var-expansion-2bf383eb-cd88-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 13:47:20.839: INFO: Trying to get logs from node ip-192-168-169-21.us-west-2.compute.internal pod var-expansion-2bf383eb-cd88-11e9-b90e-8ed318f3d3c6 container dapi-container: <nil>
STEP: delete the pod
Sep  2 13:47:20.857: INFO: Waiting for pod var-expansion-2bf383eb-cd88-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 13:47:20.859: INFO: Pod var-expansion-2bf383eb-cd88-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:47:20.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-8wn4s" for this suite.
Sep  2 13:47:26.878: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:47:26.957: INFO: namespace: e2e-tests-var-expansion-8wn4s, resource: bindings, ignored listing per whitelist
Sep  2 13:47:26.980: INFO: namespace e2e-tests-var-expansion-8wn4s deletion completed in 6.116833639s

• [SLOW TEST:12.327 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:47:26.980: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-78wbt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:47:27.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-78wbt" for this suite.
Sep  2 13:47:33.171: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:47:33.221: INFO: namespace: e2e-tests-services-78wbt, resource: bindings, ignored listing per whitelist
Sep  2 13:47:33.268: INFO: namespace e2e-tests-services-78wbt deletion completed in 6.113595652s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:6.288 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:47:33.268: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-jgh64
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Sep  2 13:47:33.435: INFO: Creating deployment "test-recreate-deployment"
Sep  2 13:47:33.439: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Sep  2 13:47:33.443: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Sep  2 13:47:35.449: INFO: Waiting deployment "test-recreate-deployment" to complete
Sep  2 13:47:35.451: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703028853, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703028853, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703028853, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703028853, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-5dfdcc846d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  2 13:47:37.454: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703028853, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703028853, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703028853, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703028853, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-5dfdcc846d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  2 13:47:39.454: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Sep  2 13:47:39.462: INFO: Updating deployment test-recreate-deployment
Sep  2 13:47:39.462: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Sep  2 13:47:39.525: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-jgh64,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-jgh64/deployments/test-recreate-deployment,UID:370d0761-cd88-11e9-a575-0a854009c708,ResourceVersion:2095251,Generation:2,CreationTimestamp:2019-09-02 13:47:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-09-02 13:47:39 +0000 UTC 2019-09-02 13:47:39 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-09-02 13:47:39 +0000 UTC 2019-09-02 13:47:33 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-697fbf54bf" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Sep  2 13:47:39.527: INFO: New ReplicaSet "test-recreate-deployment-697fbf54bf" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf,GenerateName:,Namespace:e2e-tests-deployment-jgh64,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-jgh64/replicasets/test-recreate-deployment-697fbf54bf,UID:3aa9e390-cd88-11e9-96cb-060c8a2202ce,ResourceVersion:2095248,Generation:1,CreationTimestamp:2019-09-02 13:47:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 370d0761-cd88-11e9-a575-0a854009c708 0xc0025bd5f7 0xc0025bd5f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep  2 13:47:39.527: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Sep  2 13:47:39.527: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5dfdcc846d,GenerateName:,Namespace:e2e-tests-deployment-jgh64,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-jgh64/replicasets/test-recreate-deployment-5dfdcc846d,UID:370ebdb8-cd88-11e9-96cb-060c8a2202ce,ResourceVersion:2095239,Generation:2,CreationTimestamp:2019-09-02 13:47:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 370d0761-cd88-11e9-a575-0a854009c708 0xc0025bd237 0xc0025bd238}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep  2 13:47:39.530: INFO: Pod "test-recreate-deployment-697fbf54bf-j62x9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf-j62x9,GenerateName:test-recreate-deployment-697fbf54bf-,Namespace:e2e-tests-deployment-jgh64,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jgh64/pods/test-recreate-deployment-697fbf54bf-j62x9,UID:3aaa7cf2-cd88-11e9-96cb-060c8a2202ce,ResourceVersion:2095250,Generation:0,CreationTimestamp:2019-09-02 13:47:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-697fbf54bf 3aa9e390-cd88-11e9-96cb-060c8a2202ce 0xc0024102e7 0xc0024102e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-n2z28 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-n2z28,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-n2z28 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-192-168-169-21.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002410640} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002410660}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:47:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:47:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:47:39 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:47:39 +0000 UTC  }],Message:,Reason:,HostIP:192.168.169.21,PodIP:,StartTime:2019-09-02 13:47:39 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:47:39.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-jgh64" for this suite.
Sep  2 13:47:45.549: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:47:45.630: INFO: namespace: e2e-tests-deployment-jgh64, resource: bindings, ignored listing per whitelist
Sep  2 13:47:45.648: INFO: namespace e2e-tests-deployment-jgh64 deletion completed in 6.114305047s

• [SLOW TEST:12.380 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:47:45.648: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-49lkb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-3e6db525-cd88-11e9-b90e-8ed318f3d3c6
STEP: Creating a pod to test consume secrets
Sep  2 13:47:45.823: INFO: Waiting up to 5m0s for pod "pod-secrets-3e6e680e-cd88-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-secrets-49lkb" to be "success or failure"
Sep  2 13:47:45.825: INFO: Pod "pod-secrets-3e6e680e-cd88-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.331412ms
Sep  2 13:47:47.829: INFO: Pod "pod-secrets-3e6e680e-cd88-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005570798s
Sep  2 13:47:49.832: INFO: Pod "pod-secrets-3e6e680e-cd88-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009097677s
STEP: Saw pod success
Sep  2 13:47:49.832: INFO: Pod "pod-secrets-3e6e680e-cd88-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 13:47:49.835: INFO: Trying to get logs from node ip-192-168-169-21.us-west-2.compute.internal pod pod-secrets-3e6e680e-cd88-11e9-b90e-8ed318f3d3c6 container secret-volume-test: <nil>
STEP: delete the pod
Sep  2 13:47:49.851: INFO: Waiting for pod pod-secrets-3e6e680e-cd88-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 13:47:49.854: INFO: Pod pod-secrets-3e6e680e-cd88-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:47:49.854: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-49lkb" for this suite.
Sep  2 13:47:55.874: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:47:55.948: INFO: namespace: e2e-tests-secrets-49lkb, resource: bindings, ignored listing per whitelist
Sep  2 13:47:55.971: INFO: namespace e2e-tests-secrets-49lkb deletion completed in 6.113086038s

• [SLOW TEST:10.323 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:47:55.972: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-xx299
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:48:56.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-xx299" for this suite.
Sep  2 13:49:18.171: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:49:18.242: INFO: namespace: e2e-tests-container-probe-xx299, resource: bindings, ignored listing per whitelist
Sep  2 13:49:18.267: INFO: namespace e2e-tests-container-probe-xx299 deletion completed in 22.114233337s

• [SLOW TEST:82.296 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:49:18.268: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-8tdf7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-47hp
STEP: Creating a pod to test atomic-volume-subpath
Sep  2 13:49:18.450: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-47hp" in namespace "e2e-tests-subpath-8tdf7" to be "success or failure"
Sep  2 13:49:18.452: INFO: Pod "pod-subpath-test-secret-47hp": Phase="Pending", Reason="", readiness=false. Elapsed: 2.586149ms
Sep  2 13:49:20.456: INFO: Pod "pod-subpath-test-secret-47hp": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005801143s
Sep  2 13:49:22.459: INFO: Pod "pod-subpath-test-secret-47hp": Phase="Running", Reason="", readiness=false. Elapsed: 4.0091148s
Sep  2 13:49:24.462: INFO: Pod "pod-subpath-test-secret-47hp": Phase="Running", Reason="", readiness=false. Elapsed: 6.01239376s
Sep  2 13:49:26.474: INFO: Pod "pod-subpath-test-secret-47hp": Phase="Running", Reason="", readiness=false. Elapsed: 8.024285238s
Sep  2 13:49:28.477: INFO: Pod "pod-subpath-test-secret-47hp": Phase="Running", Reason="", readiness=false. Elapsed: 10.027520056s
Sep  2 13:49:30.481: INFO: Pod "pod-subpath-test-secret-47hp": Phase="Running", Reason="", readiness=false. Elapsed: 12.030894869s
Sep  2 13:49:32.484: INFO: Pod "pod-subpath-test-secret-47hp": Phase="Running", Reason="", readiness=false. Elapsed: 14.034394751s
Sep  2 13:49:34.492: INFO: Pod "pod-subpath-test-secret-47hp": Phase="Running", Reason="", readiness=false. Elapsed: 16.042435532s
Sep  2 13:49:36.501: INFO: Pod "pod-subpath-test-secret-47hp": Phase="Running", Reason="", readiness=false. Elapsed: 18.050964912s
Sep  2 13:49:38.504: INFO: Pod "pod-subpath-test-secret-47hp": Phase="Running", Reason="", readiness=false. Elapsed: 20.054201758s
Sep  2 13:49:40.507: INFO: Pod "pod-subpath-test-secret-47hp": Phase="Running", Reason="", readiness=false. Elapsed: 22.057509866s
Sep  2 13:49:42.511: INFO: Pod "pod-subpath-test-secret-47hp": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.060706599s
STEP: Saw pod success
Sep  2 13:49:42.511: INFO: Pod "pod-subpath-test-secret-47hp" satisfied condition "success or failure"
Sep  2 13:49:42.513: INFO: Trying to get logs from node ip-192-168-169-21.us-west-2.compute.internal pod pod-subpath-test-secret-47hp container test-container-subpath-secret-47hp: <nil>
STEP: delete the pod
Sep  2 13:49:42.530: INFO: Waiting for pod pod-subpath-test-secret-47hp to disappear
Sep  2 13:49:42.533: INFO: Pod pod-subpath-test-secret-47hp no longer exists
STEP: Deleting pod pod-subpath-test-secret-47hp
Sep  2 13:49:42.533: INFO: Deleting pod "pod-subpath-test-secret-47hp" in namespace "e2e-tests-subpath-8tdf7"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:49:42.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-8tdf7" for this suite.
Sep  2 13:49:48.556: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:49:48.593: INFO: namespace: e2e-tests-subpath-8tdf7, resource: bindings, ignored listing per whitelist
Sep  2 13:49:48.654: INFO: namespace e2e-tests-subpath-8tdf7 deletion completed in 6.114928946s

• [SLOW TEST:30.387 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:49:48.654: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-xp2nk
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0902 13:49:58.887786      19 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep  2 13:49:58.887: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:49:58.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-xp2nk" for this suite.
Sep  2 13:50:04.907: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:50:04.989: INFO: namespace: e2e-tests-gc-xp2nk, resource: bindings, ignored listing per whitelist
Sep  2 13:50:05.009: INFO: namespace e2e-tests-gc-xp2nk deletion completed in 6.118273067s

• [SLOW TEST:16.355 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:50:05.009: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-gzz4g
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Sep  2 13:50:05.178: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 version'
Sep  2 13:50:05.237: INFO: stderr: ""
Sep  2 13:50:05.237: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"13+\", GitVersion:\"v1.13.8-eks-a977ba\", GitCommit:\"a977bab148535ec195f12edc8720913c7b943f9c\", GitTreeState:\"clean\", BuildDate:\"2019-07-29T20:47:04Z\", GoVersion:\"go1.11.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:50:05.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-gzz4g" for this suite.
Sep  2 13:50:11.257: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:50:11.272: INFO: namespace: e2e-tests-kubectl-gzz4g, resource: bindings, ignored listing per whitelist
Sep  2 13:50:11.355: INFO: namespace e2e-tests-kubectl-gzz4g deletion completed in 6.114091518s

• [SLOW TEST:6.346 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:50:11.356: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-6zqwb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-9546784a-cd88-11e9-b90e-8ed318f3d3c6
STEP: Creating a pod to test consume secrets
Sep  2 13:50:11.530: INFO: Waiting up to 5m0s for pod "pod-secrets-95473832-cd88-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-secrets-6zqwb" to be "success or failure"
Sep  2 13:50:11.532: INFO: Pod "pod-secrets-95473832-cd88-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.31487ms
Sep  2 13:50:13.535: INFO: Pod "pod-secrets-95473832-cd88-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005376743s
STEP: Saw pod success
Sep  2 13:50:13.535: INFO: Pod "pod-secrets-95473832-cd88-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 13:50:13.538: INFO: Trying to get logs from node ip-192-168-169-21.us-west-2.compute.internal pod pod-secrets-95473832-cd88-11e9-b90e-8ed318f3d3c6 container secret-volume-test: <nil>
STEP: delete the pod
Sep  2 13:50:13.555: INFO: Waiting for pod pod-secrets-95473832-cd88-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 13:50:13.557: INFO: Pod pod-secrets-95473832-cd88-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:50:13.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-6zqwb" for this suite.
Sep  2 13:50:19.582: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:50:19.659: INFO: namespace: e2e-tests-secrets-6zqwb, resource: bindings, ignored listing per whitelist
Sep  2 13:50:19.683: INFO: namespace e2e-tests-secrets-6zqwb deletion completed in 6.121923876s

• [SLOW TEST:8.327 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:50:19.683: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-6znx7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-wlcb
STEP: Creating a pod to test atomic-volume-subpath
Sep  2 13:50:19.864: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-wlcb" in namespace "e2e-tests-subpath-6znx7" to be "success or failure"
Sep  2 13:50:19.867: INFO: Pod "pod-subpath-test-configmap-wlcb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.553431ms
Sep  2 13:50:21.870: INFO: Pod "pod-subpath-test-configmap-wlcb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005949081s
Sep  2 13:50:23.873: INFO: Pod "pod-subpath-test-configmap-wlcb": Phase="Running", Reason="", readiness=false. Elapsed: 4.009338106s
Sep  2 13:50:25.877: INFO: Pod "pod-subpath-test-configmap-wlcb": Phase="Running", Reason="", readiness=false. Elapsed: 6.012698642s
Sep  2 13:50:27.880: INFO: Pod "pod-subpath-test-configmap-wlcb": Phase="Running", Reason="", readiness=false. Elapsed: 8.016087126s
Sep  2 13:50:29.889: INFO: Pod "pod-subpath-test-configmap-wlcb": Phase="Running", Reason="", readiness=false. Elapsed: 10.025070253s
Sep  2 13:50:31.893: INFO: Pod "pod-subpath-test-configmap-wlcb": Phase="Running", Reason="", readiness=false. Elapsed: 12.0284866s
Sep  2 13:50:33.896: INFO: Pod "pod-subpath-test-configmap-wlcb": Phase="Running", Reason="", readiness=false. Elapsed: 14.031948095s
Sep  2 13:50:35.899: INFO: Pod "pod-subpath-test-configmap-wlcb": Phase="Running", Reason="", readiness=false. Elapsed: 16.035164548s
Sep  2 13:50:37.903: INFO: Pod "pod-subpath-test-configmap-wlcb": Phase="Running", Reason="", readiness=false. Elapsed: 18.038653909s
Sep  2 13:50:39.912: INFO: Pod "pod-subpath-test-configmap-wlcb": Phase="Running", Reason="", readiness=false. Elapsed: 20.04810648s
Sep  2 13:50:41.915: INFO: Pod "pod-subpath-test-configmap-wlcb": Phase="Running", Reason="", readiness=false. Elapsed: 22.051318219s
Sep  2 13:50:43.919: INFO: Pod "pod-subpath-test-configmap-wlcb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.054737877s
STEP: Saw pod success
Sep  2 13:50:43.919: INFO: Pod "pod-subpath-test-configmap-wlcb" satisfied condition "success or failure"
Sep  2 13:50:43.922: INFO: Trying to get logs from node ip-192-168-169-21.us-west-2.compute.internal pod pod-subpath-test-configmap-wlcb container test-container-subpath-configmap-wlcb: <nil>
STEP: delete the pod
Sep  2 13:50:43.940: INFO: Waiting for pod pod-subpath-test-configmap-wlcb to disappear
Sep  2 13:50:43.942: INFO: Pod pod-subpath-test-configmap-wlcb no longer exists
STEP: Deleting pod pod-subpath-test-configmap-wlcb
Sep  2 13:50:43.942: INFO: Deleting pod "pod-subpath-test-configmap-wlcb" in namespace "e2e-tests-subpath-6znx7"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:50:43.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-6znx7" for this suite.
Sep  2 13:50:49.970: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:50:50.005: INFO: namespace: e2e-tests-subpath-6znx7, resource: bindings, ignored listing per whitelist
Sep  2 13:50:50.069: INFO: namespace e2e-tests-subpath-6znx7 deletion completed in 6.120646506s

• [SLOW TEST:30.386 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:50:50.069: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-custom-resource-definition-jph5b
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Sep  2 13:50:50.237: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:50:51.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-jph5b" for this suite.
Sep  2 13:50:57.314: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:50:57.403: INFO: namespace: e2e-tests-custom-resource-definition-jph5b, resource: bindings, ignored listing per whitelist
Sep  2 13:50:57.414: INFO: namespace e2e-tests-custom-resource-definition-jph5b deletion completed in 6.115780038s

• [SLOW TEST:7.344 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:50:57.414: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-dc5tr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Sep  2 13:51:05.612: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep  2 13:51:05.614: INFO: Pod pod-with-prestop-http-hook still exists
Sep  2 13:51:07.614: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep  2 13:51:07.618: INFO: Pod pod-with-prestop-http-hook still exists
Sep  2 13:51:09.614: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep  2 13:51:09.618: INFO: Pod pod-with-prestop-http-hook still exists
Sep  2 13:51:11.614: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep  2 13:51:11.623: INFO: Pod pod-with-prestop-http-hook still exists
Sep  2 13:51:13.614: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep  2 13:51:13.618: INFO: Pod pod-with-prestop-http-hook still exists
Sep  2 13:51:15.614: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep  2 13:51:15.618: INFO: Pod pod-with-prestop-http-hook still exists
Sep  2 13:51:17.614: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep  2 13:51:17.617: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:51:17.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-dc5tr" for this suite.
Sep  2 13:51:39.645: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:51:39.730: INFO: namespace: e2e-tests-container-lifecycle-hook-dc5tr, resource: bindings, ignored listing per whitelist
Sep  2 13:51:39.744: INFO: namespace e2e-tests-container-lifecycle-hook-dc5tr deletion completed in 22.115930546s

• [SLOW TEST:42.331 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:51:39.745: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-t845n
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Sep  2 13:51:39.911: INFO: Creating deployment "nginx-deployment"
Sep  2 13:51:39.915: INFO: Waiting for observed generation 1
Sep  2 13:51:41.921: INFO: Waiting for all required pods to come up
Sep  2 13:51:41.925: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Sep  2 13:51:43.938: INFO: Waiting for deployment "nginx-deployment" to complete
Sep  2 13:51:43.945: INFO: Updating deployment "nginx-deployment" with a non-existent image
Sep  2 13:51:43.951: INFO: Updating deployment nginx-deployment
Sep  2 13:51:43.951: INFO: Waiting for observed generation 2
Sep  2 13:51:45.956: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Sep  2 13:51:45.960: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Sep  2 13:51:45.963: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Sep  2 13:51:45.974: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Sep  2 13:51:45.974: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Sep  2 13:51:45.977: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Sep  2 13:51:45.983: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Sep  2 13:51:45.983: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Sep  2 13:51:45.990: INFO: Updating deployment nginx-deployment
Sep  2 13:51:45.990: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Sep  2 13:51:45.997: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Sep  2 13:51:46.002: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Sep  2 13:51:46.012: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-t845n,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-t845n/deployments/nginx-deployment,UID:c9f64534-cd88-11e9-a575-0a854009c708,ResourceVersion:2096384,Generation:3,CreationTimestamp:2019-09-02 13:51:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Progressing True 2019-09-02 13:51:44 +0000 UTC 2019-09-02 13:51:39 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-65bbdb5f8" is progressing.} {Available False 2019-09-02 13:51:46 +0000 UTC 2019-09-02 13:51:46 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}],ReadyReplicas:8,CollisionCount:nil,},}

Sep  2 13:51:46.018: INFO: New ReplicaSet "nginx-deployment-65bbdb5f8" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8,GenerateName:,Namespace:e2e-tests-deployment-t845n,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-t845n/replicasets/nginx-deployment-65bbdb5f8,UID:cc5ecd97-cd88-11e9-96cb-060c8a2202ce,ResourceVersion:2096376,Generation:3,CreationTimestamp:2019-09-02 13:51:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment c9f64534-cd88-11e9-a575-0a854009c708 0xc001afadc7 0xc001afadc8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep  2 13:51:46.018: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Sep  2 13:51:46.018: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965,GenerateName:,Namespace:e2e-tests-deployment-t845n,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-t845n/replicasets/nginx-deployment-555b55d965,UID:c9f801ee-cd88-11e9-96cb-060c8a2202ce,ResourceVersion:2096374,Generation:3,CreationTimestamp:2019-09-02 13:51:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment c9f64534-cd88-11e9-a575-0a854009c708 0xc001aface7 0xc001aface8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Sep  2 13:51:46.025: INFO: Pod "nginx-deployment-555b55d965-5gtbr" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-5gtbr,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-t845n,SelfLink:/api/v1/namespaces/e2e-tests-deployment-t845n/pods/nginx-deployment-555b55d965-5gtbr,UID:c9fafd46-cd88-11e9-96cb-060c8a2202ce,ResourceVersion:2096292,Generation:0,CreationTimestamp:2019-09-02 13:51:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 c9f801ee-cd88-11e9-96cb-060c8a2202ce 0xc0023310e7 0xc0023310e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qghwv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qghwv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qghwv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-192-168-55-191.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002331150} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002331170}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:51:39 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:51:42 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:51:42 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:51:39 +0000 UTC  }],Message:,Reason:,HostIP:192.168.55.191,PodIP:192.168.37.168,StartTime:2019-09-02 13:51:39 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-02 13:51:41 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://8d9ff5b40969031b1807f2daf9af09247ccd969a7c9d81a2ef9247e68edd6bcd}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  2 13:51:46.025: INFO: Pod "nginx-deployment-555b55d965-6mvrv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-6mvrv,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-t845n,SelfLink:/api/v1/namespaces/e2e-tests-deployment-t845n/pods/nginx-deployment-555b55d965-6mvrv,UID:cd97d827-cd88-11e9-96cb-060c8a2202ce,ResourceVersion:2096388,Generation:0,CreationTimestamp:2019-09-02 13:51:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 c9f801ee-cd88-11e9-96cb-060c8a2202ce 0xc002331357 0xc002331358}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qghwv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qghwv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qghwv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-192-168-6-156.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0023313c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0023313e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:51:46 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  2 13:51:46.026: INFO: Pod "nginx-deployment-555b55d965-76rsr" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-76rsr,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-t845n,SelfLink:/api/v1/namespaces/e2e-tests-deployment-t845n/pods/nginx-deployment-555b55d965-76rsr,UID:c9fd7988-cd88-11e9-96cb-060c8a2202ce,ResourceVersion:2096282,Generation:0,CreationTimestamp:2019-09-02 13:51:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 c9f801ee-cd88-11e9-96cb-060c8a2202ce 0xc002331457 0xc002331458}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qghwv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qghwv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qghwv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-192-168-6-156.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002331520} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002331540}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:51:39 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:51:42 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:51:42 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:51:39 +0000 UTC  }],Message:,Reason:,HostIP:192.168.6.156,PodIP:192.168.30.172,StartTime:2019-09-02 13:51:39 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-02 13:51:41 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://9d0101adb042d9409b2b30efe9b0529245178b94933a80c85e744aa51ddf4eb0}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  2 13:51:46.026: INFO: Pod "nginx-deployment-555b55d965-8w5p7" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-8w5p7,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-t845n,SelfLink:/api/v1/namespaces/e2e-tests-deployment-t845n/pods/nginx-deployment-555b55d965-8w5p7,UID:c9fd7962-cd88-11e9-96cb-060c8a2202ce,ResourceVersion:2096276,Generation:0,CreationTimestamp:2019-09-02 13:51:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 c9f801ee-cd88-11e9-96cb-060c8a2202ce 0xc002331607 0xc002331608}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qghwv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qghwv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qghwv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-192-168-77-237.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0023316c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0023316e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:51:39 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:51:42 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:51:42 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:51:39 +0000 UTC  }],Message:,Reason:,HostIP:192.168.77.237,PodIP:192.168.72.177,StartTime:2019-09-02 13:51:39 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-02 13:51:41 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://bd8b3709d3bb8d301a4d1d3b8cb62740efac2c907a52f324289ee19b080bb673}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  2 13:51:46.026: INFO: Pod "nginx-deployment-555b55d965-bcq2j" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-bcq2j,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-t845n,SelfLink:/api/v1/namespaces/e2e-tests-deployment-t845n/pods/nginx-deployment-555b55d965-bcq2j,UID:cd997f53-cd88-11e9-96cb-060c8a2202ce,ResourceVersion:2096392,Generation:0,CreationTimestamp:2019-09-02 13:51:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 c9f801ee-cd88-11e9-96cb-060c8a2202ce 0xc0023317a7 0xc0023317a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qghwv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qghwv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qghwv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002331810} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002331840}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  2 13:51:46.026: INFO: Pod "nginx-deployment-555b55d965-cdnd8" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-cdnd8,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-t845n,SelfLink:/api/v1/namespaces/e2e-tests-deployment-t845n/pods/nginx-deployment-555b55d965-cdnd8,UID:c9fd7bf5-cd88-11e9-96cb-060c8a2202ce,ResourceVersion:2096295,Generation:0,CreationTimestamp:2019-09-02 13:51:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 c9f801ee-cd88-11e9-96cb-060c8a2202ce 0xc0023319d0 0xc0023319d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qghwv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qghwv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qghwv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-192-168-55-191.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002331a30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002331a50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:51:40 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:51:42 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:51:42 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:51:39 +0000 UTC  }],Message:,Reason:,HostIP:192.168.55.191,PodIP:192.168.34.74,StartTime:2019-09-02 13:51:40 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-02 13:51:42 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://7b593dcd0b3c86b0951ed743155bce693240da122254554573c67f6805f8d3ea}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  2 13:51:46.026: INFO: Pod "nginx-deployment-555b55d965-f4n6g" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-f4n6g,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-t845n,SelfLink:/api/v1/namespaces/e2e-tests-deployment-t845n/pods/nginx-deployment-555b55d965-f4n6g,UID:cd97e264-cd88-11e9-96cb-060c8a2202ce,ResourceVersion:2096387,Generation:0,CreationTimestamp:2019-09-02 13:51:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 c9f801ee-cd88-11e9-96cb-060c8a2202ce 0xc002331b17 0xc002331b18}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qghwv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qghwv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qghwv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-192-168-169-21.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002331cc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002331ce0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:51:46 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  2 13:51:46.026: INFO: Pod "nginx-deployment-555b55d965-g2qlv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-g2qlv,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-t845n,SelfLink:/api/v1/namespaces/e2e-tests-deployment-t845n/pods/nginx-deployment-555b55d965-g2qlv,UID:cd9987a5-cd88-11e9-96cb-060c8a2202ce,ResourceVersion:2096394,Generation:0,CreationTimestamp:2019-09-02 13:51:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 c9f801ee-cd88-11e9-96cb-060c8a2202ce 0xc002331d57 0xc002331d58}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qghwv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qghwv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qghwv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002331dc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002331de0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  2 13:51:46.027: INFO: Pod "nginx-deployment-555b55d965-gjcc6" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-gjcc6,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-t845n,SelfLink:/api/v1/namespaces/e2e-tests-deployment-t845n/pods/nginx-deployment-555b55d965-gjcc6,UID:c9fa4724-cd88-11e9-96cb-060c8a2202ce,ResourceVersion:2096271,Generation:0,CreationTimestamp:2019-09-02 13:51:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 c9f801ee-cd88-11e9-96cb-060c8a2202ce 0xc002331f20 0xc002331f21}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qghwv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qghwv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qghwv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-192-168-169-21.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002331f80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002331fa0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:51:39 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:51:42 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:51:42 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:51:39 +0000 UTC  }],Message:,Reason:,HostIP:192.168.169.21,PodIP:192.168.189.136,StartTime:2019-09-02 13:51:39 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-02 13:51:41 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://06136198def7cfcd363547198713e0c24bbc64c039b812b720a8c03d95b0e30e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  2 13:51:46.027: INFO: Pod "nginx-deployment-555b55d965-hwvkl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-hwvkl,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-t845n,SelfLink:/api/v1/namespaces/e2e-tests-deployment-t845n/pods/nginx-deployment-555b55d965-hwvkl,UID:cd9983ec-cd88-11e9-96cb-060c8a2202ce,ResourceVersion:2096393,Generation:0,CreationTimestamp:2019-09-02 13:51:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 c9f801ee-cd88-11e9-96cb-060c8a2202ce 0xc001ac5157 0xc001ac5158}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qghwv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qghwv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qghwv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ac51c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ac51e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  2 13:51:46.027: INFO: Pod "nginx-deployment-555b55d965-jjh7h" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-jjh7h,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-t845n,SelfLink:/api/v1/namespaces/e2e-tests-deployment-t845n/pods/nginx-deployment-555b55d965-jjh7h,UID:c9fbf355-cd88-11e9-96cb-060c8a2202ce,ResourceVersion:2096297,Generation:0,CreationTimestamp:2019-09-02 13:51:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 c9f801ee-cd88-11e9-96cb-060c8a2202ce 0xc001ac5240 0xc001ac5241}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qghwv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qghwv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qghwv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-192-168-55-191.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ac52a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ac52c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:51:39 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:51:42 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:51:42 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:51:39 +0000 UTC  }],Message:,Reason:,HostIP:192.168.55.191,PodIP:192.168.47.169,StartTime:2019-09-02 13:51:39 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-02 13:51:42 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://5018cc5590eb9f77f84989bd0c3c7c3cf2fc706fd97daa9073372b0625dc5d42}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  2 13:51:46.027: INFO: Pod "nginx-deployment-555b55d965-jm4bb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-jm4bb,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-t845n,SelfLink:/api/v1/namespaces/e2e-tests-deployment-t845n/pods/nginx-deployment-555b55d965-jm4bb,UID:cd96b985-cd88-11e9-96cb-060c8a2202ce,ResourceVersion:2096397,Generation:0,CreationTimestamp:2019-09-02 13:51:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 c9f801ee-cd88-11e9-96cb-060c8a2202ce 0xc001ac5827 0xc001ac5828}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qghwv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qghwv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qghwv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-192-168-6-156.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ac5910} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ac5930}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:51:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:51:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:51:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:51:46 +0000 UTC  }],Message:,Reason:,HostIP:192.168.6.156,PodIP:,StartTime:2019-09-02 13:51:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  2 13:51:46.027: INFO: Pod "nginx-deployment-555b55d965-n9lh5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-n9lh5,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-t845n,SelfLink:/api/v1/namespaces/e2e-tests-deployment-t845n/pods/nginx-deployment-555b55d965-n9lh5,UID:cd999a1a-cd88-11e9-96cb-060c8a2202ce,ResourceVersion:2096395,Generation:0,CreationTimestamp:2019-09-02 13:51:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 c9f801ee-cd88-11e9-96cb-060c8a2202ce 0xc001ac5a57 0xc001ac5a58}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qghwv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qghwv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qghwv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ac5b50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ac5b70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  2 13:51:46.027: INFO: Pod "nginx-deployment-555b55d965-qsvwf" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-qsvwf,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-t845n,SelfLink:/api/v1/namespaces/e2e-tests-deployment-t845n/pods/nginx-deployment-555b55d965-qsvwf,UID:c9fbff13-cd88-11e9-96cb-060c8a2202ce,ResourceVersion:2096269,Generation:0,CreationTimestamp:2019-09-02 13:51:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 c9f801ee-cd88-11e9-96cb-060c8a2202ce 0xc001ac5bd0 0xc001ac5bd1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qghwv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qghwv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qghwv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-192-168-169-21.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ac5c40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ac5c70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:51:39 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:51:42 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:51:42 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:51:39 +0000 UTC  }],Message:,Reason:,HostIP:192.168.169.21,PodIP:192.168.160.37,StartTime:2019-09-02 13:51:39 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-02 13:51:41 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://32c20f4bdee817dd89ac8e60a77fa29155f6f0ccb2e1a26eb217f779b144c65c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  2 13:51:46.027: INFO: Pod "nginx-deployment-555b55d965-rldxm" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-rldxm,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-t845n,SelfLink:/api/v1/namespaces/e2e-tests-deployment-t845n/pods/nginx-deployment-555b55d965-rldxm,UID:c9fbe9d7-cd88-11e9-96cb-060c8a2202ce,ResourceVersion:2096278,Generation:0,CreationTimestamp:2019-09-02 13:51:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 c9f801ee-cd88-11e9-96cb-060c8a2202ce 0xc001ac5e07 0xc001ac5e08}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qghwv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qghwv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qghwv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-192-168-77-237.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ac5e70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ac5e90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:51:39 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:51:42 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:51:42 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:51:39 +0000 UTC  }],Message:,Reason:,HostIP:192.168.77.237,PodIP:192.168.75.155,StartTime:2019-09-02 13:51:39 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-02 13:51:41 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://08d522bb0c10b68b42adfbd131b2750ca3dd6bf8e44c1725e1482dd954492ac8}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  2 13:51:46.028: INFO: Pod "nginx-deployment-65bbdb5f8-2p8b2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-2p8b2,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-t845n,SelfLink:/api/v1/namespaces/e2e-tests-deployment-t845n/pods/nginx-deployment-65bbdb5f8-2p8b2,UID:cd994959-cd88-11e9-96cb-060c8a2202ce,ResourceVersion:2096390,Generation:0,CreationTimestamp:2019-09-02 13:51:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 cc5ecd97-cd88-11e9-96cb-060c8a2202ce 0xc001a08377 0xc001a08378}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qghwv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qghwv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qghwv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a083e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a08400}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  2 13:51:46.028: INFO: Pod "nginx-deployment-65bbdb5f8-468cj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-468cj,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-t845n,SelfLink:/api/v1/namespaces/e2e-tests-deployment-t845n/pods/nginx-deployment-65bbdb5f8-468cj,UID:cd995795-cd88-11e9-96cb-060c8a2202ce,ResourceVersion:2096391,Generation:0,CreationTimestamp:2019-09-02 13:51:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 cc5ecd97-cd88-11e9-96cb-060c8a2202ce 0xc001a084f0 0xc001a084f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qghwv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qghwv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qghwv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a085e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a08600}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  2 13:51:46.028: INFO: Pod "nginx-deployment-65bbdb5f8-7szvj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-7szvj,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-t845n,SelfLink:/api/v1/namespaces/e2e-tests-deployment-t845n/pods/nginx-deployment-65bbdb5f8-7szvj,UID:cc5f9116-cd88-11e9-96cb-060c8a2202ce,ResourceVersion:2096324,Generation:0,CreationTimestamp:2019-09-02 13:51:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 cc5ecd97-cd88-11e9-96cb-060c8a2202ce 0xc001a08dc0 0xc001a08dc1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qghwv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qghwv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qghwv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-192-168-169-21.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a08e30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a08e50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:51:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:51:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:51:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:51:43 +0000 UTC  }],Message:,Reason:,HostIP:192.168.169.21,PodIP:,StartTime:2019-09-02 13:51:43 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  2 13:51:46.028: INFO: Pod "nginx-deployment-65bbdb5f8-c2c7c" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-c2c7c,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-t845n,SelfLink:/api/v1/namespaces/e2e-tests-deployment-t845n/pods/nginx-deployment-65bbdb5f8-c2c7c,UID:cc60808e-cd88-11e9-96cb-060c8a2202ce,ResourceVersion:2096332,Generation:0,CreationTimestamp:2019-09-02 13:51:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 cc5ecd97-cd88-11e9-96cb-060c8a2202ce 0xc001a09597 0xc001a09598}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qghwv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qghwv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qghwv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-192-168-6-156.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a09680} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a096a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:51:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:51:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:51:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:51:43 +0000 UTC  }],Message:,Reason:,HostIP:192.168.6.156,PodIP:,StartTime:2019-09-02 13:51:43 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  2 13:51:46.028: INFO: Pod "nginx-deployment-65bbdb5f8-hq8b4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-hq8b4,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-t845n,SelfLink:/api/v1/namespaces/e2e-tests-deployment-t845n/pods/nginx-deployment-65bbdb5f8-hq8b4,UID:cd977be4-cd88-11e9-96cb-060c8a2202ce,ResourceVersion:2096385,Generation:0,CreationTimestamp:2019-09-02 13:51:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 cc5ecd97-cd88-11e9-96cb-060c8a2202ce 0xc001a09f37 0xc001a09f38}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qghwv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qghwv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qghwv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-192-168-55-191.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a09fa0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a09fd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:51:46 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  2 13:51:46.028: INFO: Pod "nginx-deployment-65bbdb5f8-jd8xn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-jd8xn,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-t845n,SelfLink:/api/v1/namespaces/e2e-tests-deployment-t845n/pods/nginx-deployment-65bbdb5f8-jd8xn,UID:cc662718-cd88-11e9-96cb-060c8a2202ce,ResourceVersion:2096352,Generation:0,CreationTimestamp:2019-09-02 13:51:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 cc5ecd97-cd88-11e9-96cb-060c8a2202ce 0xc0007ba307 0xc0007ba308}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qghwv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qghwv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qghwv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-192-168-6-156.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0007ba5b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0007ba5d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:51:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:51:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:51:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:51:44 +0000 UTC  }],Message:,Reason:,HostIP:192.168.6.156,PodIP:,StartTime:2019-09-02 13:51:44 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  2 13:51:46.028: INFO: Pod "nginx-deployment-65bbdb5f8-wgzfq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-wgzfq,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-t845n,SelfLink:/api/v1/namespaces/e2e-tests-deployment-t845n/pods/nginx-deployment-65bbdb5f8-wgzfq,UID:cc647739-cd88-11e9-96cb-060c8a2202ce,ResourceVersion:2096348,Generation:0,CreationTimestamp:2019-09-02 13:51:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 cc5ecd97-cd88-11e9-96cb-060c8a2202ce 0xc0007ba707 0xc0007ba708}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qghwv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qghwv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qghwv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-192-168-77-237.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0007ba770} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0007ba790}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:51:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:51:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:51:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:51:43 +0000 UTC  }],Message:,Reason:,HostIP:192.168.77.237,PodIP:,StartTime:2019-09-02 13:51:44 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  2 13:51:46.029: INFO: Pod "nginx-deployment-65bbdb5f8-wn56s" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-wn56s,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-t845n,SelfLink:/api/v1/namespaces/e2e-tests-deployment-t845n/pods/nginx-deployment-65bbdb5f8-wn56s,UID:cc608f28-cd88-11e9-96cb-060c8a2202ce,ResourceVersion:2096365,Generation:0,CreationTimestamp:2019-09-02 13:51:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 cc5ecd97-cd88-11e9-96cb-060c8a2202ce 0xc0007babc7 0xc0007babc8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qghwv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qghwv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qghwv true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-192-168-55-191.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0007bac30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0007bad10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:51:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:51:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:51:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 13:51:43 +0000 UTC  }],Message:,Reason:,HostIP:192.168.55.191,PodIP:192.168.39.217,StartTime:2019-09-02 13:51:43 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:51:46.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-t845n" for this suite.
Sep  2 13:51:52.057: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:51:52.064: INFO: namespace: e2e-tests-deployment-t845n, resource: bindings, ignored listing per whitelist
Sep  2 13:51:52.170: INFO: namespace e2e-tests-deployment-t845n deletion completed in 6.135642242s

• [SLOW TEST:12.426 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:51:52.170: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-rlc69
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0902 13:51:53.383558      19 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep  2 13:51:53.383: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:51:53.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-rlc69" for this suite.
Sep  2 13:51:59.403: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:51:59.484: INFO: namespace: e2e-tests-gc-rlc69, resource: bindings, ignored listing per whitelist
Sep  2 13:51:59.505: INFO: namespace e2e-tests-gc-rlc69 deletion completed in 6.117625462s

• [SLOW TEST:7.334 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:51:59.505: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-rvbc8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Sep  2 13:52:02.241: INFO: Successfully updated pod "annotationupdated5bc6166-cd88-11e9-b90e-8ed318f3d3c6"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:52:06.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rvbc8" for this suite.
Sep  2 13:52:28.298: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:52:28.388: INFO: namespace: e2e-tests-projected-rvbc8, resource: bindings, ignored listing per whitelist
Sep  2 13:52:28.396: INFO: namespace e2e-tests-projected-rvbc8 deletion completed in 22.120223878s

• [SLOW TEST:28.891 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:52:28.396: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-prestop-rcz4t
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-rcz4t
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-rcz4t
STEP: Deleting pre-stop pod
Sep  2 13:52:39.602: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:52:39.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-rcz4t" for this suite.
Sep  2 13:53:19.627: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:53:19.636: INFO: namespace: e2e-tests-prestop-rcz4t, resource: bindings, ignored listing per whitelist
Sep  2 13:53:19.727: INFO: namespace e2e-tests-prestop-rcz4t deletion completed in 40.116456162s

• [SLOW TEST:51.330 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:53:19.727: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-ktjjl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1134
STEP: creating an rc
Sep  2 13:53:19.894: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 create -f - --namespace=e2e-tests-kubectl-ktjjl'
Sep  2 13:53:20.141: INFO: stderr: ""
Sep  2 13:53:20.141: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Sep  2 13:53:21.144: INFO: Selector matched 1 pods for map[app:redis]
Sep  2 13:53:21.144: INFO: Found 0 / 1
Sep  2 13:53:22.145: INFO: Selector matched 1 pods for map[app:redis]
Sep  2 13:53:22.145: INFO: Found 0 / 1
Sep  2 13:53:23.144: INFO: Selector matched 1 pods for map[app:redis]
Sep  2 13:53:23.144: INFO: Found 1 / 1
Sep  2 13:53:23.144: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Sep  2 13:53:23.147: INFO: Selector matched 1 pods for map[app:redis]
Sep  2 13:53:23.147: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Sep  2 13:53:23.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 logs redis-master-p7fnx redis-master --namespace=e2e-tests-kubectl-ktjjl'
Sep  2 13:53:23.222: INFO: stderr: ""
Sep  2 13:53:23.222: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 02 Sep 13:53:21.386 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 02 Sep 13:53:21.386 # Server started, Redis version 3.2.12\n1:M 02 Sep 13:53:21.386 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 02 Sep 13:53:21.386 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Sep  2 13:53:23.222: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 log redis-master-p7fnx redis-master --namespace=e2e-tests-kubectl-ktjjl --tail=1'
Sep  2 13:53:23.296: INFO: stderr: ""
Sep  2 13:53:23.296: INFO: stdout: "1:M 02 Sep 13:53:21.386 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Sep  2 13:53:23.296: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 log redis-master-p7fnx redis-master --namespace=e2e-tests-kubectl-ktjjl --limit-bytes=1'
Sep  2 13:53:23.379: INFO: stderr: ""
Sep  2 13:53:23.379: INFO: stdout: " "
STEP: exposing timestamps
Sep  2 13:53:23.379: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 log redis-master-p7fnx redis-master --namespace=e2e-tests-kubectl-ktjjl --tail=1 --timestamps'
Sep  2 13:53:23.460: INFO: stderr: ""
Sep  2 13:53:23.460: INFO: stdout: "2019-09-02T13:53:21.386776278Z 1:M 02 Sep 13:53:21.386 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Sep  2 13:53:25.960: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 log redis-master-p7fnx redis-master --namespace=e2e-tests-kubectl-ktjjl --since=1s'
Sep  2 13:53:26.047: INFO: stderr: ""
Sep  2 13:53:26.047: INFO: stdout: ""
Sep  2 13:53:26.047: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 log redis-master-p7fnx redis-master --namespace=e2e-tests-kubectl-ktjjl --since=24h'
Sep  2 13:53:26.124: INFO: stderr: ""
Sep  2 13:53:26.124: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 02 Sep 13:53:21.386 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 02 Sep 13:53:21.386 # Server started, Redis version 3.2.12\n1:M 02 Sep 13:53:21.386 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 02 Sep 13:53:21.386 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1140
STEP: using delete to clean up resources
Sep  2 13:53:26.124: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-ktjjl'
Sep  2 13:53:26.193: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  2 13:53:26.193: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Sep  2 13:53:26.193: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-ktjjl'
Sep  2 13:53:26.263: INFO: stderr: "No resources found.\n"
Sep  2 13:53:26.263: INFO: stdout: ""
Sep  2 13:53:26.263: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 get pods -l name=nginx --namespace=e2e-tests-kubectl-ktjjl -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep  2 13:53:26.332: INFO: stderr: ""
Sep  2 13:53:26.332: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:53:26.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ktjjl" for this suite.
Sep  2 13:53:32.372: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:53:32.399: INFO: namespace: e2e-tests-kubectl-ktjjl, resource: bindings, ignored listing per whitelist
Sep  2 13:53:32.473: INFO: namespace e2e-tests-kubectl-ktjjl deletion completed in 6.117399308s

• [SLOW TEST:12.746 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:53:32.473: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-vnnf4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Sep  2 13:53:32.648: INFO: Waiting up to 5m0s for pod "var-expansion-0d2749ee-cd89-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-var-expansion-vnnf4" to be "success or failure"
Sep  2 13:53:32.651: INFO: Pod "var-expansion-0d2749ee-cd89-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.323573ms
Sep  2 13:53:34.654: INFO: Pod "var-expansion-0d2749ee-cd89-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005654054s
STEP: Saw pod success
Sep  2 13:53:34.654: INFO: Pod "var-expansion-0d2749ee-cd89-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 13:53:34.656: INFO: Trying to get logs from node ip-192-168-169-21.us-west-2.compute.internal pod var-expansion-0d2749ee-cd89-11e9-b90e-8ed318f3d3c6 container dapi-container: <nil>
STEP: delete the pod
Sep  2 13:53:34.673: INFO: Waiting for pod var-expansion-0d2749ee-cd89-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 13:53:34.675: INFO: Pod var-expansion-0d2749ee-cd89-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:53:34.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-vnnf4" for this suite.
Sep  2 13:53:40.695: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:53:40.704: INFO: namespace: e2e-tests-var-expansion-vnnf4, resource: bindings, ignored listing per whitelist
Sep  2 13:53:40.795: INFO: namespace e2e-tests-var-expansion-vnnf4 deletion completed in 6.1160862s

• [SLOW TEST:8.322 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:53:40.796: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-l88l7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0902 13:54:11.495369      19 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep  2 13:54:11.495: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:54:11.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-l88l7" for this suite.
Sep  2 13:54:17.514: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:54:17.593: INFO: namespace: e2e-tests-gc-l88l7, resource: bindings, ignored listing per whitelist
Sep  2 13:54:17.613: INFO: namespace e2e-tests-gc-l88l7 deletion completed in 6.113758161s

• [SLOW TEST:36.817 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:54:17.613: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-5rlnk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Sep  2 13:54:17.779: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-041707028 proxy --unix-socket=/tmp/kubectl-proxy-unix222314595/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:54:17.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-5rlnk" for this suite.
Sep  2 13:54:23.849: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:54:23.941: INFO: namespace: e2e-tests-kubectl-5rlnk, resource: bindings, ignored listing per whitelist
Sep  2 13:54:23.947: INFO: namespace e2e-tests-kubectl-5rlnk deletion completed in 6.113385243s

• [SLOW TEST:6.335 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:54:23.948: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-lgsng
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:54:28.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-lgsng" for this suite.
Sep  2 13:55:08.155: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:55:08.207: INFO: namespace: e2e-tests-kubelet-test-lgsng, resource: bindings, ignored listing per whitelist
Sep  2 13:55:08.255: INFO: namespace e2e-tests-kubelet-test-lgsng deletion completed in 40.121329704s

• [SLOW TEST:44.307 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a read only busybox container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:186
    should not write to root filesystem [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:55:08.255: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-tf2wl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Sep  2 13:55:08.429: INFO: Waiting up to 5m0s for pod "pod-463e5ea5-cd89-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-emptydir-tf2wl" to be "success or failure"
Sep  2 13:55:08.431: INFO: Pod "pod-463e5ea5-cd89-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.386155ms
Sep  2 13:55:10.435: INFO: Pod "pod-463e5ea5-cd89-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005505676s
Sep  2 13:55:12.438: INFO: Pod "pod-463e5ea5-cd89-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008707187s
STEP: Saw pod success
Sep  2 13:55:12.438: INFO: Pod "pod-463e5ea5-cd89-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 13:55:12.440: INFO: Trying to get logs from node ip-192-168-169-21.us-west-2.compute.internal pod pod-463e5ea5-cd89-11e9-b90e-8ed318f3d3c6 container test-container: <nil>
STEP: delete the pod
Sep  2 13:55:12.458: INFO: Waiting for pod pod-463e5ea5-cd89-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 13:55:12.461: INFO: Pod pod-463e5ea5-cd89-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:55:12.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-tf2wl" for this suite.
Sep  2 13:55:18.485: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:55:18.524: INFO: namespace: e2e-tests-emptydir-tf2wl, resource: bindings, ignored listing per whitelist
Sep  2 13:55:18.584: INFO: namespace e2e-tests-emptydir-tf2wl deletion completed in 6.119520288s

• [SLOW TEST:10.329 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:55:18.585: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-5kfx2
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-4c671400-cd89-11e9-b90e-8ed318f3d3c6
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-4c671400-cd89-11e9-b90e-8ed318f3d3c6
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:55:22.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5kfx2" for this suite.
Sep  2 13:55:44.819: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:55:44.840: INFO: namespace: e2e-tests-projected-5kfx2, resource: bindings, ignored listing per whitelist
Sep  2 13:55:44.918: INFO: namespace e2e-tests-projected-5kfx2 deletion completed in 22.114759114s

• [SLOW TEST:26.333 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:55:44.918: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-swxz4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-swxz4
Sep  2 13:55:49.103: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-swxz4
STEP: checking the pod's current state and verifying that restartCount is present
Sep  2 13:55:49.106: INFO: Initial restart count of pod liveness-http is 0
Sep  2 13:56:05.145: INFO: Restart count of pod e2e-tests-container-probe-swxz4/liveness-http is now 1 (16.039313161s elapsed)
Sep  2 13:56:25.189: INFO: Restart count of pod e2e-tests-container-probe-swxz4/liveness-http is now 2 (36.083322302s elapsed)
Sep  2 13:56:45.233: INFO: Restart count of pod e2e-tests-container-probe-swxz4/liveness-http is now 3 (56.127031496s elapsed)
Sep  2 13:57:05.282: INFO: Restart count of pod e2e-tests-container-probe-swxz4/liveness-http is now 4 (1m16.17678593s elapsed)
Sep  2 13:58:05.417: INFO: Restart count of pod e2e-tests-container-probe-swxz4/liveness-http is now 5 (2m16.311625065s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:58:05.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-swxz4" for this suite.
Sep  2 13:58:11.452: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:58:11.516: INFO: namespace: e2e-tests-container-probe-swxz4, resource: bindings, ignored listing per whitelist
Sep  2 13:58:11.552: INFO: namespace e2e-tests-container-probe-swxz4 deletion completed in 6.122778787s

• [SLOW TEST:146.635 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:58:11.553: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-886d9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Sep  2 13:58:11.745: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"b381ecbf-cd89-11e9-a575-0a854009c708", Controller:(*bool)(0xc0007bb53a), BlockOwnerDeletion:(*bool)(0xc0007bb53b)}}
Sep  2 13:58:11.749: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"b380a631-cd89-11e9-a575-0a854009c708", Controller:(*bool)(0xc001ac504a), BlockOwnerDeletion:(*bool)(0xc001ac504b)}}
Sep  2 13:58:11.754: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"b3813cb5-cd89-11e9-a575-0a854009c708", Controller:(*bool)(0xc001afaa3a), BlockOwnerDeletion:(*bool)(0xc001afaa3b)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:58:16.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-886d9" for this suite.
Sep  2 13:58:22.788: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:58:22.835: INFO: namespace: e2e-tests-gc-886d9, resource: bindings, ignored listing per whitelist
Sep  2 13:58:22.891: INFO: namespace e2e-tests-gc-886d9 deletion completed in 6.125228609s

• [SLOW TEST:11.338 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:58:22.891: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-fgnzf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Sep  2 13:58:29.099: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  2 13:58:29.102: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  2 13:58:31.102: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  2 13:58:31.105: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  2 13:58:33.102: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  2 13:58:33.111: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  2 13:58:35.102: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  2 13:58:35.105: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  2 13:58:37.102: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  2 13:58:37.105: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  2 13:58:39.102: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  2 13:58:39.105: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  2 13:58:41.102: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  2 13:58:41.105: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  2 13:58:43.102: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  2 13:58:43.105: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  2 13:58:45.102: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  2 13:58:45.111: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  2 13:58:47.102: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  2 13:58:47.105: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  2 13:58:49.102: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  2 13:58:49.105: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  2 13:58:51.102: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  2 13:58:51.105: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  2 13:58:53.102: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  2 13:58:53.105: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  2 13:58:55.102: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  2 13:58:55.105: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  2 13:58:57.102: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  2 13:58:57.111: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  2 13:58:59.102: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  2 13:58:59.105: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:58:59.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-fgnzf" for this suite.
Sep  2 13:59:21.125: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:59:21.158: INFO: namespace: e2e-tests-container-lifecycle-hook-fgnzf, resource: bindings, ignored listing per whitelist
Sep  2 13:59:21.222: INFO: namespace e2e-tests-container-lifecycle-hook-fgnzf deletion completed in 22.113729397s

• [SLOW TEST:58.331 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:59:21.223: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-l4nlb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-l4nlb
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-l4nlb
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-l4nlb
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-l4nlb
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-l4nlb
Sep  2 13:59:25.416: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-l4nlb, name: ss-0, uid: dd135797-cd89-11e9-96cb-060c8a2202ce, status phase: Pending. Waiting for statefulset controller to delete.
Sep  2 13:59:27.574: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-l4nlb, name: ss-0, uid: dd135797-cd89-11e9-96cb-060c8a2202ce, status phase: Failed. Waiting for statefulset controller to delete.
Sep  2 13:59:27.582: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-l4nlb, name: ss-0, uid: dd135797-cd89-11e9-96cb-060c8a2202ce, status phase: Failed. Waiting for statefulset controller to delete.
Sep  2 13:59:27.588: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-l4nlb
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-l4nlb
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-l4nlb and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Sep  2 13:59:31.613: INFO: Deleting all statefulset in ns e2e-tests-statefulset-l4nlb
Sep  2 13:59:31.616: INFO: Scaling statefulset ss to 0
Sep  2 13:59:41.634: INFO: Waiting for statefulset status.replicas updated to 0
Sep  2 13:59:41.637: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:59:41.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-l4nlb" for this suite.
Sep  2 13:59:47.668: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 13:59:47.729: INFO: namespace: e2e-tests-statefulset-l4nlb, resource: bindings, ignored listing per whitelist
Sep  2 13:59:47.768: INFO: namespace e2e-tests-statefulset-l4nlb deletion completed in 6.116513506s

• [SLOW TEST:26.545 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 13:59:47.768: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-namespaces-5twk8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-8894x
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-d2thc
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 13:59:54.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-5twk8" for this suite.
Sep  2 14:00:00.263: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:00:00.320: INFO: namespace: e2e-tests-namespaces-5twk8, resource: bindings, ignored listing per whitelist
Sep  2 14:00:00.361: INFO: namespace e2e-tests-namespaces-5twk8 deletion completed in 6.114374197s
STEP: Destroying namespace "e2e-tests-nsdeletetest-8894x" for this suite.
Sep  2 14:00:00.365: INFO: Namespace e2e-tests-nsdeletetest-8894x was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-d2thc" for this suite.
Sep  2 14:00:06.381: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:00:06.465: INFO: namespace: e2e-tests-nsdeletetest-d2thc, resource: bindings, ignored listing per whitelist
Sep  2 14:00:06.478: INFO: namespace e2e-tests-nsdeletetest-d2thc deletion completed in 6.113081557s

• [SLOW TEST:18.710 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:00:06.478: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-htj8q
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-8882
STEP: Creating a pod to test atomic-volume-subpath
Sep  2 14:00:06.661: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-8882" in namespace "e2e-tests-subpath-htj8q" to be "success or failure"
Sep  2 14:00:06.664: INFO: Pod "pod-subpath-test-projected-8882": Phase="Pending", Reason="", readiness=false. Elapsed: 2.347529ms
Sep  2 14:00:08.667: INFO: Pod "pod-subpath-test-projected-8882": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005614894s
Sep  2 14:00:10.670: INFO: Pod "pod-subpath-test-projected-8882": Phase="Running", Reason="", readiness=false. Elapsed: 4.009017458s
Sep  2 14:00:12.679: INFO: Pod "pod-subpath-test-projected-8882": Phase="Running", Reason="", readiness=false. Elapsed: 6.018040455s
Sep  2 14:00:14.683: INFO: Pod "pod-subpath-test-projected-8882": Phase="Running", Reason="", readiness=false. Elapsed: 8.021614276s
Sep  2 14:00:16.686: INFO: Pod "pod-subpath-test-projected-8882": Phase="Running", Reason="", readiness=false. Elapsed: 10.025096207s
Sep  2 14:00:18.690: INFO: Pod "pod-subpath-test-projected-8882": Phase="Running", Reason="", readiness=false. Elapsed: 12.028511192s
Sep  2 14:00:20.693: INFO: Pod "pod-subpath-test-projected-8882": Phase="Running", Reason="", readiness=false. Elapsed: 14.032104043s
Sep  2 14:00:22.703: INFO: Pod "pod-subpath-test-projected-8882": Phase="Running", Reason="", readiness=false. Elapsed: 16.041298276s
Sep  2 14:00:24.706: INFO: Pod "pod-subpath-test-projected-8882": Phase="Running", Reason="", readiness=false. Elapsed: 18.044689818s
Sep  2 14:00:26.709: INFO: Pod "pod-subpath-test-projected-8882": Phase="Running", Reason="", readiness=false. Elapsed: 20.048121564s
Sep  2 14:00:28.713: INFO: Pod "pod-subpath-test-projected-8882": Phase="Running", Reason="", readiness=false. Elapsed: 22.051626751s
Sep  2 14:00:30.716: INFO: Pod "pod-subpath-test-projected-8882": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.055164689s
STEP: Saw pod success
Sep  2 14:00:30.716: INFO: Pod "pod-subpath-test-projected-8882" satisfied condition "success or failure"
Sep  2 14:00:30.719: INFO: Trying to get logs from node ip-192-168-169-21.us-west-2.compute.internal pod pod-subpath-test-projected-8882 container test-container-subpath-projected-8882: <nil>
STEP: delete the pod
Sep  2 14:00:30.737: INFO: Waiting for pod pod-subpath-test-projected-8882 to disappear
Sep  2 14:00:30.739: INFO: Pod pod-subpath-test-projected-8882 no longer exists
STEP: Deleting pod pod-subpath-test-projected-8882
Sep  2 14:00:30.739: INFO: Deleting pod "pod-subpath-test-projected-8882" in namespace "e2e-tests-subpath-htj8q"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:00:30.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-htj8q" for this suite.
Sep  2 14:00:36.760: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:00:36.787: INFO: namespace: e2e-tests-subpath-htj8q, resource: bindings, ignored listing per whitelist
Sep  2 14:00:36.860: INFO: namespace e2e-tests-subpath-htj8q deletion completed in 6.115221083s

• [SLOW TEST:30.382 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:00:36.860: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-6r6r4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-6r6r4
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-6r6r4 to expose endpoints map[]
Sep  2 14:00:37.044: INFO: Get endpoints failed (3.776867ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Sep  2 14:00:38.049: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-6r6r4 exposes endpoints map[] (1.008512994s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-6r6r4
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-6r6r4 to expose endpoints map[pod1:[80]]
Sep  2 14:00:40.076: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-6r6r4 exposes endpoints map[pod1:[80]] (2.019873228s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-6r6r4
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-6r6r4 to expose endpoints map[pod1:[80] pod2:[80]]
Sep  2 14:00:42.108: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-6r6r4 exposes endpoints map[pod1:[80] pod2:[80]] (2.027477455s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-6r6r4
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-6r6r4 to expose endpoints map[pod2:[80]]
Sep  2 14:00:43.132: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-6r6r4 exposes endpoints map[pod2:[80]] (1.018544531s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-6r6r4
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-6r6r4 to expose endpoints map[]
Sep  2 14:00:44.145: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-6r6r4 exposes endpoints map[] (1.008337824s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:00:44.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-6r6r4" for this suite.
Sep  2 14:00:50.190: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:00:50.223: INFO: namespace: e2e-tests-services-6r6r4, resource: bindings, ignored listing per whitelist
Sep  2 14:00:50.294: INFO: namespace e2e-tests-services-6r6r4 deletion completed in 6.120729183s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:13.434 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:00:50.294: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-2kssx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-121d3702-cd8a-11e9-b90e-8ed318f3d3c6
STEP: Creating a pod to test consume secrets
Sep  2 14:00:50.472: INFO: Waiting up to 5m0s for pod "pod-secrets-121de981-cd8a-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-secrets-2kssx" to be "success or failure"
Sep  2 14:00:50.474: INFO: Pod "pod-secrets-121de981-cd8a-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.266646ms
Sep  2 14:00:52.477: INFO: Pod "pod-secrets-121de981-cd8a-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005411647s
STEP: Saw pod success
Sep  2 14:00:52.477: INFO: Pod "pod-secrets-121de981-cd8a-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 14:00:52.480: INFO: Trying to get logs from node ip-192-168-169-21.us-west-2.compute.internal pod pod-secrets-121de981-cd8a-11e9-b90e-8ed318f3d3c6 container secret-volume-test: <nil>
STEP: delete the pod
Sep  2 14:00:52.496: INFO: Waiting for pod pod-secrets-121de981-cd8a-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 14:00:52.499: INFO: Pod pod-secrets-121de981-cd8a-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:00:52.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-2kssx" for this suite.
Sep  2 14:00:58.518: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:00:58.607: INFO: namespace: e2e-tests-secrets-2kssx, resource: bindings, ignored listing per whitelist
Sep  2 14:00:58.623: INFO: namespace e2e-tests-secrets-2kssx deletion completed in 6.120573151s

• [SLOW TEST:8.329 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:00:58.623: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-b2scq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Sep  2 14:00:58.791: INFO: Waiting up to 5m0s for pod "pod-171344fb-cd8a-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-emptydir-b2scq" to be "success or failure"
Sep  2 14:00:58.793: INFO: Pod "pod-171344fb-cd8a-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.285318ms
Sep  2 14:01:00.797: INFO: Pod "pod-171344fb-cd8a-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005629303s
STEP: Saw pod success
Sep  2 14:01:00.797: INFO: Pod "pod-171344fb-cd8a-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 14:01:00.799: INFO: Trying to get logs from node ip-192-168-169-21.us-west-2.compute.internal pod pod-171344fb-cd8a-11e9-b90e-8ed318f3d3c6 container test-container: <nil>
STEP: delete the pod
Sep  2 14:01:00.817: INFO: Waiting for pod pod-171344fb-cd8a-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 14:01:00.820: INFO: Pod pod-171344fb-cd8a-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:01:00.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-b2scq" for this suite.
Sep  2 14:01:06.840: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:01:06.854: INFO: namespace: e2e-tests-emptydir-b2scq, resource: bindings, ignored listing per whitelist
Sep  2 14:01:06.942: INFO: namespace e2e-tests-emptydir-b2scq deletion completed in 6.118420014s

• [SLOW TEST:8.319 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:01:06.942: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-k2j74
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Sep  2 14:01:07.130: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Sep  2 14:01:07.137: INFO: Number of nodes with available pods: 0
Sep  2 14:01:07.137: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Sep  2 14:01:07.150: INFO: Number of nodes with available pods: 0
Sep  2 14:01:07.150: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:01:08.154: INFO: Number of nodes with available pods: 0
Sep  2 14:01:08.154: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:01:09.154: INFO: Number of nodes with available pods: 0
Sep  2 14:01:09.154: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:01:10.154: INFO: Number of nodes with available pods: 0
Sep  2 14:01:10.154: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:01:11.154: INFO: Number of nodes with available pods: 1
Sep  2 14:01:11.154: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Sep  2 14:01:11.166: INFO: Number of nodes with available pods: 1
Sep  2 14:01:11.167: INFO: Number of running nodes: 0, number of available pods: 1
Sep  2 14:01:12.170: INFO: Number of nodes with available pods: 0
Sep  2 14:01:12.170: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Sep  2 14:01:12.177: INFO: Number of nodes with available pods: 0
Sep  2 14:01:12.177: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:01:13.181: INFO: Number of nodes with available pods: 0
Sep  2 14:01:13.181: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:01:14.181: INFO: Number of nodes with available pods: 0
Sep  2 14:01:14.181: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:01:15.186: INFO: Number of nodes with available pods: 0
Sep  2 14:01:15.186: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:01:16.181: INFO: Number of nodes with available pods: 0
Sep  2 14:01:16.181: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:01:17.181: INFO: Number of nodes with available pods: 0
Sep  2 14:01:17.181: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:01:18.181: INFO: Number of nodes with available pods: 0
Sep  2 14:01:18.181: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:01:19.181: INFO: Number of nodes with available pods: 0
Sep  2 14:01:19.181: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:01:20.181: INFO: Number of nodes with available pods: 0
Sep  2 14:01:20.181: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:01:21.181: INFO: Number of nodes with available pods: 0
Sep  2 14:01:21.181: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:01:22.181: INFO: Number of nodes with available pods: 0
Sep  2 14:01:22.181: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:01:23.181: INFO: Number of nodes with available pods: 0
Sep  2 14:01:23.181: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:01:24.181: INFO: Number of nodes with available pods: 0
Sep  2 14:01:24.181: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:01:25.181: INFO: Number of nodes with available pods: 0
Sep  2 14:01:25.181: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:01:26.191: INFO: Number of nodes with available pods: 0
Sep  2 14:01:26.191: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:01:27.180: INFO: Number of nodes with available pods: 0
Sep  2 14:01:27.180: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:01:28.181: INFO: Number of nodes with available pods: 0
Sep  2 14:01:28.181: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:01:29.181: INFO: Number of nodes with available pods: 0
Sep  2 14:01:29.181: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:01:30.181: INFO: Number of nodes with available pods: 0
Sep  2 14:01:30.181: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:01:31.181: INFO: Number of nodes with available pods: 0
Sep  2 14:01:31.181: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:01:32.181: INFO: Number of nodes with available pods: 0
Sep  2 14:01:32.181: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:01:33.181: INFO: Number of nodes with available pods: 0
Sep  2 14:01:33.181: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:01:34.181: INFO: Number of nodes with available pods: 0
Sep  2 14:01:34.181: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:01:35.181: INFO: Number of nodes with available pods: 0
Sep  2 14:01:35.181: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:01:36.181: INFO: Number of nodes with available pods: 0
Sep  2 14:01:36.181: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:01:37.186: INFO: Number of nodes with available pods: 0
Sep  2 14:01:37.186: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:01:38.181: INFO: Number of nodes with available pods: 0
Sep  2 14:01:38.181: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:01:39.181: INFO: Number of nodes with available pods: 0
Sep  2 14:01:39.181: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:01:40.181: INFO: Number of nodes with available pods: 0
Sep  2 14:01:40.181: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:01:41.181: INFO: Number of nodes with available pods: 0
Sep  2 14:01:41.181: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:01:42.181: INFO: Number of nodes with available pods: 0
Sep  2 14:01:42.181: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:01:43.181: INFO: Number of nodes with available pods: 0
Sep  2 14:01:43.181: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:01:44.181: INFO: Number of nodes with available pods: 0
Sep  2 14:01:44.181: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:01:45.181: INFO: Number of nodes with available pods: 0
Sep  2 14:01:45.181: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:01:46.181: INFO: Number of nodes with available pods: 0
Sep  2 14:01:46.181: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:01:47.181: INFO: Number of nodes with available pods: 0
Sep  2 14:01:47.181: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:01:48.187: INFO: Number of nodes with available pods: 0
Sep  2 14:01:48.187: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:01:49.181: INFO: Number of nodes with available pods: 0
Sep  2 14:01:49.181: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:01:50.181: INFO: Number of nodes with available pods: 1
Sep  2 14:01:50.181: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-k2j74, will wait for the garbage collector to delete the pods
Sep  2 14:01:50.252: INFO: Deleting DaemonSet.extensions daemon-set took: 10.424357ms
Sep  2 14:01:50.352: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.205164ms
Sep  2 14:02:23.761: INFO: Number of nodes with available pods: 0
Sep  2 14:02:23.761: INFO: Number of running nodes: 0, number of available pods: 0
Sep  2 14:02:23.764: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-k2j74/daemonsets","resourceVersion":"2098560"},"items":null}

Sep  2 14:02:23.766: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-k2j74/pods","resourceVersion":"2098560"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:02:23.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-k2j74" for this suite.
Sep  2 14:02:29.804: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:02:29.895: INFO: namespace: e2e-tests-daemonsets-k2j74, resource: bindings, ignored listing per whitelist
Sep  2 14:02:29.905: INFO: namespace e2e-tests-daemonsets-k2j74 deletion completed in 6.118021078s

• [SLOW TEST:82.963 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:02:29.905: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-qbf4v
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Sep  2 14:02:30.070: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Sep  2 14:02:30.070: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 create -f - --namespace=e2e-tests-kubectl-qbf4v'
Sep  2 14:02:31.175: INFO: stderr: ""
Sep  2 14:02:31.175: INFO: stdout: "service/redis-slave created\n"
Sep  2 14:02:31.175: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Sep  2 14:02:31.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 create -f - --namespace=e2e-tests-kubectl-qbf4v'
Sep  2 14:02:31.394: INFO: stderr: ""
Sep  2 14:02:31.394: INFO: stdout: "service/redis-master created\n"
Sep  2 14:02:31.394: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Sep  2 14:02:31.394: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 create -f - --namespace=e2e-tests-kubectl-qbf4v'
Sep  2 14:02:31.620: INFO: stderr: ""
Sep  2 14:02:31.620: INFO: stdout: "service/frontend created\n"
Sep  2 14:02:31.620: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Sep  2 14:02:31.620: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 create -f - --namespace=e2e-tests-kubectl-qbf4v'
Sep  2 14:02:33.242: INFO: stderr: ""
Sep  2 14:02:33.242: INFO: stdout: "deployment.extensions/frontend created\n"
Sep  2 14:02:33.242: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Sep  2 14:02:33.242: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 create -f - --namespace=e2e-tests-kubectl-qbf4v'
Sep  2 14:02:33.399: INFO: stderr: ""
Sep  2 14:02:33.399: INFO: stdout: "deployment.extensions/redis-master created\n"
Sep  2 14:02:33.400: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Sep  2 14:02:33.400: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 create -f - --namespace=e2e-tests-kubectl-qbf4v'
Sep  2 14:02:33.553: INFO: stderr: ""
Sep  2 14:02:33.553: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Sep  2 14:02:33.553: INFO: Waiting for all frontend pods to be Running.
Sep  2 14:02:38.603: INFO: Waiting for frontend to serve content.
Sep  2 14:02:39.632: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection refused [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection refu...', 111)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stream in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Sep  2 14:02:44.648: INFO: Trying to add a new entry to the guestbook.
Sep  2 14:02:44.661: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Sep  2 14:02:44.674: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-qbf4v'
Sep  2 14:02:44.764: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  2 14:02:44.765: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Sep  2 14:02:44.765: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-qbf4v'
Sep  2 14:02:44.861: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  2 14:02:44.861: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Sep  2 14:02:44.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-qbf4v'
Sep  2 14:02:44.955: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  2 14:02:44.955: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Sep  2 14:02:44.955: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-qbf4v'
Sep  2 14:02:45.030: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  2 14:02:45.030: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Sep  2 14:02:45.030: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-qbf4v'
Sep  2 14:02:45.120: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  2 14:02:45.120: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Sep  2 14:02:45.120: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-qbf4v'
Sep  2 14:02:45.204: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  2 14:02:45.204: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:02:45.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-qbf4v" for this suite.
Sep  2 14:03:31.223: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:03:31.233: INFO: namespace: e2e-tests-kubectl-qbf4v, resource: bindings, ignored listing per whitelist
Sep  2 14:03:31.317: INFO: namespace e2e-tests-kubectl-qbf4v deletion completed in 46.109787529s

• [SLOW TEST:61.412 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:03:31.317: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-xcbvh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-72172398-cd8a-11e9-b90e-8ed318f3d3c6
STEP: Creating a pod to test consume configMaps
Sep  2 14:03:31.492: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-7217cd0d-cd8a-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-projected-xcbvh" to be "success or failure"
Sep  2 14:03:31.494: INFO: Pod "pod-projected-configmaps-7217cd0d-cd8a-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.297931ms
Sep  2 14:03:33.498: INFO: Pod "pod-projected-configmaps-7217cd0d-cd8a-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005543859s
STEP: Saw pod success
Sep  2 14:03:33.498: INFO: Pod "pod-projected-configmaps-7217cd0d-cd8a-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 14:03:33.500: INFO: Trying to get logs from node ip-192-168-169-21.us-west-2.compute.internal pod pod-projected-configmaps-7217cd0d-cd8a-11e9-b90e-8ed318f3d3c6 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep  2 14:03:33.518: INFO: Waiting for pod pod-projected-configmaps-7217cd0d-cd8a-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 14:03:33.521: INFO: Pod pod-projected-configmaps-7217cd0d-cd8a-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:03:33.521: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xcbvh" for this suite.
Sep  2 14:03:39.540: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:03:39.551: INFO: namespace: e2e-tests-projected-xcbvh, resource: bindings, ignored listing per whitelist
Sep  2 14:03:39.636: INFO: namespace e2e-tests-projected-xcbvh deletion completed in 6.111695477s

• [SLOW TEST:8.319 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:03:39.636: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-7dl86
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0902 14:04:19.831278      19 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep  2 14:04:19.831: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:04:19.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-7dl86" for this suite.
Sep  2 14:04:25.850: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:04:25.927: INFO: namespace: e2e-tests-gc-7dl86, resource: bindings, ignored listing per whitelist
Sep  2 14:04:25.946: INFO: namespace e2e-tests-gc-7dl86 deletion completed in 6.111769206s

• [SLOW TEST:46.310 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:04:25.946: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-5chfk
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secret-namespace-l9xwm
STEP: Creating secret with name secret-test-92a6d5e5-cd8a-11e9-b90e-8ed318f3d3c6
STEP: Creating a pod to test consume secrets
Sep  2 14:04:26.258: INFO: Waiting up to 5m0s for pod "pod-secrets-92bc7fba-cd8a-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-secrets-5chfk" to be "success or failure"
Sep  2 14:04:26.261: INFO: Pod "pod-secrets-92bc7fba-cd8a-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.353416ms
Sep  2 14:04:28.264: INFO: Pod "pod-secrets-92bc7fba-cd8a-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005401451s
STEP: Saw pod success
Sep  2 14:04:28.264: INFO: Pod "pod-secrets-92bc7fba-cd8a-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 14:04:28.266: INFO: Trying to get logs from node ip-192-168-169-21.us-west-2.compute.internal pod pod-secrets-92bc7fba-cd8a-11e9-b90e-8ed318f3d3c6 container secret-volume-test: <nil>
STEP: delete the pod
Sep  2 14:04:28.283: INFO: Waiting for pod pod-secrets-92bc7fba-cd8a-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 14:04:28.286: INFO: Pod pod-secrets-92bc7fba-cd8a-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:04:28.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-5chfk" for this suite.
Sep  2 14:04:34.305: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:04:34.328: INFO: namespace: e2e-tests-secrets-5chfk, resource: bindings, ignored listing per whitelist
Sep  2 14:04:34.401: INFO: namespace e2e-tests-secrets-5chfk deletion completed in 6.111932894s
STEP: Destroying namespace "e2e-tests-secret-namespace-l9xwm" for this suite.
Sep  2 14:04:40.423: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:04:40.501: INFO: namespace: e2e-tests-secret-namespace-l9xwm, resource: bindings, ignored listing per whitelist
Sep  2 14:04:40.523: INFO: namespace e2e-tests-secret-namespace-l9xwm deletion completed in 6.121936686s

• [SLOW TEST:14.577 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:04:40.523: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-jsrwm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-jsrwm
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-jsrwm
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-jsrwm
Sep  2 14:04:40.696: INFO: Found 0 stateful pods, waiting for 1
Sep  2 14:04:50.705: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Sep  2 14:04:50.708: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  2 14:04:50.866: INFO: stderr: ""
Sep  2 14:04:50.866: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  2 14:04:50.866: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  2 14:04:50.869: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Sep  2 14:05:00.879: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep  2 14:05:00.879: INFO: Waiting for statefulset status.replicas updated to 0
Sep  2 14:05:00.890: INFO: POD   NODE                                          PHASE    GRACE  CONDITIONS
Sep  2 14:05:00.890: INFO: ss-0  ip-192-168-169-21.us-west-2.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:04:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:04:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:04:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:04:40 +0000 UTC  }]
Sep  2 14:05:00.890: INFO: 
Sep  2 14:05:00.890: INFO: StatefulSet ss has not reached scale 3, at 1
Sep  2 14:05:01.894: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.99714355s
Sep  2 14:05:02.903: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.993311903s
Sep  2 14:05:03.907: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.983365737s
Sep  2 14:05:04.912: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.979520351s
Sep  2 14:05:05.916: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.975196462s
Sep  2 14:05:06.919: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.971397502s
Sep  2 14:05:07.923: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.967909588s
Sep  2 14:05:08.927: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.964107633s
Sep  2 14:05:09.931: INFO: Verifying statefulset ss doesn't scale past 3 for another 959.980853ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-jsrwm
Sep  2 14:05:10.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  2 14:05:11.090: INFO: stderr: ""
Sep  2 14:05:11.090: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  2 14:05:11.090: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  2 14:05:11.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  2 14:05:11.240: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Sep  2 14:05:11.240: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  2 14:05:11.240: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  2 14:05:11.240: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  2 14:05:11.386: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Sep  2 14:05:11.386: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  2 14:05:11.386: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  2 14:05:11.389: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Sep  2 14:05:21.399: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Sep  2 14:05:21.399: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Sep  2 14:05:21.399: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Sep  2 14:05:21.401: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  2 14:05:21.548: INFO: stderr: ""
Sep  2 14:05:21.548: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  2 14:05:21.548: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  2 14:05:21.549: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  2 14:05:21.690: INFO: stderr: ""
Sep  2 14:05:21.690: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  2 14:05:21.690: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  2 14:05:21.690: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  2 14:05:21.831: INFO: stderr: ""
Sep  2 14:05:21.831: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  2 14:05:21.831: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  2 14:05:21.831: INFO: Waiting for statefulset status.replicas updated to 0
Sep  2 14:05:21.837: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Sep  2 14:05:31.849: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep  2 14:05:31.849: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Sep  2 14:05:31.849: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Sep  2 14:05:31.857: INFO: POD   NODE                                          PHASE    GRACE  CONDITIONS
Sep  2 14:05:31.857: INFO: ss-0  ip-192-168-169-21.us-west-2.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:04:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:05:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:05:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:04:40 +0000 UTC  }]
Sep  2 14:05:31.857: INFO: ss-1  ip-192-168-6-156.us-west-2.compute.internal   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:05:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:05:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:05:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:05:00 +0000 UTC  }]
Sep  2 14:05:31.858: INFO: ss-2  ip-192-168-55-191.us-west-2.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:05:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:05:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:05:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:05:00 +0000 UTC  }]
Sep  2 14:05:31.858: INFO: 
Sep  2 14:05:31.858: INFO: StatefulSet ss has not reached scale 0, at 3
Sep  2 14:05:32.861: INFO: POD   NODE                                          PHASE    GRACE  CONDITIONS
Sep  2 14:05:32.861: INFO: ss-0  ip-192-168-169-21.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:04:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:05:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:05:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:04:40 +0000 UTC  }]
Sep  2 14:05:32.861: INFO: ss-1  ip-192-168-6-156.us-west-2.compute.internal   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:05:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:05:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:05:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:05:00 +0000 UTC  }]
Sep  2 14:05:32.861: INFO: ss-2  ip-192-168-55-191.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:05:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:05:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:05:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:05:00 +0000 UTC  }]
Sep  2 14:05:32.861: INFO: 
Sep  2 14:05:32.861: INFO: StatefulSet ss has not reached scale 0, at 3
Sep  2 14:05:33.864: INFO: POD   NODE                                          PHASE    GRACE  CONDITIONS
Sep  2 14:05:33.864: INFO: ss-0  ip-192-168-169-21.us-west-2.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:04:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:05:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:05:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:04:40 +0000 UTC  }]
Sep  2 14:05:33.865: INFO: ss-2  ip-192-168-55-191.us-west-2.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:05:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:05:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:05:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:05:00 +0000 UTC  }]
Sep  2 14:05:33.865: INFO: 
Sep  2 14:05:33.865: INFO: StatefulSet ss has not reached scale 0, at 2
Sep  2 14:05:34.868: INFO: POD   NODE                                          PHASE    GRACE  CONDITIONS
Sep  2 14:05:34.868: INFO: ss-2  ip-192-168-55-191.us-west-2.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:05:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:05:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:05:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:05:00 +0000 UTC  }]
Sep  2 14:05:34.868: INFO: 
Sep  2 14:05:34.868: INFO: StatefulSet ss has not reached scale 0, at 1
Sep  2 14:05:35.872: INFO: POD   NODE                                          PHASE    GRACE  CONDITIONS
Sep  2 14:05:35.872: INFO: ss-2  ip-192-168-55-191.us-west-2.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:05:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:05:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:05:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:05:00 +0000 UTC  }]
Sep  2 14:05:35.872: INFO: 
Sep  2 14:05:35.872: INFO: StatefulSet ss has not reached scale 0, at 1
Sep  2 14:05:36.875: INFO: POD   NODE                                          PHASE    GRACE  CONDITIONS
Sep  2 14:05:36.875: INFO: ss-2  ip-192-168-55-191.us-west-2.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:05:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:05:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:05:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:05:00 +0000 UTC  }]
Sep  2 14:05:36.875: INFO: 
Sep  2 14:05:36.875: INFO: StatefulSet ss has not reached scale 0, at 1
Sep  2 14:05:37.878: INFO: POD   NODE                                          PHASE    GRACE  CONDITIONS
Sep  2 14:05:37.878: INFO: ss-2  ip-192-168-55-191.us-west-2.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:05:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:05:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:05:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:05:00 +0000 UTC  }]
Sep  2 14:05:37.878: INFO: 
Sep  2 14:05:37.878: INFO: StatefulSet ss has not reached scale 0, at 1
Sep  2 14:05:38.882: INFO: POD   NODE                                          PHASE    GRACE  CONDITIONS
Sep  2 14:05:38.882: INFO: ss-2  ip-192-168-55-191.us-west-2.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:05:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:05:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:05:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:05:00 +0000 UTC  }]
Sep  2 14:05:38.882: INFO: 
Sep  2 14:05:38.882: INFO: StatefulSet ss has not reached scale 0, at 1
Sep  2 14:05:39.886: INFO: POD   NODE                                          PHASE    GRACE  CONDITIONS
Sep  2 14:05:39.886: INFO: ss-2  ip-192-168-55-191.us-west-2.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:05:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:05:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:05:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:05:00 +0000 UTC  }]
Sep  2 14:05:39.886: INFO: 
Sep  2 14:05:39.886: INFO: StatefulSet ss has not reached scale 0, at 1
Sep  2 14:05:40.889: INFO: POD   NODE                                          PHASE    GRACE  CONDITIONS
Sep  2 14:05:40.889: INFO: ss-2  ip-192-168-55-191.us-west-2.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:05:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:05:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:05:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:05:00 +0000 UTC  }]
Sep  2 14:05:40.889: INFO: 
Sep  2 14:05:40.889: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-jsrwm
Sep  2 14:05:41.898: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  2 14:05:41.992: INFO: rc: 1
Sep  2 14:05:41.992: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc001c48ae0 exit status 1 <nil> <nil> true [0xc000153960 0xc000153aa0 0xc000153b48] [0xc000153960 0xc000153aa0 0xc000153b48] [0xc000153a70 0xc000153b10] [0x92f8e0 0x92f8e0] 0xc00101c4e0 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Sep  2 14:05:51.993: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  2 14:05:52.055: INFO: rc: 1
Sep  2 14:05:52.055: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000e133b0 exit status 1 <nil> <nil> true [0xc000c7a250 0xc000c7a268 0xc000c7a280] [0xc000c7a250 0xc000c7a268 0xc000c7a280] [0xc000c7a260 0xc000c7a278] [0x92f8e0 0x92f8e0] 0xc0025b1380 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Sep  2 14:06:02.056: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  2 14:06:02.117: INFO: rc: 1
Sep  2 14:06:02.117: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001c48e70 exit status 1 <nil> <nil> true [0xc000153b50 0xc000153bb0 0xc000153c50] [0xc000153b50 0xc000153bb0 0xc000153c50] [0xc000153ba0 0xc000153c28] [0x92f8e0 0x92f8e0] 0xc00101c7e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Sep  2 14:06:12.117: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  2 14:06:12.178: INFO: rc: 1
Sep  2 14:06:12.178: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000e13770 exit status 1 <nil> <nil> true [0xc000c7a288 0xc000c7a2a0 0xc000c7a2b8] [0xc000c7a288 0xc000c7a2a0 0xc000c7a2b8] [0xc000c7a298 0xc000c7a2b0] [0x92f8e0 0x92f8e0] 0xc0025b17a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Sep  2 14:06:22.178: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  2 14:06:22.241: INFO: rc: 1
Sep  2 14:06:22.241: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0021bc6f0 exit status 1 <nil> <nil> true [0xc0016fa118 0xc0016fa130 0xc0016fa170] [0xc0016fa118 0xc0016fa130 0xc0016fa170] [0xc0016fa128 0xc0016fa168] [0x92f8e0 0x92f8e0] 0xc002701ce0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Sep  2 14:06:32.241: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  2 14:06:32.305: INFO: rc: 1
Sep  2 14:06:32.305: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001c49230 exit status 1 <nil> <nil> true [0xc000153ca8 0xc000153d30 0xc000153dd0] [0xc000153ca8 0xc000153d30 0xc000153dd0] [0xc000153d28 0xc000153dc8] [0x92f8e0 0x92f8e0] 0xc00101cae0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Sep  2 14:06:42.305: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  2 14:06:42.366: INFO: rc: 1
Sep  2 14:06:42.366: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001c495f0 exit status 1 <nil> <nil> true [0xc000153ea0 0xc00148e008 0xc00148e020] [0xc000153ea0 0xc00148e008 0xc00148e020] [0xc00148e000 0xc00148e018] [0x92f8e0 0x92f8e0] 0xc00101cde0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Sep  2 14:06:52.367: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  2 14:06:52.428: INFO: rc: 1
Sep  2 14:06:52.428: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000e13b30 exit status 1 <nil> <nil> true [0xc000c7a2c0 0xc000c7a2d8 0xc000c7a2f8] [0xc000c7a2c0 0xc000c7a2d8 0xc000c7a2f8] [0xc000c7a2d0 0xc000c7a2f0] [0x92f8e0 0x92f8e0] 0xc0025b1bc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Sep  2 14:07:02.429: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  2 14:07:02.501: INFO: rc: 1
Sep  2 14:07:02.501: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000e13ef0 exit status 1 <nil> <nil> true [0xc000c7a308 0xc000c7a320 0xc000c7a338] [0xc000c7a308 0xc000c7a320 0xc000c7a338] [0xc000c7a318 0xc000c7a330] [0x92f8e0 0x92f8e0] 0xc00204e0c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Sep  2 14:07:12.502: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  2 14:07:12.562: INFO: rc: 1
Sep  2 14:07:12.562: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0013f2450 exit status 1 <nil> <nil> true [0xc000153258 0xc000153420 0xc0001534f0] [0xc000153258 0xc000153420 0xc0001534f0] [0xc000153338 0xc000153470] [0x92f8e0 0x92f8e0] 0xc0025b0240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Sep  2 14:07:22.563: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  2 14:07:22.624: INFO: rc: 1
Sep  2 14:07:22.625: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0023447e0 exit status 1 <nil> <nil> true [0xc0003be158 0xc0003bf078 0xc0003bf458] [0xc0003be158 0xc0003bf078 0xc0003bf458] [0xc0003bef28 0xc0003bf438] [0x92f8e0 0x92f8e0] 0xc0016764e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Sep  2 14:07:32.625: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  2 14:07:32.685: INFO: rc: 1
Sep  2 14:07:32.685: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002344ba0 exit status 1 <nil> <nil> true [0xc0003bf5b0 0xc0003bf880 0xc0003bf960] [0xc0003bf5b0 0xc0003bf880 0xc0003bf960] [0xc0003bf770 0xc0003bf948] [0x92f8e0 0x92f8e0] 0xc001676d20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Sep  2 14:07:42.685: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  2 14:07:42.749: INFO: rc: 1
Sep  2 14:07:42.749: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0013f2870 exit status 1 <nil> <nil> true [0xc000153570 0xc000153608 0xc0001537c8] [0xc000153570 0xc000153608 0xc0001537c8] [0xc0001535c0 0xc000153700] [0x92f8e0 0x92f8e0] 0xc0025b0660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Sep  2 14:07:52.750: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  2 14:07:52.813: INFO: rc: 1
Sep  2 14:07:52.813: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002344f90 exit status 1 <nil> <nil> true [0xc0003bf9c8 0xc0003bfa10 0xc0003bfab8] [0xc0003bf9c8 0xc0003bfa10 0xc0003bfab8] [0xc0003bfa00 0xc0003bfa90] [0x92f8e0 0x92f8e0] 0xc0016774a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Sep  2 14:08:02.813: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  2 14:08:02.879: INFO: rc: 1
Sep  2 14:08:02.879: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00211c480 exit status 1 <nil> <nil> true [0xc00148e000 0xc00148e018 0xc00148e030] [0xc00148e000 0xc00148e018 0xc00148e030] [0xc00148e010 0xc00148e028] [0x92f8e0 0x92f8e0] 0xc00101c2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Sep  2 14:08:12.879: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  2 14:08:12.943: INFO: rc: 1
Sep  2 14:08:12.944: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0013f2cf0 exit status 1 <nil> <nil> true [0xc0001537d8 0xc0001538e8 0xc000153960] [0xc0001537d8 0xc0001538e8 0xc000153960] [0xc0001538b8 0xc000153958] [0x92f8e0 0x92f8e0] 0xc0025b0c60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Sep  2 14:08:22.944: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  2 14:08:23.020: INFO: rc: 1
Sep  2 14:08:23.021: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002345380 exit status 1 <nil> <nil> true [0xc0003bfac0 0xc0003bfb50 0xc0003bfb90] [0xc0003bfac0 0xc0003bfb50 0xc0003bfb90] [0xc0003bfb08 0xc0003bfb88] [0x92f8e0 0x92f8e0] 0xc001677920 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Sep  2 14:08:33.021: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  2 14:08:33.084: INFO: rc: 1
Sep  2 14:08:33.084: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00220a6c0 exit status 1 <nil> <nil> true [0xc0016fa038 0xc0016fa088 0xc0016fa0c8] [0xc0016fa038 0xc0016fa088 0xc0016fa0c8] [0xc0016fa080 0xc0016fa0b0] [0x92f8e0 0x92f8e0] 0xc0027005a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Sep  2 14:08:43.085: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  2 14:08:43.149: INFO: rc: 1
Sep  2 14:08:43.149: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00211c900 exit status 1 <nil> <nil> true [0xc00148e038 0xc00148e050 0xc00148e068] [0xc00148e038 0xc00148e050 0xc00148e068] [0xc00148e048 0xc00148e060] [0x92f8e0 0x92f8e0] 0xc00101c5a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Sep  2 14:08:53.149: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  2 14:08:53.214: INFO: rc: 1
Sep  2 14:08:53.214: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0023457a0 exit status 1 <nil> <nil> true [0xc0003bfb98 0xc0003bfbd8 0xc0003bfc58] [0xc0003bfb98 0xc0003bfbd8 0xc0003bfc58] [0xc0003bfbd0 0xc0003bfc40] [0x92f8e0 0x92f8e0] 0xc001677c80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Sep  2 14:09:03.214: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  2 14:09:03.278: INFO: rc: 1
Sep  2 14:09:03.278: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0013f2480 exit status 1 <nil> <nil> true [0xc0001532a8 0xc000153458 0xc000153570] [0xc0001532a8 0xc000153458 0xc000153570] [0xc000153420 0xc0001534f0] [0x92f8e0 0x92f8e0] 0xc0025b0240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Sep  2 14:09:13.279: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  2 14:09:13.343: INFO: rc: 1
Sep  2 14:09:13.343: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00220a6f0 exit status 1 <nil> <nil> true [0xc0003be158 0xc0003bf078 0xc0003bf458] [0xc0003be158 0xc0003bf078 0xc0003bf458] [0xc0003bef28 0xc0003bf438] [0x92f8e0 0x92f8e0] 0xc0016764e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Sep  2 14:09:23.343: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  2 14:09:23.405: INFO: rc: 1
Sep  2 14:09:23.405: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002344810 exit status 1 <nil> <nil> true [0xc0016fa038 0xc0016fa088 0xc0016fa0c8] [0xc0016fa038 0xc0016fa088 0xc0016fa0c8] [0xc0016fa080 0xc0016fa0b0] [0x92f8e0 0x92f8e0] 0xc0027005a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Sep  2 14:09:33.405: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  2 14:09:33.469: INFO: rc: 1
Sep  2 14:09:33.469: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0013f2840 exit status 1 <nil> <nil> true [0xc000153590 0xc0001536d0 0xc0001537d8] [0xc000153590 0xc0001536d0 0xc0001537d8] [0xc000153608 0xc0001537c8] [0x92f8e0 0x92f8e0] 0xc0025b0660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Sep  2 14:09:43.469: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  2 14:09:43.531: INFO: rc: 1
Sep  2 14:09:43.531: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00220aab0 exit status 1 <nil> <nil> true [0xc0003bf5b0 0xc0003bf880 0xc0003bf960] [0xc0003bf5b0 0xc0003bf880 0xc0003bf960] [0xc0003bf770 0xc0003bf948] [0x92f8e0 0x92f8e0] 0xc001676d20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Sep  2 14:09:53.531: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  2 14:09:53.597: INFO: rc: 1
Sep  2 14:09:53.597: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00211c4e0 exit status 1 <nil> <nil> true [0xc00148e000 0xc00148e018 0xc00148e030] [0xc00148e000 0xc00148e018 0xc00148e030] [0xc00148e010 0xc00148e028] [0x92f8e0 0x92f8e0] 0xc00101c2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Sep  2 14:10:03.597: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  2 14:10:03.659: INFO: rc: 1
Sep  2 14:10:03.659: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00211c990 exit status 1 <nil> <nil> true [0xc00148e038 0xc00148e050 0xc00148e068] [0xc00148e038 0xc00148e050 0xc00148e068] [0xc00148e048 0xc00148e060] [0x92f8e0 0x92f8e0] 0xc00101c5a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Sep  2 14:10:13.659: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  2 14:10:13.724: INFO: rc: 1
Sep  2 14:10:13.724: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002344c00 exit status 1 <nil> <nil> true [0xc0016fa0d0 0xc0016fa118 0xc0016fa130] [0xc0016fa0d0 0xc0016fa118 0xc0016fa130] [0xc0016fa0e0 0xc0016fa128] [0x92f8e0 0x92f8e0] 0xc002700900 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Sep  2 14:10:23.725: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  2 14:10:23.792: INFO: rc: 1
Sep  2 14:10:23.792: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002344ff0 exit status 1 <nil> <nil> true [0xc0016fa150 0xc0016fa178 0xc0016fa1b8] [0xc0016fa150 0xc0016fa178 0xc0016fa1b8] [0xc0016fa170 0xc0016fa1a0] [0x92f8e0 0x92f8e0] 0xc002700c00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Sep  2 14:10:33.792: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  2 14:10:33.853: INFO: rc: 1
Sep  2 14:10:33.853: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0013f2d80 exit status 1 <nil> <nil> true [0xc000153818 0xc000153920 0xc000153a18] [0xc000153818 0xc000153920 0xc000153a18] [0xc0001538e8 0xc000153960] [0x92f8e0 0x92f8e0] 0xc0025b0c60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Sep  2 14:10:43.853: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-jsrwm ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  2 14:10:43.915: INFO: rc: 1
Sep  2 14:10:43.915: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: 
Sep  2 14:10:43.915: INFO: Scaling statefulset ss to 0
Sep  2 14:10:43.929: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Sep  2 14:10:43.932: INFO: Deleting all statefulset in ns e2e-tests-statefulset-jsrwm
Sep  2 14:10:43.934: INFO: Scaling statefulset ss to 0
Sep  2 14:10:43.942: INFO: Waiting for statefulset status.replicas updated to 0
Sep  2 14:10:43.944: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:10:43.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-jsrwm" for this suite.
Sep  2 14:10:49.973: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:10:50.000: INFO: namespace: e2e-tests-statefulset-jsrwm, resource: bindings, ignored listing per whitelist
Sep  2 14:10:50.069: INFO: namespace e2e-tests-statefulset-jsrwm deletion completed in 6.111792061s

• [SLOW TEST:369.546 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:10:50.070: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-mbsmq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-779bc938-cd8b-11e9-b90e-8ed318f3d3c6
STEP: Creating a pod to test consume secrets
Sep  2 14:10:50.246: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-779c7aab-cd8b-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-projected-mbsmq" to be "success or failure"
Sep  2 14:10:50.248: INFO: Pod "pod-projected-secrets-779c7aab-cd8b-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.233546ms
Sep  2 14:10:52.251: INFO: Pod "pod-projected-secrets-779c7aab-cd8b-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005409645s
STEP: Saw pod success
Sep  2 14:10:52.251: INFO: Pod "pod-projected-secrets-779c7aab-cd8b-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 14:10:52.253: INFO: Trying to get logs from node ip-192-168-169-21.us-west-2.compute.internal pod pod-projected-secrets-779c7aab-cd8b-11e9-b90e-8ed318f3d3c6 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep  2 14:10:52.271: INFO: Waiting for pod pod-projected-secrets-779c7aab-cd8b-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 14:10:52.274: INFO: Pod pod-projected-secrets-779c7aab-cd8b-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:10:52.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mbsmq" for this suite.
Sep  2 14:10:58.292: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:10:58.344: INFO: namespace: e2e-tests-projected-mbsmq, resource: bindings, ignored listing per whitelist
Sep  2 14:10:58.391: INFO: namespace e2e-tests-projected-mbsmq deletion completed in 6.113797222s

• [SLOW TEST:8.321 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:10:58.391: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-lzfwh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Sep  2 14:10:58.557: INFO: Waiting up to 5m0s for pod "pod-7c909c7c-cd8b-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-emptydir-lzfwh" to be "success or failure"
Sep  2 14:10:58.559: INFO: Pod "pod-7c909c7c-cd8b-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.224394ms
Sep  2 14:11:00.562: INFO: Pod "pod-7c909c7c-cd8b-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005346614s
STEP: Saw pod success
Sep  2 14:11:00.562: INFO: Pod "pod-7c909c7c-cd8b-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 14:11:00.564: INFO: Trying to get logs from node ip-192-168-169-21.us-west-2.compute.internal pod pod-7c909c7c-cd8b-11e9-b90e-8ed318f3d3c6 container test-container: <nil>
STEP: delete the pod
Sep  2 14:11:00.581: INFO: Waiting for pod pod-7c909c7c-cd8b-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 14:11:00.584: INFO: Pod pod-7c909c7c-cd8b-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:11:00.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-lzfwh" for this suite.
Sep  2 14:11:06.603: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:11:06.659: INFO: namespace: e2e-tests-emptydir-lzfwh, resource: bindings, ignored listing per whitelist
Sep  2 14:11:06.702: INFO: namespace e2e-tests-emptydir-lzfwh deletion completed in 6.114411563s

• [SLOW TEST:8.311 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:11:06.702: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-m7rdj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Sep  2 14:11:06.873: INFO: Waiting up to 5m0s for pod "downwardapi-volume-818599c9-cd8b-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-downward-api-m7rdj" to be "success or failure"
Sep  2 14:11:06.876: INFO: Pod "downwardapi-volume-818599c9-cd8b-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.328568ms
Sep  2 14:11:08.879: INFO: Pod "downwardapi-volume-818599c9-cd8b-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005708898s
STEP: Saw pod success
Sep  2 14:11:08.879: INFO: Pod "downwardapi-volume-818599c9-cd8b-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 14:11:08.881: INFO: Trying to get logs from node ip-192-168-169-21.us-west-2.compute.internal pod downwardapi-volume-818599c9-cd8b-11e9-b90e-8ed318f3d3c6 container client-container: <nil>
STEP: delete the pod
Sep  2 14:11:08.899: INFO: Waiting for pod downwardapi-volume-818599c9-cd8b-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 14:11:08.901: INFO: Pod downwardapi-volume-818599c9-cd8b-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:11:08.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-m7rdj" for this suite.
Sep  2 14:11:14.927: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:11:14.967: INFO: namespace: e2e-tests-downward-api-m7rdj, resource: bindings, ignored listing per whitelist
Sep  2 14:11:15.029: INFO: namespace e2e-tests-downward-api-m7rdj deletion completed in 6.124517832s

• [SLOW TEST:8.328 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:11:15.030: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-hostpath-pd25p
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Sep  2 14:11:15.196: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-pd25p" to be "success or failure"
Sep  2 14:11:15.198: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.363808ms
Sep  2 14:11:17.201: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005641588s
Sep  2 14:11:19.205: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009253396s
STEP: Saw pod success
Sep  2 14:11:19.205: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Sep  2 14:11:19.208: INFO: Trying to get logs from node ip-192-168-169-21.us-west-2.compute.internal pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Sep  2 14:11:19.224: INFO: Waiting for pod pod-host-path-test to disappear
Sep  2 14:11:19.226: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:11:19.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-pd25p" for this suite.
Sep  2 14:11:25.251: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:11:25.260: INFO: namespace: e2e-tests-hostpath-pd25p, resource: bindings, ignored listing per whitelist
Sep  2 14:11:25.355: INFO: namespace e2e-tests-hostpath-pd25p deletion completed in 6.125902887s

• [SLOW TEST:10.326 seconds]
[sig-storage] HostPath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:11:25.356: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-www5r
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:11:27.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-www5r" for this suite.
Sep  2 14:12:09.568: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:12:09.641: INFO: namespace: e2e-tests-kubelet-test-www5r, resource: bindings, ignored listing per whitelist
Sep  2 14:12:09.679: INFO: namespace e2e-tests-kubelet-test-www5r deletion completed in 42.129208582s

• [SLOW TEST:44.323 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:12:09.679: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-gwrwn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Sep  2 14:12:09.851: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a70f3b7b-cd8b-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-projected-gwrwn" to be "success or failure"
Sep  2 14:12:09.853: INFO: Pod "downwardapi-volume-a70f3b7b-cd8b-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.28111ms
Sep  2 14:12:11.857: INFO: Pod "downwardapi-volume-a70f3b7b-cd8b-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005488385s
STEP: Saw pod success
Sep  2 14:12:11.857: INFO: Pod "downwardapi-volume-a70f3b7b-cd8b-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 14:12:11.859: INFO: Trying to get logs from node ip-192-168-169-21.us-west-2.compute.internal pod downwardapi-volume-a70f3b7b-cd8b-11e9-b90e-8ed318f3d3c6 container client-container: <nil>
STEP: delete the pod
Sep  2 14:12:11.876: INFO: Waiting for pod downwardapi-volume-a70f3b7b-cd8b-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 14:12:11.878: INFO: Pod downwardapi-volume-a70f3b7b-cd8b-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:12:11.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gwrwn" for this suite.
Sep  2 14:12:17.898: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:12:17.954: INFO: namespace: e2e-tests-projected-gwrwn, resource: bindings, ignored listing per whitelist
Sep  2 14:12:17.997: INFO: namespace e2e-tests-projected-gwrwn deletion completed in 6.115384302s

• [SLOW TEST:8.318 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:12:17.997: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-5hp72
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Sep  2 14:12:20.698: INFO: Successfully updated pod "annotationupdateac03e66d-cd8b-11e9-b90e-8ed318f3d3c6"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:12:22.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-5hp72" for this suite.
Sep  2 14:12:44.734: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:12:44.746: INFO: namespace: e2e-tests-downward-api-5hp72, resource: bindings, ignored listing per whitelist
Sep  2 14:12:44.833: INFO: namespace e2e-tests-downward-api-5hp72 deletion completed in 22.115455042s

• [SLOW TEST:26.836 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:12:44.833: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-b52s5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0902 14:12:55.038084      19 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep  2 14:12:55.038: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:12:55.038: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-b52s5" for this suite.
Sep  2 14:13:01.057: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:13:01.121: INFO: namespace: e2e-tests-gc-b52s5, resource: bindings, ignored listing per whitelist
Sep  2 14:13:01.162: INFO: namespace e2e-tests-gc-b52s5 deletion completed in 6.121451214s

• [SLOW TEST:16.329 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:13:01.163: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replication-controller-5vkgd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Sep  2 14:13:01.341: INFO: Pod name pod-release: Found 0 pods out of 1
Sep  2 14:13:06.350: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:13:07.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-5vkgd" for this suite.
Sep  2 14:13:13.382: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:13:13.415: INFO: namespace: e2e-tests-replication-controller-5vkgd, resource: bindings, ignored listing per whitelist
Sep  2 14:13:13.480: INFO: namespace e2e-tests-replication-controller-5vkgd deletion completed in 6.114213237s

• [SLOW TEST:12.317 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:13:13.480: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-zc9mp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Sep  2 14:13:13.667: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-zc9mp,SelfLink:/api/v1/namespaces/e2e-tests-watch-zc9mp/configmaps/e2e-watch-test-resource-version,UID:cd16a26d-cd8b-11e9-a575-0a854009c708,ResourceVersion:2100583,Generation:0,CreationTimestamp:2019-09-02 14:13:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep  2 14:13:13.667: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-zc9mp,SelfLink:/api/v1/namespaces/e2e-tests-watch-zc9mp/configmaps/e2e-watch-test-resource-version,UID:cd16a26d-cd8b-11e9-a575-0a854009c708,ResourceVersion:2100584,Generation:0,CreationTimestamp:2019-09-02 14:13:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:13:13.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-zc9mp" for this suite.
Sep  2 14:13:19.686: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:13:19.721: INFO: namespace: e2e-tests-watch-zc9mp, resource: bindings, ignored listing per whitelist
Sep  2 14:13:19.789: INFO: namespace e2e-tests-watch-zc9mp deletion completed in 6.119052488s

• [SLOW TEST:6.310 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:13:19.790: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-p5vvr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Sep  2 14:13:19.949: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 create -f - --namespace=e2e-tests-kubectl-p5vvr'
Sep  2 14:13:20.223: INFO: stderr: ""
Sep  2 14:13:20.223: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep  2 14:13:20.223: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-p5vvr'
Sep  2 14:13:20.289: INFO: stderr: ""
Sep  2 14:13:20.289: INFO: stdout: "update-demo-nautilus-4l96w update-demo-nautilus-9ks9n "
Sep  2 14:13:20.289: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 get pods update-demo-nautilus-4l96w -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p5vvr'
Sep  2 14:13:20.350: INFO: stderr: ""
Sep  2 14:13:20.350: INFO: stdout: ""
Sep  2 14:13:20.350: INFO: update-demo-nautilus-4l96w is created but not running
Sep  2 14:13:25.350: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-p5vvr'
Sep  2 14:13:25.418: INFO: stderr: ""
Sep  2 14:13:25.418: INFO: stdout: "update-demo-nautilus-4l96w update-demo-nautilus-9ks9n "
Sep  2 14:13:25.418: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 get pods update-demo-nautilus-4l96w -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p5vvr'
Sep  2 14:13:25.484: INFO: stderr: ""
Sep  2 14:13:25.484: INFO: stdout: "true"
Sep  2 14:13:25.484: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 get pods update-demo-nautilus-4l96w -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p5vvr'
Sep  2 14:13:25.547: INFO: stderr: ""
Sep  2 14:13:25.547: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  2 14:13:25.547: INFO: validating pod update-demo-nautilus-4l96w
Sep  2 14:13:25.550: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  2 14:13:25.550: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  2 14:13:25.550: INFO: update-demo-nautilus-4l96w is verified up and running
Sep  2 14:13:25.550: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 get pods update-demo-nautilus-9ks9n -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p5vvr'
Sep  2 14:13:25.615: INFO: stderr: ""
Sep  2 14:13:25.615: INFO: stdout: "true"
Sep  2 14:13:25.615: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 get pods update-demo-nautilus-9ks9n -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p5vvr'
Sep  2 14:13:25.683: INFO: stderr: ""
Sep  2 14:13:25.683: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  2 14:13:25.683: INFO: validating pod update-demo-nautilus-9ks9n
Sep  2 14:13:25.688: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  2 14:13:25.689: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  2 14:13:25.689: INFO: update-demo-nautilus-9ks9n is verified up and running
STEP: rolling-update to new replication controller
Sep  2 14:13:25.690: INFO: scanned /root for discovery docs: <nil>
Sep  2 14:13:25.690: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-p5vvr'
Sep  2 14:13:48.068: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Sep  2 14:13:48.068: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep  2 14:13:48.068: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-p5vvr'
Sep  2 14:13:48.136: INFO: stderr: ""
Sep  2 14:13:48.136: INFO: stdout: "update-demo-kitten-h58wd update-demo-kitten-stgtp "
Sep  2 14:13:48.136: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 get pods update-demo-kitten-h58wd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p5vvr'
Sep  2 14:13:48.198: INFO: stderr: ""
Sep  2 14:13:48.198: INFO: stdout: "true"
Sep  2 14:13:48.198: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 get pods update-demo-kitten-h58wd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p5vvr'
Sep  2 14:13:48.260: INFO: stderr: ""
Sep  2 14:13:48.260: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Sep  2 14:13:48.260: INFO: validating pod update-demo-kitten-h58wd
Sep  2 14:13:48.264: INFO: got data: {
  "image": "kitten.jpg"
}

Sep  2 14:13:48.264: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Sep  2 14:13:48.264: INFO: update-demo-kitten-h58wd is verified up and running
Sep  2 14:13:48.264: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 get pods update-demo-kitten-stgtp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p5vvr'
Sep  2 14:13:48.328: INFO: stderr: ""
Sep  2 14:13:48.328: INFO: stdout: "true"
Sep  2 14:13:48.328: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 get pods update-demo-kitten-stgtp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p5vvr'
Sep  2 14:13:48.398: INFO: stderr: ""
Sep  2 14:13:48.398: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Sep  2 14:13:48.398: INFO: validating pod update-demo-kitten-stgtp
Sep  2 14:13:48.403: INFO: got data: {
  "image": "kitten.jpg"
}

Sep  2 14:13:48.403: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Sep  2 14:13:48.403: INFO: update-demo-kitten-stgtp is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:13:48.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-p5vvr" for this suite.
Sep  2 14:14:10.423: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:14:10.520: INFO: namespace: e2e-tests-kubectl-p5vvr, resource: bindings, ignored listing per whitelist
Sep  2 14:14:10.522: INFO: namespace e2e-tests-kubectl-p5vvr deletion completed in 22.115706774s

• [SLOW TEST:50.733 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:14:10.523: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-h68lz
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-h68lz
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep  2 14:14:10.689: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep  2 14:14:34.775: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.166.113:8080/dial?request=hostName&protocol=http&host=192.168.189.136&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-h68lz PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  2 14:14:34.775: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
Sep  2 14:14:34.863: INFO: Waiting for endpoints: map[]
Sep  2 14:14:34.866: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.166.113:8080/dial?request=hostName&protocol=http&host=192.168.75.155&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-h68lz PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  2 14:14:34.866: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
Sep  2 14:14:34.950: INFO: Waiting for endpoints: map[]
Sep  2 14:14:34.953: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.166.113:8080/dial?request=hostName&protocol=http&host=192.168.20.219&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-h68lz PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  2 14:14:34.953: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
Sep  2 14:14:35.045: INFO: Waiting for endpoints: map[]
Sep  2 14:14:35.048: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.166.113:8080/dial?request=hostName&protocol=http&host=192.168.63.158&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-h68lz PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  2 14:14:35.048: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
Sep  2 14:14:35.139: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:14:35.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-h68lz" for this suite.
Sep  2 14:14:57.165: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:14:57.200: INFO: namespace: e2e-tests-pod-network-test-h68lz, resource: bindings, ignored listing per whitelist
Sep  2 14:14:57.265: INFO: namespace e2e-tests-pod-network-test-h68lz deletion completed in 22.121000216s

• [SLOW TEST:46.742 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:14:57.265: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-cd5pz
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-0af4971d-cd8c-11e9-b90e-8ed318f3d3c6
STEP: Creating secret with name s-test-opt-upd-0af4976b-cd8c-11e9-b90e-8ed318f3d3c6
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-0af4971d-cd8c-11e9-b90e-8ed318f3d3c6
STEP: Updating secret s-test-opt-upd-0af4976b-cd8c-11e9-b90e-8ed318f3d3c6
STEP: Creating secret with name s-test-opt-create-0af4978d-cd8c-11e9-b90e-8ed318f3d3c6
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:15:01.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-cd5pz" for this suite.
Sep  2 14:15:23.554: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:15:23.578: INFO: namespace: e2e-tests-secrets-cd5pz, resource: bindings, ignored listing per whitelist
Sep  2 14:15:23.655: INFO: namespace e2e-tests-secrets-cd5pz deletion completed in 22.116827096s

• [SLOW TEST:26.390 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:15:23.655: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-wrapper-smcwl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Sep  2 14:15:24.027: INFO: Pod name wrapped-volume-race-1ac50885-cd8c-11e9-b90e-8ed318f3d3c6: Found 3 pods out of 5
Sep  2 14:15:29.033: INFO: Pod name wrapped-volume-race-1ac50885-cd8c-11e9-b90e-8ed318f3d3c6: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-1ac50885-cd8c-11e9-b90e-8ed318f3d3c6 in namespace e2e-tests-emptydir-wrapper-smcwl, will wait for the garbage collector to delete the pods
Sep  2 14:17:11.109: INFO: Deleting ReplicationController wrapped-volume-race-1ac50885-cd8c-11e9-b90e-8ed318f3d3c6 took: 5.664504ms
Sep  2 14:17:11.209: INFO: Terminating ReplicationController wrapped-volume-race-1ac50885-cd8c-11e9-b90e-8ed318f3d3c6 pods took: 100.236665ms
STEP: Creating RC which spawns configmap-volume pods
Sep  2 14:17:47.728: INFO: Pod name wrapped-volume-race-707145f6-cd8c-11e9-b90e-8ed318f3d3c6: Found 0 pods out of 5
Sep  2 14:17:52.735: INFO: Pod name wrapped-volume-race-707145f6-cd8c-11e9-b90e-8ed318f3d3c6: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-707145f6-cd8c-11e9-b90e-8ed318f3d3c6 in namespace e2e-tests-emptydir-wrapper-smcwl, will wait for the garbage collector to delete the pods
Sep  2 14:19:36.812: INFO: Deleting ReplicationController wrapped-volume-race-707145f6-cd8c-11e9-b90e-8ed318f3d3c6 took: 6.914743ms
Sep  2 14:19:36.912: INFO: Terminating ReplicationController wrapped-volume-race-707145f6-cd8c-11e9-b90e-8ed318f3d3c6 pods took: 100.214028ms
STEP: Creating RC which spawns configmap-volume pods
Sep  2 14:20:17.632: INFO: Pod name wrapped-volume-race-c9caa4a3-cd8c-11e9-b90e-8ed318f3d3c6: Found 0 pods out of 5
Sep  2 14:20:22.639: INFO: Pod name wrapped-volume-race-c9caa4a3-cd8c-11e9-b90e-8ed318f3d3c6: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-c9caa4a3-cd8c-11e9-b90e-8ed318f3d3c6 in namespace e2e-tests-emptydir-wrapper-smcwl, will wait for the garbage collector to delete the pods
Sep  2 14:22:36.730: INFO: Deleting ReplicationController wrapped-volume-race-c9caa4a3-cd8c-11e9-b90e-8ed318f3d3c6 took: 10.318682ms
Sep  2 14:22:36.830: INFO: Terminating ReplicationController wrapped-volume-race-c9caa4a3-cd8c-11e9-b90e-8ed318f3d3c6 pods took: 100.285637ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:23:11.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-smcwl" for this suite.
Sep  2 14:23:17.285: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:23:17.376: INFO: namespace: e2e-tests-emptydir-wrapper-smcwl, resource: bindings, ignored listing per whitelist
Sep  2 14:23:17.378: INFO: namespace e2e-tests-emptydir-wrapper-smcwl deletion completed in 6.1089377s

• [SLOW TEST:473.723 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:23:17.378: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-xn7sn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-fhw9
STEP: Creating a pod to test atomic-volume-subpath
Sep  2 14:23:17.557: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-fhw9" in namespace "e2e-tests-subpath-xn7sn" to be "success or failure"
Sep  2 14:23:17.560: INFO: Pod "pod-subpath-test-downwardapi-fhw9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.360299ms
Sep  2 14:23:19.562: INFO: Pod "pod-subpath-test-downwardapi-fhw9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005200749s
Sep  2 14:23:21.571: INFO: Pod "pod-subpath-test-downwardapi-fhw9": Phase="Running", Reason="", readiness=false. Elapsed: 4.014116625s
Sep  2 14:23:23.575: INFO: Pod "pod-subpath-test-downwardapi-fhw9": Phase="Running", Reason="", readiness=false. Elapsed: 6.017285454s
Sep  2 14:23:25.578: INFO: Pod "pod-subpath-test-downwardapi-fhw9": Phase="Running", Reason="", readiness=false. Elapsed: 8.020708494s
Sep  2 14:23:27.581: INFO: Pod "pod-subpath-test-downwardapi-fhw9": Phase="Running", Reason="", readiness=false. Elapsed: 10.024212015s
Sep  2 14:23:29.585: INFO: Pod "pod-subpath-test-downwardapi-fhw9": Phase="Running", Reason="", readiness=false. Elapsed: 12.027811752s
Sep  2 14:23:31.594: INFO: Pod "pod-subpath-test-downwardapi-fhw9": Phase="Running", Reason="", readiness=false. Elapsed: 14.03656694s
Sep  2 14:23:33.597: INFO: Pod "pod-subpath-test-downwardapi-fhw9": Phase="Running", Reason="", readiness=false. Elapsed: 16.040029266s
Sep  2 14:23:35.601: INFO: Pod "pod-subpath-test-downwardapi-fhw9": Phase="Running", Reason="", readiness=false. Elapsed: 18.043380275s
Sep  2 14:23:37.604: INFO: Pod "pod-subpath-test-downwardapi-fhw9": Phase="Running", Reason="", readiness=false. Elapsed: 20.046513372s
Sep  2 14:23:39.607: INFO: Pod "pod-subpath-test-downwardapi-fhw9": Phase="Running", Reason="", readiness=false. Elapsed: 22.049836166s
Sep  2 14:23:41.616: INFO: Pod "pod-subpath-test-downwardapi-fhw9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.058589418s
STEP: Saw pod success
Sep  2 14:23:41.616: INFO: Pod "pod-subpath-test-downwardapi-fhw9" satisfied condition "success or failure"
Sep  2 14:23:41.618: INFO: Trying to get logs from node ip-192-168-169-21.us-west-2.compute.internal pod pod-subpath-test-downwardapi-fhw9 container test-container-subpath-downwardapi-fhw9: <nil>
STEP: delete the pod
Sep  2 14:23:41.637: INFO: Waiting for pod pod-subpath-test-downwardapi-fhw9 to disappear
Sep  2 14:23:41.639: INFO: Pod pod-subpath-test-downwardapi-fhw9 no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-fhw9
Sep  2 14:23:41.639: INFO: Deleting pod "pod-subpath-test-downwardapi-fhw9" in namespace "e2e-tests-subpath-xn7sn"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:23:41.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-xn7sn" for this suite.
Sep  2 14:23:47.661: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:23:47.673: INFO: namespace: e2e-tests-subpath-xn7sn, resource: bindings, ignored listing per whitelist
Sep  2 14:23:47.754: INFO: namespace e2e-tests-subpath-xn7sn deletion completed in 6.109016541s

• [SLOW TEST:30.375 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:23:47.754: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-brtrx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-4724c9c6-cd8d-11e9-b90e-8ed318f3d3c6
STEP: Creating a pod to test consume secrets
Sep  2 14:23:47.929: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-47257b65-cd8d-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-projected-brtrx" to be "success or failure"
Sep  2 14:23:47.932: INFO: Pod "pod-projected-secrets-47257b65-cd8d-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.316061ms
Sep  2 14:23:49.935: INFO: Pod "pod-projected-secrets-47257b65-cd8d-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005375285s
STEP: Saw pod success
Sep  2 14:23:49.935: INFO: Pod "pod-projected-secrets-47257b65-cd8d-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 14:23:49.937: INFO: Trying to get logs from node ip-192-168-169-21.us-west-2.compute.internal pod pod-projected-secrets-47257b65-cd8d-11e9-b90e-8ed318f3d3c6 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep  2 14:23:49.954: INFO: Waiting for pod pod-projected-secrets-47257b65-cd8d-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 14:23:49.956: INFO: Pod pod-projected-secrets-47257b65-cd8d-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:23:49.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-brtrx" for this suite.
Sep  2 14:23:55.975: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:23:56.056: INFO: namespace: e2e-tests-projected-brtrx, resource: bindings, ignored listing per whitelist
Sep  2 14:23:56.073: INFO: namespace e2e-tests-projected-brtrx deletion completed in 6.112891826s

• [SLOW TEST:8.319 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:23:56.073: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-vs7p2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-4c194261-cd8d-11e9-b90e-8ed318f3d3c6
STEP: Creating a pod to test consume configMaps
Sep  2 14:23:56.240: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4c19b7f1-cd8d-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-projected-vs7p2" to be "success or failure"
Sep  2 14:23:56.242: INFO: Pod "pod-projected-configmaps-4c19b7f1-cd8d-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.365584ms
Sep  2 14:23:58.245: INFO: Pod "pod-projected-configmaps-4c19b7f1-cd8d-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005528711s
STEP: Saw pod success
Sep  2 14:23:58.245: INFO: Pod "pod-projected-configmaps-4c19b7f1-cd8d-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 14:23:58.248: INFO: Trying to get logs from node ip-192-168-169-21.us-west-2.compute.internal pod pod-projected-configmaps-4c19b7f1-cd8d-11e9-b90e-8ed318f3d3c6 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep  2 14:23:58.265: INFO: Waiting for pod pod-projected-configmaps-4c19b7f1-cd8d-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 14:23:58.267: INFO: Pod pod-projected-configmaps-4c19b7f1-cd8d-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:23:58.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vs7p2" for this suite.
Sep  2 14:24:04.286: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:24:04.376: INFO: namespace: e2e-tests-projected-vs7p2, resource: bindings, ignored listing per whitelist
Sep  2 14:24:04.380: INFO: namespace e2e-tests-projected-vs7p2 deletion completed in 6.109171301s

• [SLOW TEST:8.307 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:24:04.380: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-wxdwp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Sep  2 14:24:04.546: INFO: namespace e2e-tests-kubectl-wxdwp
Sep  2 14:24:04.546: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 create -f - --namespace=e2e-tests-kubectl-wxdwp'
Sep  2 14:24:05.856: INFO: stderr: ""
Sep  2 14:24:05.857: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Sep  2 14:24:06.860: INFO: Selector matched 1 pods for map[app:redis]
Sep  2 14:24:06.860: INFO: Found 0 / 1
Sep  2 14:24:07.860: INFO: Selector matched 1 pods for map[app:redis]
Sep  2 14:24:07.860: INFO: Found 1 / 1
Sep  2 14:24:07.860: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Sep  2 14:24:07.863: INFO: Selector matched 1 pods for map[app:redis]
Sep  2 14:24:07.863: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep  2 14:24:07.863: INFO: wait on redis-master startup in e2e-tests-kubectl-wxdwp 
Sep  2 14:24:07.863: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 logs redis-master-sl8nl redis-master --namespace=e2e-tests-kubectl-wxdwp'
Sep  2 14:24:07.946: INFO: stderr: ""
Sep  2 14:24:07.946: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 02 Sep 14:24:06.965 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 02 Sep 14:24:06.965 # Server started, Redis version 3.2.12\n1:M 02 Sep 14:24:06.965 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 02 Sep 14:24:06.965 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Sep  2 14:24:07.946: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-wxdwp'
Sep  2 14:24:08.037: INFO: stderr: ""
Sep  2 14:24:08.037: INFO: stdout: "service/rm2 exposed\n"
Sep  2 14:24:08.041: INFO: Service rm2 in namespace e2e-tests-kubectl-wxdwp found.
STEP: exposing service
Sep  2 14:24:10.049: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-wxdwp'
Sep  2 14:24:10.133: INFO: stderr: ""
Sep  2 14:24:10.133: INFO: stdout: "service/rm3 exposed\n"
Sep  2 14:24:10.136: INFO: Service rm3 in namespace e2e-tests-kubectl-wxdwp found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:24:12.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wxdwp" for this suite.
Sep  2 14:24:34.164: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:24:34.187: INFO: namespace: e2e-tests-kubectl-wxdwp, resource: bindings, ignored listing per whitelist
Sep  2 14:24:34.256: INFO: namespace e2e-tests-kubectl-wxdwp deletion completed in 22.107729182s

• [SLOW TEST:29.876 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:24:34.256: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-ntf49
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Sep  2 14:24:36.446: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-62dcbb22-cd8d-11e9-b90e-8ed318f3d3c6", GenerateName:"", Namespace:"e2e-tests-pods-ntf49", SelfLink:"/api/v1/namespaces/e2e-tests-pods-ntf49/pods/pod-submit-remove-62dcbb22-cd8d-11e9-b90e-8ed318f3d3c6", UID:"62dd991f-cd8d-11e9-a575-0a854009c708", ResourceVersion:"2102567", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63703031074, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"422667001"}, Annotations:map[string]string{"kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-rdvn8", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0027b7800), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-rdvn8", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0028c6118), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-192-168-169-21.us-west-2.compute.internal", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0027015c0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0028c6150)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0028c6170)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0028c6178), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0028c617c)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703031074, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703031076, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703031076, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703031074, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.169.21", PodIP:"192.168.177.65", StartTime:(*v1.Time)(0xc00296a7a0), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc00296a7c0), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7", ContainerID:"docker://70876b91c0b651c9da1a9e13d1c72e15c4f66d2b7eb2745d873e8576034af814"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Sep  2 14:24:41.457: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:24:41.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-ntf49" for this suite.
Sep  2 14:24:47.485: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:24:47.546: INFO: namespace: e2e-tests-pods-ntf49, resource: bindings, ignored listing per whitelist
Sep  2 14:24:47.580: INFO: namespace e2e-tests-pods-ntf49 deletion completed in 6.116080311s

• [SLOW TEST:13.323 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:24:47.580: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-m2vqm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:24:47.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-m2vqm" for this suite.
Sep  2 14:24:53.782: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:24:53.846: INFO: namespace: e2e-tests-kubelet-test-m2vqm, resource: bindings, ignored listing per whitelist
Sep  2 14:24:53.875: INFO: namespace e2e-tests-kubelet-test-m2vqm deletion completed in 6.10805375s

• [SLOW TEST:6.295 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:24:53.875: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-629dj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Sep  2 14:24:54.041: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6e8d59f2-cd8d-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-downward-api-629dj" to be "success or failure"
Sep  2 14:24:54.043: INFO: Pod "downwardapi-volume-6e8d59f2-cd8d-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.256008ms
Sep  2 14:24:56.046: INFO: Pod "downwardapi-volume-6e8d59f2-cd8d-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005407583s
Sep  2 14:24:58.055: INFO: Pod "downwardapi-volume-6e8d59f2-cd8d-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.014157611s
Sep  2 14:25:00.058: INFO: Pod "downwardapi-volume-6e8d59f2-cd8d-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.017405134s
STEP: Saw pod success
Sep  2 14:25:00.058: INFO: Pod "downwardapi-volume-6e8d59f2-cd8d-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 14:25:00.061: INFO: Trying to get logs from node ip-192-168-77-237.us-west-2.compute.internal pod downwardapi-volume-6e8d59f2-cd8d-11e9-b90e-8ed318f3d3c6 container client-container: <nil>
STEP: delete the pod
Sep  2 14:25:00.080: INFO: Waiting for pod downwardapi-volume-6e8d59f2-cd8d-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 14:25:00.082: INFO: Pod downwardapi-volume-6e8d59f2-cd8d-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:25:00.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-629dj" for this suite.
Sep  2 14:25:06.102: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:25:06.123: INFO: namespace: e2e-tests-downward-api-629dj, resource: bindings, ignored listing per whitelist
Sep  2 14:25:06.196: INFO: namespace e2e-tests-downward-api-629dj deletion completed in 6.109317309s

• [SLOW TEST:12.320 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:25:06.196: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-66wg8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-66wg8
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Sep  2 14:25:06.373: INFO: Found 0 stateful pods, waiting for 3
Sep  2 14:25:16.383: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep  2 14:25:16.383: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep  2 14:25:16.383: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Sep  2 14:25:16.412: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Sep  2 14:25:26.504: INFO: Updating stateful set ss2
Sep  2 14:25:26.510: INFO: Waiting for Pod e2e-tests-statefulset-66wg8/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Sep  2 14:25:36.546: INFO: Found 1 stateful pods, waiting for 3
Sep  2 14:25:46.555: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep  2 14:25:46.555: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep  2 14:25:46.555: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Sep  2 14:25:46.580: INFO: Updating stateful set ss2
Sep  2 14:25:46.586: INFO: Waiting for Pod e2e-tests-statefulset-66wg8/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Sep  2 14:25:56.603: INFO: Waiting for Pod e2e-tests-statefulset-66wg8/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Sep  2 14:26:06.618: INFO: Updating stateful set ss2
Sep  2 14:26:06.624: INFO: Waiting for StatefulSet e2e-tests-statefulset-66wg8/ss2 to complete update
Sep  2 14:26:06.624: INFO: Waiting for Pod e2e-tests-statefulset-66wg8/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Sep  2 14:26:16.637: INFO: Waiting for StatefulSet e2e-tests-statefulset-66wg8/ss2 to complete update
Sep  2 14:26:16.637: INFO: Waiting for Pod e2e-tests-statefulset-66wg8/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Sep  2 14:26:26.649: INFO: Deleting all statefulset in ns e2e-tests-statefulset-66wg8
Sep  2 14:26:26.657: INFO: Scaling statefulset ss2 to 0
Sep  2 14:26:46.686: INFO: Waiting for statefulset status.replicas updated to 0
Sep  2 14:26:46.690: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:26:46.712: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-66wg8" for this suite.
Sep  2 14:26:52.732: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:26:52.780: INFO: namespace: e2e-tests-statefulset-66wg8, resource: bindings, ignored listing per whitelist
Sep  2 14:26:52.830: INFO: namespace e2e-tests-statefulset-66wg8 deletion completed in 6.114433649s

• [SLOW TEST:106.634 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:26:52.830: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-wrapper-8pj5z
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:26:55.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-8pj5z" for this suite.
Sep  2 14:27:01.060: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:27:01.085: INFO: namespace: e2e-tests-emptydir-wrapper-8pj5z, resource: bindings, ignored listing per whitelist
Sep  2 14:27:01.156: INFO: namespace e2e-tests-emptydir-wrapper-8pj5z deletion completed in 6.111272088s

• [SLOW TEST:8.326 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:27:01.156: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-5xwnl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-ba6a88b9-cd8d-11e9-b90e-8ed318f3d3c6
STEP: Creating a pod to test consume secrets
Sep  2 14:27:01.324: INFO: Waiting up to 5m0s for pod "pod-secrets-ba6b3e61-cd8d-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-secrets-5xwnl" to be "success or failure"
Sep  2 14:27:01.326: INFO: Pod "pod-secrets-ba6b3e61-cd8d-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.250881ms
Sep  2 14:27:03.329: INFO: Pod "pod-secrets-ba6b3e61-cd8d-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0054561s
STEP: Saw pod success
Sep  2 14:27:03.330: INFO: Pod "pod-secrets-ba6b3e61-cd8d-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 14:27:03.332: INFO: Trying to get logs from node ip-192-168-169-21.us-west-2.compute.internal pod pod-secrets-ba6b3e61-cd8d-11e9-b90e-8ed318f3d3c6 container secret-env-test: <nil>
STEP: delete the pod
Sep  2 14:27:03.349: INFO: Waiting for pod pod-secrets-ba6b3e61-cd8d-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 14:27:03.351: INFO: Pod pod-secrets-ba6b3e61-cd8d-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:27:03.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-5xwnl" for this suite.
Sep  2 14:27:09.375: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:27:09.448: INFO: namespace: e2e-tests-secrets-5xwnl, resource: bindings, ignored listing per whitelist
Sep  2 14:27:09.468: INFO: namespace e2e-tests-secrets-5xwnl deletion completed in 6.113194545s

• [SLOW TEST:8.312 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:27:09.469: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-namespaces-v9jvg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-rmvbz
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
Sep  2 14:27:11.785: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-bmfpd
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:27:35.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-v9jvg" for this suite.
Sep  2 14:27:41.967: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:27:41.978: INFO: namespace: e2e-tests-namespaces-v9jvg, resource: bindings, ignored listing per whitelist
Sep  2 14:27:42.062: INFO: namespace e2e-tests-namespaces-v9jvg deletion completed in 6.11014873s
STEP: Destroying namespace "e2e-tests-nsdeletetest-rmvbz" for this suite.
Sep  2 14:27:42.066: INFO: Namespace e2e-tests-nsdeletetest-rmvbz was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-bmfpd" for this suite.
Sep  2 14:27:48.082: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:27:48.145: INFO: namespace: e2e-tests-nsdeletetest-bmfpd, resource: bindings, ignored listing per whitelist
Sep  2 14:27:48.174: INFO: namespace e2e-tests-nsdeletetest-bmfpd deletion completed in 6.107569271s

• [SLOW TEST:38.705 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:27:48.174: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-pxlzp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Sep  2 14:28:14.359: INFO: Container started at 2019-09-02 14:27:49 +0000 UTC, pod became ready at 2019-09-02 14:28:13 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:28:14.359: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-pxlzp" for this suite.
Sep  2 14:28:36.384: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:28:36.413: INFO: namespace: e2e-tests-container-probe-pxlzp, resource: bindings, ignored listing per whitelist
Sep  2 14:28:36.481: INFO: namespace e2e-tests-container-probe-pxlzp deletion completed in 22.118412393s

• [SLOW TEST:48.307 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:28:36.481: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-qvpkn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Sep  2 14:28:36.651: INFO: Waiting up to 5m0s for pod "pod-f33d0a27-cd8d-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-emptydir-qvpkn" to be "success or failure"
Sep  2 14:28:36.654: INFO: Pod "pod-f33d0a27-cd8d-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.241023ms
Sep  2 14:28:38.657: INFO: Pod "pod-f33d0a27-cd8d-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005533579s
STEP: Saw pod success
Sep  2 14:28:38.657: INFO: Pod "pod-f33d0a27-cd8d-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 14:28:38.660: INFO: Trying to get logs from node ip-192-168-169-21.us-west-2.compute.internal pod pod-f33d0a27-cd8d-11e9-b90e-8ed318f3d3c6 container test-container: <nil>
STEP: delete the pod
Sep  2 14:28:38.677: INFO: Waiting for pod pod-f33d0a27-cd8d-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 14:28:38.680: INFO: Pod pod-f33d0a27-cd8d-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:28:38.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-qvpkn" for this suite.
Sep  2 14:28:44.699: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:28:44.756: INFO: namespace: e2e-tests-emptydir-qvpkn, resource: bindings, ignored listing per whitelist
Sep  2 14:28:44.792: INFO: namespace e2e-tests-emptydir-qvpkn deletion completed in 6.108815101s

• [SLOW TEST:8.311 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:28:44.792: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replicaset-tm8jj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Sep  2 14:28:49.985: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:28:50.999: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-tm8jj" for this suite.
Sep  2 14:29:13.017: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:29:13.034: INFO: namespace: e2e-tests-replicaset-tm8jj, resource: bindings, ignored listing per whitelist
Sep  2 14:29:13.111: INFO: namespace e2e-tests-replicaset-tm8jj deletion completed in 22.108774515s

• [SLOW TEST:28.319 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:29:13.111: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-pkl92
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-09125ae7-cd8e-11e9-b90e-8ed318f3d3c6
STEP: Creating a pod to test consume secrets
Sep  2 14:29:13.285: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-09130ad8-cd8e-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-projected-pkl92" to be "success or failure"
Sep  2 14:29:13.288: INFO: Pod "pod-projected-secrets-09130ad8-cd8e-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.313336ms
Sep  2 14:29:15.291: INFO: Pod "pod-projected-secrets-09130ad8-cd8e-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005600723s
STEP: Saw pod success
Sep  2 14:29:15.291: INFO: Pod "pod-projected-secrets-09130ad8-cd8e-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 14:29:15.293: INFO: Trying to get logs from node ip-192-168-169-21.us-west-2.compute.internal pod pod-projected-secrets-09130ad8-cd8e-11e9-b90e-8ed318f3d3c6 container secret-volume-test: <nil>
STEP: delete the pod
Sep  2 14:29:15.312: INFO: Waiting for pod pod-projected-secrets-09130ad8-cd8e-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 14:29:15.314: INFO: Pod pod-projected-secrets-09130ad8-cd8e-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:29:15.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pkl92" for this suite.
Sep  2 14:29:21.333: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:29:21.351: INFO: namespace: e2e-tests-projected-pkl92, resource: bindings, ignored listing per whitelist
Sep  2 14:29:21.426: INFO: namespace e2e-tests-projected-pkl92 deletion completed in 6.107962941s

• [SLOW TEST:8.315 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:29:21.426: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-95cdt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Sep  2 14:29:21.591: INFO: Waiting up to 5m0s for pod "pod-0e0645ee-cd8e-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-emptydir-95cdt" to be "success or failure"
Sep  2 14:29:21.593: INFO: Pod "pod-0e0645ee-cd8e-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.393745ms
Sep  2 14:29:23.596: INFO: Pod "pod-0e0645ee-cd8e-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005801907s
STEP: Saw pod success
Sep  2 14:29:23.596: INFO: Pod "pod-0e0645ee-cd8e-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 14:29:23.599: INFO: Trying to get logs from node ip-192-168-169-21.us-west-2.compute.internal pod pod-0e0645ee-cd8e-11e9-b90e-8ed318f3d3c6 container test-container: <nil>
STEP: delete the pod
Sep  2 14:29:23.616: INFO: Waiting for pod pod-0e0645ee-cd8e-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 14:29:23.618: INFO: Pod pod-0e0645ee-cd8e-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:29:23.618: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-95cdt" for this suite.
Sep  2 14:29:29.644: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:29:29.715: INFO: namespace: e2e-tests-emptydir-95cdt, resource: bindings, ignored listing per whitelist
Sep  2 14:29:29.735: INFO: namespace e2e-tests-emptydir-95cdt deletion completed in 6.112964478s

• [SLOW TEST:8.309 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:29:29.735: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-psbgq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Sep  2 14:29:30.412: INFO: Waiting up to 5m0s for pod "pod-service-account-1348374e-cd8e-11e9-b90e-8ed318f3d3c6-cvqf5" in namespace "e2e-tests-svcaccounts-psbgq" to be "success or failure"
Sep  2 14:29:30.414: INFO: Pod "pod-service-account-1348374e-cd8e-11e9-b90e-8ed318f3d3c6-cvqf5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.317742ms
Sep  2 14:29:32.417: INFO: Pod "pod-service-account-1348374e-cd8e-11e9-b90e-8ed318f3d3c6-cvqf5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005808188s
Sep  2 14:29:34.421: INFO: Pod "pod-service-account-1348374e-cd8e-11e9-b90e-8ed318f3d3c6-cvqf5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009255806s
STEP: Saw pod success
Sep  2 14:29:34.421: INFO: Pod "pod-service-account-1348374e-cd8e-11e9-b90e-8ed318f3d3c6-cvqf5" satisfied condition "success or failure"
Sep  2 14:29:34.423: INFO: Trying to get logs from node ip-192-168-169-21.us-west-2.compute.internal pod pod-service-account-1348374e-cd8e-11e9-b90e-8ed318f3d3c6-cvqf5 container token-test: <nil>
STEP: delete the pod
Sep  2 14:29:34.441: INFO: Waiting for pod pod-service-account-1348374e-cd8e-11e9-b90e-8ed318f3d3c6-cvqf5 to disappear
Sep  2 14:29:34.443: INFO: Pod pod-service-account-1348374e-cd8e-11e9-b90e-8ed318f3d3c6-cvqf5 no longer exists
STEP: Creating a pod to test consume service account root CA
Sep  2 14:29:34.448: INFO: Waiting up to 5m0s for pod "pod-service-account-1348374e-cd8e-11e9-b90e-8ed318f3d3c6-hjc57" in namespace "e2e-tests-svcaccounts-psbgq" to be "success or failure"
Sep  2 14:29:34.450: INFO: Pod "pod-service-account-1348374e-cd8e-11e9-b90e-8ed318f3d3c6-hjc57": Phase="Pending", Reason="", readiness=false. Elapsed: 2.351081ms
Sep  2 14:29:36.454: INFO: Pod "pod-service-account-1348374e-cd8e-11e9-b90e-8ed318f3d3c6-hjc57": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006067749s
Sep  2 14:29:38.457: INFO: Pod "pod-service-account-1348374e-cd8e-11e9-b90e-8ed318f3d3c6-hjc57": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009481358s
STEP: Saw pod success
Sep  2 14:29:38.457: INFO: Pod "pod-service-account-1348374e-cd8e-11e9-b90e-8ed318f3d3c6-hjc57" satisfied condition "success or failure"
Sep  2 14:29:38.460: INFO: Trying to get logs from node ip-192-168-169-21.us-west-2.compute.internal pod pod-service-account-1348374e-cd8e-11e9-b90e-8ed318f3d3c6-hjc57 container root-ca-test: <nil>
STEP: delete the pod
Sep  2 14:29:38.477: INFO: Waiting for pod pod-service-account-1348374e-cd8e-11e9-b90e-8ed318f3d3c6-hjc57 to disappear
Sep  2 14:29:38.480: INFO: Pod pod-service-account-1348374e-cd8e-11e9-b90e-8ed318f3d3c6-hjc57 no longer exists
STEP: Creating a pod to test consume service account namespace
Sep  2 14:29:38.484: INFO: Waiting up to 5m0s for pod "pod-service-account-1348374e-cd8e-11e9-b90e-8ed318f3d3c6-dbzvs" in namespace "e2e-tests-svcaccounts-psbgq" to be "success or failure"
Sep  2 14:29:38.486: INFO: Pod "pod-service-account-1348374e-cd8e-11e9-b90e-8ed318f3d3c6-dbzvs": Phase="Pending", Reason="", readiness=false. Elapsed: 2.211259ms
Sep  2 14:29:40.495: INFO: Pod "pod-service-account-1348374e-cd8e-11e9-b90e-8ed318f3d3c6-dbzvs": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011066665s
Sep  2 14:29:42.498: INFO: Pod "pod-service-account-1348374e-cd8e-11e9-b90e-8ed318f3d3c6-dbzvs": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014261811s
STEP: Saw pod success
Sep  2 14:29:42.498: INFO: Pod "pod-service-account-1348374e-cd8e-11e9-b90e-8ed318f3d3c6-dbzvs" satisfied condition "success or failure"
Sep  2 14:29:42.501: INFO: Trying to get logs from node ip-192-168-169-21.us-west-2.compute.internal pod pod-service-account-1348374e-cd8e-11e9-b90e-8ed318f3d3c6-dbzvs container namespace-test: <nil>
STEP: delete the pod
Sep  2 14:29:42.518: INFO: Waiting for pod pod-service-account-1348374e-cd8e-11e9-b90e-8ed318f3d3c6-dbzvs to disappear
Sep  2 14:29:42.520: INFO: Pod pod-service-account-1348374e-cd8e-11e9-b90e-8ed318f3d3c6-dbzvs no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:29:42.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-psbgq" for this suite.
Sep  2 14:29:48.539: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:29:48.571: INFO: namespace: e2e-tests-svcaccounts-psbgq, resource: bindings, ignored listing per whitelist
Sep  2 14:29:48.632: INFO: namespace e2e-tests-svcaccounts-psbgq deletion completed in 6.108996039s

• [SLOW TEST:18.898 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:29:48.633: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-cxjrr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Sep  2 14:29:51.334: INFO: Successfully updated pod "labelsupdate1e3e9047-cd8e-11e9-b90e-8ed318f3d3c6"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:29:55.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-cxjrr" for this suite.
Sep  2 14:30:17.378: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:30:17.447: INFO: namespace: e2e-tests-projected-cxjrr, resource: bindings, ignored listing per whitelist
Sep  2 14:30:17.470: INFO: namespace e2e-tests-projected-cxjrr deletion completed in 22.108207895s

• [SLOW TEST:28.838 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:30:17.470: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-fcjp9
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-2f6f5bd1-cd8e-11e9-b90e-8ed318f3d3c6
STEP: Creating secret with name s-test-opt-upd-2f6f5c35-cd8e-11e9-b90e-8ed318f3d3c6
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-2f6f5bd1-cd8e-11e9-b90e-8ed318f3d3c6
STEP: Updating secret s-test-opt-upd-2f6f5c35-cd8e-11e9-b90e-8ed318f3d3c6
STEP: Creating secret with name s-test-opt-create-2f6f5c5a-cd8e-11e9-b90e-8ed318f3d3c6
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:30:21.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fcjp9" for this suite.
Sep  2 14:30:43.748: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:30:43.801: INFO: namespace: e2e-tests-projected-fcjp9, resource: bindings, ignored listing per whitelist
Sep  2 14:30:43.841: INFO: namespace e2e-tests-projected-fcjp9 deletion completed in 22.108778735s

• [SLOW TEST:26.370 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:30:43.841: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-xbnlh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Sep  2 14:30:44.024: INFO: (0) /api/v1/nodes/ip-192-168-169-21.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="aws-routed-eni/">aws-routed-eni/</a>
<a href="boot.log... (200; 6.374685ms)
Sep  2 14:30:44.027: INFO: (1) /api/v1/nodes/ip-192-168-169-21.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="aws-routed-eni/">aws-routed-eni/</a>
<a href="boot.log... (200; 2.962675ms)
Sep  2 14:30:44.030: INFO: (2) /api/v1/nodes/ip-192-168-169-21.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="aws-routed-eni/">aws-routed-eni/</a>
<a href="boot.log... (200; 2.937565ms)
Sep  2 14:30:44.032: INFO: (3) /api/v1/nodes/ip-192-168-169-21.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="aws-routed-eni/">aws-routed-eni/</a>
<a href="boot.log... (200; 2.783122ms)
Sep  2 14:30:44.035: INFO: (4) /api/v1/nodes/ip-192-168-169-21.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="aws-routed-eni/">aws-routed-eni/</a>
<a href="boot.log... (200; 2.876803ms)
Sep  2 14:30:44.038: INFO: (5) /api/v1/nodes/ip-192-168-169-21.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="aws-routed-eni/">aws-routed-eni/</a>
<a href="boot.log... (200; 2.802337ms)
Sep  2 14:30:44.041: INFO: (6) /api/v1/nodes/ip-192-168-169-21.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="aws-routed-eni/">aws-routed-eni/</a>
<a href="boot.log... (200; 2.84918ms)
Sep  2 14:30:44.044: INFO: (7) /api/v1/nodes/ip-192-168-169-21.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="aws-routed-eni/">aws-routed-eni/</a>
<a href="boot.log... (200; 2.82808ms)
Sep  2 14:30:44.047: INFO: (8) /api/v1/nodes/ip-192-168-169-21.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="aws-routed-eni/">aws-routed-eni/</a>
<a href="boot.log... (200; 2.77745ms)
Sep  2 14:30:44.050: INFO: (9) /api/v1/nodes/ip-192-168-169-21.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="aws-routed-eni/">aws-routed-eni/</a>
<a href="boot.log... (200; 2.95558ms)
Sep  2 14:30:44.053: INFO: (10) /api/v1/nodes/ip-192-168-169-21.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="aws-routed-eni/">aws-routed-eni/</a>
<a href="boot.log... (200; 2.945407ms)
Sep  2 14:30:44.055: INFO: (11) /api/v1/nodes/ip-192-168-169-21.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="aws-routed-eni/">aws-routed-eni/</a>
<a href="boot.log... (200; 2.866161ms)
Sep  2 14:30:44.058: INFO: (12) /api/v1/nodes/ip-192-168-169-21.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="aws-routed-eni/">aws-routed-eni/</a>
<a href="boot.log... (200; 2.849957ms)
Sep  2 14:30:44.061: INFO: (13) /api/v1/nodes/ip-192-168-169-21.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="aws-routed-eni/">aws-routed-eni/</a>
<a href="boot.log... (200; 2.792586ms)
Sep  2 14:30:44.064: INFO: (14) /api/v1/nodes/ip-192-168-169-21.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="aws-routed-eni/">aws-routed-eni/</a>
<a href="boot.log... (200; 2.936737ms)
Sep  2 14:30:44.067: INFO: (15) /api/v1/nodes/ip-192-168-169-21.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="aws-routed-eni/">aws-routed-eni/</a>
<a href="boot.log... (200; 2.845332ms)
Sep  2 14:30:44.070: INFO: (16) /api/v1/nodes/ip-192-168-169-21.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="aws-routed-eni/">aws-routed-eni/</a>
<a href="boot.log... (200; 2.88485ms)
Sep  2 14:30:44.073: INFO: (17) /api/v1/nodes/ip-192-168-169-21.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="aws-routed-eni/">aws-routed-eni/</a>
<a href="boot.log... (200; 2.843754ms)
Sep  2 14:30:44.076: INFO: (18) /api/v1/nodes/ip-192-168-169-21.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="aws-routed-eni/">aws-routed-eni/</a>
<a href="boot.log... (200; 2.998989ms)
Sep  2 14:30:44.079: INFO: (19) /api/v1/nodes/ip-192-168-169-21.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="aws-routed-eni/">aws-routed-eni/</a>
<a href="boot.log... (200; 2.82073ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:30:44.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-xbnlh" for this suite.
Sep  2 14:30:50.097: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:30:50.112: INFO: namespace: e2e-tests-proxy-xbnlh, resource: bindings, ignored listing per whitelist
Sep  2 14:30:50.192: INFO: namespace e2e-tests-proxy-xbnlh deletion completed in 6.110363314s

• [SLOW TEST:6.352 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:30:50.193: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-d6zs7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Sep  2 14:30:50.356: INFO: Waiting up to 5m0s for pod "downwardapi-volume-42eea8a7-cd8e-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-projected-d6zs7" to be "success or failure"
Sep  2 14:30:50.358: INFO: Pod "downwardapi-volume-42eea8a7-cd8e-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.26018ms
Sep  2 14:30:52.361: INFO: Pod "downwardapi-volume-42eea8a7-cd8e-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005632726s
STEP: Saw pod success
Sep  2 14:30:52.361: INFO: Pod "downwardapi-volume-42eea8a7-cd8e-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 14:30:52.364: INFO: Trying to get logs from node ip-192-168-169-21.us-west-2.compute.internal pod downwardapi-volume-42eea8a7-cd8e-11e9-b90e-8ed318f3d3c6 container client-container: <nil>
STEP: delete the pod
Sep  2 14:30:52.382: INFO: Waiting for pod downwardapi-volume-42eea8a7-cd8e-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 14:30:52.385: INFO: Pod downwardapi-volume-42eea8a7-cd8e-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:30:52.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-d6zs7" for this suite.
Sep  2 14:30:58.404: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:30:58.416: INFO: namespace: e2e-tests-projected-d6zs7, resource: bindings, ignored listing per whitelist
Sep  2 14:30:58.503: INFO: namespace e2e-tests-projected-d6zs7 deletion completed in 6.114883973s

• [SLOW TEST:8.311 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:30:58.503: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-l24fh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Sep  2 14:30:58.674: INFO: Waiting up to 5m0s for pod "client-containers-47e3e581-cd8e-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-containers-l24fh" to be "success or failure"
Sep  2 14:30:58.676: INFO: Pod "client-containers-47e3e581-cd8e-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.252246ms
Sep  2 14:31:00.679: INFO: Pod "client-containers-47e3e581-cd8e-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005378287s
Sep  2 14:31:02.682: INFO: Pod "client-containers-47e3e581-cd8e-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008734027s
STEP: Saw pod success
Sep  2 14:31:02.682: INFO: Pod "client-containers-47e3e581-cd8e-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 14:31:02.685: INFO: Trying to get logs from node ip-192-168-169-21.us-west-2.compute.internal pod client-containers-47e3e581-cd8e-11e9-b90e-8ed318f3d3c6 container test-container: <nil>
STEP: delete the pod
Sep  2 14:31:02.705: INFO: Waiting for pod client-containers-47e3e581-cd8e-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 14:31:02.708: INFO: Pod client-containers-47e3e581-cd8e-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:31:02.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-l24fh" for this suite.
Sep  2 14:31:08.727: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:31:08.804: INFO: namespace: e2e-tests-containers-l24fh, resource: bindings, ignored listing per whitelist
Sep  2 14:31:08.821: INFO: namespace e2e-tests-containers-l24fh deletion completed in 6.110235946s

• [SLOW TEST:10.318 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:31:08.822: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-wllx7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Sep  2 14:31:08.993: INFO: (0) /api/v1/nodes/ip-192-168-169-21.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="aws-routed-eni/">aws-routed-eni/</a>
<a href="boot.log... (200; 3.248609ms)
Sep  2 14:31:08.996: INFO: (1) /api/v1/nodes/ip-192-168-169-21.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="aws-routed-eni/">aws-routed-eni/</a>
<a href="boot.log... (200; 3.035485ms)
Sep  2 14:31:09.000: INFO: (2) /api/v1/nodes/ip-192-168-169-21.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="aws-routed-eni/">aws-routed-eni/</a>
<a href="boot.log... (200; 3.02343ms)
Sep  2 14:31:09.002: INFO: (3) /api/v1/nodes/ip-192-168-169-21.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="aws-routed-eni/">aws-routed-eni/</a>
<a href="boot.log... (200; 2.862434ms)
Sep  2 14:31:09.005: INFO: (4) /api/v1/nodes/ip-192-168-169-21.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="aws-routed-eni/">aws-routed-eni/</a>
<a href="boot.log... (200; 2.891233ms)
Sep  2 14:31:09.008: INFO: (5) /api/v1/nodes/ip-192-168-169-21.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="aws-routed-eni/">aws-routed-eni/</a>
<a href="boot.log... (200; 2.877548ms)
Sep  2 14:31:09.011: INFO: (6) /api/v1/nodes/ip-192-168-169-21.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="aws-routed-eni/">aws-routed-eni/</a>
<a href="boot.log... (200; 2.899324ms)
Sep  2 14:31:09.014: INFO: (7) /api/v1/nodes/ip-192-168-169-21.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="aws-routed-eni/">aws-routed-eni/</a>
<a href="boot.log... (200; 2.913081ms)
Sep  2 14:31:09.017: INFO: (8) /api/v1/nodes/ip-192-168-169-21.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="aws-routed-eni/">aws-routed-eni/</a>
<a href="boot.log... (200; 2.970516ms)
Sep  2 14:31:09.020: INFO: (9) /api/v1/nodes/ip-192-168-169-21.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="aws-routed-eni/">aws-routed-eni/</a>
<a href="boot.log... (200; 2.904746ms)
Sep  2 14:31:09.023: INFO: (10) /api/v1/nodes/ip-192-168-169-21.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="aws-routed-eni/">aws-routed-eni/</a>
<a href="boot.log... (200; 2.905095ms)
Sep  2 14:31:09.026: INFO: (11) /api/v1/nodes/ip-192-168-169-21.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="aws-routed-eni/">aws-routed-eni/</a>
<a href="boot.log... (200; 3.052337ms)
Sep  2 14:31:09.029: INFO: (12) /api/v1/nodes/ip-192-168-169-21.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="aws-routed-eni/">aws-routed-eni/</a>
<a href="boot.log... (200; 2.891869ms)
Sep  2 14:31:09.032: INFO: (13) /api/v1/nodes/ip-192-168-169-21.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="aws-routed-eni/">aws-routed-eni/</a>
<a href="boot.log... (200; 2.871148ms)
Sep  2 14:31:09.035: INFO: (14) /api/v1/nodes/ip-192-168-169-21.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="aws-routed-eni/">aws-routed-eni/</a>
<a href="boot.log... (200; 2.873541ms)
Sep  2 14:31:09.038: INFO: (15) /api/v1/nodes/ip-192-168-169-21.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="aws-routed-eni/">aws-routed-eni/</a>
<a href="boot.log... (200; 2.89162ms)
Sep  2 14:31:09.041: INFO: (16) /api/v1/nodes/ip-192-168-169-21.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="aws-routed-eni/">aws-routed-eni/</a>
<a href="boot.log... (200; 2.951942ms)
Sep  2 14:31:09.044: INFO: (17) /api/v1/nodes/ip-192-168-169-21.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="aws-routed-eni/">aws-routed-eni/</a>
<a href="boot.log... (200; 2.866035ms)
Sep  2 14:31:09.046: INFO: (18) /api/v1/nodes/ip-192-168-169-21.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="aws-routed-eni/">aws-routed-eni/</a>
<a href="boot.log... (200; 2.826403ms)
Sep  2 14:31:09.049: INFO: (19) /api/v1/nodes/ip-192-168-169-21.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="aws-routed-eni/">aws-routed-eni/</a>
<a href="boot.log... (200; 2.843688ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:31:09.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-wllx7" for this suite.
Sep  2 14:31:15.068: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:31:15.097: INFO: namespace: e2e-tests-proxy-wllx7, resource: bindings, ignored listing per whitelist
Sep  2 14:31:15.162: INFO: namespace e2e-tests-proxy-wllx7 deletion completed in 6.10916714s

• [SLOW TEST:6.340 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:31:15.162: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-q7g59
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1052
STEP: creating the pod
Sep  2 14:31:15.319: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 create -f - --namespace=e2e-tests-kubectl-q7g59'
Sep  2 14:31:15.471: INFO: stderr: ""
Sep  2 14:31:15.471: INFO: stdout: "pod/pause created\n"
Sep  2 14:31:15.471: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Sep  2 14:31:15.471: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-q7g59" to be "running and ready"
Sep  2 14:31:15.474: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.417447ms
Sep  2 14:31:17.482: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.010622222s
Sep  2 14:31:17.482: INFO: Pod "pause" satisfied condition "running and ready"
Sep  2 14:31:17.482: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Sep  2 14:31:17.482: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-q7g59'
Sep  2 14:31:17.552: INFO: stderr: ""
Sep  2 14:31:17.552: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Sep  2 14:31:17.552: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 get pod pause -L testing-label --namespace=e2e-tests-kubectl-q7g59'
Sep  2 14:31:17.613: INFO: stderr: ""
Sep  2 14:31:17.613: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Sep  2 14:31:17.613: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 label pods pause testing-label- --namespace=e2e-tests-kubectl-q7g59'
Sep  2 14:31:17.684: INFO: stderr: ""
Sep  2 14:31:17.684: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Sep  2 14:31:17.684: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 get pod pause -L testing-label --namespace=e2e-tests-kubectl-q7g59'
Sep  2 14:31:17.746: INFO: stderr: ""
Sep  2 14:31:17.746: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1059
STEP: using delete to clean up resources
Sep  2 14:31:17.746: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-q7g59'
Sep  2 14:31:17.819: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  2 14:31:17.819: INFO: stdout: "pod \"pause\" force deleted\n"
Sep  2 14:31:17.819: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-q7g59'
Sep  2 14:31:17.889: INFO: stderr: "No resources found.\n"
Sep  2 14:31:17.889: INFO: stdout: ""
Sep  2 14:31:17.889: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 get pods -l name=pause --namespace=e2e-tests-kubectl-q7g59 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep  2 14:31:17.952: INFO: stderr: ""
Sep  2 14:31:17.952: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:31:17.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-q7g59" for this suite.
Sep  2 14:31:23.972: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:31:24.054: INFO: namespace: e2e-tests-kubectl-q7g59, resource: bindings, ignored listing per whitelist
Sep  2 14:31:24.067: INFO: namespace e2e-tests-kubectl-q7g59 deletion completed in 6.110934256s

• [SLOW TEST:8.905 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:31:24.067: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-t4hgp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Sep  2 14:31:24.236: INFO: Waiting up to 5m0s for pod "pod-5720842f-cd8e-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-emptydir-t4hgp" to be "success or failure"
Sep  2 14:31:24.239: INFO: Pod "pod-5720842f-cd8e-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.404621ms
Sep  2 14:31:26.252: INFO: Pod "pod-5720842f-cd8e-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015445106s
STEP: Saw pod success
Sep  2 14:31:26.252: INFO: Pod "pod-5720842f-cd8e-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 14:31:26.266: INFO: Trying to get logs from node ip-192-168-169-21.us-west-2.compute.internal pod pod-5720842f-cd8e-11e9-b90e-8ed318f3d3c6 container test-container: <nil>
STEP: delete the pod
Sep  2 14:31:26.299: INFO: Waiting for pod pod-5720842f-cd8e-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 14:31:26.301: INFO: Pod pod-5720842f-cd8e-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:31:26.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-t4hgp" for this suite.
Sep  2 14:31:32.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:31:32.372: INFO: namespace: e2e-tests-emptydir-t4hgp, resource: bindings, ignored listing per whitelist
Sep  2 14:31:32.415: INFO: namespace e2e-tests-emptydir-t4hgp deletion completed in 6.110855912s

• [SLOW TEST:8.348 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:31:32.416: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-fl5tl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Sep  2 14:31:32.600: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Sep  2 14:31:32.610: INFO: Number of nodes with available pods: 0
Sep  2 14:31:32.610: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:31:33.618: INFO: Number of nodes with available pods: 0
Sep  2 14:31:33.618: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:31:34.618: INFO: Number of nodes with available pods: 1
Sep  2 14:31:34.618: INFO: Node ip-192-168-55-191.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:31:35.618: INFO: Number of nodes with available pods: 3
Sep  2 14:31:35.618: INFO: Node ip-192-168-77-237.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:31:36.619: INFO: Number of nodes with available pods: 4
Sep  2 14:31:36.619: INFO: Number of running nodes: 4, number of available pods: 4
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Sep  2 14:31:36.639: INFO: Wrong image for pod: daemon-set-7hztt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:36.639: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:36.639: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:36.639: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:37.647: INFO: Wrong image for pod: daemon-set-7hztt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:37.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:37.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:37.647: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:38.653: INFO: Wrong image for pod: daemon-set-7hztt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:38.653: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:38.653: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:38.653: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:39.647: INFO: Wrong image for pod: daemon-set-7hztt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:39.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:39.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:39.647: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:40.647: INFO: Wrong image for pod: daemon-set-7hztt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:40.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:40.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:40.647: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:41.647: INFO: Wrong image for pod: daemon-set-7hztt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:41.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:41.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:41.647: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:42.647: INFO: Wrong image for pod: daemon-set-7hztt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:42.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:42.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:42.647: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:43.646: INFO: Wrong image for pod: daemon-set-7hztt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:43.646: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:43.646: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:43.646: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:44.647: INFO: Wrong image for pod: daemon-set-7hztt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:44.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:44.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:44.647: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:45.647: INFO: Wrong image for pod: daemon-set-7hztt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:45.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:45.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:45.647: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:46.647: INFO: Wrong image for pod: daemon-set-7hztt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:46.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:46.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:46.647: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:47.647: INFO: Wrong image for pod: daemon-set-7hztt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:47.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:47.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:47.647: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:48.647: INFO: Wrong image for pod: daemon-set-7hztt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:48.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:48.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:48.647: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:49.652: INFO: Wrong image for pod: daemon-set-7hztt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:49.652: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:49.652: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:49.652: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:50.647: INFO: Wrong image for pod: daemon-set-7hztt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:50.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:50.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:50.647: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:51.647: INFO: Wrong image for pod: daemon-set-7hztt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:51.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:51.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:51.647: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:52.647: INFO: Wrong image for pod: daemon-set-7hztt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:52.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:52.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:52.647: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:53.646: INFO: Wrong image for pod: daemon-set-7hztt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:53.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:53.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:53.647: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:54.647: INFO: Wrong image for pod: daemon-set-7hztt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:54.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:54.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:54.647: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:55.647: INFO: Wrong image for pod: daemon-set-7hztt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:55.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:55.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:55.647: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:56.647: INFO: Wrong image for pod: daemon-set-7hztt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:56.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:56.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:56.647: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:57.647: INFO: Wrong image for pod: daemon-set-7hztt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:57.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:57.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:57.647: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:58.647: INFO: Wrong image for pod: daemon-set-7hztt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:58.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:58.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:58.647: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:59.646: INFO: Wrong image for pod: daemon-set-7hztt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:59.646: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:59.646: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:31:59.646: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:00.652: INFO: Wrong image for pod: daemon-set-7hztt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:00.652: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:00.652: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:00.652: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:01.647: INFO: Wrong image for pod: daemon-set-7hztt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:01.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:01.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:01.647: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:02.647: INFO: Wrong image for pod: daemon-set-7hztt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:02.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:02.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:02.647: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:03.647: INFO: Wrong image for pod: daemon-set-7hztt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:03.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:03.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:03.647: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:04.647: INFO: Wrong image for pod: daemon-set-7hztt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:04.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:04.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:04.647: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:05.647: INFO: Wrong image for pod: daemon-set-7hztt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:05.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:05.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:05.647: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:06.647: INFO: Wrong image for pod: daemon-set-7hztt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:06.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:06.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:06.647: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:07.647: INFO: Wrong image for pod: daemon-set-7hztt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:07.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:07.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:07.647: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:08.647: INFO: Wrong image for pod: daemon-set-7hztt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:08.647: INFO: Pod daemon-set-7hztt is not available
Sep  2 14:32:08.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:08.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:08.647: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:09.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:09.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:09.647: INFO: Pod daemon-set-qtq5c is not available
Sep  2 14:32:09.647: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:10.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:10.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:10.647: INFO: Pod daemon-set-qtq5c is not available
Sep  2 14:32:10.647: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:11.653: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:11.653: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:11.653: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:12.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:12.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:12.647: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:13.654: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:13.654: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:13.654: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:14.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:14.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:14.647: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:15.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:15.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:15.647: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:16.646: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:16.646: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:16.646: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:17.646: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:17.646: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:17.646: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:18.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:18.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:18.647: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:19.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:19.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:19.647: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:20.646: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:20.646: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:20.646: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:21.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:21.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:21.647: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:22.652: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:22.652: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:22.652: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:23.646: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:23.646: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:23.646: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:24.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:24.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:24.647: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:25.659: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:25.659: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:25.659: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:26.651: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:26.651: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:26.651: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:27.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:27.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:27.647: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:28.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:28.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:28.647: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:29.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:29.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:29.647: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:30.648: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:30.648: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:30.648: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:31.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:31.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:31.647: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:32.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:32.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:32.647: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:33.652: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:33.652: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:33.652: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:34.646: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:34.646: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:34.646: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:35.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:35.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:35.647: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:36.646: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:36.646: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:36.646: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:37.646: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:37.646: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:37.646: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:38.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:38.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:38.647: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:39.646: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:39.646: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:39.646: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:40.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:40.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:40.647: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:41.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:41.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:41.647: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:42.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:42.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:42.647: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:42.647: INFO: Pod daemon-set-zlckh is not available
Sep  2 14:32:43.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:43.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:43.647: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:43.647: INFO: Pod daemon-set-zlckh is not available
Sep  2 14:32:44.652: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:44.652: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:44.652: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:44.652: INFO: Pod daemon-set-zlckh is not available
Sep  2 14:32:45.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:45.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:45.647: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:45.647: INFO: Pod daemon-set-zlckh is not available
Sep  2 14:32:46.646: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:46.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:46.647: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:46.647: INFO: Pod daemon-set-zlckh is not available
Sep  2 14:32:47.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:47.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:47.647: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:47.647: INFO: Pod daemon-set-zlckh is not available
Sep  2 14:32:48.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:48.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:48.647: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:48.647: INFO: Pod daemon-set-zlckh is not available
Sep  2 14:32:49.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:49.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:49.647: INFO: Wrong image for pod: daemon-set-zlckh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:49.647: INFO: Pod daemon-set-zlckh is not available
Sep  2 14:32:50.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:50.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:50.647: INFO: Pod daemon-set-q2v5l is not available
Sep  2 14:32:51.646: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:51.646: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:52.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:52.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:53.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:53.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:54.646: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:54.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:55.652: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:55.652: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:56.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:56.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:57.646: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:57.646: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:58.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:58.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:59.646: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:32:59.646: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:00.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:00.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:01.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:01.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:02.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:02.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:03.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:03.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:04.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:04.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:05.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:05.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:06.652: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:06.652: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:07.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:07.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:08.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:08.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:09.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:09.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:10.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:10.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:11.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:11.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:12.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:12.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:13.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:13.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:14.646: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:14.646: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:15.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:15.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:16.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:16.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:17.652: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:17.653: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:18.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:18.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:19.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:19.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:20.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:20.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:21.646: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:21.646: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:22.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:22.647: INFO: Pod daemon-set-czd2l is not available
Sep  2 14:33:22.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:23.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:23.647: INFO: Pod daemon-set-czd2l is not available
Sep  2 14:33:23.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:24.647: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:24.647: INFO: Pod daemon-set-czd2l is not available
Sep  2 14:33:24.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:25.668: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:25.668: INFO: Pod daemon-set-czd2l is not available
Sep  2 14:33:25.668: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:26.659: INFO: Wrong image for pod: daemon-set-czd2l. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:26.659: INFO: Pod daemon-set-czd2l is not available
Sep  2 14:33:26.659: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:27.646: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:27.646: INFO: Pod daemon-set-shmrw is not available
Sep  2 14:33:28.653: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:28.653: INFO: Pod daemon-set-shmrw is not available
Sep  2 14:33:29.646: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:30.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:31.646: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:32.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:33.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:34.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:35.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:36.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:37.646: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:38.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:39.652: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:40.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:41.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:42.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:43.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:44.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:45.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:46.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:47.646: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:48.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:49.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:50.653: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:51.646: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:52.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:53.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:54.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:55.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:56.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:57.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:58.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:33:59.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:34:00.647: INFO: Wrong image for pod: daemon-set-njxlq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Sep  2 14:34:00.647: INFO: Pod daemon-set-njxlq is not available
Sep  2 14:34:01.654: INFO: Pod daemon-set-956tx is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Sep  2 14:34:01.665: INFO: Number of nodes with available pods: 3
Sep  2 14:34:01.665: INFO: Node ip-192-168-6-156.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:34:02.672: INFO: Number of nodes with available pods: 3
Sep  2 14:34:02.672: INFO: Node ip-192-168-6-156.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:34:03.673: INFO: Number of nodes with available pods: 3
Sep  2 14:34:03.673: INFO: Node ip-192-168-6-156.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:34:04.673: INFO: Number of nodes with available pods: 3
Sep  2 14:34:04.673: INFO: Node ip-192-168-6-156.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:34:05.672: INFO: Number of nodes with available pods: 4
Sep  2 14:34:05.672: INFO: Number of running nodes: 4, number of available pods: 4
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-fl5tl, will wait for the garbage collector to delete the pods
Sep  2 14:34:05.751: INFO: Deleting DaemonSet.extensions daemon-set took: 10.228959ms
Sep  2 14:34:05.851: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.232691ms
Sep  2 14:34:16.960: INFO: Number of nodes with available pods: 0
Sep  2 14:34:16.960: INFO: Number of running nodes: 0, number of available pods: 0
Sep  2 14:34:16.963: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-fl5tl/daemonsets","resourceVersion":"2104532"},"items":null}

Sep  2 14:34:16.966: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-fl5tl/pods","resourceVersion":"2104532"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:34:16.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-fl5tl" for this suite.
Sep  2 14:34:22.999: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:34:23.053: INFO: namespace: e2e-tests-daemonsets-fl5tl, resource: bindings, ignored listing per whitelist
Sep  2 14:34:23.096: INFO: namespace e2e-tests-daemonsets-fl5tl deletion completed in 6.115337784s

• [SLOW TEST:170.681 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:34:23.097: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-xctd2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep  2 14:34:23.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-xctd2'
Sep  2 14:34:23.442: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep  2 14:34:23.442: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Sep  2 14:34:23.446: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-xctd2'
Sep  2 14:34:23.531: INFO: stderr: ""
Sep  2 14:34:23.531: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:34:23.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xctd2" for this suite.
Sep  2 14:34:29.559: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:34:29.650: INFO: namespace: e2e-tests-kubectl-xctd2, resource: bindings, ignored listing per whitelist
Sep  2 14:34:29.655: INFO: namespace e2e-tests-kubectl-xctd2 deletion completed in 6.120315061s

• [SLOW TEST:6.559 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:34:29.655: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-cm9vh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-c5be566a-cd8e-11e9-b90e-8ed318f3d3c6
STEP: Creating a pod to test consume configMaps
Sep  2 14:34:29.825: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c5bed721-cd8e-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-projected-cm9vh" to be "success or failure"
Sep  2 14:34:29.827: INFO: Pod "pod-projected-configmaps-c5bed721-cd8e-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.39996ms
Sep  2 14:34:31.830: INFO: Pod "pod-projected-configmaps-c5bed721-cd8e-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005378438s
STEP: Saw pod success
Sep  2 14:34:31.830: INFO: Pod "pod-projected-configmaps-c5bed721-cd8e-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 14:34:31.833: INFO: Trying to get logs from node ip-192-168-169-21.us-west-2.compute.internal pod pod-projected-configmaps-c5bed721-cd8e-11e9-b90e-8ed318f3d3c6 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep  2 14:34:31.851: INFO: Waiting for pod pod-projected-configmaps-c5bed721-cd8e-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 14:34:31.854: INFO: Pod pod-projected-configmaps-c5bed721-cd8e-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:34:31.854: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-cm9vh" for this suite.
Sep  2 14:34:37.879: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:34:37.935: INFO: namespace: e2e-tests-projected-cm9vh, resource: bindings, ignored listing per whitelist
Sep  2 14:34:37.977: INFO: namespace e2e-tests-projected-cm9vh deletion completed in 6.118812151s

• [SLOW TEST:8.321 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:34:37.977: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-stfzr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-stfzr/secret-test-cab520dc-cd8e-11e9-b90e-8ed318f3d3c6
STEP: Creating a pod to test consume secrets
Sep  2 14:34:38.154: INFO: Waiting up to 5m0s for pod "pod-configmaps-cab5dcbb-cd8e-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-secrets-stfzr" to be "success or failure"
Sep  2 14:34:38.157: INFO: Pod "pod-configmaps-cab5dcbb-cd8e-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.228717ms
Sep  2 14:34:40.160: INFO: Pod "pod-configmaps-cab5dcbb-cd8e-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005252977s
STEP: Saw pod success
Sep  2 14:34:40.160: INFO: Pod "pod-configmaps-cab5dcbb-cd8e-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 14:34:40.162: INFO: Trying to get logs from node ip-192-168-169-21.us-west-2.compute.internal pod pod-configmaps-cab5dcbb-cd8e-11e9-b90e-8ed318f3d3c6 container env-test: <nil>
STEP: delete the pod
Sep  2 14:34:40.179: INFO: Waiting for pod pod-configmaps-cab5dcbb-cd8e-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 14:34:40.181: INFO: Pod pod-configmaps-cab5dcbb-cd8e-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:34:40.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-stfzr" for this suite.
Sep  2 14:34:46.200: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:34:46.239: INFO: namespace: e2e-tests-secrets-stfzr, resource: bindings, ignored listing per whitelist
Sep  2 14:34:46.295: INFO: namespace e2e-tests-secrets-stfzr deletion completed in 6.110493111s

• [SLOW TEST:8.319 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:34:46.296: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-tps6r
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Sep  2 14:34:46.462: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-tps6r,SelfLink:/api/v1/namespaces/e2e-tests-watch-tps6r/configmaps/e2e-watch-test-watch-closed,UID:cfa95de7-cd8e-11e9-a575-0a854009c708,ResourceVersion:2104727,Generation:0,CreationTimestamp:2019-09-02 14:34:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep  2 14:34:46.462: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-tps6r,SelfLink:/api/v1/namespaces/e2e-tests-watch-tps6r/configmaps/e2e-watch-test-watch-closed,UID:cfa95de7-cd8e-11e9-a575-0a854009c708,ResourceVersion:2104728,Generation:0,CreationTimestamp:2019-09-02 14:34:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Sep  2 14:34:46.474: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-tps6r,SelfLink:/api/v1/namespaces/e2e-tests-watch-tps6r/configmaps/e2e-watch-test-watch-closed,UID:cfa95de7-cd8e-11e9-a575-0a854009c708,ResourceVersion:2104729,Generation:0,CreationTimestamp:2019-09-02 14:34:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep  2 14:34:46.474: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-tps6r,SelfLink:/api/v1/namespaces/e2e-tests-watch-tps6r/configmaps/e2e-watch-test-watch-closed,UID:cfa95de7-cd8e-11e9-a575-0a854009c708,ResourceVersion:2104730,Generation:0,CreationTimestamp:2019-09-02 14:34:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:34:46.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-tps6r" for this suite.
Sep  2 14:34:52.494: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:34:52.582: INFO: namespace: e2e-tests-watch-tps6r, resource: bindings, ignored listing per whitelist
Sep  2 14:34:52.590: INFO: namespace e2e-tests-watch-tps6r deletion completed in 6.112392231s

• [SLOW TEST:6.295 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:34:52.591: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-ppcns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Sep  2 14:34:52.763: INFO: Waiting up to 5m0s for pod "pod-d36ab53b-cd8e-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-emptydir-ppcns" to be "success or failure"
Sep  2 14:34:52.765: INFO: Pod "pod-d36ab53b-cd8e-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.305403ms
Sep  2 14:34:54.768: INFO: Pod "pod-d36ab53b-cd8e-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005664133s
STEP: Saw pod success
Sep  2 14:34:54.768: INFO: Pod "pod-d36ab53b-cd8e-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 14:34:54.771: INFO: Trying to get logs from node ip-192-168-169-21.us-west-2.compute.internal pod pod-d36ab53b-cd8e-11e9-b90e-8ed318f3d3c6 container test-container: <nil>
STEP: delete the pod
Sep  2 14:34:54.788: INFO: Waiting for pod pod-d36ab53b-cd8e-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 14:34:54.790: INFO: Pod pod-d36ab53b-cd8e-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:34:54.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-ppcns" for this suite.
Sep  2 14:35:00.810: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:35:00.888: INFO: namespace: e2e-tests-emptydir-ppcns, resource: bindings, ignored listing per whitelist
Sep  2 14:35:00.907: INFO: namespace e2e-tests-emptydir-ppcns deletion completed in 6.113668306s

• [SLOW TEST:8.317 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:35:00.908: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-jpx4p
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-d8608490-cd8e-11e9-b90e-8ed318f3d3c6
STEP: Creating a pod to test consume configMaps
Sep  2 14:35:01.087: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d861218a-cd8e-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-projected-jpx4p" to be "success or failure"
Sep  2 14:35:01.090: INFO: Pod "pod-projected-configmaps-d861218a-cd8e-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.371446ms
Sep  2 14:35:03.093: INFO: Pod "pod-projected-configmaps-d861218a-cd8e-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00583643s
Sep  2 14:35:05.097: INFO: Pod "pod-projected-configmaps-d861218a-cd8e-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009665175s
STEP: Saw pod success
Sep  2 14:35:05.097: INFO: Pod "pod-projected-configmaps-d861218a-cd8e-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 14:35:05.100: INFO: Trying to get logs from node ip-192-168-169-21.us-west-2.compute.internal pod pod-projected-configmaps-d861218a-cd8e-11e9-b90e-8ed318f3d3c6 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep  2 14:35:05.117: INFO: Waiting for pod pod-projected-configmaps-d861218a-cd8e-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 14:35:05.120: INFO: Pod pod-projected-configmaps-d861218a-cd8e-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:35:05.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jpx4p" for this suite.
Sep  2 14:35:11.139: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:35:11.154: INFO: namespace: e2e-tests-projected-jpx4p, resource: bindings, ignored listing per whitelist
Sep  2 14:35:11.239: INFO: namespace e2e-tests-projected-jpx4p deletion completed in 6.115615174s

• [SLOW TEST:10.332 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:35:11.239: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-2hvs4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Sep  2 14:35:13.929: INFO: Successfully updated pod "pod-update-de884673-cd8e-11e9-b90e-8ed318f3d3c6"
STEP: verifying the updated pod is in kubernetes
Sep  2 14:35:13.934: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:35:13.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-2hvs4" for this suite.
Sep  2 14:35:35.954: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:35:36.009: INFO: namespace: e2e-tests-pods-2hvs4, resource: bindings, ignored listing per whitelist
Sep  2 14:35:36.051: INFO: namespace e2e-tests-pods-2hvs4 deletion completed in 22.113379088s

• [SLOW TEST:24.812 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:35:36.052: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-r9fvn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Sep  2 14:35:36.248: INFO: Number of nodes with available pods: 0
Sep  2 14:35:36.248: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:35:37.255: INFO: Number of nodes with available pods: 0
Sep  2 14:35:37.255: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:35:38.256: INFO: Number of nodes with available pods: 3
Sep  2 14:35:38.256: INFO: Node ip-192-168-6-156.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:35:39.256: INFO: Number of nodes with available pods: 4
Sep  2 14:35:39.256: INFO: Number of running nodes: 4, number of available pods: 4
STEP: Stop a daemon pod, check that the daemon pod is revived.
Sep  2 14:35:39.274: INFO: Number of nodes with available pods: 3
Sep  2 14:35:39.274: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:35:40.282: INFO: Number of nodes with available pods: 3
Sep  2 14:35:40.282: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:35:41.282: INFO: Number of nodes with available pods: 3
Sep  2 14:35:41.282: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:35:42.287: INFO: Number of nodes with available pods: 3
Sep  2 14:35:42.287: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:35:43.282: INFO: Number of nodes with available pods: 3
Sep  2 14:35:43.282: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:35:44.282: INFO: Number of nodes with available pods: 3
Sep  2 14:35:44.282: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:35:45.282: INFO: Number of nodes with available pods: 3
Sep  2 14:35:45.282: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:35:46.282: INFO: Number of nodes with available pods: 3
Sep  2 14:35:46.282: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:35:47.282: INFO: Number of nodes with available pods: 3
Sep  2 14:35:47.282: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:35:48.282: INFO: Number of nodes with available pods: 3
Sep  2 14:35:48.282: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:35:49.282: INFO: Number of nodes with available pods: 3
Sep  2 14:35:49.282: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:35:50.282: INFO: Number of nodes with available pods: 3
Sep  2 14:35:50.282: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:35:51.282: INFO: Number of nodes with available pods: 3
Sep  2 14:35:51.282: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:35:52.282: INFO: Number of nodes with available pods: 3
Sep  2 14:35:52.282: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:35:53.287: INFO: Number of nodes with available pods: 3
Sep  2 14:35:53.287: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:35:54.282: INFO: Number of nodes with available pods: 3
Sep  2 14:35:54.282: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:35:55.282: INFO: Number of nodes with available pods: 3
Sep  2 14:35:55.282: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:35:56.282: INFO: Number of nodes with available pods: 3
Sep  2 14:35:56.282: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:35:57.282: INFO: Number of nodes with available pods: 3
Sep  2 14:35:57.282: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:35:58.282: INFO: Number of nodes with available pods: 3
Sep  2 14:35:58.282: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:35:59.283: INFO: Number of nodes with available pods: 3
Sep  2 14:35:59.283: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:36:00.282: INFO: Number of nodes with available pods: 3
Sep  2 14:36:00.282: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:36:01.282: INFO: Number of nodes with available pods: 3
Sep  2 14:36:01.282: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:36:02.282: INFO: Number of nodes with available pods: 3
Sep  2 14:36:02.282: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:36:03.282: INFO: Number of nodes with available pods: 3
Sep  2 14:36:03.282: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:36:04.288: INFO: Number of nodes with available pods: 3
Sep  2 14:36:04.288: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:36:05.282: INFO: Number of nodes with available pods: 3
Sep  2 14:36:05.282: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:36:06.282: INFO: Number of nodes with available pods: 3
Sep  2 14:36:06.282: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:36:07.282: INFO: Number of nodes with available pods: 3
Sep  2 14:36:07.282: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:36:08.282: INFO: Number of nodes with available pods: 3
Sep  2 14:36:08.282: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:36:09.282: INFO: Number of nodes with available pods: 3
Sep  2 14:36:09.282: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:36:10.282: INFO: Number of nodes with available pods: 3
Sep  2 14:36:10.282: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:36:11.282: INFO: Number of nodes with available pods: 3
Sep  2 14:36:11.282: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:36:12.282: INFO: Number of nodes with available pods: 3
Sep  2 14:36:12.282: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:36:13.282: INFO: Number of nodes with available pods: 3
Sep  2 14:36:13.282: INFO: Node ip-192-168-169-21.us-west-2.compute.internal is running more than one daemon pod
Sep  2 14:36:14.282: INFO: Number of nodes with available pods: 4
Sep  2 14:36:14.282: INFO: Number of running nodes: 4, number of available pods: 4
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-r9fvn, will wait for the garbage collector to delete the pods
Sep  2 14:36:14.355: INFO: Deleting DaemonSet.extensions daemon-set took: 9.977239ms
Sep  2 14:36:14.455: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.237009ms
Sep  2 14:36:56.963: INFO: Number of nodes with available pods: 0
Sep  2 14:36:56.963: INFO: Number of running nodes: 0, number of available pods: 0
Sep  2 14:36:56.966: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-r9fvn/daemonsets","resourceVersion":"2105114"},"items":null}

Sep  2 14:36:56.969: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-r9fvn/pods","resourceVersion":"2105114"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:36:56.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-r9fvn" for this suite.
Sep  2 14:37:03.000: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:37:03.020: INFO: namespace: e2e-tests-daemonsets-r9fvn, resource: bindings, ignored listing per whitelist
Sep  2 14:37:03.100: INFO: namespace e2e-tests-daemonsets-r9fvn deletion completed in 6.116294851s

• [SLOW TEST:87.048 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:37:03.100: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-282v7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-282v7
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep  2 14:37:03.267: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep  2 14:37:25.338: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.7.245:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-282v7 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  2 14:37:25.338: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
Sep  2 14:37:25.431: INFO: Found all expected endpoints: [netserver-0]
Sep  2 14:37:25.434: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.47.51:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-282v7 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  2 14:37:25.434: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
Sep  2 14:37:25.525: INFO: Found all expected endpoints: [netserver-1]
Sep  2 14:37:25.527: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.162.73:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-282v7 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  2 14:37:25.527: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
Sep  2 14:37:25.622: INFO: Found all expected endpoints: [netserver-2]
Sep  2 14:37:25.646: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.94.2:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-282v7 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  2 14:37:25.646: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
Sep  2 14:37:25.739: INFO: Found all expected endpoints: [netserver-3]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:37:25.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-282v7" for this suite.
Sep  2 14:37:47.760: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:37:47.837: INFO: namespace: e2e-tests-pod-network-test-282v7, resource: bindings, ignored listing per whitelist
Sep  2 14:37:47.857: INFO: namespace e2e-tests-pod-network-test-282v7 deletion completed in 22.113434929s

• [SLOW TEST:44.757 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:37:47.857: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-7hhvw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1527
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep  2 14:37:48.022: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-7hhvw'
Sep  2 14:37:48.099: INFO: stderr: ""
Sep  2 14:37:48.099: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1532
Sep  2 14:37:48.102: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-7hhvw'
Sep  2 14:37:57.585: INFO: stderr: ""
Sep  2 14:37:57.585: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:37:57.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-7hhvw" for this suite.
Sep  2 14:38:03.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:38:03.653: INFO: namespace: e2e-tests-kubectl-7hhvw, resource: bindings, ignored listing per whitelist
Sep  2 14:38:03.715: INFO: namespace e2e-tests-kubectl-7hhvw deletion completed in 6.120023326s

• [SLOW TEST:15.857 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:38:03.715: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-ssk4c
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Sep  2 14:38:03.892: INFO: Waiting up to 5m0s for pod "client-containers-4556a8a2-cd8f-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-containers-ssk4c" to be "success or failure"
Sep  2 14:38:03.894: INFO: Pod "client-containers-4556a8a2-cd8f-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.516803ms
Sep  2 14:38:05.898: INFO: Pod "client-containers-4556a8a2-cd8f-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006058346s
Sep  2 14:38:07.907: INFO: Pod "client-containers-4556a8a2-cd8f-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015238381s
STEP: Saw pod success
Sep  2 14:38:07.907: INFO: Pod "client-containers-4556a8a2-cd8f-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 14:38:07.909: INFO: Trying to get logs from node ip-192-168-169-21.us-west-2.compute.internal pod client-containers-4556a8a2-cd8f-11e9-b90e-8ed318f3d3c6 container test-container: <nil>
STEP: delete the pod
Sep  2 14:38:07.925: INFO: Waiting for pod client-containers-4556a8a2-cd8f-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 14:38:07.927: INFO: Pod client-containers-4556a8a2-cd8f-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:38:07.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-ssk4c" for this suite.
Sep  2 14:38:13.946: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:38:13.952: INFO: namespace: e2e-tests-containers-ssk4c, resource: bindings, ignored listing per whitelist
Sep  2 14:38:14.044: INFO: namespace e2e-tests-containers-ssk4c deletion completed in 6.112473799s

• [SLOW TEST:10.329 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:38:14.044: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-tsbw5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-4b7e2c19-cd8f-11e9-b90e-8ed318f3d3c6
STEP: Creating a pod to test consume configMaps
Sep  2 14:38:14.220: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4b7ed822-cd8f-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-projected-tsbw5" to be "success or failure"
Sep  2 14:38:14.223: INFO: Pod "pod-projected-configmaps-4b7ed822-cd8f-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.212032ms
Sep  2 14:38:16.226: INFO: Pod "pod-projected-configmaps-4b7ed822-cd8f-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005473721s
STEP: Saw pod success
Sep  2 14:38:16.226: INFO: Pod "pod-projected-configmaps-4b7ed822-cd8f-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 14:38:16.228: INFO: Trying to get logs from node ip-192-168-169-21.us-west-2.compute.internal pod pod-projected-configmaps-4b7ed822-cd8f-11e9-b90e-8ed318f3d3c6 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep  2 14:38:16.246: INFO: Waiting for pod pod-projected-configmaps-4b7ed822-cd8f-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 14:38:16.248: INFO: Pod pod-projected-configmaps-4b7ed822-cd8f-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:38:16.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-tsbw5" for this suite.
Sep  2 14:38:22.267: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:38:22.282: INFO: namespace: e2e-tests-projected-tsbw5, resource: bindings, ignored listing per whitelist
Sep  2 14:38:22.362: INFO: namespace e2e-tests-projected-tsbw5 deletion completed in 6.110304736s

• [SLOW TEST:8.318 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:38:22.362: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-4xpvm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Sep  2 14:38:22.532: INFO: Waiting up to 5m0s for pod "downward-api-50732532-cd8f-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-downward-api-4xpvm" to be "success or failure"
Sep  2 14:38:22.534: INFO: Pod "downward-api-50732532-cd8f-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.313355ms
Sep  2 14:38:24.538: INFO: Pod "downward-api-50732532-cd8f-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005658049s
STEP: Saw pod success
Sep  2 14:38:24.538: INFO: Pod "downward-api-50732532-cd8f-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 14:38:24.540: INFO: Trying to get logs from node ip-192-168-169-21.us-west-2.compute.internal pod downward-api-50732532-cd8f-11e9-b90e-8ed318f3d3c6 container dapi-container: <nil>
STEP: delete the pod
Sep  2 14:38:24.558: INFO: Waiting for pod downward-api-50732532-cd8f-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 14:38:24.560: INFO: Pod downward-api-50732532-cd8f-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:38:24.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-4xpvm" for this suite.
Sep  2 14:38:30.580: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:38:30.643: INFO: namespace: e2e-tests-downward-api-4xpvm, resource: bindings, ignored listing per whitelist
Sep  2 14:38:30.678: INFO: namespace e2e-tests-downward-api-4xpvm deletion completed in 6.11457898s

• [SLOW TEST:8.316 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:38:30.679: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-g9fvl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1399
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep  2 14:38:30.842: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-g9fvl'
Sep  2 14:38:30.915: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep  2 14:38:30.915: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1404
Sep  2 14:38:34.925: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-g9fvl'
Sep  2 14:38:35.000: INFO: stderr: ""
Sep  2 14:38:35.000: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:38:35.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-g9fvl" for this suite.
Sep  2 14:38:57.021: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:38:57.084: INFO: namespace: e2e-tests-kubectl-g9fvl, resource: bindings, ignored listing per whitelist
Sep  2 14:38:57.119: INFO: namespace e2e-tests-kubectl-g9fvl deletion completed in 22.114235913s

• [SLOW TEST:26.441 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:38:57.119: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-qw9gd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep  2 14:38:57.285: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-qw9gd'
Sep  2 14:38:57.356: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep  2 14:38:57.356: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Sep  2 14:38:59.364: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-9tm45]
Sep  2 14:38:59.364: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-9tm45" in namespace "e2e-tests-kubectl-qw9gd" to be "running and ready"
Sep  2 14:38:59.366: INFO: Pod "e2e-test-nginx-rc-9tm45": Phase="Running", Reason="", readiness=true. Elapsed: 2.315099ms
Sep  2 14:38:59.366: INFO: Pod "e2e-test-nginx-rc-9tm45" satisfied condition "running and ready"
Sep  2 14:38:59.366: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-9tm45]
Sep  2 14:38:59.366: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-qw9gd'
Sep  2 14:38:59.453: INFO: stderr: ""
Sep  2 14:38:59.453: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1303
Sep  2 14:38:59.453: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-qw9gd'
Sep  2 14:38:59.527: INFO: stderr: ""
Sep  2 14:38:59.527: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:38:59.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-qw9gd" for this suite.
Sep  2 14:39:21.548: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:39:21.605: INFO: namespace: e2e-tests-kubectl-qw9gd, resource: bindings, ignored listing per whitelist
Sep  2 14:39:21.643: INFO: namespace e2e-tests-kubectl-qw9gd deletion completed in 22.112116886s

• [SLOW TEST:24.524 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:39:21.643: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-55sgt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Sep  2 14:39:21.815: INFO: Waiting up to 5m0s for pod "downwardapi-volume-73c90a74-cd8f-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-projected-55sgt" to be "success or failure"
Sep  2 14:39:21.818: INFO: Pod "downwardapi-volume-73c90a74-cd8f-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.229001ms
Sep  2 14:39:23.827: INFO: Pod "downwardapi-volume-73c90a74-cd8f-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011653953s
Sep  2 14:39:25.831: INFO: Pod "downwardapi-volume-73c90a74-cd8f-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015074564s
STEP: Saw pod success
Sep  2 14:39:25.831: INFO: Pod "downwardapi-volume-73c90a74-cd8f-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 14:39:25.833: INFO: Trying to get logs from node ip-192-168-77-237.us-west-2.compute.internal pod downwardapi-volume-73c90a74-cd8f-11e9-b90e-8ed318f3d3c6 container client-container: <nil>
STEP: delete the pod
Sep  2 14:39:25.852: INFO: Waiting for pod downwardapi-volume-73c90a74-cd8f-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 14:39:25.855: INFO: Pod downwardapi-volume-73c90a74-cd8f-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:39:25.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-55sgt" for this suite.
Sep  2 14:39:31.874: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:39:31.950: INFO: namespace: e2e-tests-projected-55sgt, resource: bindings, ignored listing per whitelist
Sep  2 14:39:31.970: INFO: namespace e2e-tests-projected-55sgt deletion completed in 6.11083266s

• [SLOW TEST:10.327 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:39:31.970: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-srxc7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-79f17ec9-cd8f-11e9-b90e-8ed318f3d3c6
STEP: Creating a pod to test consume configMaps
Sep  2 14:39:32.153: INFO: Waiting up to 5m0s for pod "pod-configmaps-79f247d5-cd8f-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-configmap-srxc7" to be "success or failure"
Sep  2 14:39:32.155: INFO: Pod "pod-configmaps-79f247d5-cd8f-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.340019ms
Sep  2 14:39:34.165: INFO: Pod "pod-configmaps-79f247d5-cd8f-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011960168s
Sep  2 14:39:36.168: INFO: Pod "pod-configmaps-79f247d5-cd8f-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015243118s
STEP: Saw pod success
Sep  2 14:39:36.168: INFO: Pod "pod-configmaps-79f247d5-cd8f-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 14:39:36.171: INFO: Trying to get logs from node ip-192-168-169-21.us-west-2.compute.internal pod pod-configmaps-79f247d5-cd8f-11e9-b90e-8ed318f3d3c6 container configmap-volume-test: <nil>
STEP: delete the pod
Sep  2 14:39:36.189: INFO: Waiting for pod pod-configmaps-79f247d5-cd8f-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 14:39:36.191: INFO: Pod pod-configmaps-79f247d5-cd8f-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:39:36.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-srxc7" for this suite.
Sep  2 14:39:42.210: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:39:42.275: INFO: namespace: e2e-tests-configmap-srxc7, resource: bindings, ignored listing per whitelist
Sep  2 14:39:42.305: INFO: namespace e2e-tests-configmap-srxc7 deletion completed in 6.110303242s

• [SLOW TEST:10.335 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:39:42.305: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-pgtp5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Sep  2 14:39:42.480: INFO: Waiting up to 5m0s for pod "downwardapi-volume-801a10d7-cd8f-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-projected-pgtp5" to be "success or failure"
Sep  2 14:39:42.482: INFO: Pod "downwardapi-volume-801a10d7-cd8f-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.320669ms
Sep  2 14:39:44.491: INFO: Pod "downwardapi-volume-801a10d7-cd8f-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01131678s
Sep  2 14:39:46.494: INFO: Pod "downwardapi-volume-801a10d7-cd8f-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014681561s
STEP: Saw pod success
Sep  2 14:39:46.494: INFO: Pod "downwardapi-volume-801a10d7-cd8f-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 14:39:46.497: INFO: Trying to get logs from node ip-192-168-169-21.us-west-2.compute.internal pod downwardapi-volume-801a10d7-cd8f-11e9-b90e-8ed318f3d3c6 container client-container: <nil>
STEP: delete the pod
Sep  2 14:39:46.513: INFO: Waiting for pod downwardapi-volume-801a10d7-cd8f-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 14:39:46.515: INFO: Pod downwardapi-volume-801a10d7-cd8f-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:39:46.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pgtp5" for this suite.
Sep  2 14:39:52.534: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:39:52.607: INFO: namespace: e2e-tests-projected-pgtp5, resource: bindings, ignored listing per whitelist
Sep  2 14:39:52.631: INFO: namespace e2e-tests-projected-pgtp5 deletion completed in 6.111784934s

• [SLOW TEST:10.326 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:39:52.631: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-plggp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-plggp A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-plggp;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-plggp A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-plggp;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-plggp.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-plggp.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-plggp.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-plggp.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-plggp.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-plggp.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-plggp.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-plggp.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-plggp.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-plggp.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-plggp.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-plggp.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-plggp.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 86.10.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.10.86_udp@PTR;check="$$(dig +tcp +noall +answer +search 86.10.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.10.86_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-plggp A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-plggp;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-plggp A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-plggp;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-plggp.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-plggp.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-plggp.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-plggp.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-plggp.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-plggp.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-plggp.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-plggp.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-plggp.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-plggp.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-plggp.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-plggp.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-plggp.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 86.10.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.10.86_udp@PTR;check="$$(dig +tcp +noall +answer +search 86.10.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.10.86_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep  2 14:40:04.836: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-plggp/dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6: the server could not find the requested resource (get pods dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6)
Sep  2 14:40:04.888: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-plggp/dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6: the server could not find the requested resource (get pods dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6)
Sep  2 14:40:04.891: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-plggp/dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6: the server could not find the requested resource (get pods dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6)
Sep  2 14:40:04.894: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-plggp from pod e2e-tests-dns-plggp/dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6: the server could not find the requested resource (get pods dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6)
Sep  2 14:40:04.897: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-plggp from pod e2e-tests-dns-plggp/dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6: the server could not find the requested resource (get pods dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6)
Sep  2 14:40:04.900: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-plggp.svc from pod e2e-tests-dns-plggp/dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6: the server could not find the requested resource (get pods dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6)
Sep  2 14:40:04.903: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-plggp.svc from pod e2e-tests-dns-plggp/dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6: the server could not find the requested resource (get pods dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6)
Sep  2 14:40:04.906: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-plggp.svc from pod e2e-tests-dns-plggp/dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6: the server could not find the requested resource (get pods dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6)
Sep  2 14:40:04.909: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-plggp.svc from pod e2e-tests-dns-plggp/dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6: the server could not find the requested resource (get pods dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6)
Sep  2 14:40:04.927: INFO: Lookups using e2e-tests-dns-plggp/dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6 failed for: [wheezy_udp@dns-test-service jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-plggp jessie_tcp@dns-test-service.e2e-tests-dns-plggp jessie_udp@dns-test-service.e2e-tests-dns-plggp.svc jessie_tcp@dns-test-service.e2e-tests-dns-plggp.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-plggp.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-plggp.svc]

Sep  2 14:40:09.931: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-plggp/dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6: the server could not find the requested resource (get pods dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6)
Sep  2 14:40:09.976: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-plggp/dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6: the server could not find the requested resource (get pods dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6)
Sep  2 14:40:09.979: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-plggp/dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6: the server could not find the requested resource (get pods dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6)
Sep  2 14:40:09.982: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-plggp from pod e2e-tests-dns-plggp/dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6: the server could not find the requested resource (get pods dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6)
Sep  2 14:40:09.985: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-plggp from pod e2e-tests-dns-plggp/dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6: the server could not find the requested resource (get pods dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6)
Sep  2 14:40:09.990: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-plggp.svc from pod e2e-tests-dns-plggp/dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6: the server could not find the requested resource (get pods dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6)
Sep  2 14:40:09.993: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-plggp.svc from pod e2e-tests-dns-plggp/dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6: the server could not find the requested resource (get pods dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6)
Sep  2 14:40:09.996: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-plggp.svc from pod e2e-tests-dns-plggp/dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6: the server could not find the requested resource (get pods dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6)
Sep  2 14:40:10.000: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-plggp.svc from pod e2e-tests-dns-plggp/dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6: the server could not find the requested resource (get pods dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6)
Sep  2 14:40:10.018: INFO: Lookups using e2e-tests-dns-plggp/dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6 failed for: [wheezy_udp@dns-test-service jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-plggp jessie_tcp@dns-test-service.e2e-tests-dns-plggp jessie_udp@dns-test-service.e2e-tests-dns-plggp.svc jessie_tcp@dns-test-service.e2e-tests-dns-plggp.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-plggp.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-plggp.svc]

Sep  2 14:40:14.937: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-plggp/dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6: the server could not find the requested resource (get pods dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6)
Sep  2 14:40:14.978: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-plggp/dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6: the server could not find the requested resource (get pods dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6)
Sep  2 14:40:14.981: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-plggp/dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6: the server could not find the requested resource (get pods dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6)
Sep  2 14:40:14.984: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-plggp from pod e2e-tests-dns-plggp/dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6: the server could not find the requested resource (get pods dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6)
Sep  2 14:40:14.987: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-plggp from pod e2e-tests-dns-plggp/dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6: the server could not find the requested resource (get pods dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6)
Sep  2 14:40:14.990: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-plggp.svc from pod e2e-tests-dns-plggp/dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6: the server could not find the requested resource (get pods dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6)
Sep  2 14:40:14.993: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-plggp.svc from pod e2e-tests-dns-plggp/dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6: the server could not find the requested resource (get pods dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6)
Sep  2 14:40:14.996: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-plggp.svc from pod e2e-tests-dns-plggp/dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6: the server could not find the requested resource (get pods dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6)
Sep  2 14:40:14.999: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-plggp.svc from pod e2e-tests-dns-plggp/dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6: the server could not find the requested resource (get pods dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6)
Sep  2 14:40:15.017: INFO: Lookups using e2e-tests-dns-plggp/dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6 failed for: [wheezy_udp@dns-test-service jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-plggp jessie_tcp@dns-test-service.e2e-tests-dns-plggp jessie_udp@dns-test-service.e2e-tests-dns-plggp.svc jessie_tcp@dns-test-service.e2e-tests-dns-plggp.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-plggp.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-plggp.svc]

Sep  2 14:40:19.931: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-plggp/dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6: the server could not find the requested resource (get pods dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6)
Sep  2 14:40:19.974: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-plggp/dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6: the server could not find the requested resource (get pods dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6)
Sep  2 14:40:19.977: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-plggp/dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6: the server could not find the requested resource (get pods dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6)
Sep  2 14:40:19.980: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-plggp from pod e2e-tests-dns-plggp/dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6: the server could not find the requested resource (get pods dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6)
Sep  2 14:40:19.983: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-plggp from pod e2e-tests-dns-plggp/dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6: the server could not find the requested resource (get pods dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6)
Sep  2 14:40:19.986: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-plggp.svc from pod e2e-tests-dns-plggp/dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6: the server could not find the requested resource (get pods dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6)
Sep  2 14:40:19.989: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-plggp.svc from pod e2e-tests-dns-plggp/dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6: the server could not find the requested resource (get pods dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6)
Sep  2 14:40:19.992: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-plggp.svc from pod e2e-tests-dns-plggp/dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6: the server could not find the requested resource (get pods dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6)
Sep  2 14:40:19.995: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-plggp.svc from pod e2e-tests-dns-plggp/dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6: the server could not find the requested resource (get pods dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6)
Sep  2 14:40:20.016: INFO: Lookups using e2e-tests-dns-plggp/dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6 failed for: [wheezy_udp@dns-test-service jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-plggp jessie_tcp@dns-test-service.e2e-tests-dns-plggp jessie_udp@dns-test-service.e2e-tests-dns-plggp.svc jessie_tcp@dns-test-service.e2e-tests-dns-plggp.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-plggp.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-plggp.svc]

Sep  2 14:40:24.931: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-plggp/dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6: the server could not find the requested resource (get pods dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6)
Sep  2 14:40:24.979: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-plggp/dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6: the server could not find the requested resource (get pods dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6)
Sep  2 14:40:24.982: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-plggp/dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6: the server could not find the requested resource (get pods dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6)
Sep  2 14:40:24.985: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-plggp from pod e2e-tests-dns-plggp/dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6: the server could not find the requested resource (get pods dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6)
Sep  2 14:40:24.988: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-plggp from pod e2e-tests-dns-plggp/dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6: the server could not find the requested resource (get pods dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6)
Sep  2 14:40:24.991: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-plggp.svc from pod e2e-tests-dns-plggp/dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6: the server could not find the requested resource (get pods dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6)
Sep  2 14:40:24.994: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-plggp.svc from pod e2e-tests-dns-plggp/dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6: the server could not find the requested resource (get pods dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6)
Sep  2 14:40:24.997: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-plggp.svc from pod e2e-tests-dns-plggp/dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6: the server could not find the requested resource (get pods dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6)
Sep  2 14:40:25.000: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-plggp.svc from pod e2e-tests-dns-plggp/dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6: the server could not find the requested resource (get pods dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6)
Sep  2 14:40:25.021: INFO: Lookups using e2e-tests-dns-plggp/dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6 failed for: [wheezy_udp@dns-test-service jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-plggp jessie_tcp@dns-test-service.e2e-tests-dns-plggp jessie_udp@dns-test-service.e2e-tests-dns-plggp.svc jessie_tcp@dns-test-service.e2e-tests-dns-plggp.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-plggp.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-plggp.svc]

Sep  2 14:40:30.016: INFO: DNS probes using e2e-tests-dns-plggp/dns-test-864439aa-cd8f-11e9-b90e-8ed318f3d3c6 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:40:30.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-plggp" for this suite.
Sep  2 14:40:36.096: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:40:36.121: INFO: namespace: e2e-tests-dns-plggp, resource: bindings, ignored listing per whitelist
Sep  2 14:40:36.197: INFO: namespace e2e-tests-dns-plggp deletion completed in 6.122143396s

• [SLOW TEST:43.566 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:40:36.197: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-hd9n2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Sep  2 14:40:36.369: INFO: Waiting up to 5m0s for pod "downward-api-a038edc8-cd8f-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-downward-api-hd9n2" to be "success or failure"
Sep  2 14:40:36.371: INFO: Pod "downward-api-a038edc8-cd8f-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.298807ms
Sep  2 14:40:38.375: INFO: Pod "downward-api-a038edc8-cd8f-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005676389s
STEP: Saw pod success
Sep  2 14:40:38.375: INFO: Pod "downward-api-a038edc8-cd8f-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 14:40:38.377: INFO: Trying to get logs from node ip-192-168-77-237.us-west-2.compute.internal pod downward-api-a038edc8-cd8f-11e9-b90e-8ed318f3d3c6 container dapi-container: <nil>
STEP: delete the pod
Sep  2 14:40:38.395: INFO: Waiting for pod downward-api-a038edc8-cd8f-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 14:40:38.397: INFO: Pod downward-api-a038edc8-cd8f-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:40:38.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-hd9n2" for this suite.
Sep  2 14:40:44.417: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:40:44.493: INFO: namespace: e2e-tests-downward-api-hd9n2, resource: bindings, ignored listing per whitelist
Sep  2 14:40:44.522: INFO: namespace e2e-tests-downward-api-hd9n2 deletion completed in 6.120356898s

• [SLOW TEST:8.325 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:40:44.522: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-8ssrq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep  2 14:40:44.679: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-8ssrq'
Sep  2 14:40:44.755: INFO: stderr: ""
Sep  2 14:40:44.755: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Sep  2 14:40:49.805: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-8ssrq -o json'
Sep  2 14:40:49.875: INFO: stderr: ""
Sep  2 14:40:49.875: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"kubernetes.io/psp\": \"e2e-test-privileged-psp\"\n        },\n        \"creationTimestamp\": \"2019-09-02T14:40:44Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-8ssrq\",\n        \"resourceVersion\": \"2105968\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-8ssrq/pods/e2e-test-nginx-pod\",\n        \"uid\": \"a537e823-cd8f-11e9-a575-0a854009c708\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-sc6q6\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"ip-192-168-169-21.us-west-2.compute.internal\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-sc6q6\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-sc6q6\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-02T14:40:44Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-02T14:40:46Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-02T14:40:46Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-02T14:40:44Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://7f5c8266dbdd78f94554b0ac3f73a5453102f8a8d5f7a73931dda0c6720710fb\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-09-02T14:40:45Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"192.168.169.21\",\n        \"phase\": \"Running\",\n        \"podIP\": \"192.168.162.180\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-09-02T14:40:44Z\"\n    }\n}\n"
STEP: replace the image in the pod
Sep  2 14:40:49.875: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 replace -f - --namespace=e2e-tests-kubectl-8ssrq'
Sep  2 14:40:50.283: INFO: stderr: ""
Sep  2 14:40:50.283: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1568
Sep  2 14:40:50.286: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-8ssrq'
Sep  2 14:40:57.584: INFO: stderr: ""
Sep  2 14:40:57.584: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:40:57.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-8ssrq" for this suite.
Sep  2 14:41:03.604: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:41:03.677: INFO: namespace: e2e-tests-kubectl-8ssrq, resource: bindings, ignored listing per whitelist
Sep  2 14:41:03.704: INFO: namespace e2e-tests-kubectl-8ssrq deletion completed in 6.115864925s

• [SLOW TEST:19.182 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:41:03.704: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-ftncr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-b09e927b-cd8f-11e9-b90e-8ed318f3d3c6
STEP: Creating a pod to test consume secrets
Sep  2 14:41:03.883: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b09f507b-cd8f-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-projected-ftncr" to be "success or failure"
Sep  2 14:41:03.885: INFO: Pod "pod-projected-secrets-b09f507b-cd8f-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.682153ms
Sep  2 14:41:05.889: INFO: Pod "pod-projected-secrets-b09f507b-cd8f-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006108858s
Sep  2 14:41:07.892: INFO: Pod "pod-projected-secrets-b09f507b-cd8f-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00924393s
STEP: Saw pod success
Sep  2 14:41:07.892: INFO: Pod "pod-projected-secrets-b09f507b-cd8f-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 14:41:07.894: INFO: Trying to get logs from node ip-192-168-169-21.us-west-2.compute.internal pod pod-projected-secrets-b09f507b-cd8f-11e9-b90e-8ed318f3d3c6 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep  2 14:41:07.912: INFO: Waiting for pod pod-projected-secrets-b09f507b-cd8f-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 14:41:07.915: INFO: Pod pod-projected-secrets-b09f507b-cd8f-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:41:07.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ftncr" for this suite.
Sep  2 14:41:13.934: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:41:13.969: INFO: namespace: e2e-tests-projected-ftncr, resource: bindings, ignored listing per whitelist
Sep  2 14:41:14.032: INFO: namespace e2e-tests-projected-ftncr deletion completed in 6.113571778s

• [SLOW TEST:10.328 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:41:14.032: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-hg8rm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Sep  2 14:41:14.196: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-041707028 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:41:14.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hg8rm" for this suite.
Sep  2 14:41:20.272: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:41:20.289: INFO: namespace: e2e-tests-kubectl-hg8rm, resource: bindings, ignored listing per whitelist
Sep  2 14:41:20.367: INFO: namespace e2e-tests-kubectl-hg8rm deletion completed in 6.112734034s

• [SLOW TEST:6.336 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:41:20.368: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-8q7vv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Sep  2 14:41:20.534: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ba8c0f7e-cd8f-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-projected-8q7vv" to be "success or failure"
Sep  2 14:41:20.537: INFO: Pod "downwardapi-volume-ba8c0f7e-cd8f-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.342522ms
Sep  2 14:41:22.546: INFO: Pod "downwardapi-volume-ba8c0f7e-cd8f-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011259003s
STEP: Saw pod success
Sep  2 14:41:22.546: INFO: Pod "downwardapi-volume-ba8c0f7e-cd8f-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 14:41:22.548: INFO: Trying to get logs from node ip-192-168-169-21.us-west-2.compute.internal pod downwardapi-volume-ba8c0f7e-cd8f-11e9-b90e-8ed318f3d3c6 container client-container: <nil>
STEP: delete the pod
Sep  2 14:41:22.565: INFO: Waiting for pod downwardapi-volume-ba8c0f7e-cd8f-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 14:41:22.567: INFO: Pod downwardapi-volume-ba8c0f7e-cd8f-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:41:22.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8q7vv" for this suite.
Sep  2 14:41:28.586: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:41:28.673: INFO: namespace: e2e-tests-projected-8q7vv, resource: bindings, ignored listing per whitelist
Sep  2 14:41:28.683: INFO: namespace e2e-tests-projected-8q7vv deletion completed in 6.112502787s

• [SLOW TEST:8.315 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:41:28.683: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-6vrhd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Sep  2 14:41:28.863: INFO: Waiting up to 5m0s for pod "client-containers-bf82f59f-cd8f-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-containers-6vrhd" to be "success or failure"
Sep  2 14:41:28.865: INFO: Pod "client-containers-bf82f59f-cd8f-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.297522ms
Sep  2 14:41:30.868: INFO: Pod "client-containers-bf82f59f-cd8f-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005553709s
STEP: Saw pod success
Sep  2 14:41:30.868: INFO: Pod "client-containers-bf82f59f-cd8f-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 14:41:30.871: INFO: Trying to get logs from node ip-192-168-169-21.us-west-2.compute.internal pod client-containers-bf82f59f-cd8f-11e9-b90e-8ed318f3d3c6 container test-container: <nil>
STEP: delete the pod
Sep  2 14:41:30.888: INFO: Waiting for pod client-containers-bf82f59f-cd8f-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 14:41:30.890: INFO: Pod client-containers-bf82f59f-cd8f-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:41:30.890: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-6vrhd" for this suite.
Sep  2 14:41:36.915: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:41:36.991: INFO: namespace: e2e-tests-containers-6vrhd, resource: bindings, ignored listing per whitelist
Sep  2 14:41:37.011: INFO: namespace e2e-tests-containers-6vrhd deletion completed in 6.11766184s

• [SLOW TEST:8.328 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:41:37.011: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-zvv4w
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-zvv4w
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Sep  2 14:41:37.184: INFO: Found 0 stateful pods, waiting for 3
Sep  2 14:41:47.193: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep  2 14:41:47.193: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep  2 14:41:47.193: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Sep  2 14:41:47.201: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-zvv4w ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  2 14:41:47.346: INFO: stderr: ""
Sep  2 14:41:47.346: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  2 14:41:47.346: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Sep  2 14:41:57.380: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Sep  2 14:42:07.400: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-zvv4w ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  2 14:42:07.559: INFO: stderr: ""
Sep  2 14:42:07.559: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  2 14:42:07.559: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

STEP: Rolling back to a previous revision
Sep  2 14:42:27.581: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-zvv4w ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  2 14:42:27.732: INFO: stderr: ""
Sep  2 14:42:27.732: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  2 14:42:27.732: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  2 14:42:37.768: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Sep  2 14:42:47.788: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 exec --namespace=e2e-tests-statefulset-zvv4w ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  2 14:42:47.944: INFO: stderr: ""
Sep  2 14:42:47.944: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  2 14:42:47.944: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Sep  2 14:43:07.967: INFO: Deleting all statefulset in ns e2e-tests-statefulset-zvv4w
Sep  2 14:43:07.970: INFO: Scaling statefulset ss2 to 0
Sep  2 14:43:17.987: INFO: Waiting for statefulset status.replicas updated to 0
Sep  2 14:43:17.989: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:43:18.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-zvv4w" for this suite.
Sep  2 14:43:24.021: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:43:24.045: INFO: namespace: e2e-tests-statefulset-zvv4w, resource: bindings, ignored listing per whitelist
Sep  2 14:43:24.115: INFO: namespace e2e-tests-statefulset-zvv4w deletion completed in 6.110903497s

• [SLOW TEST:107.104 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:43:24.115: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-dhzzz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Sep  2 14:43:24.287: INFO: Pod name rollover-pod: Found 0 pods out of 1
Sep  2 14:43:29.296: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep  2 14:43:29.296: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Sep  2 14:43:31.300: INFO: Creating deployment "test-rollover-deployment"
Sep  2 14:43:31.306: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Sep  2 14:43:33.311: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Sep  2 14:43:33.317: INFO: Ensure that both replica sets have 1 created replica
Sep  2 14:43:33.324: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Sep  2 14:43:33.330: INFO: Updating deployment test-rollover-deployment
Sep  2 14:43:33.330: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Sep  2 14:43:35.335: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Sep  2 14:43:35.341: INFO: Make sure deployment "test-rollover-deployment" is complete
Sep  2 14:43:35.347: INFO: all replica sets need to contain the pod-template-hash label
Sep  2 14:43:35.347: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703032211, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703032211, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703032215, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703032211, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  2 14:43:37.354: INFO: all replica sets need to contain the pod-template-hash label
Sep  2 14:43:37.354: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703032211, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703032211, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703032215, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703032211, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  2 14:43:39.359: INFO: all replica sets need to contain the pod-template-hash label
Sep  2 14:43:39.359: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703032211, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703032211, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703032215, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703032211, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  2 14:43:41.354: INFO: all replica sets need to contain the pod-template-hash label
Sep  2 14:43:41.354: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703032211, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703032211, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703032215, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703032211, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  2 14:43:43.354: INFO: all replica sets need to contain the pod-template-hash label
Sep  2 14:43:43.354: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703032211, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703032211, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703032215, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703032211, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  2 14:43:45.354: INFO: 
Sep  2 14:43:45.354: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:2, UnavailableReplicas:0, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703032211, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703032211, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703032225, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703032211, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  2 14:43:47.354: INFO: 
Sep  2 14:43:47.354: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Sep  2 14:43:47.363: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-dhzzz,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-dhzzz/deployments/test-rollover-deployment,UID:087eb560-cd90-11e9-a575-0a854009c708,ResourceVersion:2106787,Generation:2,CreationTimestamp:2019-09-02 14:43:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-09-02 14:43:31 +0000 UTC 2019-09-02 14:43:31 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-09-02 14:43:45 +0000 UTC 2019-09-02 14:43:31 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-6b7f9d6597" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Sep  2 14:43:47.367: INFO: New ReplicaSet "test-rollover-deployment-6b7f9d6597" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597,GenerateName:,Namespace:e2e-tests-deployment-dhzzz,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-dhzzz/replicasets/test-rollover-deployment-6b7f9d6597,UID:09b4899d-cd90-11e9-96cb-060c8a2202ce,ResourceVersion:2106778,Generation:2,CreationTimestamp:2019-09-02 14:43:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 087eb560-cd90-11e9-a575-0a854009c708 0xc001a08777 0xc001a08778}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Sep  2 14:43:47.367: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Sep  2 14:43:47.367: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-dhzzz,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-dhzzz/replicasets/test-rollover-controller,UID:044f63d6-cd90-11e9-a575-0a854009c708,ResourceVersion:2106786,Generation:2,CreationTimestamp:2019-09-02 14:43:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 087eb560-cd90-11e9-a575-0a854009c708 0xc001a08567 0xc001a08568}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep  2 14:43:47.367: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6586df867b,GenerateName:,Namespace:e2e-tests-deployment-dhzzz,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-dhzzz/replicasets/test-rollover-deployment-6586df867b,UID:08819ade-cd90-11e9-96cb-060c8a2202ce,ResourceVersion:2106746,Generation:2,CreationTimestamp:2019-09-02 14:43:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 087eb560-cd90-11e9-a575-0a854009c708 0xc001a08627 0xc001a08628}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep  2 14:43:47.370: INFO: Pod "test-rollover-deployment-6b7f9d6597-9q74j" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597-9q74j,GenerateName:test-rollover-deployment-6b7f9d6597-,Namespace:e2e-tests-deployment-dhzzz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-dhzzz/pods/test-rollover-deployment-6b7f9d6597-9q74j,UID:09b81c20-cd90-11e9-96cb-060c8a2202ce,ResourceVersion:2106759,Generation:0,CreationTimestamp:2019-09-02 14:43:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-6b7f9d6597 09b4899d-cd90-11e9-96cb-060c8a2202ce 0xc001a09637 0xc001a09638}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-gkj7g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-gkj7g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-gkj7g true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-192-168-169-21.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001a096a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001a096c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:43:33 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:43:35 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:43:35 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-02 14:43:33 +0000 UTC  }],Message:,Reason:,HostIP:192.168.169.21,PodIP:192.168.173.15,StartTime:2019-09-02 14:43:33 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-09-02 14:43:34 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://f2ba73cfbb81a418cc4f7a49f8a723fba88650a136e54d8b17ef28d55258f975}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:43:47.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-dhzzz" for this suite.
Sep  2 14:43:53.393: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:43:53.439: INFO: namespace: e2e-tests-deployment-dhzzz, resource: bindings, ignored listing per whitelist
Sep  2 14:43:53.489: INFO: namespace e2e-tests-deployment-dhzzz deletion completed in 6.115719185s

• [SLOW TEST:29.374 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:43:53.489: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-dvlgm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-dvlgm
Sep  2 14:43:55.671: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-dvlgm
STEP: checking the pod's current state and verifying that restartCount is present
Sep  2 14:43:55.674: INFO: Initial restart count of pod liveness-exec is 0
Sep  2 14:44:41.780: INFO: Restart count of pod e2e-tests-container-probe-dvlgm/liveness-exec is now 1 (46.106530522s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:44:41.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-dvlgm" for this suite.
Sep  2 14:44:47.809: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:44:47.852: INFO: namespace: e2e-tests-container-probe-dvlgm, resource: bindings, ignored listing per whitelist
Sep  2 14:44:47.903: INFO: namespace e2e-tests-container-probe-dvlgm deletion completed in 6.109184279s

• [SLOW TEST:54.414 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:44:47.903: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-runtime-6l5lr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:45:12.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-runtime-6l5lr" for this suite.
Sep  2 14:45:18.267: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:45:18.313: INFO: namespace: e2e-tests-container-runtime-6l5lr, resource: bindings, ignored listing per whitelist
Sep  2 14:45:18.363: INFO: namespace e2e-tests-container-runtime-6l5lr deletion completed in 6.112548318s

• [SLOW TEST:30.460 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  blackbox test
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:45:18.363: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-9lzwk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Sep  2 14:45:18.529: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-041707028 --namespace=e2e-tests-kubectl-9lzwk run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Sep  2 14:45:20.760: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Sep  2 14:45:20.760: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:45:22.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-9lzwk" for this suite.
Sep  2 14:45:28.788: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:45:28.823: INFO: namespace: e2e-tests-kubectl-9lzwk, resource: bindings, ignored listing per whitelist
Sep  2 14:45:28.893: INFO: namespace e2e-tests-kubectl-9lzwk deletion completed in 6.121188542s

• [SLOW TEST:10.530 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:45:28.894: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-zdqqn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-zdqqn/configmap-test-4eaefb67-cd90-11e9-b90e-8ed318f3d3c6
STEP: Creating a pod to test consume configMaps
Sep  2 14:45:29.071: INFO: Waiting up to 5m0s for pod "pod-configmaps-4eafd548-cd90-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-configmap-zdqqn" to be "success or failure"
Sep  2 14:45:29.073: INFO: Pod "pod-configmaps-4eafd548-cd90-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.353917ms
Sep  2 14:45:31.082: INFO: Pod "pod-configmaps-4eafd548-cd90-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01092697s
STEP: Saw pod success
Sep  2 14:45:31.082: INFO: Pod "pod-configmaps-4eafd548-cd90-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 14:45:31.084: INFO: Trying to get logs from node ip-192-168-169-21.us-west-2.compute.internal pod pod-configmaps-4eafd548-cd90-11e9-b90e-8ed318f3d3c6 container env-test: <nil>
STEP: delete the pod
Sep  2 14:45:31.102: INFO: Waiting for pod pod-configmaps-4eafd548-cd90-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 14:45:31.104: INFO: Pod pod-configmaps-4eafd548-cd90-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:45:31.104: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-zdqqn" for this suite.
Sep  2 14:45:37.124: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:45:37.193: INFO: namespace: e2e-tests-configmap-zdqqn, resource: bindings, ignored listing per whitelist
Sep  2 14:45:37.219: INFO: namespace e2e-tests-configmap-zdqqn deletion completed in 6.111469019s

• [SLOW TEST:8.326 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:45:37.219: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-8wml2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-53a4eb55-cd90-11e9-b90e-8ed318f3d3c6
STEP: Creating a pod to test consume secrets
Sep  2 14:45:37.392: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-53a59a15-cd90-11e9-b90e-8ed318f3d3c6" in namespace "e2e-tests-projected-8wml2" to be "success or failure"
Sep  2 14:45:37.394: INFO: Pod "pod-projected-secrets-53a59a15-cd90-11e9-b90e-8ed318f3d3c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.249493ms
Sep  2 14:45:39.397: INFO: Pod "pod-projected-secrets-53a59a15-cd90-11e9-b90e-8ed318f3d3c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005322823s
STEP: Saw pod success
Sep  2 14:45:39.397: INFO: Pod "pod-projected-secrets-53a59a15-cd90-11e9-b90e-8ed318f3d3c6" satisfied condition "success or failure"
Sep  2 14:45:39.400: INFO: Trying to get logs from node ip-192-168-169-21.us-west-2.compute.internal pod pod-projected-secrets-53a59a15-cd90-11e9-b90e-8ed318f3d3c6 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep  2 14:45:39.417: INFO: Waiting for pod pod-projected-secrets-53a59a15-cd90-11e9-b90e-8ed318f3d3c6 to disappear
Sep  2 14:45:39.419: INFO: Pod pod-projected-secrets-53a59a15-cd90-11e9-b90e-8ed318f3d3c6 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:45:39.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8wml2" for this suite.
Sep  2 14:45:45.437: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:45:45.504: INFO: namespace: e2e-tests-projected-8wml2, resource: bindings, ignored listing per whitelist
Sep  2 14:45:45.533: INFO: namespace e2e-tests-projected-8wml2 deletion completed in 6.110879104s

• [SLOW TEST:8.314 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:45:45.533: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-ng7cc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:45:49.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-ng7cc" for this suite.
Sep  2 14:45:55.733: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:45:55.818: INFO: namespace: e2e-tests-kubelet-test-ng7cc, resource: bindings, ignored listing per whitelist
Sep  2 14:45:55.827: INFO: namespace e2e-tests-kubelet-test-ng7cc deletion completed in 6.109723983s

• [SLOW TEST:10.294 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Sep  2 14:45:55.827: INFO: >>> kubeConfig: /tmp/kubeconfig-041707028
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-xbl74
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-xbl74
Sep  2 14:45:58.006: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-xbl74
STEP: checking the pod's current state and verifying that restartCount is present
Sep  2 14:45:58.009: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Sep  2 14:49:58.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-xbl74" for this suite.
Sep  2 14:50:04.578: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  2 14:50:04.584: INFO: namespace: e2e-tests-container-probe-xbl74, resource: bindings, ignored listing per whitelist
Sep  2 14:50:04.684: INFO: namespace e2e-tests-container-probe-xbl74 deletion completed in 6.121848296s

• [SLOW TEST:248.857 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSep  2 14:50:04.685: INFO: Running AfterSuite actions on all nodes
Sep  2 14:50:04.685: INFO: Running AfterSuite actions on node 1
Sep  2 14:50:04.685: INFO: Skipping dumping logs from cluster

Ran 200 of 1946 Specs in 6101.518 seconds
SUCCESS! -- 200 Passed | 0 Failed | 0 Pending | 1746 Skipped PASS

Ginkgo ran 1 suite in 1h41m42.328228919s
Test Suite Passed
