I0206 01:52:42.141596      15 test_context.go:358] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-511574509
I0206 01:52:42.141690      15 e2e.go:224] Starting e2e run "e37cbfc9-29b1-11e9-b6e7-06cba7aec104" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1549417961 - Will randomize all specs
Will run 201 of 1946 specs

Feb  6 01:52:42.347: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
Feb  6 01:52:42.349: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Feb  6 01:52:42.468: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Feb  6 01:52:43.240: INFO: 23 / 23 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Feb  6 01:52:43.240: INFO: expected 11 pod replicas in namespace 'kube-system', 11 are Running and Ready.
Feb  6 01:52:43.240: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Feb  6 01:52:43.258: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Feb  6 01:52:43.258: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ibm-keepalived-watcher' (0 seconds elapsed)
Feb  6 01:52:43.258: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ibm-kube-fluentd' (0 seconds elapsed)
Feb  6 01:52:43.258: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'ibm-master-proxy' (0 seconds elapsed)
Feb  6 01:52:43.258: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-driver-installer' (0 seconds elapsed)
Feb  6 01:52:43.258: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-gpu-device-plugin' (0 seconds elapsed)
Feb  6 01:52:43.258: INFO: e2e test version: v1.13.0
Feb  6 01:52:43.261: INFO: kube-apiserver version: v1.13.2+IKS
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 01:52:43.261: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename emptydir
Feb  6 01:52:43.521: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Feb  6 01:52:43.551: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-4r5zj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb  6 01:52:43.696: INFO: Waiting up to 5m0s for pod "pod-e4d6c2c0-29b1-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-emptydir-4r5zj" to be "success or failure"
Feb  6 01:52:43.703: INFO: Pod "pod-e4d6c2c0-29b1-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 6.770702ms
Feb  6 01:52:45.710: INFO: Pod "pod-e4d6c2c0-29b1-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014385455s
STEP: Saw pod success
Feb  6 01:52:45.710: INFO: Pod "pod-e4d6c2c0-29b1-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 01:52:45.717: INFO: Trying to get logs from node 10.190.119.145 pod pod-e4d6c2c0-29b1-11e9-b6e7-06cba7aec104 container test-container: <nil>
STEP: delete the pod
Feb  6 01:52:45.938: INFO: Waiting for pod pod-e4d6c2c0-29b1-11e9-b6e7-06cba7aec104 to disappear
Feb  6 01:52:45.950: INFO: Pod pod-e4d6c2c0-29b1-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 01:52:45.950: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-4r5zj" for this suite.
Feb  6 01:52:54.037: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 01:52:54.416: INFO: namespace: e2e-tests-emptydir-4r5zj, resource: bindings, ignored listing per whitelist
Feb  6 01:52:54.535: INFO: namespace e2e-tests-emptydir-4r5zj deletion completed in 8.573275304s

• [SLOW TEST:11.274 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 01:52:54.538: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-5zb65
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Feb  6 01:52:55.056: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb  6 01:52:55.083: INFO: Waiting for terminating namespaces to be deleted...
Feb  6 01:52:55.094: INFO: 
Logging pods the kubelet thinks is on node 10.190.119.144 before test
Feb  6 01:52:55.137: INFO: coredns-autoscaler-64f9c5b4df-44r7b from kube-system started at 2019-02-05 20:41:42 +0000 UTC (1 container statuses recorded)
Feb  6 01:52:55.137: INFO: 	Container autoscaler ready: true, restart count 0
Feb  6 01:52:55.137: INFO: ibm-kube-fluentd-8hwlq from kube-system started at 2019-02-05 20:46:37 +0000 UTC (1 container statuses recorded)
Feb  6 01:52:55.137: INFO: 	Container fluentd ready: true, restart count 0
Feb  6 01:52:55.137: INFO: ibm-storage-watcher-d566545b-tgbbx from kube-system started at 2019-02-05 20:41:42 +0000 UTC (1 container statuses recorded)
Feb  6 01:52:55.137: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Feb  6 01:52:55.138: INFO: test-k8s-e2e-pvg-master-verification from default started at 2019-02-06 01:52:30 +0000 UTC (1 container statuses recorded)
Feb  6 01:52:55.138: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Feb  6 01:52:55.138: INFO: calico-kube-controllers-65868f965d-5tqjq from kube-system started at 2019-02-05 20:41:42 +0000 UTC (1 container statuses recorded)
Feb  6 01:52:55.138: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Feb  6 01:52:55.138: INFO: sonobuoy-e2e-job-8583898d905b4e12 from heptio-sonobuoy started at 2019-02-06 01:52:39 +0000 UTC (2 container statuses recorded)
Feb  6 01:52:55.138: INFO: 	Container e2e ready: true, restart count 0
Feb  6 01:52:55.138: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  6 01:52:55.138: INFO: sonobuoy-systemd-logs-daemon-set-5456463907b0461e-nvm56 from heptio-sonobuoy started at 2019-02-06 01:52:39 +0000 UTC (2 container statuses recorded)
Feb  6 01:52:55.138: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb  6 01:52:55.139: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  6 01:52:55.139: INFO: ibm-file-plugin-7b7c4fbfdf-bn7kf from kube-system started at 2019-02-05 20:41:42 +0000 UTC (1 container statuses recorded)
Feb  6 01:52:55.139: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Feb  6 01:52:55.139: INFO: ibm-master-proxy-static-10.190.119.144 from kube-system started at <nil> (0 container statuses recorded)
Feb  6 01:52:55.139: INFO: kubernetes-dashboard-7996b848f4-nsjp4 from kube-system started at 2019-02-05 20:41:42 +0000 UTC (1 container statuses recorded)
Feb  6 01:52:55.139: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Feb  6 01:52:55.139: INFO: vpn-74bb4868b9-htqtq from kube-system started at 2019-02-05 20:41:42 +0000 UTC (1 container statuses recorded)
Feb  6 01:52:55.139: INFO: 	Container vpn ready: true, restart count 0
Feb  6 01:52:55.139: INFO: calico-node-d28tb from kube-system started at 2019-02-05 20:41:42 +0000 UTC (1 container statuses recorded)
Feb  6 01:52:55.139: INFO: 	Container calico-node ready: true, restart count 0
Feb  6 01:52:55.139: INFO: ibm-keepalived-watcher-sxzhx from kube-system started at 2019-02-05 20:41:42 +0000 UTC (1 container statuses recorded)
Feb  6 01:52:55.140: INFO: 	Container keepalived-watcher ready: true, restart count 0
Feb  6 01:52:55.140: INFO: coredns-977545f8c-8xszx from kube-system started at 2019-02-05 20:41:42 +0000 UTC (1 container statuses recorded)
Feb  6 01:52:55.140: INFO: 	Container coredns ready: true, restart count 0
Feb  6 01:52:55.140: INFO: 
Logging pods the kubelet thinks is on node 10.190.119.145 before test
Feb  6 01:52:55.176: INFO: calico-node-g74q7 from kube-system started at 2019-02-05 20:41:46 +0000 UTC (1 container statuses recorded)
Feb  6 01:52:55.176: INFO: 	Container calico-node ready: true, restart count 0
Feb  6 01:52:55.176: INFO: coredns-977545f8c-wd8s5 from kube-system started at 2019-02-05 20:42:21 +0000 UTC (1 container statuses recorded)
Feb  6 01:52:55.176: INFO: 	Container coredns ready: true, restart count 0
Feb  6 01:52:55.176: INFO: ibm-master-proxy-static-10.190.119.145 from kube-system started at <nil> (0 container statuses recorded)
Feb  6 01:52:55.176: INFO: ibm-keepalived-watcher-9tr5j from kube-system started at 2019-02-05 20:41:46 +0000 UTC (1 container statuses recorded)
Feb  6 01:52:55.176: INFO: 	Container keepalived-watcher ready: true, restart count 0
Feb  6 01:52:55.176: INFO: sonobuoy-systemd-logs-daemon-set-5456463907b0461e-58dv7 from heptio-sonobuoy started at 2019-02-06 01:52:39 +0000 UTC (2 container statuses recorded)
Feb  6 01:52:55.177: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb  6 01:52:55.177: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  6 01:52:55.177: INFO: ibm-cloud-provider-ip-169-62-46-254-d46d48fdc-ft5xq from ibm-system started at 2019-02-05 20:44:05 +0000 UTC (1 container statuses recorded)
Feb  6 01:52:55.177: INFO: 	Container ibm-cloud-provider-ip-169-62-46-254 ready: true, restart count 0
Feb  6 01:52:55.177: INFO: ibm-kube-fluentd-ps2t7 from kube-system started at 2019-02-05 20:46:37 +0000 UTC (1 container statuses recorded)
Feb  6 01:52:55.177: INFO: 	Container fluentd ready: true, restart count 0
Feb  6 01:52:55.177: INFO: public-cr12917ac601404a7783a11c06c1855dfa-alb1-577556c79f-qtqdm from kube-system started at 2019-02-05 20:44:39 +0000 UTC (4 container statuses recorded)
Feb  6 01:52:55.177: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Feb  6 01:52:55.177: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Feb  6 01:52:55.177: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Feb  6 01:52:55.177: INFO: 	Container nginx-ingress ready: true, restart count 0
Feb  6 01:52:55.178: INFO: 
Logging pods the kubelet thinks is on node 10.190.119.175 before test
Feb  6 01:52:55.211: INFO: ibm-kube-fluentd-xv99z from kube-system started at 2019-02-05 20:46:37 +0000 UTC (1 container statuses recorded)
Feb  6 01:52:55.211: INFO: 	Container fluentd ready: true, restart count 0
Feb  6 01:52:55.212: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-06 01:52:37 +0000 UTC (1 container statuses recorded)
Feb  6 01:52:55.212: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb  6 01:52:55.212: INFO: metrics-server-5cd649bcd6-xk698 from kube-system started at 2019-02-05 20:42:24 +0000 UTC (2 container statuses recorded)
Feb  6 01:52:55.212: INFO: 	Container metrics-server ready: true, restart count 0
Feb  6 01:52:55.212: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Feb  6 01:52:55.212: INFO: ibm-master-proxy-static-10.190.119.175 from kube-system started at <nil> (0 container statuses recorded)
Feb  6 01:52:55.212: INFO: calico-node-zndfr from kube-system started at 2019-02-05 20:41:53 +0000 UTC (1 container statuses recorded)
Feb  6 01:52:55.212: INFO: 	Container calico-node ready: true, restart count 0
Feb  6 01:52:55.212: INFO: ibm-cloud-provider-ip-169-62-46-254-d46d48fdc-4hd27 from ibm-system started at 2019-02-05 20:44:05 +0000 UTC (1 container statuses recorded)
Feb  6 01:52:55.212: INFO: 	Container ibm-cloud-provider-ip-169-62-46-254 ready: true, restart count 0
Feb  6 01:52:55.213: INFO: ibm-keepalived-watcher-ktp5r from kube-system started at 2019-02-05 20:41:53 +0000 UTC (1 container statuses recorded)
Feb  6 01:52:55.213: INFO: 	Container keepalived-watcher ready: true, restart count 0
Feb  6 01:52:55.213: INFO: public-cr12917ac601404a7783a11c06c1855dfa-alb1-577556c79f-stvrk from kube-system started at 2019-02-05 20:44:39 +0000 UTC (4 container statuses recorded)
Feb  6 01:52:55.213: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Feb  6 01:52:55.213: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Feb  6 01:52:55.213: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Feb  6 01:52:55.213: INFO: 	Container nginx-ingress ready: true, restart count 0
Feb  6 01:52:55.213: INFO: sonobuoy-systemd-logs-daemon-set-5456463907b0461e-mp9gt from heptio-sonobuoy started at 2019-02-06 01:52:39 +0000 UTC (2 container statuses recorded)
Feb  6 01:52:55.213: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb  6 01:52:55.213: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1580a37078f12c62], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 01:52:56.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-5zb65" for this suite.
Feb  6 01:53:02.351: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 01:53:02.466: INFO: namespace: e2e-tests-sched-pred-5zb65, resource: bindings, ignored listing per whitelist
Feb  6 01:53:02.676: INFO: namespace e2e-tests-sched-pred-5zb65 deletion completed in 6.362584238s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:8.139 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 01:53:02.676: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-wbnwn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Feb  6 01:53:03.026: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb  6 01:53:03.044: INFO: Waiting for terminating namespaces to be deleted...
Feb  6 01:53:03.053: INFO: 
Logging pods the kubelet thinks is on node 10.190.119.144 before test
Feb  6 01:53:03.089: INFO: ibm-file-plugin-7b7c4fbfdf-bn7kf from kube-system started at 2019-02-05 20:41:42 +0000 UTC (1 container statuses recorded)
Feb  6 01:53:03.089: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Feb  6 01:53:03.089: INFO: sonobuoy-e2e-job-8583898d905b4e12 from heptio-sonobuoy started at 2019-02-06 01:52:39 +0000 UTC (2 container statuses recorded)
Feb  6 01:53:03.089: INFO: 	Container e2e ready: true, restart count 0
Feb  6 01:53:03.089: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  6 01:53:03.089: INFO: sonobuoy-systemd-logs-daemon-set-5456463907b0461e-nvm56 from heptio-sonobuoy started at 2019-02-06 01:52:39 +0000 UTC (2 container statuses recorded)
Feb  6 01:53:03.089: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb  6 01:53:03.089: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  6 01:53:03.089: INFO: ibm-master-proxy-static-10.190.119.144 from kube-system started at <nil> (0 container statuses recorded)
Feb  6 01:53:03.089: INFO: ibm-keepalived-watcher-sxzhx from kube-system started at 2019-02-05 20:41:42 +0000 UTC (1 container statuses recorded)
Feb  6 01:53:03.089: INFO: 	Container keepalived-watcher ready: true, restart count 0
Feb  6 01:53:03.089: INFO: coredns-977545f8c-8xszx from kube-system started at 2019-02-05 20:41:42 +0000 UTC (1 container statuses recorded)
Feb  6 01:53:03.089: INFO: 	Container coredns ready: true, restart count 0
Feb  6 01:53:03.089: INFO: kubernetes-dashboard-7996b848f4-nsjp4 from kube-system started at 2019-02-05 20:41:42 +0000 UTC (1 container statuses recorded)
Feb  6 01:53:03.089: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Feb  6 01:53:03.089: INFO: vpn-74bb4868b9-htqtq from kube-system started at 2019-02-05 20:41:42 +0000 UTC (1 container statuses recorded)
Feb  6 01:53:03.089: INFO: 	Container vpn ready: true, restart count 0
Feb  6 01:53:03.089: INFO: calico-node-d28tb from kube-system started at 2019-02-05 20:41:42 +0000 UTC (1 container statuses recorded)
Feb  6 01:53:03.089: INFO: 	Container calico-node ready: true, restart count 0
Feb  6 01:53:03.089: INFO: test-k8s-e2e-pvg-master-verification from default started at 2019-02-06 01:52:30 +0000 UTC (1 container statuses recorded)
Feb  6 01:53:03.089: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Feb  6 01:53:03.089: INFO: calico-kube-controllers-65868f965d-5tqjq from kube-system started at 2019-02-05 20:41:42 +0000 UTC (1 container statuses recorded)
Feb  6 01:53:03.089: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Feb  6 01:53:03.089: INFO: coredns-autoscaler-64f9c5b4df-44r7b from kube-system started at 2019-02-05 20:41:42 +0000 UTC (1 container statuses recorded)
Feb  6 01:53:03.089: INFO: 	Container autoscaler ready: true, restart count 0
Feb  6 01:53:03.089: INFO: ibm-kube-fluentd-8hwlq from kube-system started at 2019-02-05 20:46:37 +0000 UTC (1 container statuses recorded)
Feb  6 01:53:03.089: INFO: 	Container fluentd ready: true, restart count 0
Feb  6 01:53:03.089: INFO: ibm-storage-watcher-d566545b-tgbbx from kube-system started at 2019-02-05 20:41:42 +0000 UTC (1 container statuses recorded)
Feb  6 01:53:03.089: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Feb  6 01:53:03.089: INFO: 
Logging pods the kubelet thinks is on node 10.190.119.145 before test
Feb  6 01:53:03.118: INFO: coredns-977545f8c-wd8s5 from kube-system started at 2019-02-05 20:42:21 +0000 UTC (1 container statuses recorded)
Feb  6 01:53:03.118: INFO: 	Container coredns ready: true, restart count 0
Feb  6 01:53:03.118: INFO: ibm-master-proxy-static-10.190.119.145 from kube-system started at <nil> (0 container statuses recorded)
Feb  6 01:53:03.118: INFO: ibm-keepalived-watcher-9tr5j from kube-system started at 2019-02-05 20:41:46 +0000 UTC (1 container statuses recorded)
Feb  6 01:53:03.118: INFO: 	Container keepalived-watcher ready: true, restart count 0
Feb  6 01:53:03.118: INFO: calico-node-g74q7 from kube-system started at 2019-02-05 20:41:46 +0000 UTC (1 container statuses recorded)
Feb  6 01:53:03.118: INFO: 	Container calico-node ready: true, restart count 0
Feb  6 01:53:03.118: INFO: ibm-cloud-provider-ip-169-62-46-254-d46d48fdc-ft5xq from ibm-system started at 2019-02-05 20:44:05 +0000 UTC (1 container statuses recorded)
Feb  6 01:53:03.118: INFO: 	Container ibm-cloud-provider-ip-169-62-46-254 ready: true, restart count 0
Feb  6 01:53:03.118: INFO: ibm-kube-fluentd-ps2t7 from kube-system started at 2019-02-05 20:46:37 +0000 UTC (1 container statuses recorded)
Feb  6 01:53:03.118: INFO: 	Container fluentd ready: true, restart count 0
Feb  6 01:53:03.118: INFO: sonobuoy-systemd-logs-daemon-set-5456463907b0461e-58dv7 from heptio-sonobuoy started at 2019-02-06 01:52:39 +0000 UTC (2 container statuses recorded)
Feb  6 01:53:03.118: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb  6 01:53:03.118: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  6 01:53:03.118: INFO: public-cr12917ac601404a7783a11c06c1855dfa-alb1-577556c79f-qtqdm from kube-system started at 2019-02-05 20:44:39 +0000 UTC (4 container statuses recorded)
Feb  6 01:53:03.118: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Feb  6 01:53:03.118: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Feb  6 01:53:03.118: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Feb  6 01:53:03.118: INFO: 	Container nginx-ingress ready: true, restart count 0
Feb  6 01:53:03.118: INFO: 
Logging pods the kubelet thinks is on node 10.190.119.175 before test
Feb  6 01:53:03.150: INFO: ibm-master-proxy-static-10.190.119.175 from kube-system started at <nil> (0 container statuses recorded)
Feb  6 01:53:03.150: INFO: calico-node-zndfr from kube-system started at 2019-02-05 20:41:53 +0000 UTC (1 container statuses recorded)
Feb  6 01:53:03.150: INFO: 	Container calico-node ready: true, restart count 0
Feb  6 01:53:03.150: INFO: ibm-cloud-provider-ip-169-62-46-254-d46d48fdc-4hd27 from ibm-system started at 2019-02-05 20:44:05 +0000 UTC (1 container statuses recorded)
Feb  6 01:53:03.150: INFO: 	Container ibm-cloud-provider-ip-169-62-46-254 ready: true, restart count 0
Feb  6 01:53:03.150: INFO: ibm-keepalived-watcher-ktp5r from kube-system started at 2019-02-05 20:41:53 +0000 UTC (1 container statuses recorded)
Feb  6 01:53:03.150: INFO: 	Container keepalived-watcher ready: true, restart count 0
Feb  6 01:53:03.150: INFO: public-cr12917ac601404a7783a11c06c1855dfa-alb1-577556c79f-stvrk from kube-system started at 2019-02-05 20:44:39 +0000 UTC (4 container statuses recorded)
Feb  6 01:53:03.151: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Feb  6 01:53:03.151: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Feb  6 01:53:03.151: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Feb  6 01:53:03.151: INFO: 	Container nginx-ingress ready: true, restart count 0
Feb  6 01:53:03.151: INFO: sonobuoy-systemd-logs-daemon-set-5456463907b0461e-mp9gt from heptio-sonobuoy started at 2019-02-06 01:52:39 +0000 UTC (2 container statuses recorded)
Feb  6 01:53:03.151: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb  6 01:53:03.151: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  6 01:53:03.151: INFO: ibm-kube-fluentd-xv99z from kube-system started at 2019-02-05 20:46:37 +0000 UTC (1 container statuses recorded)
Feb  6 01:53:03.151: INFO: 	Container fluentd ready: true, restart count 0
Feb  6 01:53:03.151: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-06 01:52:37 +0000 UTC (1 container statuses recorded)
Feb  6 01:53:03.151: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb  6 01:53:03.151: INFO: metrics-server-5cd649bcd6-xk698 from kube-system started at 2019-02-05 20:42:24 +0000 UTC (2 container statuses recorded)
Feb  6 01:53:03.151: INFO: 	Container metrics-server ready: true, restart count 0
Feb  6 01:53:03.151: INFO: 	Container metrics-server-nanny ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-f1b2ebd9-29b1-11e9-b6e7-06cba7aec104 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-f1b2ebd9-29b1-11e9-b6e7-06cba7aec104 off the node 10.190.119.175
STEP: verifying the node doesn't have the label kubernetes.io/e2e-f1b2ebd9-29b1-11e9-b6e7-06cba7aec104
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 01:53:07.556: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-wbnwn" for this suite.
Feb  6 01:53:23.603: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 01:53:23.846: INFO: namespace: e2e-tests-sched-pred-wbnwn, resource: bindings, ignored listing per whitelist
Feb  6 01:53:24.876: INFO: namespace e2e-tests-sched-pred-wbnwn deletion completed in 17.309172785s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:22.199 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 01:53:24.876: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-9rlbk
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Feb  6 01:53:25.266: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-9rlbk,SelfLink:/api/v1/namespaces/e2e-tests-watch-9rlbk/configmaps/e2e-watch-test-label-changed,UID:fd9a382f-29b1-11e9-9423-66f50c9be06e,ResourceVersion:49374,Generation:0,CreationTimestamp:2019-02-06 01:53:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb  6 01:53:25.266: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-9rlbk,SelfLink:/api/v1/namespaces/e2e-tests-watch-9rlbk/configmaps/e2e-watch-test-label-changed,UID:fd9a382f-29b1-11e9-9423-66f50c9be06e,ResourceVersion:49375,Generation:0,CreationTimestamp:2019-02-06 01:53:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb  6 01:53:25.266: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-9rlbk,SelfLink:/api/v1/namespaces/e2e-tests-watch-9rlbk/configmaps/e2e-watch-test-label-changed,UID:fd9a382f-29b1-11e9-9423-66f50c9be06e,ResourceVersion:49376,Generation:0,CreationTimestamp:2019-02-06 01:53:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Feb  6 01:53:35.361: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-9rlbk,SelfLink:/api/v1/namespaces/e2e-tests-watch-9rlbk/configmaps/e2e-watch-test-label-changed,UID:fd9a382f-29b1-11e9-9423-66f50c9be06e,ResourceVersion:49394,Generation:0,CreationTimestamp:2019-02-06 01:53:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb  6 01:53:35.361: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-9rlbk,SelfLink:/api/v1/namespaces/e2e-tests-watch-9rlbk/configmaps/e2e-watch-test-label-changed,UID:fd9a382f-29b1-11e9-9423-66f50c9be06e,ResourceVersion:49395,Generation:0,CreationTimestamp:2019-02-06 01:53:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Feb  6 01:53:35.362: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-9rlbk,SelfLink:/api/v1/namespaces/e2e-tests-watch-9rlbk/configmaps/e2e-watch-test-label-changed,UID:fd9a382f-29b1-11e9-9423-66f50c9be06e,ResourceVersion:49396,Generation:0,CreationTimestamp:2019-02-06 01:53:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 01:53:35.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-9rlbk" for this suite.
Feb  6 01:53:41.413: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 01:53:41.524: INFO: namespace: e2e-tests-watch-9rlbk, resource: bindings, ignored listing per whitelist
Feb  6 01:53:41.815: INFO: namespace e2e-tests-watch-9rlbk deletion completed in 6.44222888s

• [SLOW TEST:16.940 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 01:53:41.816: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-wgfkl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Feb  6 01:53:42.267: INFO: Waiting up to 5m0s for pod "client-containers-07c061f8-29b2-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-containers-wgfkl" to be "success or failure"
Feb  6 01:53:42.274: INFO: Pod "client-containers-07c061f8-29b2-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 7.159184ms
Feb  6 01:53:44.281: INFO: Pod "client-containers-07c061f8-29b2-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01452263s
STEP: Saw pod success
Feb  6 01:53:44.282: INFO: Pod "client-containers-07c061f8-29b2-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 01:53:44.289: INFO: Trying to get logs from node 10.190.119.144 pod client-containers-07c061f8-29b2-11e9-b6e7-06cba7aec104 container test-container: <nil>
STEP: delete the pod
Feb  6 01:53:44.332: INFO: Waiting for pod client-containers-07c061f8-29b2-11e9-b6e7-06cba7aec104 to disappear
Feb  6 01:53:44.340: INFO: Pod client-containers-07c061f8-29b2-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 01:53:44.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-wgfkl" for this suite.
Feb  6 01:53:50.563: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 01:53:50.745: INFO: namespace: e2e-tests-containers-wgfkl, resource: bindings, ignored listing per whitelist
Feb  6 01:53:50.975: INFO: namespace e2e-tests-containers-wgfkl deletion completed in 6.624514795s

• [SLOW TEST:9.160 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 01:53:50.976: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-vflnw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secret-namespace-gdfrr
STEP: Creating secret with name secret-test-0d39989d-29b2-11e9-b6e7-06cba7aec104
STEP: Creating a pod to test consume secrets
Feb  6 01:53:51.684: INFO: Waiting up to 5m0s for pod "pod-secrets-0d5d520c-29b2-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-secrets-vflnw" to be "success or failure"
Feb  6 01:53:51.691: INFO: Pod "pod-secrets-0d5d520c-29b2-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 6.88286ms
Feb  6 01:53:53.699: INFO: Pod "pod-secrets-0d5d520c-29b2-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01538769s
STEP: Saw pod success
Feb  6 01:53:53.699: INFO: Pod "pod-secrets-0d5d520c-29b2-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 01:53:53.706: INFO: Trying to get logs from node 10.190.119.145 pod pod-secrets-0d5d520c-29b2-11e9-b6e7-06cba7aec104 container secret-volume-test: <nil>
STEP: delete the pod
Feb  6 01:53:53.797: INFO: Waiting for pod pod-secrets-0d5d520c-29b2-11e9-b6e7-06cba7aec104 to disappear
Feb  6 01:53:53.807: INFO: Pod pod-secrets-0d5d520c-29b2-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 01:53:53.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-vflnw" for this suite.
Feb  6 01:53:59.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 01:54:00.220: INFO: namespace: e2e-tests-secrets-vflnw, resource: bindings, ignored listing per whitelist
Feb  6 01:54:00.417: INFO: namespace e2e-tests-secrets-vflnw deletion completed in 6.599753768s
STEP: Destroying namespace "e2e-tests-secret-namespace-gdfrr" for this suite.
Feb  6 01:54:08.699: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 01:54:08.980: INFO: namespace: e2e-tests-secret-namespace-gdfrr, resource: bindings, ignored listing per whitelist
Feb  6 01:54:09.115: INFO: namespace e2e-tests-secret-namespace-gdfrr deletion completed in 8.697446631s

• [SLOW TEST:18.139 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 01:54:09.116: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-ldv46
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  6 01:54:09.503: INFO: Waiting up to 5m0s for pod "downwardapi-volume-17fbe6ff-29b2-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-downward-api-ldv46" to be "success or failure"
Feb  6 01:54:09.513: INFO: Pod "downwardapi-volume-17fbe6ff-29b2-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 9.057548ms
Feb  6 01:54:11.522: INFO: Pod "downwardapi-volume-17fbe6ff-29b2-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018152568s
STEP: Saw pod success
Feb  6 01:54:11.522: INFO: Pod "downwardapi-volume-17fbe6ff-29b2-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 01:54:11.529: INFO: Trying to get logs from node 10.190.119.175 pod downwardapi-volume-17fbe6ff-29b2-11e9-b6e7-06cba7aec104 container client-container: <nil>
STEP: delete the pod
Feb  6 01:54:11.575: INFO: Waiting for pod downwardapi-volume-17fbe6ff-29b2-11e9-b6e7-06cba7aec104 to disappear
Feb  6 01:54:11.583: INFO: Pod downwardapi-volume-17fbe6ff-29b2-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 01:54:11.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-ldv46" for this suite.
Feb  6 01:54:17.635: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 01:54:17.767: INFO: namespace: e2e-tests-downward-api-ldv46, resource: bindings, ignored listing per whitelist
Feb  6 01:54:17.983: INFO: namespace e2e-tests-downward-api-ldv46 deletion completed in 6.388455517s

• [SLOW TEST:8.867 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 01:54:17.985: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-94bvw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  6 01:54:18.356: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1d43415d-29b2-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-downward-api-94bvw" to be "success or failure"
Feb  6 01:54:18.365: INFO: Pod "downwardapi-volume-1d43415d-29b2-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 9.082634ms
Feb  6 01:54:20.391: INFO: Pod "downwardapi-volume-1d43415d-29b2-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.034711978s
STEP: Saw pod success
Feb  6 01:54:20.391: INFO: Pod "downwardapi-volume-1d43415d-29b2-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 01:54:20.399: INFO: Trying to get logs from node 10.190.119.175 pod downwardapi-volume-1d43415d-29b2-11e9-b6e7-06cba7aec104 container client-container: <nil>
STEP: delete the pod
Feb  6 01:54:20.439: INFO: Waiting for pod downwardapi-volume-1d43415d-29b2-11e9-b6e7-06cba7aec104 to disappear
Feb  6 01:54:20.446: INFO: Pod downwardapi-volume-1d43415d-29b2-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 01:54:20.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-94bvw" for this suite.
Feb  6 01:54:26.499: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 01:54:26.844: INFO: namespace: e2e-tests-downward-api-94bvw, resource: bindings, ignored listing per whitelist
Feb  6 01:54:26.871: INFO: namespace e2e-tests-downward-api-94bvw deletion completed in 6.414519591s

• [SLOW TEST:8.886 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 01:54:26.872: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-7h5zx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  6 01:54:27.213: INFO: Waiting up to 5m0s for pod "downwardapi-volume-228a6a8f-29b2-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-downward-api-7h5zx" to be "success or failure"
Feb  6 01:54:27.225: INFO: Pod "downwardapi-volume-228a6a8f-29b2-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 11.895356ms
Feb  6 01:54:29.233: INFO: Pod "downwardapi-volume-228a6a8f-29b2-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019820533s
STEP: Saw pod success
Feb  6 01:54:29.233: INFO: Pod "downwardapi-volume-228a6a8f-29b2-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 01:54:29.240: INFO: Trying to get logs from node 10.190.119.145 pod downwardapi-volume-228a6a8f-29b2-11e9-b6e7-06cba7aec104 container client-container: <nil>
STEP: delete the pod
Feb  6 01:54:29.282: INFO: Waiting for pod downwardapi-volume-228a6a8f-29b2-11e9-b6e7-06cba7aec104 to disappear
Feb  6 01:54:29.295: INFO: Pod downwardapi-volume-228a6a8f-29b2-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 01:54:29.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-7h5zx" for this suite.
Feb  6 01:54:35.415: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 01:54:35.523: INFO: namespace: e2e-tests-downward-api-7h5zx, resource: bindings, ignored listing per whitelist
Feb  6 01:54:35.796: INFO: namespace e2e-tests-downward-api-7h5zx deletion completed in 6.489587345s

• [SLOW TEST:8.924 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 01:54:35.796: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-hostpath-5s7w5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Feb  6 01:54:36.569: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-5s7w5" to be "success or failure"
Feb  6 01:54:36.578: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 9.289336ms
Feb  6 01:54:38.586: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016926148s
STEP: Saw pod success
Feb  6 01:54:38.586: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Feb  6 01:54:38.597: INFO: Trying to get logs from node 10.190.119.145 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Feb  6 01:54:38.640: INFO: Waiting for pod pod-host-path-test to disappear
Feb  6 01:54:38.652: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 01:54:38.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-5s7w5" for this suite.
Feb  6 01:54:44.706: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 01:54:44.874: INFO: namespace: e2e-tests-hostpath-5s7w5, resource: bindings, ignored listing per whitelist
Feb  6 01:54:45.007: INFO: namespace e2e-tests-hostpath-5s7w5 deletion completed in 6.345684418s

• [SLOW TEST:9.211 seconds]
[sig-storage] HostPath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 01:54:45.008: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svc-latency-8zwct
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-8zwct
I0206 01:54:45.467917      15 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-8zwct, replica count: 1
I0206 01:54:46.518373      15 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0206 01:54:47.518593      15 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0206 01:54:48.518803      15 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb  6 01:54:48.645: INFO: Created: latency-svc-d64hz
Feb  6 01:54:48.670: INFO: Got endpoints: latency-svc-d64hz [51.748609ms]
Feb  6 01:54:48.694: INFO: Created: latency-svc-6ztrf
Feb  6 01:54:48.713: INFO: Got endpoints: latency-svc-6ztrf [42.420253ms]
Feb  6 01:54:48.719: INFO: Created: latency-svc-gjp2h
Feb  6 01:54:48.732: INFO: Got endpoints: latency-svc-gjp2h [61.19137ms]
Feb  6 01:54:48.737: INFO: Created: latency-svc-xmktq
Feb  6 01:54:48.749: INFO: Got endpoints: latency-svc-xmktq [77.924831ms]
Feb  6 01:54:48.756: INFO: Created: latency-svc-7zhhr
Feb  6 01:54:48.769: INFO: Got endpoints: latency-svc-7zhhr [97.875919ms]
Feb  6 01:54:48.778: INFO: Created: latency-svc-wwn7r
Feb  6 01:54:48.786: INFO: Got endpoints: latency-svc-wwn7r [115.275204ms]
Feb  6 01:54:48.793: INFO: Created: latency-svc-2z7zd
Feb  6 01:54:48.805: INFO: Got endpoints: latency-svc-2z7zd [133.954105ms]
Feb  6 01:54:48.815: INFO: Created: latency-svc-w4bfx
Feb  6 01:54:48.824: INFO: Got endpoints: latency-svc-w4bfx [153.116627ms]
Feb  6 01:54:48.830: INFO: Created: latency-svc-svdkv
Feb  6 01:54:48.839: INFO: Got endpoints: latency-svc-svdkv [168.242128ms]
Feb  6 01:54:48.846: INFO: Created: latency-svc-7g8m6
Feb  6 01:54:48.857: INFO: Got endpoints: latency-svc-7g8m6 [185.569069ms]
Feb  6 01:54:48.868: INFO: Created: latency-svc-n6kfz
Feb  6 01:54:48.882: INFO: Got endpoints: latency-svc-n6kfz [210.436182ms]
Feb  6 01:54:48.888: INFO: Created: latency-svc-42r5n
Feb  6 01:54:48.900: INFO: Got endpoints: latency-svc-42r5n [43.197691ms]
Feb  6 01:54:48.904: INFO: Created: latency-svc-g9w8h
Feb  6 01:54:48.915: INFO: Got endpoints: latency-svc-g9w8h [243.684677ms]
Feb  6 01:54:48.922: INFO: Created: latency-svc-mgw84
Feb  6 01:54:48.935: INFO: Got endpoints: latency-svc-mgw84 [263.350977ms]
Feb  6 01:54:48.941: INFO: Created: latency-svc-sqq75
Feb  6 01:54:48.955: INFO: Got endpoints: latency-svc-sqq75 [284.101702ms]
Feb  6 01:54:48.959: INFO: Created: latency-svc-89rdh
Feb  6 01:54:48.970: INFO: Got endpoints: latency-svc-89rdh [299.096547ms]
Feb  6 01:54:48.977: INFO: Created: latency-svc-skp48
Feb  6 01:54:48.993: INFO: Created: latency-svc-xl8wf
Feb  6 01:54:48.995: INFO: Got endpoints: latency-svc-skp48 [323.751022ms]
Feb  6 01:54:49.093: INFO: Created: latency-svc-n798w
Feb  6 01:54:49.094: INFO: Got endpoints: latency-svc-n798w [361.253914ms]
Feb  6 01:54:49.094: INFO: Got endpoints: latency-svc-xl8wf [381.088874ms]
Feb  6 01:54:49.095: INFO: Created: latency-svc-pgkqs
Feb  6 01:54:49.095: INFO: Got endpoints: latency-svc-pgkqs [345.730959ms]
Feb  6 01:54:49.095: INFO: Created: latency-svc-6r8fc
Feb  6 01:54:49.095: INFO: Created: latency-svc-4xjll
Feb  6 01:54:49.095: INFO: Got endpoints: latency-svc-4xjll [326.279303ms]
Feb  6 01:54:49.107: INFO: Got endpoints: latency-svc-6r8fc [320.951782ms]
Feb  6 01:54:49.120: INFO: Created: latency-svc-5n4sr
Feb  6 01:54:49.131: INFO: Got endpoints: latency-svc-5n4sr [326.002837ms]
Feb  6 01:54:49.135: INFO: Created: latency-svc-cqvgl
Feb  6 01:54:49.150: INFO: Got endpoints: latency-svc-cqvgl [325.624362ms]
Feb  6 01:54:49.151: INFO: Created: latency-svc-zw2lh
Feb  6 01:54:49.163: INFO: Got endpoints: latency-svc-zw2lh [323.531701ms]
Feb  6 01:54:49.168: INFO: Created: latency-svc-b5rjs
Feb  6 01:54:49.178: INFO: Got endpoints: latency-svc-b5rjs [296.345681ms]
Feb  6 01:54:49.196: INFO: Created: latency-svc-hh4br
Feb  6 01:54:49.207: INFO: Got endpoints: latency-svc-hh4br [306.768488ms]
Feb  6 01:54:49.208: INFO: Created: latency-svc-rtxpc
Feb  6 01:54:49.228: INFO: Got endpoints: latency-svc-rtxpc [312.839961ms]
Feb  6 01:54:49.233: INFO: Created: latency-svc-n9lvn
Feb  6 01:54:49.245: INFO: Got endpoints: latency-svc-n9lvn [310.199281ms]
Feb  6 01:54:49.251: INFO: Created: latency-svc-xb9rj
Feb  6 01:54:49.264: INFO: Got endpoints: latency-svc-xb9rj [308.931394ms]
Feb  6 01:54:49.268: INFO: Created: latency-svc-vn7dc
Feb  6 01:54:49.278: INFO: Got endpoints: latency-svc-vn7dc [308.090256ms]
Feb  6 01:54:49.284: INFO: Created: latency-svc-zplnq
Feb  6 01:54:49.295: INFO: Got endpoints: latency-svc-zplnq [299.454667ms]
Feb  6 01:54:49.306: INFO: Created: latency-svc-fznsn
Feb  6 01:54:49.314: INFO: Got endpoints: latency-svc-fznsn [220.264017ms]
Feb  6 01:54:49.318: INFO: Created: latency-svc-dp5m6
Feb  6 01:54:49.333: INFO: Got endpoints: latency-svc-dp5m6 [238.674878ms]
Feb  6 01:54:49.339: INFO: Created: latency-svc-xx7df
Feb  6 01:54:49.350: INFO: Got endpoints: latency-svc-xx7df [255.57122ms]
Feb  6 01:54:49.360: INFO: Created: latency-svc-4gfxx
Feb  6 01:54:49.370: INFO: Got endpoints: latency-svc-4gfxx [274.653122ms]
Feb  6 01:54:49.378: INFO: Created: latency-svc-lj88q
Feb  6 01:54:49.387: INFO: Got endpoints: latency-svc-lj88q [279.557778ms]
Feb  6 01:54:49.399: INFO: Created: latency-svc-cwlw8
Feb  6 01:54:49.411: INFO: Got endpoints: latency-svc-cwlw8 [279.309101ms]
Feb  6 01:54:49.416: INFO: Created: latency-svc-qt4wn
Feb  6 01:54:49.430: INFO: Got endpoints: latency-svc-qt4wn [280.148065ms]
Feb  6 01:54:49.431: INFO: Created: latency-svc-4kp4w
Feb  6 01:54:49.440: INFO: Got endpoints: latency-svc-4kp4w [277.043629ms]
Feb  6 01:54:49.455: INFO: Created: latency-svc-l9csh
Feb  6 01:54:49.466: INFO: Got endpoints: latency-svc-l9csh [288.237642ms]
Feb  6 01:54:49.469: INFO: Created: latency-svc-8dfv9
Feb  6 01:54:49.484: INFO: Got endpoints: latency-svc-8dfv9 [276.487906ms]
Feb  6 01:54:49.488: INFO: Created: latency-svc-qgk86
Feb  6 01:54:49.502: INFO: Got endpoints: latency-svc-qgk86 [273.854566ms]
Feb  6 01:54:49.503: INFO: Created: latency-svc-ffqtl
Feb  6 01:54:49.516: INFO: Got endpoints: latency-svc-ffqtl [271.119993ms]
Feb  6 01:54:49.521: INFO: Created: latency-svc-ddgxw
Feb  6 01:54:49.531: INFO: Got endpoints: latency-svc-ddgxw [266.970527ms]
Feb  6 01:54:49.537: INFO: Created: latency-svc-p784h
Feb  6 01:54:49.554: INFO: Created: latency-svc-rht54
Feb  6 01:54:49.555: INFO: Got endpoints: latency-svc-p784h [277.124694ms]
Feb  6 01:54:49.565: INFO: Got endpoints: latency-svc-rht54 [270.322808ms]
Feb  6 01:54:49.571: INFO: Created: latency-svc-v24vg
Feb  6 01:54:49.580: INFO: Got endpoints: latency-svc-v24vg [265.678673ms]
Feb  6 01:54:49.586: INFO: Created: latency-svc-cpf89
Feb  6 01:54:49.602: INFO: Created: latency-svc-8vrlf
Feb  6 01:54:49.607: INFO: Got endpoints: latency-svc-cpf89 [274.067497ms]
Feb  6 01:54:49.622: INFO: Created: latency-svc-vjlnl
Feb  6 01:54:49.638: INFO: Created: latency-svc-kmbg5
Feb  6 01:54:49.657: INFO: Got endpoints: latency-svc-8vrlf [306.805139ms]
Feb  6 01:54:49.657: INFO: Created: latency-svc-9bqmf
Feb  6 01:54:49.676: INFO: Created: latency-svc-kdvkf
Feb  6 01:54:49.692: INFO: Created: latency-svc-gjr56
Feb  6 01:54:49.704: INFO: Got endpoints: latency-svc-vjlnl [333.829623ms]
Feb  6 01:54:49.709: INFO: Created: latency-svc-zn97x
Feb  6 01:54:49.727: INFO: Created: latency-svc-wwxpf
Feb  6 01:54:49.745: INFO: Created: latency-svc-jqvrj
Feb  6 01:54:49.757: INFO: Got endpoints: latency-svc-kmbg5 [369.932179ms]
Feb  6 01:54:49.762: INFO: Created: latency-svc-gf4qw
Feb  6 01:54:49.777: INFO: Created: latency-svc-8spcj
Feb  6 01:54:49.792: INFO: Created: latency-svc-5qmv7
Feb  6 01:54:49.805: INFO: Got endpoints: latency-svc-9bqmf [394.318217ms]
Feb  6 01:54:49.809: INFO: Created: latency-svc-25lv9
Feb  6 01:54:49.828: INFO: Created: latency-svc-9jmvd
Feb  6 01:54:49.917: INFO: Got endpoints: latency-svc-kdvkf [486.568011ms]
Feb  6 01:54:49.917: INFO: Got endpoints: latency-svc-gjr56 [476.842588ms]
Feb  6 01:54:49.920: INFO: Created: latency-svc-d8l6m
Feb  6 01:54:49.937: INFO: Created: latency-svc-2ltqr
Feb  6 01:54:49.954: INFO: Got endpoints: latency-svc-zn97x [487.24315ms]
Feb  6 01:54:49.956: INFO: Created: latency-svc-dgxzr
Feb  6 01:54:49.972: INFO: Created: latency-svc-xkw9f
Feb  6 01:54:49.986: INFO: Created: latency-svc-g7j7c
Feb  6 01:54:50.003: INFO: Created: latency-svc-s7bwx
Feb  6 01:54:50.019: INFO: Created: latency-svc-kxsrt
Feb  6 01:54:50.035: INFO: Created: latency-svc-t56t9
Feb  6 01:54:50.463: INFO: Got endpoints: latency-svc-wwxpf [979.585719ms]
Feb  6 01:54:50.468: INFO: Got endpoints: latency-svc-jqvrj [966.610501ms]
Feb  6 01:54:50.469: INFO: Got endpoints: latency-svc-8spcj [937.692546ms]
Feb  6 01:54:50.498: INFO: Created: latency-svc-6cxw4
Feb  6 01:54:50.498: INFO: Got endpoints: latency-svc-dgxzr [793.743612ms]
Feb  6 01:54:50.498: INFO: Got endpoints: latency-svc-25lv9 [933.172244ms]
Feb  6 01:54:50.499: INFO: Got endpoints: latency-svc-9jmvd [918.749287ms]
Feb  6 01:54:50.499: INFO: Got endpoints: latency-svc-gf4qw [982.323913ms]
Feb  6 01:54:50.499: INFO: Got endpoints: latency-svc-d8l6m [891.847189ms]
Feb  6 01:54:50.499: INFO: Got endpoints: latency-svc-5qmv7 [943.860717ms]
Feb  6 01:54:50.499: INFO: Got endpoints: latency-svc-2ltqr [841.999462ms]
Feb  6 01:54:50.509: INFO: Got endpoints: latency-svc-xkw9f [751.77605ms]
Feb  6 01:54:50.524: INFO: Created: latency-svc-r8d9r
Feb  6 01:54:50.541: INFO: Created: latency-svc-9kzww
Feb  6 01:54:50.555: INFO: Got endpoints: latency-svc-g7j7c [750.154415ms]
Feb  6 01:54:50.560: INFO: Created: latency-svc-rxzzj
Feb  6 01:54:50.574: INFO: Created: latency-svc-t65fd
Feb  6 01:54:50.589: INFO: Created: latency-svc-25qmx
Feb  6 01:54:50.604: INFO: Got endpoints: latency-svc-s7bwx [686.787097ms]
Feb  6 01:54:50.605: INFO: Created: latency-svc-nx7fm
Feb  6 01:54:50.621: INFO: Created: latency-svc-wthkj
Feb  6 01:54:50.640: INFO: Created: latency-svc-cdrz8
Feb  6 01:54:50.656: INFO: Got endpoints: latency-svc-kxsrt [739.20358ms]
Feb  6 01:54:50.667: INFO: Created: latency-svc-xqstw
Feb  6 01:54:50.687: INFO: Created: latency-svc-vxgl4
Feb  6 01:54:50.705: INFO: Got endpoints: latency-svc-t56t9 [751.058822ms]
Feb  6 01:54:50.709: INFO: Created: latency-svc-pn2jw
Feb  6 01:54:51.290: INFO: Got endpoints: latency-svc-r8d9r [820.99988ms]
Feb  6 01:54:51.290: INFO: Got endpoints: latency-svc-6cxw4 [827.012815ms]
Feb  6 01:54:51.296: INFO: Got endpoints: latency-svc-9kzww [827.147875ms]
Feb  6 01:54:51.301: INFO: Got endpoints: latency-svc-t65fd [801.979619ms]
Feb  6 01:54:51.301: INFO: Got endpoints: latency-svc-rxzzj [802.393951ms]
Feb  6 01:54:51.302: INFO: Got endpoints: latency-svc-wthkj [803.147961ms]
Feb  6 01:54:51.302: INFO: Got endpoints: latency-svc-nx7fm [803.057907ms]
Feb  6 01:54:51.303: INFO: Got endpoints: latency-svc-25qmx [803.360066ms]
Feb  6 01:54:51.304: INFO: Got endpoints: latency-svc-vxgl4 [794.846568ms]
Feb  6 01:54:51.304: INFO: Got endpoints: latency-svc-cdrz8 [805.19747ms]
Feb  6 01:54:51.304: INFO: Got endpoints: latency-svc-xqstw [805.877858ms]
Feb  6 01:54:51.305: INFO: Got endpoints: latency-svc-pn2jw [750.058354ms]
Feb  6 01:54:51.320: INFO: Created: latency-svc-6xrj9
Feb  6 01:54:51.327: INFO: Created: latency-svc-xj4dv
Feb  6 01:54:51.345: INFO: Created: latency-svc-xmd72
Feb  6 01:54:51.355: INFO: Got endpoints: latency-svc-6xrj9 [751.408738ms]
Feb  6 01:54:51.361: INFO: Created: latency-svc-92k5r
Feb  6 01:54:51.376: INFO: Created: latency-svc-p4645
Feb  6 01:54:51.391: INFO: Created: latency-svc-nh2jj
Feb  6 01:54:51.404: INFO: Got endpoints: latency-svc-xj4dv [747.614781ms]
Feb  6 01:54:51.410: INFO: Created: latency-svc-wpfxw
Feb  6 01:54:51.427: INFO: Created: latency-svc-5tf9z
Feb  6 01:54:51.443: INFO: Created: latency-svc-jdmsl
Feb  6 01:54:51.457: INFO: Got endpoints: latency-svc-xmd72 [752.08386ms]
Feb  6 01:54:51.460: INFO: Created: latency-svc-dldbt
Feb  6 01:54:51.476: INFO: Created: latency-svc-7fd24
Feb  6 01:54:51.492: INFO: Created: latency-svc-x5qrz
Feb  6 01:54:51.504: INFO: Got endpoints: latency-svc-92k5r [213.795356ms]
Feb  6 01:54:51.511: INFO: Created: latency-svc-npg6c
Feb  6 01:54:51.525: INFO: Created: latency-svc-g6ssr
Feb  6 01:54:51.539: INFO: Created: latency-svc-zv7qf
Feb  6 01:54:51.553: INFO: Created: latency-svc-559hl
Feb  6 01:54:51.556: INFO: Got endpoints: latency-svc-p4645 [265.231844ms]
Feb  6 01:54:51.568: INFO: Created: latency-svc-tmhbh
Feb  6 01:54:51.583: INFO: Created: latency-svc-t7cjv
Feb  6 01:54:51.600: INFO: Created: latency-svc-8lpc2
Feb  6 01:54:51.613: INFO: Got endpoints: latency-svc-nh2jj [317.329517ms]
Feb  6 01:54:51.618: INFO: Created: latency-svc-9zxm2
Feb  6 01:54:51.645: INFO: Created: latency-svc-cjmx4
Feb  6 01:54:51.656: INFO: Got endpoints: latency-svc-wpfxw [355.393058ms]
Feb  6 01:54:51.682: INFO: Created: latency-svc-99tf6
Feb  6 01:54:51.704: INFO: Got endpoints: latency-svc-5tf9z [403.572591ms]
Feb  6 01:54:51.732: INFO: Created: latency-svc-cpxvd
Feb  6 01:54:51.756: INFO: Got endpoints: latency-svc-jdmsl [454.050931ms]
Feb  6 01:54:51.784: INFO: Created: latency-svc-bxpcw
Feb  6 01:54:51.804: INFO: Got endpoints: latency-svc-dldbt [501.75678ms]
Feb  6 01:54:51.829: INFO: Created: latency-svc-hqznw
Feb  6 01:54:51.855: INFO: Got endpoints: latency-svc-7fd24 [552.722302ms]
Feb  6 01:54:51.881: INFO: Created: latency-svc-8qnhq
Feb  6 01:54:51.903: INFO: Got endpoints: latency-svc-x5qrz [599.140932ms]
Feb  6 01:54:51.928: INFO: Created: latency-svc-pxqw4
Feb  6 01:54:51.955: INFO: Got endpoints: latency-svc-npg6c [651.003338ms]
Feb  6 01:54:51.984: INFO: Created: latency-svc-ndgtj
Feb  6 01:54:52.004: INFO: Got endpoints: latency-svc-g6ssr [700.525685ms]
Feb  6 01:54:52.030: INFO: Created: latency-svc-hg6qh
Feb  6 01:54:52.057: INFO: Got endpoints: latency-svc-zv7qf [751.825972ms]
Feb  6 01:54:52.080: INFO: Created: latency-svc-4d52d
Feb  6 01:54:52.104: INFO: Got endpoints: latency-svc-559hl [749.06196ms]
Feb  6 01:54:52.130: INFO: Created: latency-svc-7drlq
Feb  6 01:54:52.159: INFO: Got endpoints: latency-svc-tmhbh [755.032458ms]
Feb  6 01:54:52.185: INFO: Created: latency-svc-nmsp8
Feb  6 01:54:52.204: INFO: Got endpoints: latency-svc-t7cjv [746.927101ms]
Feb  6 01:54:52.233: INFO: Created: latency-svc-l9c28
Feb  6 01:54:52.257: INFO: Got endpoints: latency-svc-8lpc2 [753.201729ms]
Feb  6 01:54:52.284: INFO: Created: latency-svc-h5hsv
Feb  6 01:54:52.305: INFO: Got endpoints: latency-svc-9zxm2 [748.681155ms]
Feb  6 01:54:52.330: INFO: Created: latency-svc-s6gxl
Feb  6 01:54:52.357: INFO: Got endpoints: latency-svc-cjmx4 [743.600483ms]
Feb  6 01:54:52.399: INFO: Created: latency-svc-qmbld
Feb  6 01:54:52.404: INFO: Got endpoints: latency-svc-99tf6 [747.90923ms]
Feb  6 01:54:52.429: INFO: Created: latency-svc-cb8r2
Feb  6 01:54:52.459: INFO: Got endpoints: latency-svc-cpxvd [755.090568ms]
Feb  6 01:54:52.486: INFO: Created: latency-svc-flpcr
Feb  6 01:54:52.507: INFO: Got endpoints: latency-svc-bxpcw [750.785328ms]
Feb  6 01:54:52.533: INFO: Created: latency-svc-zjxbb
Feb  6 01:54:52.553: INFO: Got endpoints: latency-svc-hqznw [748.357447ms]
Feb  6 01:54:52.580: INFO: Created: latency-svc-bcsws
Feb  6 01:54:52.604: INFO: Got endpoints: latency-svc-8qnhq [749.42016ms]
Feb  6 01:54:52.628: INFO: Created: latency-svc-sdbdq
Feb  6 01:54:52.654: INFO: Got endpoints: latency-svc-pxqw4 [750.476061ms]
Feb  6 01:54:52.682: INFO: Created: latency-svc-mn9qp
Feb  6 01:54:52.711: INFO: Got endpoints: latency-svc-ndgtj [756.15654ms]
Feb  6 01:54:52.754: INFO: Created: latency-svc-gxl8h
Feb  6 01:54:52.757: INFO: Got endpoints: latency-svc-hg6qh [752.616781ms]
Feb  6 01:54:52.784: INFO: Created: latency-svc-fwv86
Feb  6 01:54:52.806: INFO: Got endpoints: latency-svc-4d52d [749.214506ms]
Feb  6 01:54:52.834: INFO: Created: latency-svc-4fsv8
Feb  6 01:54:52.856: INFO: Got endpoints: latency-svc-7drlq [751.629559ms]
Feb  6 01:54:52.891: INFO: Created: latency-svc-7q4w9
Feb  6 01:54:52.904: INFO: Got endpoints: latency-svc-nmsp8 [744.835225ms]
Feb  6 01:54:52.928: INFO: Created: latency-svc-glgdk
Feb  6 01:54:52.956: INFO: Got endpoints: latency-svc-l9c28 [751.767377ms]
Feb  6 01:54:52.985: INFO: Created: latency-svc-sw4w9
Feb  6 01:54:53.009: INFO: Got endpoints: latency-svc-h5hsv [750.928162ms]
Feb  6 01:54:53.040: INFO: Created: latency-svc-fqkhv
Feb  6 01:54:53.054: INFO: Got endpoints: latency-svc-s6gxl [749.628799ms]
Feb  6 01:54:53.085: INFO: Created: latency-svc-vjghr
Feb  6 01:54:53.105: INFO: Got endpoints: latency-svc-qmbld [748.207818ms]
Feb  6 01:54:53.134: INFO: Created: latency-svc-vt9fg
Feb  6 01:54:53.155: INFO: Got endpoints: latency-svc-cb8r2 [751.116497ms]
Feb  6 01:54:53.185: INFO: Created: latency-svc-pssx2
Feb  6 01:54:53.209: INFO: Got endpoints: latency-svc-flpcr [749.125515ms]
Feb  6 01:54:53.240: INFO: Created: latency-svc-wfr2b
Feb  6 01:54:53.258: INFO: Got endpoints: latency-svc-zjxbb [750.969384ms]
Feb  6 01:54:53.299: INFO: Created: latency-svc-zq9vj
Feb  6 01:54:53.305: INFO: Got endpoints: latency-svc-bcsws [751.158378ms]
Feb  6 01:54:53.330: INFO: Created: latency-svc-zrqbc
Feb  6 01:54:53.354: INFO: Got endpoints: latency-svc-sdbdq [749.284126ms]
Feb  6 01:54:53.392: INFO: Created: latency-svc-cjncx
Feb  6 01:54:53.404: INFO: Got endpoints: latency-svc-mn9qp [750.056362ms]
Feb  6 01:54:53.430: INFO: Created: latency-svc-ngnmx
Feb  6 01:54:53.455: INFO: Got endpoints: latency-svc-gxl8h [744.066766ms]
Feb  6 01:54:53.482: INFO: Created: latency-svc-kxpjn
Feb  6 01:54:53.504: INFO: Got endpoints: latency-svc-fwv86 [747.055548ms]
Feb  6 01:54:53.531: INFO: Created: latency-svc-z444b
Feb  6 01:54:53.554: INFO: Got endpoints: latency-svc-4fsv8 [747.401595ms]
Feb  6 01:54:53.578: INFO: Created: latency-svc-ghcpr
Feb  6 01:54:53.608: INFO: Got endpoints: latency-svc-7q4w9 [751.615052ms]
Feb  6 01:54:53.633: INFO: Created: latency-svc-snmpj
Feb  6 01:54:53.657: INFO: Got endpoints: latency-svc-glgdk [753.050797ms]
Feb  6 01:54:53.683: INFO: Created: latency-svc-lgltz
Feb  6 01:54:53.704: INFO: Got endpoints: latency-svc-sw4w9 [747.686712ms]
Feb  6 01:54:53.729: INFO: Created: latency-svc-7c9w7
Feb  6 01:54:53.754: INFO: Got endpoints: latency-svc-fqkhv [745.785781ms]
Feb  6 01:54:53.779: INFO: Created: latency-svc-p5t7v
Feb  6 01:54:53.806: INFO: Got endpoints: latency-svc-vjghr [751.831502ms]
Feb  6 01:54:53.830: INFO: Created: latency-svc-mffgg
Feb  6 01:54:53.858: INFO: Got endpoints: latency-svc-vt9fg [752.768595ms]
Feb  6 01:54:53.881: INFO: Created: latency-svc-64vrk
Feb  6 01:54:53.904: INFO: Got endpoints: latency-svc-pssx2 [748.981297ms]
Feb  6 01:54:53.928: INFO: Created: latency-svc-xsf8p
Feb  6 01:54:53.955: INFO: Got endpoints: latency-svc-wfr2b [746.245797ms]
Feb  6 01:54:53.982: INFO: Created: latency-svc-vglcc
Feb  6 01:54:54.006: INFO: Got endpoints: latency-svc-zq9vj [747.598651ms]
Feb  6 01:54:54.030: INFO: Created: latency-svc-tlgjp
Feb  6 01:54:54.054: INFO: Got endpoints: latency-svc-zrqbc [749.30884ms]
Feb  6 01:54:54.082: INFO: Created: latency-svc-rjxrw
Feb  6 01:54:54.104: INFO: Got endpoints: latency-svc-cjncx [750.144088ms]
Feb  6 01:54:54.137: INFO: Created: latency-svc-6pv7x
Feb  6 01:54:54.155: INFO: Got endpoints: latency-svc-ngnmx [750.62477ms]
Feb  6 01:54:54.179: INFO: Created: latency-svc-2fnmn
Feb  6 01:54:54.204: INFO: Got endpoints: latency-svc-kxpjn [749.098148ms]
Feb  6 01:54:54.231: INFO: Created: latency-svc-xxkfv
Feb  6 01:54:54.255: INFO: Got endpoints: latency-svc-z444b [750.649936ms]
Feb  6 01:54:54.281: INFO: Created: latency-svc-82s5r
Feb  6 01:54:54.310: INFO: Got endpoints: latency-svc-ghcpr [755.586045ms]
Feb  6 01:54:54.334: INFO: Created: latency-svc-tbbsq
Feb  6 01:54:54.354: INFO: Got endpoints: latency-svc-snmpj [746.010779ms]
Feb  6 01:54:54.377: INFO: Created: latency-svc-nmql9
Feb  6 01:54:54.405: INFO: Got endpoints: latency-svc-lgltz [748.260565ms]
Feb  6 01:54:54.430: INFO: Created: latency-svc-7p92r
Feb  6 01:54:54.454: INFO: Got endpoints: latency-svc-7c9w7 [750.058622ms]
Feb  6 01:54:54.505: INFO: Got endpoints: latency-svc-p5t7v [750.850945ms]
Feb  6 01:54:54.512: INFO: Created: latency-svc-rqqv4
Feb  6 01:54:54.529: INFO: Created: latency-svc-kccnz
Feb  6 01:54:55.147: INFO: Got endpoints: latency-svc-mffgg [1.340525313s]
Feb  6 01:54:55.150: INFO: Got endpoints: latency-svc-vglcc [1.195369432s]
Feb  6 01:54:55.151: INFO: Got endpoints: latency-svc-64vrk [1.292866027s]
Feb  6 01:54:55.152: INFO: Got endpoints: latency-svc-xsf8p [1.247235487s]
Feb  6 01:54:55.152: INFO: Got endpoints: latency-svc-tlgjp [1.146425985s]
Feb  6 01:54:55.197: INFO: Created: latency-svc-wghd4
Feb  6 01:54:55.198: INFO: Got endpoints: latency-svc-7p92r [792.284657ms]
Feb  6 01:54:55.198: INFO: Got endpoints: latency-svc-rjxrw [1.14382641s]
Feb  6 01:54:55.199: INFO: Got endpoints: latency-svc-6pv7x [1.094224071s]
Feb  6 01:54:55.199: INFO: Got endpoints: latency-svc-82s5r [944.004375ms]
Feb  6 01:54:55.199: INFO: Got endpoints: latency-svc-tbbsq [889.381061ms]
Feb  6 01:54:55.199: INFO: Got endpoints: latency-svc-nmql9 [844.944134ms]
Feb  6 01:54:55.199: INFO: Got endpoints: latency-svc-xxkfv [994.527058ms]
Feb  6 01:54:55.199: INFO: Got endpoints: latency-svc-2fnmn [1.044069861s]
Feb  6 01:54:55.206: INFO: Got endpoints: latency-svc-rqqv4 [751.763477ms]
Feb  6 01:54:55.208: INFO: Created: latency-svc-p24nc
Feb  6 01:54:55.232: INFO: Created: latency-svc-qxnl9
Feb  6 01:54:55.251: INFO: Created: latency-svc-wmkmd
Feb  6 01:54:55.262: INFO: Got endpoints: latency-svc-kccnz [756.278157ms]
Feb  6 01:54:55.266: INFO: Created: latency-svc-s2pv8
Feb  6 01:54:55.284: INFO: Created: latency-svc-pf4kn
Feb  6 01:54:55.306: INFO: Got endpoints: latency-svc-wghd4 [155.237126ms]
Feb  6 01:54:55.308: INFO: Created: latency-svc-csfhm
Feb  6 01:54:55.326: INFO: Created: latency-svc-s2brb
Feb  6 01:54:55.344: INFO: Created: latency-svc-hs75x
Feb  6 01:54:55.356: INFO: Got endpoints: latency-svc-p24nc [204.71643ms]
Feb  6 01:54:55.365: INFO: Created: latency-svc-z4rtq
Feb  6 01:54:55.381: INFO: Created: latency-svc-76ffr
Feb  6 01:54:55.395: INFO: Created: latency-svc-pjsqq
Feb  6 01:54:55.405: INFO: Got endpoints: latency-svc-qxnl9 [257.830115ms]
Feb  6 01:54:55.415: INFO: Created: latency-svc-72vrn
Feb  6 01:54:55.429: INFO: Created: latency-svc-6qllf
Feb  6 01:54:55.446: INFO: Created: latency-svc-7tww4
Feb  6 01:54:55.458: INFO: Got endpoints: latency-svc-wmkmd [306.846244ms]
Feb  6 01:54:55.465: INFO: Created: latency-svc-9pt7b
Feb  6 01:54:55.481: INFO: Created: latency-svc-5c5qn
Feb  6 01:54:55.502: INFO: Created: latency-svc-5xzjg
Feb  6 01:54:55.507: INFO: Got endpoints: latency-svc-s2pv8 [354.186268ms]
Feb  6 01:54:55.520: INFO: Created: latency-svc-2gfk6
Feb  6 01:54:55.538: INFO: Created: latency-svc-n7c48
Feb  6 01:54:55.555: INFO: Got endpoints: latency-svc-pf4kn [357.517076ms]
Feb  6 01:54:55.593: INFO: Created: latency-svc-hxj6q
Feb  6 01:54:55.604: INFO: Got endpoints: latency-svc-csfhm [405.807105ms]
Feb  6 01:54:55.631: INFO: Created: latency-svc-4xtnh
Feb  6 01:54:55.655: INFO: Got endpoints: latency-svc-s2brb [456.810746ms]
Feb  6 01:54:55.680: INFO: Created: latency-svc-97jn4
Feb  6 01:54:55.707: INFO: Got endpoints: latency-svc-hs75x [508.115064ms]
Feb  6 01:54:55.744: INFO: Created: latency-svc-rr46k
Feb  6 01:54:55.754: INFO: Got endpoints: latency-svc-z4rtq [553.603966ms]
Feb  6 01:54:55.789: INFO: Created: latency-svc-6pttz
Feb  6 01:54:55.806: INFO: Got endpoints: latency-svc-76ffr [605.637313ms]
Feb  6 01:54:55.835: INFO: Created: latency-svc-sphcs
Feb  6 01:54:55.856: INFO: Got endpoints: latency-svc-pjsqq [655.962702ms]
Feb  6 01:54:55.882: INFO: Created: latency-svc-djrcx
Feb  6 01:54:55.905: INFO: Got endpoints: latency-svc-72vrn [706.252509ms]
Feb  6 01:54:55.932: INFO: Created: latency-svc-5w5lw
Feb  6 01:54:55.955: INFO: Got endpoints: latency-svc-6qllf [748.751345ms]
Feb  6 01:54:55.981: INFO: Created: latency-svc-qlsf6
Feb  6 01:54:56.005: INFO: Got endpoints: latency-svc-7tww4 [742.56729ms]
Feb  6 01:54:56.030: INFO: Created: latency-svc-77mgz
Feb  6 01:54:56.055: INFO: Got endpoints: latency-svc-9pt7b [749.163228ms]
Feb  6 01:54:56.083: INFO: Created: latency-svc-ch59n
Feb  6 01:54:56.106: INFO: Got endpoints: latency-svc-5c5qn [749.495807ms]
Feb  6 01:54:56.132: INFO: Created: latency-svc-5kfr4
Feb  6 01:54:56.154: INFO: Got endpoints: latency-svc-5xzjg [749.119426ms]
Feb  6 01:54:56.184: INFO: Created: latency-svc-9g972
Feb  6 01:54:56.205: INFO: Got endpoints: latency-svc-2gfk6 [747.456617ms]
Feb  6 01:54:56.230: INFO: Created: latency-svc-grsxm
Feb  6 01:54:56.309: INFO: Got endpoints: latency-svc-hxj6q [753.658212ms]
Feb  6 01:54:56.309: INFO: Got endpoints: latency-svc-n7c48 [802.46498ms]
Feb  6 01:54:56.397: INFO: Created: latency-svc-2fmd5
Feb  6 01:54:56.398: INFO: Created: latency-svc-2hghn
Feb  6 01:54:56.398: INFO: Got endpoints: latency-svc-4xtnh [793.27949ms]
Feb  6 01:54:56.405: INFO: Got endpoints: latency-svc-97jn4 [750.311863ms]
Feb  6 01:54:56.426: INFO: Created: latency-svc-t4jnh
Feb  6 01:54:56.443: INFO: Created: latency-svc-fwrqf
Feb  6 01:54:56.454: INFO: Got endpoints: latency-svc-rr46k [746.936376ms]
Feb  6 01:54:56.477: INFO: Created: latency-svc-p8g78
Feb  6 01:54:56.506: INFO: Got endpoints: latency-svc-6pttz [752.064297ms]
Feb  6 01:54:56.555: INFO: Got endpoints: latency-svc-sphcs [749.261376ms]
Feb  6 01:54:56.604: INFO: Got endpoints: latency-svc-djrcx [748.357199ms]
Feb  6 01:54:56.655: INFO: Got endpoints: latency-svc-5w5lw [749.339589ms]
Feb  6 01:54:56.704: INFO: Got endpoints: latency-svc-qlsf6 [748.659472ms]
Feb  6 01:54:56.756: INFO: Got endpoints: latency-svc-77mgz [751.666036ms]
Feb  6 01:54:56.806: INFO: Got endpoints: latency-svc-ch59n [751.157965ms]
Feb  6 01:54:56.854: INFO: Got endpoints: latency-svc-5kfr4 [748.414463ms]
Feb  6 01:54:56.905: INFO: Got endpoints: latency-svc-9g972 [750.60051ms]
Feb  6 01:54:56.957: INFO: Got endpoints: latency-svc-grsxm [751.022304ms]
Feb  6 01:54:57.008: INFO: Got endpoints: latency-svc-2hghn [698.105217ms]
Feb  6 01:54:57.060: INFO: Got endpoints: latency-svc-2fmd5 [739.563739ms]
Feb  6 01:54:57.106: INFO: Got endpoints: latency-svc-t4jnh [708.186283ms]
Feb  6 01:54:57.154: INFO: Got endpoints: latency-svc-fwrqf [748.737ms]
Feb  6 01:54:57.267: INFO: Got endpoints: latency-svc-p8g78 [812.430868ms]
Feb  6 01:54:57.267: INFO: Latencies: [42.420253ms 43.197691ms 61.19137ms 77.924831ms 97.875919ms 115.275204ms 133.954105ms 153.116627ms 155.237126ms 168.242128ms 185.569069ms 204.71643ms 210.436182ms 213.795356ms 220.264017ms 238.674878ms 243.684677ms 255.57122ms 257.830115ms 263.350977ms 265.231844ms 265.678673ms 266.970527ms 270.322808ms 271.119993ms 273.854566ms 274.067497ms 274.653122ms 276.487906ms 277.043629ms 277.124694ms 279.309101ms 279.557778ms 280.148065ms 284.101702ms 288.237642ms 296.345681ms 299.096547ms 299.454667ms 306.768488ms 306.805139ms 306.846244ms 308.090256ms 308.931394ms 310.199281ms 312.839961ms 317.329517ms 320.951782ms 323.531701ms 323.751022ms 325.624362ms 326.002837ms 326.279303ms 333.829623ms 345.730959ms 354.186268ms 355.393058ms 357.517076ms 361.253914ms 369.932179ms 381.088874ms 394.318217ms 403.572591ms 405.807105ms 454.050931ms 456.810746ms 476.842588ms 486.568011ms 487.24315ms 501.75678ms 508.115064ms 552.722302ms 553.603966ms 599.140932ms 605.637313ms 651.003338ms 655.962702ms 686.787097ms 698.105217ms 700.525685ms 706.252509ms 708.186283ms 739.20358ms 739.563739ms 742.56729ms 743.600483ms 744.066766ms 744.835225ms 745.785781ms 746.010779ms 746.245797ms 746.927101ms 746.936376ms 747.055548ms 747.401595ms 747.456617ms 747.598651ms 747.614781ms 747.686712ms 747.90923ms 748.207818ms 748.260565ms 748.357199ms 748.357447ms 748.414463ms 748.659472ms 748.681155ms 748.737ms 748.751345ms 748.981297ms 749.06196ms 749.098148ms 749.119426ms 749.125515ms 749.163228ms 749.214506ms 749.261376ms 749.284126ms 749.30884ms 749.339589ms 749.42016ms 749.495807ms 749.628799ms 750.056362ms 750.058354ms 750.058622ms 750.144088ms 750.154415ms 750.311863ms 750.476061ms 750.60051ms 750.62477ms 750.649936ms 750.785328ms 750.850945ms 750.928162ms 750.969384ms 751.022304ms 751.058822ms 751.116497ms 751.157965ms 751.158378ms 751.408738ms 751.615052ms 751.629559ms 751.666036ms 751.763477ms 751.767377ms 751.77605ms 751.825972ms 751.831502ms 752.064297ms 752.08386ms 752.616781ms 752.768595ms 753.050797ms 753.201729ms 753.658212ms 755.032458ms 755.090568ms 755.586045ms 756.15654ms 756.278157ms 792.284657ms 793.27949ms 793.743612ms 794.846568ms 801.979619ms 802.393951ms 802.46498ms 803.057907ms 803.147961ms 803.360066ms 805.19747ms 805.877858ms 812.430868ms 820.99988ms 827.012815ms 827.147875ms 841.999462ms 844.944134ms 889.381061ms 891.847189ms 918.749287ms 933.172244ms 937.692546ms 943.860717ms 944.004375ms 966.610501ms 979.585719ms 982.323913ms 994.527058ms 1.044069861s 1.094224071s 1.14382641s 1.146425985s 1.195369432s 1.247235487s 1.292866027s 1.340525313s]
Feb  6 01:54:57.267: INFO: 50 %ile: 748.207818ms
Feb  6 01:54:57.267: INFO: 90 %ile: 844.944134ms
Feb  6 01:54:57.267: INFO: 99 %ile: 1.292866027s
Feb  6 01:54:57.267: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 01:54:57.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-8zwct" for this suite.
Feb  6 01:55:19.323: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 01:55:19.723: INFO: namespace: e2e-tests-svc-latency-8zwct, resource: bindings, ignored listing per whitelist
Feb  6 01:55:20.173: INFO: namespace e2e-tests-svc-latency-8zwct deletion completed in 22.895757716s

• [SLOW TEST:35.165 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 01:55:20.173: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-xw9x5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb  6 01:55:20.512: INFO: Waiting up to 5m0s for pod "pod-424fb07b-29b2-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-emptydir-xw9x5" to be "success or failure"
Feb  6 01:55:20.523: INFO: Pod "pod-424fb07b-29b2-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 10.917636ms
Feb  6 01:55:22.531: INFO: Pod "pod-424fb07b-29b2-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018415282s
Feb  6 01:55:24.749: INFO: Pod "pod-424fb07b-29b2-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.236640949s
STEP: Saw pod success
Feb  6 01:55:24.749: INFO: Pod "pod-424fb07b-29b2-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 01:55:24.756: INFO: Trying to get logs from node 10.190.119.145 pod pod-424fb07b-29b2-11e9-b6e7-06cba7aec104 container test-container: <nil>
STEP: delete the pod
Feb  6 01:55:24.801: INFO: Waiting for pod pod-424fb07b-29b2-11e9-b6e7-06cba7aec104 to disappear
Feb  6 01:55:24.808: INFO: Pod pod-424fb07b-29b2-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 01:55:24.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-xw9x5" for this suite.
Feb  6 01:55:30.937: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 01:55:31.476: INFO: namespace: e2e-tests-emptydir-xw9x5, resource: bindings, ignored listing per whitelist
Feb  6 01:55:31.624: INFO: namespace e2e-tests-emptydir-xw9x5 deletion completed in 6.805487763s

• [SLOW TEST:11.450 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 01:55:31.624: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-namespaces-9vwrk
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-x5nrh
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-7dk9q
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 01:55:38.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-9vwrk" for this suite.
Feb  6 01:55:46.589: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 01:55:46.688: INFO: namespace: e2e-tests-namespaces-9vwrk, resource: bindings, ignored listing per whitelist
Feb  6 01:55:46.901: INFO: namespace e2e-tests-namespaces-9vwrk deletion completed in 8.355909236s
STEP: Destroying namespace "e2e-tests-nsdeletetest-x5nrh" for this suite.
Feb  6 01:55:46.910: INFO: Namespace e2e-tests-nsdeletetest-x5nrh was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-7dk9q" for this suite.
Feb  6 01:55:52.953: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 01:55:53.010: INFO: namespace: e2e-tests-nsdeletetest-7dk9q, resource: bindings, ignored listing per whitelist
Feb  6 01:55:53.299: INFO: namespace e2e-tests-nsdeletetest-7dk9q deletion completed in 6.388927267s

• [SLOW TEST:21.675 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 01:55:53.300: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-wvl6g
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Feb  6 01:55:53.655: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-wvl6g,SelfLink:/api/v1/namespaces/e2e-tests-watch-wvl6g/configmaps/e2e-watch-test-configmap-a,UID:5611d926-29b2-11e9-9423-66f50c9be06e,ResourceVersion:51206,Generation:0,CreationTimestamp:2019-02-06 01:55:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb  6 01:55:53.655: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-wvl6g,SelfLink:/api/v1/namespaces/e2e-tests-watch-wvl6g/configmaps/e2e-watch-test-configmap-a,UID:5611d926-29b2-11e9-9423-66f50c9be06e,ResourceVersion:51206,Generation:0,CreationTimestamp:2019-02-06 01:55:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Feb  6 01:56:03.697: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-wvl6g,SelfLink:/api/v1/namespaces/e2e-tests-watch-wvl6g/configmaps/e2e-watch-test-configmap-a,UID:5611d926-29b2-11e9-9423-66f50c9be06e,ResourceVersion:51223,Generation:0,CreationTimestamp:2019-02-06 01:55:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb  6 01:56:03.697: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-wvl6g,SelfLink:/api/v1/namespaces/e2e-tests-watch-wvl6g/configmaps/e2e-watch-test-configmap-a,UID:5611d926-29b2-11e9-9423-66f50c9be06e,ResourceVersion:51223,Generation:0,CreationTimestamp:2019-02-06 01:55:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Feb  6 01:56:13.732: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-wvl6g,SelfLink:/api/v1/namespaces/e2e-tests-watch-wvl6g/configmaps/e2e-watch-test-configmap-a,UID:5611d926-29b2-11e9-9423-66f50c9be06e,ResourceVersion:51240,Generation:0,CreationTimestamp:2019-02-06 01:55:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb  6 01:56:13.732: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-wvl6g,SelfLink:/api/v1/namespaces/e2e-tests-watch-wvl6g/configmaps/e2e-watch-test-configmap-a,UID:5611d926-29b2-11e9-9423-66f50c9be06e,ResourceVersion:51240,Generation:0,CreationTimestamp:2019-02-06 01:55:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Feb  6 01:56:23.768: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-wvl6g,SelfLink:/api/v1/namespaces/e2e-tests-watch-wvl6g/configmaps/e2e-watch-test-configmap-a,UID:5611d926-29b2-11e9-9423-66f50c9be06e,ResourceVersion:51257,Generation:0,CreationTimestamp:2019-02-06 01:55:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb  6 01:56:23.768: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-wvl6g,SelfLink:/api/v1/namespaces/e2e-tests-watch-wvl6g/configmaps/e2e-watch-test-configmap-a,UID:5611d926-29b2-11e9-9423-66f50c9be06e,ResourceVersion:51257,Generation:0,CreationTimestamp:2019-02-06 01:55:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Feb  6 01:56:33.808: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-wvl6g,SelfLink:/api/v1/namespaces/e2e-tests-watch-wvl6g/configmaps/e2e-watch-test-configmap-b,UID:6dff7a72-29b2-11e9-9423-66f50c9be06e,ResourceVersion:51274,Generation:0,CreationTimestamp:2019-02-06 01:56:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb  6 01:56:33.808: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-wvl6g,SelfLink:/api/v1/namespaces/e2e-tests-watch-wvl6g/configmaps/e2e-watch-test-configmap-b,UID:6dff7a72-29b2-11e9-9423-66f50c9be06e,ResourceVersion:51274,Generation:0,CreationTimestamp:2019-02-06 01:56:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Feb  6 01:56:43.846: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-wvl6g,SelfLink:/api/v1/namespaces/e2e-tests-watch-wvl6g/configmaps/e2e-watch-test-configmap-b,UID:6dff7a72-29b2-11e9-9423-66f50c9be06e,ResourceVersion:51291,Generation:0,CreationTimestamp:2019-02-06 01:56:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb  6 01:56:43.846: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-wvl6g,SelfLink:/api/v1/namespaces/e2e-tests-watch-wvl6g/configmaps/e2e-watch-test-configmap-b,UID:6dff7a72-29b2-11e9-9423-66f50c9be06e,ResourceVersion:51291,Generation:0,CreationTimestamp:2019-02-06 01:56:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 01:56:53.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-wvl6g" for this suite.
Feb  6 01:56:59.964: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 01:57:00.260: INFO: namespace: e2e-tests-watch-wvl6g, resource: bindings, ignored listing per whitelist
Feb  6 01:57:00.261: INFO: namespace e2e-tests-watch-wvl6g deletion completed in 6.335130868s

• [SLOW TEST:66.961 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 01:57:00.262: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-xs7lw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-xs7lw
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-xs7lw
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-xs7lw
Feb  6 01:57:00.637: INFO: Found 0 stateful pods, waiting for 1
Feb  6 01:57:10.662: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Feb  6 01:57:10.670: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  6 01:57:10.994: INFO: stderr: ""
Feb  6 01:57:10.994: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  6 01:57:10.994: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  6 01:57:11.005: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb  6 01:57:21.032: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb  6 01:57:21.032: INFO: Waiting for statefulset status.replicas updated to 0
Feb  6 01:57:21.076: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Feb  6 01:57:21.076: INFO: ss-0  10.190.119.175  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:00 +0000 UTC  }]
Feb  6 01:57:21.076: INFO: 
Feb  6 01:57:21.076: INFO: StatefulSet ss has not reached scale 3, at 1
Feb  6 01:57:22.085: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.992073588s
Feb  6 01:57:23.107: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.982768214s
Feb  6 01:57:24.116: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.960834439s
Feb  6 01:57:25.124: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.95262081s
Feb  6 01:57:26.133: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.944195517s
Feb  6 01:57:27.141: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.935452513s
Feb  6 01:57:28.150: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.92674246s
Feb  6 01:57:29.158: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.918108562s
Feb  6 01:57:30.167: INFO: Verifying statefulset ss doesn't scale past 3 for another 910.272906ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-xs7lw
Feb  6 01:57:31.199: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 01:57:31.518: INFO: stderr: ""
Feb  6 01:57:31.518: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  6 01:57:31.518: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb  6 01:57:31.518: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 01:57:31.880: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Feb  6 01:57:31.880: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  6 01:57:31.880: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb  6 01:57:31.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 01:57:32.174: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Feb  6 01:57:32.174: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  6 01:57:32.174: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb  6 01:57:32.185: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb  6 01:57:32.185: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb  6 01:57:32.185: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Feb  6 01:57:32.194: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  6 01:57:32.508: INFO: stderr: ""
Feb  6 01:57:32.508: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  6 01:57:32.508: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  6 01:57:32.508: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  6 01:57:32.815: INFO: stderr: ""
Feb  6 01:57:32.815: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  6 01:57:32.815: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  6 01:57:32.815: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  6 01:57:33.180: INFO: stderr: ""
Feb  6 01:57:33.180: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  6 01:57:33.180: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  6 01:57:33.180: INFO: Waiting for statefulset status.replicas updated to 0
Feb  6 01:57:33.190: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Feb  6 01:57:43.236: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb  6 01:57:43.236: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb  6 01:57:43.236: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb  6 01:57:43.272: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Feb  6 01:57:43.272: INFO: ss-0  10.190.119.175  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:00 +0000 UTC  }]
Feb  6 01:57:43.272: INFO: ss-1  10.190.119.144  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:21 +0000 UTC  }]
Feb  6 01:57:43.272: INFO: ss-2  10.190.119.145  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:21 +0000 UTC  }]
Feb  6 01:57:43.272: INFO: 
Feb  6 01:57:43.272: INFO: StatefulSet ss has not reached scale 0, at 3
Feb  6 01:57:44.281: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Feb  6 01:57:44.281: INFO: ss-0  10.190.119.175  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:00 +0000 UTC  }]
Feb  6 01:57:44.281: INFO: ss-1  10.190.119.144  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:21 +0000 UTC  }]
Feb  6 01:57:44.281: INFO: ss-2  10.190.119.145  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:21 +0000 UTC  }]
Feb  6 01:57:44.281: INFO: 
Feb  6 01:57:44.281: INFO: StatefulSet ss has not reached scale 0, at 3
Feb  6 01:57:45.289: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Feb  6 01:57:45.289: INFO: ss-0  10.190.119.175  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:00 +0000 UTC  }]
Feb  6 01:57:45.289: INFO: ss-1  10.190.119.144  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:21 +0000 UTC  }]
Feb  6 01:57:45.289: INFO: ss-2  10.190.119.145  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:21 +0000 UTC  }]
Feb  6 01:57:45.289: INFO: 
Feb  6 01:57:45.290: INFO: StatefulSet ss has not reached scale 0, at 3
Feb  6 01:57:46.411: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Feb  6 01:57:46.411: INFO: ss-0  10.190.119.175  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:00 +0000 UTC  }]
Feb  6 01:57:46.411: INFO: ss-2  10.190.119.145  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:21 +0000 UTC  }]
Feb  6 01:57:46.411: INFO: 
Feb  6 01:57:46.411: INFO: StatefulSet ss has not reached scale 0, at 2
Feb  6 01:57:47.420: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Feb  6 01:57:47.420: INFO: ss-0  10.190.119.175  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:00 +0000 UTC  }]
Feb  6 01:57:47.420: INFO: ss-2  10.190.119.145  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:21 +0000 UTC  }]
Feb  6 01:57:47.420: INFO: 
Feb  6 01:57:47.420: INFO: StatefulSet ss has not reached scale 0, at 2
Feb  6 01:57:48.429: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Feb  6 01:57:48.429: INFO: ss-0  10.190.119.175  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:00 +0000 UTC  }]
Feb  6 01:57:48.429: INFO: ss-2  10.190.119.145  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:21 +0000 UTC  }]
Feb  6 01:57:48.429: INFO: 
Feb  6 01:57:48.429: INFO: StatefulSet ss has not reached scale 0, at 2
Feb  6 01:57:49.438: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Feb  6 01:57:49.438: INFO: ss-0  10.190.119.175  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:00 +0000 UTC  }]
Feb  6 01:57:49.438: INFO: ss-2  10.190.119.145  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:21 +0000 UTC  }]
Feb  6 01:57:49.438: INFO: 
Feb  6 01:57:49.438: INFO: StatefulSet ss has not reached scale 0, at 2
Feb  6 01:57:50.446: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Feb  6 01:57:50.446: INFO: ss-0  10.190.119.175  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:00 +0000 UTC  }]
Feb  6 01:57:50.447: INFO: ss-2  10.190.119.145  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:21 +0000 UTC  }]
Feb  6 01:57:50.447: INFO: 
Feb  6 01:57:50.447: INFO: StatefulSet ss has not reached scale 0, at 2
Feb  6 01:57:51.455: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Feb  6 01:57:51.455: INFO: ss-0  10.190.119.175  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:00 +0000 UTC  }]
Feb  6 01:57:51.455: INFO: ss-2  10.190.119.145  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:21 +0000 UTC  }]
Feb  6 01:57:51.455: INFO: 
Feb  6 01:57:51.455: INFO: StatefulSet ss has not reached scale 0, at 2
Feb  6 01:57:52.734: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Feb  6 01:57:52.734: INFO: ss-2  10.190.119.145  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 01:57:21 +0000 UTC  }]
Feb  6 01:57:52.734: INFO: 
Feb  6 01:57:52.734: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-xs7lw
Feb  6 01:57:53.763: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 01:57:53.978: INFO: rc: 1
Feb  6 01:57:53.978: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc000abb170 exit status 1 <nil> <nil> true [0xc000a6e530 0xc000a6e548 0xc000a6e560] [0xc000a6e530 0xc000a6e548 0xc000a6e560] [0xc000a6e540 0xc000a6e558] [0x92f8e0 0x92f8e0] 0xc00181f680 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Feb  6 01:58:03.978: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 01:58:04.078: INFO: rc: 1
Feb  6 01:58:04.078: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000abb620 exit status 1 <nil> <nil> true [0xc000a6e568 0xc000a6e580 0xc000a6e598] [0xc000a6e568 0xc000a6e580 0xc000a6e598] [0xc000a6e578 0xc000a6e590] [0x92f8e0 0x92f8e0] 0xc00181f980 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 01:58:14.078: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 01:58:14.207: INFO: rc: 1
Feb  6 01:58:14.207: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000abbc50 exit status 1 <nil> <nil> true [0xc000a6e5a0 0xc000a6e5b8 0xc000a6e5d0] [0xc000a6e5a0 0xc000a6e5b8 0xc000a6e5d0] [0xc000a6e5b0 0xc000a6e5c8] [0x92f8e0 0x92f8e0] 0xc00181fc80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 01:58:24.208: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 01:58:24.315: INFO: rc: 1
Feb  6 01:58:24.315: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000f440c0 exit status 1 <nil> <nil> true [0xc000a6e5d8 0xc000a6e5f0 0xc000a6e608] [0xc000a6e5d8 0xc000a6e5f0 0xc000a6e608] [0xc000a6e5e8 0xc000a6e600] [0x92f8e0 0x92f8e0] 0xc00181ff80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 01:58:34.316: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 01:58:34.432: INFO: rc: 1
Feb  6 01:58:34.432: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000d9f680 exit status 1 <nil> <nil> true [0xc000d6e478 0xc000d6e4b0 0xc000d6e500] [0xc000d6e478 0xc000d6e4b0 0xc000d6e500] [0xc000d6e490 0xc000d6e4e8] [0x92f8e0 0x92f8e0] 0xc00082a7e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 01:58:44.432: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 01:58:44.599: INFO: rc: 1
Feb  6 01:58:44.599: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000f44480 exit status 1 <nil> <nil> true [0xc000a6e610 0xc000a6e630 0xc000a6e648] [0xc000a6e610 0xc000a6e630 0xc000a6e648] [0xc000a6e628 0xc000a6e640] [0x92f8e0 0x92f8e0] 0xc001942420 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 01:58:54.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 01:58:54.718: INFO: rc: 1
Feb  6 01:58:54.718: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000f44840 exit status 1 <nil> <nil> true [0xc000a6e650 0xc000a6e668 0xc000a6e680] [0xc000a6e650 0xc000a6e668 0xc000a6e680] [0xc000a6e660 0xc000a6e678] [0x92f8e0 0x92f8e0] 0xc001942840 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 01:59:04.718: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 01:59:04.852: INFO: rc: 1
Feb  6 01:59:04.852: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000d9faa0 exit status 1 <nil> <nil> true [0xc000d6e540 0xc000d6e580 0xc000d6e5a8] [0xc000d6e540 0xc000d6e580 0xc000d6e5a8] [0xc000d6e578 0xc000d6e590] [0x92f8e0 0x92f8e0] 0xc00082ade0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 01:59:14.852: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 01:59:14.999: INFO: rc: 1
Feb  6 01:59:14.999: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000d9fe60 exit status 1 <nil> <nil> true [0xc000d6e5c0 0xc000d6e5d8 0xc000d6e618] [0xc000d6e5c0 0xc000d6e5d8 0xc000d6e618] [0xc000d6e5d0 0xc000d6e610] [0x92f8e0 0x92f8e0] 0xc00082b320 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 01:59:24.999: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 01:59:25.102: INFO: rc: 1
Feb  6 01:59:25.102: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000aba450 exit status 1 <nil> <nil> true [0xc000a6e008 0xc000a6e048 0xc000a6e088] [0xc000a6e008 0xc000a6e048 0xc000a6e088] [0xc000a6e028 0xc000a6e070] [0x92f8e0 0x92f8e0] 0xc00181e240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 01:59:35.102: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 01:59:35.237: INFO: rc: 1
Feb  6 01:59:35.237: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000aba810 exit status 1 <nil> <nil> true [0xc000a6e0a8 0xc000a6e0d0 0xc000a6e108] [0xc000a6e0a8 0xc000a6e0d0 0xc000a6e108] [0xc000a6e0c8 0xc000a6e0f0] [0x92f8e0 0x92f8e0] 0xc00181e6c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 01:59:45.237: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 01:59:45.348: INFO: rc: 1
Feb  6 01:59:45.348: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000abae10 exit status 1 <nil> <nil> true [0xc000a6e110 0xc000a6e128 0xc000a6e160] [0xc000a6e110 0xc000a6e128 0xc000a6e160] [0xc000a6e120 0xc000a6e158] [0x92f8e0 0x92f8e0] 0xc00181ecc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 01:59:55.348: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 01:59:55.451: INFO: rc: 1
Feb  6 01:59:55.451: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000abb290 exit status 1 <nil> <nil> true [0xc000a6e168 0xc000a6e180 0xc000a6e1b0] [0xc000a6e168 0xc000a6e180 0xc000a6e1b0] [0xc000a6e178 0xc000a6e198] [0x92f8e0 0x92f8e0] 0xc00181f320 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 02:00:05.451: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 02:00:05.556: INFO: rc: 1
Feb  6 02:00:05.556: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000abb980 exit status 1 <nil> <nil> true [0xc000a6e1b8 0xc000a6e1d0 0xc000a6e1f0] [0xc000a6e1b8 0xc000a6e1d0 0xc000a6e1f0] [0xc000a6e1c8 0xc000a6e1e8] [0x92f8e0 0x92f8e0] 0xc00181f740 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 02:00:15.556: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 02:00:15.655: INFO: rc: 1
Feb  6 02:00:15.656: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000abbe60 exit status 1 <nil> <nil> true [0xc000a6e1f8 0xc000a6e210 0xc000a6e228] [0xc000a6e1f8 0xc000a6e210 0xc000a6e228] [0xc000a6e208 0xc000a6e220] [0x92f8e0 0x92f8e0] 0xc00181fa40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 02:00:25.656: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 02:00:25.776: INFO: rc: 1
Feb  6 02:00:25.776: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0015dc420 exit status 1 <nil> <nil> true [0xc000d6e010 0xc000d6e048 0xc000d6e080] [0xc000d6e010 0xc000d6e048 0xc000d6e080] [0xc000d6e040 0xc000d6e068] [0x92f8e0 0x92f8e0] 0xc002736240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 02:00:35.776: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 02:00:35.876: INFO: rc: 1
Feb  6 02:00:35.876: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001858270 exit status 1 <nil> <nil> true [0xc000a6e230 0xc000a6e248 0xc000a6e260] [0xc000a6e230 0xc000a6e248 0xc000a6e260] [0xc000a6e240 0xc000a6e258] [0x92f8e0 0x92f8e0] 0xc00181fd40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 02:00:45.876: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 02:00:46.002: INFO: rc: 1
Feb  6 02:00:46.002: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0015dc7e0 exit status 1 <nil> <nil> true [0xc000d6e098 0xc000d6e0d8 0xc000d6e108] [0xc000d6e098 0xc000d6e0d8 0xc000d6e108] [0xc000d6e0c0 0xc000d6e0f0] [0x92f8e0 0x92f8e0] 0xc0027365a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 02:00:56.002: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 02:00:56.128: INFO: rc: 1
Feb  6 02:00:56.128: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0018586c0 exit status 1 <nil> <nil> true [0xc000a6e270 0xc000a6e288 0xc000a6e2a0] [0xc000a6e270 0xc000a6e288 0xc000a6e2a0] [0xc000a6e280 0xc000a6e298] [0x92f8e0 0x92f8e0] 0xc0015120c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 02:01:06.128: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 02:01:06.239: INFO: rc: 1
Feb  6 02:01:06.239: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0015dcba0 exit status 1 <nil> <nil> true [0xc000d6e110 0xc000d6e148 0xc000d6e190] [0xc000d6e110 0xc000d6e148 0xc000d6e190] [0xc000d6e128 0xc000d6e178] [0x92f8e0 0x92f8e0] 0xc0027368a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 02:01:16.239: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 02:01:16.413: INFO: rc: 1
Feb  6 02:01:16.413: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001858ab0 exit status 1 <nil> <nil> true [0xc000a6e2a8 0xc000a6e2c0 0xc000a6e2d8] [0xc000a6e2a8 0xc000a6e2c0 0xc000a6e2d8] [0xc000a6e2b8 0xc000a6e2d0] [0x92f8e0 0x92f8e0] 0xc0015126c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 02:01:26.414: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 02:01:26.526: INFO: rc: 1
Feb  6 02:01:26.526: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001858e40 exit status 1 <nil> <nil> true [0xc000a6e2e8 0xc000a6e300 0xc000a6e318] [0xc000a6e2e8 0xc000a6e300 0xc000a6e318] [0xc000a6e2f8 0xc000a6e310] [0x92f8e0 0x92f8e0] 0xc001512c00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 02:01:36.527: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 02:01:36.637: INFO: rc: 1
Feb  6 02:01:36.637: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0015dc450 exit status 1 <nil> <nil> true [0xc000d6e010 0xc000d6e048 0xc000d6e080] [0xc000d6e010 0xc000d6e048 0xc000d6e080] [0xc000d6e040 0xc000d6e068] [0x92f8e0 0x92f8e0] 0xc00181e240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 02:01:46.637: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 02:01:46.770: INFO: rc: 1
Feb  6 02:01:46.770: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0015dc840 exit status 1 <nil> <nil> true [0xc000d6e098 0xc000d6e0d8 0xc000d6e108] [0xc000d6e098 0xc000d6e0d8 0xc000d6e108] [0xc000d6e0c0 0xc000d6e0f0] [0x92f8e0 0x92f8e0] 0xc00181e6c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 02:01:56.770: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 02:01:56.895: INFO: rc: 1
Feb  6 02:01:56.895: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0015dcc90 exit status 1 <nil> <nil> true [0xc000d6e110 0xc000d6e148 0xc000d6e190] [0xc000d6e110 0xc000d6e148 0xc000d6e190] [0xc000d6e128 0xc000d6e178] [0x92f8e0 0x92f8e0] 0xc00181ecc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 02:02:06.895: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 02:02:06.994: INFO: rc: 1
Feb  6 02:02:06.994: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0015dd020 exit status 1 <nil> <nil> true [0xc000d6e198 0xc000d6e1d8 0xc000d6e200] [0xc000d6e198 0xc000d6e1d8 0xc000d6e200] [0xc000d6e1b8 0xc000d6e1f8] [0x92f8e0 0x92f8e0] 0xc00181f320 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 02:02:16.994: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 02:02:17.114: INFO: rc: 1
Feb  6 02:02:17.114: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000aba4b0 exit status 1 <nil> <nil> true [0xc000a6e000 0xc000a6e028 0xc000a6e070] [0xc000a6e000 0xc000a6e028 0xc000a6e070] [0xc000a6e010 0xc000a6e060] [0x92f8e0 0x92f8e0] 0xc002736240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 02:02:27.115: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 02:02:27.228: INFO: rc: 1
Feb  6 02:02:27.228: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000aba8a0 exit status 1 <nil> <nil> true [0xc000a6e088 0xc000a6e0c8 0xc000a6e0f0] [0xc000a6e088 0xc000a6e0c8 0xc000a6e0f0] [0xc000a6e0c0 0xc000a6e0d8] [0x92f8e0 0x92f8e0] 0xc0027365a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 02:02:37.229: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 02:02:37.399: INFO: rc: 1
Feb  6 02:02:37.399: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0015dd410 exit status 1 <nil> <nil> true [0xc000d6e208 0xc000d6e268 0xc000d6e290] [0xc000d6e208 0xc000d6e268 0xc000d6e290] [0xc000d6e248 0xc000d6e288] [0x92f8e0 0x92f8e0] 0xc00181f740 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 02:02:47.399: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 02:02:47.519: INFO: rc: 1
Feb  6 02:02:47.519: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000abaed0 exit status 1 <nil> <nil> true [0xc000a6e108 0xc000a6e120 0xc000a6e158] [0xc000a6e108 0xc000a6e120 0xc000a6e158] [0xc000a6e118 0xc000a6e140] [0x92f8e0 0x92f8e0] 0xc0027368a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 02:02:57.520: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-xs7lw ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 02:02:57.625: INFO: rc: 1
Feb  6 02:02:57.625: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: 
Feb  6 02:02:57.625: INFO: Scaling statefulset ss to 0
Feb  6 02:02:57.716: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb  6 02:02:57.725: INFO: Deleting all statefulset in ns e2e-tests-statefulset-xs7lw
Feb  6 02:02:57.736: INFO: Scaling statefulset ss to 0
Feb  6 02:02:57.764: INFO: Waiting for statefulset status.replicas updated to 0
Feb  6 02:02:57.773: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:02:57.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-xs7lw" for this suite.
Feb  6 02:03:05.871: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:03:06.081: INFO: namespace: e2e-tests-statefulset-xs7lw, resource: bindings, ignored listing per whitelist
Feb  6 02:03:06.212: INFO: namespace e2e-tests-statefulset-xs7lw deletion completed in 8.38091674s

• [SLOW TEST:365.950 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:03:06.214: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-t4vsm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Feb  6 02:03:06.713: INFO: Waiting up to 5m0s for pod "var-expansion-5822838c-29b3-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-var-expansion-t4vsm" to be "success or failure"
Feb  6 02:03:06.722: INFO: Pod "var-expansion-5822838c-29b3-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 8.239371ms
Feb  6 02:03:09.223: INFO: Pod "var-expansion-5822838c-29b3-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.509129138s
STEP: Saw pod success
Feb  6 02:03:09.223: INFO: Pod "var-expansion-5822838c-29b3-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 02:03:09.278: INFO: Trying to get logs from node 10.190.119.175 pod var-expansion-5822838c-29b3-11e9-b6e7-06cba7aec104 container dapi-container: <nil>
STEP: delete the pod
Feb  6 02:03:09.330: INFO: Waiting for pod var-expansion-5822838c-29b3-11e9-b6e7-06cba7aec104 to disappear
Feb  6 02:03:09.337: INFO: Pod var-expansion-5822838c-29b3-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:03:09.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-t4vsm" for this suite.
Feb  6 02:03:15.386: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:03:15.718: INFO: namespace: e2e-tests-var-expansion-t4vsm, resource: bindings, ignored listing per whitelist
Feb  6 02:03:15.789: INFO: namespace e2e-tests-var-expansion-t4vsm deletion completed in 6.440343731s

• [SLOW TEST:9.576 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:03:15.790: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-wrapper-ptwx7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:03:20.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-ptwx7" for this suite.
Feb  6 02:03:28.448: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:03:28.564: INFO: namespace: e2e-tests-emptydir-wrapper-ptwx7, resource: bindings, ignored listing per whitelist
Feb  6 02:03:28.776: INFO: namespace e2e-tests-emptydir-wrapper-ptwx7 deletion completed in 8.364421679s

• [SLOW TEST:12.985 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:03:28.776: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-kqg7n
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb  6 02:03:29.108: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-kqg7n'
Feb  6 02:03:29.540: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb  6 02:03:29.540: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Feb  6 02:03:29.548: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-kqg7n'
Feb  6 02:03:29.675: INFO: stderr: ""
Feb  6 02:03:29.675: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:03:29.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-kqg7n" for this suite.
Feb  6 02:03:53.729: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:03:53.866: INFO: namespace: e2e-tests-kubectl-kqg7n, resource: bindings, ignored listing per whitelist
Feb  6 02:03:54.124: INFO: namespace e2e-tests-kubectl-kqg7n deletion completed in 24.438151066s

• [SLOW TEST:25.348 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:03:54.125: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-tjsm4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-74a6ad74-29b3-11e9-b6e7-06cba7aec104
STEP: Creating a pod to test consume configMaps
Feb  6 02:03:54.474: INFO: Waiting up to 5m0s for pod "pod-configmaps-74a823d7-29b3-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-configmap-tjsm4" to be "success or failure"
Feb  6 02:03:54.480: INFO: Pod "pod-configmaps-74a823d7-29b3-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 6.525918ms
Feb  6 02:03:56.489: INFO: Pod "pod-configmaps-74a823d7-29b3-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015532815s
STEP: Saw pod success
Feb  6 02:03:56.489: INFO: Pod "pod-configmaps-74a823d7-29b3-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 02:03:56.499: INFO: Trying to get logs from node 10.190.119.175 pod pod-configmaps-74a823d7-29b3-11e9-b6e7-06cba7aec104 container configmap-volume-test: <nil>
STEP: delete the pod
Feb  6 02:03:56.544: INFO: Waiting for pod pod-configmaps-74a823d7-29b3-11e9-b6e7-06cba7aec104 to disappear
Feb  6 02:03:56.604: INFO: Pod pod-configmaps-74a823d7-29b3-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:03:56.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-tjsm4" for this suite.
Feb  6 02:04:04.676: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:04:04.770: INFO: namespace: e2e-tests-configmap-tjsm4, resource: bindings, ignored listing per whitelist
Feb  6 02:04:05.635: INFO: namespace e2e-tests-configmap-tjsm4 deletion completed in 9.020475255s

• [SLOW TEST:11.511 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:04:05.638: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-b67xl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:04:05.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-b67xl" for this suite.
Feb  6 02:04:12.021: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:04:12.369: INFO: namespace: e2e-tests-services-b67xl, resource: bindings, ignored listing per whitelist
Feb  6 02:04:12.426: INFO: namespace e2e-tests-services-b67xl deletion completed in 6.445208851s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:6.788 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:04:12.426: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-5wkpn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Feb  6 02:04:12.737: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Feb  6 02:04:12.738: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 create -f - --namespace=e2e-tests-kubectl-5wkpn'
Feb  6 02:04:13.055: INFO: stderr: ""
Feb  6 02:04:13.055: INFO: stdout: "service/redis-slave created\n"
Feb  6 02:04:13.055: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Feb  6 02:04:13.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 create -f - --namespace=e2e-tests-kubectl-5wkpn'
Feb  6 02:04:13.346: INFO: stderr: ""
Feb  6 02:04:13.346: INFO: stdout: "service/redis-master created\n"
Feb  6 02:04:13.347: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Feb  6 02:04:13.347: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 create -f - --namespace=e2e-tests-kubectl-5wkpn'
Feb  6 02:04:13.664: INFO: stderr: ""
Feb  6 02:04:13.664: INFO: stdout: "service/frontend created\n"
Feb  6 02:04:13.664: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Feb  6 02:04:13.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 create -f - --namespace=e2e-tests-kubectl-5wkpn'
Feb  6 02:04:13.889: INFO: stderr: ""
Feb  6 02:04:13.889: INFO: stdout: "deployment.extensions/frontend created\n"
Feb  6 02:04:13.889: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Feb  6 02:04:13.889: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 create -f - --namespace=e2e-tests-kubectl-5wkpn'
Feb  6 02:04:14.157: INFO: stderr: ""
Feb  6 02:04:14.157: INFO: stdout: "deployment.extensions/redis-master created\n"
Feb  6 02:04:14.157: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Feb  6 02:04:14.158: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 create -f - --namespace=e2e-tests-kubectl-5wkpn'
Feb  6 02:04:14.436: INFO: stderr: ""
Feb  6 02:04:14.436: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Feb  6 02:04:14.436: INFO: Waiting for all frontend pods to be Running.
Feb  6 02:04:19.487: INFO: Waiting for frontend to serve content.
Feb  6 02:04:19.538: INFO: Trying to add a new entry to the guestbook.
Feb  6 02:04:19.561: INFO: Verifying that added entry can be retrieved.
Feb  6 02:04:19.592: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
STEP: using delete to clean up resources
Feb  6 02:04:24.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-5wkpn'
Feb  6 02:04:24.842: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  6 02:04:24.842: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Feb  6 02:04:24.842: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-5wkpn'
Feb  6 02:04:25.624: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  6 02:04:25.624: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb  6 02:04:25.624: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-5wkpn'
Feb  6 02:04:25.808: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  6 02:04:25.808: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb  6 02:04:25.808: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-5wkpn'
Feb  6 02:04:25.925: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  6 02:04:25.925: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb  6 02:04:25.925: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-5wkpn'
Feb  6 02:04:26.089: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  6 02:04:26.089: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb  6 02:04:26.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-5wkpn'
Feb  6 02:04:26.316: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  6 02:04:26.316: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:04:26.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-5wkpn" for this suite.
Feb  6 02:05:08.384: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:05:08.456: INFO: namespace: e2e-tests-kubectl-5wkpn, resource: bindings, ignored listing per whitelist
Feb  6 02:05:08.694: INFO: namespace e2e-tests-kubectl-5wkpn deletion completed in 42.348531713s

• [SLOW TEST:56.267 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:05:08.694: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-pmfgd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-pmfgd/configmap-test-a1255bb2-29b3-11e9-b6e7-06cba7aec104
STEP: Creating a pod to test consume configMaps
Feb  6 02:05:09.513: INFO: Waiting up to 5m0s for pod "pod-configmaps-a126f52b-29b3-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-configmap-pmfgd" to be "success or failure"
Feb  6 02:05:09.520: INFO: Pod "pod-configmaps-a126f52b-29b3-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 7.46226ms
Feb  6 02:05:11.528: INFO: Pod "pod-configmaps-a126f52b-29b3-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015458924s
STEP: Saw pod success
Feb  6 02:05:11.529: INFO: Pod "pod-configmaps-a126f52b-29b3-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 02:05:11.537: INFO: Trying to get logs from node 10.190.119.144 pod pod-configmaps-a126f52b-29b3-11e9-b6e7-06cba7aec104 container env-test: <nil>
STEP: delete the pod
Feb  6 02:05:11.587: INFO: Waiting for pod pod-configmaps-a126f52b-29b3-11e9-b6e7-06cba7aec104 to disappear
Feb  6 02:05:11.604: INFO: Pod pod-configmaps-a126f52b-29b3-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:05:11.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-pmfgd" for this suite.
Feb  6 02:05:17.677: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:05:17.835: INFO: namespace: e2e-tests-configmap-pmfgd, resource: bindings, ignored listing per whitelist
Feb  6 02:05:17.995: INFO: namespace e2e-tests-configmap-pmfgd deletion completed in 6.379657476s

• [SLOW TEST:9.301 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:05:17.996: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replication-controller-h79p2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Feb  6 02:05:18.341: INFO: Pod name pod-release: Found 0 pods out of 1
Feb  6 02:05:23.349: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:05:24.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-h79p2" for this suite.
Feb  6 02:05:30.512: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:05:30.929: INFO: namespace: e2e-tests-replication-controller-h79p2, resource: bindings, ignored listing per whitelist
Feb  6 02:05:31.069: INFO: namespace e2e-tests-replication-controller-h79p2 deletion completed in 6.653334111s

• [SLOW TEST:13.074 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:05:31.071: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-lvsmt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-ae7267aa-29b3-11e9-b6e7-06cba7aec104
STEP: Creating a pod to test consume configMaps
Feb  6 02:05:31.443: INFO: Waiting up to 5m0s for pod "pod-configmaps-ae740b18-29b3-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-configmap-lvsmt" to be "success or failure"
Feb  6 02:05:31.455: INFO: Pod "pod-configmaps-ae740b18-29b3-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 11.372952ms
Feb  6 02:05:33.463: INFO: Pod "pod-configmaps-ae740b18-29b3-11e9-b6e7-06cba7aec104": Phase="Running", Reason="", readiness=true. Elapsed: 2.019846896s
Feb  6 02:05:35.471: INFO: Pod "pod-configmaps-ae740b18-29b3-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027792136s
STEP: Saw pod success
Feb  6 02:05:35.472: INFO: Pod "pod-configmaps-ae740b18-29b3-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 02:05:35.479: INFO: Trying to get logs from node 10.190.119.144 pod pod-configmaps-ae740b18-29b3-11e9-b6e7-06cba7aec104 container configmap-volume-test: <nil>
STEP: delete the pod
Feb  6 02:05:35.521: INFO: Waiting for pod pod-configmaps-ae740b18-29b3-11e9-b6e7-06cba7aec104 to disappear
Feb  6 02:05:35.528: INFO: Pod pod-configmaps-ae740b18-29b3-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:05:35.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-lvsmt" for this suite.
Feb  6 02:05:41.634: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:05:41.984: INFO: namespace: e2e-tests-configmap-lvsmt, resource: bindings, ignored listing per whitelist
Feb  6 02:05:42.004: INFO: namespace e2e-tests-configmap-lvsmt deletion completed in 6.406946129s

• [SLOW TEST:10.934 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:05:42.006: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-q2bc7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  6 02:05:42.451: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"b5037a26-29b3-11e9-9423-66f50c9be06e", Controller:(*bool)(0xc0012e240e), BlockOwnerDeletion:(*bool)(0xc0012e240f)}}
Feb  6 02:05:42.469: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"b4ffd866-29b3-11e9-9423-66f50c9be06e", Controller:(*bool)(0xc0026d0426), BlockOwnerDeletion:(*bool)(0xc0026d0427)}}
Feb  6 02:05:42.480: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"b501b4b2-29b3-11e9-9423-66f50c9be06e", Controller:(*bool)(0xc0012e2606), BlockOwnerDeletion:(*bool)(0xc0012e2607)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:05:47.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-q2bc7" for this suite.
Feb  6 02:05:53.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:05:53.690: INFO: namespace: e2e-tests-gc-q2bc7, resource: bindings, ignored listing per whitelist
Feb  6 02:05:53.844: INFO: namespace e2e-tests-gc-q2bc7 deletion completed in 6.331711523s

• [SLOW TEST:11.839 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:05:53.845: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-8j5sz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  6 02:05:54.259: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bc0d9583-29b3-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-downward-api-8j5sz" to be "success or failure"
Feb  6 02:05:54.266: INFO: Pod "downwardapi-volume-bc0d9583-29b3-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 6.482512ms
Feb  6 02:05:56.276: INFO: Pod "downwardapi-volume-bc0d9583-29b3-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016502255s
STEP: Saw pod success
Feb  6 02:05:56.276: INFO: Pod "downwardapi-volume-bc0d9583-29b3-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 02:05:56.285: INFO: Trying to get logs from node 10.190.119.145 pod downwardapi-volume-bc0d9583-29b3-11e9-b6e7-06cba7aec104 container client-container: <nil>
STEP: delete the pod
Feb  6 02:05:56.344: INFO: Waiting for pod downwardapi-volume-bc0d9583-29b3-11e9-b6e7-06cba7aec104 to disappear
Feb  6 02:05:56.403: INFO: Pod downwardapi-volume-bc0d9583-29b3-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:05:56.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-8j5sz" for this suite.
Feb  6 02:06:04.461: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:06:04.605: INFO: namespace: e2e-tests-downward-api-8j5sz, resource: bindings, ignored listing per whitelist
Feb  6 02:06:04.800: INFO: namespace e2e-tests-downward-api-8j5sz deletion completed in 8.381037076s

• [SLOW TEST:10.956 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:06:04.802: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-wrapper-276l6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Feb  6 02:06:06.228: INFO: Pod name wrapped-volume-race-c32e13a7-29b3-11e9-b6e7-06cba7aec104: Found 0 pods out of 5
Feb  6 02:06:11.247: INFO: Pod name wrapped-volume-race-c32e13a7-29b3-11e9-b6e7-06cba7aec104: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-c32e13a7-29b3-11e9-b6e7-06cba7aec104 in namespace e2e-tests-emptydir-wrapper-276l6, will wait for the garbage collector to delete the pods
Feb  6 02:06:21.379: INFO: Deleting ReplicationController wrapped-volume-race-c32e13a7-29b3-11e9-b6e7-06cba7aec104 took: 21.683539ms
Feb  6 02:06:21.480: INFO: Terminating ReplicationController wrapped-volume-race-c32e13a7-29b3-11e9-b6e7-06cba7aec104 pods took: 100.171773ms
STEP: Creating RC which spawns configmap-volume pods
Feb  6 02:07:01.634: INFO: Pod name wrapped-volume-race-e430ee1a-29b3-11e9-b6e7-06cba7aec104: Found 0 pods out of 5
Feb  6 02:07:06.647: INFO: Pod name wrapped-volume-race-e430ee1a-29b3-11e9-b6e7-06cba7aec104: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-e430ee1a-29b3-11e9-b6e7-06cba7aec104 in namespace e2e-tests-emptydir-wrapper-276l6, will wait for the garbage collector to delete the pods
Feb  6 02:07:16.789: INFO: Deleting ReplicationController wrapped-volume-race-e430ee1a-29b3-11e9-b6e7-06cba7aec104 took: 27.565394ms
Feb  6 02:07:16.890: INFO: Terminating ReplicationController wrapped-volume-race-e430ee1a-29b3-11e9-b6e7-06cba7aec104 pods took: 100.221101ms
STEP: Creating RC which spawns configmap-volume pods
Feb  6 02:08:01.354: INFO: Pod name wrapped-volume-race-07c7e4a2-29b4-11e9-b6e7-06cba7aec104: Found 0 pods out of 5
Feb  6 02:08:06.409: INFO: Pod name wrapped-volume-race-07c7e4a2-29b4-11e9-b6e7-06cba7aec104: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-07c7e4a2-29b4-11e9-b6e7-06cba7aec104 in namespace e2e-tests-emptydir-wrapper-276l6, will wait for the garbage collector to delete the pods
Feb  6 02:08:16.546: INFO: Deleting ReplicationController wrapped-volume-race-07c7e4a2-29b4-11e9-b6e7-06cba7aec104 took: 26.290899ms
Feb  6 02:08:16.746: INFO: Terminating ReplicationController wrapped-volume-race-07c7e4a2-29b4-11e9-b6e7-06cba7aec104 pods took: 200.230458ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:09:01.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-276l6" for this suite.
Feb  6 02:09:12.041: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:09:12.171: INFO: namespace: e2e-tests-emptydir-wrapper-276l6, resource: bindings, ignored listing per whitelist
Feb  6 02:09:12.391: INFO: namespace e2e-tests-emptydir-wrapper-276l6 deletion completed in 10.402277239s

• [SLOW TEST:187.589 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:09:12.391: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-qpgfw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb  6 02:09:12.849: INFO: Number of nodes with available pods: 0
Feb  6 02:09:12.849: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 02:09:13.904: INFO: Number of nodes with available pods: 0
Feb  6 02:09:13.904: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 02:09:14.872: INFO: Number of nodes with available pods: 3
Feb  6 02:09:14.872: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Feb  6 02:09:14.923: INFO: Number of nodes with available pods: 3
Feb  6 02:09:14.923: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-qpgfw, will wait for the garbage collector to delete the pods
Feb  6 02:09:16.024: INFO: Deleting DaemonSet.extensions daemon-set took: 18.632082ms
Feb  6 02:09:16.125: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.449551ms
Feb  6 02:09:54.658: INFO: Number of nodes with available pods: 0
Feb  6 02:09:54.658: INFO: Number of running nodes: 0, number of available pods: 0
Feb  6 02:09:54.668: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-qpgfw/daemonsets","resourceVersion":"54541"},"items":null}

Feb  6 02:09:54.677: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-qpgfw/pods","resourceVersion":"54541"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:09:54.712: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-qpgfw" for this suite.
Feb  6 02:10:02.766: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:10:02.851: INFO: namespace: e2e-tests-daemonsets-qpgfw, resource: bindings, ignored listing per whitelist
Feb  6 02:10:03.143: INFO: namespace e2e-tests-daemonsets-qpgfw deletion completed in 8.416713621s

• [SLOW TEST:50.752 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:10:03.145: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-btk4s
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb  6 02:10:03.556: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:10:07.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-btk4s" for this suite.
Feb  6 02:10:31.244: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:10:31.410: INFO: namespace: e2e-tests-init-container-btk4s, resource: bindings, ignored listing per whitelist
Feb  6 02:10:31.727: INFO: namespace e2e-tests-init-container-btk4s deletion completed in 24.529835281s

• [SLOW TEST:28.583 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:10:31.728: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-qkfct
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-61a5c737-29b4-11e9-b6e7-06cba7aec104
STEP: Creating secret with name s-test-opt-upd-61a5c780-29b4-11e9-b6e7-06cba7aec104
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-61a5c737-29b4-11e9-b6e7-06cba7aec104
STEP: Updating secret s-test-opt-upd-61a5c780-29b4-11e9-b6e7-06cba7aec104
STEP: Creating secret with name s-test-opt-create-61a5c7a0-29b4-11e9-b6e7-06cba7aec104
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:10:36.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qkfct" for this suite.
Feb  6 02:11:00.504: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:11:00.700: INFO: namespace: e2e-tests-projected-qkfct, resource: bindings, ignored listing per whitelist
Feb  6 02:11:00.907: INFO: namespace e2e-tests-projected-qkfct deletion completed in 24.459454389s

• [SLOW TEST:29.179 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:11:00.911: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-e2e-kubelet-etc-hosts-lxklb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Feb  6 02:11:07.322: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-lxklb PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 02:11:07.322: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
Feb  6 02:11:07.507: INFO: Exec stderr: ""
Feb  6 02:11:07.508: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-lxklb PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 02:11:07.508: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
Feb  6 02:11:07.794: INFO: Exec stderr: ""
Feb  6 02:11:07.794: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-lxklb PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 02:11:07.794: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
Feb  6 02:11:07.984: INFO: Exec stderr: ""
Feb  6 02:11:07.985: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-lxklb PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 02:11:07.985: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
Feb  6 02:11:08.279: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Feb  6 02:11:08.279: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-lxklb PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 02:11:08.279: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
Feb  6 02:11:08.482: INFO: Exec stderr: ""
Feb  6 02:11:08.482: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-lxklb PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 02:11:08.482: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
Feb  6 02:11:08.678: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Feb  6 02:11:08.678: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-lxklb PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 02:11:08.678: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
Feb  6 02:11:08.944: INFO: Exec stderr: ""
Feb  6 02:11:08.944: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-lxklb PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 02:11:08.944: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
Feb  6 02:11:09.137: INFO: Exec stderr: ""
Feb  6 02:11:09.138: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-lxklb PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 02:11:09.138: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
Feb  6 02:11:09.351: INFO: Exec stderr: ""
Feb  6 02:11:09.351: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-lxklb PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 02:11:09.351: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
Feb  6 02:11:09.529: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:11:09.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-lxklb" for this suite.
Feb  6 02:11:55.606: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:11:55.938: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-lxklb, resource: bindings, ignored listing per whitelist
Feb  6 02:11:56.062: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-lxklb deletion completed in 46.520128251s

• [SLOW TEST:55.151 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:11:56.062: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-gdqqb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-93eb459a-29b4-11e9-b6e7-06cba7aec104
STEP: Creating secret with name secret-projected-all-test-volume-93eb4570-29b4-11e9-b6e7-06cba7aec104
STEP: Creating a pod to test Check all projections for projected volume plugin
Feb  6 02:11:56.454: INFO: Waiting up to 5m0s for pod "projected-volume-93eb4507-29b4-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-projected-gdqqb" to be "success or failure"
Feb  6 02:11:56.461: INFO: Pod "projected-volume-93eb4507-29b4-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 6.862452ms
Feb  6 02:11:58.469: INFO: Pod "projected-volume-93eb4507-29b4-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015583138s
STEP: Saw pod success
Feb  6 02:11:58.470: INFO: Pod "projected-volume-93eb4507-29b4-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 02:11:58.478: INFO: Trying to get logs from node 10.190.119.144 pod projected-volume-93eb4507-29b4-11e9-b6e7-06cba7aec104 container projected-all-volume-test: <nil>
STEP: delete the pod
Feb  6 02:11:58.527: INFO: Waiting for pod projected-volume-93eb4507-29b4-11e9-b6e7-06cba7aec104 to disappear
Feb  6 02:11:58.534: INFO: Pod projected-volume-93eb4507-29b4-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:11:58.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gdqqb" for this suite.
Feb  6 02:12:06.612: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:12:06.975: INFO: namespace: e2e-tests-projected-gdqqb, resource: bindings, ignored listing per whitelist
Feb  6 02:12:06.997: INFO: namespace e2e-tests-projected-gdqqb deletion completed in 8.452605621s

• [SLOW TEST:10.935 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:12:06.998: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-9zfcl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Feb  6 02:12:07.373: INFO: Waiting up to 5m0s for pod "var-expansion-9a724d2d-29b4-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-var-expansion-9zfcl" to be "success or failure"
Feb  6 02:12:07.380: INFO: Pod "var-expansion-9a724d2d-29b4-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 6.929701ms
Feb  6 02:12:09.389: INFO: Pod "var-expansion-9a724d2d-29b4-11e9-b6e7-06cba7aec104": Phase="Running", Reason="", readiness=true. Elapsed: 2.015605314s
Feb  6 02:12:11.414: INFO: Pod "var-expansion-9a724d2d-29b4-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040991262s
STEP: Saw pod success
Feb  6 02:12:11.414: INFO: Pod "var-expansion-9a724d2d-29b4-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 02:12:11.423: INFO: Trying to get logs from node 10.190.119.145 pod var-expansion-9a724d2d-29b4-11e9-b6e7-06cba7aec104 container dapi-container: <nil>
STEP: delete the pod
Feb  6 02:12:11.472: INFO: Waiting for pod var-expansion-9a724d2d-29b4-11e9-b6e7-06cba7aec104 to disappear
Feb  6 02:12:11.481: INFO: Pod var-expansion-9a724d2d-29b4-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:12:11.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-9zfcl" for this suite.
Feb  6 02:12:19.533: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:12:19.835: INFO: namespace: e2e-tests-var-expansion-9zfcl, resource: bindings, ignored listing per whitelist
Feb  6 02:12:19.884: INFO: namespace e2e-tests-var-expansion-9zfcl deletion completed in 8.391191207s

• [SLOW TEST:12.887 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:12:19.886: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-llwl4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb  6 02:12:22.797: INFO: Successfully updated pod "pod-update-activedeadlineseconds-a21c9e93-29b4-11e9-b6e7-06cba7aec104"
Feb  6 02:12:22.797: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-a21c9e93-29b4-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-pods-llwl4" to be "terminated due to deadline exceeded"
Feb  6 02:12:22.805: INFO: Pod "pod-update-activedeadlineseconds-a21c9e93-29b4-11e9-b6e7-06cba7aec104": Phase="Running", Reason="", readiness=true. Elapsed: 7.706043ms
Feb  6 02:12:24.813: INFO: Pod "pod-update-activedeadlineseconds-a21c9e93-29b4-11e9-b6e7-06cba7aec104": Phase="Running", Reason="", readiness=true. Elapsed: 2.016079627s
Feb  6 02:12:26.823: INFO: Pod "pod-update-activedeadlineseconds-a21c9e93-29b4-11e9-b6e7-06cba7aec104": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.026161242s
Feb  6 02:12:26.823: INFO: Pod "pod-update-activedeadlineseconds-a21c9e93-29b4-11e9-b6e7-06cba7aec104" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:12:26.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-llwl4" for this suite.
Feb  6 02:12:32.902: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:12:33.379: INFO: namespace: e2e-tests-pods-llwl4, resource: bindings, ignored listing per whitelist
Feb  6 02:12:33.552: INFO: namespace e2e-tests-pods-llwl4 deletion completed in 6.715025861s

• [SLOW TEST:13.666 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:12:33.552: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-9fqfq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Feb  6 02:12:34.445: INFO: Waiting up to 5m0s for pod "pod-service-account-aa957202-29b4-11e9-b6e7-06cba7aec104-vln4q" in namespace "e2e-tests-svcaccounts-9fqfq" to be "success or failure"
Feb  6 02:12:34.453: INFO: Pod "pod-service-account-aa957202-29b4-11e9-b6e7-06cba7aec104-vln4q": Phase="Pending", Reason="", readiness=false. Elapsed: 8.44879ms
Feb  6 02:12:36.740: INFO: Pod "pod-service-account-aa957202-29b4-11e9-b6e7-06cba7aec104-vln4q": Phase="Running", Reason="", readiness=false. Elapsed: 2.294916356s
Feb  6 02:12:38.748: INFO: Pod "pod-service-account-aa957202-29b4-11e9-b6e7-06cba7aec104-vln4q": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.303544498s
STEP: Saw pod success
Feb  6 02:12:38.748: INFO: Pod "pod-service-account-aa957202-29b4-11e9-b6e7-06cba7aec104-vln4q" satisfied condition "success or failure"
Feb  6 02:12:38.757: INFO: Trying to get logs from node 10.190.119.144 pod pod-service-account-aa957202-29b4-11e9-b6e7-06cba7aec104-vln4q container token-test: <nil>
STEP: delete the pod
Feb  6 02:12:38.800: INFO: Waiting for pod pod-service-account-aa957202-29b4-11e9-b6e7-06cba7aec104-vln4q to disappear
Feb  6 02:12:38.897: INFO: Pod pod-service-account-aa957202-29b4-11e9-b6e7-06cba7aec104-vln4q no longer exists
STEP: Creating a pod to test consume service account root CA
Feb  6 02:12:38.909: INFO: Waiting up to 5m0s for pod "pod-service-account-aa957202-29b4-11e9-b6e7-06cba7aec104-j5gdb" in namespace "e2e-tests-svcaccounts-9fqfq" to be "success or failure"
Feb  6 02:12:38.917: INFO: Pod "pod-service-account-aa957202-29b4-11e9-b6e7-06cba7aec104-j5gdb": Phase="Pending", Reason="", readiness=false. Elapsed: 7.788727ms
Feb  6 02:12:40.925: INFO: Pod "pod-service-account-aa957202-29b4-11e9-b6e7-06cba7aec104-j5gdb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015630508s
STEP: Saw pod success
Feb  6 02:12:40.925: INFO: Pod "pod-service-account-aa957202-29b4-11e9-b6e7-06cba7aec104-j5gdb" satisfied condition "success or failure"
Feb  6 02:12:40.933: INFO: Trying to get logs from node 10.190.119.145 pod pod-service-account-aa957202-29b4-11e9-b6e7-06cba7aec104-j5gdb container root-ca-test: <nil>
STEP: delete the pod
Feb  6 02:12:41.024: INFO: Waiting for pod pod-service-account-aa957202-29b4-11e9-b6e7-06cba7aec104-j5gdb to disappear
Feb  6 02:12:41.031: INFO: Pod pod-service-account-aa957202-29b4-11e9-b6e7-06cba7aec104-j5gdb no longer exists
STEP: Creating a pod to test consume service account namespace
Feb  6 02:12:41.043: INFO: Waiting up to 5m0s for pod "pod-service-account-aa957202-29b4-11e9-b6e7-06cba7aec104-4wsbt" in namespace "e2e-tests-svcaccounts-9fqfq" to be "success or failure"
Feb  6 02:12:41.050: INFO: Pod "pod-service-account-aa957202-29b4-11e9-b6e7-06cba7aec104-4wsbt": Phase="Pending", Reason="", readiness=false. Elapsed: 7.014856ms
Feb  6 02:12:43.076: INFO: Pod "pod-service-account-aa957202-29b4-11e9-b6e7-06cba7aec104-4wsbt": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.033265765s
STEP: Saw pod success
Feb  6 02:12:43.076: INFO: Pod "pod-service-account-aa957202-29b4-11e9-b6e7-06cba7aec104-4wsbt" satisfied condition "success or failure"
Feb  6 02:12:43.084: INFO: Trying to get logs from node 10.190.119.175 pod pod-service-account-aa957202-29b4-11e9-b6e7-06cba7aec104-4wsbt container namespace-test: <nil>
STEP: delete the pod
Feb  6 02:12:43.137: INFO: Waiting for pod pod-service-account-aa957202-29b4-11e9-b6e7-06cba7aec104-4wsbt to disappear
Feb  6 02:12:43.144: INFO: Pod pod-service-account-aa957202-29b4-11e9-b6e7-06cba7aec104-4wsbt no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:12:43.144: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-9fqfq" for this suite.
Feb  6 02:12:51.193: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:12:51.341: INFO: namespace: e2e-tests-svcaccounts-9fqfq, resource: bindings, ignored listing per whitelist
Feb  6 02:12:51.622: INFO: namespace e2e-tests-svcaccounts-9fqfq deletion completed in 8.466672803s

• [SLOW TEST:18.070 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:12:51.623: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-czxtn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0206 02:12:53.326812      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb  6 02:12:53.326: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:12:53.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-czxtn" for this suite.
Feb  6 02:12:59.846: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:13:00.136: INFO: namespace: e2e-tests-gc-czxtn, resource: bindings, ignored listing per whitelist
Feb  6 02:13:00.212: INFO: namespace e2e-tests-gc-czxtn deletion completed in 6.876587544s

• [SLOW TEST:8.589 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:13:00.212: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-smtzb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-ba241bbe-29b4-11e9-b6e7-06cba7aec104
STEP: Creating a pod to test consume configMaps
Feb  6 02:13:00.623: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ba2fb8f1-29b4-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-projected-smtzb" to be "success or failure"
Feb  6 02:13:00.633: INFO: Pod "pod-projected-configmaps-ba2fb8f1-29b4-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 9.191255ms
Feb  6 02:13:02.640: INFO: Pod "pod-projected-configmaps-ba2fb8f1-29b4-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016880552s
STEP: Saw pod success
Feb  6 02:13:02.640: INFO: Pod "pod-projected-configmaps-ba2fb8f1-29b4-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 02:13:02.647: INFO: Trying to get logs from node 10.190.119.175 pod pod-projected-configmaps-ba2fb8f1-29b4-11e9-b6e7-06cba7aec104 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  6 02:13:02.720: INFO: Waiting for pod pod-projected-configmaps-ba2fb8f1-29b4-11e9-b6e7-06cba7aec104 to disappear
Feb  6 02:13:02.727: INFO: Pod pod-projected-configmaps-ba2fb8f1-29b4-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:13:02.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-smtzb" for this suite.
Feb  6 02:13:08.783: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:13:08.913: INFO: namespace: e2e-tests-projected-smtzb, resource: bindings, ignored listing per whitelist
Feb  6 02:13:09.108: INFO: namespace e2e-tests-projected-smtzb deletion completed in 6.366792695s

• [SLOW TEST:8.896 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:13:09.109: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-bhwt7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0206 02:13:19.690378      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb  6 02:13:19.690: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:13:19.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-bhwt7" for this suite.
Feb  6 02:13:27.734: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:13:28.065: INFO: namespace: e2e-tests-gc-bhwt7, resource: bindings, ignored listing per whitelist
Feb  6 02:13:28.330: INFO: namespace e2e-tests-gc-bhwt7 deletion completed in 8.630217225s

• [SLOW TEST:19.221 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:13:28.330: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-9hhz8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  6 02:13:28.952: INFO: (0) /api/v1/nodes/10.190.119.144:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 17.261302ms)
Feb  6 02:13:28.965: INFO: (1) /api/v1/nodes/10.190.119.144:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 12.329456ms)
Feb  6 02:13:28.980: INFO: (2) /api/v1/nodes/10.190.119.144:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 15.294476ms)
Feb  6 02:13:28.993: INFO: (3) /api/v1/nodes/10.190.119.144:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 13.177322ms)
Feb  6 02:13:29.007: INFO: (4) /api/v1/nodes/10.190.119.144:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 13.257924ms)
Feb  6 02:13:29.020: INFO: (5) /api/v1/nodes/10.190.119.144:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 13.162605ms)
Feb  6 02:13:29.037: INFO: (6) /api/v1/nodes/10.190.119.144:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 17.025301ms)
Feb  6 02:13:29.050: INFO: (7) /api/v1/nodes/10.190.119.144:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 13.091609ms)
Feb  6 02:13:29.064: INFO: (8) /api/v1/nodes/10.190.119.144:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 13.608222ms)
Feb  6 02:13:29.077: INFO: (9) /api/v1/nodes/10.190.119.144:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 13.207093ms)
Feb  6 02:13:29.091: INFO: (10) /api/v1/nodes/10.190.119.144:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 13.523379ms)
Feb  6 02:13:29.103: INFO: (11) /api/v1/nodes/10.190.119.144:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 12.529862ms)
Feb  6 02:13:29.116: INFO: (12) /api/v1/nodes/10.190.119.144:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 12.801951ms)
Feb  6 02:13:29.128: INFO: (13) /api/v1/nodes/10.190.119.144:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 12.297221ms)
Feb  6 02:13:29.140: INFO: (14) /api/v1/nodes/10.190.119.144:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 11.960384ms)
Feb  6 02:13:29.154: INFO: (15) /api/v1/nodes/10.190.119.144:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 13.230615ms)
Feb  6 02:13:29.167: INFO: (16) /api/v1/nodes/10.190.119.144:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 13.063118ms)
Feb  6 02:13:29.180: INFO: (17) /api/v1/nodes/10.190.119.144:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 12.99689ms)
Feb  6 02:13:29.193: INFO: (18) /api/v1/nodes/10.190.119.144:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 13.272371ms)
Feb  6 02:13:29.206: INFO: (19) /api/v1/nodes/10.190.119.144:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 12.534131ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:13:29.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-9hhz8" for this suite.
Feb  6 02:13:35.258: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:13:35.433: INFO: namespace: e2e-tests-proxy-9hhz8, resource: bindings, ignored listing per whitelist
Feb  6 02:13:35.596: INFO: namespace e2e-tests-proxy-9hhz8 deletion completed in 6.379739499s

• [SLOW TEST:7.266 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:13:35.596: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-22658
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:13:36.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-22658" for this suite.
Feb  6 02:13:42.218: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:13:42.660: INFO: namespace: e2e-tests-kubelet-test-22658, resource: bindings, ignored listing per whitelist
Feb  6 02:13:42.677: INFO: namespace e2e-tests-kubelet-test-22658 deletion completed in 6.511558238s

• [SLOW TEST:7.081 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:13:42.679: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-csnxm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-k9nd
STEP: Creating a pod to test atomic-volume-subpath
Feb  6 02:13:43.062: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-k9nd" in namespace "e2e-tests-subpath-csnxm" to be "success or failure"
Feb  6 02:13:43.077: INFO: Pod "pod-subpath-test-projected-k9nd": Phase="Pending", Reason="", readiness=false. Elapsed: 15.119473ms
Feb  6 02:13:45.089: INFO: Pod "pod-subpath-test-projected-k9nd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027141061s
Feb  6 02:13:47.096: INFO: Pod "pod-subpath-test-projected-k9nd": Phase="Running", Reason="", readiness=false. Elapsed: 4.034895245s
Feb  6 02:13:49.104: INFO: Pod "pod-subpath-test-projected-k9nd": Phase="Running", Reason="", readiness=false. Elapsed: 6.042354091s
Feb  6 02:13:51.113: INFO: Pod "pod-subpath-test-projected-k9nd": Phase="Running", Reason="", readiness=false. Elapsed: 8.051828325s
Feb  6 02:13:53.585: INFO: Pod "pod-subpath-test-projected-k9nd": Phase="Running", Reason="", readiness=false. Elapsed: 10.52381461s
Feb  6 02:13:55.594: INFO: Pod "pod-subpath-test-projected-k9nd": Phase="Running", Reason="", readiness=false. Elapsed: 12.532012329s
Feb  6 02:13:57.601: INFO: Pod "pod-subpath-test-projected-k9nd": Phase="Running", Reason="", readiness=false. Elapsed: 14.539621837s
Feb  6 02:13:59.609: INFO: Pod "pod-subpath-test-projected-k9nd": Phase="Running", Reason="", readiness=false. Elapsed: 16.547606687s
Feb  6 02:14:01.619: INFO: Pod "pod-subpath-test-projected-k9nd": Phase="Running", Reason="", readiness=false. Elapsed: 18.557351029s
Feb  6 02:14:03.642: INFO: Pod "pod-subpath-test-projected-k9nd": Phase="Running", Reason="", readiness=false. Elapsed: 20.580012795s
Feb  6 02:14:05.705: INFO: Pod "pod-subpath-test-projected-k9nd": Phase="Running", Reason="", readiness=false. Elapsed: 22.643578524s
Feb  6 02:14:07.752: INFO: Pod "pod-subpath-test-projected-k9nd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.690472885s
STEP: Saw pod success
Feb  6 02:14:07.752: INFO: Pod "pod-subpath-test-projected-k9nd" satisfied condition "success or failure"
Feb  6 02:14:07.761: INFO: Trying to get logs from node 10.190.119.145 pod pod-subpath-test-projected-k9nd container test-container-subpath-projected-k9nd: <nil>
STEP: delete the pod
Feb  6 02:14:07.825: INFO: Waiting for pod pod-subpath-test-projected-k9nd to disappear
Feb  6 02:14:07.833: INFO: Pod pod-subpath-test-projected-k9nd no longer exists
STEP: Deleting pod pod-subpath-test-projected-k9nd
Feb  6 02:14:07.834: INFO: Deleting pod "pod-subpath-test-projected-k9nd" in namespace "e2e-tests-subpath-csnxm"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:14:07.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-csnxm" for this suite.
Feb  6 02:14:13.912: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:14:14.017: INFO: namespace: e2e-tests-subpath-csnxm, resource: bindings, ignored listing per whitelist
Feb  6 02:14:14.283: INFO: namespace e2e-tests-subpath-csnxm deletion completed in 6.428337442s

• [SLOW TEST:31.604 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:14:14.283: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-7zfcx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  6 02:14:14.629: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:14:17.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-7zfcx" for this suite.
Feb  6 02:14:57.618: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:14:58.262: INFO: namespace: e2e-tests-pods-7zfcx, resource: bindings, ignored listing per whitelist
Feb  6 02:14:58.647: INFO: namespace e2e-tests-pods-7zfcx deletion completed in 41.076633834s

• [SLOW TEST:44.364 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:14:58.647: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-events-cnsb7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Feb  6 02:15:01.372: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-00f014db-29b5-11e9-b6e7-06cba7aec104,GenerateName:,Namespace:e2e-tests-events-cnsb7,SelfLink:/api/v1/namespaces/e2e-tests-events-cnsb7/pods/send-events-00f014db-29b5-11e9-b6e7-06cba7aec104,UID:00f12681-29b5-11e9-9423-66f50c9be06e,ResourceVersion:56055,Generation:0,CreationTimestamp:2019-02-06 02:14:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 306422293,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-88w7l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-88w7l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-88w7l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0015fc710} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0015fc730}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:14:59 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:15:00 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:15:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:14:59 +0000 UTC  }],Message:,Reason:,HostIP:10.190.119.145,PodIP:172.30.70.208,StartTime:2019-02-06 02:14:59 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-02-06 02:15:00 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 containerd://002ab589d9fae439abd43698e926ed7630f6571a656a504788a5f583bc391696}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Feb  6 02:15:03.381: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Feb  6 02:15:05.389: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:15:05.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-cnsb7" for this suite.
Feb  6 02:15:51.501: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:15:51.740: INFO: namespace: e2e-tests-events-cnsb7, resource: bindings, ignored listing per whitelist
Feb  6 02:15:51.882: INFO: namespace e2e-tests-events-cnsb7 deletion completed in 46.467850905s

• [SLOW TEST:53.235 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:15:51.883: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-9kllp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  6 02:15:52.242: INFO: Pod name rollover-pod: Found 0 pods out of 1
Feb  6 02:15:57.251: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb  6 02:15:57.251: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Feb  6 02:15:59.278: INFO: Creating deployment "test-rollover-deployment"
Feb  6 02:15:59.299: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Feb  6 02:16:01.319: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Feb  6 02:16:01.339: INFO: Ensure that both replica sets have 1 created replica
Feb  6 02:16:01.356: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Feb  6 02:16:01.381: INFO: Updating deployment test-rollover-deployment
Feb  6 02:16:01.381: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Feb  6 02:16:03.401: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Feb  6 02:16:03.422: INFO: Make sure deployment "test-rollover-deployment" is complete
Feb  6 02:16:03.444: INFO: all replica sets need to contain the pod-template-hash label
Feb  6 02:16:03.444: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685016159, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685016159, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685016161, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685016159, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  6 02:16:05.471: INFO: all replica sets need to contain the pod-template-hash label
Feb  6 02:16:05.471: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685016159, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685016159, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685016164, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685016159, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  6 02:16:07.464: INFO: all replica sets need to contain the pod-template-hash label
Feb  6 02:16:07.465: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685016159, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685016159, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685016164, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685016159, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  6 02:16:09.484: INFO: all replica sets need to contain the pod-template-hash label
Feb  6 02:16:09.484: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685016159, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685016159, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685016164, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685016159, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  6 02:16:11.464: INFO: all replica sets need to contain the pod-template-hash label
Feb  6 02:16:11.464: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685016159, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685016159, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685016164, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685016159, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  6 02:16:13.465: INFO: all replica sets need to contain the pod-template-hash label
Feb  6 02:16:13.465: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685016159, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685016159, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685016164, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685016159, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  6 02:16:15.466: INFO: 
Feb  6 02:16:15.466: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb  6 02:16:15.496: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-9kllp,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-9kllp/deployments/test-rollover-deployment,UID:24af0425-29b5-11e9-9423-66f50c9be06e,ResourceVersion:56282,Generation:2,CreationTimestamp:2019-02-06 02:15:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-02-06 02:15:59 +0000 UTC 2019-02-06 02:15:59 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-02-06 02:16:14 +0000 UTC 2019-02-06 02:15:59 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-6b7f9d6597" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Feb  6 02:16:15.506: INFO: New ReplicaSet "test-rollover-deployment-6b7f9d6597" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597,GenerateName:,Namespace:e2e-tests-deployment-9kllp,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-9kllp/replicasets/test-rollover-deployment-6b7f9d6597,UID:25ef91a0-29b5-11e9-a9bb-366cc78d8813,ResourceVersion:56272,Generation:2,CreationTimestamp:2019-02-06 02:16:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 24af0425-29b5-11e9-9423-66f50c9be06e 0xc0025e6fa7 0xc0025e6fa8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb  6 02:16:15.506: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Feb  6 02:16:15.506: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-9kllp,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-9kllp/replicasets/test-rollover-controller,UID:207a4b1e-29b5-11e9-9423-66f50c9be06e,ResourceVersion:56281,Generation:2,CreationTimestamp:2019-02-06 02:15:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 24af0425-29b5-11e9-9423-66f50c9be06e 0xc0025e6ac7 0xc0025e6ac8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb  6 02:16:15.506: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6586df867b,GenerateName:,Namespace:e2e-tests-deployment-9kllp,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-9kllp/replicasets/test-rollover-deployment-6586df867b,UID:24b57c2f-29b5-11e9-a9bb-366cc78d8813,ResourceVersion:56233,Generation:2,CreationTimestamp:2019-02-06 02:15:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 24af0425-29b5-11e9-9423-66f50c9be06e 0xc0025e6e97 0xc0025e6e98}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb  6 02:16:15.516: INFO: Pod "test-rollover-deployment-6b7f9d6597-gbbmw" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597-gbbmw,GenerateName:test-rollover-deployment-6b7f9d6597-,Namespace:e2e-tests-deployment-9kllp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-9kllp/pods/test-rollover-deployment-6b7f9d6597-gbbmw,UID:25fa2fd6-29b5-11e9-a9bb-366cc78d8813,ResourceVersion:56254,Generation:0,CreationTimestamp:2019-02-06 02:16:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-6b7f9d6597 25ef91a0-29b5-11e9-a9bb-366cc78d8813 0xc00130ea57 0xc00130ea58}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9bqzp {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9bqzp,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-9bqzp true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00130ead0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00130eaf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:16:01 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:16:04 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:16:04 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:16:01 +0000 UTC  }],Message:,Reason:,HostIP:10.190.119.145,PodIP:172.30.70.215,StartTime:2019-02-06 02:16:01 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-02-06 02:16:03 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://950ca889164009209fb3f09a40b15c5ebfeea18e1d602fb525279d219bb9159f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:16:15.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-9kllp" for this suite.
Feb  6 02:16:23.569: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:16:23.847: INFO: namespace: e2e-tests-deployment-9kllp, resource: bindings, ignored listing per whitelist
Feb  6 02:16:24.174: INFO: namespace e2e-tests-deployment-9kllp deletion completed in 8.646991956s

• [SLOW TEST:32.292 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:16:24.175: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-x2dhr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb  6 02:16:24.527: INFO: Waiting up to 5m0s for pod "downward-api-33b8c938-29b5-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-downward-api-x2dhr" to be "success or failure"
Feb  6 02:16:24.533: INFO: Pod "downward-api-33b8c938-29b5-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 6.537242ms
Feb  6 02:16:26.541: INFO: Pod "downward-api-33b8c938-29b5-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014284736s
STEP: Saw pod success
Feb  6 02:16:26.541: INFO: Pod "downward-api-33b8c938-29b5-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 02:16:26.549: INFO: Trying to get logs from node 10.190.119.175 pod downward-api-33b8c938-29b5-11e9-b6e7-06cba7aec104 container dapi-container: <nil>
STEP: delete the pod
Feb  6 02:16:26.597: INFO: Waiting for pod downward-api-33b8c938-29b5-11e9-b6e7-06cba7aec104 to disappear
Feb  6 02:16:26.606: INFO: Pod downward-api-33b8c938-29b5-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:16:26.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-x2dhr" for this suite.
Feb  6 02:16:34.655: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:16:34.735: INFO: namespace: e2e-tests-downward-api-x2dhr, resource: bindings, ignored listing per whitelist
Feb  6 02:16:34.986: INFO: namespace e2e-tests-downward-api-x2dhr deletion completed in 8.367890134s

• [SLOW TEST:10.811 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:16:34.989: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-rhwc9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-3a376efa-29b5-11e9-b6e7-06cba7aec104
STEP: Creating a pod to test consume secrets
Feb  6 02:16:35.432: INFO: Waiting up to 5m0s for pod "pod-secrets-3a38ffd2-29b5-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-secrets-rhwc9" to be "success or failure"
Feb  6 02:16:35.443: INFO: Pod "pod-secrets-3a38ffd2-29b5-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 11.225454ms
Feb  6 02:16:37.453: INFO: Pod "pod-secrets-3a38ffd2-29b5-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021336265s
STEP: Saw pod success
Feb  6 02:16:37.453: INFO: Pod "pod-secrets-3a38ffd2-29b5-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 02:16:37.460: INFO: Trying to get logs from node 10.190.119.144 pod pod-secrets-3a38ffd2-29b5-11e9-b6e7-06cba7aec104 container secret-volume-test: <nil>
STEP: delete the pod
Feb  6 02:16:37.512: INFO: Waiting for pod pod-secrets-3a38ffd2-29b5-11e9-b6e7-06cba7aec104 to disappear
Feb  6 02:16:37.520: INFO: Pod pod-secrets-3a38ffd2-29b5-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:16:37.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-rhwc9" for this suite.
Feb  6 02:16:45.749: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:16:46.063: INFO: namespace: e2e-tests-secrets-rhwc9, resource: bindings, ignored listing per whitelist
Feb  6 02:16:46.175: INFO: namespace e2e-tests-secrets-rhwc9 deletion completed in 8.645581272s

• [SLOW TEST:11.186 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:16:46.177: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-kxzb8
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-40dc36fb-29b5-11e9-b6e7-06cba7aec104
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-40dc36fb-29b5-11e9-b6e7-06cba7aec104
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:18:21.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-kxzb8" for this suite.
Feb  6 02:18:45.523: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:18:45.730: INFO: namespace: e2e-tests-projected-kxzb8, resource: bindings, ignored listing per whitelist
Feb  6 02:18:45.914: INFO: namespace e2e-tests-projected-kxzb8 deletion completed in 24.46570141s

• [SLOW TEST:119.737 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:18:45.915: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-tb8jr
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-883c7d9e-29b5-11e9-b6e7-06cba7aec104
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:18:48.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-tb8jr" for this suite.
Feb  6 02:19:13.446: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:19:14.171: INFO: namespace: e2e-tests-configmap-tb8jr, resource: bindings, ignored listing per whitelist
Feb  6 02:19:14.239: INFO: namespace e2e-tests-configmap-tb8jr deletion completed in 25.324761856s

• [SLOW TEST:28.325 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:19:14.239: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-mbkft
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0206 02:19:45.217759      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb  6 02:19:45.217: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:19:45.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-mbkft" for this suite.
Feb  6 02:19:51.344: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:19:51.617: INFO: namespace: e2e-tests-gc-mbkft, resource: bindings, ignored listing per whitelist
Feb  6 02:19:51.774: INFO: namespace e2e-tests-gc-mbkft deletion completed in 6.466839579s

• [SLOW TEST:37.534 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:19:51.775: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-wqnmc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  6 02:19:52.226: INFO: (0) /api/v1/nodes/10.190.119.144/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 18.819405ms)
Feb  6 02:19:52.239: INFO: (1) /api/v1/nodes/10.190.119.144/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 13.549078ms)
Feb  6 02:19:52.253: INFO: (2) /api/v1/nodes/10.190.119.144/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 13.831782ms)
Feb  6 02:19:52.267: INFO: (3) /api/v1/nodes/10.190.119.144/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 13.716311ms)
Feb  6 02:19:52.284: INFO: (4) /api/v1/nodes/10.190.119.144/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 17.336884ms)
Feb  6 02:19:52.298: INFO: (5) /api/v1/nodes/10.190.119.144/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 13.781736ms)
Feb  6 02:19:52.312: INFO: (6) /api/v1/nodes/10.190.119.144/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 13.512101ms)
Feb  6 02:19:52.324: INFO: (7) /api/v1/nodes/10.190.119.144/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 12.47068ms)
Feb  6 02:19:52.339: INFO: (8) /api/v1/nodes/10.190.119.144/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 14.351382ms)
Feb  6 02:19:52.352: INFO: (9) /api/v1/nodes/10.190.119.144/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 12.953976ms)
Feb  6 02:19:52.369: INFO: (10) /api/v1/nodes/10.190.119.144/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 17.376563ms)
Feb  6 02:19:52.382: INFO: (11) /api/v1/nodes/10.190.119.144/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 12.435831ms)
Feb  6 02:19:52.394: INFO: (12) /api/v1/nodes/10.190.119.144/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 12.498859ms)
Feb  6 02:19:52.407: INFO: (13) /api/v1/nodes/10.190.119.144/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 12.296881ms)
Feb  6 02:19:52.420: INFO: (14) /api/v1/nodes/10.190.119.144/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 13.08534ms)
Feb  6 02:19:52.433: INFO: (15) /api/v1/nodes/10.190.119.144/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 13.292435ms)
Feb  6 02:19:52.448: INFO: (16) /api/v1/nodes/10.190.119.144/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 14.07143ms)
Feb  6 02:19:52.461: INFO: (17) /api/v1/nodes/10.190.119.144/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 13.649263ms)
Feb  6 02:19:52.480: INFO: (18) /api/v1/nodes/10.190.119.144/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 19.06439ms)
Feb  6 02:19:52.494: INFO: (19) /api/v1/nodes/10.190.119.144/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 13.108778ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:19:52.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-wqnmc" for this suite.
Feb  6 02:19:58.540: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:19:58.634: INFO: namespace: e2e-tests-proxy-wqnmc, resource: bindings, ignored listing per whitelist
Feb  6 02:19:58.853: INFO: namespace e2e-tests-proxy-wqnmc deletion completed in 6.348923983s

• [SLOW TEST:7.079 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:19:58.854: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-2vfnl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Feb  6 02:19:59.159: INFO: namespace e2e-tests-kubectl-2vfnl
Feb  6 02:19:59.160: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 create -f - --namespace=e2e-tests-kubectl-2vfnl'
Feb  6 02:19:59.510: INFO: stderr: ""
Feb  6 02:19:59.510: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb  6 02:20:00.520: INFO: Selector matched 1 pods for map[app:redis]
Feb  6 02:20:00.520: INFO: Found 0 / 1
Feb  6 02:20:01.518: INFO: Selector matched 1 pods for map[app:redis]
Feb  6 02:20:01.518: INFO: Found 1 / 1
Feb  6 02:20:01.518: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb  6 02:20:01.526: INFO: Selector matched 1 pods for map[app:redis]
Feb  6 02:20:01.526: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb  6 02:20:01.526: INFO: wait on redis-master startup in e2e-tests-kubectl-2vfnl 
Feb  6 02:20:01.526: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 logs redis-master-v82c4 redis-master --namespace=e2e-tests-kubectl-2vfnl'
Feb  6 02:20:01.684: INFO: stderr: ""
Feb  6 02:20:01.684: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 06 Feb 02:20:00.581 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 06 Feb 02:20:00.582 # Server started, Redis version 3.2.12\n1:M 06 Feb 02:20:00.582 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 06 Feb 02:20:00.582 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Feb  6 02:20:01.684: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-2vfnl'
Feb  6 02:20:02.249: INFO: stderr: ""
Feb  6 02:20:02.249: INFO: stdout: "service/rm2 exposed\n"
Feb  6 02:20:02.297: INFO: Service rm2 in namespace e2e-tests-kubectl-2vfnl found.
STEP: exposing service
Feb  6 02:20:04.316: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-2vfnl'
Feb  6 02:20:04.454: INFO: stderr: ""
Feb  6 02:20:04.454: INFO: stdout: "service/rm3 exposed\n"
Feb  6 02:20:04.461: INFO: Service rm3 in namespace e2e-tests-kubectl-2vfnl found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:20:06.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2vfnl" for this suite.
Feb  6 02:20:30.527: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:20:30.760: INFO: namespace: e2e-tests-kubectl-2vfnl, resource: bindings, ignored listing per whitelist
Feb  6 02:20:31.081: INFO: namespace e2e-tests-kubectl-2vfnl deletion completed in 24.589252415s

• [SLOW TEST:32.227 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:20:31.082: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-vcjh7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-c6e98576-29b5-11e9-b6e7-06cba7aec104
STEP: Creating a pod to test consume configMaps
Feb  6 02:20:31.531: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c6f20749-29b5-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-projected-vcjh7" to be "success or failure"
Feb  6 02:20:31.539: INFO: Pod "pod-projected-configmaps-c6f20749-29b5-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 8.261356ms
Feb  6 02:20:33.547: INFO: Pod "pod-projected-configmaps-c6f20749-29b5-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015575208s
Feb  6 02:20:35.611: INFO: Pod "pod-projected-configmaps-c6f20749-29b5-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.079840272s
STEP: Saw pod success
Feb  6 02:20:35.611: INFO: Pod "pod-projected-configmaps-c6f20749-29b5-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 02:20:35.621: INFO: Trying to get logs from node 10.190.119.144 pod pod-projected-configmaps-c6f20749-29b5-11e9-b6e7-06cba7aec104 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  6 02:20:35.668: INFO: Waiting for pod pod-projected-configmaps-c6f20749-29b5-11e9-b6e7-06cba7aec104 to disappear
Feb  6 02:20:35.676: INFO: Pod pod-projected-configmaps-c6f20749-29b5-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:20:35.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vcjh7" for this suite.
Feb  6 02:20:41.759: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:20:42.079: INFO: namespace: e2e-tests-projected-vcjh7, resource: bindings, ignored listing per whitelist
Feb  6 02:20:42.223: INFO: namespace e2e-tests-projected-vcjh7 deletion completed in 6.524400096s

• [SLOW TEST:11.142 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:20:42.224: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-gfgv9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0206 02:20:52.735096      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb  6 02:20:52.735: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:20:52.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-gfgv9" for this suite.
Feb  6 02:20:58.838: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:20:59.363: INFO: namespace: e2e-tests-gc-gfgv9, resource: bindings, ignored listing per whitelist
Feb  6 02:20:59.377: INFO: namespace e2e-tests-gc-gfgv9 deletion completed in 6.579603701s

• [SLOW TEST:17.153 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:20:59.378: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-qd9xz
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-d7cea3c8-29b5-11e9-b6e7-06cba7aec104
STEP: Creating a pod to test consume secrets
Feb  6 02:20:59.828: INFO: Waiting up to 5m0s for pod "pod-secrets-d7d0ddca-29b5-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-secrets-qd9xz" to be "success or failure"
Feb  6 02:20:59.835: INFO: Pod "pod-secrets-d7d0ddca-29b5-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 6.819355ms
Feb  6 02:21:01.844: INFO: Pod "pod-secrets-d7d0ddca-29b5-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016349159s
STEP: Saw pod success
Feb  6 02:21:01.844: INFO: Pod "pod-secrets-d7d0ddca-29b5-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 02:21:01.851: INFO: Trying to get logs from node 10.190.119.144 pod pod-secrets-d7d0ddca-29b5-11e9-b6e7-06cba7aec104 container secret-volume-test: <nil>
STEP: delete the pod
Feb  6 02:21:01.892: INFO: Waiting for pod pod-secrets-d7d0ddca-29b5-11e9-b6e7-06cba7aec104 to disappear
Feb  6 02:21:01.905: INFO: Pod pod-secrets-d7d0ddca-29b5-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:21:01.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-qd9xz" for this suite.
Feb  6 02:21:07.956: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:21:08.583: INFO: namespace: e2e-tests-secrets-qd9xz, resource: bindings, ignored listing per whitelist
Feb  6 02:21:08.732: INFO: namespace e2e-tests-secrets-qd9xz deletion completed in 6.813447623s

• [SLOW TEST:9.354 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:21:08.732: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-gnvfk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb  6 02:21:09.038: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-gnvfk'
Feb  6 02:21:09.205: INFO: stderr: ""
Feb  6 02:21:09.205: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Feb  6 02:21:14.255: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-gnvfk -o json'
Feb  6 02:21:14.388: INFO: stderr: ""
Feb  6 02:21:14.388: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"kubernetes.io/psp\": \"e2e-test-privileged-psp\"\n        },\n        \"creationTimestamp\": \"2019-02-06T02:21:09Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-gnvfk\",\n        \"resourceVersion\": \"57311\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-gnvfk/pods/e2e-test-nginx-pod\",\n        \"uid\": \"dd62a207-29b5-11e9-9423-66f50c9be06e\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-jkpzv\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"10.190.119.145\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-jkpzv\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-jkpzv\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-06T02:21:09Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-06T02:21:10Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-06T02:21:10Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-06T02:21:09Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://345b374387caa9632769500135df722a383c59b451c6d7615082141f501635b4\",\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imageID\": \"docker.io/library/nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-02-06T02:21:10Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.190.119.145\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.30.70.219\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-02-06T02:21:09Z\"\n    }\n}\n"
STEP: replace the image in the pod
Feb  6 02:21:14.389: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 replace -f - --namespace=e2e-tests-kubectl-gnvfk'
Feb  6 02:21:14.606: INFO: stderr: ""
Feb  6 02:21:14.606: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1568
Feb  6 02:21:14.697: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-gnvfk'
Feb  6 02:21:17.508: INFO: stderr: ""
Feb  6 02:21:17.508: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:21:17.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-gnvfk" for this suite.
Feb  6 02:21:24.121: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:21:24.240: INFO: namespace: e2e-tests-kubectl-gnvfk, resource: bindings, ignored listing per whitelist
Feb  6 02:21:24.615: INFO: namespace e2e-tests-kubectl-gnvfk deletion completed in 7.01750336s

• [SLOW TEST:15.884 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:21:24.617: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-z74qr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:21:27.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-z74qr" for this suite.
Feb  6 02:22:13.511: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:22:14.249: INFO: namespace: e2e-tests-kubelet-test-z74qr, resource: bindings, ignored listing per whitelist
Feb  6 02:22:14.275: INFO: namespace e2e-tests-kubelet-test-z74qr deletion completed in 46.80439423s

• [SLOW TEST:49.658 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:22:14.279: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-hmvcm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb  6 02:22:14.624: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-hmvcm'
Feb  6 02:22:14.757: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb  6 02:22:14.757: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1268
Feb  6 02:22:16.773: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-hmvcm'
Feb  6 02:22:16.907: INFO: stderr: ""
Feb  6 02:22:16.907: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:22:16.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hmvcm" for this suite.
Feb  6 02:22:23.277: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:22:23.572: INFO: namespace: e2e-tests-kubectl-hmvcm, resource: bindings, ignored listing per whitelist
Feb  6 02:22:23.603: INFO: namespace e2e-tests-kubectl-hmvcm deletion completed in 6.68335988s

• [SLOW TEST:9.324 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:22:23.604: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-gxc69
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  6 02:22:23.939: INFO: Waiting up to 5m0s for pod "downwardapi-volume-09f30a48-29b6-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-downward-api-gxc69" to be "success or failure"
Feb  6 02:22:23.951: INFO: Pod "downwardapi-volume-09f30a48-29b6-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 11.944487ms
Feb  6 02:22:25.959: INFO: Pod "downwardapi-volume-09f30a48-29b6-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01950968s
STEP: Saw pod success
Feb  6 02:22:25.959: INFO: Pod "downwardapi-volume-09f30a48-29b6-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 02:22:25.966: INFO: Trying to get logs from node 10.190.119.145 pod downwardapi-volume-09f30a48-29b6-11e9-b6e7-06cba7aec104 container client-container: <nil>
STEP: delete the pod
Feb  6 02:22:26.021: INFO: Waiting for pod downwardapi-volume-09f30a48-29b6-11e9-b6e7-06cba7aec104 to disappear
Feb  6 02:22:26.033: INFO: Pod downwardapi-volume-09f30a48-29b6-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:22:26.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-gxc69" for this suite.
Feb  6 02:22:32.084: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:22:32.268: INFO: namespace: e2e-tests-downward-api-gxc69, resource: bindings, ignored listing per whitelist
Feb  6 02:22:32.410: INFO: namespace e2e-tests-downward-api-gxc69 deletion completed in 6.367227008s

• [SLOW TEST:8.806 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:22:32.411: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-thmsm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-0f354402-29b6-11e9-b6e7-06cba7aec104
STEP: Creating a pod to test consume secrets
Feb  6 02:22:32.781: INFO: Waiting up to 5m0s for pod "pod-secrets-0f382cb7-29b6-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-secrets-thmsm" to be "success or failure"
Feb  6 02:22:32.790: INFO: Pod "pod-secrets-0f382cb7-29b6-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 8.319506ms
Feb  6 02:22:34.817: INFO: Pod "pod-secrets-0f382cb7-29b6-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.034596513s
STEP: Saw pod success
Feb  6 02:22:34.817: INFO: Pod "pod-secrets-0f382cb7-29b6-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 02:22:34.824: INFO: Trying to get logs from node 10.190.119.175 pod pod-secrets-0f382cb7-29b6-11e9-b6e7-06cba7aec104 container secret-env-test: <nil>
STEP: delete the pod
Feb  6 02:22:34.897: INFO: Waiting for pod pod-secrets-0f382cb7-29b6-11e9-b6e7-06cba7aec104 to disappear
Feb  6 02:22:34.904: INFO: Pod pod-secrets-0f382cb7-29b6-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:22:34.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-thmsm" for this suite.
Feb  6 02:22:40.955: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:22:41.263: INFO: namespace: e2e-tests-secrets-thmsm, resource: bindings, ignored listing per whitelist
Feb  6 02:22:41.324: INFO: namespace e2e-tests-secrets-thmsm deletion completed in 6.409303281s

• [SLOW TEST:8.913 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:22:41.324: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-ntdkt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1358
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb  6 02:22:41.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-ntdkt'
Feb  6 02:22:41.847: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb  6 02:22:41.847: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Feb  6 02:22:41.859: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Feb  6 02:22:41.901: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Feb  6 02:22:41.919: INFO: scanned /root for discovery docs: <nil>
Feb  6 02:22:41.919: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-ntdkt'
Feb  6 02:22:56.063: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb  6 02:22:56.063: INFO: stdout: "Created e2e-test-nginx-rc-b065faf56f372069aaeb07ec500cc8f1\nScaling up e2e-test-nginx-rc-b065faf56f372069aaeb07ec500cc8f1 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-b065faf56f372069aaeb07ec500cc8f1 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-b065faf56f372069aaeb07ec500cc8f1 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Feb  6 02:22:56.063: INFO: stdout: "Created e2e-test-nginx-rc-b065faf56f372069aaeb07ec500cc8f1\nScaling up e2e-test-nginx-rc-b065faf56f372069aaeb07ec500cc8f1 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-b065faf56f372069aaeb07ec500cc8f1 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-b065faf56f372069aaeb07ec500cc8f1 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Feb  6 02:22:56.063: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-ntdkt'
Feb  6 02:22:56.201: INFO: stderr: ""
Feb  6 02:22:56.201: INFO: stdout: "e2e-test-nginx-rc-b065faf56f372069aaeb07ec500cc8f1-d2dkm "
Feb  6 02:22:56.201: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 get pods e2e-test-nginx-rc-b065faf56f372069aaeb07ec500cc8f1-d2dkm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ntdkt'
Feb  6 02:22:56.360: INFO: stderr: ""
Feb  6 02:22:56.360: INFO: stdout: "true"
Feb  6 02:22:56.362: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 get pods e2e-test-nginx-rc-b065faf56f372069aaeb07ec500cc8f1-d2dkm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ntdkt'
Feb  6 02:22:56.482: INFO: stderr: ""
Feb  6 02:22:56.483: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Feb  6 02:22:56.483: INFO: e2e-test-nginx-rc-b065faf56f372069aaeb07ec500cc8f1-d2dkm is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1364
Feb  6 02:22:56.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-ntdkt'
Feb  6 02:22:56.605: INFO: stderr: ""
Feb  6 02:22:56.605: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:22:56.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ntdkt" for this suite.
Feb  6 02:23:02.654: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:23:02.791: INFO: namespace: e2e-tests-kubectl-ntdkt, resource: bindings, ignored listing per whitelist
Feb  6 02:23:03.043: INFO: namespace e2e-tests-kubectl-ntdkt deletion completed in 6.425979289s

• [SLOW TEST:21.720 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:23:03.045: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-dwmvm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-cb8b
STEP: Creating a pod to test atomic-volume-subpath
Feb  6 02:23:03.439: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-cb8b" in namespace "e2e-tests-subpath-dwmvm" to be "success or failure"
Feb  6 02:23:03.449: INFO: Pod "pod-subpath-test-configmap-cb8b": Phase="Pending", Reason="", readiness=false. Elapsed: 9.582039ms
Feb  6 02:23:05.457: INFO: Pod "pod-subpath-test-configmap-cb8b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017485598s
Feb  6 02:23:07.488: INFO: Pod "pod-subpath-test-configmap-cb8b": Phase="Running", Reason="", readiness=false. Elapsed: 4.048717111s
Feb  6 02:23:09.497: INFO: Pod "pod-subpath-test-configmap-cb8b": Phase="Running", Reason="", readiness=false. Elapsed: 6.057891863s
Feb  6 02:23:11.505: INFO: Pod "pod-subpath-test-configmap-cb8b": Phase="Running", Reason="", readiness=false. Elapsed: 8.06545687s
Feb  6 02:23:13.514: INFO: Pod "pod-subpath-test-configmap-cb8b": Phase="Running", Reason="", readiness=false. Elapsed: 10.075098166s
Feb  6 02:23:15.525: INFO: Pod "pod-subpath-test-configmap-cb8b": Phase="Running", Reason="", readiness=false. Elapsed: 12.085866749s
Feb  6 02:23:17.549: INFO: Pod "pod-subpath-test-configmap-cb8b": Phase="Running", Reason="", readiness=false. Elapsed: 14.109912959s
Feb  6 02:23:19.557: INFO: Pod "pod-subpath-test-configmap-cb8b": Phase="Running", Reason="", readiness=false. Elapsed: 16.11804634s
Feb  6 02:23:21.565: INFO: Pod "pod-subpath-test-configmap-cb8b": Phase="Running", Reason="", readiness=false. Elapsed: 18.126011611s
Feb  6 02:23:23.576: INFO: Pod "pod-subpath-test-configmap-cb8b": Phase="Running", Reason="", readiness=false. Elapsed: 20.136571573s
Feb  6 02:23:25.856: INFO: Pod "pod-subpath-test-configmap-cb8b": Phase="Running", Reason="", readiness=false. Elapsed: 22.417298131s
Feb  6 02:23:27.884: INFO: Pod "pod-subpath-test-configmap-cb8b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.444816857s
STEP: Saw pod success
Feb  6 02:23:27.884: INFO: Pod "pod-subpath-test-configmap-cb8b" satisfied condition "success or failure"
Feb  6 02:23:27.896: INFO: Trying to get logs from node 10.190.119.145 pod pod-subpath-test-configmap-cb8b container test-container-subpath-configmap-cb8b: <nil>
STEP: delete the pod
Feb  6 02:23:27.951: INFO: Waiting for pod pod-subpath-test-configmap-cb8b to disappear
Feb  6 02:23:27.959: INFO: Pod pod-subpath-test-configmap-cb8b no longer exists
STEP: Deleting pod pod-subpath-test-configmap-cb8b
Feb  6 02:23:27.959: INFO: Deleting pod "pod-subpath-test-configmap-cb8b" in namespace "e2e-tests-subpath-dwmvm"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:23:27.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-dwmvm" for this suite.
Feb  6 02:23:34.600: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:23:34.921: INFO: namespace: e2e-tests-subpath-dwmvm, resource: bindings, ignored listing per whitelist
Feb  6 02:23:35.041: INFO: namespace e2e-tests-subpath-dwmvm deletion completed in 7.04256611s

• [SLOW TEST:31.996 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:23:35.041: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-prestop-l64zx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-l64zx
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-l64zx
STEP: Deleting pre-stop pod
Feb  6 02:23:46.537: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:23:46.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-l64zx" for this suite.
Feb  6 02:24:26.658: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:24:26.967: INFO: namespace: e2e-tests-prestop-l64zx, resource: bindings, ignored listing per whitelist
Feb  6 02:24:27.012: INFO: namespace e2e-tests-prestop-l64zx deletion completed in 40.413162472s

• [SLOW TEST:51.971 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:24:27.014: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replication-controller-gzfzp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-5394c8ae-29b6-11e9-b6e7-06cba7aec104
Feb  6 02:24:27.505: INFO: Pod name my-hostname-basic-5394c8ae-29b6-11e9-b6e7-06cba7aec104: Found 0 pods out of 1
Feb  6 02:24:32.514: INFO: Pod name my-hostname-basic-5394c8ae-29b6-11e9-b6e7-06cba7aec104: Found 1 pods out of 1
Feb  6 02:24:32.514: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-5394c8ae-29b6-11e9-b6e7-06cba7aec104" are running
Feb  6 02:24:32.521: INFO: Pod "my-hostname-basic-5394c8ae-29b6-11e9-b6e7-06cba7aec104-gc6b4" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-06 02:24:27 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-06 02:24:29 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-06 02:24:29 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-06 02:24:27 +0000 UTC Reason: Message:}])
Feb  6 02:24:32.521: INFO: Trying to dial the pod
Feb  6 02:24:37.597: INFO: Controller my-hostname-basic-5394c8ae-29b6-11e9-b6e7-06cba7aec104: Got expected result from replica 1 [my-hostname-basic-5394c8ae-29b6-11e9-b6e7-06cba7aec104-gc6b4]: "my-hostname-basic-5394c8ae-29b6-11e9-b6e7-06cba7aec104-gc6b4", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:24:37.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-gzfzp" for this suite.
Feb  6 02:24:43.647: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:24:43.828: INFO: namespace: e2e-tests-replication-controller-gzfzp, resource: bindings, ignored listing per whitelist
Feb  6 02:24:44.320: INFO: namespace e2e-tests-replication-controller-gzfzp deletion completed in 6.710429857s

• [SLOW TEST:17.306 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:24:44.322: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-lhmf6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:25:44.754: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-lhmf6" for this suite.
Feb  6 02:26:08.813: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:26:09.261: INFO: namespace: e2e-tests-container-probe-lhmf6, resource: bindings, ignored listing per whitelist
Feb  6 02:26:09.341: INFO: namespace e2e-tests-container-probe-lhmf6 deletion completed in 24.575232217s

• [SLOW TEST:85.020 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:26:09.342: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-sz2fp
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-90865c10-29b6-11e9-b6e7-06cba7aec104
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-90865c10-29b6-11e9-b6e7-06cba7aec104
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:26:13.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-sz2fp" for this suite.
Feb  6 02:26:37.885: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:26:37.952: INFO: namespace: e2e-tests-configmap-sz2fp, resource: bindings, ignored listing per whitelist
Feb  6 02:26:38.187: INFO: namespace e2e-tests-configmap-sz2fp deletion completed in 24.33782625s

• [SLOW TEST:28.845 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:26:38.187: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-khjhl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1134
STEP: creating an rc
Feb  6 02:26:38.569: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 create -f - --namespace=e2e-tests-kubectl-khjhl'
Feb  6 02:26:38.885: INFO: stderr: ""
Feb  6 02:26:38.885: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Feb  6 02:26:39.894: INFO: Selector matched 1 pods for map[app:redis]
Feb  6 02:26:39.894: INFO: Found 0 / 1
Feb  6 02:26:40.894: INFO: Selector matched 1 pods for map[app:redis]
Feb  6 02:26:40.894: INFO: Found 1 / 1
Feb  6 02:26:40.894: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb  6 02:26:40.904: INFO: Selector matched 1 pods for map[app:redis]
Feb  6 02:26:40.904: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Feb  6 02:26:40.904: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 logs redis-master-tq94k redis-master --namespace=e2e-tests-kubectl-khjhl'
Feb  6 02:26:41.050: INFO: stderr: ""
Feb  6 02:26:41.050: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 06 Feb 02:26:40.455 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 06 Feb 02:26:40.456 # Server started, Redis version 3.2.12\n1:M 06 Feb 02:26:40.456 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 06 Feb 02:26:40.456 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Feb  6 02:26:41.050: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 log redis-master-tq94k redis-master --namespace=e2e-tests-kubectl-khjhl --tail=1'
Feb  6 02:26:41.187: INFO: stderr: ""
Feb  6 02:26:41.187: INFO: stdout: "1:M 06 Feb 02:26:40.456 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Feb  6 02:26:41.188: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 log redis-master-tq94k redis-master --namespace=e2e-tests-kubectl-khjhl --limit-bytes=1'
Feb  6 02:26:41.336: INFO: stderr: ""
Feb  6 02:26:41.336: INFO: stdout: " "
STEP: exposing timestamps
Feb  6 02:26:41.337: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 log redis-master-tq94k redis-master --namespace=e2e-tests-kubectl-khjhl --tail=1 --timestamps'
Feb  6 02:26:41.475: INFO: stderr: ""
Feb  6 02:26:41.475: INFO: stdout: "2019-02-06T02:26:40.456325022Z 1:M 06 Feb 02:26:40.456 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Feb  6 02:26:43.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 log redis-master-tq94k redis-master --namespace=e2e-tests-kubectl-khjhl --since=1s'
Feb  6 02:26:44.130: INFO: stderr: ""
Feb  6 02:26:44.130: INFO: stdout: ""
Feb  6 02:26:44.131: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 log redis-master-tq94k redis-master --namespace=e2e-tests-kubectl-khjhl --since=24h'
Feb  6 02:26:44.278: INFO: stderr: ""
Feb  6 02:26:44.278: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 06 Feb 02:26:40.455 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 06 Feb 02:26:40.456 # Server started, Redis version 3.2.12\n1:M 06 Feb 02:26:40.456 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 06 Feb 02:26:40.456 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1140
STEP: using delete to clean up resources
Feb  6 02:26:44.279: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-khjhl'
Feb  6 02:26:44.408: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  6 02:26:44.408: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Feb  6 02:26:44.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-khjhl'
Feb  6 02:26:44.527: INFO: stderr: "No resources found.\n"
Feb  6 02:26:44.527: INFO: stdout: ""
Feb  6 02:26:44.527: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 get pods -l name=nginx --namespace=e2e-tests-kubectl-khjhl -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb  6 02:26:44.641: INFO: stderr: ""
Feb  6 02:26:44.641: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:26:44.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-khjhl" for this suite.
Feb  6 02:27:08.689: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:27:09.031: INFO: namespace: e2e-tests-kubectl-khjhl, resource: bindings, ignored listing per whitelist
Feb  6 02:27:09.031: INFO: namespace e2e-tests-kubectl-khjhl deletion completed in 24.378110906s

• [SLOW TEST:30.844 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:27:09.032: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-dmjw8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:27:11.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-dmjw8" for this suite.
Feb  6 02:27:53.641: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:27:53.850: INFO: namespace: e2e-tests-kubelet-test-dmjw8, resource: bindings, ignored listing per whitelist
Feb  6 02:27:54.114: INFO: namespace e2e-tests-kubelet-test-dmjw8 deletion completed in 42.590788541s

• [SLOW TEST:45.083 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a read only busybox container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:186
    should not write to root filesystem [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:27:54.117: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-mb8w9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-mb8w9
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb  6 02:27:54.988: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb  6 02:28:17.313: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.70.224:8080/dial?request=hostName&protocol=udp&host=172.30.175.249&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-mb8w9 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 02:28:17.313: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
Feb  6 02:28:17.603: INFO: Waiting for endpoints: map[]
Feb  6 02:28:17.612: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.70.224:8080/dial?request=hostName&protocol=udp&host=172.30.70.222&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-mb8w9 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 02:28:17.612: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
Feb  6 02:28:17.801: INFO: Waiting for endpoints: map[]
Feb  6 02:28:17.809: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.70.224:8080/dial?request=hostName&protocol=udp&host=172.30.176.15&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-mb8w9 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 02:28:17.809: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
Feb  6 02:28:18.071: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:28:18.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-mb8w9" for this suite.
Feb  6 02:28:42.125: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:28:42.369: INFO: namespace: e2e-tests-pod-network-test-mb8w9, resource: bindings, ignored listing per whitelist
Feb  6 02:28:42.491: INFO: namespace e2e-tests-pod-network-test-mb8w9 deletion completed in 24.40872203s

• [SLOW TEST:48.374 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:28:42.492: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-t8ctn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Feb  6 02:28:43.407: INFO: created pod pod-service-account-defaultsa
Feb  6 02:28:43.407: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Feb  6 02:28:43.419: INFO: created pod pod-service-account-mountsa
Feb  6 02:28:43.420: INFO: pod pod-service-account-mountsa service account token volume mount: true
Feb  6 02:28:43.436: INFO: created pod pod-service-account-nomountsa
Feb  6 02:28:43.436: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Feb  6 02:28:43.450: INFO: created pod pod-service-account-defaultsa-mountspec
Feb  6 02:28:43.450: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Feb  6 02:28:43.460: INFO: created pod pod-service-account-mountsa-mountspec
Feb  6 02:28:43.461: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Feb  6 02:28:43.472: INFO: created pod pod-service-account-nomountsa-mountspec
Feb  6 02:28:43.472: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Feb  6 02:28:43.483: INFO: created pod pod-service-account-defaultsa-nomountspec
Feb  6 02:28:43.483: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Feb  6 02:28:43.496: INFO: created pod pod-service-account-mountsa-nomountspec
Feb  6 02:28:43.496: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Feb  6 02:28:43.511: INFO: created pod pod-service-account-nomountsa-nomountspec
Feb  6 02:28:43.511: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:28:43.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-t8ctn" for this suite.
Feb  6 02:28:51.567: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:28:51.742: INFO: namespace: e2e-tests-svcaccounts-t8ctn, resource: bindings, ignored listing per whitelist
Feb  6 02:28:51.893: INFO: namespace e2e-tests-svcaccounts-t8ctn deletion completed in 8.36654273s

• [SLOW TEST:9.401 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:28:51.895: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-6xlz8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Feb  6 02:28:52.741: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 --namespace=e2e-tests-kubectl-6xlz8 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Feb  6 02:28:55.074: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Feb  6 02:28:55.074: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:28:57.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6xlz8" for this suite.
Feb  6 02:29:03.139: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:29:03.337: INFO: namespace: e2e-tests-kubectl-6xlz8, resource: bindings, ignored listing per whitelist
Feb  6 02:29:03.523: INFO: namespace e2e-tests-kubectl-6xlz8 deletion completed in 6.421175061s

• [SLOW TEST:11.628 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:29:03.523: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-j96qs
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-f854bde7-29b6-11e9-b6e7-06cba7aec104
STEP: Creating a pod to test consume secrets
Feb  6 02:29:03.896: INFO: Waiting up to 5m0s for pod "pod-secrets-f857b780-29b6-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-secrets-j96qs" to be "success or failure"
Feb  6 02:29:03.905: INFO: Pod "pod-secrets-f857b780-29b6-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 9.483387ms
Feb  6 02:29:05.914: INFO: Pod "pod-secrets-f857b780-29b6-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018194346s
STEP: Saw pod success
Feb  6 02:29:05.914: INFO: Pod "pod-secrets-f857b780-29b6-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 02:29:05.997: INFO: Trying to get logs from node 10.190.119.145 pod pod-secrets-f857b780-29b6-11e9-b6e7-06cba7aec104 container secret-volume-test: <nil>
STEP: delete the pod
Feb  6 02:29:06.055: INFO: Waiting for pod pod-secrets-f857b780-29b6-11e9-b6e7-06cba7aec104 to disappear
Feb  6 02:29:06.063: INFO: Pod pod-secrets-f857b780-29b6-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:29:06.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-j96qs" for this suite.
Feb  6 02:29:12.131: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:29:12.169: INFO: namespace: e2e-tests-secrets-j96qs, resource: bindings, ignored listing per whitelist
Feb  6 02:29:12.497: INFO: namespace e2e-tests-secrets-j96qs deletion completed in 6.423252442s

• [SLOW TEST:8.974 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:29:12.497: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-9tdkw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb  6 02:29:12.850: INFO: Waiting up to 5m0s for pod "pod-fdade82e-29b6-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-emptydir-9tdkw" to be "success or failure"
Feb  6 02:29:12.860: INFO: Pod "pod-fdade82e-29b6-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 9.935431ms
Feb  6 02:29:14.868: INFO: Pod "pod-fdade82e-29b6-11e9-b6e7-06cba7aec104": Phase="Running", Reason="", readiness=true. Elapsed: 2.017569163s
Feb  6 02:29:16.880: INFO: Pod "pod-fdade82e-29b6-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029979377s
STEP: Saw pod success
Feb  6 02:29:16.880: INFO: Pod "pod-fdade82e-29b6-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 02:29:16.887: INFO: Trying to get logs from node 10.190.119.175 pod pod-fdade82e-29b6-11e9-b6e7-06cba7aec104 container test-container: <nil>
STEP: delete the pod
Feb  6 02:29:16.933: INFO: Waiting for pod pod-fdade82e-29b6-11e9-b6e7-06cba7aec104 to disappear
Feb  6 02:29:16.941: INFO: Pod pod-fdade82e-29b6-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:29:16.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-9tdkw" for this suite.
Feb  6 02:29:23.042: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:29:23.595: INFO: namespace: e2e-tests-emptydir-9tdkw, resource: bindings, ignored listing per whitelist
Feb  6 02:29:23.757: INFO: namespace e2e-tests-emptydir-9tdkw deletion completed in 6.805444808s

• [SLOW TEST:11.260 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:29:23.758: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-vt4fk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb  6 02:29:28.833: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb  6 02:29:28.897: INFO: Pod pod-with-prestop-http-hook still exists
Feb  6 02:29:30.897: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb  6 02:29:30.906: INFO: Pod pod-with-prestop-http-hook still exists
Feb  6 02:29:32.897: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb  6 02:29:33.094: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:29:33.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-vt4fk" for this suite.
Feb  6 02:29:57.236: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:29:57.343: INFO: namespace: e2e-tests-container-lifecycle-hook-vt4fk, resource: bindings, ignored listing per whitelist
Feb  6 02:29:57.732: INFO: namespace e2e-tests-container-lifecycle-hook-vt4fk deletion completed in 24.572848283s

• [SLOW TEST:33.974 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:29:57.734: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-r77zl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-snb2
STEP: Creating a pod to test atomic-volume-subpath
Feb  6 02:29:58.112: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-snb2" in namespace "e2e-tests-subpath-r77zl" to be "success or failure"
Feb  6 02:29:58.124: INFO: Pod "pod-subpath-test-downwardapi-snb2": Phase="Pending", Reason="", readiness=false. Elapsed: 10.844577ms
Feb  6 02:30:00.133: INFO: Pod "pod-subpath-test-downwardapi-snb2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020117941s
Feb  6 02:30:02.142: INFO: Pod "pod-subpath-test-downwardapi-snb2": Phase="Running", Reason="", readiness=false. Elapsed: 4.028679048s
Feb  6 02:30:04.150: INFO: Pod "pod-subpath-test-downwardapi-snb2": Phase="Running", Reason="", readiness=false. Elapsed: 6.037184275s
Feb  6 02:30:06.174: INFO: Pod "pod-subpath-test-downwardapi-snb2": Phase="Running", Reason="", readiness=false. Elapsed: 8.060558478s
Feb  6 02:30:08.185: INFO: Pod "pod-subpath-test-downwardapi-snb2": Phase="Running", Reason="", readiness=false. Elapsed: 10.072091053s
Feb  6 02:30:10.193: INFO: Pod "pod-subpath-test-downwardapi-snb2": Phase="Running", Reason="", readiness=false. Elapsed: 12.080103994s
Feb  6 02:30:12.203: INFO: Pod "pod-subpath-test-downwardapi-snb2": Phase="Running", Reason="", readiness=false. Elapsed: 14.089678298s
Feb  6 02:30:14.211: INFO: Pod "pod-subpath-test-downwardapi-snb2": Phase="Running", Reason="", readiness=false. Elapsed: 16.097540858s
Feb  6 02:30:16.236: INFO: Pod "pod-subpath-test-downwardapi-snb2": Phase="Running", Reason="", readiness=false. Elapsed: 18.123136193s
Feb  6 02:30:18.244: INFO: Pod "pod-subpath-test-downwardapi-snb2": Phase="Running", Reason="", readiness=false. Elapsed: 20.131180714s
Feb  6 02:30:20.253: INFO: Pod "pod-subpath-test-downwardapi-snb2": Phase="Running", Reason="", readiness=false. Elapsed: 22.139795774s
Feb  6 02:30:22.260: INFO: Pod "pod-subpath-test-downwardapi-snb2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.14729802s
STEP: Saw pod success
Feb  6 02:30:22.260: INFO: Pod "pod-subpath-test-downwardapi-snb2" satisfied condition "success or failure"
Feb  6 02:30:22.269: INFO: Trying to get logs from node 10.190.119.145 pod pod-subpath-test-downwardapi-snb2 container test-container-subpath-downwardapi-snb2: <nil>
STEP: delete the pod
Feb  6 02:30:22.320: INFO: Waiting for pod pod-subpath-test-downwardapi-snb2 to disappear
Feb  6 02:30:22.327: INFO: Pod pod-subpath-test-downwardapi-snb2 no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-snb2
Feb  6 02:30:22.327: INFO: Deleting pod "pod-subpath-test-downwardapi-snb2" in namespace "e2e-tests-subpath-r77zl"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:30:22.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-r77zl" for this suite.
Feb  6 02:30:28.384: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:30:28.646: INFO: namespace: e2e-tests-subpath-r77zl, resource: bindings, ignored listing per whitelist
Feb  6 02:30:28.737: INFO: namespace e2e-tests-subpath-r77zl deletion completed in 6.392891507s

• [SLOW TEST:31.003 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:30:28.738: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-4qxv8
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-2b32430c-29b7-11e9-b6e7-06cba7aec104
STEP: Creating configMap with name cm-test-opt-upd-2b324351-29b7-11e9-b6e7-06cba7aec104
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-2b32430c-29b7-11e9-b6e7-06cba7aec104
STEP: Updating configmap cm-test-opt-upd-2b324351-29b7-11e9-b6e7-06cba7aec104
STEP: Creating configMap with name cm-test-opt-create-2b324372-29b7-11e9-b6e7-06cba7aec104
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:30:33.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-4qxv8" for this suite.
Feb  6 02:30:57.491: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:30:57.636: INFO: namespace: e2e-tests-configmap-4qxv8, resource: bindings, ignored listing per whitelist
Feb  6 02:30:57.996: INFO: namespace e2e-tests-configmap-4qxv8 deletion completed in 24.539417117s

• [SLOW TEST:29.258 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:30:57.997: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-4wjpz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  6 02:30:58.414: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3c93339f-29b7-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-projected-4wjpz" to be "success or failure"
Feb  6 02:30:58.420: INFO: Pod "downwardapi-volume-3c93339f-29b7-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 6.242516ms
Feb  6 02:31:00.443: INFO: Pod "downwardapi-volume-3c93339f-29b7-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.029114433s
STEP: Saw pod success
Feb  6 02:31:00.443: INFO: Pod "downwardapi-volume-3c93339f-29b7-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 02:31:00.451: INFO: Trying to get logs from node 10.190.119.175 pod downwardapi-volume-3c93339f-29b7-11e9-b6e7-06cba7aec104 container client-container: <nil>
STEP: delete the pod
Feb  6 02:31:00.496: INFO: Waiting for pod downwardapi-volume-3c93339f-29b7-11e9-b6e7-06cba7aec104 to disappear
Feb  6 02:31:00.504: INFO: Pod downwardapi-volume-3c93339f-29b7-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:31:00.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4wjpz" for this suite.
Feb  6 02:31:06.558: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:31:06.854: INFO: namespace: e2e-tests-projected-4wjpz, resource: bindings, ignored listing per whitelist
Feb  6 02:31:06.887: INFO: namespace e2e-tests-projected-4wjpz deletion completed in 6.371349123s

• [SLOW TEST:8.890 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:31:06.887: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replicaset-2d68r
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  6 02:31:07.371: INFO: Creating ReplicaSet my-hostname-basic-41f3205d-29b7-11e9-b6e7-06cba7aec104
Feb  6 02:31:07.391: INFO: Pod name my-hostname-basic-41f3205d-29b7-11e9-b6e7-06cba7aec104: Found 0 pods out of 1
Feb  6 02:31:12.417: INFO: Pod name my-hostname-basic-41f3205d-29b7-11e9-b6e7-06cba7aec104: Found 1 pods out of 1
Feb  6 02:31:12.417: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-41f3205d-29b7-11e9-b6e7-06cba7aec104" is running
Feb  6 02:31:12.424: INFO: Pod "my-hostname-basic-41f3205d-29b7-11e9-b6e7-06cba7aec104-wcltw" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-06 02:31:07 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-06 02:31:09 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-06 02:31:09 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-06 02:31:07 +0000 UTC Reason: Message:}])
Feb  6 02:31:12.424: INFO: Trying to dial the pod
Feb  6 02:31:17.459: INFO: Controller my-hostname-basic-41f3205d-29b7-11e9-b6e7-06cba7aec104: Got expected result from replica 1 [my-hostname-basic-41f3205d-29b7-11e9-b6e7-06cba7aec104-wcltw]: "my-hostname-basic-41f3205d-29b7-11e9-b6e7-06cba7aec104-wcltw", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:31:17.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-2d68r" for this suite.
Feb  6 02:31:25.537: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:31:25.932: INFO: namespace: e2e-tests-replicaset-2d68r, resource: bindings, ignored listing per whitelist
Feb  6 02:31:25.941: INFO: namespace e2e-tests-replicaset-2d68r deletion completed in 8.470415709s

• [SLOW TEST:19.053 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:31:25.942: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-vwj9g
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Feb  6 02:31:26.416: INFO: Waiting up to 5m0s for pod "pod-4d45856d-29b7-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-emptydir-vwj9g" to be "success or failure"
Feb  6 02:31:26.424: INFO: Pod "pod-4d45856d-29b7-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 8.241242ms
Feb  6 02:31:28.434: INFO: Pod "pod-4d45856d-29b7-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017851971s
STEP: Saw pod success
Feb  6 02:31:28.434: INFO: Pod "pod-4d45856d-29b7-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 02:31:28.441: INFO: Trying to get logs from node 10.190.119.144 pod pod-4d45856d-29b7-11e9-b6e7-06cba7aec104 container test-container: <nil>
STEP: delete the pod
Feb  6 02:31:28.488: INFO: Waiting for pod pod-4d45856d-29b7-11e9-b6e7-06cba7aec104 to disappear
Feb  6 02:31:28.495: INFO: Pod pod-4d45856d-29b7-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:31:28.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-vwj9g" for this suite.
Feb  6 02:31:36.568: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:31:36.806: INFO: namespace: e2e-tests-emptydir-vwj9g, resource: bindings, ignored listing per whitelist
Feb  6 02:31:36.917: INFO: namespace e2e-tests-emptydir-vwj9g deletion completed in 8.410482591s

• [SLOW TEST:10.975 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:31:36.917: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-ss9mn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb  6 02:31:37.314: INFO: Waiting up to 5m0s for pod "pod-53c20316-29b7-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-emptydir-ss9mn" to be "success or failure"
Feb  6 02:31:37.331: INFO: Pod "pod-53c20316-29b7-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 17.151387ms
Feb  6 02:31:39.347: INFO: Pod "pod-53c20316-29b7-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.033068517s
STEP: Saw pod success
Feb  6 02:31:39.347: INFO: Pod "pod-53c20316-29b7-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 02:31:39.355: INFO: Trying to get logs from node 10.190.119.145 pod pod-53c20316-29b7-11e9-b6e7-06cba7aec104 container test-container: <nil>
STEP: delete the pod
Feb  6 02:31:39.400: INFO: Waiting for pod pod-53c20316-29b7-11e9-b6e7-06cba7aec104 to disappear
Feb  6 02:31:39.409: INFO: Pod pod-53c20316-29b7-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:31:39.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-ss9mn" for this suite.
Feb  6 02:31:45.478: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:31:45.764: INFO: namespace: e2e-tests-emptydir-ss9mn, resource: bindings, ignored listing per whitelist
Feb  6 02:31:45.834: INFO: namespace e2e-tests-emptydir-ss9mn deletion completed in 6.413447706s

• [SLOW TEST:8.917 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:31:45.835: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-gst2l
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-gst2l
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Feb  6 02:31:46.186: INFO: Found 0 stateful pods, waiting for 3
Feb  6 02:31:56.220: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb  6 02:31:56.220: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb  6 02:31:56.220: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Feb  6 02:31:56.284: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Feb  6 02:32:06.413: INFO: Updating stateful set ss2
Feb  6 02:32:06.432: INFO: Waiting for Pod e2e-tests-statefulset-gst2l/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Feb  6 02:32:16.527: INFO: Found 1 stateful pods, waiting for 3
Feb  6 02:32:26.665: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb  6 02:32:26.665: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb  6 02:32:26.665: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Feb  6 02:32:26.723: INFO: Updating stateful set ss2
Feb  6 02:32:26.744: INFO: Waiting for Pod e2e-tests-statefulset-gst2l/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb  6 02:32:36.818: INFO: Updating stateful set ss2
Feb  6 02:32:36.838: INFO: Waiting for StatefulSet e2e-tests-statefulset-gst2l/ss2 to complete update
Feb  6 02:32:36.838: INFO: Waiting for Pod e2e-tests-statefulset-gst2l/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb  6 02:32:46.881: INFO: Deleting all statefulset in ns e2e-tests-statefulset-gst2l
Feb  6 02:32:46.893: INFO: Scaling statefulset ss2 to 0
Feb  6 02:33:07.010: INFO: Waiting for statefulset status.replicas updated to 0
Feb  6 02:33:07.019: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:33:07.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-gst2l" for this suite.
Feb  6 02:33:15.140: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:33:15.479: INFO: namespace: e2e-tests-statefulset-gst2l, resource: bindings, ignored listing per whitelist
Feb  6 02:33:15.518: INFO: namespace e2e-tests-statefulset-gst2l deletion completed in 8.424353561s

• [SLOW TEST:89.683 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:33:15.519: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-5mzzl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-5mzzl
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-5mzzl to expose endpoints map[]
Feb  6 02:33:16.310: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-5mzzl exposes endpoints map[] (13.205906ms elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-5mzzl
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-5mzzl to expose endpoints map[pod1:[80]]
Feb  6 02:33:18.476: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-5mzzl exposes endpoints map[pod1:[80]] (2.147886598s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-5mzzl
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-5mzzl to expose endpoints map[pod1:[80] pod2:[80]]
Feb  6 02:33:19.548: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-5mzzl exposes endpoints map[pod1:[80] pod2:[80]] (1.058277282s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-5mzzl
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-5mzzl to expose endpoints map[pod2:[80]]
Feb  6 02:33:20.594: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-5mzzl exposes endpoints map[pod2:[80]] (1.034123674s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-5mzzl
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-5mzzl to expose endpoints map[]
Feb  6 02:33:20.616: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-5mzzl exposes endpoints map[] (8.951916ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:33:20.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-5mzzl" for this suite.
Feb  6 02:33:44.745: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:33:45.212: INFO: namespace: e2e-tests-services-5mzzl, resource: bindings, ignored listing per whitelist
Feb  6 02:33:45.355: INFO: namespace e2e-tests-services-5mzzl deletion completed in 24.64827947s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:29.836 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:33:45.356: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-w4xh7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  6 02:33:45.763: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a058f197-29b7-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-projected-w4xh7" to be "success or failure"
Feb  6 02:33:45.770: INFO: Pod "downwardapi-volume-a058f197-29b7-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 7.226117ms
Feb  6 02:33:47.778: INFO: Pod "downwardapi-volume-a058f197-29b7-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015104954s
STEP: Saw pod success
Feb  6 02:33:47.778: INFO: Pod "downwardapi-volume-a058f197-29b7-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 02:33:47.787: INFO: Trying to get logs from node 10.190.119.144 pod downwardapi-volume-a058f197-29b7-11e9-b6e7-06cba7aec104 container client-container: <nil>
STEP: delete the pod
Feb  6 02:33:47.849: INFO: Waiting for pod downwardapi-volume-a058f197-29b7-11e9-b6e7-06cba7aec104 to disappear
Feb  6 02:33:47.856: INFO: Pod downwardapi-volume-a058f197-29b7-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:33:47.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-w4xh7" for this suite.
Feb  6 02:33:53.910: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:33:54.525: INFO: namespace: e2e-tests-projected-w4xh7, resource: bindings, ignored listing per whitelist
Feb  6 02:33:54.918: INFO: namespace e2e-tests-projected-w4xh7 deletion completed in 7.048601979s

• [SLOW TEST:9.563 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:33:54.921: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-wt9dh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-wt9dh
Feb  6 02:33:59.448: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-wt9dh
STEP: checking the pod's current state and verifying that restartCount is present
Feb  6 02:33:59.455: INFO: Initial restart count of pod liveness-http is 0
Feb  6 02:34:17.621: INFO: Restart count of pod e2e-tests-container-probe-wt9dh/liveness-http is now 1 (18.165979072s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:34:17.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-wt9dh" for this suite.
Feb  6 02:34:23.766: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:34:24.017: INFO: namespace: e2e-tests-container-probe-wt9dh, resource: bindings, ignored listing per whitelist
Feb  6 02:34:24.288: INFO: namespace e2e-tests-container-probe-wt9dh deletion completed in 6.578923419s

• [SLOW TEST:29.368 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:34:24.290: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-pdg4x
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  6 02:34:24.958: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b7b5aa9b-29b7-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-projected-pdg4x" to be "success or failure"
Feb  6 02:34:24.967: INFO: Pod "downwardapi-volume-b7b5aa9b-29b7-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 9.500273ms
Feb  6 02:34:26.975: INFO: Pod "downwardapi-volume-b7b5aa9b-29b7-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017513186s
STEP: Saw pod success
Feb  6 02:34:26.975: INFO: Pod "downwardapi-volume-b7b5aa9b-29b7-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 02:34:26.982: INFO: Trying to get logs from node 10.190.119.175 pod downwardapi-volume-b7b5aa9b-29b7-11e9-b6e7-06cba7aec104 container client-container: <nil>
STEP: delete the pod
Feb  6 02:34:27.029: INFO: Waiting for pod downwardapi-volume-b7b5aa9b-29b7-11e9-b6e7-06cba7aec104 to disappear
Feb  6 02:34:27.038: INFO: Pod downwardapi-volume-b7b5aa9b-29b7-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:34:27.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pdg4x" for this suite.
Feb  6 02:34:33.092: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:34:33.473: INFO: namespace: e2e-tests-projected-pdg4x, resource: bindings, ignored listing per whitelist
Feb  6 02:34:33.489: INFO: namespace e2e-tests-projected-pdg4x deletion completed in 6.439447416s

• [SLOW TEST:9.199 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:34:33.490: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-gkfc2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Feb  6 02:34:34.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 create -f - --namespace=e2e-tests-kubectl-gkfc2'
Feb  6 02:34:35.381: INFO: stderr: ""
Feb  6 02:34:35.381: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb  6 02:34:35.381: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-gkfc2'
Feb  6 02:34:35.515: INFO: stderr: ""
Feb  6 02:34:35.515: INFO: stdout: "update-demo-nautilus-crwrz update-demo-nautilus-wsf7r "
Feb  6 02:34:35.515: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 get pods update-demo-nautilus-crwrz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gkfc2'
Feb  6 02:34:35.631: INFO: stderr: ""
Feb  6 02:34:35.631: INFO: stdout: ""
Feb  6 02:34:35.631: INFO: update-demo-nautilus-crwrz is created but not running
Feb  6 02:34:40.632: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-gkfc2'
Feb  6 02:34:40.809: INFO: stderr: ""
Feb  6 02:34:40.809: INFO: stdout: "update-demo-nautilus-crwrz update-demo-nautilus-wsf7r "
Feb  6 02:34:40.809: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 get pods update-demo-nautilus-crwrz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gkfc2'
Feb  6 02:34:40.931: INFO: stderr: ""
Feb  6 02:34:40.931: INFO: stdout: "true"
Feb  6 02:34:40.931: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 get pods update-demo-nautilus-crwrz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gkfc2'
Feb  6 02:34:41.041: INFO: stderr: ""
Feb  6 02:34:41.041: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  6 02:34:41.041: INFO: validating pod update-demo-nautilus-crwrz
Feb  6 02:34:41.059: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  6 02:34:41.059: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  6 02:34:41.059: INFO: update-demo-nautilus-crwrz is verified up and running
Feb  6 02:34:41.059: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 get pods update-demo-nautilus-wsf7r -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gkfc2'
Feb  6 02:34:41.174: INFO: stderr: ""
Feb  6 02:34:41.174: INFO: stdout: "true"
Feb  6 02:34:41.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 get pods update-demo-nautilus-wsf7r -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gkfc2'
Feb  6 02:34:41.277: INFO: stderr: ""
Feb  6 02:34:41.278: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  6 02:34:41.278: INFO: validating pod update-demo-nautilus-wsf7r
Feb  6 02:34:41.297: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  6 02:34:41.297: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  6 02:34:41.297: INFO: update-demo-nautilus-wsf7r is verified up and running
STEP: rolling-update to new replication controller
Feb  6 02:34:41.299: INFO: scanned /root for discovery docs: <nil>
Feb  6 02:34:41.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-gkfc2'
Feb  6 02:34:59.768: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb  6 02:34:59.768: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb  6 02:34:59.768: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-gkfc2'
Feb  6 02:34:59.897: INFO: stderr: ""
Feb  6 02:34:59.897: INFO: stdout: "update-demo-kitten-4wvc5 update-demo-kitten-drffk update-demo-nautilus-wsf7r "
STEP: Replicas for name=update-demo: expected=2 actual=3
Feb  6 02:35:04.897: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-gkfc2'
Feb  6 02:35:05.013: INFO: stderr: ""
Feb  6 02:35:05.013: INFO: stdout: "update-demo-kitten-4wvc5 update-demo-kitten-drffk "
Feb  6 02:35:05.013: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 get pods update-demo-kitten-4wvc5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gkfc2'
Feb  6 02:35:05.136: INFO: stderr: ""
Feb  6 02:35:05.136: INFO: stdout: "true"
Feb  6 02:35:05.136: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 get pods update-demo-kitten-4wvc5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gkfc2'
Feb  6 02:35:05.250: INFO: stderr: ""
Feb  6 02:35:05.250: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb  6 02:35:05.250: INFO: validating pod update-demo-kitten-4wvc5
Feb  6 02:35:05.269: INFO: got data: {
  "image": "kitten.jpg"
}

Feb  6 02:35:05.269: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb  6 02:35:05.269: INFO: update-demo-kitten-4wvc5 is verified up and running
Feb  6 02:35:05.269: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 get pods update-demo-kitten-drffk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gkfc2'
Feb  6 02:35:05.378: INFO: stderr: ""
Feb  6 02:35:05.378: INFO: stdout: "true"
Feb  6 02:35:05.378: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 get pods update-demo-kitten-drffk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-gkfc2'
Feb  6 02:35:05.511: INFO: stderr: ""
Feb  6 02:35:05.511: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb  6 02:35:05.511: INFO: validating pod update-demo-kitten-drffk
Feb  6 02:35:05.811: INFO: got data: {
  "image": "kitten.jpg"
}

Feb  6 02:35:05.811: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb  6 02:35:05.811: INFO: update-demo-kitten-drffk is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:35:05.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-gkfc2" for this suite.
Feb  6 02:35:29.918: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:35:30.341: INFO: namespace: e2e-tests-kubectl-gkfc2, resource: bindings, ignored listing per whitelist
Feb  6 02:35:30.409: INFO: namespace e2e-tests-kubectl-gkfc2 deletion completed in 24.587705411s

• [SLOW TEST:56.920 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:35:30.410: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-n4mnt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  6 02:35:31.077: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 version'
Feb  6 02:35:31.195: INFO: stderr: ""
Feb  6 02:35:31.195: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.2+IKS\", GitCommit:\"c1267db0263569a92950ef1312aa41b96de6966e\", GitTreeState:\"clean\", BuildDate:\"2019-01-31T12:11:46Z\", GoVersion:\"go1.11.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:35:31.195: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-n4mnt" for this suite.
Feb  6 02:35:37.256: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:35:37.521: INFO: namespace: e2e-tests-kubectl-n4mnt, resource: bindings, ignored listing per whitelist
Feb  6 02:35:37.660: INFO: namespace e2e-tests-kubectl-n4mnt deletion completed in 6.453856357s

• [SLOW TEST:7.250 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:35:37.661: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-hlk2k
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb  6 02:35:38.053: INFO: Waiting up to 5m0s for pod "pod-e3464c0e-29b7-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-emptydir-hlk2k" to be "success or failure"
Feb  6 02:35:38.097: INFO: Pod "pod-e3464c0e-29b7-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 43.94579ms
Feb  6 02:35:40.106: INFO: Pod "pod-e3464c0e-29b7-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.052578667s
STEP: Saw pod success
Feb  6 02:35:40.106: INFO: Pod "pod-e3464c0e-29b7-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 02:35:40.112: INFO: Trying to get logs from node 10.190.119.145 pod pod-e3464c0e-29b7-11e9-b6e7-06cba7aec104 container test-container: <nil>
STEP: delete the pod
Feb  6 02:35:40.164: INFO: Waiting for pod pod-e3464c0e-29b7-11e9-b6e7-06cba7aec104 to disappear
Feb  6 02:35:40.175: INFO: Pod pod-e3464c0e-29b7-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:35:40.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-hlk2k" for this suite.
Feb  6 02:35:46.234: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:35:46.459: INFO: namespace: e2e-tests-emptydir-hlk2k, resource: bindings, ignored listing per whitelist
Feb  6 02:35:46.671: INFO: namespace e2e-tests-emptydir-hlk2k deletion completed in 6.474170484s

• [SLOW TEST:9.011 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:35:46.672: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-pnfjx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-pnfjx
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-pnfjx
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-pnfjx
Feb  6 02:35:47.123: INFO: Found 0 stateful pods, waiting for 1
Feb  6 02:35:57.155: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Feb  6 02:35:57.163: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  6 02:35:57.491: INFO: stderr: ""
Feb  6 02:35:57.491: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  6 02:35:57.491: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  6 02:35:57.501: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb  6 02:36:07.526: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb  6 02:36:07.526: INFO: Waiting for statefulset status.replicas updated to 0
Feb  6 02:36:07.604: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999998973s
Feb  6 02:36:08.614: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.95190747s
Feb  6 02:36:09.625: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.941404282s
Feb  6 02:36:10.633: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.930843345s
Feb  6 02:36:11.641: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.923155526s
Feb  6 02:36:12.649: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.915197809s
Feb  6 02:36:13.657: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.906748755s
Feb  6 02:36:14.665: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.898987474s
Feb  6 02:36:15.673: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.890725302s
Feb  6 02:36:16.681: INFO: Verifying statefulset ss doesn't scale past 1 for another 882.461478ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-pnfjx
Feb  6 02:36:17.713: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 02:36:18.011: INFO: stderr: ""
Feb  6 02:36:18.011: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  6 02:36:18.011: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb  6 02:36:18.020: INFO: Found 1 stateful pods, waiting for 3
Feb  6 02:36:28.044: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb  6 02:36:28.044: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb  6 02:36:28.044: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Feb  6 02:36:28.056: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  6 02:36:28.346: INFO: stderr: ""
Feb  6 02:36:28.346: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  6 02:36:28.346: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  6 02:36:28.347: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  6 02:36:28.715: INFO: stderr: ""
Feb  6 02:36:28.715: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  6 02:36:28.715: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  6 02:36:28.715: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  6 02:36:29.093: INFO: stderr: ""
Feb  6 02:36:29.093: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  6 02:36:29.093: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  6 02:36:29.093: INFO: Waiting for statefulset status.replicas updated to 0
Feb  6 02:36:29.568: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Feb  6 02:36:39.605: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb  6 02:36:39.605: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb  6 02:36:39.606: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb  6 02:36:39.705: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999998767s
Feb  6 02:36:40.713: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.991465944s
Feb  6 02:36:41.722: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.983495998s
Feb  6 02:36:42.730: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.974925217s
Feb  6 02:36:43.741: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.966820788s
Feb  6 02:36:44.749: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.956005642s
Feb  6 02:36:45.758: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.948056961s
Feb  6 02:36:46.766: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.939161433s
Feb  6 02:36:47.774: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.930699358s
Feb  6 02:36:48.783: INFO: Verifying statefulset ss doesn't scale past 3 for another 922.499333ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-pnfjx
Feb  6 02:36:49.810: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 02:36:50.096: INFO: stderr: ""
Feb  6 02:36:50.096: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  6 02:36:50.096: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb  6 02:36:50.096: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 02:36:50.401: INFO: stderr: ""
Feb  6 02:36:50.402: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  6 02:36:50.402: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb  6 02:36:50.402: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 02:36:50.668: INFO: rc: 1
Feb  6 02:36:50.669: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: Internal error occurred: error executing command in container: failed to exec in container: container is in CONTAINER_EXITED state
 [] <nil> 0xc002938000 exit status 1 <nil> <nil> true [0xc000d6eaf8 0xc000d6eb80 0xc000d6ebd8] [0xc000d6eaf8 0xc000d6eb80 0xc000d6ebd8] [0xc000d6eb50 0xc000d6ebc8] [0x92f8e0 0x92f8e0] 0xc001db80c0 <nil>}:
Command stdout:

stderr:
error: Internal error occurred: error executing command in container: failed to exec in container: container is in CONTAINER_EXITED state

error:
exit status 1

Feb  6 02:37:00.669: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 02:37:00.910: INFO: rc: 1
Feb  6 02:37:00.910: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc0029387b0 exit status 1 <nil> <nil> true [0xc000d6ec18 0xc000d6ecb8 0xc000d6ed60] [0xc000d6ec18 0xc000d6ecb8 0xc000d6ed60] [0xc000d6ec80 0xc000d6ed10] [0x92f8e0 0x92f8e0] 0xc001db83c0 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Feb  6 02:37:10.910: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 02:37:11.025: INFO: rc: 1
Feb  6 02:37:11.025: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002938c00 exit status 1 <nil> <nil> true [0xc000d6ed70 0xc000d6ee08 0xc000d6ee58] [0xc000d6ed70 0xc000d6ee08 0xc000d6ee58] [0xc000d6edc0 0xc000d6ee40] [0x92f8e0 0x92f8e0] 0xc001db86c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 02:37:21.025: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 02:37:21.146: INFO: rc: 1
Feb  6 02:37:21.147: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002939170 exit status 1 <nil> <nil> true [0xc000d6eec0 0xc000d6ef30 0xc000d6ef98] [0xc000d6eec0 0xc000d6ef30 0xc000d6ef98] [0xc000d6ef18 0xc000d6ef78] [0x92f8e0 0x92f8e0] 0xc001db89c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 02:37:31.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 02:37:31.328: INFO: rc: 1
Feb  6 02:37:31.328: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002939530 exit status 1 <nil> <nil> true [0xc000d6efa8 0xc000d6f040 0xc000d6f088] [0xc000d6efa8 0xc000d6f040 0xc000d6f088] [0xc000d6f028 0xc000d6f068] [0x92f8e0 0x92f8e0] 0xc001db8cc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 02:37:41.328: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 02:37:41.499: INFO: rc: 1
Feb  6 02:37:41.499: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0009c50e0 exit status 1 <nil> <nil> true [0xc000a6e228 0xc000a6e240 0xc000a6e258] [0xc000a6e228 0xc000a6e240 0xc000a6e258] [0xc000a6e238 0xc000a6e250] [0x92f8e0 0x92f8e0] 0xc001eb1b00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 02:37:51.499: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 02:37:51.618: INFO: rc: 1
Feb  6 02:37:51.618: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002939920 exit status 1 <nil> <nil> true [0xc000d6f098 0xc000d6f0e0 0xc000d6f148] [0xc000d6f098 0xc000d6f0e0 0xc000d6f148] [0xc000d6f0c0 0xc000d6f138] [0x92f8e0 0x92f8e0] 0xc001db9020 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 02:38:01.619: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 02:38:01.743: INFO: rc: 1
Feb  6 02:38:01.744: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002939ce0 exit status 1 <nil> <nil> true [0xc000d6f160 0xc000d6f198 0xc000d6f200] [0xc000d6f160 0xc000d6f198 0xc000d6f200] [0xc000d6f188 0xc000d6f1c8] [0x92f8e0 0x92f8e0] 0xc001db9440 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 02:38:11.744: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 02:38:11.870: INFO: rc: 1
Feb  6 02:38:11.870: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0009c5560 exit status 1 <nil> <nil> true [0xc000a6e260 0xc000a6e278 0xc000a6e290] [0xc000a6e260 0xc000a6e278 0xc000a6e290] [0xc000a6e270 0xc000a6e288] [0x92f8e0 0x92f8e0] 0xc0028f2060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 02:38:21.871: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 02:38:22.102: INFO: rc: 1
Feb  6 02:38:22.102: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0009c5920 exit status 1 <nil> <nil> true [0xc000a6e298 0xc000a6e2b0 0xc000a6e2c8] [0xc000a6e298 0xc000a6e2b0 0xc000a6e2c8] [0xc000a6e2a8 0xc000a6e2c0] [0x92f8e0 0x92f8e0] 0xc0028f2360 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 02:38:32.102: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 02:38:32.218: INFO: rc: 1
Feb  6 02:38:32.218: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001aa80c0 exit status 1 <nil> <nil> true [0xc000d6f218 0xc000d6f258 0xc000d6f2a0] [0xc000d6f218 0xc000d6f258 0xc000d6f2a0] [0xc000d6f240 0xc000d6f290] [0x92f8e0 0x92f8e0] 0xc001db9860 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 02:38:42.219: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 02:38:42.401: INFO: rc: 1
Feb  6 02:38:42.401: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0029387e0 exit status 1 <nil> <nil> true [0xc000a6e008 0xc000a6e048 0xc000a6e088] [0xc000a6e008 0xc000a6e048 0xc000a6e088] [0xc000a6e028 0xc000a6e070] [0x92f8e0 0x92f8e0] 0xc001eb0360 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 02:38:52.401: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 02:38:52.630: INFO: rc: 1
Feb  6 02:38:52.630: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0028ac390 exit status 1 <nil> <nil> true [0xc000d6e040 0xc000d6e0c0 0xc000d6e178] [0xc000d6e040 0xc000d6e0c0 0xc000d6e178] [0xc000d6e098 0xc000d6e118] [0x92f8e0 0x92f8e0] 0xc001ee4720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 02:39:02.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 02:39:02.728: INFO: rc: 1
Feb  6 02:39:02.729: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002938db0 exit status 1 <nil> <nil> true [0xc000a6e0a8 0xc000a6e0d0 0xc000a6e108] [0xc000a6e0a8 0xc000a6e0d0 0xc000a6e108] [0xc000a6e0c8 0xc000a6e0f0] [0x92f8e0 0x92f8e0] 0xc001eb0780 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 02:39:12.729: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 02:39:12.837: INFO: rc: 1
Feb  6 02:39:12.837: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002939200 exit status 1 <nil> <nil> true [0xc000a6e110 0xc000a6e128 0xc000a6e160] [0xc000a6e110 0xc000a6e128 0xc000a6e160] [0xc000a6e120 0xc000a6e158] [0x92f8e0 0x92f8e0] 0xc001eb0d80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 02:39:22.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 02:39:23.000: INFO: rc: 1
Feb  6 02:39:23.000: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0028ac750 exit status 1 <nil> <nil> true [0xc000d6e198 0xc000d6e248 0xc000d6e350] [0xc000d6e198 0xc000d6e248 0xc000d6e350] [0xc000d6e200 0xc000d6e298] [0x92f8e0 0x92f8e0] 0xc001ee5020 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 02:39:33.000: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 02:39:33.131: INFO: rc: 1
Feb  6 02:39:33.131: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0029395f0 exit status 1 <nil> <nil> true [0xc000a6e168 0xc000a6e180 0xc000a6e1b8] [0xc000a6e168 0xc000a6e180 0xc000a6e1b8] [0xc000a6e178 0xc000a6e1b0] [0x92f8e0 0x92f8e0] 0xc001eb1380 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 02:39:43.131: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 02:39:43.257: INFO: rc: 1
Feb  6 02:39:43.257: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0029399e0 exit status 1 <nil> <nil> true [0xc000a6e1c0 0xc000a6e1d8 0xc000a6e200] [0xc000a6e1c0 0xc000a6e1d8 0xc000a6e200] [0xc000a6e1d0 0xc000a6e1f8] [0x92f8e0 0x92f8e0] 0xc001eb18c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 02:39:53.257: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 02:39:53.375: INFO: rc: 1
Feb  6 02:39:53.375: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002939dd0 exit status 1 <nil> <nil> true [0xc000a6e208 0xc000a6e220 0xc000a6e238] [0xc000a6e208 0xc000a6e220 0xc000a6e238] [0xc000a6e218 0xc000a6e230] [0x92f8e0 0x92f8e0] 0xc001eb1ec0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 02:40:03.375: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 02:40:03.523: INFO: rc: 1
Feb  6 02:40:03.523: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0028ad5c0 exit status 1 <nil> <nil> true [0xc000d6e370 0xc000d6e3d8 0xc000d6e470] [0xc000d6e370 0xc000d6e3d8 0xc000d6e470] [0xc000d6e3c0 0xc000d6e440] [0x92f8e0 0x92f8e0] 0xc001ee54a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 02:40:13.523: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 02:40:13.645: INFO: rc: 1
Feb  6 02:40:13.645: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001db2240 exit status 1 <nil> <nil> true [0xc000a6e240 0xc000a6e258 0xc000a6e270] [0xc000a6e240 0xc000a6e258 0xc000a6e270] [0xc000a6e250 0xc000a6e268] [0x92f8e0 0x92f8e0] 0xc0028f2240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 02:40:23.645: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 02:40:23.758: INFO: rc: 1
Feb  6 02:40:23.758: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0028ada40 exit status 1 <nil> <nil> true [0xc000d6e480 0xc000d6e588 0xc000d6e610] [0xc000d6e480 0xc000d6e588 0xc000d6e610] [0xc000d6e540 0xc000d6e5d8] [0x92f8e0 0x92f8e0] 0xc001ee58c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 02:40:33.758: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 02:40:33.881: INFO: rc: 1
Feb  6 02:40:33.881: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001db2600 exit status 1 <nil> <nil> true [0xc000a6e278 0xc000a6e290 0xc000a6e2a8] [0xc000a6e278 0xc000a6e290 0xc000a6e2a8] [0xc000a6e288 0xc000a6e2a0] [0x92f8e0 0x92f8e0] 0xc0028f26c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 02:40:43.882: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 02:40:43.997: INFO: rc: 1
Feb  6 02:40:43.997: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002938780 exit status 1 <nil> <nil> true [0xc000a6e008 0xc000a6e048 0xc000a6e088] [0xc000a6e008 0xc000a6e048 0xc000a6e088] [0xc000a6e028 0xc000a6e070] [0x92f8e0 0x92f8e0] 0xc001eb0360 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 02:40:53.997: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 02:40:54.126: INFO: rc: 1
Feb  6 02:40:54.126: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001db2450 exit status 1 <nil> <nil> true [0xc000d6e040 0xc000d6e0c0 0xc000d6e178] [0xc000d6e040 0xc000d6e0c0 0xc000d6e178] [0xc000d6e098 0xc000d6e118] [0x92f8e0 0x92f8e0] 0xc0028f2240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 02:41:04.126: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 02:41:04.240: INFO: rc: 1
Feb  6 02:41:04.240: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001db2840 exit status 1 <nil> <nil> true [0xc000d6e198 0xc000d6e248 0xc000d6e350] [0xc000d6e198 0xc000d6e248 0xc000d6e350] [0xc000d6e200 0xc000d6e298] [0x92f8e0 0x92f8e0] 0xc0028f26c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 02:41:14.240: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 02:41:14.400: INFO: rc: 1
Feb  6 02:41:14.400: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002938c00 exit status 1 <nil> <nil> true [0xc000a6e0a8 0xc000a6e0d0 0xc000a6e108] [0xc000a6e0a8 0xc000a6e0d0 0xc000a6e108] [0xc000a6e0c8 0xc000a6e0f0] [0x92f8e0 0x92f8e0] 0xc001eb0780 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 02:41:24.400: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 02:41:24.521: INFO: rc: 1
Feb  6 02:41:24.521: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001db2c30 exit status 1 <nil> <nil> true [0xc000d6e370 0xc000d6e3d8 0xc000d6e470] [0xc000d6e370 0xc000d6e3d8 0xc000d6e470] [0xc000d6e3c0 0xc000d6e440] [0x92f8e0 0x92f8e0] 0xc0028f2cc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 02:41:34.521: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 02:41:34.700: INFO: rc: 1
Feb  6 02:41:34.700: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001db2ff0 exit status 1 <nil> <nil> true [0xc000d6e480 0xc000d6e588 0xc000d6e610] [0xc000d6e480 0xc000d6e588 0xc000d6e610] [0xc000d6e540 0xc000d6e5d8] [0x92f8e0 0x92f8e0] 0xc0028f3260 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 02:41:44.701: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 02:41:44.809: INFO: rc: 1
Feb  6 02:41:44.809: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002939170 exit status 1 <nil> <nil> true [0xc000a6e110 0xc000a6e128 0xc000a6e160] [0xc000a6e110 0xc000a6e128 0xc000a6e160] [0xc000a6e120 0xc000a6e158] [0x92f8e0 0x92f8e0] 0xc001eb0d80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 02:41:54.810: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-pnfjx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 02:41:55.000: INFO: rc: 1
Feb  6 02:41:55.000: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: 
Feb  6 02:41:55.000: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb  6 02:41:55.077: INFO: Deleting all statefulset in ns e2e-tests-statefulset-pnfjx
Feb  6 02:41:55.088: INFO: Scaling statefulset ss to 0
Feb  6 02:41:55.118: INFO: Waiting for statefulset status.replicas updated to 0
Feb  6 02:41:55.128: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:41:55.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-pnfjx" for this suite.
Feb  6 02:42:03.223: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:42:03.835: INFO: namespace: e2e-tests-statefulset-pnfjx, resource: bindings, ignored listing per whitelist
Feb  6 02:42:03.878: INFO: namespace e2e-tests-statefulset-pnfjx deletion completed in 8.692449046s

• [SLOW TEST:377.207 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:42:03.879: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-6bc7s
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb  6 02:42:04.252: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:42:07.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-6bc7s" for this suite.
Feb  6 02:42:15.523: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:42:15.652: INFO: namespace: e2e-tests-init-container-6bc7s, resource: bindings, ignored listing per whitelist
Feb  6 02:42:15.913: INFO: namespace e2e-tests-init-container-6bc7s deletion completed in 8.434869615s

• [SLOW TEST:12.034 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:42:15.915: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-cf4k4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-cf4k4
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb  6 02:42:16.251: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb  6 02:42:39.150: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.70.240:8080/dial?request=hostName&protocol=http&host=172.30.70.239&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-cf4k4 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 02:42:39.150: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
Feb  6 02:42:39.671: INFO: Waiting for endpoints: map[]
Feb  6 02:42:39.680: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.70.240:8080/dial?request=hostName&protocol=http&host=172.30.176.40&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-cf4k4 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 02:42:39.680: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
Feb  6 02:42:39.866: INFO: Waiting for endpoints: map[]
Feb  6 02:42:39.904: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.70.240:8080/dial?request=hostName&protocol=http&host=172.30.175.209&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-cf4k4 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 02:42:39.904: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
Feb  6 02:42:40.088: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:42:40.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-cf4k4" for this suite.
Feb  6 02:43:04.134: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:43:04.588: INFO: namespace: e2e-tests-pod-network-test-cf4k4, resource: bindings, ignored listing per whitelist
Feb  6 02:43:04.654: INFO: namespace e2e-tests-pod-network-test-cf4k4 deletion completed in 24.554782276s

• [SLOW TEST:48.739 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:43:04.655: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-n4wxb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  6 02:43:05.076: INFO: Waiting up to 5m0s for pod "downwardapi-volume-edb83856-29b8-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-projected-n4wxb" to be "success or failure"
Feb  6 02:43:05.084: INFO: Pod "downwardapi-volume-edb83856-29b8-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 7.194213ms
Feb  6 02:43:07.092: INFO: Pod "downwardapi-volume-edb83856-29b8-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015409124s
STEP: Saw pod success
Feb  6 02:43:07.092: INFO: Pod "downwardapi-volume-edb83856-29b8-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 02:43:07.101: INFO: Trying to get logs from node 10.190.119.175 pod downwardapi-volume-edb83856-29b8-11e9-b6e7-06cba7aec104 container client-container: <nil>
STEP: delete the pod
Feb  6 02:43:07.151: INFO: Waiting for pod downwardapi-volume-edb83856-29b8-11e9-b6e7-06cba7aec104 to disappear
Feb  6 02:43:07.158: INFO: Pod downwardapi-volume-edb83856-29b8-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:43:07.159: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-n4wxb" for this suite.
Feb  6 02:43:13.212: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:43:13.493: INFO: namespace: e2e-tests-projected-n4wxb, resource: bindings, ignored listing per whitelist
Feb  6 02:43:13.653: INFO: namespace e2e-tests-projected-n4wxb deletion completed in 6.483459282s

• [SLOW TEST:8.999 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:43:13.654: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-fxn9d
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Feb  6 02:43:14.042: INFO: Waiting up to 5m0s for pod "client-containers-f3119220-29b8-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-containers-fxn9d" to be "success or failure"
Feb  6 02:43:14.050: INFO: Pod "client-containers-f3119220-29b8-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 7.179091ms
Feb  6 02:43:16.079: INFO: Pod "client-containers-f3119220-29b8-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.036957016s
STEP: Saw pod success
Feb  6 02:43:16.079: INFO: Pod "client-containers-f3119220-29b8-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 02:43:16.088: INFO: Trying to get logs from node 10.190.119.144 pod client-containers-f3119220-29b8-11e9-b6e7-06cba7aec104 container test-container: <nil>
STEP: delete the pod
Feb  6 02:43:16.139: INFO: Waiting for pod client-containers-f3119220-29b8-11e9-b6e7-06cba7aec104 to disappear
Feb  6 02:43:16.146: INFO: Pod client-containers-f3119220-29b8-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:43:16.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-fxn9d" for this suite.
Feb  6 02:43:22.207: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:43:22.336: INFO: namespace: e2e-tests-containers-fxn9d, resource: bindings, ignored listing per whitelist
Feb  6 02:43:22.677: INFO: namespace e2e-tests-containers-fxn9d deletion completed in 6.519242019s

• [SLOW TEST:9.023 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:43:22.677: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-vgk24
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  6 02:43:23.004: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:43:25.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-vgk24" for this suite.
Feb  6 02:44:13.530: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:44:13.768: INFO: namespace: e2e-tests-pods-vgk24, resource: bindings, ignored listing per whitelist
Feb  6 02:44:13.868: INFO: namespace e2e-tests-pods-vgk24 deletion completed in 48.380274994s

• [SLOW TEST:51.191 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:44:13.871: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replicaset-w849d
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Feb  6 02:44:17.288: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:44:18.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-w849d" for this suite.
Feb  6 02:44:42.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:44:42.874: INFO: namespace: e2e-tests-replicaset-w849d, resource: bindings, ignored listing per whitelist
Feb  6 02:44:43.147: INFO: namespace e2e-tests-replicaset-w849d deletion completed in 24.749557098s

• [SLOW TEST:29.277 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:44:43.147: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-p8xdz
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-p8xdz
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb  6 02:44:43.484: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb  6 02:45:05.702: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.70.241:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-p8xdz PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 02:45:05.702: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
Feb  6 02:45:05.888: INFO: Found all expected endpoints: [netserver-0]
Feb  6 02:45:05.895: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.176.44:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-p8xdz PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 02:45:05.895: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
Feb  6 02:45:06.316: INFO: Found all expected endpoints: [netserver-1]
Feb  6 02:45:06.329: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.175.217:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-p8xdz PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 02:45:06.329: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
Feb  6 02:45:06.527: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:45:06.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-p8xdz" for this suite.
Feb  6 02:45:30.576: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:45:30.678: INFO: namespace: e2e-tests-pod-network-test-p8xdz, resource: bindings, ignored listing per whitelist
Feb  6 02:45:30.889: INFO: namespace e2e-tests-pod-network-test-p8xdz deletion completed in 24.350540664s

• [SLOW TEST:47.742 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:45:30.890: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-vpjmc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  6 02:45:31.259: INFO: Waiting up to 5m0s for pod "downwardapi-volume-44db0ad8-29b9-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-downward-api-vpjmc" to be "success or failure"
Feb  6 02:45:31.266: INFO: Pod "downwardapi-volume-44db0ad8-29b9-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 7.715528ms
Feb  6 02:45:33.294: INFO: Pod "downwardapi-volume-44db0ad8-29b9-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.035357667s
STEP: Saw pod success
Feb  6 02:45:33.294: INFO: Pod "downwardapi-volume-44db0ad8-29b9-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 02:45:33.301: INFO: Trying to get logs from node 10.190.119.175 pod downwardapi-volume-44db0ad8-29b9-11e9-b6e7-06cba7aec104 container client-container: <nil>
STEP: delete the pod
Feb  6 02:45:33.341: INFO: Waiting for pod downwardapi-volume-44db0ad8-29b9-11e9-b6e7-06cba7aec104 to disappear
Feb  6 02:45:33.348: INFO: Pod downwardapi-volume-44db0ad8-29b9-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:45:33.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-vpjmc" for this suite.
Feb  6 02:45:39.410: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:45:40.151: INFO: namespace: e2e-tests-downward-api-vpjmc, resource: bindings, ignored listing per whitelist
Feb  6 02:45:40.257: INFO: namespace e2e-tests-downward-api-vpjmc deletion completed in 6.891213513s

• [SLOW TEST:9.366 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:45:40.257: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-7z6z2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb  6 02:45:40.608: INFO: Waiting up to 5m0s for pod "downward-api-4a6c7164-29b9-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-downward-api-7z6z2" to be "success or failure"
Feb  6 02:45:40.616: INFO: Pod "downward-api-4a6c7164-29b9-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 8.2356ms
Feb  6 02:45:42.624: INFO: Pod "downward-api-4a6c7164-29b9-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016298174s
Feb  6 02:45:44.649: INFO: Pod "downward-api-4a6c7164-29b9-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040435317s
STEP: Saw pod success
Feb  6 02:45:44.649: INFO: Pod "downward-api-4a6c7164-29b9-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 02:45:44.656: INFO: Trying to get logs from node 10.190.119.175 pod downward-api-4a6c7164-29b9-11e9-b6e7-06cba7aec104 container dapi-container: <nil>
STEP: delete the pod
Feb  6 02:45:44.709: INFO: Waiting for pod downward-api-4a6c7164-29b9-11e9-b6e7-06cba7aec104 to disappear
Feb  6 02:45:44.716: INFO: Pod downward-api-4a6c7164-29b9-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:45:44.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-7z6z2" for this suite.
Feb  6 02:45:50.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:45:51.131: INFO: namespace: e2e-tests-downward-api-7z6z2, resource: bindings, ignored listing per whitelist
Feb  6 02:45:51.341: INFO: namespace e2e-tests-downward-api-7z6z2 deletion completed in 6.533937642s

• [SLOW TEST:11.084 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:45:51.343: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-rswf6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb  6 02:45:51.689: INFO: Waiting up to 5m0s for pod "pod-5108f006-29b9-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-emptydir-rswf6" to be "success or failure"
Feb  6 02:45:51.697: INFO: Pod "pod-5108f006-29b9-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 7.274444ms
Feb  6 02:45:53.705: INFO: Pod "pod-5108f006-29b9-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015375191s
STEP: Saw pod success
Feb  6 02:45:53.705: INFO: Pod "pod-5108f006-29b9-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 02:45:53.712: INFO: Trying to get logs from node 10.190.119.175 pod pod-5108f006-29b9-11e9-b6e7-06cba7aec104 container test-container: <nil>
STEP: delete the pod
Feb  6 02:45:53.822: INFO: Waiting for pod pod-5108f006-29b9-11e9-b6e7-06cba7aec104 to disappear
Feb  6 02:45:53.832: INFO: Pod pod-5108f006-29b9-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:45:53.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-rswf6" for this suite.
Feb  6 02:46:01.878: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:46:01.968: INFO: namespace: e2e-tests-emptydir-rswf6, resource: bindings, ignored listing per whitelist
Feb  6 02:46:02.299: INFO: namespace e2e-tests-emptydir-rswf6 deletion completed in 8.456723165s

• [SLOW TEST:10.957 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:46:02.301: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-spkn7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  6 02:46:02.758: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Feb  6 02:46:02.775: INFO: Number of nodes with available pods: 0
Feb  6 02:46:02.775: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Feb  6 02:46:02.820: INFO: Number of nodes with available pods: 0
Feb  6 02:46:02.820: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 02:46:03.830: INFO: Number of nodes with available pods: 0
Feb  6 02:46:03.830: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 02:46:04.828: INFO: Number of nodes with available pods: 1
Feb  6 02:46:04.828: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Feb  6 02:46:04.869: INFO: Number of nodes with available pods: 1
Feb  6 02:46:04.869: INFO: Number of running nodes: 0, number of available pods: 1
Feb  6 02:46:05.877: INFO: Number of nodes with available pods: 0
Feb  6 02:46:05.877: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Feb  6 02:46:05.911: INFO: Number of nodes with available pods: 0
Feb  6 02:46:05.911: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 02:46:06.919: INFO: Number of nodes with available pods: 0
Feb  6 02:46:06.919: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 02:46:07.919: INFO: Number of nodes with available pods: 0
Feb  6 02:46:07.920: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 02:46:08.919: INFO: Number of nodes with available pods: 0
Feb  6 02:46:08.919: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 02:46:09.922: INFO: Number of nodes with available pods: 0
Feb  6 02:46:09.922: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 02:46:10.920: INFO: Number of nodes with available pods: 0
Feb  6 02:46:10.920: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 02:46:11.919: INFO: Number of nodes with available pods: 0
Feb  6 02:46:11.920: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 02:46:12.919: INFO: Number of nodes with available pods: 0
Feb  6 02:46:12.919: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 02:46:13.920: INFO: Number of nodes with available pods: 0
Feb  6 02:46:13.920: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 02:46:14.919: INFO: Number of nodes with available pods: 0
Feb  6 02:46:14.919: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 02:46:15.936: INFO: Number of nodes with available pods: 0
Feb  6 02:46:15.936: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 02:46:16.920: INFO: Number of nodes with available pods: 0
Feb  6 02:46:16.920: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 02:46:17.922: INFO: Number of nodes with available pods: 0
Feb  6 02:46:17.922: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 02:46:18.920: INFO: Number of nodes with available pods: 0
Feb  6 02:46:18.920: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 02:46:19.919: INFO: Number of nodes with available pods: 0
Feb  6 02:46:19.919: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 02:46:20.920: INFO: Number of nodes with available pods: 0
Feb  6 02:46:20.920: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 02:46:21.921: INFO: Number of nodes with available pods: 0
Feb  6 02:46:21.921: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 02:46:22.919: INFO: Number of nodes with available pods: 0
Feb  6 02:46:22.919: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 02:46:23.920: INFO: Number of nodes with available pods: 0
Feb  6 02:46:23.920: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 02:46:24.920: INFO: Number of nodes with available pods: 0
Feb  6 02:46:24.920: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 02:46:25.920: INFO: Number of nodes with available pods: 0
Feb  6 02:46:25.920: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 02:46:26.936: INFO: Number of nodes with available pods: 0
Feb  6 02:46:26.936: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 02:46:27.920: INFO: Number of nodes with available pods: 0
Feb  6 02:46:27.920: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 02:46:28.919: INFO: Number of nodes with available pods: 0
Feb  6 02:46:28.919: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 02:46:29.921: INFO: Number of nodes with available pods: 0
Feb  6 02:46:29.921: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 02:46:30.921: INFO: Number of nodes with available pods: 0
Feb  6 02:46:30.921: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 02:46:31.919: INFO: Number of nodes with available pods: 0
Feb  6 02:46:31.919: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 02:46:32.921: INFO: Number of nodes with available pods: 0
Feb  6 02:46:32.921: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 02:46:33.919: INFO: Number of nodes with available pods: 0
Feb  6 02:46:33.919: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 02:46:34.919: INFO: Number of nodes with available pods: 0
Feb  6 02:46:34.919: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 02:46:35.919: INFO: Number of nodes with available pods: 0
Feb  6 02:46:35.919: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 02:46:36.921: INFO: Number of nodes with available pods: 0
Feb  6 02:46:36.921: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 02:46:37.944: INFO: Number of nodes with available pods: 0
Feb  6 02:46:37.944: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 02:46:38.921: INFO: Number of nodes with available pods: 0
Feb  6 02:46:38.921: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 02:46:39.920: INFO: Number of nodes with available pods: 0
Feb  6 02:46:39.920: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 02:46:40.978: INFO: Number of nodes with available pods: 0
Feb  6 02:46:40.978: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 02:46:41.933: INFO: Number of nodes with available pods: 0
Feb  6 02:46:41.933: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 02:46:42.920: INFO: Number of nodes with available pods: 0
Feb  6 02:46:42.920: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 02:46:43.921: INFO: Number of nodes with available pods: 1
Feb  6 02:46:43.921: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-spkn7, will wait for the garbage collector to delete the pods
Feb  6 02:46:44.016: INFO: Deleting DaemonSet.extensions daemon-set took: 20.131053ms
Feb  6 02:46:44.117: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.787298ms
Feb  6 02:47:17.244: INFO: Number of nodes with available pods: 0
Feb  6 02:47:17.244: INFO: Number of running nodes: 0, number of available pods: 0
Feb  6 02:47:17.250: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-spkn7/daemonsets","resourceVersion":"62916"},"items":null}

Feb  6 02:47:17.257: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-spkn7/pods","resourceVersion":"62916"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:47:17.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-spkn7" for this suite.
Feb  6 02:47:25.358: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:47:25.685: INFO: namespace: e2e-tests-daemonsets-spkn7, resource: bindings, ignored listing per whitelist
Feb  6 02:47:25.817: INFO: namespace e2e-tests-daemonsets-spkn7 deletion completed in 8.502068124s

• [SLOW TEST:83.517 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:47:25.819: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-dgk4s
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-dgk4s.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-dgk4s.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-dgk4s.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-dgk4s.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-dgk4s.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-dgk4s.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb  6 02:47:36.684: INFO: DNS probes using e2e-tests-dns-dgk4s/dns-test-89673428-29b9-11e9-b6e7-06cba7aec104 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:47:36.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-dgk4s" for this suite.
Feb  6 02:47:42.762: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:47:42.913: INFO: namespace: e2e-tests-dns-dgk4s, resource: bindings, ignored listing per whitelist
Feb  6 02:47:43.105: INFO: namespace e2e-tests-dns-dgk4s deletion completed in 6.382020075s

• [SLOW TEST:17.286 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:47:43.106: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-qrrcz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:47:46.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-qrrcz" for this suite.
Feb  6 02:48:36.527: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:48:36.825: INFO: namespace: e2e-tests-kubelet-test-qrrcz, resource: bindings, ignored listing per whitelist
Feb  6 02:48:37.015: INFO: namespace e2e-tests-kubelet-test-qrrcz deletion completed in 50.537933401s

• [SLOW TEST:53.910 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:48:37.016: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-t4ss4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1527
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb  6 02:48:37.366: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-t4ss4'
Feb  6 02:48:37.752: INFO: stderr: ""
Feb  6 02:48:37.752: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1532
Feb  6 02:48:37.759: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-t4ss4'
Feb  6 02:48:41.744: INFO: stderr: ""
Feb  6 02:48:41.744: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:48:41.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-t4ss4" for this suite.
Feb  6 02:48:47.915: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:48:48.447: INFO: namespace: e2e-tests-kubectl-t4ss4, resource: bindings, ignored listing per whitelist
Feb  6 02:48:48.481: INFO: namespace e2e-tests-kubectl-t4ss4 deletion completed in 6.674211683s

• [SLOW TEST:11.465 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:48:48.482: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-rmz8h
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb  6 02:48:48.829: INFO: Waiting up to 5m0s for pod "pod-ba9dfbb1-29b9-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-emptydir-rmz8h" to be "success or failure"
Feb  6 02:48:48.898: INFO: Pod "pod-ba9dfbb1-29b9-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 68.775529ms
Feb  6 02:48:50.906: INFO: Pod "pod-ba9dfbb1-29b9-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.076710327s
STEP: Saw pod success
Feb  6 02:48:50.906: INFO: Pod "pod-ba9dfbb1-29b9-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 02:48:50.916: INFO: Trying to get logs from node 10.190.119.144 pod pod-ba9dfbb1-29b9-11e9-b6e7-06cba7aec104 container test-container: <nil>
STEP: delete the pod
Feb  6 02:48:50.965: INFO: Waiting for pod pod-ba9dfbb1-29b9-11e9-b6e7-06cba7aec104 to disappear
Feb  6 02:48:50.972: INFO: Pod pod-ba9dfbb1-29b9-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:48:50.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-rmz8h" for this suite.
Feb  6 02:48:57.021: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:48:57.234: INFO: namespace: e2e-tests-emptydir-rmz8h, resource: bindings, ignored listing per whitelist
Feb  6 02:48:57.323: INFO: namespace e2e-tests-emptydir-rmz8h deletion completed in 6.339336808s

• [SLOW TEST:8.841 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:48:57.324: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-zxksf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-zxksf
Feb  6 02:49:00.096: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-zxksf
STEP: checking the pod's current state and verifying that restartCount is present
Feb  6 02:49:00.111: INFO: Initial restart count of pod liveness-exec is 0
Feb  6 02:49:46.552: INFO: Restart count of pod e2e-tests-container-probe-zxksf/liveness-exec is now 1 (46.44103193s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:49:46.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-zxksf" for this suite.
Feb  6 02:49:54.636: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:49:54.822: INFO: namespace: e2e-tests-container-probe-zxksf, resource: bindings, ignored listing per whitelist
Feb  6 02:49:55.482: INFO: namespace e2e-tests-container-probe-zxksf deletion completed in 8.894780415s

• [SLOW TEST:58.158 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:49:55.482: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-mgglh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Feb  6 02:49:55.910: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 api-versions'
Feb  6 02:49:56.041: INFO: stderr: ""
Feb  6 02:49:56.041: INFO: stdout: "admissionregistration.k8s.io/v1alpha1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\nbatch/v2alpha1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:49:56.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-mgglh" for this suite.
Feb  6 02:50:02.110: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:50:02.265: INFO: namespace: e2e-tests-kubectl-mgglh, resource: bindings, ignored listing per whitelist
Feb  6 02:50:02.503: INFO: namespace e2e-tests-kubectl-mgglh deletion completed in 6.449943117s

• [SLOW TEST:7.021 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:50:02.504: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-custom-resource-definition-tt5mp
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  6 02:50:02.815: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:50:03.924: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-tt5mp" for this suite.
Feb  6 02:50:09.970: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:50:10.861: INFO: namespace: e2e-tests-custom-resource-definition-tt5mp, resource: bindings, ignored listing per whitelist
Feb  6 02:50:11.647: INFO: namespace e2e-tests-custom-resource-definition-tt5mp deletion completed in 7.712552768s

• [SLOW TEST:9.143 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:50:11.647: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-namespaces-v55cm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-fmskb
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
Feb  6 02:50:21.976: INFO: error from create uninitialized namespace: Internal error occurred: object deleted while waiting for creation
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-7sr59
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:50:50.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-v55cm" for this suite.
Feb  6 02:50:56.866: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:50:57.015: INFO: namespace: e2e-tests-namespaces-v55cm, resource: bindings, ignored listing per whitelist
Feb  6 02:50:57.212: INFO: namespace e2e-tests-namespaces-v55cm deletion completed in 6.382559014s
STEP: Destroying namespace "e2e-tests-nsdeletetest-fmskb" for this suite.
Feb  6 02:50:57.222: INFO: Namespace e2e-tests-nsdeletetest-fmskb was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-7sr59" for this suite.
Feb  6 02:51:03.256: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:51:03.314: INFO: namespace: e2e-tests-nsdeletetest-7sr59, resource: bindings, ignored listing per whitelist
Feb  6 02:51:03.617: INFO: namespace e2e-tests-nsdeletetest-7sr59 deletion completed in 6.395115486s

• [SLOW TEST:51.970 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:51:03.624: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-znc9t
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Feb  6 02:51:06.237: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-0b2d71c1-29ba-11e9-b6e7-06cba7aec104", GenerateName:"", Namespace:"e2e-tests-pods-znc9t", SelfLink:"/api/v1/namespaces/e2e-tests-pods-znc9t/pods/pod-submit-remove-0b2d71c1-29ba-11e9-b6e7-06cba7aec104", UID:"0b30913f-29ba-11e9-9423-66f50c9be06e", ResourceVersion:"63625", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63685018263, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"969552664"}, Annotations:map[string]string{"kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-bb299", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001b74040), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-bb299", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0008b9958), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"10.190.119.144", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc000b5ff20), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0008b99a0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0008b99c0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0008b99c8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0008b99cc)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685018264, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685018265, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685018265, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685018264, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.190.119.144", PodIP:"172.30.175.219", StartTime:(*v1.Time)(0xc000a9cde0), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc000a9ce00), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"docker.io/library/nginx:1.14-alpine", ImageID:"docker.io/library/nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632", ContainerID:"containerd://826cc34e34406a9fdb3fdc192dbb15b3ca9e12431cac18f4861d680f530c9b7d"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Feb  6 02:51:11.301: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:51:11.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-znc9t" for this suite.
Feb  6 02:51:17.373: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:51:17.678: INFO: namespace: e2e-tests-pods-znc9t, resource: bindings, ignored listing per whitelist
Feb  6 02:51:17.710: INFO: namespace e2e-tests-pods-znc9t deletion completed in 6.388824443s

• [SLOW TEST:14.085 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:51:17.710: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-f546p
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  6 02:51:36.259: INFO: Container started at 2019-02-06 02:51:19 +0000 UTC, pod became ready at 2019-02-06 02:51:35 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:51:36.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-f546p" for this suite.
Feb  6 02:52:00.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:52:00.429: INFO: namespace: e2e-tests-container-probe-f546p, resource: bindings, ignored listing per whitelist
Feb  6 02:52:00.684: INFO: namespace e2e-tests-container-probe-f546p deletion completed in 24.414030968s

• [SLOW TEST:42.974 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:52:00.684: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-8vh44
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb  6 02:52:05.157: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb  6 02:52:05.166: INFO: Pod pod-with-poststart-http-hook still exists
Feb  6 02:52:07.167: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb  6 02:52:07.175: INFO: Pod pod-with-poststart-http-hook still exists
Feb  6 02:52:09.167: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb  6 02:52:09.175: INFO: Pod pod-with-poststart-http-hook still exists
Feb  6 02:52:11.167: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb  6 02:52:11.196: INFO: Pod pod-with-poststart-http-hook still exists
Feb  6 02:52:13.167: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb  6 02:52:13.175: INFO: Pod pod-with-poststart-http-hook still exists
Feb  6 02:52:15.167: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb  6 02:52:15.179: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:52:15.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-8vh44" for this suite.
Feb  6 02:52:39.237: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:52:39.428: INFO: namespace: e2e-tests-container-lifecycle-hook-8vh44, resource: bindings, ignored listing per whitelist
Feb  6 02:52:39.722: INFO: namespace e2e-tests-container-lifecycle-hook-8vh44 deletion completed in 24.531918431s

• [SLOW TEST:39.038 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:52:39.725: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-q9qcd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-q9qcd
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-q9qcd
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-q9qcd
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-q9qcd
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-q9qcd
Feb  6 02:52:44.853: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-q9qcd, name: ss-0, uid: 472d7fb0-29ba-11e9-a9bb-366cc78d8813, status phase: Pending. Waiting for statefulset controller to delete.
Feb  6 02:52:45.599: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-q9qcd, name: ss-0, uid: 472d7fb0-29ba-11e9-a9bb-366cc78d8813, status phase: Failed. Waiting for statefulset controller to delete.
Feb  6 02:52:45.619: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-q9qcd, name: ss-0, uid: 472d7fb0-29ba-11e9-a9bb-366cc78d8813, status phase: Failed. Waiting for statefulset controller to delete.
Feb  6 02:52:45.637: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-q9qcd
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-q9qcd
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-q9qcd and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb  6 02:52:49.725: INFO: Deleting all statefulset in ns e2e-tests-statefulset-q9qcd
Feb  6 02:52:49.734: INFO: Scaling statefulset ss to 0
Feb  6 02:53:09.777: INFO: Waiting for statefulset status.replicas updated to 0
Feb  6 02:53:09.787: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:53:09.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-q9qcd" for this suite.
Feb  6 02:53:17.953: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:53:18.059: INFO: namespace: e2e-tests-statefulset-q9qcd, resource: bindings, ignored listing per whitelist
Feb  6 02:53:18.539: INFO: namespace e2e-tests-statefulset-q9qcd deletion completed in 8.629539578s

• [SLOW TEST:38.815 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:53:18.540: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-28dmc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  6 02:53:18.972: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5ba273df-29ba-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-projected-28dmc" to be "success or failure"
Feb  6 02:53:18.979: INFO: Pod "downwardapi-volume-5ba273df-29ba-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 7.410997ms
Feb  6 02:53:21.002: INFO: Pod "downwardapi-volume-5ba273df-29ba-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.030585078s
STEP: Saw pod success
Feb  6 02:53:21.003: INFO: Pod "downwardapi-volume-5ba273df-29ba-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 02:53:21.010: INFO: Trying to get logs from node 10.190.119.175 pod downwardapi-volume-5ba273df-29ba-11e9-b6e7-06cba7aec104 container client-container: <nil>
STEP: delete the pod
Feb  6 02:53:21.061: INFO: Waiting for pod downwardapi-volume-5ba273df-29ba-11e9-b6e7-06cba7aec104 to disappear
Feb  6 02:53:21.097: INFO: Pod downwardapi-volume-5ba273df-29ba-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:53:21.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-28dmc" for this suite.
Feb  6 02:53:27.150: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:53:27.206: INFO: namespace: e2e-tests-projected-28dmc, resource: bindings, ignored listing per whitelist
Feb  6 02:53:27.515: INFO: namespace e2e-tests-projected-28dmc deletion completed in 6.408115598s

• [SLOW TEST:8.976 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:53:27.518: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-plwv9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-60eef7db-29ba-11e9-b6e7-06cba7aec104
STEP: Creating a pod to test consume configMaps
Feb  6 02:53:27.915: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-60f0821c-29ba-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-projected-plwv9" to be "success or failure"
Feb  6 02:53:27.923: INFO: Pod "pod-projected-configmaps-60f0821c-29ba-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 8.518429ms
Feb  6 02:53:29.934: INFO: Pod "pod-projected-configmaps-60f0821c-29ba-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0188615s
STEP: Saw pod success
Feb  6 02:53:29.934: INFO: Pod "pod-projected-configmaps-60f0821c-29ba-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 02:53:29.944: INFO: Trying to get logs from node 10.190.119.145 pod pod-projected-configmaps-60f0821c-29ba-11e9-b6e7-06cba7aec104 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  6 02:53:29.990: INFO: Waiting for pod pod-projected-configmaps-60f0821c-29ba-11e9-b6e7-06cba7aec104 to disappear
Feb  6 02:53:29.998: INFO: Pod pod-projected-configmaps-60f0821c-29ba-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:53:29.998: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-plwv9" for this suite.
Feb  6 02:53:36.052: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:53:36.383: INFO: namespace: e2e-tests-projected-plwv9, resource: bindings, ignored listing per whitelist
Feb  6 02:53:36.432: INFO: namespace e2e-tests-projected-plwv9 deletion completed in 6.416482534s

• [SLOW TEST:8.914 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:53:36.433: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-fw7wz
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-66404ff3-29ba-11e9-b6e7-06cba7aec104
STEP: Creating a pod to test consume configMaps
Feb  6 02:53:36.795: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-6641c4f9-29ba-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-projected-fw7wz" to be "success or failure"
Feb  6 02:53:36.808: INFO: Pod "pod-projected-configmaps-6641c4f9-29ba-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 13.623019ms
Feb  6 02:53:38.817: INFO: Pod "pod-projected-configmaps-6641c4f9-29ba-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022531533s
STEP: Saw pod success
Feb  6 02:53:38.817: INFO: Pod "pod-projected-configmaps-6641c4f9-29ba-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 02:53:38.824: INFO: Trying to get logs from node 10.190.119.144 pod pod-projected-configmaps-6641c4f9-29ba-11e9-b6e7-06cba7aec104 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  6 02:53:38.865: INFO: Waiting for pod pod-projected-configmaps-6641c4f9-29ba-11e9-b6e7-06cba7aec104 to disappear
Feb  6 02:53:38.905: INFO: Pod pod-projected-configmaps-6641c4f9-29ba-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:53:38.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fw7wz" for this suite.
Feb  6 02:53:46.953: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:53:47.169: INFO: namespace: e2e-tests-projected-fw7wz, resource: bindings, ignored listing per whitelist
Feb  6 02:53:47.629: INFO: namespace e2e-tests-projected-fw7wz deletion completed in 8.712968837s

• [SLOW TEST:11.197 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:53:47.629: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-7d5ps
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-6cf8bfd4-29ba-11e9-b6e7-06cba7aec104
STEP: Creating a pod to test consume secrets
Feb  6 02:53:48.076: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-6cfa7994-29ba-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-projected-7d5ps" to be "success or failure"
Feb  6 02:53:48.083: INFO: Pod "pod-projected-secrets-6cfa7994-29ba-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 6.839121ms
Feb  6 02:53:50.092: INFO: Pod "pod-projected-secrets-6cfa7994-29ba-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015903971s
STEP: Saw pod success
Feb  6 02:53:50.093: INFO: Pod "pod-projected-secrets-6cfa7994-29ba-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 02:53:50.101: INFO: Trying to get logs from node 10.190.119.145 pod pod-projected-secrets-6cfa7994-29ba-11e9-b6e7-06cba7aec104 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb  6 02:53:50.146: INFO: Waiting for pod pod-projected-secrets-6cfa7994-29ba-11e9-b6e7-06cba7aec104 to disappear
Feb  6 02:53:50.197: INFO: Pod pod-projected-secrets-6cfa7994-29ba-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:53:50.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7d5ps" for this suite.
Feb  6 02:53:56.246: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:53:56.432: INFO: namespace: e2e-tests-projected-7d5ps, resource: bindings, ignored listing per whitelist
Feb  6 02:53:56.633: INFO: namespace e2e-tests-projected-7d5ps deletion completed in 6.424964936s

• [SLOW TEST:9.003 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:53:56.633: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-k9v9n
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Feb  6 02:53:57.514: INFO: Waiting up to 5m0s for pod "client-containers-729bb95e-29ba-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-containers-k9v9n" to be "success or failure"
Feb  6 02:53:57.523: INFO: Pod "client-containers-729bb95e-29ba-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 8.744941ms
Feb  6 02:53:59.530: INFO: Pod "client-containers-729bb95e-29ba-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016276266s
STEP: Saw pod success
Feb  6 02:53:59.530: INFO: Pod "client-containers-729bb95e-29ba-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 02:53:59.537: INFO: Trying to get logs from node 10.190.119.145 pod client-containers-729bb95e-29ba-11e9-b6e7-06cba7aec104 container test-container: <nil>
STEP: delete the pod
Feb  6 02:53:59.623: INFO: Waiting for pod client-containers-729bb95e-29ba-11e9-b6e7-06cba7aec104 to disappear
Feb  6 02:53:59.636: INFO: Pod client-containers-729bb95e-29ba-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:53:59.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-k9v9n" for this suite.
Feb  6 02:54:06.425: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:54:06.516: INFO: namespace: e2e-tests-containers-k9v9n, resource: bindings, ignored listing per whitelist
Feb  6 02:54:06.806: INFO: namespace e2e-tests-containers-k9v9n deletion completed in 7.156063107s

• [SLOW TEST:10.173 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:54:06.807: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-jslkg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  6 02:54:07.135: INFO: Creating deployment "test-recreate-deployment"
Feb  6 02:54:07.145: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Feb  6 02:54:07.164: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Feb  6 02:54:09.194: INFO: Waiting deployment "test-recreate-deployment" to complete
Feb  6 02:54:09.204: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Feb  6 02:54:09.298: INFO: Updating deployment test-recreate-deployment
Feb  6 02:54:09.298: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb  6 02:54:09.390: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-jslkg,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-jslkg/deployments/test-recreate-deployment,UID:785a2db2-29ba-11e9-9423-66f50c9be06e,ResourceVersion:64503,Generation:2,CreationTimestamp:2019-02-06 02:54:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-02-06 02:54:09 +0000 UTC 2019-02-06 02:54:09 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-02-06 02:54:09 +0000 UTC 2019-02-06 02:54:07 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-697fbf54bf" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Feb  6 02:54:09.402: INFO: New ReplicaSet "test-recreate-deployment-697fbf54bf" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf,GenerateName:,Namespace:e2e-tests-deployment-jslkg,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-jslkg/replicasets/test-recreate-deployment-697fbf54bf,UID:79a50545-29ba-11e9-a9bb-366cc78d8813,ResourceVersion:64501,Generation:1,CreationTimestamp:2019-02-06 02:54:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 785a2db2-29ba-11e9-9423-66f50c9be06e 0xc0020f5a67 0xc0020f5a68}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb  6 02:54:09.402: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Feb  6 02:54:09.403: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5dfdcc846d,GenerateName:,Namespace:e2e-tests-deployment-jslkg,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-jslkg/replicasets/test-recreate-deployment-5dfdcc846d,UID:785e164f-29ba-11e9-a9bb-366cc78d8813,ResourceVersion:64491,Generation:2,CreationTimestamp:2019-02-06 02:54:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 785a2db2-29ba-11e9-9423-66f50c9be06e 0xc0020f59a7 0xc0020f59a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb  6 02:54:09.413: INFO: Pod "test-recreate-deployment-697fbf54bf-pssqt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf-pssqt,GenerateName:test-recreate-deployment-697fbf54bf-,Namespace:e2e-tests-deployment-jslkg,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jslkg/pods/test-recreate-deployment-697fbf54bf-pssqt,UID:79a726cf-29ba-11e9-a9bb-366cc78d8813,ResourceVersion:64502,Generation:0,CreationTimestamp:2019-02-06 02:54:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-697fbf54bf 79a50545-29ba-11e9-a9bb-366cc78d8813 0xc002b30207 0xc002b30208}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4qbxn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4qbxn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4qbxn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b30370} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b30390}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:54:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:54:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:54:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:54:09 +0000 UTC  }],Message:,Reason:,HostIP:10.190.119.145,PodIP:,StartTime:2019-02-06 02:54:09 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:54:09.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-jslkg" for this suite.
Feb  6 02:54:15.481: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:54:15.646: INFO: namespace: e2e-tests-deployment-jslkg, resource: bindings, ignored listing per whitelist
Feb  6 02:54:15.787: INFO: namespace e2e-tests-deployment-jslkg deletion completed in 6.361424346s

• [SLOW TEST:8.981 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:54:15.790: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-r4vjc
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-7db4446c-29ba-11e9-b6e7-06cba7aec104
STEP: Creating secret with name s-test-opt-upd-7db444c9-29ba-11e9-b6e7-06cba7aec104
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-7db4446c-29ba-11e9-b6e7-06cba7aec104
STEP: Updating secret s-test-opt-upd-7db444c9-29ba-11e9-b6e7-06cba7aec104
STEP: Creating secret with name s-test-opt-create-7db444e9-29ba-11e9-b6e7-06cba7aec104
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:54:20.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-r4vjc" for this suite.
Feb  6 02:54:44.518: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:54:44.711: INFO: namespace: e2e-tests-secrets-r4vjc, resource: bindings, ignored listing per whitelist
Feb  6 02:54:44.952: INFO: namespace e2e-tests-secrets-r4vjc deletion completed in 24.483811397s

• [SLOW TEST:29.162 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:54:44.952: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-8mwcz
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-8f17d797-29ba-11e9-b6e7-06cba7aec104
STEP: Creating a pod to test consume secrets
Feb  6 02:54:45.317: INFO: Waiting up to 5m0s for pod "pod-secrets-8f19aa2b-29ba-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-secrets-8mwcz" to be "success or failure"
Feb  6 02:54:45.326: INFO: Pod "pod-secrets-8f19aa2b-29ba-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 9.372194ms
Feb  6 02:54:47.344: INFO: Pod "pod-secrets-8f19aa2b-29ba-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027427536s
STEP: Saw pod success
Feb  6 02:54:47.345: INFO: Pod "pod-secrets-8f19aa2b-29ba-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 02:54:47.355: INFO: Trying to get logs from node 10.190.119.144 pod pod-secrets-8f19aa2b-29ba-11e9-b6e7-06cba7aec104 container secret-volume-test: <nil>
STEP: delete the pod
Feb  6 02:54:47.405: INFO: Waiting for pod pod-secrets-8f19aa2b-29ba-11e9-b6e7-06cba7aec104 to disappear
Feb  6 02:54:47.412: INFO: Pod pod-secrets-8f19aa2b-29ba-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:54:47.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-8mwcz" for this suite.
Feb  6 02:54:53.458: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:54:53.731: INFO: namespace: e2e-tests-secrets-8mwcz, resource: bindings, ignored listing per whitelist
Feb  6 02:54:53.798: INFO: namespace e2e-tests-secrets-8mwcz deletion completed in 6.375094582s

• [SLOW TEST:8.846 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:54:53.799: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-f26nw
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-94785ea9-29ba-11e9-b6e7-06cba7aec104
STEP: Creating configMap with name cm-test-opt-upd-94785f4f-29ba-11e9-b6e7-06cba7aec104
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-94785ea9-29ba-11e9-b6e7-06cba7aec104
STEP: Updating configmap cm-test-opt-upd-94785f4f-29ba-11e9-b6e7-06cba7aec104
STEP: Creating configMap with name cm-test-opt-create-94785f6d-29ba-11e9-b6e7-06cba7aec104
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:54:58.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-f26nw" for this suite.
Feb  6 02:55:22.620: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:55:23.226: INFO: namespace: e2e-tests-projected-f26nw, resource: bindings, ignored listing per whitelist
Feb  6 02:55:23.270: INFO: namespace e2e-tests-projected-f26nw deletion completed in 24.703484101s

• [SLOW TEST:29.471 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:55:23.273: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-rwqps
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  6 02:55:23.624: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Feb  6 02:55:23.645: INFO: Pod name sample-pod: Found 0 pods out of 1
Feb  6 02:55:28.654: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb  6 02:55:28.654: INFO: Creating deployment "test-rolling-update-deployment"
Feb  6 02:55:28.665: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Feb  6 02:55:28.686: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Feb  6 02:55:30.706: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Feb  6 02:55:30.716: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb  6 02:55:30.743: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-rwqps,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-rwqps/deployments/test-rolling-update-deployment,UID:a8f100e2-29ba-11e9-9423-66f50c9be06e,ResourceVersion:64877,Generation:1,CreationTimestamp:2019-02-06 02:55:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-02-06 02:55:28 +0000 UTC 2019-02-06 02:55:28 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-02-06 02:55:30 +0000 UTC 2019-02-06 02:55:28 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-68b55d7bc6" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Feb  6 02:55:30.752: INFO: New ReplicaSet "test-rolling-update-deployment-68b55d7bc6" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6,GenerateName:,Namespace:e2e-tests-deployment-rwqps,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-rwqps/replicasets/test-rolling-update-deployment-68b55d7bc6,UID:a8f83903-29ba-11e9-a9bb-366cc78d8813,ResourceVersion:64867,Generation:1,CreationTimestamp:2019-02-06 02:55:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment a8f100e2-29ba-11e9-9423-66f50c9be06e 0xc0026df067 0xc0026df068}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb  6 02:55:30.752: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Feb  6 02:55:30.753: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-rwqps,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-rwqps/replicasets/test-rolling-update-controller,UID:a5f18d66-29ba-11e9-9423-66f50c9be06e,ResourceVersion:64876,Generation:2,CreationTimestamp:2019-02-06 02:55:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment a8f100e2-29ba-11e9-9423-66f50c9be06e 0xc0026def97 0xc0026def98}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb  6 02:55:30.760: INFO: Pod "test-rolling-update-deployment-68b55d7bc6-vdc75" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6-vdc75,GenerateName:test-rolling-update-deployment-68b55d7bc6-,Namespace:e2e-tests-deployment-rwqps,SelfLink:/api/v1/namespaces/e2e-tests-deployment-rwqps/pods/test-rolling-update-deployment-68b55d7bc6-vdc75,UID:a8fa1dbd-29ba-11e9-a9bb-366cc78d8813,ResourceVersion:64866,Generation:0,CreationTimestamp:2019-02-06 02:55:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-68b55d7bc6 a8f83903-29ba-11e9-a9bb-366cc78d8813 0xc002cc45c7 0xc002cc45c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-79msl {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-79msl,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-79msl true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002cc46d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002cc46f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:55:28 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:55:30 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:55:30 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:55:28 +0000 UTC  }],Message:,Reason:,HostIP:10.190.119.145,PodIP:172.30.70.253,StartTime:2019-02-06 02:55:28 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-02-06 02:55:29 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://9d1d8db02e565138a58d17fb6ecef83b871b378691f07d21d2874cd239dc0c47}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:55:30.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-rwqps" for this suite.
Feb  6 02:55:38.835: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:55:39.576: INFO: namespace: e2e-tests-deployment-rwqps, resource: bindings, ignored listing per whitelist
Feb  6 02:55:39.642: INFO: namespace e2e-tests-deployment-rwqps deletion completed in 8.868770702s

• [SLOW TEST:16.369 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:55:39.642: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-kpr4z
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Feb  6 02:55:39.998: INFO: Waiting up to 5m0s for pod "var-expansion-afb15575-29ba-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-var-expansion-kpr4z" to be "success or failure"
Feb  6 02:55:40.008: INFO: Pod "var-expansion-afb15575-29ba-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 9.997503ms
Feb  6 02:55:42.017: INFO: Pod "var-expansion-afb15575-29ba-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019407618s
STEP: Saw pod success
Feb  6 02:55:42.017: INFO: Pod "var-expansion-afb15575-29ba-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 02:55:42.026: INFO: Trying to get logs from node 10.190.119.145 pod var-expansion-afb15575-29ba-11e9-b6e7-06cba7aec104 container dapi-container: <nil>
STEP: delete the pod
Feb  6 02:55:42.072: INFO: Waiting for pod var-expansion-afb15575-29ba-11e9-b6e7-06cba7aec104 to disappear
Feb  6 02:55:42.097: INFO: Pod var-expansion-afb15575-29ba-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:55:42.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-kpr4z" for this suite.
Feb  6 02:55:50.148: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:55:50.262: INFO: namespace: e2e-tests-var-expansion-kpr4z, resource: bindings, ignored listing per whitelist
Feb  6 02:55:50.521: INFO: namespace e2e-tests-var-expansion-kpr4z deletion completed in 8.413021785s

• [SLOW TEST:10.880 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:55:50.524: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-2tm95
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-b62dbdc9-29ba-11e9-b6e7-06cba7aec104
STEP: Creating a pod to test consume secrets
Feb  6 02:55:50.917: INFO: Waiting up to 5m0s for pod "pod-secrets-b6332e79-29ba-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-secrets-2tm95" to be "success or failure"
Feb  6 02:55:50.924: INFO: Pod "pod-secrets-b6332e79-29ba-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 7.177954ms
Feb  6 02:55:52.932: INFO: Pod "pod-secrets-b6332e79-29ba-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014902889s
Feb  6 02:55:54.959: INFO: Pod "pod-secrets-b6332e79-29ba-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.042127485s
STEP: Saw pod success
Feb  6 02:55:54.959: INFO: Pod "pod-secrets-b6332e79-29ba-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 02:55:54.966: INFO: Trying to get logs from node 10.190.119.145 pod pod-secrets-b6332e79-29ba-11e9-b6e7-06cba7aec104 container secret-volume-test: <nil>
STEP: delete the pod
Feb  6 02:55:55.008: INFO: Waiting for pod pod-secrets-b6332e79-29ba-11e9-b6e7-06cba7aec104 to disappear
Feb  6 02:55:55.016: INFO: Pod pod-secrets-b6332e79-29ba-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:55:55.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-2tm95" for this suite.
Feb  6 02:56:01.061: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:56:01.242: INFO: namespace: e2e-tests-secrets-2tm95, resource: bindings, ignored listing per whitelist
Feb  6 02:56:01.434: INFO: namespace e2e-tests-secrets-2tm95 deletion completed in 6.406674358s

• [SLOW TEST:10.910 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:56:01.435: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-b2bgq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  6 02:56:01.776: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bcac9daf-29ba-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-downward-api-b2bgq" to be "success or failure"
Feb  6 02:56:01.804: INFO: Pod "downwardapi-volume-bcac9daf-29ba-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 28.064634ms
Feb  6 02:56:03.813: INFO: Pod "downwardapi-volume-bcac9daf-29ba-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.037273377s
STEP: Saw pod success
Feb  6 02:56:03.814: INFO: Pod "downwardapi-volume-bcac9daf-29ba-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 02:56:03.821: INFO: Trying to get logs from node 10.190.119.144 pod downwardapi-volume-bcac9daf-29ba-11e9-b6e7-06cba7aec104 container client-container: <nil>
STEP: delete the pod
Feb  6 02:56:03.922: INFO: Waiting for pod downwardapi-volume-bcac9daf-29ba-11e9-b6e7-06cba7aec104 to disappear
Feb  6 02:56:03.928: INFO: Pod downwardapi-volume-bcac9daf-29ba-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:56:03.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-b2bgq" for this suite.
Feb  6 02:56:09.974: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:56:10.017: INFO: namespace: e2e-tests-downward-api-b2bgq, resource: bindings, ignored listing per whitelist
Feb  6 02:56:10.425: INFO: namespace e2e-tests-downward-api-b2bgq deletion completed in 6.487933978s

• [SLOW TEST:8.991 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:56:10.427: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-r4kj7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb  6 02:56:10.897: INFO: Waiting up to 5m0s for pod "pod-c21538dc-29ba-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-emptydir-r4kj7" to be "success or failure"
Feb  6 02:56:10.905: INFO: Pod "pod-c21538dc-29ba-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 8.024541ms
Feb  6 02:56:12.913: INFO: Pod "pod-c21538dc-29ba-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015843724s
STEP: Saw pod success
Feb  6 02:56:12.913: INFO: Pod "pod-c21538dc-29ba-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 02:56:12.921: INFO: Trying to get logs from node 10.190.119.145 pod pod-c21538dc-29ba-11e9-b6e7-06cba7aec104 container test-container: <nil>
STEP: delete the pod
Feb  6 02:56:12.969: INFO: Waiting for pod pod-c21538dc-29ba-11e9-b6e7-06cba7aec104 to disappear
Feb  6 02:56:12.985: INFO: Pod pod-c21538dc-29ba-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:56:12.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-r4kj7" for this suite.
Feb  6 02:56:21.048: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:56:21.196: INFO: namespace: e2e-tests-emptydir-r4kj7, resource: bindings, ignored listing per whitelist
Feb  6 02:56:21.388: INFO: namespace e2e-tests-emptydir-r4kj7 deletion completed in 8.387873719s

• [SLOW TEST:10.961 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:56:21.389: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-rhr54
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-6hvq
STEP: Creating a pod to test atomic-volume-subpath
Feb  6 02:56:21.825: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-6hvq" in namespace "e2e-tests-subpath-rhr54" to be "success or failure"
Feb  6 02:56:21.834: INFO: Pod "pod-subpath-test-configmap-6hvq": Phase="Pending", Reason="", readiness=false. Elapsed: 9.710673ms
Feb  6 02:56:23.842: INFO: Pod "pod-subpath-test-configmap-6hvq": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017500475s
Feb  6 02:56:25.852: INFO: Pod "pod-subpath-test-configmap-6hvq": Phase="Running", Reason="", readiness=false. Elapsed: 4.027261976s
Feb  6 02:56:27.875: INFO: Pod "pod-subpath-test-configmap-6hvq": Phase="Running", Reason="", readiness=false. Elapsed: 6.05045133s
Feb  6 02:56:29.884: INFO: Pod "pod-subpath-test-configmap-6hvq": Phase="Running", Reason="", readiness=false. Elapsed: 8.059198653s
Feb  6 02:56:31.892: INFO: Pod "pod-subpath-test-configmap-6hvq": Phase="Running", Reason="", readiness=false. Elapsed: 10.067180134s
Feb  6 02:56:33.899: INFO: Pod "pod-subpath-test-configmap-6hvq": Phase="Running", Reason="", readiness=false. Elapsed: 12.074786498s
Feb  6 02:56:35.908: INFO: Pod "pod-subpath-test-configmap-6hvq": Phase="Running", Reason="", readiness=false. Elapsed: 14.083153124s
Feb  6 02:56:37.933: INFO: Pod "pod-subpath-test-configmap-6hvq": Phase="Running", Reason="", readiness=false. Elapsed: 16.108080923s
Feb  6 02:56:39.942: INFO: Pod "pod-subpath-test-configmap-6hvq": Phase="Running", Reason="", readiness=false. Elapsed: 18.116973627s
Feb  6 02:56:41.949: INFO: Pod "pod-subpath-test-configmap-6hvq": Phase="Running", Reason="", readiness=false. Elapsed: 20.124412204s
Feb  6 02:56:43.957: INFO: Pod "pod-subpath-test-configmap-6hvq": Phase="Running", Reason="", readiness=false. Elapsed: 22.132381286s
Feb  6 02:56:45.966: INFO: Pod "pod-subpath-test-configmap-6hvq": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.140965796s
STEP: Saw pod success
Feb  6 02:56:45.966: INFO: Pod "pod-subpath-test-configmap-6hvq" satisfied condition "success or failure"
Feb  6 02:56:45.973: INFO: Trying to get logs from node 10.190.119.145 pod pod-subpath-test-configmap-6hvq container test-container-subpath-configmap-6hvq: <nil>
STEP: delete the pod
Feb  6 02:56:46.018: INFO: Waiting for pod pod-subpath-test-configmap-6hvq to disappear
Feb  6 02:56:46.029: INFO: Pod pod-subpath-test-configmap-6hvq no longer exists
STEP: Deleting pod pod-subpath-test-configmap-6hvq
Feb  6 02:56:46.029: INFO: Deleting pod "pod-subpath-test-configmap-6hvq" in namespace "e2e-tests-subpath-rhr54"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:56:46.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-rhr54" for this suite.
Feb  6 02:56:52.713: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:56:52.939: INFO: namespace: e2e-tests-subpath-rhr54, resource: bindings, ignored listing per whitelist
Feb  6 02:56:53.308: INFO: namespace e2e-tests-subpath-rhr54 deletion completed in 6.633849079s

• [SLOW TEST:31.920 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:56:53.311: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-gzwkj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  6 02:56:53.816: INFO: Waiting up to 5m0s for pod "downwardapi-volume-dba96021-29ba-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-projected-gzwkj" to be "success or failure"
Feb  6 02:56:53.825: INFO: Pod "downwardapi-volume-dba96021-29ba-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 9.080929ms
Feb  6 02:56:55.839: INFO: Pod "downwardapi-volume-dba96021-29ba-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023054041s
STEP: Saw pod success
Feb  6 02:56:55.839: INFO: Pod "downwardapi-volume-dba96021-29ba-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 02:56:55.850: INFO: Trying to get logs from node 10.190.119.144 pod downwardapi-volume-dba96021-29ba-11e9-b6e7-06cba7aec104 container client-container: <nil>
STEP: delete the pod
Feb  6 02:56:55.899: INFO: Waiting for pod downwardapi-volume-dba96021-29ba-11e9-b6e7-06cba7aec104 to disappear
Feb  6 02:56:55.909: INFO: Pod downwardapi-volume-dba96021-29ba-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:56:55.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gzwkj" for this suite.
Feb  6 02:57:01.957: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:57:02.035: INFO: namespace: e2e-tests-projected-gzwkj, resource: bindings, ignored listing per whitelist
Feb  6 02:57:02.400: INFO: namespace e2e-tests-projected-gzwkj deletion completed in 6.478790466s

• [SLOW TEST:9.090 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:57:02.401: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-pxfjz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  6 02:57:04.805: INFO: Waiting up to 5m0s for pod "client-envvars-e23eca49-29ba-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-pods-pxfjz" to be "success or failure"
Feb  6 02:57:04.897: INFO: Pod "client-envvars-e23eca49-29ba-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 92.55403ms
Feb  6 02:57:06.905: INFO: Pod "client-envvars-e23eca49-29ba-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.100825615s
STEP: Saw pod success
Feb  6 02:57:06.906: INFO: Pod "client-envvars-e23eca49-29ba-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 02:57:06.913: INFO: Trying to get logs from node 10.190.119.175 pod client-envvars-e23eca49-29ba-11e9-b6e7-06cba7aec104 container env3cont: <nil>
STEP: delete the pod
Feb  6 02:57:06.959: INFO: Waiting for pod client-envvars-e23eca49-29ba-11e9-b6e7-06cba7aec104 to disappear
Feb  6 02:57:06.997: INFO: Pod client-envvars-e23eca49-29ba-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:57:06.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-pxfjz" for this suite.
Feb  6 02:57:59.059: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:57:59.317: INFO: namespace: e2e-tests-pods-pxfjz, resource: bindings, ignored listing per whitelist
Feb  6 02:57:59.415: INFO: namespace e2e-tests-pods-pxfjz deletion completed in 52.405845781s

• [SLOW TEST:57.015 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:57:59.416: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-6fbps
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Feb  6 02:57:59.884: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-6fbps,SelfLink:/api/v1/namespaces/e2e-tests-watch-6fbps/configmaps/e2e-watch-test-watch-closed,UID:0310b8e0-29bb-11e9-9423-66f50c9be06e,ResourceVersion:65492,Generation:0,CreationTimestamp:2019-02-06 02:57:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb  6 02:57:59.884: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-6fbps,SelfLink:/api/v1/namespaces/e2e-tests-watch-6fbps/configmaps/e2e-watch-test-watch-closed,UID:0310b8e0-29bb-11e9-9423-66f50c9be06e,ResourceVersion:65493,Generation:0,CreationTimestamp:2019-02-06 02:57:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Feb  6 02:57:59.921: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-6fbps,SelfLink:/api/v1/namespaces/e2e-tests-watch-6fbps/configmaps/e2e-watch-test-watch-closed,UID:0310b8e0-29bb-11e9-9423-66f50c9be06e,ResourceVersion:65494,Generation:0,CreationTimestamp:2019-02-06 02:57:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb  6 02:57:59.921: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-6fbps,SelfLink:/api/v1/namespaces/e2e-tests-watch-6fbps/configmaps/e2e-watch-test-watch-closed,UID:0310b8e0-29bb-11e9-9423-66f50c9be06e,ResourceVersion:65495,Generation:0,CreationTimestamp:2019-02-06 02:57:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:57:59.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-6fbps" for this suite.
Feb  6 02:58:05.985: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:58:06.018: INFO: namespace: e2e-tests-watch-6fbps, resource: bindings, ignored listing per whitelist
Feb  6 02:58:06.422: INFO: namespace e2e-tests-watch-6fbps deletion completed in 6.490555739s

• [SLOW TEST:7.006 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:58:06.423: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-4vztn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-072a8318-29bb-11e9-b6e7-06cba7aec104
STEP: Creating a pod to test consume configMaps
Feb  6 02:58:06.764: INFO: Waiting up to 5m0s for pod "pod-configmaps-072be71b-29bb-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-configmap-4vztn" to be "success or failure"
Feb  6 02:58:06.772: INFO: Pod "pod-configmaps-072be71b-29bb-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 7.937425ms
Feb  6 02:58:08.781: INFO: Pod "pod-configmaps-072be71b-29bb-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016350406s
STEP: Saw pod success
Feb  6 02:58:08.781: INFO: Pod "pod-configmaps-072be71b-29bb-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 02:58:08.792: INFO: Trying to get logs from node 10.190.119.144 pod pod-configmaps-072be71b-29bb-11e9-b6e7-06cba7aec104 container configmap-volume-test: <nil>
STEP: delete the pod
Feb  6 02:58:08.839: INFO: Waiting for pod pod-configmaps-072be71b-29bb-11e9-b6e7-06cba7aec104 to disappear
Feb  6 02:58:08.846: INFO: Pod pod-configmaps-072be71b-29bb-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 02:58:08.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-4vztn" for this suite.
Feb  6 02:58:14.899: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:58:15.054: INFO: namespace: e2e-tests-configmap-4vztn, resource: bindings, ignored listing per whitelist
Feb  6 02:58:15.330: INFO: namespace e2e-tests-configmap-4vztn deletion completed in 6.473647256s

• [SLOW TEST:8.907 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 02:58:15.332: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-wtkhg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-wtkhg
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Feb  6 02:58:15.766: INFO: Found 0 stateful pods, waiting for 3
Feb  6 02:58:25.793: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb  6 02:58:25.793: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb  6 02:58:25.793: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Feb  6 02:58:25.819: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-wtkhg ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  6 02:58:26.162: INFO: stderr: ""
Feb  6 02:58:26.162: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  6 02:58:26.162: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Feb  6 02:58:36.523: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Feb  6 02:58:46.595: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-wtkhg ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 02:58:46.974: INFO: stderr: ""
Feb  6 02:58:46.974: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  6 02:58:46.974: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb  6 02:58:57.056: INFO: Waiting for StatefulSet e2e-tests-statefulset-wtkhg/ss2 to complete update
Feb  6 02:58:57.056: INFO: Waiting for Pod e2e-tests-statefulset-wtkhg/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Feb  6 02:59:07.092: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-wtkhg ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  6 02:59:07.501: INFO: stderr: ""
Feb  6 02:59:07.501: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  6 02:59:07.501: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  6 02:59:17.598: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Feb  6 02:59:27.660: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 exec --namespace=e2e-tests-statefulset-wtkhg ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 02:59:28.209: INFO: stderr: ""
Feb  6 02:59:28.209: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  6 02:59:28.209: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb  6 02:59:48.379: INFO: Waiting for StatefulSet e2e-tests-statefulset-wtkhg/ss2 to complete update
Feb  6 02:59:48.379: INFO: Waiting for Pod e2e-tests-statefulset-wtkhg/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb  6 02:59:58.412: INFO: Deleting all statefulset in ns e2e-tests-statefulset-wtkhg
Feb  6 02:59:58.422: INFO: Scaling statefulset ss2 to 0
Feb  6 03:00:18.468: INFO: Waiting for statefulset status.replicas updated to 0
Feb  6 03:00:18.478: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:00:18.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-wtkhg" for this suite.
Feb  6 03:00:26.623: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:00:27.091: INFO: namespace: e2e-tests-statefulset-wtkhg, resource: bindings, ignored listing per whitelist
Feb  6 03:00:27.107: INFO: namespace e2e-tests-statefulset-wtkhg deletion completed in 8.550589521s

• [SLOW TEST:131.775 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:00:27.108: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-rvqst
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb  6 03:00:34.164: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  6 03:00:34.172: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  6 03:00:36.173: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  6 03:00:36.183: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  6 03:00:38.173: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  6 03:00:38.180: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  6 03:00:40.173: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  6 03:00:40.204: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  6 03:00:42.173: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  6 03:00:42.181: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  6 03:00:44.173: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  6 03:00:44.182: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  6 03:00:46.173: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  6 03:00:46.181: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  6 03:00:48.173: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  6 03:00:48.182: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  6 03:00:50.173: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  6 03:00:50.181: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  6 03:00:52.173: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  6 03:00:52.197: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  6 03:00:54.173: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  6 03:00:54.180: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  6 03:00:56.173: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  6 03:00:56.181: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  6 03:00:58.172: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  6 03:00:58.180: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  6 03:01:00.173: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  6 03:01:00.180: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  6 03:01:02.173: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  6 03:01:02.180: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:01:02.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-rvqst" for this suite.
Feb  6 03:01:26.244: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:01:26.378: INFO: namespace: e2e-tests-container-lifecycle-hook-rvqst, resource: bindings, ignored listing per whitelist
Feb  6 03:01:27.315: INFO: namespace e2e-tests-container-lifecycle-hook-rvqst deletion completed in 25.124138152s

• [SLOW TEST:60.207 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:01:27.316: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-rnd6k
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0206 03:01:34.017318      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb  6 03:01:34.017: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:01:34.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-rnd6k" for this suite.
Feb  6 03:01:42.118: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:01:42.800: INFO: namespace: e2e-tests-gc-rnd6k, resource: bindings, ignored listing per whitelist
Feb  6 03:01:42.815: INFO: namespace e2e-tests-gc-rnd6k deletion completed in 8.787804316s

• [SLOW TEST:15.499 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:01:42.817: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-87qtd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-882a2036-29bb-11e9-b6e7-06cba7aec104
STEP: Creating a pod to test consume secrets
Feb  6 03:01:43.230: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-8831f305-29bb-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-projected-87qtd" to be "success or failure"
Feb  6 03:01:43.244: INFO: Pod "pod-projected-secrets-8831f305-29bb-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 14.346634ms
Feb  6 03:01:45.256: INFO: Pod "pod-projected-secrets-8831f305-29bb-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.026503342s
STEP: Saw pod success
Feb  6 03:01:45.256: INFO: Pod "pod-projected-secrets-8831f305-29bb-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 03:01:45.264: INFO: Trying to get logs from node 10.190.119.145 pod pod-projected-secrets-8831f305-29bb-11e9-b6e7-06cba7aec104 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb  6 03:01:45.310: INFO: Waiting for pod pod-projected-secrets-8831f305-29bb-11e9-b6e7-06cba7aec104 to disappear
Feb  6 03:01:45.317: INFO: Pod pod-projected-secrets-8831f305-29bb-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:01:45.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-87qtd" for this suite.
Feb  6 03:01:51.366: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:01:51.389: INFO: namespace: e2e-tests-projected-87qtd, resource: bindings, ignored listing per whitelist
Feb  6 03:01:52.674: INFO: namespace e2e-tests-projected-87qtd deletion completed in 7.346926727s

• [SLOW TEST:9.858 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:01:52.677: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-c6cbh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb  6 03:01:53.117: INFO: Waiting up to 5m0s for pod "pod-8e11cda1-29bb-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-emptydir-c6cbh" to be "success or failure"
Feb  6 03:01:53.126: INFO: Pod "pod-8e11cda1-29bb-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 8.665924ms
Feb  6 03:01:55.134: INFO: Pod "pod-8e11cda1-29bb-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016811708s
STEP: Saw pod success
Feb  6 03:01:55.134: INFO: Pod "pod-8e11cda1-29bb-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 03:01:55.142: INFO: Trying to get logs from node 10.190.119.175 pod pod-8e11cda1-29bb-11e9-b6e7-06cba7aec104 container test-container: <nil>
STEP: delete the pod
Feb  6 03:01:55.197: INFO: Waiting for pod pod-8e11cda1-29bb-11e9-b6e7-06cba7aec104 to disappear
Feb  6 03:01:55.207: INFO: Pod pod-8e11cda1-29bb-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:01:55.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-c6cbh" for this suite.
Feb  6 03:02:01.262: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:02:01.375: INFO: namespace: e2e-tests-emptydir-c6cbh, resource: bindings, ignored listing per whitelist
Feb  6 03:02:01.674: INFO: namespace e2e-tests-emptydir-c6cbh deletion completed in 6.456721013s

• [SLOW TEST:8.998 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:02:01.677: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-tg2h7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  6 03:02:02.097: INFO: Waiting up to 5m0s for pod "downwardapi-volume-936ba7e1-29bb-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-projected-tg2h7" to be "success or failure"
Feb  6 03:02:02.109: INFO: Pod "downwardapi-volume-936ba7e1-29bb-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 12.037239ms
Feb  6 03:02:04.124: INFO: Pod "downwardapi-volume-936ba7e1-29bb-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.026711605s
STEP: Saw pod success
Feb  6 03:02:04.124: INFO: Pod "downwardapi-volume-936ba7e1-29bb-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 03:02:04.132: INFO: Trying to get logs from node 10.190.119.175 pod downwardapi-volume-936ba7e1-29bb-11e9-b6e7-06cba7aec104 container client-container: <nil>
STEP: delete the pod
Feb  6 03:02:04.176: INFO: Waiting for pod downwardapi-volume-936ba7e1-29bb-11e9-b6e7-06cba7aec104 to disappear
Feb  6 03:02:04.185: INFO: Pod downwardapi-volume-936ba7e1-29bb-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:02:04.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-tg2h7" for this suite.
Feb  6 03:02:12.244: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:02:12.365: INFO: namespace: e2e-tests-projected-tg2h7, resource: bindings, ignored listing per whitelist
Feb  6 03:02:12.583: INFO: namespace e2e-tests-projected-tg2h7 deletion completed in 8.376083006s

• [SLOW TEST:10.906 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:02:12.583: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-96ctr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:02:12.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-96ctr" for this suite.
Feb  6 03:02:36.974: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:02:37.159: INFO: namespace: e2e-tests-pods-96ctr, resource: bindings, ignored listing per whitelist
Feb  6 03:02:37.315: INFO: namespace e2e-tests-pods-96ctr deletion completed in 24.37681244s

• [SLOW TEST:24.732 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:02:37.315: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-wqqrz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  6 03:02:37.714: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a8a943a8-29bb-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-downward-api-wqqrz" to be "success or failure"
Feb  6 03:02:37.725: INFO: Pod "downwardapi-volume-a8a943a8-29bb-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 11.005712ms
Feb  6 03:02:39.734: INFO: Pod "downwardapi-volume-a8a943a8-29bb-11e9-b6e7-06cba7aec104": Phase="Running", Reason="", readiness=true. Elapsed: 2.019959039s
Feb  6 03:02:41.741: INFO: Pod "downwardapi-volume-a8a943a8-29bb-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027496383s
STEP: Saw pod success
Feb  6 03:02:41.741: INFO: Pod "downwardapi-volume-a8a943a8-29bb-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 03:02:41.748: INFO: Trying to get logs from node 10.190.119.175 pod downwardapi-volume-a8a943a8-29bb-11e9-b6e7-06cba7aec104 container client-container: <nil>
STEP: delete the pod
Feb  6 03:02:41.840: INFO: Waiting for pod downwardapi-volume-a8a943a8-29bb-11e9-b6e7-06cba7aec104 to disappear
Feb  6 03:02:41.847: INFO: Pod downwardapi-volume-a8a943a8-29bb-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:02:41.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-wqqrz" for this suite.
Feb  6 03:02:47.900: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:02:48.172: INFO: namespace: e2e-tests-downward-api-wqqrz, resource: bindings, ignored listing per whitelist
Feb  6 03:02:48.253: INFO: namespace e2e-tests-downward-api-wqqrz deletion completed in 6.395397892s

• [SLOW TEST:10.938 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:02:48.254: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-mb52v
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-af2d6a81-29bb-11e9-b6e7-06cba7aec104
STEP: Creating a pod to test consume secrets
Feb  6 03:02:48.698: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-af2fe198-29bb-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-projected-mb52v" to be "success or failure"
Feb  6 03:02:48.705: INFO: Pod "pod-projected-secrets-af2fe198-29bb-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 7.47944ms
Feb  6 03:02:50.714: INFO: Pod "pod-projected-secrets-af2fe198-29bb-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016469572s
STEP: Saw pod success
Feb  6 03:02:50.714: INFO: Pod "pod-projected-secrets-af2fe198-29bb-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 03:02:50.721: INFO: Trying to get logs from node 10.190.119.144 pod pod-projected-secrets-af2fe198-29bb-11e9-b6e7-06cba7aec104 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb  6 03:02:50.988: INFO: Waiting for pod pod-projected-secrets-af2fe198-29bb-11e9-b6e7-06cba7aec104 to disappear
Feb  6 03:02:50.994: INFO: Pod pod-projected-secrets-af2fe198-29bb-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:02:50.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mb52v" for this suite.
Feb  6 03:02:57.040: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:02:57.329: INFO: namespace: e2e-tests-projected-mb52v, resource: bindings, ignored listing per whitelist
Feb  6 03:02:57.423: INFO: namespace e2e-tests-projected-mb52v deletion completed in 6.418337812s

• [SLOW TEST:9.169 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:02:57.424: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-75wk9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb  6 03:02:57.953: INFO: Waiting up to 5m0s for pod "downward-api-b4bbc9f6-29bb-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-downward-api-75wk9" to be "success or failure"
Feb  6 03:02:57.962: INFO: Pod "downward-api-b4bbc9f6-29bb-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 9.09922ms
Feb  6 03:02:59.995: INFO: Pod "downward-api-b4bbc9f6-29bb-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 2.042233979s
Feb  6 03:03:02.004: INFO: Pod "downward-api-b4bbc9f6-29bb-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.050167259s
STEP: Saw pod success
Feb  6 03:03:02.004: INFO: Pod "downward-api-b4bbc9f6-29bb-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 03:03:02.011: INFO: Trying to get logs from node 10.190.119.175 pod downward-api-b4bbc9f6-29bb-11e9-b6e7-06cba7aec104 container dapi-container: <nil>
STEP: delete the pod
Feb  6 03:03:02.055: INFO: Waiting for pod downward-api-b4bbc9f6-29bb-11e9-b6e7-06cba7aec104 to disappear
Feb  6 03:03:02.062: INFO: Pod downward-api-b4bbc9f6-29bb-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:03:02.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-75wk9" for this suite.
Feb  6 03:03:10.144: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:03:10.539: INFO: namespace: e2e-tests-downward-api-75wk9, resource: bindings, ignored listing per whitelist
Feb  6 03:03:10.649: INFO: namespace e2e-tests-downward-api-75wk9 deletion completed in 8.55006794s

• [SLOW TEST:13.226 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:03:10.651: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-n9ktv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  6 03:03:11.105: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
Feb  6 03:03:11.120: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-n9ktv/daemonsets","resourceVersion":"67091"},"items":null}

Feb  6 03:03:11.128: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-n9ktv/pods","resourceVersion":"67091"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:03:11.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-n9ktv" for this suite.
Feb  6 03:03:17.232: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:03:17.257: INFO: namespace: e2e-tests-daemonsets-n9ktv, resource: bindings, ignored listing per whitelist
Feb  6 03:03:17.545: INFO: namespace e2e-tests-daemonsets-n9ktv deletion completed in 6.372300617s

S [SKIPPING] [6.894 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Feb  6 03:03:11.105: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:03:17.547: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-k869w
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-c11538b3-29bb-11e9-b6e7-06cba7aec104
STEP: Creating a pod to test consume secrets
Feb  6 03:03:18.687: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-c1170181-29bb-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-projected-k869w" to be "success or failure"
Feb  6 03:03:18.695: INFO: Pod "pod-projected-secrets-c1170181-29bb-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 8.219595ms
Feb  6 03:03:20.703: INFO: Pod "pod-projected-secrets-c1170181-29bb-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01611526s
STEP: Saw pod success
Feb  6 03:03:20.703: INFO: Pod "pod-projected-secrets-c1170181-29bb-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 03:03:20.711: INFO: Trying to get logs from node 10.190.119.175 pod pod-projected-secrets-c1170181-29bb-11e9-b6e7-06cba7aec104 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb  6 03:03:20.752: INFO: Waiting for pod pod-projected-secrets-c1170181-29bb-11e9-b6e7-06cba7aec104 to disappear
Feb  6 03:03:20.760: INFO: Pod pod-projected-secrets-c1170181-29bb-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:03:20.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-k869w" for this suite.
Feb  6 03:03:26.804: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:03:27.034: INFO: namespace: e2e-tests-projected-k869w, resource: bindings, ignored listing per whitelist
Feb  6 03:03:27.343: INFO: namespace e2e-tests-projected-k869w deletion completed in 6.572706372s

• [SLOW TEST:9.795 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:03:27.343: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-hjzhg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb  6 03:03:27.753: INFO: Waiting up to 5m0s for pod "pod-c67f3bf9-29bb-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-emptydir-hjzhg" to be "success or failure"
Feb  6 03:03:27.760: INFO: Pod "pod-c67f3bf9-29bb-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 7.427023ms
Feb  6 03:03:29.768: INFO: Pod "pod-c67f3bf9-29bb-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015308355s
STEP: Saw pod success
Feb  6 03:03:29.768: INFO: Pod "pod-c67f3bf9-29bb-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 03:03:29.775: INFO: Trying to get logs from node 10.190.119.144 pod pod-c67f3bf9-29bb-11e9-b6e7-06cba7aec104 container test-container: <nil>
STEP: delete the pod
Feb  6 03:03:30.329: INFO: Waiting for pod pod-c67f3bf9-29bb-11e9-b6e7-06cba7aec104 to disappear
Feb  6 03:03:30.350: INFO: Pod pod-c67f3bf9-29bb-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:03:30.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-hjzhg" for this suite.
Feb  6 03:03:36.405: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:03:36.422: INFO: namespace: e2e-tests-emptydir-hjzhg, resource: bindings, ignored listing per whitelist
Feb  6 03:03:36.823: INFO: namespace e2e-tests-emptydir-hjzhg deletion completed in 6.457624332s

• [SLOW TEST:9.481 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:03:36.824: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-2w76m
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1052
STEP: creating the pod
Feb  6 03:03:37.130: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 create -f - --namespace=e2e-tests-kubectl-2w76m'
Feb  6 03:03:37.702: INFO: stderr: ""
Feb  6 03:03:37.702: INFO: stdout: "pod/pause created\n"
Feb  6 03:03:37.702: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Feb  6 03:03:37.702: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-2w76m" to be "running and ready"
Feb  6 03:03:37.726: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 24.350904ms
Feb  6 03:03:39.734: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.031986367s
Feb  6 03:03:39.734: INFO: Pod "pause" satisfied condition "running and ready"
Feb  6 03:03:39.734: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Feb  6 03:03:39.734: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-2w76m'
Feb  6 03:03:39.858: INFO: stderr: ""
Feb  6 03:03:39.859: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Feb  6 03:03:39.859: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 get pod pause -L testing-label --namespace=e2e-tests-kubectl-2w76m'
Feb  6 03:03:39.968: INFO: stderr: ""
Feb  6 03:03:39.968: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Feb  6 03:03:39.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 label pods pause testing-label- --namespace=e2e-tests-kubectl-2w76m'
Feb  6 03:03:40.102: INFO: stderr: ""
Feb  6 03:03:40.102: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Feb  6 03:03:40.102: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 get pod pause -L testing-label --namespace=e2e-tests-kubectl-2w76m'
Feb  6 03:03:40.211: INFO: stderr: ""
Feb  6 03:03:40.211: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1059
STEP: using delete to clean up resources
Feb  6 03:03:40.211: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-2w76m'
Feb  6 03:03:40.343: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  6 03:03:40.343: INFO: stdout: "pod \"pause\" force deleted\n"
Feb  6 03:03:40.343: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-2w76m'
Feb  6 03:03:40.476: INFO: stderr: "No resources found.\n"
Feb  6 03:03:40.476: INFO: stdout: ""
Feb  6 03:03:40.476: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 get pods -l name=pause --namespace=e2e-tests-kubectl-2w76m -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb  6 03:03:40.575: INFO: stderr: ""
Feb  6 03:03:40.576: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:03:40.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2w76m" for this suite.
Feb  6 03:03:46.626: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:03:46.977: INFO: namespace: e2e-tests-kubectl-2w76m, resource: bindings, ignored listing per whitelist
Feb  6 03:03:47.017: INFO: namespace e2e-tests-kubectl-2w76m deletion completed in 6.42969199s

• [SLOW TEST:10.193 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:03:47.017: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-x66nx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-d255d144-29bb-11e9-b6e7-06cba7aec104
STEP: Creating a pod to test consume configMaps
Feb  6 03:03:47.622: INFO: Waiting up to 5m0s for pod "pod-configmaps-d257374c-29bb-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-configmap-x66nx" to be "success or failure"
Feb  6 03:03:47.631: INFO: Pod "pod-configmaps-d257374c-29bb-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 8.193599ms
Feb  6 03:03:49.657: INFO: Pod "pod-configmaps-d257374c-29bb-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.034727537s
STEP: Saw pod success
Feb  6 03:03:49.657: INFO: Pod "pod-configmaps-d257374c-29bb-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 03:03:49.665: INFO: Trying to get logs from node 10.190.119.175 pod pod-configmaps-d257374c-29bb-11e9-b6e7-06cba7aec104 container configmap-volume-test: <nil>
STEP: delete the pod
Feb  6 03:03:49.724: INFO: Waiting for pod pod-configmaps-d257374c-29bb-11e9-b6e7-06cba7aec104 to disappear
Feb  6 03:03:49.731: INFO: Pod pod-configmaps-d257374c-29bb-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:03:49.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-x66nx" for this suite.
Feb  6 03:03:57.777: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:03:57.860: INFO: namespace: e2e-tests-configmap-x66nx, resource: bindings, ignored listing per whitelist
Feb  6 03:03:58.144: INFO: namespace e2e-tests-configmap-x66nx deletion completed in 8.40212602s

• [SLOW TEST:11.127 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:03:58.148: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-bxxjf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0206 03:04:38.697493      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb  6 03:04:38.697: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:04:38.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-bxxjf" for this suite.
Feb  6 03:04:46.750: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:04:46.826: INFO: namespace: e2e-tests-gc-bxxjf, resource: bindings, ignored listing per whitelist
Feb  6 03:04:47.221: INFO: namespace e2e-tests-gc-bxxjf deletion completed in 8.511686422s

• [SLOW TEST:49.073 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:04:47.223: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-w5fq5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  6 03:04:47.754: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f62e35ef-29bb-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-projected-w5fq5" to be "success or failure"
Feb  6 03:04:47.762: INFO: Pod "downwardapi-volume-f62e35ef-29bb-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 8.719938ms
Feb  6 03:04:49.786: INFO: Pod "downwardapi-volume-f62e35ef-29bb-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.032191224s
STEP: Saw pod success
Feb  6 03:04:49.786: INFO: Pod "downwardapi-volume-f62e35ef-29bb-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 03:04:49.793: INFO: Trying to get logs from node 10.190.119.175 pod downwardapi-volume-f62e35ef-29bb-11e9-b6e7-06cba7aec104 container client-container: <nil>
STEP: delete the pod
Feb  6 03:04:49.837: INFO: Waiting for pod downwardapi-volume-f62e35ef-29bb-11e9-b6e7-06cba7aec104 to disappear
Feb  6 03:04:49.846: INFO: Pod downwardapi-volume-f62e35ef-29bb-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:04:49.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-w5fq5" for this suite.
Feb  6 03:04:55.905: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:04:56.366: INFO: namespace: e2e-tests-projected-w5fq5, resource: bindings, ignored listing per whitelist
Feb  6 03:04:56.420: INFO: namespace e2e-tests-projected-w5fq5 deletion completed in 6.559991704s

• [SLOW TEST:9.197 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:04:56.420: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-r975q
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-r975q/secret-test-fb98754a-29bb-11e9-b6e7-06cba7aec104
STEP: Creating a pod to test consume secrets
Feb  6 03:04:56.852: INFO: Waiting up to 5m0s for pod "pod-configmaps-fb9a685d-29bb-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-secrets-r975q" to be "success or failure"
Feb  6 03:04:56.859: INFO: Pod "pod-configmaps-fb9a685d-29bb-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 6.826963ms
Feb  6 03:04:58.868: INFO: Pod "pod-configmaps-fb9a685d-29bb-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015146724s
STEP: Saw pod success
Feb  6 03:04:58.868: INFO: Pod "pod-configmaps-fb9a685d-29bb-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 03:04:58.875: INFO: Trying to get logs from node 10.190.119.175 pod pod-configmaps-fb9a685d-29bb-11e9-b6e7-06cba7aec104 container env-test: <nil>
STEP: delete the pod
Feb  6 03:04:58.925: INFO: Waiting for pod pod-configmaps-fb9a685d-29bb-11e9-b6e7-06cba7aec104 to disappear
Feb  6 03:04:58.934: INFO: Pod pod-configmaps-fb9a685d-29bb-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:04:58.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-r975q" for this suite.
Feb  6 03:05:04.984: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:05:05.393: INFO: namespace: e2e-tests-secrets-r975q, resource: bindings, ignored listing per whitelist
Feb  6 03:05:05.393: INFO: namespace e2e-tests-secrets-r975q deletion completed in 6.448514964s

• [SLOW TEST:8.973 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:05:05.394: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replication-controller-vxlxc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:05:09.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-vxlxc" for this suite.
Feb  6 03:05:33.311: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:05:33.718: INFO: namespace: e2e-tests-replication-controller-vxlxc, resource: bindings, ignored listing per whitelist
Feb  6 03:05:33.838: INFO: namespace e2e-tests-replication-controller-vxlxc deletion completed in 24.573839762s

• [SLOW TEST:28.445 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:05:33.839: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-2kgsg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-11dbe9a3-29bc-11e9-b6e7-06cba7aec104
STEP: Creating a pod to test consume configMaps
Feb  6 03:05:34.200: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-11dd5784-29bc-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-projected-2kgsg" to be "success or failure"
Feb  6 03:05:34.207: INFO: Pod "pod-projected-configmaps-11dd5784-29bc-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 7.231011ms
Feb  6 03:05:36.218: INFO: Pod "pod-projected-configmaps-11dd5784-29bc-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018035215s
STEP: Saw pod success
Feb  6 03:05:36.218: INFO: Pod "pod-projected-configmaps-11dd5784-29bc-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 03:05:36.226: INFO: Trying to get logs from node 10.190.119.145 pod pod-projected-configmaps-11dd5784-29bc-11e9-b6e7-06cba7aec104 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  6 03:05:36.278: INFO: Waiting for pod pod-projected-configmaps-11dd5784-29bc-11e9-b6e7-06cba7aec104 to disappear
Feb  6 03:05:36.285: INFO: Pod pod-projected-configmaps-11dd5784-29bc-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:05:36.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2kgsg" for this suite.
Feb  6 03:05:42.339: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:05:42.669: INFO: namespace: e2e-tests-projected-2kgsg, resource: bindings, ignored listing per whitelist
Feb  6 03:05:42.694: INFO: namespace e2e-tests-projected-2kgsg deletion completed in 6.396303476s

• [SLOW TEST:8.855 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:05:42.694: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-s765h
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-s765h A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-s765h;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-s765h A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-s765h;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-s765h.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-s765h.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-s765h.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-s765h.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-s765h.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-s765h.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-s765h.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-s765h.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-s765h.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-s765h.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-s765h.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-s765h.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-s765h.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 91.147.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.147.91_udp@PTR;check="$$(dig +tcp +noall +answer +search 91.147.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.147.91_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-s765h A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-s765h;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-s765h A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-s765h;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-s765h.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-s765h.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-s765h.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-s765h.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-s765h.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-s765h.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-s765h.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-s765h.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-s765h.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-s765h.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-s765h.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-s765h.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-s765h.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 91.147.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.147.91_udp@PTR;check="$$(dig +tcp +noall +answer +search 91.147.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.147.91_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb  6 03:05:55.322: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-s765h.svc from pod e2e-tests-dns-s765h/dns-test-17285910-29bc-11e9-b6e7-06cba7aec104: the server could not find the requested resource (get pods dns-test-17285910-29bc-11e9-b6e7-06cba7aec104)
Feb  6 03:05:55.444: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-s765h/dns-test-17285910-29bc-11e9-b6e7-06cba7aec104: the server could not find the requested resource (get pods dns-test-17285910-29bc-11e9-b6e7-06cba7aec104)
Feb  6 03:05:55.456: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-s765h/dns-test-17285910-29bc-11e9-b6e7-06cba7aec104: the server could not find the requested resource (get pods dns-test-17285910-29bc-11e9-b6e7-06cba7aec104)
Feb  6 03:05:55.470: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-s765h from pod e2e-tests-dns-s765h/dns-test-17285910-29bc-11e9-b6e7-06cba7aec104: the server could not find the requested resource (get pods dns-test-17285910-29bc-11e9-b6e7-06cba7aec104)
Feb  6 03:05:55.483: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-s765h from pod e2e-tests-dns-s765h/dns-test-17285910-29bc-11e9-b6e7-06cba7aec104: the server could not find the requested resource (get pods dns-test-17285910-29bc-11e9-b6e7-06cba7aec104)
Feb  6 03:05:55.497: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-s765h.svc from pod e2e-tests-dns-s765h/dns-test-17285910-29bc-11e9-b6e7-06cba7aec104: the server could not find the requested resource (get pods dns-test-17285910-29bc-11e9-b6e7-06cba7aec104)
Feb  6 03:05:55.510: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-s765h.svc from pod e2e-tests-dns-s765h/dns-test-17285910-29bc-11e9-b6e7-06cba7aec104: the server could not find the requested resource (get pods dns-test-17285910-29bc-11e9-b6e7-06cba7aec104)
Feb  6 03:05:55.523: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-s765h.svc from pod e2e-tests-dns-s765h/dns-test-17285910-29bc-11e9-b6e7-06cba7aec104: the server could not find the requested resource (get pods dns-test-17285910-29bc-11e9-b6e7-06cba7aec104)
Feb  6 03:05:55.538: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-s765h.svc from pod e2e-tests-dns-s765h/dns-test-17285910-29bc-11e9-b6e7-06cba7aec104: the server could not find the requested resource (get pods dns-test-17285910-29bc-11e9-b6e7-06cba7aec104)
Feb  6 03:05:55.625: INFO: Lookups using e2e-tests-dns-s765h/dns-test-17285910-29bc-11e9-b6e7-06cba7aec104 failed for: [wheezy_tcp@dns-test-service.e2e-tests-dns-s765h.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-s765h jessie_tcp@dns-test-service.e2e-tests-dns-s765h jessie_udp@dns-test-service.e2e-tests-dns-s765h.svc jessie_tcp@dns-test-service.e2e-tests-dns-s765h.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-s765h.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-s765h.svc]

Feb  6 03:06:00.721: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-s765h.svc from pod e2e-tests-dns-s765h/dns-test-17285910-29bc-11e9-b6e7-06cba7aec104: the server could not find the requested resource (get pods dns-test-17285910-29bc-11e9-b6e7-06cba7aec104)
Feb  6 03:06:00.858: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-s765h/dns-test-17285910-29bc-11e9-b6e7-06cba7aec104: the server could not find the requested resource (get pods dns-test-17285910-29bc-11e9-b6e7-06cba7aec104)
Feb  6 03:06:00.871: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-s765h/dns-test-17285910-29bc-11e9-b6e7-06cba7aec104: the server could not find the requested resource (get pods dns-test-17285910-29bc-11e9-b6e7-06cba7aec104)
Feb  6 03:06:00.886: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-s765h from pod e2e-tests-dns-s765h/dns-test-17285910-29bc-11e9-b6e7-06cba7aec104: the server could not find the requested resource (get pods dns-test-17285910-29bc-11e9-b6e7-06cba7aec104)
Feb  6 03:06:00.898: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-s765h from pod e2e-tests-dns-s765h/dns-test-17285910-29bc-11e9-b6e7-06cba7aec104: the server could not find the requested resource (get pods dns-test-17285910-29bc-11e9-b6e7-06cba7aec104)
Feb  6 03:06:00.912: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-s765h.svc from pod e2e-tests-dns-s765h/dns-test-17285910-29bc-11e9-b6e7-06cba7aec104: the server could not find the requested resource (get pods dns-test-17285910-29bc-11e9-b6e7-06cba7aec104)
Feb  6 03:06:00.926: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-s765h.svc from pod e2e-tests-dns-s765h/dns-test-17285910-29bc-11e9-b6e7-06cba7aec104: the server could not find the requested resource (get pods dns-test-17285910-29bc-11e9-b6e7-06cba7aec104)
Feb  6 03:06:00.939: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-s765h.svc from pod e2e-tests-dns-s765h/dns-test-17285910-29bc-11e9-b6e7-06cba7aec104: the server could not find the requested resource (get pods dns-test-17285910-29bc-11e9-b6e7-06cba7aec104)
Feb  6 03:06:00.956: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-s765h.svc from pod e2e-tests-dns-s765h/dns-test-17285910-29bc-11e9-b6e7-06cba7aec104: the server could not find the requested resource (get pods dns-test-17285910-29bc-11e9-b6e7-06cba7aec104)
Feb  6 03:06:01.079: INFO: Lookups using e2e-tests-dns-s765h/dns-test-17285910-29bc-11e9-b6e7-06cba7aec104 failed for: [wheezy_tcp@dns-test-service.e2e-tests-dns-s765h.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-s765h jessie_tcp@dns-test-service.e2e-tests-dns-s765h jessie_udp@dns-test-service.e2e-tests-dns-s765h.svc jessie_tcp@dns-test-service.e2e-tests-dns-s765h.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-s765h.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-s765h.svc]

Feb  6 03:06:05.731: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-s765h.svc from pod e2e-tests-dns-s765h/dns-test-17285910-29bc-11e9-b6e7-06cba7aec104: the server could not find the requested resource (get pods dns-test-17285910-29bc-11e9-b6e7-06cba7aec104)
Feb  6 03:06:05.848: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-s765h/dns-test-17285910-29bc-11e9-b6e7-06cba7aec104: the server could not find the requested resource (get pods dns-test-17285910-29bc-11e9-b6e7-06cba7aec104)
Feb  6 03:06:05.861: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-s765h/dns-test-17285910-29bc-11e9-b6e7-06cba7aec104: the server could not find the requested resource (get pods dns-test-17285910-29bc-11e9-b6e7-06cba7aec104)
Feb  6 03:06:05.876: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-s765h from pod e2e-tests-dns-s765h/dns-test-17285910-29bc-11e9-b6e7-06cba7aec104: the server could not find the requested resource (get pods dns-test-17285910-29bc-11e9-b6e7-06cba7aec104)
Feb  6 03:06:05.888: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-s765h from pod e2e-tests-dns-s765h/dns-test-17285910-29bc-11e9-b6e7-06cba7aec104: the server could not find the requested resource (get pods dns-test-17285910-29bc-11e9-b6e7-06cba7aec104)
Feb  6 03:06:05.901: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-s765h.svc from pod e2e-tests-dns-s765h/dns-test-17285910-29bc-11e9-b6e7-06cba7aec104: the server could not find the requested resource (get pods dns-test-17285910-29bc-11e9-b6e7-06cba7aec104)
Feb  6 03:06:05.915: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-s765h.svc from pod e2e-tests-dns-s765h/dns-test-17285910-29bc-11e9-b6e7-06cba7aec104: the server could not find the requested resource (get pods dns-test-17285910-29bc-11e9-b6e7-06cba7aec104)
Feb  6 03:06:05.928: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-s765h.svc from pod e2e-tests-dns-s765h/dns-test-17285910-29bc-11e9-b6e7-06cba7aec104: the server could not find the requested resource (get pods dns-test-17285910-29bc-11e9-b6e7-06cba7aec104)
Feb  6 03:06:05.943: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-s765h.svc from pod e2e-tests-dns-s765h/dns-test-17285910-29bc-11e9-b6e7-06cba7aec104: the server could not find the requested resource (get pods dns-test-17285910-29bc-11e9-b6e7-06cba7aec104)
Feb  6 03:06:06.035: INFO: Lookups using e2e-tests-dns-s765h/dns-test-17285910-29bc-11e9-b6e7-06cba7aec104 failed for: [wheezy_tcp@dns-test-service.e2e-tests-dns-s765h.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-s765h jessie_tcp@dns-test-service.e2e-tests-dns-s765h jessie_udp@dns-test-service.e2e-tests-dns-s765h.svc jessie_tcp@dns-test-service.e2e-tests-dns-s765h.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-s765h.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-s765h.svc]

Feb  6 03:06:10.746: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-s765h.svc from pod e2e-tests-dns-s765h/dns-test-17285910-29bc-11e9-b6e7-06cba7aec104: the server could not find the requested resource (get pods dns-test-17285910-29bc-11e9-b6e7-06cba7aec104)
Feb  6 03:06:10.875: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-s765h/dns-test-17285910-29bc-11e9-b6e7-06cba7aec104: the server could not find the requested resource (get pods dns-test-17285910-29bc-11e9-b6e7-06cba7aec104)
Feb  6 03:06:10.887: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-s765h/dns-test-17285910-29bc-11e9-b6e7-06cba7aec104: the server could not find the requested resource (get pods dns-test-17285910-29bc-11e9-b6e7-06cba7aec104)
Feb  6 03:06:10.902: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-s765h from pod e2e-tests-dns-s765h/dns-test-17285910-29bc-11e9-b6e7-06cba7aec104: the server could not find the requested resource (get pods dns-test-17285910-29bc-11e9-b6e7-06cba7aec104)
Feb  6 03:06:10.917: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-s765h from pod e2e-tests-dns-s765h/dns-test-17285910-29bc-11e9-b6e7-06cba7aec104: the server could not find the requested resource (get pods dns-test-17285910-29bc-11e9-b6e7-06cba7aec104)
Feb  6 03:06:10.930: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-s765h.svc from pod e2e-tests-dns-s765h/dns-test-17285910-29bc-11e9-b6e7-06cba7aec104: the server could not find the requested resource (get pods dns-test-17285910-29bc-11e9-b6e7-06cba7aec104)
Feb  6 03:06:10.944: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-s765h.svc from pod e2e-tests-dns-s765h/dns-test-17285910-29bc-11e9-b6e7-06cba7aec104: the server could not find the requested resource (get pods dns-test-17285910-29bc-11e9-b6e7-06cba7aec104)
Feb  6 03:06:10.957: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-s765h.svc from pod e2e-tests-dns-s765h/dns-test-17285910-29bc-11e9-b6e7-06cba7aec104: the server could not find the requested resource (get pods dns-test-17285910-29bc-11e9-b6e7-06cba7aec104)
Feb  6 03:06:10.969: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-s765h.svc from pod e2e-tests-dns-s765h/dns-test-17285910-29bc-11e9-b6e7-06cba7aec104: the server could not find the requested resource (get pods dns-test-17285910-29bc-11e9-b6e7-06cba7aec104)
Feb  6 03:06:11.076: INFO: Lookups using e2e-tests-dns-s765h/dns-test-17285910-29bc-11e9-b6e7-06cba7aec104 failed for: [wheezy_tcp@dns-test-service.e2e-tests-dns-s765h.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-s765h jessie_tcp@dns-test-service.e2e-tests-dns-s765h jessie_udp@dns-test-service.e2e-tests-dns-s765h.svc jessie_tcp@dns-test-service.e2e-tests-dns-s765h.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-s765h.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-s765h.svc]

Feb  6 03:06:15.739: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-s765h.svc from pod e2e-tests-dns-s765h/dns-test-17285910-29bc-11e9-b6e7-06cba7aec104: the server could not find the requested resource (get pods dns-test-17285910-29bc-11e9-b6e7-06cba7aec104)
Feb  6 03:06:15.849: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-s765h/dns-test-17285910-29bc-11e9-b6e7-06cba7aec104: the server could not find the requested resource (get pods dns-test-17285910-29bc-11e9-b6e7-06cba7aec104)
Feb  6 03:06:15.861: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-s765h/dns-test-17285910-29bc-11e9-b6e7-06cba7aec104: the server could not find the requested resource (get pods dns-test-17285910-29bc-11e9-b6e7-06cba7aec104)
Feb  6 03:06:15.872: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-s765h from pod e2e-tests-dns-s765h/dns-test-17285910-29bc-11e9-b6e7-06cba7aec104: the server could not find the requested resource (get pods dns-test-17285910-29bc-11e9-b6e7-06cba7aec104)
Feb  6 03:06:15.887: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-s765h from pod e2e-tests-dns-s765h/dns-test-17285910-29bc-11e9-b6e7-06cba7aec104: the server could not find the requested resource (get pods dns-test-17285910-29bc-11e9-b6e7-06cba7aec104)
Feb  6 03:06:15.907: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-s765h.svc from pod e2e-tests-dns-s765h/dns-test-17285910-29bc-11e9-b6e7-06cba7aec104: the server could not find the requested resource (get pods dns-test-17285910-29bc-11e9-b6e7-06cba7aec104)
Feb  6 03:06:15.920: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-s765h.svc from pod e2e-tests-dns-s765h/dns-test-17285910-29bc-11e9-b6e7-06cba7aec104: the server could not find the requested resource (get pods dns-test-17285910-29bc-11e9-b6e7-06cba7aec104)
Feb  6 03:06:15.932: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-s765h.svc from pod e2e-tests-dns-s765h/dns-test-17285910-29bc-11e9-b6e7-06cba7aec104: the server could not find the requested resource (get pods dns-test-17285910-29bc-11e9-b6e7-06cba7aec104)
Feb  6 03:06:15.956: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-s765h.svc from pod e2e-tests-dns-s765h/dns-test-17285910-29bc-11e9-b6e7-06cba7aec104: the server could not find the requested resource (get pods dns-test-17285910-29bc-11e9-b6e7-06cba7aec104)
Feb  6 03:06:16.669: INFO: Lookups using e2e-tests-dns-s765h/dns-test-17285910-29bc-11e9-b6e7-06cba7aec104 failed for: [wheezy_tcp@dns-test-service.e2e-tests-dns-s765h.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-s765h jessie_tcp@dns-test-service.e2e-tests-dns-s765h jessie_udp@dns-test-service.e2e-tests-dns-s765h.svc jessie_tcp@dns-test-service.e2e-tests-dns-s765h.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-s765h.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-s765h.svc]

Feb  6 03:06:21.053: INFO: DNS probes using e2e-tests-dns-s765h/dns-test-17285910-29bc-11e9-b6e7-06cba7aec104 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:06:21.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-s765h" for this suite.
Feb  6 03:06:29.224: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:06:29.514: INFO: namespace: e2e-tests-dns-s765h, resource: bindings, ignored listing per whitelist
Feb  6 03:06:29.600: INFO: namespace e2e-tests-dns-s765h deletion completed in 8.414687167s

• [SLOW TEST:46.906 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:06:29.601: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-7pz2g
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Feb  6 03:06:30.438: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb  6 03:06:30.507: INFO: Waiting for terminating namespaces to be deleted...
Feb  6 03:06:30.849: INFO: 
Logging pods the kubelet thinks is on node 10.190.119.144 before test
Feb  6 03:06:30.900: INFO: coredns-autoscaler-64f9c5b4df-44r7b from kube-system started at 2019-02-05 20:41:42 +0000 UTC (1 container statuses recorded)
Feb  6 03:06:30.900: INFO: 	Container autoscaler ready: true, restart count 0
Feb  6 03:06:30.900: INFO: ibm-kube-fluentd-8hwlq from kube-system started at 2019-02-05 20:46:37 +0000 UTC (1 container statuses recorded)
Feb  6 03:06:30.900: INFO: 	Container fluentd ready: true, restart count 0
Feb  6 03:06:30.900: INFO: ibm-storage-watcher-d566545b-tgbbx from kube-system started at 2019-02-05 20:41:42 +0000 UTC (1 container statuses recorded)
Feb  6 03:06:30.900: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Feb  6 03:06:30.900: INFO: test-k8s-e2e-pvg-master-verification from default started at 2019-02-06 01:52:30 +0000 UTC (1 container statuses recorded)
Feb  6 03:06:30.900: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Feb  6 03:06:30.900: INFO: calico-kube-controllers-65868f965d-5tqjq from kube-system started at 2019-02-05 20:41:42 +0000 UTC (1 container statuses recorded)
Feb  6 03:06:30.901: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Feb  6 03:06:30.901: INFO: sonobuoy-e2e-job-8583898d905b4e12 from heptio-sonobuoy started at 2019-02-06 01:52:39 +0000 UTC (2 container statuses recorded)
Feb  6 03:06:30.901: INFO: 	Container e2e ready: true, restart count 0
Feb  6 03:06:30.901: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  6 03:06:30.901: INFO: sonobuoy-systemd-logs-daemon-set-5456463907b0461e-nvm56 from heptio-sonobuoy started at 2019-02-06 01:52:39 +0000 UTC (2 container statuses recorded)
Feb  6 03:06:30.901: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Feb  6 03:06:30.901: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb  6 03:06:30.901: INFO: ibm-file-plugin-7b7c4fbfdf-bn7kf from kube-system started at 2019-02-05 20:41:42 +0000 UTC (1 container statuses recorded)
Feb  6 03:06:30.901: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Feb  6 03:06:30.901: INFO: ibm-master-proxy-static-10.190.119.144 from kube-system started at <nil> (0 container statuses recorded)
Feb  6 03:06:30.901: INFO: kubernetes-dashboard-7996b848f4-nsjp4 from kube-system started at 2019-02-05 20:41:42 +0000 UTC (1 container statuses recorded)
Feb  6 03:06:30.901: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Feb  6 03:06:30.901: INFO: vpn-74bb4868b9-htqtq from kube-system started at 2019-02-05 20:41:42 +0000 UTC (1 container statuses recorded)
Feb  6 03:06:30.901: INFO: 	Container vpn ready: true, restart count 0
Feb  6 03:06:30.901: INFO: calico-node-d28tb from kube-system started at 2019-02-05 20:41:42 +0000 UTC (1 container statuses recorded)
Feb  6 03:06:30.901: INFO: 	Container calico-node ready: true, restart count 0
Feb  6 03:06:30.901: INFO: ibm-keepalived-watcher-sxzhx from kube-system started at 2019-02-05 20:41:42 +0000 UTC (1 container statuses recorded)
Feb  6 03:06:30.901: INFO: 	Container keepalived-watcher ready: true, restart count 0
Feb  6 03:06:30.901: INFO: coredns-977545f8c-8xszx from kube-system started at 2019-02-05 20:41:42 +0000 UTC (1 container statuses recorded)
Feb  6 03:06:30.901: INFO: 	Container coredns ready: true, restart count 0
Feb  6 03:06:30.901: INFO: 
Logging pods the kubelet thinks is on node 10.190.119.145 before test
Feb  6 03:06:30.932: INFO: ibm-master-proxy-static-10.190.119.145 from kube-system started at <nil> (0 container statuses recorded)
Feb  6 03:06:30.932: INFO: ibm-keepalived-watcher-9tr5j from kube-system started at 2019-02-05 20:41:46 +0000 UTC (1 container statuses recorded)
Feb  6 03:06:30.932: INFO: 	Container keepalived-watcher ready: true, restart count 0
Feb  6 03:06:30.932: INFO: calico-node-g74q7 from kube-system started at 2019-02-05 20:41:46 +0000 UTC (1 container statuses recorded)
Feb  6 03:06:30.932: INFO: 	Container calico-node ready: true, restart count 0
Feb  6 03:06:30.932: INFO: coredns-977545f8c-wd8s5 from kube-system started at 2019-02-05 20:42:21 +0000 UTC (1 container statuses recorded)
Feb  6 03:06:30.932: INFO: 	Container coredns ready: true, restart count 0
Feb  6 03:06:30.932: INFO: ibm-cloud-provider-ip-169-62-46-254-d46d48fdc-ft5xq from ibm-system started at 2019-02-05 20:44:05 +0000 UTC (1 container statuses recorded)
Feb  6 03:06:30.932: INFO: 	Container ibm-cloud-provider-ip-169-62-46-254 ready: true, restart count 0
Feb  6 03:06:30.932: INFO: ibm-kube-fluentd-ps2t7 from kube-system started at 2019-02-05 20:46:37 +0000 UTC (1 container statuses recorded)
Feb  6 03:06:30.932: INFO: 	Container fluentd ready: true, restart count 0
Feb  6 03:06:30.932: INFO: sonobuoy-systemd-logs-daemon-set-5456463907b0461e-58dv7 from heptio-sonobuoy started at 2019-02-06 01:52:39 +0000 UTC (2 container statuses recorded)
Feb  6 03:06:30.932: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Feb  6 03:06:30.932: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb  6 03:06:30.932: INFO: public-cr12917ac601404a7783a11c06c1855dfa-alb1-577556c79f-qtqdm from kube-system started at 2019-02-05 20:44:39 +0000 UTC (4 container statuses recorded)
Feb  6 03:06:30.932: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Feb  6 03:06:30.932: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Feb  6 03:06:30.932: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Feb  6 03:06:30.932: INFO: 	Container nginx-ingress ready: true, restart count 0
Feb  6 03:06:30.933: INFO: 
Logging pods the kubelet thinks is on node 10.190.119.175 before test
Feb  6 03:06:30.959: INFO: ibm-master-proxy-static-10.190.119.175 from kube-system started at <nil> (0 container statuses recorded)
Feb  6 03:06:30.959: INFO: calico-node-zndfr from kube-system started at 2019-02-05 20:41:53 +0000 UTC (1 container statuses recorded)
Feb  6 03:06:30.959: INFO: 	Container calico-node ready: true, restart count 0
Feb  6 03:06:30.959: INFO: ibm-cloud-provider-ip-169-62-46-254-d46d48fdc-4hd27 from ibm-system started at 2019-02-05 20:44:05 +0000 UTC (1 container statuses recorded)
Feb  6 03:06:30.959: INFO: 	Container ibm-cloud-provider-ip-169-62-46-254 ready: true, restart count 0
Feb  6 03:06:30.959: INFO: ibm-keepalived-watcher-ktp5r from kube-system started at 2019-02-05 20:41:53 +0000 UTC (1 container statuses recorded)
Feb  6 03:06:30.959: INFO: 	Container keepalived-watcher ready: true, restart count 0
Feb  6 03:06:30.959: INFO: public-cr12917ac601404a7783a11c06c1855dfa-alb1-577556c79f-stvrk from kube-system started at 2019-02-05 20:44:39 +0000 UTC (4 container statuses recorded)
Feb  6 03:06:30.959: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Feb  6 03:06:30.959: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Feb  6 03:06:30.959: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Feb  6 03:06:30.959: INFO: 	Container nginx-ingress ready: true, restart count 0
Feb  6 03:06:30.959: INFO: sonobuoy-systemd-logs-daemon-set-5456463907b0461e-mp9gt from heptio-sonobuoy started at 2019-02-06 01:52:39 +0000 UTC (2 container statuses recorded)
Feb  6 03:06:30.959: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Feb  6 03:06:30.959: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb  6 03:06:30.959: INFO: ibm-kube-fluentd-xv99z from kube-system started at 2019-02-05 20:46:37 +0000 UTC (1 container statuses recorded)
Feb  6 03:06:30.959: INFO: 	Container fluentd ready: true, restart count 0
Feb  6 03:06:30.959: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-06 01:52:37 +0000 UTC (1 container statuses recorded)
Feb  6 03:06:30.959: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb  6 03:06:30.959: INFO: metrics-server-5cd649bcd6-xk698 from kube-system started at 2019-02-05 20:42:24 +0000 UTC (2 container statuses recorded)
Feb  6 03:06:30.959: INFO: 	Container metrics-server ready: true, restart count 0
Feb  6 03:06:30.959: INFO: 	Container metrics-server-nanny ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node 10.190.119.144
STEP: verifying the node has the label node 10.190.119.145
STEP: verifying the node has the label node 10.190.119.175
Feb  6 03:06:31.068: INFO: Pod test-k8s-e2e-pvg-master-verification requesting resource cpu=0m on Node 10.190.119.144
Feb  6 03:06:31.068: INFO: Pod sonobuoy requesting resource cpu=0m on Node 10.190.119.175
Feb  6 03:06:31.068: INFO: Pod sonobuoy-e2e-job-8583898d905b4e12 requesting resource cpu=0m on Node 10.190.119.144
Feb  6 03:06:31.068: INFO: Pod sonobuoy-systemd-logs-daemon-set-5456463907b0461e-58dv7 requesting resource cpu=0m on Node 10.190.119.145
Feb  6 03:06:31.068: INFO: Pod sonobuoy-systemd-logs-daemon-set-5456463907b0461e-mp9gt requesting resource cpu=0m on Node 10.190.119.175
Feb  6 03:06:31.068: INFO: Pod sonobuoy-systemd-logs-daemon-set-5456463907b0461e-nvm56 requesting resource cpu=0m on Node 10.190.119.144
Feb  6 03:06:31.069: INFO: Pod ibm-cloud-provider-ip-169-62-46-254-d46d48fdc-4hd27 requesting resource cpu=5m on Node 10.190.119.175
Feb  6 03:06:31.069: INFO: Pod ibm-cloud-provider-ip-169-62-46-254-d46d48fdc-ft5xq requesting resource cpu=5m on Node 10.190.119.145
Feb  6 03:06:31.069: INFO: Pod calico-kube-controllers-65868f965d-5tqjq requesting resource cpu=10m on Node 10.190.119.144
Feb  6 03:06:31.069: INFO: Pod calico-node-d28tb requesting resource cpu=250m on Node 10.190.119.144
Feb  6 03:06:31.069: INFO: Pod calico-node-g74q7 requesting resource cpu=250m on Node 10.190.119.145
Feb  6 03:06:31.069: INFO: Pod calico-node-zndfr requesting resource cpu=250m on Node 10.190.119.175
Feb  6 03:06:31.069: INFO: Pod coredns-977545f8c-8xszx requesting resource cpu=100m on Node 10.190.119.144
Feb  6 03:06:31.069: INFO: Pod coredns-977545f8c-wd8s5 requesting resource cpu=100m on Node 10.190.119.145
Feb  6 03:06:31.069: INFO: Pod coredns-autoscaler-64f9c5b4df-44r7b requesting resource cpu=20m on Node 10.190.119.144
Feb  6 03:06:31.069: INFO: Pod ibm-file-plugin-7b7c4fbfdf-bn7kf requesting resource cpu=50m on Node 10.190.119.144
Feb  6 03:06:31.069: INFO: Pod ibm-keepalived-watcher-9tr5j requesting resource cpu=5m on Node 10.190.119.145
Feb  6 03:06:31.069: INFO: Pod ibm-keepalived-watcher-ktp5r requesting resource cpu=5m on Node 10.190.119.175
Feb  6 03:06:31.069: INFO: Pod ibm-keepalived-watcher-sxzhx requesting resource cpu=5m on Node 10.190.119.144
Feb  6 03:06:31.069: INFO: Pod ibm-kube-fluentd-8hwlq requesting resource cpu=25m on Node 10.190.119.144
Feb  6 03:06:31.069: INFO: Pod ibm-kube-fluentd-ps2t7 requesting resource cpu=25m on Node 10.190.119.145
Feb  6 03:06:31.069: INFO: Pod ibm-kube-fluentd-xv99z requesting resource cpu=25m on Node 10.190.119.175
Feb  6 03:06:31.069: INFO: Pod ibm-master-proxy-static-10.190.119.144 requesting resource cpu=25m on Node 10.190.119.144
Feb  6 03:06:31.069: INFO: Pod ibm-master-proxy-static-10.190.119.145 requesting resource cpu=25m on Node 10.190.119.145
Feb  6 03:06:31.070: INFO: Pod ibm-master-proxy-static-10.190.119.175 requesting resource cpu=25m on Node 10.190.119.175
Feb  6 03:06:31.070: INFO: Pod ibm-storage-watcher-d566545b-tgbbx requesting resource cpu=50m on Node 10.190.119.144
Feb  6 03:06:31.070: INFO: Pod kubernetes-dashboard-7996b848f4-nsjp4 requesting resource cpu=50m on Node 10.190.119.144
Feb  6 03:06:31.070: INFO: Pod metrics-server-5cd649bcd6-xk698 requesting resource cpu=53m on Node 10.190.119.175
Feb  6 03:06:31.070: INFO: Pod public-cr12917ac601404a7783a11c06c1855dfa-alb1-577556c79f-qtqdm requesting resource cpu=0m on Node 10.190.119.145
Feb  6 03:06:31.070: INFO: Pod public-cr12917ac601404a7783a11c06c1855dfa-alb1-577556c79f-stvrk requesting resource cpu=0m on Node 10.190.119.175
Feb  6 03:06:31.070: INFO: Pod vpn-74bb4868b9-htqtq requesting resource cpu=5m on Node 10.190.119.144
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-33c5d2e2-29bc-11e9-b6e7-06cba7aec104.1580a7749d1b03dd], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-7pz2g/filler-pod-33c5d2e2-29bc-11e9-b6e7-06cba7aec104 to 10.190.119.144]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-33c5d2e2-29bc-11e9-b6e7-06cba7aec104.1580a774d11100cc], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-33c5d2e2-29bc-11e9-b6e7-06cba7aec104.1580a774d3e959fb], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-33c5d2e2-29bc-11e9-b6e7-06cba7aec104.1580a774dcc4ee19], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-33c93ecf-29bc-11e9-b6e7-06cba7aec104.1580a7749d5ed086], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-7pz2g/filler-pod-33c93ecf-29bc-11e9-b6e7-06cba7aec104 to 10.190.119.145]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-33c93ecf-29bc-11e9-b6e7-06cba7aec104.1580a774f464348d], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-33c93ecf-29bc-11e9-b6e7-06cba7aec104.1580a774f70d4309], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-33c93ecf-29bc-11e9-b6e7-06cba7aec104.1580a774ffa7bcae], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-33cad38e-29bc-11e9-b6e7-06cba7aec104.1580a7749e746e27], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-7pz2g/filler-pod-33cad38e-29bc-11e9-b6e7-06cba7aec104 to 10.190.119.175]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-33cad38e-29bc-11e9-b6e7-06cba7aec104.1580a774d209bc43], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-33cad38e-29bc-11e9-b6e7-06cba7aec104.1580a774d503610f], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-33cad38e-29bc-11e9-b6e7-06cba7aec104.1580a774dd824fe2], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1580a77596269aea], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node 10.190.119.144
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.190.119.145
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.190.119.175
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:06:36.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-7pz2g" for this suite.
Feb  6 03:06:44.686: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:06:44.732: INFO: namespace: e2e-tests-sched-pred-7pz2g, resource: bindings, ignored listing per whitelist
Feb  6 03:06:45.019: INFO: namespace e2e-tests-sched-pred-7pz2g deletion completed in 8.376909735s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:15.419 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:06:45.020: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-vtb72
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-fhjbg in namespace e2e-tests-proxy-vtb72
I0206 03:06:45.502782      15 runners.go:184] Created replication controller with name: proxy-service-fhjbg, namespace: e2e-tests-proxy-vtb72, replica count: 1
I0206 03:06:46.553184      15 runners.go:184] proxy-service-fhjbg Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0206 03:06:47.553379      15 runners.go:184] proxy-service-fhjbg Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0206 03:06:48.553548      15 runners.go:184] proxy-service-fhjbg Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb  6 03:06:48.564: INFO: setup took 3.108371303s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Feb  6 03:06:48.588: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:160/proxy/: foo (200; 23.811866ms)
Feb  6 03:06:48.591: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:160/proxy/: foo (200; 26.342464ms)
Feb  6 03:06:48.591: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:1080/proxy/rewri... (200; 25.573369ms)
Feb  6 03:06:48.600: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj/proxy/rewriteme"... (200; 34.234957ms)
Feb  6 03:06:48.600: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:1080/proxy/... (200; 34.859219ms)
Feb  6 03:06:48.600: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/http:proxy-service-fhjbg:portname1/proxy/: foo (200; 35.380969ms)
Feb  6 03:06:48.600: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/proxy-service-fhjbg:portname1/proxy/: foo (200; 35.087815ms)
Feb  6 03:06:48.608: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:162/proxy/: bar (200; 43.35842ms)
Feb  6 03:06:48.608: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/http:proxy-service-fhjbg:portname2/proxy/: bar (200; 42.524304ms)
Feb  6 03:06:48.608: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:162/proxy/: bar (200; 42.839599ms)
Feb  6 03:06:48.608: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/proxy-service-fhjbg:portname2/proxy/: bar (200; 43.10816ms)
Feb  6 03:06:48.617: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:462/proxy/: tls qux (200; 51.897064ms)
Feb  6 03:06:48.623: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:460/proxy/: tls baz (200; 57.54598ms)
Feb  6 03:06:48.629: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:443/proxy/... (200; 64.117641ms)
Feb  6 03:06:48.629: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/https:proxy-service-fhjbg:tlsportname1/proxy/: tls baz (200; 63.747232ms)
Feb  6 03:06:48.642: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/https:proxy-service-fhjbg:tlsportname2/proxy/: tls qux (200; 76.714957ms)
Feb  6 03:06:48.654: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:160/proxy/: foo (200; 11.852722ms)
Feb  6 03:06:48.656: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:443/proxy/... (200; 13.224631ms)
Feb  6 03:06:48.656: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:1080/proxy/rewri... (200; 13.755365ms)
Feb  6 03:06:48.657: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:162/proxy/: bar (200; 13.600607ms)
Feb  6 03:06:48.658: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:162/proxy/: bar (200; 15.764375ms)
Feb  6 03:06:48.658: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:462/proxy/: tls qux (200; 15.111497ms)
Feb  6 03:06:48.658: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:160/proxy/: foo (200; 15.901382ms)
Feb  6 03:06:48.658: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:460/proxy/: tls baz (200; 15.153327ms)
Feb  6 03:06:48.659: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/http:proxy-service-fhjbg:portname1/proxy/: foo (200; 16.874909ms)
Feb  6 03:06:48.659: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:1080/proxy/... (200; 17.495323ms)
Feb  6 03:06:48.660: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj/proxy/rewriteme"... (200; 18.256764ms)
Feb  6 03:06:48.666: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/proxy-service-fhjbg:portname1/proxy/: foo (200; 22.753856ms)
Feb  6 03:06:48.668: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/https:proxy-service-fhjbg:tlsportname1/proxy/: tls baz (200; 25.34736ms)
Feb  6 03:06:48.668: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/https:proxy-service-fhjbg:tlsportname2/proxy/: tls qux (200; 25.505621ms)
Feb  6 03:06:48.668: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/http:proxy-service-fhjbg:portname2/proxy/: bar (200; 25.302942ms)
Feb  6 03:06:48.668: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/proxy-service-fhjbg:portname2/proxy/: bar (200; 24.907348ms)
Feb  6 03:06:48.684: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:462/proxy/: tls qux (200; 15.893094ms)
Feb  6 03:06:48.692: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj/proxy/rewriteme"... (200; 24.359702ms)
Feb  6 03:06:48.693: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:162/proxy/: bar (200; 24.4594ms)
Feb  6 03:06:48.693: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:160/proxy/: foo (200; 24.614047ms)
Feb  6 03:06:48.693: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:162/proxy/: bar (200; 23.940526ms)
Feb  6 03:06:48.693: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:1080/proxy/rewri... (200; 25.02013ms)
Feb  6 03:06:48.693: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:443/proxy/... (200; 24.961443ms)
Feb  6 03:06:48.693: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:1080/proxy/... (200; 25.309787ms)
Feb  6 03:06:48.693: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:160/proxy/: foo (200; 25.323612ms)
Feb  6 03:06:48.694: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:460/proxy/: tls baz (200; 24.784123ms)
Feb  6 03:06:48.696: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/https:proxy-service-fhjbg:tlsportname2/proxy/: tls qux (200; 27.202668ms)
Feb  6 03:06:48.698: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/proxy-service-fhjbg:portname1/proxy/: foo (200; 29.10393ms)
Feb  6 03:06:48.698: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/http:proxy-service-fhjbg:portname2/proxy/: bar (200; 28.817463ms)
Feb  6 03:06:48.698: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/proxy-service-fhjbg:portname2/proxy/: bar (200; 29.466603ms)
Feb  6 03:06:48.699: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/http:proxy-service-fhjbg:portname1/proxy/: foo (200; 30.409914ms)
Feb  6 03:06:48.699: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/https:proxy-service-fhjbg:tlsportname1/proxy/: tls baz (200; 30.503304ms)
Feb  6 03:06:48.740: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:462/proxy/: tls qux (200; 40.928279ms)
Feb  6 03:06:48.756: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/proxy-service-fhjbg:portname2/proxy/: bar (200; 56.188265ms)
Feb  6 03:06:48.764: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:460/proxy/: tls baz (200; 64.264821ms)
Feb  6 03:06:48.764: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:443/proxy/... (200; 64.468829ms)
Feb  6 03:06:48.764: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:162/proxy/: bar (200; 64.541279ms)
Feb  6 03:06:48.764: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj/proxy/rewriteme"... (200; 64.471912ms)
Feb  6 03:06:48.764: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:160/proxy/: foo (200; 64.936894ms)
Feb  6 03:06:48.764: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:162/proxy/: bar (200; 64.921263ms)
Feb  6 03:06:48.764: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:1080/proxy/rewri... (200; 65.351772ms)
Feb  6 03:06:48.764: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:160/proxy/: foo (200; 65.462324ms)
Feb  6 03:06:48.765: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:1080/proxy/... (200; 64.92335ms)
Feb  6 03:06:48.771: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/http:proxy-service-fhjbg:portname2/proxy/: bar (200; 72.139293ms)
Feb  6 03:06:48.777: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/https:proxy-service-fhjbg:tlsportname1/proxy/: tls baz (200; 77.970142ms)
Feb  6 03:06:48.778: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/https:proxy-service-fhjbg:tlsportname2/proxy/: tls qux (200; 78.404281ms)
Feb  6 03:06:48.778: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/http:proxy-service-fhjbg:portname1/proxy/: foo (200; 79.055606ms)
Feb  6 03:06:48.778: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/proxy-service-fhjbg:portname1/proxy/: foo (200; 78.899331ms)
Feb  6 03:06:48.794: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:162/proxy/: bar (200; 15.839567ms)
Feb  6 03:06:48.794: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:1080/proxy/rewri... (200; 15.836121ms)
Feb  6 03:06:48.796: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:462/proxy/: tls qux (200; 17.777291ms)
Feb  6 03:06:48.797: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:160/proxy/: foo (200; 17.603523ms)
Feb  6 03:06:48.801: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/https:proxy-service-fhjbg:tlsportname1/proxy/: tls baz (200; 22.551717ms)
Feb  6 03:06:48.801: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj/proxy/rewriteme"... (200; 22.228423ms)
Feb  6 03:06:48.801: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:1080/proxy/... (200; 22.393193ms)
Feb  6 03:06:48.801: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:460/proxy/: tls baz (200; 22.468738ms)
Feb  6 03:06:48.801: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:443/proxy/... (200; 22.889031ms)
Feb  6 03:06:48.802: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:162/proxy/: bar (200; 23.046163ms)
Feb  6 03:06:48.802: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:160/proxy/: foo (200; 22.671821ms)
Feb  6 03:06:48.804: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/proxy-service-fhjbg:portname1/proxy/: foo (200; 24.802945ms)
Feb  6 03:06:48.808: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/https:proxy-service-fhjbg:tlsportname2/proxy/: tls qux (200; 28.994158ms)
Feb  6 03:06:48.817: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/proxy-service-fhjbg:portname2/proxy/: bar (200; 38.22658ms)
Feb  6 03:06:48.817: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/http:proxy-service-fhjbg:portname1/proxy/: foo (200; 38.956544ms)
Feb  6 03:06:48.817: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/http:proxy-service-fhjbg:portname2/proxy/: bar (200; 38.882714ms)
Feb  6 03:06:48.835: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:460/proxy/: tls baz (200; 17.060487ms)
Feb  6 03:06:48.841: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:462/proxy/: tls qux (200; 23.521251ms)
Feb  6 03:06:48.841: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:443/proxy/... (200; 22.811379ms)
Feb  6 03:06:48.854: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:162/proxy/: bar (200; 35.948398ms)
Feb  6 03:06:48.854: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:1080/proxy/... (200; 36.218501ms)
Feb  6 03:06:48.854: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:1080/proxy/rewri... (200; 36.338335ms)
Feb  6 03:06:48.855: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:160/proxy/: foo (200; 36.678787ms)
Feb  6 03:06:48.855: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:160/proxy/: foo (200; 37.352937ms)
Feb  6 03:06:48.855: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:162/proxy/: bar (200; 36.840883ms)
Feb  6 03:06:48.855: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj/proxy/rewriteme"... (200; 37.616007ms)
Feb  6 03:06:48.856: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/https:proxy-service-fhjbg:tlsportname1/proxy/: tls baz (200; 37.683996ms)
Feb  6 03:06:48.856: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/https:proxy-service-fhjbg:tlsportname2/proxy/: tls qux (200; 38.523677ms)
Feb  6 03:06:48.862: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/http:proxy-service-fhjbg:portname1/proxy/: foo (200; 44.36051ms)
Feb  6 03:06:48.875: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/http:proxy-service-fhjbg:portname2/proxy/: bar (200; 57.133341ms)
Feb  6 03:06:48.875: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/proxy-service-fhjbg:portname2/proxy/: bar (200; 57.056783ms)
Feb  6 03:06:48.882: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/proxy-service-fhjbg:portname1/proxy/: foo (200; 63.952495ms)
Feb  6 03:06:48.975: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/http:proxy-service-fhjbg:portname1/proxy/: foo (200; 92.685882ms)
Feb  6 03:06:48.976: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:162/proxy/: bar (200; 93.652846ms)
Feb  6 03:06:48.976: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/proxy-service-fhjbg:portname1/proxy/: foo (200; 93.507334ms)
Feb  6 03:06:48.976: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:1080/proxy/... (200; 93.474863ms)
Feb  6 03:06:48.976: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:162/proxy/: bar (200; 93.841553ms)
Feb  6 03:06:48.976: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:1080/proxy/rewri... (200; 93.991207ms)
Feb  6 03:06:48.976: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj/proxy/rewriteme"... (200; 93.717664ms)
Feb  6 03:06:48.977: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/https:proxy-service-fhjbg:tlsportname1/proxy/: tls baz (200; 95.241757ms)
Feb  6 03:06:48.978: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:460/proxy/: tls baz (200; 95.098115ms)
Feb  6 03:06:48.978: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:462/proxy/: tls qux (200; 95.55441ms)
Feb  6 03:06:48.978: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:443/proxy/... (200; 95.895972ms)
Feb  6 03:06:48.981: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:160/proxy/: foo (200; 98.481056ms)
Feb  6 03:06:48.981: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:160/proxy/: foo (200; 98.299445ms)
Feb  6 03:06:48.982: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/proxy-service-fhjbg:portname2/proxy/: bar (200; 99.042563ms)
Feb  6 03:06:48.982: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/http:proxy-service-fhjbg:portname2/proxy/: bar (200; 99.519359ms)
Feb  6 03:06:49.001: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/https:proxy-service-fhjbg:tlsportname2/proxy/: tls qux (200; 119.229777ms)
Feb  6 03:06:49.014: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:460/proxy/: tls baz (200; 12.365193ms)
Feb  6 03:06:49.016: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:443/proxy/... (200; 14.562234ms)
Feb  6 03:06:49.018: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:162/proxy/: bar (200; 16.187768ms)
Feb  6 03:06:49.018: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:1080/proxy/rewri... (200; 16.634966ms)
Feb  6 03:06:49.018: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:160/proxy/: foo (200; 16.854898ms)
Feb  6 03:06:49.018: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:160/proxy/: foo (200; 16.073186ms)
Feb  6 03:06:49.018: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj/proxy/rewriteme"... (200; 17.001719ms)
Feb  6 03:06:49.019: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:162/proxy/: bar (200; 16.8033ms)
Feb  6 03:06:49.019: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:1080/proxy/... (200; 16.62432ms)
Feb  6 03:06:49.021: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:462/proxy/: tls qux (200; 18.531217ms)
Feb  6 03:06:49.023: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/http:proxy-service-fhjbg:portname2/proxy/: bar (200; 21.369944ms)
Feb  6 03:06:49.027: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/https:proxy-service-fhjbg:tlsportname2/proxy/: tls qux (200; 24.932289ms)
Feb  6 03:06:49.029: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/https:proxy-service-fhjbg:tlsportname1/proxy/: tls baz (200; 27.079799ms)
Feb  6 03:06:49.029: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/proxy-service-fhjbg:portname2/proxy/: bar (200; 27.204453ms)
Feb  6 03:06:49.030: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/http:proxy-service-fhjbg:portname1/proxy/: foo (200; 27.68353ms)
Feb  6 03:06:49.030: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/proxy-service-fhjbg:portname1/proxy/: foo (200; 27.452613ms)
Feb  6 03:06:49.042: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:160/proxy/: foo (200; 11.927767ms)
Feb  6 03:06:49.055: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:162/proxy/: bar (200; 25.147917ms)
Feb  6 03:06:49.055: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:162/proxy/: bar (200; 24.338336ms)
Feb  6 03:06:49.055: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:1080/proxy/... (200; 25.492997ms)
Feb  6 03:06:49.055: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:160/proxy/: foo (200; 25.293551ms)
Feb  6 03:06:49.055: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:460/proxy/: tls baz (200; 24.641307ms)
Feb  6 03:06:49.055: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/http:proxy-service-fhjbg:portname1/proxy/: foo (200; 25.177971ms)
Feb  6 03:06:49.056: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:1080/proxy/rewri... (200; 25.016089ms)
Feb  6 03:06:49.056: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj/proxy/rewriteme"... (200; 25.6323ms)
Feb  6 03:06:49.056: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:462/proxy/: tls qux (200; 24.685378ms)
Feb  6 03:06:49.056: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:443/proxy/... (200; 25.026956ms)
Feb  6 03:06:49.060: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/https:proxy-service-fhjbg:tlsportname2/proxy/: tls qux (200; 29.603395ms)
Feb  6 03:06:49.060: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/https:proxy-service-fhjbg:tlsportname1/proxy/: tls baz (200; 29.568042ms)
Feb  6 03:06:49.060: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/http:proxy-service-fhjbg:portname2/proxy/: bar (200; 29.864178ms)
Feb  6 03:06:49.060: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/proxy-service-fhjbg:portname2/proxy/: bar (200; 29.636843ms)
Feb  6 03:06:49.061: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/proxy-service-fhjbg:portname1/proxy/: foo (200; 29.567535ms)
Feb  6 03:06:49.074: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:443/proxy/... (200; 12.729886ms)
Feb  6 03:06:49.074: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:162/proxy/: bar (200; 12.885763ms)
Feb  6 03:06:49.075: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:160/proxy/: foo (200; 14.022473ms)
Feb  6 03:06:49.077: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:160/proxy/: foo (200; 16.297011ms)
Feb  6 03:06:49.078: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:1080/proxy/... (200; 16.212698ms)
Feb  6 03:06:49.078: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:162/proxy/: bar (200; 16.450553ms)
Feb  6 03:06:49.078: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:462/proxy/: tls qux (200; 17.028328ms)
Feb  6 03:06:49.078: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:1080/proxy/rewri... (200; 16.666225ms)
Feb  6 03:06:49.078: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj/proxy/rewriteme"... (200; 16.978174ms)
Feb  6 03:06:49.078: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:460/proxy/: tls baz (200; 16.687757ms)
Feb  6 03:06:49.088: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/http:proxy-service-fhjbg:portname2/proxy/: bar (200; 27.218454ms)
Feb  6 03:06:49.095: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/https:proxy-service-fhjbg:tlsportname2/proxy/: tls qux (200; 33.82645ms)
Feb  6 03:06:49.097: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/https:proxy-service-fhjbg:tlsportname1/proxy/: tls baz (200; 35.461989ms)
Feb  6 03:06:49.097: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/http:proxy-service-fhjbg:portname1/proxy/: foo (200; 35.787314ms)
Feb  6 03:06:49.097: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/proxy-service-fhjbg:portname1/proxy/: foo (200; 36.065928ms)
Feb  6 03:06:49.097: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/proxy-service-fhjbg:portname2/proxy/: bar (200; 35.612898ms)
Feb  6 03:06:49.111: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:160/proxy/: foo (200; 14.16052ms)
Feb  6 03:06:49.114: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:460/proxy/: tls baz (200; 16.368558ms)
Feb  6 03:06:49.114: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj/proxy/rewriteme"... (200; 16.281531ms)
Feb  6 03:06:49.114: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:462/proxy/: tls qux (200; 16.673661ms)
Feb  6 03:06:49.114: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:443/proxy/... (200; 16.606476ms)
Feb  6 03:06:49.114: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:1080/proxy/... (200; 17.25484ms)
Feb  6 03:06:49.115: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:160/proxy/: foo (200; 16.799083ms)
Feb  6 03:06:49.115: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:162/proxy/: bar (200; 16.949942ms)
Feb  6 03:06:49.115: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:1080/proxy/rewri... (200; 17.473081ms)
Feb  6 03:06:49.117: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:162/proxy/: bar (200; 19.811856ms)
Feb  6 03:06:49.118: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/proxy-service-fhjbg:portname2/proxy/: bar (200; 20.948151ms)
Feb  6 03:06:49.121: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/proxy-service-fhjbg:portname1/proxy/: foo (200; 24.048374ms)
Feb  6 03:06:49.123: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/http:proxy-service-fhjbg:portname1/proxy/: foo (200; 25.697742ms)
Feb  6 03:06:49.123: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/https:proxy-service-fhjbg:tlsportname1/proxy/: tls baz (200; 25.947621ms)
Feb  6 03:06:49.124: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/http:proxy-service-fhjbg:portname2/proxy/: bar (200; 26.022131ms)
Feb  6 03:06:49.124: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/https:proxy-service-fhjbg:tlsportname2/proxy/: tls qux (200; 25.786537ms)
Feb  6 03:06:49.136: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:1080/proxy/... (200; 11.647492ms)
Feb  6 03:06:49.138: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:162/proxy/: bar (200; 13.640276ms)
Feb  6 03:06:49.138: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:460/proxy/: tls baz (200; 14.066316ms)
Feb  6 03:06:49.138: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:443/proxy/... (200; 14.019877ms)
Feb  6 03:06:49.138: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:160/proxy/: foo (200; 14.440608ms)
Feb  6 03:06:49.140: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:462/proxy/: tls qux (200; 15.890364ms)
Feb  6 03:06:49.140: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj/proxy/rewriteme"... (200; 16.380819ms)
Feb  6 03:06:49.141: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:1080/proxy/rewri... (200; 16.283618ms)
Feb  6 03:06:49.141: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:160/proxy/: foo (200; 16.568351ms)
Feb  6 03:06:49.141: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:162/proxy/: bar (200; 17.360192ms)
Feb  6 03:06:49.142: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/http:proxy-service-fhjbg:portname2/proxy/: bar (200; 18.756928ms)
Feb  6 03:06:49.146: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/proxy-service-fhjbg:portname1/proxy/: foo (200; 21.163828ms)
Feb  6 03:06:49.146: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/https:proxy-service-fhjbg:tlsportname2/proxy/: tls qux (200; 21.354797ms)
Feb  6 03:06:49.146: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/https:proxy-service-fhjbg:tlsportname1/proxy/: tls baz (200; 21.681272ms)
Feb  6 03:06:49.147: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/proxy-service-fhjbg:portname2/proxy/: bar (200; 23.232267ms)
Feb  6 03:06:49.147: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/http:proxy-service-fhjbg:portname1/proxy/: foo (200; 23.534327ms)
Feb  6 03:06:49.162: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:1080/proxy/... (200; 14.03719ms)
Feb  6 03:06:49.162: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:460/proxy/: tls baz (200; 14.550467ms)
Feb  6 03:06:49.167: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj/proxy/rewriteme"... (200; 19.399954ms)
Feb  6 03:06:49.167: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:160/proxy/: foo (200; 19.35442ms)
Feb  6 03:06:49.167: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:162/proxy/: bar (200; 19.153059ms)
Feb  6 03:06:49.167: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:162/proxy/: bar (200; 19.387388ms)
Feb  6 03:06:49.168: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:1080/proxy/rewri... (200; 20.019285ms)
Feb  6 03:06:49.168: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:160/proxy/: foo (200; 20.338448ms)
Feb  6 03:06:49.168: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:443/proxy/... (200; 20.322533ms)
Feb  6 03:06:49.168: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:462/proxy/: tls qux (200; 20.371613ms)
Feb  6 03:06:49.172: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/proxy-service-fhjbg:portname2/proxy/: bar (200; 24.151488ms)
Feb  6 03:06:49.173: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/proxy-service-fhjbg:portname1/proxy/: foo (200; 25.074764ms)
Feb  6 03:06:49.173: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/https:proxy-service-fhjbg:tlsportname2/proxy/: tls qux (200; 24.920484ms)
Feb  6 03:06:49.173: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/http:proxy-service-fhjbg:portname2/proxy/: bar (200; 24.83542ms)
Feb  6 03:06:49.173: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/http:proxy-service-fhjbg:portname1/proxy/: foo (200; 25.117933ms)
Feb  6 03:06:49.173: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/https:proxy-service-fhjbg:tlsportname1/proxy/: tls baz (200; 25.053262ms)
Feb  6 03:06:49.187: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:162/proxy/: bar (200; 13.44234ms)
Feb  6 03:06:49.187: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:460/proxy/: tls baz (200; 14.105235ms)
Feb  6 03:06:49.188: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:162/proxy/: bar (200; 15.089071ms)
Feb  6 03:06:49.189: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:1080/proxy/rewri... (200; 14.586189ms)
Feb  6 03:06:49.189: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:160/proxy/: foo (200; 15.113167ms)
Feb  6 03:06:49.189: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:1080/proxy/... (200; 15.86734ms)
Feb  6 03:06:49.189: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj/proxy/rewriteme"... (200; 15.570233ms)
Feb  6 03:06:49.189: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:160/proxy/: foo (200; 15.871605ms)
Feb  6 03:06:49.190: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:443/proxy/... (200; 15.800896ms)
Feb  6 03:06:49.190: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:462/proxy/: tls qux (200; 16.029534ms)
Feb  6 03:06:49.195: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/http:proxy-service-fhjbg:portname1/proxy/: foo (200; 21.573489ms)
Feb  6 03:06:49.198: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/https:proxy-service-fhjbg:tlsportname1/proxy/: tls baz (200; 23.706384ms)
Feb  6 03:06:49.198: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/https:proxy-service-fhjbg:tlsportname2/proxy/: tls qux (200; 24.719744ms)
Feb  6 03:06:49.199: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/proxy-service-fhjbg:portname1/proxy/: foo (200; 24.951567ms)
Feb  6 03:06:49.199: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/proxy-service-fhjbg:portname2/proxy/: bar (200; 25.697499ms)
Feb  6 03:06:49.199: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/http:proxy-service-fhjbg:portname2/proxy/: bar (200; 26.031885ms)
Feb  6 03:06:49.212: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:1080/proxy/... (200; 13.002795ms)
Feb  6 03:06:49.217: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj/proxy/rewriteme"... (200; 17.463463ms)
Feb  6 03:06:49.217: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:1080/proxy/rewri... (200; 17.024422ms)
Feb  6 03:06:49.217: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:160/proxy/: foo (200; 17.490963ms)
Feb  6 03:06:49.217: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:160/proxy/: foo (200; 17.738839ms)
Feb  6 03:06:49.217: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:162/proxy/: bar (200; 17.110697ms)
Feb  6 03:06:49.217: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:443/proxy/... (200; 17.024946ms)
Feb  6 03:06:49.218: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:162/proxy/: bar (200; 16.682119ms)
Feb  6 03:06:49.218: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:460/proxy/: tls baz (200; 17.113473ms)
Feb  6 03:06:49.218: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:462/proxy/: tls qux (200; 17.68458ms)
Feb  6 03:06:49.224: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/proxy-service-fhjbg:portname1/proxy/: foo (200; 23.12988ms)
Feb  6 03:06:49.228: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/http:proxy-service-fhjbg:portname1/proxy/: foo (200; 27.713716ms)
Feb  6 03:06:49.229: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/proxy-service-fhjbg:portname2/proxy/: bar (200; 28.195568ms)
Feb  6 03:06:49.230: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/http:proxy-service-fhjbg:portname2/proxy/: bar (200; 28.739366ms)
Feb  6 03:06:49.230: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/https:proxy-service-fhjbg:tlsportname1/proxy/: tls baz (200; 29.93988ms)
Feb  6 03:06:49.230: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/https:proxy-service-fhjbg:tlsportname2/proxy/: tls qux (200; 30.106905ms)
Feb  6 03:06:49.244: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj/proxy/rewriteme"... (200; 13.568249ms)
Feb  6 03:06:49.246: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:162/proxy/: bar (200; 14.952894ms)
Feb  6 03:06:49.246: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:160/proxy/: foo (200; 14.792383ms)
Feb  6 03:06:49.246: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:462/proxy/: tls qux (200; 14.259919ms)
Feb  6 03:06:49.246: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:1080/proxy/rewri... (200; 14.446364ms)
Feb  6 03:06:49.246: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:162/proxy/: bar (200; 14.629315ms)
Feb  6 03:06:49.246: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:160/proxy/: foo (200; 14.960843ms)
Feb  6 03:06:49.246: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:1080/proxy/... (200; 15.739329ms)
Feb  6 03:06:49.247: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:460/proxy/: tls baz (200; 16.252304ms)
Feb  6 03:06:49.247: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:443/proxy/... (200; 15.581468ms)
Feb  6 03:06:49.248: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/https:proxy-service-fhjbg:tlsportname2/proxy/: tls qux (200; 17.95886ms)
Feb  6 03:06:49.257: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/proxy-service-fhjbg:portname1/proxy/: foo (200; 26.147728ms)
Feb  6 03:06:49.259: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/http:proxy-service-fhjbg:portname1/proxy/: foo (200; 28.056004ms)
Feb  6 03:06:49.262: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/https:proxy-service-fhjbg:tlsportname1/proxy/: tls baz (200; 30.742644ms)
Feb  6 03:06:49.262: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/http:proxy-service-fhjbg:portname2/proxy/: bar (200; 30.455675ms)
Feb  6 03:06:49.262: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/proxy-service-fhjbg:portname2/proxy/: bar (200; 31.467816ms)
Feb  6 03:06:49.273: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:162/proxy/: bar (200; 10.738895ms)
Feb  6 03:06:49.276: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:462/proxy/: tls qux (200; 12.819133ms)
Feb  6 03:06:49.276: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:443/proxy/... (200; 13.111787ms)
Feb  6 03:06:49.276: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj/proxy/rewriteme"... (200; 13.561907ms)
Feb  6 03:06:49.276: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:160/proxy/: foo (200; 13.557581ms)
Feb  6 03:06:49.276: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:1080/proxy/... (200; 13.906108ms)
Feb  6 03:06:49.279: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/https:proxy-service-fhjbg:tlsportname2/proxy/: tls qux (200; 16.960331ms)
Feb  6 03:06:49.279: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:460/proxy/: tls baz (200; 16.962253ms)
Feb  6 03:06:49.279: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:160/proxy/: foo (200; 16.225775ms)
Feb  6 03:06:49.279: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:1080/proxy/rewri... (200; 16.034117ms)
Feb  6 03:06:49.279: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:162/proxy/: bar (200; 15.977899ms)
Feb  6 03:06:49.283: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/proxy-service-fhjbg:portname2/proxy/: bar (200; 21.071452ms)
Feb  6 03:06:49.288: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/http:proxy-service-fhjbg:portname1/proxy/: foo (200; 24.964784ms)
Feb  6 03:06:49.288: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/https:proxy-service-fhjbg:tlsportname1/proxy/: tls baz (200; 26.211896ms)
Feb  6 03:06:49.290: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/http:proxy-service-fhjbg:portname2/proxy/: bar (200; 26.342441ms)
Feb  6 03:06:49.290: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/proxy-service-fhjbg:portname1/proxy/: foo (200; 26.498127ms)
Feb  6 03:06:49.302: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:162/proxy/: bar (200; 12.595519ms)
Feb  6 03:06:49.305: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj/proxy/rewriteme"... (200; 14.103122ms)
Feb  6 03:06:49.305: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:160/proxy/: foo (200; 14.896586ms)
Feb  6 03:06:49.305: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:1080/proxy/rewri... (200; 14.842998ms)
Feb  6 03:06:49.305: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:160/proxy/: foo (200; 15.055688ms)
Feb  6 03:06:49.307: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:1080/proxy/... (200; 16.237877ms)
Feb  6 03:06:49.309: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/http:proxy-service-fhjbg:portname1/proxy/: foo (200; 19.194209ms)
Feb  6 03:06:49.310: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/http:proxy-service-fhjbg:portname2/proxy/: bar (200; 20.283685ms)
Feb  6 03:06:49.310: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:162/proxy/: bar (200; 20.157746ms)
Feb  6 03:06:49.310: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:462/proxy/: tls qux (200; 20.113736ms)
Feb  6 03:06:49.311: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:460/proxy/: tls baz (200; 20.715564ms)
Feb  6 03:06:49.311: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:443/proxy/... (200; 20.170492ms)
Feb  6 03:06:49.311: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/proxy-service-fhjbg:portname2/proxy/: bar (200; 20.654074ms)
Feb  6 03:06:49.313: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/proxy-service-fhjbg:portname1/proxy/: foo (200; 22.388947ms)
Feb  6 03:06:49.313: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/https:proxy-service-fhjbg:tlsportname2/proxy/: tls qux (200; 23.21473ms)
Feb  6 03:06:49.314: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/https:proxy-service-fhjbg:tlsportname1/proxy/: tls baz (200; 23.651416ms)
Feb  6 03:06:49.332: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:1080/proxy/rewri... (200; 17.846902ms)
Feb  6 03:06:49.332: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj/proxy/rewriteme"... (200; 17.517746ms)
Feb  6 03:06:49.332: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:443/proxy/... (200; 17.609293ms)
Feb  6 03:06:49.333: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:160/proxy/: foo (200; 17.619879ms)
Feb  6 03:06:49.333: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:162/proxy/: bar (200; 17.842804ms)
Feb  6 03:06:49.333: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:160/proxy/: foo (200; 17.657085ms)
Feb  6 03:06:49.333: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:1080/proxy/... (200; 18.325997ms)
Feb  6 03:06:49.333: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:462/proxy/: tls qux (200; 17.714946ms)
Feb  6 03:06:49.333: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:162/proxy/: bar (200; 18.660673ms)
Feb  6 03:06:49.333: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:460/proxy/: tls baz (200; 18.627433ms)
Feb  6 03:06:49.343: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/http:proxy-service-fhjbg:portname2/proxy/: bar (200; 28.712909ms)
Feb  6 03:06:49.347: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/proxy-service-fhjbg:portname2/proxy/: bar (200; 32.291676ms)
Feb  6 03:06:49.347: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/http:proxy-service-fhjbg:portname1/proxy/: foo (200; 32.632146ms)
Feb  6 03:06:49.347: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/proxy-service-fhjbg:portname1/proxy/: foo (200; 31.471831ms)
Feb  6 03:06:49.347: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/https:proxy-service-fhjbg:tlsportname2/proxy/: tls qux (200; 32.20471ms)
Feb  6 03:06:49.347: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/https:proxy-service-fhjbg:tlsportname1/proxy/: tls baz (200; 32.237666ms)
Feb  6 03:06:49.361: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:462/proxy/: tls qux (200; 14.4524ms)
Feb  6 03:06:49.362: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:160/proxy/: foo (200; 15.566082ms)
Feb  6 03:06:49.362: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:162/proxy/: bar (200; 15.477762ms)
Feb  6 03:06:49.362: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:1080/proxy/rewri... (200; 15.243878ms)
Feb  6 03:06:49.363: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:443/proxy/... (200; 15.802995ms)
Feb  6 03:06:49.363: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:1080/proxy/... (200; 15.633479ms)
Feb  6 03:06:49.363: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/https:proxy-service-fhjbg-msmgj:460/proxy/: tls baz (200; 15.577249ms)
Feb  6 03:06:49.363: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/http:proxy-service-fhjbg-msmgj:160/proxy/: foo (200; 15.561567ms)
Feb  6 03:06:49.364: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj:162/proxy/: bar (200; 16.358855ms)
Feb  6 03:06:49.364: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-vtb72/pods/proxy-service-fhjbg-msmgj/proxy/rewriteme"... (200; 16.707772ms)
Feb  6 03:06:49.369: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/proxy-service-fhjbg:portname1/proxy/: foo (200; 21.943006ms)
Feb  6 03:06:49.372: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/http:proxy-service-fhjbg:portname2/proxy/: bar (200; 24.554377ms)
Feb  6 03:06:49.372: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/https:proxy-service-fhjbg:tlsportname1/proxy/: tls baz (200; 25.022634ms)
Feb  6 03:06:49.374: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/proxy-service-fhjbg:portname2/proxy/: bar (200; 27.394252ms)
Feb  6 03:06:49.374: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/http:proxy-service-fhjbg:portname1/proxy/: foo (200; 26.885031ms)
Feb  6 03:06:49.374: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-vtb72/services/https:proxy-service-fhjbg:tlsportname2/proxy/: tls qux (200; 26.92432ms)
STEP: deleting ReplicationController proxy-service-fhjbg in namespace e2e-tests-proxy-vtb72, will wait for the garbage collector to delete the pods
Feb  6 03:06:49.460: INFO: Deleting ReplicationController proxy-service-fhjbg took: 27.300519ms
Feb  6 03:06:49.561: INFO: Terminating ReplicationController proxy-service-fhjbg pods took: 100.232001ms
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:06:51.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-vtb72" for this suite.
Feb  6 03:06:59.422: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:06:59.521: INFO: namespace: e2e-tests-proxy-vtb72, resource: bindings, ignored listing per whitelist
Feb  6 03:06:59.795: INFO: namespace e2e-tests-proxy-vtb72 deletion completed in 8.42232595s

• [SLOW TEST:14.775 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:06:59.795: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-98q7d
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Feb  6 03:07:00.158: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 create -f - --namespace=e2e-tests-kubectl-98q7d'
Feb  6 03:07:00.390: INFO: stderr: ""
Feb  6 03:07:00.390: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb  6 03:07:00.390: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-98q7d'
Feb  6 03:07:00.554: INFO: stderr: ""
Feb  6 03:07:00.554: INFO: stdout: "update-demo-nautilus-8r8nd update-demo-nautilus-ls6pc "
Feb  6 03:07:00.554: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 get pods update-demo-nautilus-8r8nd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-98q7d'
Feb  6 03:07:00.668: INFO: stderr: ""
Feb  6 03:07:00.668: INFO: stdout: ""
Feb  6 03:07:00.668: INFO: update-demo-nautilus-8r8nd is created but not running
Feb  6 03:07:05.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-98q7d'
Feb  6 03:07:05.781: INFO: stderr: ""
Feb  6 03:07:05.781: INFO: stdout: "update-demo-nautilus-8r8nd update-demo-nautilus-ls6pc "
Feb  6 03:07:05.781: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 get pods update-demo-nautilus-8r8nd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-98q7d'
Feb  6 03:07:05.878: INFO: stderr: ""
Feb  6 03:07:05.878: INFO: stdout: "true"
Feb  6 03:07:05.878: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 get pods update-demo-nautilus-8r8nd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-98q7d'
Feb  6 03:07:05.982: INFO: stderr: ""
Feb  6 03:07:05.982: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  6 03:07:05.982: INFO: validating pod update-demo-nautilus-8r8nd
Feb  6 03:07:06.000: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  6 03:07:06.000: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  6 03:07:06.000: INFO: update-demo-nautilus-8r8nd is verified up and running
Feb  6 03:07:06.000: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 get pods update-demo-nautilus-ls6pc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-98q7d'
Feb  6 03:07:06.109: INFO: stderr: ""
Feb  6 03:07:06.109: INFO: stdout: "true"
Feb  6 03:07:06.109: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 get pods update-demo-nautilus-ls6pc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-98q7d'
Feb  6 03:07:06.223: INFO: stderr: ""
Feb  6 03:07:06.223: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  6 03:07:06.223: INFO: validating pod update-demo-nautilus-ls6pc
Feb  6 03:07:06.242: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  6 03:07:06.242: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  6 03:07:06.242: INFO: update-demo-nautilus-ls6pc is verified up and running
STEP: using delete to clean up resources
Feb  6 03:07:06.242: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-98q7d'
Feb  6 03:07:06.450: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  6 03:07:06.450: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb  6 03:07:06.450: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-98q7d'
Feb  6 03:07:06.652: INFO: stderr: "No resources found.\n"
Feb  6 03:07:06.652: INFO: stdout: ""
Feb  6 03:07:06.652: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 get pods -l name=update-demo --namespace=e2e-tests-kubectl-98q7d -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb  6 03:07:06.824: INFO: stderr: ""
Feb  6 03:07:06.824: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:07:06.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-98q7d" for this suite.
Feb  6 03:07:30.876: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:07:31.029: INFO: namespace: e2e-tests-kubectl-98q7d, resource: bindings, ignored listing per whitelist
Feb  6 03:07:31.228: INFO: namespace e2e-tests-kubectl-98q7d deletion completed in 24.389249969s

• [SLOW TEST:31.433 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:07:31.228: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-sh6pm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Feb  6 03:07:31.578: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 create -f - --namespace=e2e-tests-kubectl-sh6pm'
Feb  6 03:07:31.773: INFO: stderr: ""
Feb  6 03:07:31.773: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb  6 03:07:31.774: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-sh6pm'
Feb  6 03:07:31.904: INFO: stderr: ""
Feb  6 03:07:31.904: INFO: stdout: "update-demo-nautilus-v88tm update-demo-nautilus-wq4xq "
Feb  6 03:07:31.904: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 get pods update-demo-nautilus-v88tm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sh6pm'
Feb  6 03:07:32.007: INFO: stderr: ""
Feb  6 03:07:32.007: INFO: stdout: ""
Feb  6 03:07:32.007: INFO: update-demo-nautilus-v88tm is created but not running
Feb  6 03:07:37.008: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-sh6pm'
Feb  6 03:07:37.709: INFO: stderr: ""
Feb  6 03:07:37.709: INFO: stdout: "update-demo-nautilus-v88tm update-demo-nautilus-wq4xq "
Feb  6 03:07:37.709: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 get pods update-demo-nautilus-v88tm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sh6pm'
Feb  6 03:07:38.393: INFO: stderr: ""
Feb  6 03:07:38.393: INFO: stdout: "true"
Feb  6 03:07:38.393: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 get pods update-demo-nautilus-v88tm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sh6pm'
Feb  6 03:07:38.497: INFO: stderr: ""
Feb  6 03:07:38.497: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  6 03:07:38.497: INFO: validating pod update-demo-nautilus-v88tm
Feb  6 03:07:38.514: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  6 03:07:38.514: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  6 03:07:38.514: INFO: update-demo-nautilus-v88tm is verified up and running
Feb  6 03:07:38.514: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 get pods update-demo-nautilus-wq4xq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sh6pm'
Feb  6 03:07:38.700: INFO: stderr: ""
Feb  6 03:07:38.700: INFO: stdout: "true"
Feb  6 03:07:38.700: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 get pods update-demo-nautilus-wq4xq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sh6pm'
Feb  6 03:07:38.808: INFO: stderr: ""
Feb  6 03:07:38.808: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  6 03:07:38.808: INFO: validating pod update-demo-nautilus-wq4xq
Feb  6 03:07:38.825: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  6 03:07:38.825: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  6 03:07:38.825: INFO: update-demo-nautilus-wq4xq is verified up and running
STEP: scaling down the replication controller
Feb  6 03:07:38.827: INFO: scanned /root for discovery docs: <nil>
Feb  6 03:07:38.827: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-sh6pm'
Feb  6 03:07:40.003: INFO: stderr: ""
Feb  6 03:07:40.003: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb  6 03:07:40.003: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-sh6pm'
Feb  6 03:07:40.125: INFO: stderr: ""
Feb  6 03:07:40.125: INFO: stdout: "update-demo-nautilus-v88tm update-demo-nautilus-wq4xq "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb  6 03:07:45.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-sh6pm'
Feb  6 03:07:45.243: INFO: stderr: ""
Feb  6 03:07:45.243: INFO: stdout: "update-demo-nautilus-wq4xq "
Feb  6 03:07:45.243: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 get pods update-demo-nautilus-wq4xq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sh6pm'
Feb  6 03:07:45.387: INFO: stderr: ""
Feb  6 03:07:45.387: INFO: stdout: "true"
Feb  6 03:07:45.387: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 get pods update-demo-nautilus-wq4xq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sh6pm'
Feb  6 03:07:45.512: INFO: stderr: ""
Feb  6 03:07:45.512: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  6 03:07:45.512: INFO: validating pod update-demo-nautilus-wq4xq
Feb  6 03:07:45.525: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  6 03:07:45.525: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  6 03:07:45.525: INFO: update-demo-nautilus-wq4xq is verified up and running
STEP: scaling up the replication controller
Feb  6 03:07:45.526: INFO: scanned /root for discovery docs: <nil>
Feb  6 03:07:45.527: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-sh6pm'
Feb  6 03:07:46.762: INFO: stderr: ""
Feb  6 03:07:46.762: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb  6 03:07:46.762: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-sh6pm'
Feb  6 03:07:46.913: INFO: stderr: ""
Feb  6 03:07:46.913: INFO: stdout: "update-demo-nautilus-wq4xq update-demo-nautilus-x6mvj "
Feb  6 03:07:46.913: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 get pods update-demo-nautilus-wq4xq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sh6pm'
Feb  6 03:07:47.023: INFO: stderr: ""
Feb  6 03:07:47.023: INFO: stdout: "true"
Feb  6 03:07:47.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 get pods update-demo-nautilus-wq4xq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sh6pm'
Feb  6 03:07:47.136: INFO: stderr: ""
Feb  6 03:07:47.136: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  6 03:07:47.136: INFO: validating pod update-demo-nautilus-wq4xq
Feb  6 03:07:47.150: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  6 03:07:47.150: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  6 03:07:47.150: INFO: update-demo-nautilus-wq4xq is verified up and running
Feb  6 03:07:47.150: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 get pods update-demo-nautilus-x6mvj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sh6pm'
Feb  6 03:07:47.258: INFO: stderr: ""
Feb  6 03:07:47.258: INFO: stdout: ""
Feb  6 03:07:47.258: INFO: update-demo-nautilus-x6mvj is created but not running
Feb  6 03:07:52.258: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-sh6pm'
Feb  6 03:07:52.431: INFO: stderr: ""
Feb  6 03:07:52.432: INFO: stdout: "update-demo-nautilus-wq4xq update-demo-nautilus-x6mvj "
Feb  6 03:07:52.432: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 get pods update-demo-nautilus-wq4xq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sh6pm'
Feb  6 03:07:52.553: INFO: stderr: ""
Feb  6 03:07:52.553: INFO: stdout: "true"
Feb  6 03:07:52.553: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 get pods update-demo-nautilus-wq4xq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sh6pm'
Feb  6 03:07:52.661: INFO: stderr: ""
Feb  6 03:07:52.661: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  6 03:07:52.661: INFO: validating pod update-demo-nautilus-wq4xq
Feb  6 03:07:52.676: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  6 03:07:52.676: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  6 03:07:52.676: INFO: update-demo-nautilus-wq4xq is verified up and running
Feb  6 03:07:52.676: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 get pods update-demo-nautilus-x6mvj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sh6pm'
Feb  6 03:07:52.802: INFO: stderr: ""
Feb  6 03:07:52.802: INFO: stdout: "true"
Feb  6 03:07:52.802: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 get pods update-demo-nautilus-x6mvj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-sh6pm'
Feb  6 03:07:52.900: INFO: stderr: ""
Feb  6 03:07:52.900: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  6 03:07:52.900: INFO: validating pod update-demo-nautilus-x6mvj
Feb  6 03:07:52.919: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  6 03:07:52.919: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  6 03:07:52.919: INFO: update-demo-nautilus-x6mvj is verified up and running
STEP: using delete to clean up resources
Feb  6 03:07:52.919: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-sh6pm'
Feb  6 03:07:53.131: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  6 03:07:53.131: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb  6 03:07:53.131: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-sh6pm'
Feb  6 03:07:53.544: INFO: stderr: "No resources found.\n"
Feb  6 03:07:53.544: INFO: stdout: ""
Feb  6 03:07:53.544: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 get pods -l name=update-demo --namespace=e2e-tests-kubectl-sh6pm -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb  6 03:07:53.726: INFO: stderr: ""
Feb  6 03:07:53.726: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:07:53.726: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-sh6pm" for this suite.
Feb  6 03:08:17.775: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:08:17.850: INFO: namespace: e2e-tests-kubectl-sh6pm, resource: bindings, ignored listing per whitelist
Feb  6 03:08:18.140: INFO: namespace e2e-tests-kubectl-sh6pm deletion completed in 24.401010301s

• [SLOW TEST:46.912 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:08:18.140: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-z8zvc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb  6 03:08:21.246: INFO: Successfully updated pod "annotationupdate73d61b05-29bc-11e9-b6e7-06cba7aec104"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:08:23.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-z8zvc" for this suite.
Feb  6 03:08:47.344: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:08:47.612: INFO: namespace: e2e-tests-downward-api-z8zvc, resource: bindings, ignored listing per whitelist
Feb  6 03:08:47.701: INFO: namespace e2e-tests-downward-api-z8zvc deletion completed in 24.39466773s

• [SLOW TEST:29.561 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:08:47.702: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-gzzp6
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Feb  6 03:08:48.068: INFO: Waiting up to 5m0s for pod "pod-856b7550-29bc-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-emptydir-gzzp6" to be "success or failure"
Feb  6 03:08:48.079: INFO: Pod "pod-856b7550-29bc-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 11.753192ms
Feb  6 03:08:50.115: INFO: Pod "pod-856b7550-29bc-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.047511849s
STEP: Saw pod success
Feb  6 03:08:50.115: INFO: Pod "pod-856b7550-29bc-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 03:08:50.123: INFO: Trying to get logs from node 10.190.119.145 pod pod-856b7550-29bc-11e9-b6e7-06cba7aec104 container test-container: <nil>
STEP: delete the pod
Feb  6 03:08:50.171: INFO: Waiting for pod pod-856b7550-29bc-11e9-b6e7-06cba7aec104 to disappear
Feb  6 03:08:50.181: INFO: Pod pod-856b7550-29bc-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:08:50.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-gzzp6" for this suite.
Feb  6 03:08:58.241: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:08:58.566: INFO: namespace: e2e-tests-emptydir-gzzp6, resource: bindings, ignored listing per whitelist
Feb  6 03:08:58.707: INFO: namespace e2e-tests-emptydir-gzzp6 deletion completed in 8.515417258s

• [SLOW TEST:11.005 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:08:58.709: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-kmg28
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-rcpz
STEP: Creating a pod to test atomic-volume-subpath
Feb  6 03:08:59.071: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-rcpz" in namespace "e2e-tests-subpath-kmg28" to be "success or failure"
Feb  6 03:08:59.078: INFO: Pod "pod-subpath-test-secret-rcpz": Phase="Pending", Reason="", readiness=false. Elapsed: 7.025317ms
Feb  6 03:09:01.107: INFO: Pod "pod-subpath-test-secret-rcpz": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035560134s
Feb  6 03:09:03.116: INFO: Pod "pod-subpath-test-secret-rcpz": Phase="Running", Reason="", readiness=false. Elapsed: 4.044869563s
Feb  6 03:09:05.124: INFO: Pod "pod-subpath-test-secret-rcpz": Phase="Running", Reason="", readiness=false. Elapsed: 6.052818177s
Feb  6 03:09:07.133: INFO: Pod "pod-subpath-test-secret-rcpz": Phase="Running", Reason="", readiness=false. Elapsed: 8.061690119s
Feb  6 03:09:09.153: INFO: Pod "pod-subpath-test-secret-rcpz": Phase="Running", Reason="", readiness=false. Elapsed: 10.08130629s
Feb  6 03:09:11.182: INFO: Pod "pod-subpath-test-secret-rcpz": Phase="Running", Reason="", readiness=false. Elapsed: 12.110288567s
Feb  6 03:09:13.189: INFO: Pod "pod-subpath-test-secret-rcpz": Phase="Running", Reason="", readiness=false. Elapsed: 14.117916757s
Feb  6 03:09:15.197: INFO: Pod "pod-subpath-test-secret-rcpz": Phase="Running", Reason="", readiness=false. Elapsed: 16.125751095s
Feb  6 03:09:17.205: INFO: Pod "pod-subpath-test-secret-rcpz": Phase="Running", Reason="", readiness=false. Elapsed: 18.133295213s
Feb  6 03:09:19.213: INFO: Pod "pod-subpath-test-secret-rcpz": Phase="Running", Reason="", readiness=false. Elapsed: 20.141482814s
Feb  6 03:09:21.241: INFO: Pod "pod-subpath-test-secret-rcpz": Phase="Running", Reason="", readiness=false. Elapsed: 22.169825286s
Feb  6 03:09:23.250: INFO: Pod "pod-subpath-test-secret-rcpz": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.178779376s
STEP: Saw pod success
Feb  6 03:09:23.250: INFO: Pod "pod-subpath-test-secret-rcpz" satisfied condition "success or failure"
Feb  6 03:09:23.257: INFO: Trying to get logs from node 10.190.119.145 pod pod-subpath-test-secret-rcpz container test-container-subpath-secret-rcpz: <nil>
STEP: delete the pod
Feb  6 03:09:23.302: INFO: Waiting for pod pod-subpath-test-secret-rcpz to disappear
Feb  6 03:09:23.309: INFO: Pod pod-subpath-test-secret-rcpz no longer exists
STEP: Deleting pod pod-subpath-test-secret-rcpz
Feb  6 03:09:23.309: INFO: Deleting pod "pod-subpath-test-secret-rcpz" in namespace "e2e-tests-subpath-kmg28"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:09:23.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-kmg28" for this suite.
Feb  6 03:09:31.384: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:09:31.689: INFO: namespace: e2e-tests-subpath-kmg28, resource: bindings, ignored listing per whitelist
Feb  6 03:09:31.735: INFO: namespace e2e-tests-subpath-kmg28 deletion completed in 8.408214869s

• [SLOW TEST:33.027 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:09:31.737: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-74dft
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  6 03:09:32.198: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9fb91426-29bc-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-projected-74dft" to be "success or failure"
Feb  6 03:09:32.206: INFO: Pod "downwardapi-volume-9fb91426-29bc-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 7.596938ms
Feb  6 03:09:34.214: INFO: Pod "downwardapi-volume-9fb91426-29bc-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015691083s
STEP: Saw pod success
Feb  6 03:09:34.214: INFO: Pod "downwardapi-volume-9fb91426-29bc-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 03:09:34.221: INFO: Trying to get logs from node 10.190.119.144 pod downwardapi-volume-9fb91426-29bc-11e9-b6e7-06cba7aec104 container client-container: <nil>
STEP: delete the pod
Feb  6 03:09:34.309: INFO: Waiting for pod downwardapi-volume-9fb91426-29bc-11e9-b6e7-06cba7aec104 to disappear
Feb  6 03:09:34.317: INFO: Pod downwardapi-volume-9fb91426-29bc-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:09:34.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-74dft" for this suite.
Feb  6 03:09:42.389: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:09:42.661: INFO: namespace: e2e-tests-projected-74dft, resource: bindings, ignored listing per whitelist
Feb  6 03:09:42.697: INFO: namespace e2e-tests-projected-74dft deletion completed in 8.368602672s

• [SLOW TEST:10.960 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:09:42.698: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-ppqg6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb  6 03:09:46.113: INFO: Successfully updated pod "labelsupdatea62e76fd-29bc-11e9-b6e7-06cba7aec104"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:09:48.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ppqg6" for this suite.
Feb  6 03:10:12.339: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:10:12.412: INFO: namespace: e2e-tests-projected-ppqg6, resource: bindings, ignored listing per whitelist
Feb  6 03:10:12.647: INFO: namespace e2e-tests-projected-ppqg6 deletion completed in 24.419294084s

• [SLOW TEST:29.950 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:10:12.649: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-qhcvp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  6 03:10:12.986: INFO: Creating deployment "nginx-deployment"
Feb  6 03:10:12.999: INFO: Waiting for observed generation 1
Feb  6 03:10:15.022: INFO: Waiting for all required pods to come up
Feb  6 03:10:15.035: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Feb  6 03:10:15.035: INFO: Waiting for deployment "nginx-deployment" to complete
Feb  6 03:10:15.048: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:10, UpdatedReplicas:10, ReadyReplicas:9, AvailableReplicas:9, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685019414, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685019414, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685019415, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685019413, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"nginx-deployment-555b55d965\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  6 03:10:17.107: INFO: Updating deployment "nginx-deployment" with a non-existent image
Feb  6 03:10:17.134: INFO: Updating deployment nginx-deployment
Feb  6 03:10:17.134: INFO: Waiting for observed generation 2
Feb  6 03:10:19.214: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Feb  6 03:10:19.234: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Feb  6 03:10:19.243: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Feb  6 03:10:19.272: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Feb  6 03:10:19.272: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Feb  6 03:10:19.297: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Feb  6 03:10:19.313: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Feb  6 03:10:19.313: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Feb  6 03:10:19.336: INFO: Updating deployment nginx-deployment
Feb  6 03:10:19.336: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Feb  6 03:10:19.356: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Feb  6 03:10:19.364: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb  6 03:10:19.385: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-qhcvp,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-qhcvp/deployments/nginx-deployment,UID:b80b6dda-29bc-11e9-9423-66f50c9be06e,ResourceVersion:69255,Generation:3,CreationTimestamp:2019-02-06 03:10:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[{Progressing True 2019-02-06 03:10:17 +0000 UTC 2019-02-06 03:10:13 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-65bbdb5f8" is progressing.} {Available False 2019-02-06 03:10:19 +0000 UTC 2019-02-06 03:10:19 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}],ReadyReplicas:8,CollisionCount:nil,},}

Feb  6 03:10:19.402: INFO: New ReplicaSet "nginx-deployment-65bbdb5f8" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8,GenerateName:,Namespace:e2e-tests-deployment-qhcvp,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-qhcvp/replicasets/nginx-deployment-65bbdb5f8,UID:ba845a13-29bc-11e9-a9bb-366cc78d8813,ResourceVersion:69249,Generation:3,CreationTimestamp:2019-02-06 03:10:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment b80b6dda-29bc-11e9-9423-66f50c9be06e 0xc00146c5a7 0xc00146c5a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb  6 03:10:19.402: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Feb  6 03:10:19.402: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965,GenerateName:,Namespace:e2e-tests-deployment-qhcvp,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-qhcvp/replicasets/nginx-deployment-555b55d965,UID:b810cd57-29bc-11e9-a9bb-366cc78d8813,ResourceVersion:69246,Generation:3,CreationTimestamp:2019-02-06 03:10:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment b80b6dda-29bc-11e9-9423-66f50c9be06e 0xc00146c4e7 0xc00146c4e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Feb  6 03:10:19.424: INFO: Pod "nginx-deployment-555b55d965-4j7nw" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-4j7nw,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-qhcvp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhcvp/pods/nginx-deployment-555b55d965-4j7nw,UID:b81fe6f1-29bc-11e9-a9bb-366cc78d8813,ResourceVersion:69105,Generation:0,CreationTimestamp:2019-02-06 03:10:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b810cd57-29bc-11e9-a9bb-366cc78d8813 0xc00146cff7 0xc00146cff8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6779m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6779m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6779m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.144,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00146d070} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00146d090}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:13 +0000 UTC  }],Message:,Reason:,HostIP:10.190.119.144,PodIP:172.30.175.245,StartTime:2019-02-06 03:10:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-06 03:10:14 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 containerd://a65068b7680771e9e1d819596281c556e1e21fbaf6a6a7f524230ec113dd6336}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 03:10:19.424: INFO: Pod "nginx-deployment-555b55d965-5f284" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-5f284,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-qhcvp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhcvp/pods/nginx-deployment-555b55d965-5f284,UID:b81feefe-29bc-11e9-a9bb-366cc78d8813,ResourceVersion:69110,Generation:0,CreationTimestamp:2019-02-06 03:10:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b810cd57-29bc-11e9-a9bb-366cc78d8813 0xc00146d157 0xc00146d158}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6779m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6779m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6779m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00146d1d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00146d1f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:13 +0000 UTC  }],Message:,Reason:,HostIP:10.190.119.145,PodIP:172.30.70.221,StartTime:2019-02-06 03:10:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-06 03:10:14 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 containerd://43bc5dff9e79db807c04acabb94d5ff5a8baf8d783e3fd86d0f9b6aacca8170a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 03:10:19.425: INFO: Pod "nginx-deployment-555b55d965-7kfdg" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-7kfdg,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-qhcvp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhcvp/pods/nginx-deployment-555b55d965-7kfdg,UID:b81cb48f-29bc-11e9-a9bb-366cc78d8813,ResourceVersion:69115,Generation:0,CreationTimestamp:2019-02-06 03:10:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b810cd57-29bc-11e9-a9bb-366cc78d8813 0xc00146d337 0xc00146d338}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6779m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6779m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6779m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00146d3b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00146d3d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:13 +0000 UTC  }],Message:,Reason:,HostIP:10.190.119.145,PodIP:172.30.70.219,StartTime:2019-02-06 03:10:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-06 03:10:14 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 containerd://da94798c4b582844d672e07a543248f4e49511a59aa015918a6be101a9a5a20a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 03:10:19.425: INFO: Pod "nginx-deployment-555b55d965-7pm4n" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-7pm4n,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-qhcvp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhcvp/pods/nginx-deployment-555b55d965-7pm4n,UID:bbdade71-29bc-11e9-a9bb-366cc78d8813,ResourceVersion:69276,Generation:0,CreationTimestamp:2019-02-06 03:10:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b810cd57-29bc-11e9-a9bb-366cc78d8813 0xc00146d497 0xc00146d498}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6779m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6779m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6779m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00146d590} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00146d5b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:19 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 03:10:19.425: INFO: Pod "nginx-deployment-555b55d965-9dj59" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-9dj59,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-qhcvp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhcvp/pods/nginx-deployment-555b55d965-9dj59,UID:bbd7f141-29bc-11e9-a9bb-366cc78d8813,ResourceVersion:69263,Generation:0,CreationTimestamp:2019-02-06 03:10:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b810cd57-29bc-11e9-a9bb-366cc78d8813 0xc00146d620 0xc00146d621}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6779m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6779m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6779m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00146d690} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00146d6b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:19 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 03:10:19.425: INFO: Pod "nginx-deployment-555b55d965-k6gpt" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-k6gpt,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-qhcvp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhcvp/pods/nginx-deployment-555b55d965-k6gpt,UID:b81d52c2-29bc-11e9-a9bb-366cc78d8813,ResourceVersion:69130,Generation:0,CreationTimestamp:2019-02-06 03:10:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b810cd57-29bc-11e9-a9bb-366cc78d8813 0xc00146d7c0 0xc00146d7c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6779m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6779m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6779m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.175,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00146d830} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00146d990}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:13 +0000 UTC  }],Message:,Reason:,HostIP:10.190.119.175,PodIP:172.30.176.22,StartTime:2019-02-06 03:10:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-06 03:10:14 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 containerd://e56817038f371a04d02916c936d82d906b5b754e045b1b7efda072a6406d3559}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 03:10:19.425: INFO: Pod "nginx-deployment-555b55d965-kk7tj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-kk7tj,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-qhcvp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhcvp/pods/nginx-deployment-555b55d965-kk7tj,UID:bbde2259-29bc-11e9-a9bb-366cc78d8813,ResourceVersion:69279,Generation:0,CreationTimestamp:2019-02-06 03:10:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b810cd57-29bc-11e9-a9bb-366cc78d8813 0xc00146da57 0xc00146da58}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6779m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6779m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6779m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00146dac0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00146dae0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 03:10:19.426: INFO: Pod "nginx-deployment-555b55d965-m4xnm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-m4xnm,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-qhcvp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhcvp/pods/nginx-deployment-555b55d965-m4xnm,UID:bbd7f34c-29bc-11e9-a9bb-366cc78d8813,ResourceVersion:69265,Generation:0,CreationTimestamp:2019-02-06 03:10:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b810cd57-29bc-11e9-a9bb-366cc78d8813 0xc00146db37 0xc00146db38}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6779m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6779m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6779m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00146dc50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00146dc70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:19 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 03:10:19.426: INFO: Pod "nginx-deployment-555b55d965-pgx4x" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-pgx4x,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-qhcvp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhcvp/pods/nginx-deployment-555b55d965-pgx4x,UID:bbda77a9-29bc-11e9-a9bb-366cc78d8813,ResourceVersion:69271,Generation:0,CreationTimestamp:2019-02-06 03:10:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b810cd57-29bc-11e9-a9bb-366cc78d8813 0xc00146dd60 0xc00146dd61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6779m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6779m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6779m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.144,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00146ddd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00146ddf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:19 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 03:10:19.426: INFO: Pod "nginx-deployment-555b55d965-q927r" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-q927r,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-qhcvp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhcvp/pods/nginx-deployment-555b55d965-q927r,UID:b81a465f-29bc-11e9-a9bb-366cc78d8813,ResourceVersion:69107,Generation:0,CreationTimestamp:2019-02-06 03:10:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b810cd57-29bc-11e9-a9bb-366cc78d8813 0xc00146de60 0xc00146de61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6779m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6779m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6779m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.144,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00146dee0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00146df20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:13 +0000 UTC  }],Message:,Reason:,HostIP:10.190.119.144,PodIP:172.30.175.246,StartTime:2019-02-06 03:10:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-06 03:10:14 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 containerd://2a1027cd8d0b46bf1c4f29f59ac7b19b5fa164ebc8eb6ea10ebab61a3f923ee4}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 03:10:19.426: INFO: Pod "nginx-deployment-555b55d965-rcv2q" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-rcv2q,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-qhcvp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhcvp/pods/nginx-deployment-555b55d965-rcv2q,UID:b818b2ba-29bc-11e9-a9bb-366cc78d8813,ResourceVersion:69125,Generation:0,CreationTimestamp:2019-02-06 03:10:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b810cd57-29bc-11e9-a9bb-366cc78d8813 0xc00146dfe7 0xc00146dfe8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6779m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6779m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6779m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.175,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0027320c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0027320e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:13 +0000 UTC  }],Message:,Reason:,HostIP:10.190.119.175,PodIP:172.30.176.21,StartTime:2019-02-06 03:10:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-06 03:10:14 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 containerd://d5d0ec2cefd102338aa9238518f528f8b5db7521260526a28e3af35933102a4a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 03:10:19.426: INFO: Pod "nginx-deployment-555b55d965-t4kpp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-t4kpp,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-qhcvp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhcvp/pods/nginx-deployment-555b55d965-t4kpp,UID:bbda53fd-29bc-11e9-a9bb-366cc78d8813,ResourceVersion:69269,Generation:0,CreationTimestamp:2019-02-06 03:10:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b810cd57-29bc-11e9-a9bb-366cc78d8813 0xc0027321a7 0xc0027321a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6779m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6779m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6779m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.175,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002732220} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002732240}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:19 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 03:10:19.426: INFO: Pod "nginx-deployment-555b55d965-tpk7t" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-tpk7t,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-qhcvp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhcvp/pods/nginx-deployment-555b55d965-tpk7t,UID:bbda6a6a-29bc-11e9-a9bb-366cc78d8813,ResourceVersion:69270,Generation:0,CreationTimestamp:2019-02-06 03:10:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b810cd57-29bc-11e9-a9bb-366cc78d8813 0xc0027322b0 0xc0027322b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6779m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6779m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6779m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.175,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002732320} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002732350}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:19 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 03:10:19.426: INFO: Pod "nginx-deployment-555b55d965-wplml" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-wplml,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-qhcvp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhcvp/pods/nginx-deployment-555b55d965-wplml,UID:b81da072-29bc-11e9-a9bb-366cc78d8813,ResourceVersion:69109,Generation:0,CreationTimestamp:2019-02-06 03:10:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b810cd57-29bc-11e9-a9bb-366cc78d8813 0xc0027323c0 0xc0027323c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6779m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6779m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6779m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.144,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002732430} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002732450}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:13 +0000 UTC  }],Message:,Reason:,HostIP:10.190.119.144,PodIP:172.30.175.247,StartTime:2019-02-06 03:10:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-06 03:10:14 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 containerd://750341ed0cea8934014429a887934b01daa155485ddaa50753207d39b494db28}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 03:10:19.427: INFO: Pod "nginx-deployment-555b55d965-xcq2x" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-xcq2x,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-qhcvp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhcvp/pods/nginx-deployment-555b55d965-xcq2x,UID:b81fc5e3-29bc-11e9-a9bb-366cc78d8813,ResourceVersion:69120,Generation:0,CreationTimestamp:2019-02-06 03:10:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b810cd57-29bc-11e9-a9bb-366cc78d8813 0xc002732517 0xc002732518}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6779m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6779m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6779m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002732590} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0027325b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:13 +0000 UTC  }],Message:,Reason:,HostIP:10.190.119.145,PodIP:172.30.70.220,StartTime:2019-02-06 03:10:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-06 03:10:14 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 containerd://22ccc924a8483aea43a0f61594bb9c19bdf8bb597406a5b6ab7d6b75b2323311}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 03:10:19.427: INFO: Pod "nginx-deployment-555b55d965-xspxc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-xspxc,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-qhcvp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhcvp/pods/nginx-deployment-555b55d965-xspxc,UID:bbde00a3-29bc-11e9-a9bb-366cc78d8813,ResourceVersion:69275,Generation:0,CreationTimestamp:2019-02-06 03:10:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b810cd57-29bc-11e9-a9bb-366cc78d8813 0xc002732677 0xc002732678}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6779m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6779m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6779m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0027326f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002732710}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 03:10:19.427: INFO: Pod "nginx-deployment-555b55d965-z9j9t" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-z9j9t,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-qhcvp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhcvp/pods/nginx-deployment-555b55d965-z9j9t,UID:bbd62a3b-29bc-11e9-a9bb-366cc78d8813,ResourceVersion:69278,Generation:0,CreationTimestamp:2019-02-06 03:10:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 b810cd57-29bc-11e9-a9bb-366cc78d8813 0xc002732767 0xc002732768}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6779m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6779m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-6779m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.175,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0027327e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002732800}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:19 +0000 UTC  }],Message:,Reason:,HostIP:10.190.119.175,PodIP:,StartTime:2019-02-06 03:10:19 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 03:10:19.427: INFO: Pod "nginx-deployment-65bbdb5f8-5dsb4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-5dsb4,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-qhcvp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhcvp/pods/nginx-deployment-65bbdb5f8-5dsb4,UID:bbdb04af-29bc-11e9-a9bb-366cc78d8813,ResourceVersion:69262,Generation:0,CreationTimestamp:2019-02-06 03:10:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 ba845a13-29bc-11e9-a9bb-366cc78d8813 0xc0027328b7 0xc0027328b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6779m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6779m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6779m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002732920} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002732940}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 03:10:19.427: INFO: Pod "nginx-deployment-65bbdb5f8-6t2r4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-6t2r4,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-qhcvp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhcvp/pods/nginx-deployment-65bbdb5f8-6t2r4,UID:ba946cdb-29bc-11e9-a9bb-366cc78d8813,ResourceVersion:69243,Generation:0,CreationTimestamp:2019-02-06 03:10:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 ba845a13-29bc-11e9-a9bb-366cc78d8813 0xc002732997 0xc002732998}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6779m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6779m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6779m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.175,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002732a10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002732a40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:17 +0000 UTC  }],Message:,Reason:,HostIP:10.190.119.175,PodIP:172.30.176.18,StartTime:2019-02-06 03:10:17 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": no available registry endpoint: docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 03:10:19.427: INFO: Pod "nginx-deployment-65bbdb5f8-77jz8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-77jz8,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-qhcvp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhcvp/pods/nginx-deployment-65bbdb5f8-77jz8,UID:ba88757e-29bc-11e9-a9bb-366cc78d8813,ResourceVersion:69224,Generation:0,CreationTimestamp:2019-02-06 03:10:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 ba845a13-29bc-11e9-a9bb-366cc78d8813 0xc002732bb0 0xc002732bb1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6779m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6779m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6779m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.175,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002732cb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002732cd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:17 +0000 UTC  }],Message:,Reason:,HostIP:10.190.119.175,PodIP:172.30.176.16,StartTime:2019-02-06 03:10:17 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": no available registry endpoint: docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 03:10:19.427: INFO: Pod "nginx-deployment-65bbdb5f8-8v58r" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-8v58r,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-qhcvp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhcvp/pods/nginx-deployment-65bbdb5f8-8v58r,UID:ba91fc0f-29bc-11e9-a9bb-366cc78d8813,ResourceVersion:69237,Generation:0,CreationTimestamp:2019-02-06 03:10:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 ba845a13-29bc-11e9-a9bb-366cc78d8813 0xc002732db0 0xc002732db1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6779m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6779m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6779m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.144,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002732f00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002732f20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:17 +0000 UTC  }],Message:,Reason:,HostIP:10.190.119.144,PodIP:172.30.175.249,StartTime:2019-02-06 03:10:17 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": no available registry endpoint: docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 03:10:19.428: INFO: Pod "nginx-deployment-65bbdb5f8-bpql4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-bpql4,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-qhcvp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhcvp/pods/nginx-deployment-65bbdb5f8-bpql4,UID:bbddf7f4-29bc-11e9-a9bb-366cc78d8813,ResourceVersion:69273,Generation:0,CreationTimestamp:2019-02-06 03:10:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 ba845a13-29bc-11e9-a9bb-366cc78d8813 0xc002733070 0xc002733071}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6779m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6779m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6779m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0027330e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002733100}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 03:10:19.428: INFO: Pod "nginx-deployment-65bbdb5f8-gxmnr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-gxmnr,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-qhcvp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhcvp/pods/nginx-deployment-65bbdb5f8-gxmnr,UID:bbde0138-29bc-11e9-a9bb-366cc78d8813,ResourceVersion:69274,Generation:0,CreationTimestamp:2019-02-06 03:10:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 ba845a13-29bc-11e9-a9bb-366cc78d8813 0xc002733157 0xc002733158}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6779m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6779m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6779m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0027331e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002733200}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 03:10:19.428: INFO: Pod "nginx-deployment-65bbdb5f8-hpgfj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-hpgfj,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-qhcvp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhcvp/pods/nginx-deployment-65bbdb5f8-hpgfj,UID:ba85f629-29bc-11e9-a9bb-366cc78d8813,ResourceVersion:69234,Generation:0,CreationTimestamp:2019-02-06 03:10:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 ba845a13-29bc-11e9-a9bb-366cc78d8813 0xc002733257 0xc002733258}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6779m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6779m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6779m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.144,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002733340} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002733360}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:17 +0000 UTC  }],Message:,Reason:,HostIP:10.190.119.144,PodIP:172.30.175.248,StartTime:2019-02-06 03:10:17 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": no available registry endpoint: docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 03:10:19.428: INFO: Pod "nginx-deployment-65bbdb5f8-k7r2t" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-k7r2t,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-qhcvp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhcvp/pods/nginx-deployment-65bbdb5f8-k7r2t,UID:ba8863aa-29bc-11e9-a9bb-366cc78d8813,ResourceVersion:69240,Generation:0,CreationTimestamp:2019-02-06 03:10:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 ba845a13-29bc-11e9-a9bb-366cc78d8813 0xc002733440 0xc002733441}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6779m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6779m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6779m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0027334c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0027334e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:17 +0000 UTC  }],Message:,Reason:,HostIP:10.190.119.145,PodIP:172.30.70.225,StartTime:2019-02-06 03:10:17 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": no available registry endpoint: docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 03:10:19.428: INFO: Pod "nginx-deployment-65bbdb5f8-lgb2m" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-lgb2m,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-qhcvp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhcvp/pods/nginx-deployment-65bbdb5f8-lgb2m,UID:bbde15f0-29bc-11e9-a9bb-366cc78d8813,ResourceVersion:69280,Generation:0,CreationTimestamp:2019-02-06 03:10:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 ba845a13-29bc-11e9-a9bb-366cc78d8813 0xc0027335c0 0xc0027335c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6779m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6779m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6779m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002733770} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0027337b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 03:10:19.428: INFO: Pod "nginx-deployment-65bbdb5f8-vvqn9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-vvqn9,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-qhcvp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhcvp/pods/nginx-deployment-65bbdb5f8-vvqn9,UID:bbde0e65-29bc-11e9-a9bb-366cc78d8813,ResourceVersion:69277,Generation:0,CreationTimestamp:2019-02-06 03:10:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 ba845a13-29bc-11e9-a9bb-366cc78d8813 0xc002733807 0xc002733808}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6779m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6779m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6779m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002733a20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002733a40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 03:10:19.428: INFO: Pod "nginx-deployment-65bbdb5f8-wc7f7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-wc7f7,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-qhcvp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhcvp/pods/nginx-deployment-65bbdb5f8-wc7f7,UID:bbd834be-29bc-11e9-a9bb-366cc78d8813,ResourceVersion:69266,Generation:0,CreationTimestamp:2019-02-06 03:10:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 ba845a13-29bc-11e9-a9bb-366cc78d8813 0xc002733a97 0xc002733a98}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6779m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6779m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6779m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002733b10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002733b30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:10:19 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 03:10:19.428: INFO: Pod "nginx-deployment-65bbdb5f8-xph74" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-xph74,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-qhcvp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-qhcvp/pods/nginx-deployment-65bbdb5f8-xph74,UID:bbdb0d28-29bc-11e9-a9bb-366cc78d8813,ResourceVersion:69267,Generation:0,CreationTimestamp:2019-02-06 03:10:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 ba845a13-29bc-11e9-a9bb-366cc78d8813 0xc002733e60 0xc002733e61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-6779m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6779m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-6779m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002733ed0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002733ef0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:10:19.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-qhcvp" for this suite.
Feb  6 03:10:29.486: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:10:29.547: INFO: namespace: e2e-tests-deployment-qhcvp, resource: bindings, ignored listing per whitelist
Feb  6 03:10:29.824: INFO: namespace e2e-tests-deployment-qhcvp deletion completed in 10.383415785s

• [SLOW TEST:17.175 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:10:29.825: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-mk7ld
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-c24753c1-29bc-11e9-b6e7-06cba7aec104
STEP: Creating a pod to test consume configMaps
Feb  6 03:10:30.186: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c2493012-29bc-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-projected-mk7ld" to be "success or failure"
Feb  6 03:10:30.194: INFO: Pod "pod-projected-configmaps-c2493012-29bc-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 7.183359ms
Feb  6 03:10:32.204: INFO: Pod "pod-projected-configmaps-c2493012-29bc-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017184409s
Feb  6 03:10:34.212: INFO: Pod "pod-projected-configmaps-c2493012-29bc-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025520629s
STEP: Saw pod success
Feb  6 03:10:34.212: INFO: Pod "pod-projected-configmaps-c2493012-29bc-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 03:10:34.220: INFO: Trying to get logs from node 10.190.119.145 pod pod-projected-configmaps-c2493012-29bc-11e9-b6e7-06cba7aec104 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  6 03:10:34.297: INFO: Waiting for pod pod-projected-configmaps-c2493012-29bc-11e9-b6e7-06cba7aec104 to disappear
Feb  6 03:10:34.303: INFO: Pod pod-projected-configmaps-c2493012-29bc-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:10:34.304: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mk7ld" for this suite.
Feb  6 03:10:40.354: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:10:40.435: INFO: namespace: e2e-tests-projected-mk7ld, resource: bindings, ignored listing per whitelist
Feb  6 03:10:41.993: INFO: namespace e2e-tests-projected-mk7ld deletion completed in 7.679379108s

• [SLOW TEST:12.169 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:10:41.995: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-jpdtb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb  6 03:10:42.444: INFO: Waiting up to 5m0s for pod "downward-api-c98b7e2f-29bc-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-downward-api-jpdtb" to be "success or failure"
Feb  6 03:10:42.454: INFO: Pod "downward-api-c98b7e2f-29bc-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 9.319555ms
Feb  6 03:10:44.464: INFO: Pod "downward-api-c98b7e2f-29bc-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019747574s
STEP: Saw pod success
Feb  6 03:10:44.464: INFO: Pod "downward-api-c98b7e2f-29bc-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 03:10:44.472: INFO: Trying to get logs from node 10.190.119.175 pod downward-api-c98b7e2f-29bc-11e9-b6e7-06cba7aec104 container dapi-container: <nil>
STEP: delete the pod
Feb  6 03:10:44.525: INFO: Waiting for pod downward-api-c98b7e2f-29bc-11e9-b6e7-06cba7aec104 to disappear
Feb  6 03:10:44.605: INFO: Pod downward-api-c98b7e2f-29bc-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:10:44.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-jpdtb" for this suite.
Feb  6 03:10:50.710: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:10:50.781: INFO: namespace: e2e-tests-downward-api-jpdtb, resource: bindings, ignored listing per whitelist
Feb  6 03:10:51.620: INFO: namespace e2e-tests-downward-api-jpdtb deletion completed in 7.000418348s

• [SLOW TEST:9.626 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:10:51.620: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-hmrxj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  6 03:10:52.154: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Feb  6 03:10:52.184: INFO: Number of nodes with available pods: 0
Feb  6 03:10:52.184: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 03:10:53.204: INFO: Number of nodes with available pods: 0
Feb  6 03:10:53.204: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 03:10:54.204: INFO: Number of nodes with available pods: 3
Feb  6 03:10:54.204: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Feb  6 03:10:54.331: INFO: Wrong image for pod: daemon-set-25sqs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:10:54.332: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:10:54.332: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:10:55.349: INFO: Wrong image for pod: daemon-set-25sqs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:10:55.349: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:10:55.349: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:10:56.350: INFO: Wrong image for pod: daemon-set-25sqs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:10:56.350: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:10:56.350: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:10:57.349: INFO: Wrong image for pod: daemon-set-25sqs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:10:57.349: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:10:57.349: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:10:58.349: INFO: Wrong image for pod: daemon-set-25sqs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:10:58.350: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:10:58.350: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:10:59.370: INFO: Wrong image for pod: daemon-set-25sqs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:10:59.370: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:10:59.370: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:00.351: INFO: Wrong image for pod: daemon-set-25sqs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:00.351: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:00.351: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:01.349: INFO: Wrong image for pod: daemon-set-25sqs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:01.350: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:01.350: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:02.350: INFO: Wrong image for pod: daemon-set-25sqs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:02.350: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:02.350: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:03.349: INFO: Wrong image for pod: daemon-set-25sqs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:03.349: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:03.349: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:04.350: INFO: Wrong image for pod: daemon-set-25sqs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:04.350: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:04.350: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:05.352: INFO: Wrong image for pod: daemon-set-25sqs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:05.352: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:05.352: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:06.354: INFO: Wrong image for pod: daemon-set-25sqs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:06.354: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:06.354: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:07.350: INFO: Wrong image for pod: daemon-set-25sqs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:07.350: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:07.350: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:08.350: INFO: Wrong image for pod: daemon-set-25sqs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:08.350: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:08.350: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:09.351: INFO: Wrong image for pod: daemon-set-25sqs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:09.351: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:09.351: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:10.366: INFO: Wrong image for pod: daemon-set-25sqs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:10.367: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:10.367: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:11.349: INFO: Wrong image for pod: daemon-set-25sqs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:11.349: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:11.349: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:12.353: INFO: Wrong image for pod: daemon-set-25sqs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:12.353: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:12.353: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:13.349: INFO: Wrong image for pod: daemon-set-25sqs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:13.350: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:13.350: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:14.348: INFO: Wrong image for pod: daemon-set-25sqs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:14.348: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:14.348: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:15.350: INFO: Wrong image for pod: daemon-set-25sqs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:15.350: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:15.350: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:16.353: INFO: Wrong image for pod: daemon-set-25sqs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:16.353: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:16.353: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:17.353: INFO: Wrong image for pod: daemon-set-25sqs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:17.353: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:17.353: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:18.350: INFO: Wrong image for pod: daemon-set-25sqs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:18.350: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:18.350: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:19.349: INFO: Wrong image for pod: daemon-set-25sqs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:19.350: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:19.350: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:20.349: INFO: Wrong image for pod: daemon-set-25sqs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:20.349: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:20.349: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:21.373: INFO: Wrong image for pod: daemon-set-25sqs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:21.373: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:21.373: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:22.349: INFO: Wrong image for pod: daemon-set-25sqs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:22.349: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:22.349: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:23.349: INFO: Wrong image for pod: daemon-set-25sqs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:23.349: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:23.349: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:24.349: INFO: Wrong image for pod: daemon-set-25sqs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:24.349: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:24.349: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:25.349: INFO: Wrong image for pod: daemon-set-25sqs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:25.350: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:25.350: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:26.375: INFO: Wrong image for pod: daemon-set-25sqs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:26.375: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:26.375: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:27.349: INFO: Wrong image for pod: daemon-set-25sqs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:27.349: INFO: Pod daemon-set-25sqs is not available
Feb  6 03:11:27.349: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:27.349: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:28.354: INFO: Wrong image for pod: daemon-set-25sqs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:28.354: INFO: Pod daemon-set-25sqs is not available
Feb  6 03:11:28.354: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:28.354: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:29.352: INFO: Wrong image for pod: daemon-set-25sqs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:29.352: INFO: Pod daemon-set-25sqs is not available
Feb  6 03:11:29.352: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:29.352: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:30.349: INFO: Wrong image for pod: daemon-set-25sqs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:30.349: INFO: Pod daemon-set-25sqs is not available
Feb  6 03:11:30.349: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:30.349: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:31.353: INFO: Wrong image for pod: daemon-set-25sqs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:31.353: INFO: Pod daemon-set-25sqs is not available
Feb  6 03:11:31.353: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:31.353: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:32.370: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:32.370: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:32.371: INFO: Pod daemon-set-hqvh6 is not available
Feb  6 03:11:33.350: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:33.350: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:33.350: INFO: Pod daemon-set-hqvh6 is not available
Feb  6 03:11:34.350: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:34.350: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:35.349: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:35.349: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:36.359: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:36.359: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:37.351: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:37.351: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:38.349: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:38.350: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:39.352: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:39.352: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:40.350: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:40.350: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:41.349: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:41.349: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:42.349: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:42.349: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:43.378: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:43.379: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:44.356: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:44.356: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:45.349: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:45.349: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:46.353: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:46.354: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:47.349: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:47.349: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:48.349: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:48.349: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:49.349: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:49.349: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:50.350: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:50.350: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:51.351: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:51.351: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:52.349: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:52.349: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:53.349: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:53.349: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:54.364: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:54.364: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:55.349: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:55.349: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:56.620: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:56.620: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:57.350: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:57.350: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:58.349: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:58.349: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:59.350: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:11:59.350: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:12:00.352: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:12:00.352: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:12:01.349: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:12:01.350: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:12:02.353: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:12:02.353: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:12:03.349: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:12:03.349: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:12:04.353: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:12:04.353: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:12:05.366: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:12:05.366: INFO: Wrong image for pod: daemon-set-djr9b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:12:05.366: INFO: Pod daemon-set-djr9b is not available
Feb  6 03:12:06.351: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:12:06.351: INFO: Pod daemon-set-l5crs is not available
Feb  6 03:12:07.349: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:12:07.349: INFO: Pod daemon-set-l5crs is not available
Feb  6 03:12:08.349: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:12:09.350: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:12:10.351: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:12:11.349: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:12:12.404: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:12:13.350: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:12:14.349: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:12:15.350: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:12:16.374: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:12:17.350: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:12:18.351: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:12:19.351: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:12:20.351: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:12:21.350: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:12:22.350: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:12:23.348: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:12:24.351: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:12:25.349: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:12:26.356: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:12:27.365: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:12:28.353: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:12:29.353: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:12:30.350: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:12:31.356: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:12:32.349: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:12:33.350: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:12:34.350: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:12:35.350: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:12:36.353: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:12:37.351: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:12:38.376: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:12:39.386: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:12:39.386: INFO: Pod daemon-set-8tpdr is not available
Feb  6 03:12:40.349: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:12:40.350: INFO: Pod daemon-set-8tpdr is not available
Feb  6 03:12:41.349: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:12:41.349: INFO: Pod daemon-set-8tpdr is not available
Feb  6 03:12:42.350: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:12:42.350: INFO: Pod daemon-set-8tpdr is not available
Feb  6 03:12:43.349: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:12:43.349: INFO: Pod daemon-set-8tpdr is not available
Feb  6 03:12:44.351: INFO: Wrong image for pod: daemon-set-8tpdr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:12:44.351: INFO: Pod daemon-set-8tpdr is not available
Feb  6 03:12:45.350: INFO: Pod daemon-set-zmdtt is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Feb  6 03:12:45.416: INFO: Number of nodes with available pods: 2
Feb  6 03:12:45.416: INFO: Node 10.190.119.145 is running more than one daemon pod
Feb  6 03:12:46.504: INFO: Number of nodes with available pods: 3
Feb  6 03:12:46.504: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-hmrxj, will wait for the garbage collector to delete the pods
Feb  6 03:12:46.637: INFO: Deleting DaemonSet.extensions daemon-set took: 17.802651ms
Feb  6 03:12:46.737: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.21498ms
Feb  6 03:12:54.662: INFO: Number of nodes with available pods: 0
Feb  6 03:12:54.662: INFO: Number of running nodes: 0, number of available pods: 0
Feb  6 03:12:54.668: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-hmrxj/daemonsets","resourceVersion":"70251"},"items":null}

Feb  6 03:12:54.709: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-hmrxj/pods","resourceVersion":"70251"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:12:54.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-hmrxj" for this suite.
Feb  6 03:13:02.792: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:13:02.821: INFO: namespace: e2e-tests-daemonsets-hmrxj, resource: bindings, ignored listing per whitelist
Feb  6 03:13:03.210: INFO: namespace e2e-tests-daemonsets-hmrxj deletion completed in 8.457402384s

• [SLOW TEST:131.590 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:13:03.212: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-gn6nx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb  6 03:13:03.680: INFO: Waiting up to 5m0s for pod "pod-1dc69966-29bd-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-emptydir-gn6nx" to be "success or failure"
Feb  6 03:13:03.705: INFO: Pod "pod-1dc69966-29bd-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 25.646059ms
Feb  6 03:13:05.742: INFO: Pod "pod-1dc69966-29bd-11e9-b6e7-06cba7aec104": Phase="Running", Reason="", readiness=true. Elapsed: 2.062669717s
Feb  6 03:13:07.750: INFO: Pod "pod-1dc69966-29bd-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.069987496s
STEP: Saw pod success
Feb  6 03:13:07.750: INFO: Pod "pod-1dc69966-29bd-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 03:13:07.757: INFO: Trying to get logs from node 10.190.119.144 pod pod-1dc69966-29bd-11e9-b6e7-06cba7aec104 container test-container: <nil>
STEP: delete the pod
Feb  6 03:13:07.801: INFO: Waiting for pod pod-1dc69966-29bd-11e9-b6e7-06cba7aec104 to disappear
Feb  6 03:13:07.809: INFO: Pod pod-1dc69966-29bd-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:13:07.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-gn6nx" for this suite.
Feb  6 03:13:13.856: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:13:14.004: INFO: namespace: e2e-tests-emptydir-gn6nx, resource: bindings, ignored listing per whitelist
Feb  6 03:13:14.218: INFO: namespace e2e-tests-emptydir-gn6nx deletion completed in 6.399126521s

• [SLOW TEST:11.006 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:13:14.219: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-p9rvn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-p9rvn
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-p9rvn to expose endpoints map[]
Feb  6 03:13:14.591: INFO: Get endpoints failed (9.046852ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Feb  6 03:13:15.600: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-p9rvn exposes endpoints map[] (1.018840435s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-p9rvn
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-p9rvn to expose endpoints map[pod1:[100]]
Feb  6 03:13:17.690: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-p9rvn exposes endpoints map[pod1:[100]] (2.068447772s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-p9rvn
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-p9rvn to expose endpoints map[pod1:[100] pod2:[101]]
Feb  6 03:13:18.830: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-p9rvn exposes endpoints map[pod1:[100] pod2:[101]] (1.128342549s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-p9rvn
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-p9rvn to expose endpoints map[pod2:[101]]
Feb  6 03:13:19.889: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-p9rvn exposes endpoints map[pod2:[101]] (1.045167025s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-p9rvn
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-p9rvn to expose endpoints map[]
Feb  6 03:13:19.915: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-p9rvn exposes endpoints map[] (11.246179ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:13:19.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-p9rvn" for this suite.
Feb  6 03:13:44.034: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:13:44.308: INFO: namespace: e2e-tests-services-p9rvn, resource: bindings, ignored listing per whitelist
Feb  6 03:13:44.431: INFO: namespace e2e-tests-services-p9rvn deletion completed in 24.432465252s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:30.212 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:13:44.432: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-sgrhs
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-3656af90-29bd-11e9-b6e7-06cba7aec104
STEP: Creating a pod to test consume secrets
Feb  6 03:13:44.912: INFO: Waiting up to 5m0s for pod "pod-secrets-365872f5-29bd-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-secrets-sgrhs" to be "success or failure"
Feb  6 03:13:44.920: INFO: Pod "pod-secrets-365872f5-29bd-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 7.846029ms
Feb  6 03:13:47.439: INFO: Pod "pod-secrets-365872f5-29bd-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.527364951s
STEP: Saw pod success
Feb  6 03:13:47.439: INFO: Pod "pod-secrets-365872f5-29bd-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 03:13:47.454: INFO: Trying to get logs from node 10.190.119.144 pod pod-secrets-365872f5-29bd-11e9-b6e7-06cba7aec104 container secret-volume-test: <nil>
STEP: delete the pod
Feb  6 03:13:47.504: INFO: Waiting for pod pod-secrets-365872f5-29bd-11e9-b6e7-06cba7aec104 to disappear
Feb  6 03:13:47.512: INFO: Pod pod-secrets-365872f5-29bd-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:13:47.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-sgrhs" for this suite.
Feb  6 03:13:53.563: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:13:53.623: INFO: namespace: e2e-tests-secrets-sgrhs, resource: bindings, ignored listing per whitelist
Feb  6 03:13:54.018: INFO: namespace e2e-tests-secrets-sgrhs deletion completed in 6.49459523s

• [SLOW TEST:9.586 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:13:54.018: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-gwjcz
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-3bf84f1b-29bd-11e9-b6e7-06cba7aec104
STEP: Creating a pod to test consume secrets
Feb  6 03:13:54.350: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-3bfa0fa9-29bd-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-projected-gwjcz" to be "success or failure"
Feb  6 03:13:54.404: INFO: Pod "pod-projected-secrets-3bfa0fa9-29bd-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 53.61926ms
Feb  6 03:13:56.412: INFO: Pod "pod-projected-secrets-3bfa0fa9-29bd-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.06151504s
STEP: Saw pod success
Feb  6 03:13:56.412: INFO: Pod "pod-projected-secrets-3bfa0fa9-29bd-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 03:13:56.424: INFO: Trying to get logs from node 10.190.119.145 pod pod-projected-secrets-3bfa0fa9-29bd-11e9-b6e7-06cba7aec104 container secret-volume-test: <nil>
STEP: delete the pod
Feb  6 03:13:56.523: INFO: Waiting for pod pod-projected-secrets-3bfa0fa9-29bd-11e9-b6e7-06cba7aec104 to disappear
Feb  6 03:13:56.531: INFO: Pod pod-projected-secrets-3bfa0fa9-29bd-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:13:56.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gwjcz" for this suite.
Feb  6 03:14:04.579: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:14:04.678: INFO: namespace: e2e-tests-projected-gwjcz, resource: bindings, ignored listing per whitelist
Feb  6 03:14:04.897: INFO: namespace e2e-tests-projected-gwjcz deletion completed in 8.353986452s

• [SLOW TEST:10.879 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:14:04.899: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-wvkqg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Feb  6 03:14:05.254: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 create -f - --namespace=e2e-tests-kubectl-wvkqg'
Feb  6 03:14:05.838: INFO: stderr: ""
Feb  6 03:14:05.838: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb  6 03:14:06.845: INFO: Selector matched 1 pods for map[app:redis]
Feb  6 03:14:06.845: INFO: Found 0 / 1
Feb  6 03:14:07.845: INFO: Selector matched 1 pods for map[app:redis]
Feb  6 03:14:07.845: INFO: Found 1 / 1
Feb  6 03:14:07.845: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Feb  6 03:14:07.854: INFO: Selector matched 1 pods for map[app:redis]
Feb  6 03:14:07.854: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb  6 03:14:07.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 patch pod redis-master-qfrrm --namespace=e2e-tests-kubectl-wvkqg -p {"metadata":{"annotations":{"x":"y"}}}'
Feb  6 03:14:07.983: INFO: stderr: ""
Feb  6 03:14:07.983: INFO: stdout: "pod/redis-master-qfrrm patched\n"
STEP: checking annotations
Feb  6 03:14:07.993: INFO: Selector matched 1 pods for map[app:redis]
Feb  6 03:14:07.993: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:14:07.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wvkqg" for this suite.
Feb  6 03:14:32.045: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:14:32.412: INFO: namespace: e2e-tests-kubectl-wvkqg, resource: bindings, ignored listing per whitelist
Feb  6 03:14:32.412: INFO: namespace e2e-tests-kubectl-wvkqg deletion completed in 24.408228152s

• [SLOW TEST:27.514 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:14:32.412: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-p6w7j
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-52e0b014-29bd-11e9-b6e7-06cba7aec104
STEP: Creating a pod to test consume configMaps
Feb  6 03:14:32.780: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-52e22391-29bd-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-projected-p6w7j" to be "success or failure"
Feb  6 03:14:32.787: INFO: Pod "pod-projected-configmaps-52e22391-29bd-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 6.96469ms
Feb  6 03:14:34.795: INFO: Pod "pod-projected-configmaps-52e22391-29bd-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014953077s
STEP: Saw pod success
Feb  6 03:14:34.795: INFO: Pod "pod-projected-configmaps-52e22391-29bd-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 03:14:34.802: INFO: Trying to get logs from node 10.190.119.144 pod pod-projected-configmaps-52e22391-29bd-11e9-b6e7-06cba7aec104 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  6 03:14:34.897: INFO: Waiting for pod pod-projected-configmaps-52e22391-29bd-11e9-b6e7-06cba7aec104 to disappear
Feb  6 03:14:34.907: INFO: Pod pod-projected-configmaps-52e22391-29bd-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:14:34.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-p6w7j" for this suite.
Feb  6 03:14:40.967: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:14:42.010: INFO: namespace: e2e-tests-projected-p6w7j, resource: bindings, ignored listing per whitelist
Feb  6 03:14:42.039: INFO: namespace e2e-tests-projected-p6w7j deletion completed in 7.121292723s

• [SLOW TEST:9.627 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:14:42.039: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-c2pf6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb  6 03:14:42.431: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:14:44.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-c2pf6" for this suite.
Feb  6 03:14:51.048: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:14:51.391: INFO: namespace: e2e-tests-init-container-c2pf6, resource: bindings, ignored listing per whitelist
Feb  6 03:14:51.391: INFO: namespace e2e-tests-init-container-c2pf6 deletion completed in 6.392127061s

• [SLOW TEST:9.352 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:14:51.392: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-4z92d
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-5e313c9c-29bd-11e9-b6e7-06cba7aec104
STEP: Creating a pod to test consume configMaps
Feb  6 03:14:51.764: INFO: Waiting up to 5m0s for pod "pod-configmaps-5e32a469-29bd-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-configmap-4z92d" to be "success or failure"
Feb  6 03:14:51.772: INFO: Pod "pod-configmaps-5e32a469-29bd-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 8.183646ms
Feb  6 03:14:53.780: INFO: Pod "pod-configmaps-5e32a469-29bd-11e9-b6e7-06cba7aec104": Phase="Running", Reason="", readiness=true. Elapsed: 2.016253945s
Feb  6 03:14:55.806: INFO: Pod "pod-configmaps-5e32a469-29bd-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041640784s
STEP: Saw pod success
Feb  6 03:14:55.806: INFO: Pod "pod-configmaps-5e32a469-29bd-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 03:14:55.813: INFO: Trying to get logs from node 10.190.119.145 pod pod-configmaps-5e32a469-29bd-11e9-b6e7-06cba7aec104 container configmap-volume-test: <nil>
STEP: delete the pod
Feb  6 03:14:55.853: INFO: Waiting for pod pod-configmaps-5e32a469-29bd-11e9-b6e7-06cba7aec104 to disappear
Feb  6 03:14:55.861: INFO: Pod pod-configmaps-5e32a469-29bd-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:14:55.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-4z92d" for this suite.
Feb  6 03:15:01.913: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:15:02.030: INFO: namespace: e2e-tests-configmap-4z92d, resource: bindings, ignored listing per whitelist
Feb  6 03:15:02.298: INFO: namespace e2e-tests-configmap-4z92d deletion completed in 6.426320275s

• [SLOW TEST:10.907 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:15:02.299: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-p67l2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-p67l2
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb  6 03:15:02.640: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb  6 03:15:22.952: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 172.30.176.32 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-p67l2 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 03:15:22.952: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
Feb  6 03:15:24.198: INFO: Found all expected endpoints: [netserver-0]
Feb  6 03:15:24.205: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 172.30.175.200 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-p67l2 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 03:15:24.205: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
Feb  6 03:15:25.448: INFO: Found all expected endpoints: [netserver-1]
Feb  6 03:15:25.829: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 172.30.70.237 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-p67l2 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 03:15:25.829: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
Feb  6 03:15:27.077: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:15:27.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-p67l2" for this suite.
Feb  6 03:15:51.139: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:15:51.259: INFO: namespace: e2e-tests-pod-network-test-p67l2, resource: bindings, ignored listing per whitelist
Feb  6 03:15:51.567: INFO: namespace e2e-tests-pod-network-test-p67l2 deletion completed in 24.468024163s

• [SLOW TEST:49.268 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:15:51.567: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-plwdw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-820b3c15-29bd-11e9-b6e7-06cba7aec104
STEP: Creating a pod to test consume secrets
Feb  6 03:15:51.914: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-820ce7e0-29bd-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-projected-plwdw" to be "success or failure"
Feb  6 03:15:51.922: INFO: Pod "pod-projected-secrets-820ce7e0-29bd-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 8.212203ms
Feb  6 03:15:53.948: INFO: Pod "pod-projected-secrets-820ce7e0-29bd-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.034050123s
STEP: Saw pod success
Feb  6 03:15:53.948: INFO: Pod "pod-projected-secrets-820ce7e0-29bd-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 03:15:53.955: INFO: Trying to get logs from node 10.190.119.175 pod pod-projected-secrets-820ce7e0-29bd-11e9-b6e7-06cba7aec104 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb  6 03:15:54.002: INFO: Waiting for pod pod-projected-secrets-820ce7e0-29bd-11e9-b6e7-06cba7aec104 to disappear
Feb  6 03:15:54.009: INFO: Pod pod-projected-secrets-820ce7e0-29bd-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:15:54.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-plwdw" for this suite.
Feb  6 03:16:02.117: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:16:02.370: INFO: namespace: e2e-tests-projected-plwdw, resource: bindings, ignored listing per whitelist
Feb  6 03:16:02.516: INFO: namespace e2e-tests-projected-plwdw deletion completed in 8.496419691s

• [SLOW TEST:10.949 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:16:02.517: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-9vml9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1399
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb  6 03:16:02.941: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-9vml9'
Feb  6 03:16:03.072: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb  6 03:16:03.072: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1404
Feb  6 03:16:07.117: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-9vml9'
Feb  6 03:16:07.259: INFO: stderr: ""
Feb  6 03:16:07.259: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:16:07.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-9vml9" for this suite.
Feb  6 03:16:13.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:16:13.500: INFO: namespace: e2e-tests-kubectl-9vml9, resource: bindings, ignored listing per whitelist
Feb  6 03:16:13.751: INFO: namespace e2e-tests-kubectl-9vml9 deletion completed in 6.480761797s

• [SLOW TEST:11.235 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:16:13.751: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-2zbh2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  6 03:16:14.159: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Feb  6 03:16:19.185: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb  6 03:16:19.185: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb  6 03:16:19.251: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-2zbh2,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-2zbh2/deployments/test-cleanup-deployment,UID:92529cb7-29bd-11e9-9423-66f50c9be06e,ResourceVersion:71199,Generation:1,CreationTimestamp:2019-02-06 03:16:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Feb  6 03:16:19.262: INFO: New ReplicaSet "test-cleanup-deployment-7dbbfcf846" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-7dbbfcf846,GenerateName:,Namespace:e2e-tests-deployment-2zbh2,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-2zbh2/replicasets/test-cleanup-deployment-7dbbfcf846,UID:925a7b74-29bd-11e9-a9bb-366cc78d8813,ResourceVersion:71201,Generation:1,CreationTimestamp:2019-02-06 03:16:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 92529cb7-29bd-11e9-9423-66f50c9be06e 0xc001b111c7 0xc001b111c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 7dbbfcf846,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb  6 03:16:19.262: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Feb  6 03:16:19.262: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:e2e-tests-deployment-2zbh2,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-2zbh2/replicasets/test-cleanup-controller,UID:8f4f3c6b-29bd-11e9-9423-66f50c9be06e,ResourceVersion:71200,Generation:1,CreationTimestamp:2019-02-06 03:16:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 92529cb7-29bd-11e9-9423-66f50c9be06e 0xc001b11107 0xc001b11108}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb  6 03:16:19.270: INFO: Pod "test-cleanup-controller-qsnvv" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-qsnvv,GenerateName:test-cleanup-controller-,Namespace:e2e-tests-deployment-2zbh2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2zbh2/pods/test-cleanup-controller-qsnvv,UID:8f5571d1-29bd-11e9-a9bb-366cc78d8813,ResourceVersion:71191,Generation:0,CreationTimestamp:2019-02-06 03:16:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller 8f4f3c6b-29bd-11e9-9423-66f50c9be06e 0xc001b11b77 0xc001b11b78}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-q7sqj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-q7sqj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-q7sqj true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.145,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001b11bf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001b11c10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:16:14 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:16:15 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:16:15 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 03:16:14 +0000 UTC  }],Message:,Reason:,HostIP:10.190.119.145,PodIP:172.30.70.239,StartTime:2019-02-06 03:16:14 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-06 03:16:15 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 containerd://18b1d0ed639d570116731505eeca1ef19ef02a652c758ab07150677e337aeec3}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:16:19.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-2zbh2" for this suite.
Feb  6 03:16:27.463: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:16:27.652: INFO: namespace: e2e-tests-deployment-2zbh2, resource: bindings, ignored listing per whitelist
Feb  6 03:16:27.802: INFO: namespace e2e-tests-deployment-2zbh2 deletion completed in 8.522106693s

• [SLOW TEST:14.051 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:16:27.802: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-fsfr2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Feb  6 03:16:28.223: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-fsfr2,SelfLink:/api/v1/namespaces/e2e-tests-watch-fsfr2/configmaps/e2e-watch-test-resource-version,UID:97a7f941-29bd-11e9-9423-66f50c9be06e,ResourceVersion:71275,Generation:0,CreationTimestamp:2019-02-06 03:16:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb  6 03:16:28.224: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-fsfr2,SelfLink:/api/v1/namespaces/e2e-tests-watch-fsfr2/configmaps/e2e-watch-test-resource-version,UID:97a7f941-29bd-11e9-9423-66f50c9be06e,ResourceVersion:71276,Generation:0,CreationTimestamp:2019-02-06 03:16:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:16:28.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-fsfr2" for this suite.
Feb  6 03:16:34.276: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:16:35.072: INFO: namespace: e2e-tests-watch-fsfr2, resource: bindings, ignored listing per whitelist
Feb  6 03:16:35.256: INFO: namespace e2e-tests-watch-fsfr2 deletion completed in 7.021428158s

• [SLOW TEST:7.454 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:16:35.257: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-tdb2d
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-tdb2d/configmap-test-9c1e1f44-29bd-11e9-b6e7-06cba7aec104
STEP: Creating a pod to test consume configMaps
Feb  6 03:16:35.654: INFO: Waiting up to 5m0s for pod "pod-configmaps-9c1f7b5f-29bd-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-configmap-tdb2d" to be "success or failure"
Feb  6 03:16:35.662: INFO: Pod "pod-configmaps-9c1f7b5f-29bd-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 7.751491ms
Feb  6 03:16:37.672: INFO: Pod "pod-configmaps-9c1f7b5f-29bd-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018055472s
STEP: Saw pod success
Feb  6 03:16:37.672: INFO: Pod "pod-configmaps-9c1f7b5f-29bd-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 03:16:37.680: INFO: Trying to get logs from node 10.190.119.144 pod pod-configmaps-9c1f7b5f-29bd-11e9-b6e7-06cba7aec104 container env-test: <nil>
STEP: delete the pod
Feb  6 03:16:37.726: INFO: Waiting for pod pod-configmaps-9c1f7b5f-29bd-11e9-b6e7-06cba7aec104 to disappear
Feb  6 03:16:37.740: INFO: Pod pod-configmaps-9c1f7b5f-29bd-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:16:37.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-tdb2d" for this suite.
Feb  6 03:16:43.809: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:16:44.177: INFO: namespace: e2e-tests-configmap-tdb2d, resource: bindings, ignored listing per whitelist
Feb  6 03:16:44.263: INFO: namespace e2e-tests-configmap-tdb2d deletion completed in 6.511125973s

• [SLOW TEST:9.006 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:16:44.264: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-l5fvp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:16:49.497: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-l5fvp" for this suite.
Feb  6 03:16:55.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:16:56.479: INFO: namespace: e2e-tests-kubelet-test-l5fvp, resource: bindings, ignored listing per whitelist
Feb  6 03:16:56.691: INFO: namespace e2e-tests-kubelet-test-l5fvp deletion completed in 7.183369711s

• [SLOW TEST:12.428 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:16:56.692: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-vv5vx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb  6 03:16:57.036: INFO: PodSpec: initContainers in spec.initContainers
Feb  6 03:17:42.421: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-a8e0adb0-29bd-11e9-b6e7-06cba7aec104", GenerateName:"", Namespace:"e2e-tests-init-container-vv5vx", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-vv5vx/pods/pod-init-a8e0adb0-29bd-11e9-b6e7-06cba7aec104", UID:"a8e2463b-29bd-11e9-9423-66f50c9be06e", ResourceVersion:"71549", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63685019817, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"36542314"}, Annotations:map[string]string{"kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-xrbn4", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc000eb9c40), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-xrbn4", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-xrbn4", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}, "cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-xrbn4", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001a70ba8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"10.190.119.175", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc000e49b00), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001a715c0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001a715e0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc001a715e8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc001a715ec)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685019817, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685019817, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685019817, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685019817, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.190.119.175", PodIP:"172.30.176.35", StartTime:(*v1.Time)(0xc0013cecc0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000f7c230)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000f7c310)}, Ready:false, RestartCount:3, Image:"docker.io/library/busybox:1.29", ImageID:"docker.io/library/busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"containerd://c8d6a761e63ed5504daa42ad4f7d76e90ec77a7b7c9b0dceaffb7eb5ab778c9f"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0013ced20), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0013ced00), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:17:42.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-vv5vx" for this suite.
Feb  6 03:18:06.512: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:18:06.790: INFO: namespace: e2e-tests-init-container-vv5vx, resource: bindings, ignored listing per whitelist
Feb  6 03:18:06.907: INFO: namespace e2e-tests-init-container-vv5vx deletion completed in 24.454560407s

• [SLOW TEST:70.215 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:18:06.907: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-66h26
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-d2baaa0c-29bd-11e9-b6e7-06cba7aec104
STEP: Creating a pod to test consume configMaps
Feb  6 03:18:07.324: INFO: Waiting up to 5m0s for pod "pod-configmaps-d2c32900-29bd-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-configmap-66h26" to be "success or failure"
Feb  6 03:18:07.331: INFO: Pod "pod-configmaps-d2c32900-29bd-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 7.269877ms
Feb  6 03:18:09.397: INFO: Pod "pod-configmaps-d2c32900-29bd-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 2.073278361s
Feb  6 03:18:11.405: INFO: Pod "pod-configmaps-d2c32900-29bd-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.081430823s
STEP: Saw pod success
Feb  6 03:18:11.405: INFO: Pod "pod-configmaps-d2c32900-29bd-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 03:18:11.414: INFO: Trying to get logs from node 10.190.119.144 pod pod-configmaps-d2c32900-29bd-11e9-b6e7-06cba7aec104 container configmap-volume-test: <nil>
STEP: delete the pod
Feb  6 03:18:11.458: INFO: Waiting for pod pod-configmaps-d2c32900-29bd-11e9-b6e7-06cba7aec104 to disappear
Feb  6 03:18:11.465: INFO: Pod pod-configmaps-d2c32900-29bd-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:18:11.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-66h26" for this suite.
Feb  6 03:18:17.517: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:18:17.629: INFO: namespace: e2e-tests-configmap-66h26, resource: bindings, ignored listing per whitelist
Feb  6 03:18:17.939: INFO: namespace e2e-tests-configmap-66h26 deletion completed in 6.461255967s

• [SLOW TEST:11.032 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:18:17.940: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-k78q6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-k78q6
Feb  6 03:18:20.641: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-k78q6
STEP: checking the pod's current state and verifying that restartCount is present
Feb  6 03:18:20.649: INFO: Initial restart count of pod liveness-http is 0
Feb  6 03:18:32.964: INFO: Restart count of pod e2e-tests-container-probe-k78q6/liveness-http is now 1 (12.314197109s elapsed)
Feb  6 03:18:53.081: INFO: Restart count of pod e2e-tests-container-probe-k78q6/liveness-http is now 2 (32.431255114s elapsed)
Feb  6 03:19:13.204: INFO: Restart count of pod e2e-tests-container-probe-k78q6/liveness-http is now 3 (52.55433075s elapsed)
Feb  6 03:19:33.762: INFO: Restart count of pod e2e-tests-container-probe-k78q6/liveness-http is now 4 (1m13.112594312s elapsed)
Feb  6 03:20:42.856: INFO: Restart count of pod e2e-tests-container-probe-k78q6/liveness-http is now 5 (2m22.206392597s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:20:42.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-k78q6" for this suite.
Feb  6 03:20:50.942: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:20:51.414: INFO: namespace: e2e-tests-container-probe-k78q6, resource: bindings, ignored listing per whitelist
Feb  6 03:20:51.558: INFO: namespace e2e-tests-container-probe-k78q6 deletion completed in 8.658857418s

• [SLOW TEST:153.618 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:20:51.558: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-7j9dz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb  6 03:20:52.082: INFO: Number of nodes with available pods: 0
Feb  6 03:20:52.082: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 03:20:53.106: INFO: Number of nodes with available pods: 0
Feb  6 03:20:53.106: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 03:20:54.104: INFO: Number of nodes with available pods: 3
Feb  6 03:20:54.104: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Feb  6 03:20:54.155: INFO: Number of nodes with available pods: 2
Feb  6 03:20:54.155: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 03:20:55.174: INFO: Number of nodes with available pods: 2
Feb  6 03:20:55.174: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 03:20:56.197: INFO: Number of nodes with available pods: 2
Feb  6 03:20:56.197: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 03:20:57.176: INFO: Number of nodes with available pods: 2
Feb  6 03:20:57.176: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 03:20:58.181: INFO: Number of nodes with available pods: 2
Feb  6 03:20:58.181: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 03:20:59.192: INFO: Number of nodes with available pods: 2
Feb  6 03:20:59.192: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 03:21:00.173: INFO: Number of nodes with available pods: 2
Feb  6 03:21:00.173: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 03:21:01.197: INFO: Number of nodes with available pods: 2
Feb  6 03:21:01.197: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 03:21:02.176: INFO: Number of nodes with available pods: 2
Feb  6 03:21:02.176: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 03:21:03.174: INFO: Number of nodes with available pods: 2
Feb  6 03:21:03.175: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 03:21:04.197: INFO: Number of nodes with available pods: 2
Feb  6 03:21:04.197: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 03:21:05.174: INFO: Number of nodes with available pods: 2
Feb  6 03:21:05.174: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 03:21:06.174: INFO: Number of nodes with available pods: 2
Feb  6 03:21:06.174: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 03:21:07.176: INFO: Number of nodes with available pods: 2
Feb  6 03:21:07.176: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 03:21:08.174: INFO: Number of nodes with available pods: 2
Feb  6 03:21:08.175: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 03:21:09.223: INFO: Number of nodes with available pods: 2
Feb  6 03:21:09.223: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 03:21:10.197: INFO: Number of nodes with available pods: 2
Feb  6 03:21:10.197: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 03:21:11.178: INFO: Number of nodes with available pods: 2
Feb  6 03:21:11.178: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 03:21:12.175: INFO: Number of nodes with available pods: 2
Feb  6 03:21:12.176: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 03:21:13.174: INFO: Number of nodes with available pods: 2
Feb  6 03:21:13.175: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 03:21:14.174: INFO: Number of nodes with available pods: 2
Feb  6 03:21:14.174: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 03:21:15.175: INFO: Number of nodes with available pods: 2
Feb  6 03:21:15.175: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 03:21:16.174: INFO: Number of nodes with available pods: 2
Feb  6 03:21:16.175: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 03:21:17.174: INFO: Number of nodes with available pods: 2
Feb  6 03:21:17.174: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 03:21:18.176: INFO: Number of nodes with available pods: 2
Feb  6 03:21:18.176: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 03:21:19.174: INFO: Number of nodes with available pods: 2
Feb  6 03:21:19.174: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 03:21:20.207: INFO: Number of nodes with available pods: 2
Feb  6 03:21:20.208: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 03:21:21.174: INFO: Number of nodes with available pods: 2
Feb  6 03:21:21.174: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 03:21:22.197: INFO: Number of nodes with available pods: 2
Feb  6 03:21:22.197: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 03:21:23.178: INFO: Number of nodes with available pods: 2
Feb  6 03:21:23.178: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 03:21:24.776: INFO: Number of nodes with available pods: 2
Feb  6 03:21:24.777: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 03:21:25.173: INFO: Number of nodes with available pods: 2
Feb  6 03:21:25.173: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 03:21:26.175: INFO: Number of nodes with available pods: 2
Feb  6 03:21:26.175: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 03:21:27.176: INFO: Number of nodes with available pods: 2
Feb  6 03:21:27.176: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 03:21:28.197: INFO: Number of nodes with available pods: 2
Feb  6 03:21:28.197: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 03:21:29.174: INFO: Number of nodes with available pods: 2
Feb  6 03:21:29.174: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 03:21:30.174: INFO: Number of nodes with available pods: 2
Feb  6 03:21:30.174: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 03:21:31.191: INFO: Number of nodes with available pods: 2
Feb  6 03:21:31.191: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 03:21:32.175: INFO: Number of nodes with available pods: 2
Feb  6 03:21:32.175: INFO: Node 10.190.119.144 is running more than one daemon pod
Feb  6 03:21:33.184: INFO: Number of nodes with available pods: 3
Feb  6 03:21:33.185: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-7j9dz, will wait for the garbage collector to delete the pods
Feb  6 03:21:33.274: INFO: Deleting DaemonSet.extensions daemon-set took: 16.987171ms
Feb  6 03:21:33.375: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.45926ms
Feb  6 03:22:11.799: INFO: Number of nodes with available pods: 0
Feb  6 03:22:11.799: INFO: Number of running nodes: 0, number of available pods: 0
Feb  6 03:22:11.806: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-7j9dz/daemonsets","resourceVersion":"72236"},"items":null}

Feb  6 03:22:11.813: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-7j9dz/pods","resourceVersion":"72236"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:22:11.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-7j9dz" for this suite.
Feb  6 03:22:19.965: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:22:20.224: INFO: namespace: e2e-tests-daemonsets-7j9dz, resource: bindings, ignored listing per whitelist
Feb  6 03:22:20.325: INFO: namespace e2e-tests-daemonsets-7j9dz deletion completed in 8.399376291s

• [SLOW TEST:88.767 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:22:20.326: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-xtgjl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-69e805ae-29be-11e9-b6e7-06cba7aec104
STEP: Creating a pod to test consume configMaps
Feb  6 03:22:20.914: INFO: Waiting up to 5m0s for pod "pod-configmaps-69e9e724-29be-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-configmap-xtgjl" to be "success or failure"
Feb  6 03:22:20.922: INFO: Pod "pod-configmaps-69e9e724-29be-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 8.079146ms
Feb  6 03:22:22.944: INFO: Pod "pod-configmaps-69e9e724-29be-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.030378779s
STEP: Saw pod success
Feb  6 03:22:22.945: INFO: Pod "pod-configmaps-69e9e724-29be-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 03:22:22.951: INFO: Trying to get logs from node 10.190.119.175 pod pod-configmaps-69e9e724-29be-11e9-b6e7-06cba7aec104 container configmap-volume-test: <nil>
STEP: delete the pod
Feb  6 03:22:23.197: INFO: Waiting for pod pod-configmaps-69e9e724-29be-11e9-b6e7-06cba7aec104 to disappear
Feb  6 03:22:23.204: INFO: Pod pod-configmaps-69e9e724-29be-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:22:23.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-xtgjl" for this suite.
Feb  6 03:22:29.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:22:29.437: INFO: namespace: e2e-tests-configmap-xtgjl, resource: bindings, ignored listing per whitelist
Feb  6 03:22:29.772: INFO: namespace e2e-tests-configmap-xtgjl deletion completed in 6.557244921s

• [SLOW TEST:9.446 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:22:29.773: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-9bzch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb  6 03:22:30.113: INFO: Waiting up to 5m0s for pod "downward-api-6f6561c5-29be-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-downward-api-9bzch" to be "success or failure"
Feb  6 03:22:30.121: INFO: Pod "downward-api-6f6561c5-29be-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 8.467257ms
Feb  6 03:22:32.129: INFO: Pod "downward-api-6f6561c5-29be-11e9-b6e7-06cba7aec104": Phase="Running", Reason="", readiness=true. Elapsed: 2.016634939s
Feb  6 03:22:34.157: INFO: Pod "downward-api-6f6561c5-29be-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044238238s
STEP: Saw pod success
Feb  6 03:22:34.157: INFO: Pod "downward-api-6f6561c5-29be-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 03:22:34.165: INFO: Trying to get logs from node 10.190.119.144 pod downward-api-6f6561c5-29be-11e9-b6e7-06cba7aec104 container dapi-container: <nil>
STEP: delete the pod
Feb  6 03:22:34.222: INFO: Waiting for pod downward-api-6f6561c5-29be-11e9-b6e7-06cba7aec104 to disappear
Feb  6 03:22:34.298: INFO: Pod downward-api-6f6561c5-29be-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:22:34.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-9bzch" for this suite.
Feb  6 03:22:42.351: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:22:42.716: INFO: namespace: e2e-tests-downward-api-9bzch, resource: bindings, ignored listing per whitelist
Feb  6 03:22:42.770: INFO: namespace e2e-tests-downward-api-9bzch deletion completed in 8.459056487s

• [SLOW TEST:12.997 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:22:42.772: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-hx894
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Feb  6 03:22:43.463: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-511574509 proxy --unix-socket=/tmp/kubectl-proxy-unix141491816/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:22:43.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hx894" for this suite.
Feb  6 03:22:50.456: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:22:50.752: INFO: namespace: e2e-tests-kubectl-hx894, resource: bindings, ignored listing per whitelist
Feb  6 03:22:50.772: INFO: namespace e2e-tests-kubectl-hx894 deletion completed in 6.858430359s

• [SLOW TEST:8.000 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:22:50.773: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-tzzzv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-tzzzv
Feb  6 03:22:53.112: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-tzzzv
STEP: checking the pod's current state and verifying that restartCount is present
Feb  6 03:22:53.120: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:26:53.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-tzzzv" for this suite.
Feb  6 03:27:01.554: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:27:02.125: INFO: namespace: e2e-tests-container-probe-tzzzv, resource: bindings, ignored listing per whitelist
Feb  6 03:27:02.263: INFO: namespace e2e-tests-container-probe-tzzzv deletion completed in 8.748609493s

• [SLOW TEST:251.490 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:27:02.264: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-296zb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb  6 03:27:02.625: INFO: Waiting up to 5m0s for pod "pod-11d33ea2-29bf-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-emptydir-296zb" to be "success or failure"
Feb  6 03:27:02.633: INFO: Pod "pod-11d33ea2-29bf-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 7.889318ms
Feb  6 03:27:04.640: INFO: Pod "pod-11d33ea2-29bf-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015277413s
STEP: Saw pod success
Feb  6 03:27:04.640: INFO: Pod "pod-11d33ea2-29bf-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 03:27:04.647: INFO: Trying to get logs from node 10.190.119.175 pod pod-11d33ea2-29bf-11e9-b6e7-06cba7aec104 container test-container: <nil>
STEP: delete the pod
Feb  6 03:27:04.722: INFO: Waiting for pod pod-11d33ea2-29bf-11e9-b6e7-06cba7aec104 to disappear
Feb  6 03:27:04.730: INFO: Pod pod-11d33ea2-29bf-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:27:04.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-296zb" for this suite.
Feb  6 03:27:12.777: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:27:13.210: INFO: namespace: e2e-tests-emptydir-296zb, resource: bindings, ignored listing per whitelist
Feb  6 03:27:13.327: INFO: namespace e2e-tests-emptydir-296zb deletion completed in 8.585624497s

• [SLOW TEST:11.062 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:27:13.328: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-gr6jk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb  6 03:27:17.769: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  6 03:27:17.777: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  6 03:27:19.777: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  6 03:27:19.784: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  6 03:27:21.777: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  6 03:27:21.800: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  6 03:27:23.777: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  6 03:27:23.785: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  6 03:27:25.777: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  6 03:27:25.785: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  6 03:27:27.777: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  6 03:27:27.784: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  6 03:27:29.777: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  6 03:27:29.785: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  6 03:27:31.777: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  6 03:27:31.785: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  6 03:27:33.777: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  6 03:27:33.800: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  6 03:27:35.777: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  6 03:27:35.784: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  6 03:27:37.777: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  6 03:27:37.784: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  6 03:27:39.777: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  6 03:27:39.786: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  6 03:27:41.777: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  6 03:27:41.785: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:27:41.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-gr6jk" for this suite.
Feb  6 03:28:05.852: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:28:05.985: INFO: namespace: e2e-tests-container-lifecycle-hook-gr6jk, resource: bindings, ignored listing per whitelist
Feb  6 03:28:06.287: INFO: namespace e2e-tests-container-lifecycle-hook-gr6jk deletion completed in 24.46865473s

• [SLOW TEST:52.960 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:28:06.288: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-9ht2t
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Feb  6 03:28:06.707: INFO: Waiting up to 5m0s for pod "client-containers-380537de-29bf-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-containers-9ht2t" to be "success or failure"
Feb  6 03:28:06.715: INFO: Pod "client-containers-380537de-29bf-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 8.636381ms
Feb  6 03:28:08.723: INFO: Pod "client-containers-380537de-29bf-11e9-b6e7-06cba7aec104": Phase="Running", Reason="", readiness=true. Elapsed: 2.016359569s
Feb  6 03:28:10.732: INFO: Pod "client-containers-380537de-29bf-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025653218s
STEP: Saw pod success
Feb  6 03:28:10.733: INFO: Pod "client-containers-380537de-29bf-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 03:28:10.742: INFO: Trying to get logs from node 10.190.119.145 pod client-containers-380537de-29bf-11e9-b6e7-06cba7aec104 container test-container: <nil>
STEP: delete the pod
Feb  6 03:28:10.834: INFO: Waiting for pod client-containers-380537de-29bf-11e9-b6e7-06cba7aec104 to disappear
Feb  6 03:28:10.843: INFO: Pod client-containers-380537de-29bf-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:28:10.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-9ht2t" for this suite.
Feb  6 03:28:16.910: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:28:17.239: INFO: namespace: e2e-tests-containers-9ht2t, resource: bindings, ignored listing per whitelist
Feb  6 03:28:17.447: INFO: namespace e2e-tests-containers-9ht2t deletion completed in 6.591213581s

• [SLOW TEST:11.159 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:28:17.449: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-dqrvt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Feb  6 03:28:19.833: INFO: Pod pod-hostip-3ea2d97d-29bf-11e9-b6e7-06cba7aec104 has hostIP: 10.190.119.144
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:28:19.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-dqrvt" for this suite.
Feb  6 03:28:43.937: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:28:44.443: INFO: namespace: e2e-tests-pods-dqrvt, resource: bindings, ignored listing per whitelist
Feb  6 03:28:44.671: INFO: namespace e2e-tests-pods-dqrvt deletion completed in 24.773301544s

• [SLOW TEST:27.222 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:28:44.672: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-brtms
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb  6 03:28:47.571: INFO: Successfully updated pod "pod-update-4edb687e-29bf-11e9-b6e7-06cba7aec104"
STEP: verifying the updated pod is in kubernetes
Feb  6 03:28:47.604: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:28:47.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-brtms" for this suite.
Feb  6 03:29:11.653: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:29:11.881: INFO: namespace: e2e-tests-pods-brtms, resource: bindings, ignored listing per whitelist
Feb  6 03:29:11.987: INFO: namespace e2e-tests-pods-brtms deletion completed in 24.370933379s

• [SLOW TEST:27.315 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:29:11.989: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-qb6rc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb  6 03:29:12.340: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-qb6rc'
Feb  6 03:29:12.740: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb  6 03:29:12.740: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Feb  6 03:29:14.786: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-9g7dx]
Feb  6 03:29:14.786: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-9g7dx" in namespace "e2e-tests-kubectl-qb6rc" to be "running and ready"
Feb  6 03:29:14.794: INFO: Pod "e2e-test-nginx-rc-9g7dx": Phase="Running", Reason="", readiness=true. Elapsed: 7.384246ms
Feb  6 03:29:14.794: INFO: Pod "e2e-test-nginx-rc-9g7dx" satisfied condition "running and ready"
Feb  6 03:29:14.794: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-9g7dx]
Feb  6 03:29:14.794: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-qb6rc'
Feb  6 03:29:14.949: INFO: stderr: ""
Feb  6 03:29:14.949: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1303
Feb  6 03:29:14.950: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-qb6rc'
Feb  6 03:29:15.104: INFO: stderr: ""
Feb  6 03:29:15.104: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:29:15.104: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-qb6rc" for this suite.
Feb  6 03:29:39.157: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:29:39.258: INFO: namespace: e2e-tests-kubectl-qb6rc, resource: bindings, ignored listing per whitelist
Feb  6 03:29:39.527: INFO: namespace e2e-tests-kubectl-qb6rc deletion completed in 24.409568753s

• [SLOW TEST:27.538 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:29:39.527: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-jmbcn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  6 03:29:40.524: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6ff04cd2-29bf-11e9-b6e7-06cba7aec104" in namespace "e2e-tests-downward-api-jmbcn" to be "success or failure"
Feb  6 03:29:40.532: INFO: Pod "downwardapi-volume-6ff04cd2-29bf-11e9-b6e7-06cba7aec104": Phase="Pending", Reason="", readiness=false. Elapsed: 8.189141ms
Feb  6 03:29:42.540: INFO: Pod "downwardapi-volume-6ff04cd2-29bf-11e9-b6e7-06cba7aec104": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015871654s
STEP: Saw pod success
Feb  6 03:29:42.540: INFO: Pod "downwardapi-volume-6ff04cd2-29bf-11e9-b6e7-06cba7aec104" satisfied condition "success or failure"
Feb  6 03:29:42.547: INFO: Trying to get logs from node 10.190.119.175 pod downwardapi-volume-6ff04cd2-29bf-11e9-b6e7-06cba7aec104 container client-container: <nil>
STEP: delete the pod
Feb  6 03:29:42.594: INFO: Waiting for pod downwardapi-volume-6ff04cd2-29bf-11e9-b6e7-06cba7aec104 to disappear
Feb  6 03:29:42.600: INFO: Pod downwardapi-volume-6ff04cd2-29bf-11e9-b6e7-06cba7aec104 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:29:42.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-jmbcn" for this suite.
Feb  6 03:29:48.674: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:29:48.872: INFO: namespace: e2e-tests-downward-api-jmbcn, resource: bindings, ignored listing per whitelist
Feb  6 03:29:49.042: INFO: namespace e2e-tests-downward-api-jmbcn deletion completed in 6.429868631s

• [SLOW TEST:9.514 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:29:49.042: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-779ln
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb  6 03:29:52.112: INFO: Successfully updated pod "labelsupdate75443e56-29bf-11e9-b6e7-06cba7aec104"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:29:56.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-779ln" for this suite.
Feb  6 03:30:20.232: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:30:21.166: INFO: namespace: e2e-tests-downward-api-779ln, resource: bindings, ignored listing per whitelist
Feb  6 03:30:21.166: INFO: namespace e2e-tests-downward-api-779ln deletion completed in 24.977943863s

• [SLOW TEST:32.124 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:30:21.167: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-8xjdn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb  6 03:30:24.178: INFO: Successfully updated pod "annotationupdate885ff438-29bf-11e9-b6e7-06cba7aec104"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:30:28.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8xjdn" for this suite.
Feb  6 03:30:52.316: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:30:52.637: INFO: namespace: e2e-tests-projected-8xjdn, resource: bindings, ignored listing per whitelist
Feb  6 03:30:52.715: INFO: namespace e2e-tests-projected-8xjdn deletion completed in 24.467283135s

• [SLOW TEST:31.548 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:30:52.715: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-q49tq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Feb  6 03:30:53.061: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 cluster-info'
Feb  6 03:30:53.168: INFO: stderr: ""
Feb  6 03:30:53.168: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mkubernetes-dashboard\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy\x1b[0m\n\x1b[0;32mMetrics-server\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:30:53.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-q49tq" for this suite.
Feb  6 03:30:59.222: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:30:59.531: INFO: namespace: e2e-tests-kubectl-q49tq, resource: bindings, ignored listing per whitelist
Feb  6 03:30:59.691: INFO: namespace e2e-tests-kubectl-q49tq deletion completed in 6.511596853s

• [SLOW TEST:6.976 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:30:59.692: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-runtime-xlnn2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:31:22.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-runtime-xlnn2" for this suite.
Feb  6 03:31:30.775: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:31:30.820: INFO: namespace: e2e-tests-container-runtime-xlnn2, resource: bindings, ignored listing per whitelist
Feb  6 03:31:31.518: INFO: namespace e2e-tests-container-runtime-xlnn2 deletion completed in 8.778546723s

• [SLOW TEST:31.827 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  blackbox test
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:31:31.519: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-58jnw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  6 03:31:31.860: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 version --client'
Feb  6 03:31:31.915: INFO: stderr: ""
Feb  6 03:31:31.915: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Feb  6 03:31:31.918: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 create -f - --namespace=e2e-tests-kubectl-58jnw'
Feb  6 03:31:32.188: INFO: stderr: ""
Feb  6 03:31:32.188: INFO: stdout: "replicationcontroller/redis-master created\n"
Feb  6 03:31:32.188: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 create -f - --namespace=e2e-tests-kubectl-58jnw'
Feb  6 03:31:32.457: INFO: stderr: ""
Feb  6 03:31:32.457: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb  6 03:31:33.465: INFO: Selector matched 1 pods for map[app:redis]
Feb  6 03:31:33.465: INFO: Found 1 / 1
Feb  6 03:31:33.465: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb  6 03:31:33.474: INFO: Selector matched 1 pods for map[app:redis]
Feb  6 03:31:33.474: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb  6 03:31:33.474: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 describe pod redis-master-lbwfz --namespace=e2e-tests-kubectl-58jnw'
Feb  6 03:31:33.596: INFO: stderr: ""
Feb  6 03:31:33.596: INFO: stdout: "Name:               redis-master-lbwfz\nNamespace:          e2e-tests-kubectl-58jnw\nPriority:           0\nPriorityClassName:  <none>\nNode:               10.190.119.144/10.190.119.144\nStart Time:         Wed, 06 Feb 2019 03:31:32 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        kubernetes.io/psp: e2e-test-privileged-psp\nStatus:             Running\nIP:                 172.30.175.220\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   containerd://9f6d13c71e09f73da74ce8a8313cf213f330cf052e3c9c62f045c17c81479a20\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 06 Feb 2019 03:31:33 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-lgs2t (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-lgs2t:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-lgs2t\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                     Message\n  ----    ------     ----  ----                     -------\n  Normal  Scheduled  1s    default-scheduler        Successfully assigned e2e-tests-kubectl-58jnw/redis-master-lbwfz to 10.190.119.144\n  Normal  Pulled     0s    kubelet, 10.190.119.144  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    0s    kubelet, 10.190.119.144  Created container\n  Normal  Started    0s    kubelet, 10.190.119.144  Started container\n"
Feb  6 03:31:33.597: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 describe rc redis-master --namespace=e2e-tests-kubectl-58jnw'
Feb  6 03:31:33.831: INFO: stderr: ""
Feb  6 03:31:33.831: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-58jnw\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  1s    replication-controller  Created pod: redis-master-lbwfz\n"
Feb  6 03:31:33.832: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 describe service redis-master --namespace=e2e-tests-kubectl-58jnw'
Feb  6 03:31:33.995: INFO: stderr: ""
Feb  6 03:31:33.995: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-58jnw\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                172.21.209.69\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         172.30.175.220:6379\nSession Affinity:  None\nEvents:            <none>\n"
Feb  6 03:31:34.009: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 describe node 10.190.119.144'
Feb  6 03:31:34.175: INFO: stderr: ""
Feb  6 03:31:34.175: INFO: stdout: "Name:               10.190.119.144\nRoles:              <none>\nLabels:             arch=amd64\n                    beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=u2c.2x4.encrypted\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=us-east\n                    failure-domain.beta.kubernetes.io/zone=wdc07\n                    ibm-cloud.kubernetes.io/encrypted-docker-data=true\n                    ibm-cloud.kubernetes.io/ha-worker=true\n                    ibm-cloud.kubernetes.io/iaas-provider=softlayer\n                    ibm-cloud.kubernetes.io/machine-type=u2c.2x4.encrypted\n                    ibm-cloud.kubernetes.io/sgx-enabled=false\n                    ibm-cloud.kubernetes.io/worker-pool-id=12917ac601404a7783a11c06c1855dfa-cb79747\n                    ibm-cloud.kubernetes.io/worker-version=1.13.2_1507\n                    kubernetes.io/hostname=10.190.119.144\n                    privateVLAN=2540259\n                    publicVLAN=2540257\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Tue, 05 Feb 2019 20:41:42 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Wed, 06 Feb 2019 03:31:25 +0000   Tue, 05 Feb 2019 20:41:42 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Wed, 06 Feb 2019 03:31:25 +0000   Tue, 05 Feb 2019 20:41:42 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Wed, 06 Feb 2019 03:31:25 +0000   Tue, 05 Feb 2019 20:41:42 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Wed, 06 Feb 2019 03:31:25 +0000   Tue, 05 Feb 2019 20:41:52 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.190.119.144\n  ExternalIP:  169.61.92.99\n  Hostname:    10.190.119.144\nCapacity:\n cpu:                2\n ephemeral-storage:  103079200Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             4041600Ki\n pods:               110\nAllocatable:\n cpu:                1920m\n ephemeral-storage:  100275445682\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             3535744Ki\n pods:               110\nSystem Info:\n Machine ID:                 266c2075dace453da02500b328c9e325\n System UUID:                DAB1E850-E8F7-9C2D-165F-1D1E21B40A17\n Boot ID:                    900ec6de-3880-47b7-88b5-26b62307ee2d\n Kernel Version:             4.4.0-141-generic\n OS Image:                   Ubuntu 16.04.5 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  containerd://1.2.2\n Kubelet Version:            v1.13.2+IKS\n Kube-Proxy Version:         v1.13.2+IKS\nProviderID:                  ibm://d18c889395112a40d2f4e3065f237a7d///12917ac601404a7783a11c06c1855dfa/kube-wdc07-cr12917ac601404a7783a11c06c1855dfa-w2\nNon-terminated Pods:         (15 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  default                    test-k8s-e2e-pvg-master-verification                       0 (0%)        0 (0%)      0 (0%)           0 (0%)         99m\n  e2e-tests-kubectl-58jnw    redis-master-lbwfz                                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         2s\n  heptio-sonobuoy            sonobuoy-e2e-job-8583898d905b4e12                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         98m\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-5456463907b0461e-nvm56    0 (0%)        0 (0%)      0 (0%)           0 (0%)         98m\n  kube-system                calico-kube-controllers-65868f965d-5tqjq                   10m (0%)      0 (0%)      25Mi (0%)        0 (0%)         6h55m\n  kube-system                calico-node-d28tb                                          250m (13%)    0 (0%)      80Mi (2%)        0 (0%)         6h49m\n  kube-system                coredns-977545f8c-8xszx                                    100m (5%)     0 (0%)      70Mi (2%)        170Mi (4%)     6h54m\n  kube-system                coredns-autoscaler-64f9c5b4df-44r7b                        20m (1%)      0 (0%)      10Mi (0%)        0 (0%)         6h54m\n  kube-system                ibm-file-plugin-7b7c4fbfdf-bn7kf                           50m (2%)      200m (10%)  100Mi (2%)       0 (0%)         6h53m\n  kube-system                ibm-keepalived-watcher-sxzhx                               5m (0%)       0 (0%)      10Mi (0%)        0 (0%)         6h49m\n  kube-system                ibm-kube-fluentd-8hwlq                                     25m (1%)      300m (15%)  50Mi (1%)        800M (22%)     6h44m\n  kube-system                ibm-master-proxy-static-10.190.119.144                     25m (1%)      300m (15%)  32M (0%)         512M (14%)     6h49m\n  kube-system                ibm-storage-watcher-d566545b-tgbbx                         50m (2%)      200m (10%)  100Mi (2%)       0 (0%)         6h53m\n  kube-system                kubernetes-dashboard-7996b848f4-nsjp4                      50m (2%)      0 (0%)      100Mi (2%)       0 (0%)         6h52m\n  kube-system                vpn-74bb4868b9-htqtq                                       5m (0%)       0 (0%)      5Mi (0%)         0 (0%)         6h52m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests        Limits\n  --------           --------        ------\n  cpu                590m (30%)      1 (52%)\n  memory             594450Ki (16%)  1455330Ki (41%)\n  ephemeral-storage  0 (0%)          0 (0%)\nEvents:              <none>\n"
Feb  6 03:31:34.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-511574509 describe namespace e2e-tests-kubectl-58jnw'
Feb  6 03:31:34.317: INFO: stderr: ""
Feb  6 03:31:34.317: INFO: stdout: "Name:         e2e-tests-kubectl-58jnw\nLabels:       e2e-framework=kubectl\n              e2e-run=e37cbfc9-29b1-11e9-b6e7-06cba7aec104\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:31:34.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-58jnw" for this suite.
Feb  6 03:31:58.363: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:31:58.440: INFO: namespace: e2e-tests-kubectl-58jnw, resource: bindings, ignored listing per whitelist
Feb  6 03:31:58.703: INFO: namespace e2e-tests-kubectl-58jnw deletion completed in 24.376104128s

• [SLOW TEST:27.184 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:31:58.703: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-w9d64
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-w9d64
Feb  6 03:32:03.094: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-w9d64
STEP: checking the pod's current state and verifying that restartCount is present
Feb  6 03:32:03.102: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:36:03.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-w9d64" for this suite.
Feb  6 03:36:09.935: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:36:10.237: INFO: namespace: e2e-tests-container-probe-w9d64, resource: bindings, ignored listing per whitelist
Feb  6 03:36:10.299: INFO: namespace e2e-tests-container-probe-w9d64 deletion completed in 6.402070689s

• [SLOW TEST:251.597 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
Feb  6 03:36:10.302: INFO: >>> kubeConfig: /tmp/kubeconfig-511574509
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-7tkw9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Feb  6 03:36:10.657: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-511574509 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
Feb  6 03:36:10.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-7tkw9" for this suite.
Feb  6 03:36:16.830: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:36:16.970: INFO: namespace: e2e-tests-kubectl-7tkw9, resource: bindings, ignored listing per whitelist
Feb  6 03:36:17.147: INFO: namespace e2e-tests-kubectl-7tkw9 deletion completed in 6.369094448s

• [SLOW TEST:6.845 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSFeb  6 03:36:17.148: INFO: Running AfterSuite actions on all nodes
Feb  6 03:36:17.148: INFO: Running AfterSuite actions on node 1
Feb  6 03:36:17.148: INFO: Skipping dumping logs from cluster

Ran 200 of 1946 Specs in 6214.801 seconds
SUCCESS! -- 200 Passed | 0 Failed | 0 Pending | 1746 Skipped PASS

Ginkgo ran 1 suite in 1h43m35.834125056s
Test Suite Passed
