I0513 18:41:11.252051      16 test_context.go:358] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-555138423
I0513 18:41:11.252137      16 e2e.go:224] Starting e2e run "ad7e8b22-75ae-11e9-8f67-2632f168be36" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1557772870 - Will randomize all specs
Will run 201 of 1946 specs

May 13 18:41:11.368: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
May 13 18:41:11.370: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
May 13 18:41:11.440: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
May 13 18:41:11.497: INFO: 23 / 23 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
May 13 18:41:11.497: INFO: expected 11 pod replicas in namespace 'kube-system', 11 are Running and Ready.
May 13 18:41:11.497: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
May 13 18:41:11.515: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
May 13 18:41:11.515: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ibm-keepalived-watcher' (0 seconds elapsed)
May 13 18:41:11.515: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ibm-kube-fluentd' (0 seconds elapsed)
May 13 18:41:11.516: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'ibm-master-proxy' (0 seconds elapsed)
May 13 18:41:11.516: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-driver-installer' (0 seconds elapsed)
May 13 18:41:11.516: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-gpu-device-plugin' (0 seconds elapsed)
May 13 18:41:11.516: INFO: e2e test version: v1.13.0
May 13 18:41:11.518: INFO: kube-apiserver version: v1.13.6+IKS
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 18:41:11.518: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename init-container
May 13 18:41:12.529: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
May 13 18:41:12.550: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-bs6n8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
May 13 18:41:12.670: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 18:41:16.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-bs6n8" for this suite.
May 13 18:41:22.197: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:41:22.293: INFO: namespace: e2e-tests-init-container-bs6n8, resource: bindings, ignored listing per whitelist
May 13 18:41:22.445: INFO: namespace e2e-tests-init-container-bs6n8 deletion completed in 6.290767253s

• [SLOW TEST:10.926 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 18:41:22.445: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-vhs7b
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-vhs7b
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-vhs7b
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-vhs7b
May 13 18:41:22.849: INFO: Found 0 stateful pods, waiting for 1
May 13 18:41:32.871: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
May 13 18:41:32.878: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 exec --namespace=e2e-tests-statefulset-vhs7b ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 13 18:41:33.197: INFO: stderr: ""
May 13 18:41:33.197: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 13 18:41:33.197: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 13 18:41:33.205: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
May 13 18:41:43.226: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 13 18:41:43.226: INFO: Waiting for statefulset status.replicas updated to 0
May 13 18:41:43.334: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999998915s
May 13 18:41:44.343: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.99239426s
May 13 18:41:45.356: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.983535621s
May 13 18:41:46.365: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.970246819s
May 13 18:41:47.374: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.961626761s
May 13 18:41:48.382: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.952328786s
May 13 18:41:49.391: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.944525454s
May 13 18:41:50.399: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.935752056s
May 13 18:41:51.408: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.927516593s
May 13 18:41:52.416: INFO: Verifying statefulset ss doesn't scale past 1 for another 918.673616ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-vhs7b
May 13 18:41:53.437: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 exec --namespace=e2e-tests-statefulset-vhs7b ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 13 18:41:53.727: INFO: stderr: ""
May 13 18:41:53.727: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 13 18:41:53.727: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 13 18:41:53.827: INFO: Found 1 stateful pods, waiting for 3
May 13 18:42:03.850: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
May 13 18:42:03.850: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
May 13 18:42:03.850: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
May 13 18:42:03.920: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 exec --namespace=e2e-tests-statefulset-vhs7b ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 13 18:42:04.175: INFO: stderr: ""
May 13 18:42:04.175: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 13 18:42:04.175: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 13 18:42:04.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 exec --namespace=e2e-tests-statefulset-vhs7b ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 13 18:42:04.502: INFO: stderr: ""
May 13 18:42:04.502: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 13 18:42:04.502: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 13 18:42:04.502: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 exec --namespace=e2e-tests-statefulset-vhs7b ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 13 18:42:04.828: INFO: stderr: ""
May 13 18:42:04.828: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 13 18:42:04.828: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 13 18:42:04.828: INFO: Waiting for statefulset status.replicas updated to 0
May 13 18:42:04.834: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
May 13 18:42:14.862: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 13 18:42:14.862: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
May 13 18:42:14.862: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
May 13 18:42:14.920: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999998974s
May 13 18:42:16.020: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.953782895s
May 13 18:42:17.029: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.853669749s
May 13 18:42:18.038: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.844568726s
May 13 18:42:19.048: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.835519558s
May 13 18:42:20.057: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.825283464s
May 13 18:42:21.066: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.816367746s
May 13 18:42:22.075: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.807599301s
May 13 18:42:23.084: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.798430196s
May 13 18:42:24.092: INFO: Verifying statefulset ss doesn't scale past 3 for another 789.787963ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-vhs7b
May 13 18:42:25.113: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 exec --namespace=e2e-tests-statefulset-vhs7b ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 13 18:42:25.370: INFO: stderr: ""
May 13 18:42:25.370: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 13 18:42:25.370: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 13 18:42:25.370: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 exec --namespace=e2e-tests-statefulset-vhs7b ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 13 18:42:25.645: INFO: stderr: ""
May 13 18:42:25.645: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 13 18:42:25.645: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 13 18:42:25.645: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 exec --namespace=e2e-tests-statefulset-vhs7b ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 13 18:42:25.933: INFO: stderr: ""
May 13 18:42:25.933: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 13 18:42:25.933: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 13 18:42:25.933: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 13 18:42:46.018: INFO: Deleting all statefulset in ns e2e-tests-statefulset-vhs7b
May 13 18:42:46.024: INFO: Scaling statefulset ss to 0
May 13 18:42:46.053: INFO: Waiting for statefulset status.replicas updated to 0
May 13 18:42:46.058: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 18:42:46.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-vhs7b" for this suite.
May 13 18:42:52.134: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:42:52.177: INFO: namespace: e2e-tests-statefulset-vhs7b, resource: bindings, ignored listing per whitelist
May 13 18:42:52.379: INFO: namespace e2e-tests-statefulset-vhs7b deletion completed in 6.283998639s

• [SLOW TEST:89.934 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 18:42:52.379: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-nd2ws
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-ea42d42e-75ae-11e9-8f67-2632f168be36
STEP: Creating a pod to test consume configMaps
May 13 18:42:52.675: INFO: Waiting up to 5m0s for pod "pod-configmaps-ea4439f4-75ae-11e9-8f67-2632f168be36" in namespace "e2e-tests-configmap-nd2ws" to be "success or failure"
May 13 18:42:52.683: INFO: Pod "pod-configmaps-ea4439f4-75ae-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 7.247409ms
May 13 18:42:54.691: INFO: Pod "pod-configmaps-ea4439f4-75ae-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015426653s
STEP: Saw pod success
May 13 18:42:54.691: INFO: Pod "pod-configmaps-ea4439f4-75ae-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 18:42:54.698: INFO: Trying to get logs from node 10.170.219.153 pod pod-configmaps-ea4439f4-75ae-11e9-8f67-2632f168be36 container configmap-volume-test: <nil>
STEP: delete the pod
May 13 18:42:54.744: INFO: Waiting for pod pod-configmaps-ea4439f4-75ae-11e9-8f67-2632f168be36 to disappear
May 13 18:42:54.751: INFO: Pod pod-configmaps-ea4439f4-75ae-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 18:42:54.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-nd2ws" for this suite.
May 13 18:43:02.788: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:43:02.822: INFO: namespace: e2e-tests-configmap-nd2ws, resource: bindings, ignored listing per whitelist
May 13 18:43:03.124: INFO: namespace e2e-tests-configmap-nd2ws deletion completed in 8.364655139s

• [SLOW TEST:10.745 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 18:43:03.124: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-tqt6c
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
May 13 18:43:03.406: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 create -f - --namespace=e2e-tests-kubectl-tqt6c'
May 13 18:43:03.878: INFO: stderr: ""
May 13 18:43:03.878: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
May 13 18:43:04.886: INFO: Selector matched 1 pods for map[app:redis]
May 13 18:43:04.886: INFO: Found 0 / 1
May 13 18:43:05.886: INFO: Selector matched 1 pods for map[app:redis]
May 13 18:43:05.887: INFO: Found 1 / 1
May 13 18:43:05.887: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
May 13 18:43:05.894: INFO: Selector matched 1 pods for map[app:redis]
May 13 18:43:05.894: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May 13 18:43:05.894: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 patch pod redis-master-nsh4l --namespace=e2e-tests-kubectl-tqt6c -p {"metadata":{"annotations":{"x":"y"}}}'
May 13 18:43:06.024: INFO: stderr: ""
May 13 18:43:06.024: INFO: stdout: "pod/redis-master-nsh4l patched\n"
STEP: checking annotations
May 13 18:43:06.034: INFO: Selector matched 1 pods for map[app:redis]
May 13 18:43:06.034: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 18:43:06.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-tqt6c" for this suite.
May 13 18:43:30.069: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:43:30.202: INFO: namespace: e2e-tests-kubectl-tqt6c, resource: bindings, ignored listing per whitelist
May 13 18:43:30.366: INFO: namespace e2e-tests-kubectl-tqt6c deletion completed in 24.324937167s

• [SLOW TEST:27.242 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 18:43:30.366: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-gcgz5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-00e6ecc5-75af-11e9-8f67-2632f168be36
STEP: Creating a pod to test consume secrets
May 13 18:43:30.666: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-00e8e9ab-75af-11e9-8f67-2632f168be36" in namespace "e2e-tests-projected-gcgz5" to be "success or failure"
May 13 18:43:30.675: INFO: Pod "pod-projected-secrets-00e8e9ab-75af-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 8.682008ms
May 13 18:43:32.684: INFO: Pod "pod-projected-secrets-00e8e9ab-75af-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017266587s
STEP: Saw pod success
May 13 18:43:32.684: INFO: Pod "pod-projected-secrets-00e8e9ab-75af-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 18:43:32.691: INFO: Trying to get logs from node 10.170.219.177 pod pod-projected-secrets-00e8e9ab-75af-11e9-8f67-2632f168be36 container secret-volume-test: <nil>
STEP: delete the pod
May 13 18:43:32.733: INFO: Waiting for pod pod-projected-secrets-00e8e9ab-75af-11e9-8f67-2632f168be36 to disappear
May 13 18:43:32.740: INFO: Pod pod-projected-secrets-00e8e9ab-75af-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 18:43:32.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gcgz5" for this suite.
May 13 18:43:38.776: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:43:38.893: INFO: namespace: e2e-tests-projected-gcgz5, resource: bindings, ignored listing per whitelist
May 13 18:43:39.035: INFO: namespace e2e-tests-projected-gcgz5 deletion completed in 6.287030363s

• [SLOW TEST:8.669 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 18:43:39.036: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-mxmlx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
May 13 18:43:39.296: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

May 13 18:43:39.296: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 create -f - --namespace=e2e-tests-kubectl-mxmlx'
May 13 18:43:39.512: INFO: stderr: ""
May 13 18:43:39.512: INFO: stdout: "service/redis-slave created\n"
May 13 18:43:39.512: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

May 13 18:43:39.512: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 create -f - --namespace=e2e-tests-kubectl-mxmlx'
May 13 18:43:39.830: INFO: stderr: ""
May 13 18:43:39.830: INFO: stdout: "service/redis-master created\n"
May 13 18:43:39.830: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

May 13 18:43:39.830: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 create -f - --namespace=e2e-tests-kubectl-mxmlx'
May 13 18:43:40.018: INFO: stderr: ""
May 13 18:43:40.018: INFO: stdout: "service/frontend created\n"
May 13 18:43:40.018: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

May 13 18:43:40.019: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 create -f - --namespace=e2e-tests-kubectl-mxmlx'
May 13 18:43:40.251: INFO: stderr: ""
May 13 18:43:40.251: INFO: stdout: "deployment.extensions/frontend created\n"
May 13 18:43:40.251: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

May 13 18:43:40.251: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 create -f - --namespace=e2e-tests-kubectl-mxmlx'
May 13 18:43:40.531: INFO: stderr: ""
May 13 18:43:40.531: INFO: stdout: "deployment.extensions/redis-master created\n"
May 13 18:43:40.532: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

May 13 18:43:40.532: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 create -f - --namespace=e2e-tests-kubectl-mxmlx'
May 13 18:43:40.786: INFO: stderr: ""
May 13 18:43:40.786: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
May 13 18:43:40.786: INFO: Waiting for all frontend pods to be Running.
May 13 18:43:45.837: INFO: Waiting for frontend to serve content.
May 13 18:43:45.865: INFO: Trying to add a new entry to the guestbook.
May 13 18:43:45.891: INFO: Verifying that added entry can be retrieved.
May 13 18:43:45.913: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
May 13 18:43:50.952: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
May 13 18:43:55.977: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
May 13 18:44:01.012: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
May 13 18:44:06.039: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
May 13 18:44:11.083: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
May 13 18:44:16.112: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
May 13 18:44:21.148: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
May 13 18:44:26.170: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
May 13 18:44:31.206: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
May 13 18:44:36.231: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
May 13 18:44:41.270: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
STEP: using delete to clean up resources
May 13 18:44:46.295: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-mxmlx'
May 13 18:44:46.474: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 13 18:44:46.474: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
May 13 18:44:46.474: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-mxmlx'
May 13 18:44:46.625: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 13 18:44:46.625: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
May 13 18:44:46.625: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-mxmlx'
May 13 18:44:46.752: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 13 18:44:46.752: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
May 13 18:44:46.752: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-mxmlx'
May 13 18:44:46.854: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 13 18:44:46.854: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
May 13 18:44:46.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-mxmlx'
May 13 18:44:46.972: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 13 18:44:46.972: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
May 13 18:44:46.972: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-mxmlx'
May 13 18:44:47.094: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 13 18:44:47.094: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 18:44:47.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-mxmlx" for this suite.
May 13 18:45:27.132: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:45:27.335: INFO: namespace: e2e-tests-kubectl-mxmlx, resource: bindings, ignored listing per whitelist
May 13 18:45:27.533: INFO: namespace e2e-tests-kubectl-mxmlx deletion completed in 40.430973147s

• [SLOW TEST:108.498 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 18:45:27.534: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-nlztd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-nlztd
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 13 18:45:27.816: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 13 18:45:48.018: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.227.86:8080/dial?request=hostName&protocol=http&host=172.30.19.77&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-nlztd PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 13 18:45:48.019: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
May 13 18:45:48.188: INFO: Waiting for endpoints: map[]
May 13 18:45:48.196: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.227.86:8080/dial?request=hostName&protocol=http&host=172.30.227.85&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-nlztd PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 13 18:45:48.196: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
May 13 18:45:48.352: INFO: Waiting for endpoints: map[]
May 13 18:45:48.359: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.227.86:8080/dial?request=hostName&protocol=http&host=172.30.63.47&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-nlztd PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 13 18:45:48.359: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
May 13 18:45:48.563: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 18:45:48.563: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-nlztd" for this suite.
May 13 18:46:12.601: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:46:12.787: INFO: namespace: e2e-tests-pod-network-test-nlztd, resource: bindings, ignored listing per whitelist
May 13 18:46:12.835: INFO: namespace e2e-tests-pod-network-test-nlztd deletion completed in 24.263113791s

• [SLOW TEST:45.301 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 18:46:12.835: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-nf25l
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 13 18:46:13.136: INFO: Waiting up to 5m0s for pod "downwardapi-volume-61bfd266-75af-11e9-8f67-2632f168be36" in namespace "e2e-tests-projected-nf25l" to be "success or failure"
May 13 18:46:13.145: INFO: Pod "downwardapi-volume-61bfd266-75af-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 8.508564ms
May 13 18:46:15.153: INFO: Pod "downwardapi-volume-61bfd266-75af-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016655135s
STEP: Saw pod success
May 13 18:46:15.153: INFO: Pod "downwardapi-volume-61bfd266-75af-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 18:46:15.161: INFO: Trying to get logs from node 10.170.219.153 pod downwardapi-volume-61bfd266-75af-11e9-8f67-2632f168be36 container client-container: <nil>
STEP: delete the pod
May 13 18:46:15.199: INFO: Waiting for pod downwardapi-volume-61bfd266-75af-11e9-8f67-2632f168be36 to disappear
May 13 18:46:15.205: INFO: Pod downwardapi-volume-61bfd266-75af-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 18:46:15.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-nf25l" for this suite.
May 13 18:46:21.259: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:46:21.392: INFO: namespace: e2e-tests-projected-nf25l, resource: bindings, ignored listing per whitelist
May 13 18:46:21.577: INFO: namespace e2e-tests-projected-nf25l deletion completed in 6.364091739s

• [SLOW TEST:8.741 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 18:46:21.577: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-tj94q
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 18:46:26.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-tj94q" for this suite.
May 13 18:46:32.106: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:46:32.468: INFO: namespace: e2e-tests-kubelet-test-tj94q, resource: bindings, ignored listing per whitelist
May 13 18:46:32.517: INFO: namespace e2e-tests-kubelet-test-tj94q deletion completed in 6.451985052s

• [SLOW TEST:10.940 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 18:46:32.518: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-jgmpr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0513 18:46:42.929095      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 13 18:46:42.929: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 18:46:42.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-jgmpr" for this suite.
May 13 18:46:48.967: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:46:49.065: INFO: namespace: e2e-tests-gc-jgmpr, resource: bindings, ignored listing per whitelist
May 13 18:46:49.410: INFO: namespace e2e-tests-gc-jgmpr deletion completed in 6.472655659s

• [SLOW TEST:16.891 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 18:46:49.410: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-e2e-kubelet-etc-hosts-dzjcb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
May 13 18:46:55.792: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dzjcb PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 13 18:46:55.792: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
May 13 18:46:55.973: INFO: Exec stderr: ""
May 13 18:46:55.973: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dzjcb PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 13 18:46:55.973: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
May 13 18:46:56.168: INFO: Exec stderr: ""
May 13 18:46:56.168: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dzjcb PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 13 18:46:56.168: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
May 13 18:46:56.344: INFO: Exec stderr: ""
May 13 18:46:56.344: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dzjcb PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 13 18:46:56.344: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
May 13 18:46:56.524: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
May 13 18:46:56.524: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dzjcb PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 13 18:46:56.524: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
May 13 18:46:56.772: INFO: Exec stderr: ""
May 13 18:46:56.772: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dzjcb PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 13 18:46:56.772: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
May 13 18:46:56.932: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
May 13 18:46:56.932: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dzjcb PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 13 18:46:56.932: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
May 13 18:46:57.087: INFO: Exec stderr: ""
May 13 18:46:57.087: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dzjcb PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 13 18:46:57.087: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
May 13 18:46:57.285: INFO: Exec stderr: ""
May 13 18:46:57.285: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dzjcb PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 13 18:46:57.285: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
May 13 18:46:57.469: INFO: Exec stderr: ""
May 13 18:46:57.469: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-dzjcb PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 13 18:46:57.469: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
May 13 18:46:57.720: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 18:46:57.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-dzjcb" for this suite.
May 13 18:47:49.756: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:47:50.060: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-dzjcb, resource: bindings, ignored listing per whitelist
May 13 18:47:50.075: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-dzjcb deletion completed in 52.347386727s

• [SLOW TEST:60.665 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 18:47:50.075: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-cmr2d
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-9bce5bd7-75af-11e9-8f67-2632f168be36
STEP: Creating a pod to test consume secrets
May 13 18:47:50.547: INFO: Waiting up to 5m0s for pod "pod-secrets-9bcfc224-75af-11e9-8f67-2632f168be36" in namespace "e2e-tests-secrets-cmr2d" to be "success or failure"
May 13 18:47:50.555: INFO: Pod "pod-secrets-9bcfc224-75af-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 7.611558ms
May 13 18:47:52.565: INFO: Pod "pod-secrets-9bcfc224-75af-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017507039s
STEP: Saw pod success
May 13 18:47:52.565: INFO: Pod "pod-secrets-9bcfc224-75af-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 18:47:52.572: INFO: Trying to get logs from node 10.170.219.177 pod pod-secrets-9bcfc224-75af-11e9-8f67-2632f168be36 container secret-env-test: <nil>
STEP: delete the pod
May 13 18:47:52.610: INFO: Waiting for pod pod-secrets-9bcfc224-75af-11e9-8f67-2632f168be36 to disappear
May 13 18:47:52.618: INFO: Pod pod-secrets-9bcfc224-75af-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 18:47:52.618: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-cmr2d" for this suite.
May 13 18:47:58.654: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:47:58.784: INFO: namespace: e2e-tests-secrets-cmr2d, resource: bindings, ignored listing per whitelist
May 13 18:47:58.939: INFO: namespace e2e-tests-secrets-cmr2d deletion completed in 6.314523453s

• [SLOW TEST:8.864 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 18:47:58.940: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-nd57p
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 13 18:47:59.363: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
May 13 18:47:59.385: INFO: Number of nodes with available pods: 0
May 13 18:47:59.385: INFO: Node 10.170.219.151 is running more than one daemon pod
May 13 18:48:00.413: INFO: Number of nodes with available pods: 0
May 13 18:48:00.413: INFO: Node 10.170.219.151 is running more than one daemon pod
May 13 18:48:01.402: INFO: Number of nodes with available pods: 2
May 13 18:48:01.402: INFO: Node 10.170.219.153 is running more than one daemon pod
May 13 18:48:02.401: INFO: Number of nodes with available pods: 3
May 13 18:48:02.401: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
May 13 18:48:02.539: INFO: Wrong image for pod: daemon-set-28d9j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:02.539: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:02.539: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:03.554: INFO: Wrong image for pod: daemon-set-28d9j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:03.554: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:03.554: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:04.554: INFO: Wrong image for pod: daemon-set-28d9j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:04.555: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:04.555: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:05.555: INFO: Wrong image for pod: daemon-set-28d9j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:05.555: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:05.555: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:06.555: INFO: Wrong image for pod: daemon-set-28d9j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:06.555: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:06.555: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:07.555: INFO: Wrong image for pod: daemon-set-28d9j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:07.555: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:07.555: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:08.554: INFO: Wrong image for pod: daemon-set-28d9j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:08.554: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:08.554: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:09.554: INFO: Wrong image for pod: daemon-set-28d9j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:09.554: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:09.554: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:10.567: INFO: Wrong image for pod: daemon-set-28d9j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:10.568: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:10.568: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:11.555: INFO: Wrong image for pod: daemon-set-28d9j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:11.555: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:11.555: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:12.555: INFO: Wrong image for pod: daemon-set-28d9j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:12.555: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:12.555: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:13.555: INFO: Wrong image for pod: daemon-set-28d9j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:13.555: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:13.555: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:14.555: INFO: Wrong image for pod: daemon-set-28d9j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:14.555: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:14.555: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:15.554: INFO: Wrong image for pod: daemon-set-28d9j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:15.554: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:15.554: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:16.554: INFO: Wrong image for pod: daemon-set-28d9j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:16.554: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:16.554: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:17.554: INFO: Wrong image for pod: daemon-set-28d9j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:17.554: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:17.554: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:18.555: INFO: Wrong image for pod: daemon-set-28d9j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:18.555: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:18.555: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:19.555: INFO: Wrong image for pod: daemon-set-28d9j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:19.555: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:19.555: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:20.554: INFO: Wrong image for pod: daemon-set-28d9j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:20.554: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:20.554: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:21.566: INFO: Wrong image for pod: daemon-set-28d9j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:21.566: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:21.566: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:22.554: INFO: Wrong image for pod: daemon-set-28d9j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:22.554: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:22.554: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:23.620: INFO: Wrong image for pod: daemon-set-28d9j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:23.620: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:23.620: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:24.556: INFO: Wrong image for pod: daemon-set-28d9j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:24.556: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:24.556: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:25.555: INFO: Wrong image for pod: daemon-set-28d9j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:25.555: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:25.555: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:26.555: INFO: Wrong image for pod: daemon-set-28d9j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:26.555: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:26.555: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:27.555: INFO: Wrong image for pod: daemon-set-28d9j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:27.555: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:27.555: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:28.555: INFO: Wrong image for pod: daemon-set-28d9j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:28.555: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:28.555: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:29.555: INFO: Wrong image for pod: daemon-set-28d9j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:29.555: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:29.555: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:30.554: INFO: Wrong image for pod: daemon-set-28d9j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:30.554: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:30.554: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:31.554: INFO: Wrong image for pod: daemon-set-28d9j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:31.554: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:31.554: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:32.827: INFO: Wrong image for pod: daemon-set-28d9j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:32.827: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:32.827: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:33.556: INFO: Wrong image for pod: daemon-set-28d9j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:33.556: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:33.556: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:34.554: INFO: Wrong image for pod: daemon-set-28d9j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:34.554: INFO: Pod daemon-set-28d9j is not available
May 13 18:48:34.554: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:34.554: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:35.627: INFO: Wrong image for pod: daemon-set-28d9j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:35.627: INFO: Pod daemon-set-28d9j is not available
May 13 18:48:35.627: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:35.627: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:36.554: INFO: Wrong image for pod: daemon-set-28d9j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:36.555: INFO: Pod daemon-set-28d9j is not available
May 13 18:48:36.555: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:36.555: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:37.628: INFO: Wrong image for pod: daemon-set-28d9j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:37.628: INFO: Pod daemon-set-28d9j is not available
May 13 18:48:37.628: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:37.628: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:38.628: INFO: Wrong image for pod: daemon-set-28d9j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:38.628: INFO: Pod daemon-set-28d9j is not available
May 13 18:48:38.628: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:38.628: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:39.553: INFO: Wrong image for pod: daemon-set-28d9j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:39.554: INFO: Pod daemon-set-28d9j is not available
May 13 18:48:39.554: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:39.554: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:40.620: INFO: Wrong image for pod: daemon-set-28d9j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:40.620: INFO: Pod daemon-set-28d9j is not available
May 13 18:48:40.620: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:40.620: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:41.554: INFO: Wrong image for pod: daemon-set-28d9j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:41.555: INFO: Pod daemon-set-28d9j is not available
May 13 18:48:41.555: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:41.555: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:42.554: INFO: Wrong image for pod: daemon-set-28d9j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:42.554: INFO: Pod daemon-set-28d9j is not available
May 13 18:48:42.554: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:42.554: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:43.567: INFO: Wrong image for pod: daemon-set-28d9j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:43.567: INFO: Pod daemon-set-28d9j is not available
May 13 18:48:43.567: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:43.567: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:44.620: INFO: Wrong image for pod: daemon-set-28d9j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:44.620: INFO: Pod daemon-set-28d9j is not available
May 13 18:48:44.620: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:44.620: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:45.555: INFO: Wrong image for pod: daemon-set-28d9j. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:45.555: INFO: Pod daemon-set-28d9j is not available
May 13 18:48:45.555: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:45.555: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:46.555: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:46.555: INFO: Pod daemon-set-d7dmf is not available
May 13 18:48:46.555: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:47.554: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:47.554: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:48.554: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:48.554: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:49.555: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:49.555: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:50.620: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:50.620: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:51.554: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:51.554: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:52.555: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:52.555: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:53.555: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:53.555: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:54.566: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:54.566: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:55.684: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:55.684: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:56.555: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:56.555: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:57.555: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:57.555: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:58.554: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:58.554: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:59.555: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:48:59.555: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:00.554: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:00.554: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:01.554: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:01.554: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:02.554: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:02.554: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:03.554: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:03.554: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:04.554: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:04.554: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:05.567: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:05.567: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:06.554: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:06.555: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:07.554: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:07.554: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:08.554: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:08.555: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:09.554: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:09.554: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:10.554: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:10.554: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:11.554: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:11.555: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:12.554: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:12.554: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:13.620: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:13.620: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:14.554: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:14.554: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:15.555: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:15.555: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:16.583: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:16.583: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:17.554: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:17.554: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:18.555: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:18.555: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:19.555: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:19.555: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:19.555: INFO: Pod daemon-set-zglt4 is not available
May 13 18:49:20.554: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:20.555: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:20.555: INFO: Pod daemon-set-zglt4 is not available
May 13 18:49:21.555: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:21.555: INFO: Wrong image for pod: daemon-set-zglt4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:21.555: INFO: Pod daemon-set-zglt4 is not available
May 13 18:49:22.557: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:22.557: INFO: Pod daemon-set-swv6c is not available
May 13 18:49:23.555: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:23.555: INFO: Pod daemon-set-swv6c is not available
May 13 18:49:24.554: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:25.555: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:26.555: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:27.570: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:28.556: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:29.556: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:30.620: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:31.554: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:32.554: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:33.554: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:34.555: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:35.554: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:36.583: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:37.554: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:38.567: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:39.555: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:40.554: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:41.554: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:42.554: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:44.172: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:44.555: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:45.555: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:46.555: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:47.554: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:48.554: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:49.567: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:50.554: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:51.554: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:52.554: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:53.554: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:54.554: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:55.554: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:55.554: INFO: Pod daemon-set-4cxm2 is not available
May 13 18:49:56.554: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:56.554: INFO: Pod daemon-set-4cxm2 is not available
May 13 18:49:57.554: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:57.554: INFO: Pod daemon-set-4cxm2 is not available
May 13 18:49:58.554: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:58.554: INFO: Pod daemon-set-4cxm2 is not available
May 13 18:49:59.554: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:49:59.554: INFO: Pod daemon-set-4cxm2 is not available
May 13 18:50:00.620: INFO: Wrong image for pod: daemon-set-4cxm2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
May 13 18:50:00.620: INFO: Pod daemon-set-4cxm2 is not available
May 13 18:50:01.620: INFO: Pod daemon-set-42dj5 is not available
STEP: Check that daemon pods are still running on every node of the cluster.
May 13 18:50:01.642: INFO: Number of nodes with available pods: 2
May 13 18:50:01.642: INFO: Node 10.170.219.177 is running more than one daemon pod
May 13 18:50:02.660: INFO: Number of nodes with available pods: 2
May 13 18:50:02.660: INFO: Node 10.170.219.177 is running more than one daemon pod
May 13 18:50:03.728: INFO: Number of nodes with available pods: 3
May 13 18:50:03.728: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-nd57p, will wait for the garbage collector to delete the pods
May 13 18:50:03.831: INFO: Deleting DaemonSet.extensions daemon-set took: 11.870457ms
May 13 18:50:03.931: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.23188ms
May 13 18:50:16.350: INFO: Number of nodes with available pods: 0
May 13 18:50:16.350: INFO: Number of running nodes: 0, number of available pods: 0
May 13 18:50:16.358: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-nd57p/daemonsets","resourceVersion":"33510"},"items":null}

May 13 18:50:16.366: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-nd57p/pods","resourceVersion":"33510"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 18:50:16.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-nd57p" for this suite.
May 13 18:50:24.426: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:50:24.623: INFO: namespace: e2e-tests-daemonsets-nd57p, resource: bindings, ignored listing per whitelist
May 13 18:50:24.774: INFO: namespace e2e-tests-daemonsets-nd57p deletion completed in 8.37761987s

• [SLOW TEST:145.834 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 18:50:24.775: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-nhhkm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
May 13 18:50:25.120: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 cluster-info'
May 13 18:50:25.242: INFO: stderr: ""
May 13 18:50:25.242: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mkubernetes-dashboard\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy\x1b[0m\n\x1b[0;32mMetrics-server\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 18:50:25.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-nhhkm" for this suite.
May 13 18:50:31.282: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:50:31.481: INFO: namespace: e2e-tests-kubectl-nhhkm, resource: bindings, ignored listing per whitelist
May 13 18:50:31.539: INFO: namespace e2e-tests-kubectl-nhhkm deletion completed in 6.289865859s

• [SLOW TEST:6.764 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 18:50:31.540: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-ktwh4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
May 13 18:50:31.798: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 create -f - --namespace=e2e-tests-kubectl-ktwh4'
May 13 18:50:31.983: INFO: stderr: ""
May 13 18:50:31.983: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 13 18:50:31.983: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-ktwh4'
May 13 18:50:32.091: INFO: stderr: ""
May 13 18:50:32.091: INFO: stdout: "update-demo-nautilus-qlj7j update-demo-nautilus-rbt2q "
May 13 18:50:32.091: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 get pods update-demo-nautilus-qlj7j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ktwh4'
May 13 18:50:32.187: INFO: stderr: ""
May 13 18:50:32.187: INFO: stdout: ""
May 13 18:50:32.187: INFO: update-demo-nautilus-qlj7j is created but not running
May 13 18:50:37.187: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-ktwh4'
May 13 18:50:37.351: INFO: stderr: ""
May 13 18:50:37.351: INFO: stdout: "update-demo-nautilus-qlj7j update-demo-nautilus-rbt2q "
May 13 18:50:37.351: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 get pods update-demo-nautilus-qlj7j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ktwh4'
May 13 18:50:37.442: INFO: stderr: ""
May 13 18:50:37.442: INFO: stdout: "true"
May 13 18:50:37.442: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 get pods update-demo-nautilus-qlj7j -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ktwh4'
May 13 18:50:37.538: INFO: stderr: ""
May 13 18:50:37.539: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 13 18:50:37.539: INFO: validating pod update-demo-nautilus-qlj7j
May 13 18:50:37.554: INFO: got data: {
  "image": "nautilus.jpg"
}

May 13 18:50:37.554: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 13 18:50:37.554: INFO: update-demo-nautilus-qlj7j is verified up and running
May 13 18:50:37.554: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 get pods update-demo-nautilus-rbt2q -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ktwh4'
May 13 18:50:37.664: INFO: stderr: ""
May 13 18:50:37.664: INFO: stdout: "true"
May 13 18:50:37.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 get pods update-demo-nautilus-rbt2q -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ktwh4'
May 13 18:50:37.768: INFO: stderr: ""
May 13 18:50:37.769: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 13 18:50:37.769: INFO: validating pod update-demo-nautilus-rbt2q
May 13 18:50:37.783: INFO: got data: {
  "image": "nautilus.jpg"
}

May 13 18:50:37.783: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 13 18:50:37.783: INFO: update-demo-nautilus-rbt2q is verified up and running
STEP: scaling down the replication controller
May 13 18:50:37.785: INFO: scanned /root for discovery docs: <nil>
May 13 18:50:37.785: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-ktwh4'
May 13 18:50:38.922: INFO: stderr: ""
May 13 18:50:38.922: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 13 18:50:38.922: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-ktwh4'
May 13 18:50:39.063: INFO: stderr: ""
May 13 18:50:39.063: INFO: stdout: "update-demo-nautilus-qlj7j update-demo-nautilus-rbt2q "
STEP: Replicas for name=update-demo: expected=1 actual=2
May 13 18:50:44.063: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-ktwh4'
May 13 18:50:44.223: INFO: stderr: ""
May 13 18:50:44.223: INFO: stdout: "update-demo-nautilus-rbt2q "
May 13 18:50:44.223: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 get pods update-demo-nautilus-rbt2q -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ktwh4'
May 13 18:50:44.331: INFO: stderr: ""
May 13 18:50:44.331: INFO: stdout: "true"
May 13 18:50:44.331: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 get pods update-demo-nautilus-rbt2q -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ktwh4'
May 13 18:50:44.417: INFO: stderr: ""
May 13 18:50:44.417: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 13 18:50:44.417: INFO: validating pod update-demo-nautilus-rbt2q
May 13 18:50:44.429: INFO: got data: {
  "image": "nautilus.jpg"
}

May 13 18:50:44.430: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 13 18:50:44.430: INFO: update-demo-nautilus-rbt2q is verified up and running
STEP: scaling up the replication controller
May 13 18:50:44.431: INFO: scanned /root for discovery docs: <nil>
May 13 18:50:44.432: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-ktwh4'
May 13 18:50:45.711: INFO: stderr: ""
May 13 18:50:45.711: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 13 18:50:45.711: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-ktwh4'
May 13 18:50:45.822: INFO: stderr: ""
May 13 18:50:45.822: INFO: stdout: "update-demo-nautilus-9l767 update-demo-nautilus-rbt2q "
May 13 18:50:45.822: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 get pods update-demo-nautilus-9l767 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ktwh4'
May 13 18:50:45.931: INFO: stderr: ""
May 13 18:50:45.931: INFO: stdout: ""
May 13 18:50:45.931: INFO: update-demo-nautilus-9l767 is created but not running
May 13 18:50:50.931: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-ktwh4'
May 13 18:50:51.031: INFO: stderr: ""
May 13 18:50:51.031: INFO: stdout: "update-demo-nautilus-9l767 update-demo-nautilus-rbt2q "
May 13 18:50:51.031: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 get pods update-demo-nautilus-9l767 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ktwh4'
May 13 18:50:51.151: INFO: stderr: ""
May 13 18:50:51.151: INFO: stdout: "true"
May 13 18:50:51.151: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 get pods update-demo-nautilus-9l767 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ktwh4'
May 13 18:50:51.255: INFO: stderr: ""
May 13 18:50:51.255: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 13 18:50:51.255: INFO: validating pod update-demo-nautilus-9l767
May 13 18:50:51.271: INFO: got data: {
  "image": "nautilus.jpg"
}

May 13 18:50:51.271: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 13 18:50:51.271: INFO: update-demo-nautilus-9l767 is verified up and running
May 13 18:50:51.271: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 get pods update-demo-nautilus-rbt2q -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ktwh4'
May 13 18:50:51.365: INFO: stderr: ""
May 13 18:50:51.365: INFO: stdout: "true"
May 13 18:50:51.365: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 get pods update-demo-nautilus-rbt2q -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-ktwh4'
May 13 18:50:51.472: INFO: stderr: ""
May 13 18:50:51.472: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 13 18:50:51.472: INFO: validating pod update-demo-nautilus-rbt2q
May 13 18:50:51.483: INFO: got data: {
  "image": "nautilus.jpg"
}

May 13 18:50:51.483: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 13 18:50:51.483: INFO: update-demo-nautilus-rbt2q is verified up and running
STEP: using delete to clean up resources
May 13 18:50:51.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-ktwh4'
May 13 18:50:51.597: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 13 18:50:51.597: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
May 13 18:50:51.598: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-ktwh4'
May 13 18:50:51.712: INFO: stderr: "No resources found.\n"
May 13 18:50:51.712: INFO: stdout: ""
May 13 18:50:51.712: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 get pods -l name=update-demo --namespace=e2e-tests-kubectl-ktwh4 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 13 18:50:51.821: INFO: stderr: ""
May 13 18:50:51.821: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 18:50:51.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ktwh4" for this suite.
May 13 18:50:57.869: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:50:58.006: INFO: namespace: e2e-tests-kubectl-ktwh4, resource: bindings, ignored listing per whitelist
May 13 18:50:58.105: INFO: namespace e2e-tests-kubectl-ktwh4 deletion completed in 6.274579966s

• [SLOW TEST:26.566 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 18:50:58.105: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-cdqz9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-cdqz9
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
May 13 18:50:58.447: INFO: Found 0 stateful pods, waiting for 3
May 13 18:51:08.469: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 13 18:51:08.469: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 13 18:51:08.469: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
May 13 18:51:08.490: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 exec --namespace=e2e-tests-statefulset-cdqz9 ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 13 18:51:08.785: INFO: stderr: ""
May 13 18:51:08.786: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 13 18:51:08.786: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
May 13 18:51:18.848: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
May 13 18:51:28.928: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 exec --namespace=e2e-tests-statefulset-cdqz9 ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 13 18:51:29.173: INFO: stderr: ""
May 13 18:51:29.173: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 13 18:51:29.173: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 13 18:51:39.320: INFO: Waiting for StatefulSet e2e-tests-statefulset-cdqz9/ss2 to complete update
May 13 18:51:39.320: INFO: Waiting for Pod e2e-tests-statefulset-cdqz9/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
May 13 18:51:39.320: INFO: Waiting for Pod e2e-tests-statefulset-cdqz9/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
May 13 18:51:39.320: INFO: Waiting for Pod e2e-tests-statefulset-cdqz9/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
May 13 18:51:49.346: INFO: Waiting for StatefulSet e2e-tests-statefulset-cdqz9/ss2 to complete update
May 13 18:51:49.346: INFO: Waiting for Pod e2e-tests-statefulset-cdqz9/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
May 13 18:51:59.335: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 exec --namespace=e2e-tests-statefulset-cdqz9 ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 13 18:51:59.719: INFO: stderr: ""
May 13 18:51:59.719: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 13 18:51:59.719: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 13 18:52:09.819: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
May 13 18:52:09.840: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 exec --namespace=e2e-tests-statefulset-cdqz9 ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 13 18:52:10.117: INFO: stderr: ""
May 13 18:52:10.117: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 13 18:52:10.117: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 13 18:52:30.173: INFO: Waiting for StatefulSet e2e-tests-statefulset-cdqz9/ss2 to complete update
May 13 18:52:30.173: INFO: Waiting for Pod e2e-tests-statefulset-cdqz9/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
May 13 18:52:40.227: INFO: Waiting for StatefulSet e2e-tests-statefulset-cdqz9/ss2 to complete update
May 13 18:52:40.227: INFO: Waiting for Pod e2e-tests-statefulset-cdqz9/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 13 18:52:50.187: INFO: Deleting all statefulset in ns e2e-tests-statefulset-cdqz9
May 13 18:52:50.207: INFO: Scaling statefulset ss2 to 0
May 13 18:53:20.260: INFO: Waiting for statefulset status.replicas updated to 0
May 13 18:53:20.266: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 18:53:20.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-cdqz9" for this suite.
May 13 18:53:28.355: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:53:28.708: INFO: namespace: e2e-tests-statefulset-cdqz9, resource: bindings, ignored listing per whitelist
May 13 18:53:28.778: INFO: namespace e2e-tests-statefulset-cdqz9 deletion completed in 8.449909689s

• [SLOW TEST:150.672 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 18:53:28.778: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replicaset-mks6t
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 13 18:53:29.123: INFO: Creating ReplicaSet my-hostname-basic-65a0a4b3-75b0-11e9-8f67-2632f168be36
May 13 18:53:29.142: INFO: Pod name my-hostname-basic-65a0a4b3-75b0-11e9-8f67-2632f168be36: Found 0 pods out of 1
May 13 18:53:34.164: INFO: Pod name my-hostname-basic-65a0a4b3-75b0-11e9-8f67-2632f168be36: Found 1 pods out of 1
May 13 18:53:34.164: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-65a0a4b3-75b0-11e9-8f67-2632f168be36" is running
May 13 18:53:34.177: INFO: Pod "my-hostname-basic-65a0a4b3-75b0-11e9-8f67-2632f168be36-x2j86" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-13 18:53:29 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-13 18:53:30 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-13 18:53:30 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-13 18:53:29 +0000 UTC Reason: Message:}])
May 13 18:53:34.177: INFO: Trying to dial the pod
May 13 18:53:39.242: INFO: Controller my-hostname-basic-65a0a4b3-75b0-11e9-8f67-2632f168be36: Got expected result from replica 1 [my-hostname-basic-65a0a4b3-75b0-11e9-8f67-2632f168be36-x2j86]: "my-hostname-basic-65a0a4b3-75b0-11e9-8f67-2632f168be36-x2j86", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 18:53:39.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-mks6t" for this suite.
May 13 18:53:45.339: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:53:45.593: INFO: namespace: e2e-tests-replicaset-mks6t, resource: bindings, ignored listing per whitelist
May 13 18:53:45.606: INFO: namespace e2e-tests-replicaset-mks6t deletion completed in 6.352888264s

• [SLOW TEST:16.828 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 18:53:45.607: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-4mlpn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
May 13 18:53:45.897: INFO: Waiting up to 5m0s for pod "downward-api-6f9db637-75b0-11e9-8f67-2632f168be36" in namespace "e2e-tests-downward-api-4mlpn" to be "success or failure"
May 13 18:53:45.904: INFO: Pod "downward-api-6f9db637-75b0-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 7.231598ms
May 13 18:53:47.914: INFO: Pod "downward-api-6f9db637-75b0-11e9-8f67-2632f168be36": Phase="Running", Reason="", readiness=true. Elapsed: 2.017030187s
May 13 18:53:49.923: INFO: Pod "downward-api-6f9db637-75b0-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025552535s
STEP: Saw pod success
May 13 18:53:49.923: INFO: Pod "downward-api-6f9db637-75b0-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 18:53:49.930: INFO: Trying to get logs from node 10.170.219.153 pod downward-api-6f9db637-75b0-11e9-8f67-2632f168be36 container dapi-container: <nil>
STEP: delete the pod
May 13 18:53:49.974: INFO: Waiting for pod downward-api-6f9db637-75b0-11e9-8f67-2632f168be36 to disappear
May 13 18:53:49.982: INFO: Pod downward-api-6f9db637-75b0-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 18:53:49.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-4mlpn" for this suite.
May 13 18:53:56.029: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:53:56.188: INFO: namespace: e2e-tests-downward-api-4mlpn, resource: bindings, ignored listing per whitelist
May 13 18:53:56.261: INFO: namespace e2e-tests-downward-api-4mlpn deletion completed in 6.270758168s

• [SLOW TEST:10.654 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 18:53:56.262: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-bbq75
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-bbq75
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-bbq75 to expose endpoints map[]
May 13 18:53:56.559: INFO: Get endpoints failed (5.246977ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
May 13 18:53:57.565: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-bbq75 exposes endpoints map[] (1.011360677s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-bbq75
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-bbq75 to expose endpoints map[pod1:[80]]
May 13 18:53:59.623: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-bbq75 exposes endpoints map[pod1:[80]] (2.042324207s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-bbq75
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-bbq75 to expose endpoints map[pod1:[80] pod2:[80]]
May 13 18:54:01.841: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-bbq75 exposes endpoints map[pod1:[80] pod2:[80]] (2.207236477s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-bbq75
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-bbq75 to expose endpoints map[pod2:[80]]
May 13 18:54:02.882: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-bbq75 exposes endpoints map[pod2:[80]] (1.026519591s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-bbq75
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-bbq75 to expose endpoints map[]
May 13 18:54:03.907: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-bbq75 exposes endpoints map[] (1.011697819s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 18:54:03.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-bbq75" for this suite.
May 13 18:54:28.000: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:54:28.341: INFO: namespace: e2e-tests-services-bbq75, resource: bindings, ignored listing per whitelist
May 13 18:54:28.360: INFO: namespace e2e-tests-services-bbq75 deletion completed in 24.388848919s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:32.098 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 18:54:28.363: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-blp6j
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 13 18:54:28.642: INFO: Creating deployment "test-recreate-deployment"
May 13 18:54:28.650: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
May 13 18:54:28.662: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
May 13 18:54:30.689: INFO: Waiting deployment "test-recreate-deployment" to complete
May 13 18:54:30.695: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
May 13 18:54:30.706: INFO: Updating deployment test-recreate-deployment
May 13 18:54:30.706: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May 13 18:54:30.799: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-blp6j,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-blp6j/deployments/test-recreate-deployment,UID:891b10aa-75b0-11e9-b786-da20024d205c,ResourceVersion:34719,Generation:2,CreationTimestamp:2019-05-13 18:54:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-05-13 18:54:30 +0000 UTC 2019-05-13 18:54:30 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-05-13 18:54:30 +0000 UTC 2019-05-13 18:54:28 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-697fbf54bf" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

May 13 18:54:30.807: INFO: New ReplicaSet "test-recreate-deployment-697fbf54bf" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf,GenerateName:,Namespace:e2e-tests-deployment-blp6j,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-blp6j/replicasets/test-recreate-deployment-697fbf54bf,UID:8a5c2507-75b0-11e9-83a8-7e0242378207,ResourceVersion:34717,Generation:1,CreationTimestamp:2019-05-13 18:54:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 891b10aa-75b0-11e9-b786-da20024d205c 0xc001076327 0xc001076328}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 13 18:54:30.807: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
May 13 18:54:30.807: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5dfdcc846d,GenerateName:,Namespace:e2e-tests-deployment-blp6j,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-blp6j/replicasets/test-recreate-deployment-5dfdcc846d,UID:891e5f35-75b0-11e9-83a8-7e0242378207,ResourceVersion:34707,Generation:2,CreationTimestamp:2019-05-13 18:54:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 891b10aa-75b0-11e9-b786-da20024d205c 0xc001bc5ee7 0xc001bc5ee8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5dfdcc846d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 13 18:54:30.816: INFO: Pod "test-recreate-deployment-697fbf54bf-wxctj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-697fbf54bf-wxctj,GenerateName:test-recreate-deployment-697fbf54bf-,Namespace:e2e-tests-deployment-blp6j,SelfLink:/api/v1/namespaces/e2e-tests-deployment-blp6j/pods/test-recreate-deployment-697fbf54bf-wxctj,UID:8a5d3573-75b0-11e9-83a8-7e0242378207,ResourceVersion:34718,Generation:0,CreationTimestamp:2019-05-13 18:54:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 697fbf54bf,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-697fbf54bf 8a5c2507-75b0-11e9-83a8-7e0242378207 0xc000feaea7 0xc000feaea8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-zpkl5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zpkl5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-zpkl5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.177,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000feaf30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000feaf50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 18:54:30 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 18:54:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 18:54:30 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 18:54:30 +0000 UTC  }],Message:,Reason:,HostIP:10.170.219.177,PodIP:,StartTime:2019-05-13 18:54:30 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 18:54:30.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-blp6j" for this suite.
May 13 18:54:36.851: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:54:37.119: INFO: namespace: e2e-tests-deployment-blp6j, resource: bindings, ignored listing per whitelist
May 13 18:54:37.122: INFO: namespace e2e-tests-deployment-blp6j deletion completed in 6.297523198s

• [SLOW TEST:8.759 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 18:54:37.122: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-mqxbm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
May 13 18:54:38.250: INFO: Waiting up to 5m0s for pod "client-containers-8ed2395c-75b0-11e9-8f67-2632f168be36" in namespace "e2e-tests-containers-mqxbm" to be "success or failure"
May 13 18:54:38.257: INFO: Pod "client-containers-8ed2395c-75b0-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 7.329415ms
May 13 18:54:40.265: INFO: Pod "client-containers-8ed2395c-75b0-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015559718s
STEP: Saw pod success
May 13 18:54:40.265: INFO: Pod "client-containers-8ed2395c-75b0-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 18:54:40.273: INFO: Trying to get logs from node 10.170.219.153 pod client-containers-8ed2395c-75b0-11e9-8f67-2632f168be36 container test-container: <nil>
STEP: delete the pod
May 13 18:54:40.310: INFO: Waiting for pod client-containers-8ed2395c-75b0-11e9-8f67-2632f168be36 to disappear
May 13 18:54:40.317: INFO: Pod client-containers-8ed2395c-75b0-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 18:54:40.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-mqxbm" for this suite.
May 13 18:54:46.351: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:54:46.452: INFO: namespace: e2e-tests-containers-mqxbm, resource: bindings, ignored listing per whitelist
May 13 18:54:46.672: INFO: namespace e2e-tests-containers-mqxbm deletion completed in 6.347751879s

• [SLOW TEST:9.550 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 18:54:46.672: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-x8tm4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
May 13 18:54:46.962: INFO: Waiting up to 5m0s for pod "var-expansion-94036e08-75b0-11e9-8f67-2632f168be36" in namespace "e2e-tests-var-expansion-x8tm4" to be "success or failure"
May 13 18:54:46.972: INFO: Pod "var-expansion-94036e08-75b0-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 9.867252ms
May 13 18:54:48.980: INFO: Pod "var-expansion-94036e08-75b0-11e9-8f67-2632f168be36": Phase="Running", Reason="", readiness=true. Elapsed: 2.017912338s
May 13 18:54:50.988: INFO: Pod "var-expansion-94036e08-75b0-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02647884s
STEP: Saw pod success
May 13 18:54:50.988: INFO: Pod "var-expansion-94036e08-75b0-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 18:54:50.996: INFO: Trying to get logs from node 10.170.219.177 pod var-expansion-94036e08-75b0-11e9-8f67-2632f168be36 container dapi-container: <nil>
STEP: delete the pod
May 13 18:54:51.037: INFO: Waiting for pod var-expansion-94036e08-75b0-11e9-8f67-2632f168be36 to disappear
May 13 18:54:51.056: INFO: Pod var-expansion-94036e08-75b0-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 18:54:51.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-x8tm4" for this suite.
May 13 18:54:57.092: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:54:57.171: INFO: namespace: e2e-tests-var-expansion-x8tm4, resource: bindings, ignored listing per whitelist
May 13 18:54:57.460: INFO: namespace e2e-tests-var-expansion-x8tm4 deletion completed in 6.396015784s

• [SLOW TEST:10.788 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 18:54:57.460: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-vtsw7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 13 18:54:57.748: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9a715bda-75b0-11e9-8f67-2632f168be36" in namespace "e2e-tests-projected-vtsw7" to be "success or failure"
May 13 18:54:57.756: INFO: Pod "downwardapi-volume-9a715bda-75b0-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 8.026421ms
May 13 18:54:59.767: INFO: Pod "downwardapi-volume-9a715bda-75b0-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018563247s
STEP: Saw pod success
May 13 18:54:59.767: INFO: Pod "downwardapi-volume-9a715bda-75b0-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 18:54:59.775: INFO: Trying to get logs from node 10.170.219.153 pod downwardapi-volume-9a715bda-75b0-11e9-8f67-2632f168be36 container client-container: <nil>
STEP: delete the pod
May 13 18:54:59.858: INFO: Waiting for pod downwardapi-volume-9a715bda-75b0-11e9-8f67-2632f168be36 to disappear
May 13 18:54:59.869: INFO: Pod downwardapi-volume-9a715bda-75b0-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 18:54:59.869: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vtsw7" for this suite.
May 13 18:55:05.906: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:55:06.145: INFO: namespace: e2e-tests-projected-vtsw7, resource: bindings, ignored listing per whitelist
May 13 18:55:06.150: INFO: namespace e2e-tests-projected-vtsw7 deletion completed in 6.272991958s

• [SLOW TEST:8.690 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 18:55:06.150: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-b7v4m
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 13 18:55:06.427: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9f9daf81-75b0-11e9-8f67-2632f168be36" in namespace "e2e-tests-projected-b7v4m" to be "success or failure"
May 13 18:55:06.434: INFO: Pod "downwardapi-volume-9f9daf81-75b0-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 7.034518ms
May 13 18:55:08.443: INFO: Pod "downwardapi-volume-9f9daf81-75b0-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016118363s
STEP: Saw pod success
May 13 18:55:08.443: INFO: Pod "downwardapi-volume-9f9daf81-75b0-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 18:55:08.452: INFO: Trying to get logs from node 10.170.219.153 pod downwardapi-volume-9f9daf81-75b0-11e9-8f67-2632f168be36 container client-container: <nil>
STEP: delete the pod
May 13 18:55:08.492: INFO: Waiting for pod downwardapi-volume-9f9daf81-75b0-11e9-8f67-2632f168be36 to disappear
May 13 18:55:08.499: INFO: Pod downwardapi-volume-9f9daf81-75b0-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 18:55:08.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-b7v4m" for this suite.
May 13 18:55:14.548: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:55:14.660: INFO: namespace: e2e-tests-projected-b7v4m, resource: bindings, ignored listing per whitelist
May 13 18:55:14.877: INFO: namespace e2e-tests-projected-b7v4m deletion completed in 6.369425s

• [SLOW TEST:8.727 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 18:55:14.877: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-d68wz
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-a4d285cc-75b0-11e9-8f67-2632f168be36
STEP: Creating a pod to test consume configMaps
May 13 18:55:15.170: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a4d3da3a-75b0-11e9-8f67-2632f168be36" in namespace "e2e-tests-projected-d68wz" to be "success or failure"
May 13 18:55:15.177: INFO: Pod "pod-projected-configmaps-a4d3da3a-75b0-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 7.448996ms
May 13 18:55:17.185: INFO: Pod "pod-projected-configmaps-a4d3da3a-75b0-11e9-8f67-2632f168be36": Phase="Running", Reason="", readiness=true. Elapsed: 2.015376699s
May 13 18:55:19.194: INFO: Pod "pod-projected-configmaps-a4d3da3a-75b0-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023993986s
STEP: Saw pod success
May 13 18:55:19.194: INFO: Pod "pod-projected-configmaps-a4d3da3a-75b0-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 18:55:19.203: INFO: Trying to get logs from node 10.170.219.153 pod pod-projected-configmaps-a4d3da3a-75b0-11e9-8f67-2632f168be36 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 13 18:55:19.241: INFO: Waiting for pod pod-projected-configmaps-a4d3da3a-75b0-11e9-8f67-2632f168be36 to disappear
May 13 18:55:19.320: INFO: Pod pod-projected-configmaps-a4d3da3a-75b0-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 18:55:19.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-d68wz" for this suite.
May 13 18:55:25.368: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:55:25.486: INFO: namespace: e2e-tests-projected-d68wz, resource: bindings, ignored listing per whitelist
May 13 18:55:25.644: INFO: namespace e2e-tests-projected-d68wz deletion completed in 6.31621283s

• [SLOW TEST:10.767 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 18:55:25.644: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-kt5mg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-kt5mg
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 13 18:55:25.916: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 13 18:55:42.141: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.227.101:8080/dial?request=hostName&protocol=udp&host=172.30.19.82&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-kt5mg PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 13 18:55:42.141: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
May 13 18:55:42.329: INFO: Waiting for endpoints: map[]
May 13 18:55:42.337: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.227.101:8080/dial?request=hostName&protocol=udp&host=172.30.227.100&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-kt5mg PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 13 18:55:42.337: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
May 13 18:55:42.523: INFO: Waiting for endpoints: map[]
May 13 18:55:42.531: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.227.101:8080/dial?request=hostName&protocol=udp&host=172.30.63.63&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-kt5mg PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 13 18:55:42.531: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
May 13 18:55:42.686: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 18:55:42.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-kt5mg" for this suite.
May 13 18:56:06.723: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:56:07.133: INFO: namespace: e2e-tests-pod-network-test-kt5mg, resource: bindings, ignored listing per whitelist
May 13 18:56:07.254: INFO: namespace e2e-tests-pod-network-test-kt5mg deletion completed in 24.559613399s

• [SLOW TEST:41.610 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 18:56:07.255: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-rpsd6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
May 13 18:56:07.628: INFO: Waiting up to 5m0s for pod "pod-c41817e4-75b0-11e9-8f67-2632f168be36" in namespace "e2e-tests-emptydir-rpsd6" to be "success or failure"
May 13 18:56:07.635: INFO: Pod "pod-c41817e4-75b0-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 7.479152ms
May 13 18:56:09.657: INFO: Pod "pod-c41817e4-75b0-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02936211s
STEP: Saw pod success
May 13 18:56:09.657: INFO: Pod "pod-c41817e4-75b0-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 18:56:09.665: INFO: Trying to get logs from node 10.170.219.177 pod pod-c41817e4-75b0-11e9-8f67-2632f168be36 container test-container: <nil>
STEP: delete the pod
May 13 18:56:09.703: INFO: Waiting for pod pod-c41817e4-75b0-11e9-8f67-2632f168be36 to disappear
May 13 18:56:09.720: INFO: Pod pod-c41817e4-75b0-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 18:56:09.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-rpsd6" for this suite.
May 13 18:56:15.761: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:56:15.852: INFO: namespace: e2e-tests-emptydir-rpsd6, resource: bindings, ignored listing per whitelist
May 13 18:56:16.001: INFO: namespace e2e-tests-emptydir-rpsd6 deletion completed in 6.27390006s

• [SLOW TEST:8.747 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 18:56:16.002: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-wrapper-xtjxg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 18:56:20.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-xtjxg" for this suite.
May 13 18:56:26.564: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:56:26.628: INFO: namespace: e2e-tests-emptydir-wrapper-xtjxg, resource: bindings, ignored listing per whitelist
May 13 18:56:26.818: INFO: namespace e2e-tests-emptydir-wrapper-xtjxg deletion completed in 6.283524234s

• [SLOW TEST:10.816 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 18:56:26.818: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-hghcz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 18:56:29.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-hghcz" for this suite.
May 13 18:57:13.188: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:57:13.763: INFO: namespace: e2e-tests-kubelet-test-hghcz, resource: bindings, ignored listing per whitelist
May 13 18:57:13.785: INFO: namespace e2e-tests-kubelet-test-hghcz deletion completed in 44.62663585s

• [SLOW TEST:46.967 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 18:57:13.785: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-9mnwf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
May 13 18:57:14.102: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-9mnwf,SelfLink:/api/v1/namespaces/e2e-tests-watch-9mnwf/configmaps/e2e-watch-test-configmap-a,UID:ebb89a30-75b0-11e9-b786-da20024d205c,ResourceVersion:35432,Generation:0,CreationTimestamp:2019-05-13 18:57:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 13 18:57:14.102: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-9mnwf,SelfLink:/api/v1/namespaces/e2e-tests-watch-9mnwf/configmaps/e2e-watch-test-configmap-a,UID:ebb89a30-75b0-11e9-b786-da20024d205c,ResourceVersion:35432,Generation:0,CreationTimestamp:2019-05-13 18:57:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
May 13 18:57:24.230: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-9mnwf,SelfLink:/api/v1/namespaces/e2e-tests-watch-9mnwf/configmaps/e2e-watch-test-configmap-a,UID:ebb89a30-75b0-11e9-b786-da20024d205c,ResourceVersion:35449,Generation:0,CreationTimestamp:2019-05-13 18:57:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
May 13 18:57:24.230: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-9mnwf,SelfLink:/api/v1/namespaces/e2e-tests-watch-9mnwf/configmaps/e2e-watch-test-configmap-a,UID:ebb89a30-75b0-11e9-b786-da20024d205c,ResourceVersion:35449,Generation:0,CreationTimestamp:2019-05-13 18:57:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
May 13 18:57:34.261: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-9mnwf,SelfLink:/api/v1/namespaces/e2e-tests-watch-9mnwf/configmaps/e2e-watch-test-configmap-a,UID:ebb89a30-75b0-11e9-b786-da20024d205c,ResourceVersion:35466,Generation:0,CreationTimestamp:2019-05-13 18:57:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 13 18:57:34.261: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-9mnwf,SelfLink:/api/v1/namespaces/e2e-tests-watch-9mnwf/configmaps/e2e-watch-test-configmap-a,UID:ebb89a30-75b0-11e9-b786-da20024d205c,ResourceVersion:35466,Generation:0,CreationTimestamp:2019-05-13 18:57:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
May 13 18:57:44.292: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-9mnwf,SelfLink:/api/v1/namespaces/e2e-tests-watch-9mnwf/configmaps/e2e-watch-test-configmap-a,UID:ebb89a30-75b0-11e9-b786-da20024d205c,ResourceVersion:35482,Generation:0,CreationTimestamp:2019-05-13 18:57:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 13 18:57:44.292: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-9mnwf,SelfLink:/api/v1/namespaces/e2e-tests-watch-9mnwf/configmaps/e2e-watch-test-configmap-a,UID:ebb89a30-75b0-11e9-b786-da20024d205c,ResourceVersion:35482,Generation:0,CreationTimestamp:2019-05-13 18:57:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
May 13 18:57:54.320: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-9mnwf,SelfLink:/api/v1/namespaces/e2e-tests-watch-9mnwf/configmaps/e2e-watch-test-configmap-b,UID:03b0d925-75b1-11e9-b786-da20024d205c,ResourceVersion:35535,Generation:0,CreationTimestamp:2019-05-13 18:57:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 13 18:57:54.320: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-9mnwf,SelfLink:/api/v1/namespaces/e2e-tests-watch-9mnwf/configmaps/e2e-watch-test-configmap-b,UID:03b0d925-75b1-11e9-b786-da20024d205c,ResourceVersion:35535,Generation:0,CreationTimestamp:2019-05-13 18:57:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
May 13 18:58:04.350: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-9mnwf,SelfLink:/api/v1/namespaces/e2e-tests-watch-9mnwf/configmaps/e2e-watch-test-configmap-b,UID:03b0d925-75b1-11e9-b786-da20024d205c,ResourceVersion:35552,Generation:0,CreationTimestamp:2019-05-13 18:57:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 13 18:58:04.350: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-9mnwf,SelfLink:/api/v1/namespaces/e2e-tests-watch-9mnwf/configmaps/e2e-watch-test-configmap-b,UID:03b0d925-75b1-11e9-b786-da20024d205c,ResourceVersion:35552,Generation:0,CreationTimestamp:2019-05-13 18:57:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 18:58:14.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-9mnwf" for this suite.
May 13 18:58:20.400: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:58:20.710: INFO: namespace: e2e-tests-watch-9mnwf, resource: bindings, ignored listing per whitelist
May 13 18:58:20.754: INFO: namespace e2e-tests-watch-9mnwf deletion completed in 6.382440495s

• [SLOW TEST:66.969 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 18:58:20.756: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-cthmt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
May 13 18:58:21.562: INFO: Waiting up to 5m0s for pod "pod-service-account-13ecad26-75b1-11e9-8f67-2632f168be36-x46qz" in namespace "e2e-tests-svcaccounts-cthmt" to be "success or failure"
May 13 18:58:21.570: INFO: Pod "pod-service-account-13ecad26-75b1-11e9-8f67-2632f168be36-x46qz": Phase="Pending", Reason="", readiness=false. Elapsed: 8.052351ms
May 13 18:58:23.578: INFO: Pod "pod-service-account-13ecad26-75b1-11e9-8f67-2632f168be36-x46qz": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01599754s
May 13 18:58:25.620: INFO: Pod "pod-service-account-13ecad26-75b1-11e9-8f67-2632f168be36-x46qz": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.057318835s
STEP: Saw pod success
May 13 18:58:25.620: INFO: Pod "pod-service-account-13ecad26-75b1-11e9-8f67-2632f168be36-x46qz" satisfied condition "success or failure"
May 13 18:58:25.628: INFO: Trying to get logs from node 10.170.219.153 pod pod-service-account-13ecad26-75b1-11e9-8f67-2632f168be36-x46qz container token-test: <nil>
STEP: delete the pod
May 13 18:58:25.668: INFO: Waiting for pod pod-service-account-13ecad26-75b1-11e9-8f67-2632f168be36-x46qz to disappear
May 13 18:58:25.675: INFO: Pod pod-service-account-13ecad26-75b1-11e9-8f67-2632f168be36-x46qz no longer exists
STEP: Creating a pod to test consume service account root CA
May 13 18:58:25.684: INFO: Waiting up to 5m0s for pod "pod-service-account-13ecad26-75b1-11e9-8f67-2632f168be36-th6ck" in namespace "e2e-tests-svcaccounts-cthmt" to be "success or failure"
May 13 18:58:25.692: INFO: Pod "pod-service-account-13ecad26-75b1-11e9-8f67-2632f168be36-th6ck": Phase="Pending", Reason="", readiness=false. Elapsed: 8.179352ms
May 13 18:58:27.701: INFO: Pod "pod-service-account-13ecad26-75b1-11e9-8f67-2632f168be36-th6ck": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016547039s
May 13 18:58:29.709: INFO: Pod "pod-service-account-13ecad26-75b1-11e9-8f67-2632f168be36-th6ck": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025384567s
STEP: Saw pod success
May 13 18:58:29.709: INFO: Pod "pod-service-account-13ecad26-75b1-11e9-8f67-2632f168be36-th6ck" satisfied condition "success or failure"
May 13 18:58:29.717: INFO: Trying to get logs from node 10.170.219.153 pod pod-service-account-13ecad26-75b1-11e9-8f67-2632f168be36-th6ck container root-ca-test: <nil>
STEP: delete the pod
May 13 18:58:29.760: INFO: Waiting for pod pod-service-account-13ecad26-75b1-11e9-8f67-2632f168be36-th6ck to disappear
May 13 18:58:29.768: INFO: Pod pod-service-account-13ecad26-75b1-11e9-8f67-2632f168be36-th6ck no longer exists
STEP: Creating a pod to test consume service account namespace
May 13 18:58:29.820: INFO: Waiting up to 5m0s for pod "pod-service-account-13ecad26-75b1-11e9-8f67-2632f168be36-x6797" in namespace "e2e-tests-svcaccounts-cthmt" to be "success or failure"
May 13 18:58:29.831: INFO: Pod "pod-service-account-13ecad26-75b1-11e9-8f67-2632f168be36-x6797": Phase="Pending", Reason="", readiness=false. Elapsed: 11.699904ms
May 13 18:58:31.839: INFO: Pod "pod-service-account-13ecad26-75b1-11e9-8f67-2632f168be36-x6797": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01969841s
May 13 18:58:33.848: INFO: Pod "pod-service-account-13ecad26-75b1-11e9-8f67-2632f168be36-x6797": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0280618s
STEP: Saw pod success
May 13 18:58:33.848: INFO: Pod "pod-service-account-13ecad26-75b1-11e9-8f67-2632f168be36-x6797" satisfied condition "success or failure"
May 13 18:58:33.856: INFO: Trying to get logs from node 10.170.219.153 pod pod-service-account-13ecad26-75b1-11e9-8f67-2632f168be36-x6797 container namespace-test: <nil>
STEP: delete the pod
May 13 18:58:33.896: INFO: Waiting for pod pod-service-account-13ecad26-75b1-11e9-8f67-2632f168be36-x6797 to disappear
May 13 18:58:33.903: INFO: Pod pod-service-account-13ecad26-75b1-11e9-8f67-2632f168be36-x6797 no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 18:58:33.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-cthmt" for this suite.
May 13 18:58:39.939: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:58:40.211: INFO: namespace: e2e-tests-svcaccounts-cthmt, resource: bindings, ignored listing per whitelist
May 13 18:58:40.264: INFO: namespace e2e-tests-svcaccounts-cthmt deletion completed in 6.3540025s

• [SLOW TEST:19.509 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 18:58:40.265: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-z79gb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
May 13 18:58:44.648: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 13 18:58:44.655: INFO: Pod pod-with-poststart-exec-hook still exists
May 13 18:58:46.655: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 13 18:58:46.676: INFO: Pod pod-with-poststart-exec-hook still exists
May 13 18:58:48.655: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 13 18:58:48.663: INFO: Pod pod-with-poststart-exec-hook still exists
May 13 18:58:50.655: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 13 18:58:50.664: INFO: Pod pod-with-poststart-exec-hook still exists
May 13 18:58:52.655: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 13 18:58:52.663: INFO: Pod pod-with-poststart-exec-hook still exists
May 13 18:58:54.655: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 13 18:58:54.663: INFO: Pod pod-with-poststart-exec-hook still exists
May 13 18:58:56.655: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 13 18:58:56.663: INFO: Pod pod-with-poststart-exec-hook still exists
May 13 18:58:58.655: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 13 18:58:58.675: INFO: Pod pod-with-poststart-exec-hook still exists
May 13 18:59:00.655: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 13 18:59:00.663: INFO: Pod pod-with-poststart-exec-hook still exists
May 13 18:59:02.655: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 13 18:59:02.663: INFO: Pod pod-with-poststart-exec-hook still exists
May 13 18:59:04.655: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 13 18:59:04.664: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 18:59:04.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-z79gb" for this suite.
May 13 18:59:28.702: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:59:28.783: INFO: namespace: e2e-tests-container-lifecycle-hook-z79gb, resource: bindings, ignored listing per whitelist
May 13 18:59:28.967: INFO: namespace e2e-tests-container-lifecycle-hook-z79gb deletion completed in 24.295316995s

• [SLOW TEST:48.703 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 18:59:28.968: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-9nsft
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 13 18:59:29.280: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
May 13 18:59:29.294: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-9nsft/daemonsets","resourceVersion":"35878"},"items":null}

May 13 18:59:29.301: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-9nsft/pods","resourceVersion":"35878"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 18:59:29.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-9nsft" for this suite.
May 13 18:59:35.357: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:59:35.494: INFO: namespace: e2e-tests-daemonsets-9nsft, resource: bindings, ignored listing per whitelist
May 13 18:59:35.596: INFO: namespace e2e-tests-daemonsets-9nsft deletion completed in 6.26603023s

S [SKIPPING] [6.628 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  May 13 18:59:29.280: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 18:59:35.597: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-kh9ms
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1527
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
May 13 18:59:35.862: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-kh9ms'
May 13 18:59:36.382: INFO: stderr: ""
May 13 18:59:36.382: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1532
May 13 18:59:37.118: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-kh9ms'
May 13 18:59:39.658: INFO: stderr: ""
May 13 18:59:39.658: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 18:59:39.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-kh9ms" for this suite.
May 13 18:59:45.752: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 18:59:45.970: INFO: namespace: e2e-tests-kubectl-kh9ms, resource: bindings, ignored listing per whitelist
May 13 18:59:46.118: INFO: namespace e2e-tests-kubectl-kh9ms deletion completed in 6.452230691s

• [SLOW TEST:10.521 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 18:59:46.118: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-m8p6l
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-46819088-75b1-11e9-8f67-2632f168be36
STEP: Creating configMap with name cm-test-opt-upd-468190d9-75b1-11e9-8f67-2632f168be36
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-46819088-75b1-11e9-8f67-2632f168be36
STEP: Updating configmap cm-test-opt-upd-468190d9-75b1-11e9-8f67-2632f168be36
STEP: Creating configMap with name cm-test-opt-create-468190fa-75b1-11e9-8f67-2632f168be36
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 18:59:50.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-m8p6l" for this suite.
May 13 19:00:14.723: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:00:15.049: INFO: namespace: e2e-tests-configmap-m8p6l, resource: bindings, ignored listing per whitelist
May 13 19:00:15.091: INFO: namespace e2e-tests-configmap-m8p6l deletion completed in 24.396274324s

• [SLOW TEST:28.973 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:00:15.091: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-7xf6f
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-57c65024-75b1-11e9-8f67-2632f168be36
STEP: Creating configMap with name cm-test-opt-upd-57c65073-75b1-11e9-8f67-2632f168be36
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-57c65024-75b1-11e9-8f67-2632f168be36
STEP: Updating configmap cm-test-opt-upd-57c65073-75b1-11e9-8f67-2632f168be36
STEP: Creating configMap with name cm-test-opt-create-57c65093-75b1-11e9-8f67-2632f168be36
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:00:19.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7xf6f" for this suite.
May 13 19:00:43.651: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:00:44.271: INFO: namespace: e2e-tests-projected-7xf6f, resource: bindings, ignored listing per whitelist
May 13 19:00:44.315: INFO: namespace e2e-tests-projected-7xf6f deletion completed in 24.693817256s

• [SLOW TEST:29.224 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:00:44.316: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-fspp7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
May 13 19:00:44.739: INFO: Waiting up to 5m0s for pod "pod-6943f5ce-75b1-11e9-8f67-2632f168be36" in namespace "e2e-tests-emptydir-fspp7" to be "success or failure"
May 13 19:00:44.748: INFO: Pod "pod-6943f5ce-75b1-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 9.671139ms
May 13 19:00:46.846: INFO: Pod "pod-6943f5ce-75b1-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.107523554s
STEP: Saw pod success
May 13 19:00:46.846: INFO: Pod "pod-6943f5ce-75b1-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 19:00:46.854: INFO: Trying to get logs from node 10.170.219.153 pod pod-6943f5ce-75b1-11e9-8f67-2632f168be36 container test-container: <nil>
STEP: delete the pod
May 13 19:00:46.892: INFO: Waiting for pod pod-6943f5ce-75b1-11e9-8f67-2632f168be36 to disappear
May 13 19:00:46.900: INFO: Pod pod-6943f5ce-75b1-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:00:46.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-fspp7" for this suite.
May 13 19:00:52.935: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:00:53.053: INFO: namespace: e2e-tests-emptydir-fspp7, resource: bindings, ignored listing per whitelist
May 13 19:00:53.227: INFO: namespace e2e-tests-emptydir-fspp7 deletion completed in 6.319583629s

• [SLOW TEST:8.912 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:00:53.227: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-wfjxh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
May 13 19:00:53.512: INFO: Waiting up to 5m0s for pod "var-expansion-6e7e90d4-75b1-11e9-8f67-2632f168be36" in namespace "e2e-tests-var-expansion-wfjxh" to be "success or failure"
May 13 19:00:53.523: INFO: Pod "var-expansion-6e7e90d4-75b1-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 10.519895ms
May 13 19:00:55.531: INFO: Pod "var-expansion-6e7e90d4-75b1-11e9-8f67-2632f168be36": Phase="Running", Reason="", readiness=true. Elapsed: 2.018798931s
May 13 19:00:57.539: INFO: Pod "var-expansion-6e7e90d4-75b1-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027058218s
STEP: Saw pod success
May 13 19:00:57.539: INFO: Pod "var-expansion-6e7e90d4-75b1-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 19:00:57.547: INFO: Trying to get logs from node 10.170.219.177 pod var-expansion-6e7e90d4-75b1-11e9-8f67-2632f168be36 container dapi-container: <nil>
STEP: delete the pod
May 13 19:00:57.644: INFO: Waiting for pod var-expansion-6e7e90d4-75b1-11e9-8f67-2632f168be36 to disappear
May 13 19:00:57.651: INFO: Pod var-expansion-6e7e90d4-75b1-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:00:57.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-wfjxh" for this suite.
May 13 19:01:03.687: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:01:04.060: INFO: namespace: e2e-tests-var-expansion-wfjxh, resource: bindings, ignored listing per whitelist
May 13 19:01:04.128: INFO: namespace e2e-tests-var-expansion-wfjxh deletion completed in 6.468175173s

• [SLOW TEST:10.900 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:01:04.128: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-dpvrq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 13 19:01:04.423: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 version --client'
May 13 19:01:04.476: INFO: stderr: ""
May 13 19:01:04.476: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
May 13 19:01:04.489: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 create -f - --namespace=e2e-tests-kubectl-dpvrq'
May 13 19:01:04.757: INFO: stderr: ""
May 13 19:01:04.757: INFO: stdout: "replicationcontroller/redis-master created\n"
May 13 19:01:04.757: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 create -f - --namespace=e2e-tests-kubectl-dpvrq'
May 13 19:01:04.956: INFO: stderr: ""
May 13 19:01:04.956: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
May 13 19:01:05.965: INFO: Selector matched 1 pods for map[app:redis]
May 13 19:01:05.965: INFO: Found 0 / 1
May 13 19:01:06.964: INFO: Selector matched 1 pods for map[app:redis]
May 13 19:01:06.964: INFO: Found 1 / 1
May 13 19:01:06.964: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May 13 19:01:06.972: INFO: Selector matched 1 pods for map[app:redis]
May 13 19:01:06.972: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May 13 19:01:06.972: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 describe pod redis-master-fbwpx --namespace=e2e-tests-kubectl-dpvrq'
May 13 19:01:07.088: INFO: stderr: ""
May 13 19:01:07.088: INFO: stdout: "Name:               redis-master-fbwpx\nNamespace:          e2e-tests-kubectl-dpvrq\nPriority:           0\nPriorityClassName:  <none>\nNode:               10.170.219.153/10.170.219.153\nStart Time:         Mon, 13 May 2019 19:01:04 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        kubernetes.io/psp: e2e-test-privileged-psp\nStatus:             Running\nIP:                 172.30.63.15\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   containerd://db8fb328abbc78c670154d0984428fe0bbd188ad2379e5cd29ec52a54899712c\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 13 May 2019 19:01:05 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-x54mw (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-x54mw:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-x54mw\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                     Message\n  ----    ------     ----  ----                     -------\n  Normal  Scheduled  3s    default-scheduler        Successfully assigned e2e-tests-kubectl-dpvrq/redis-master-fbwpx to 10.170.219.153\n  Normal  Pulled     2s    kubelet, 10.170.219.153  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    2s    kubelet, 10.170.219.153  Created container\n  Normal  Started    2s    kubelet, 10.170.219.153  Started container\n"
May 13 19:01:07.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 describe rc redis-master --namespace=e2e-tests-kubectl-dpvrq'
May 13 19:01:07.331: INFO: stderr: ""
May 13 19:01:07.331: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-dpvrq\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-fbwpx\n"
May 13 19:01:07.331: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 describe service redis-master --namespace=e2e-tests-kubectl-dpvrq'
May 13 19:01:07.469: INFO: stderr: ""
May 13 19:01:07.469: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-dpvrq\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                172.21.170.97\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         172.30.63.15:6379\nSession Affinity:  None\nEvents:            <none>\n"
May 13 19:01:07.477: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 describe node 10.170.219.151'
May 13 19:01:07.623: INFO: stderr: ""
May 13 19:01:07.623: INFO: stdout: "Name:               10.170.219.151\nRoles:              <none>\nLabels:             arch=amd64\n                    beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=b3c.4x16.encrypted\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=us-east\n                    failure-domain.beta.kubernetes.io/zone=wdc04\n                    ibm-cloud.kubernetes.io/encrypted-docker-data=true\n                    ibm-cloud.kubernetes.io/ha-worker=true\n                    ibm-cloud.kubernetes.io/iaas-provider=softlayer\n                    ibm-cloud.kubernetes.io/machine-type=b3c.4x16.encrypted\n                    ibm-cloud.kubernetes.io/os=UBUNTU_18_64\n                    ibm-cloud.kubernetes.io/sgx-enabled=false\n                    ibm-cloud.kubernetes.io/worker-pool-id=0ef1a5f1e33c44fe9c21650356d908ee-715ddc0\n                    ibm-cloud.kubernetes.io/worker-version=1.13.6_1521\n                    kubernetes.io/hostname=10.170.219.151\n                    privateVLAN=2615309\n                    publicVLAN=2615307\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 13 May 2019 16:27:05 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Mon, 13 May 2019 19:01:04 +0000   Mon, 13 May 2019 16:27:05 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Mon, 13 May 2019 19:01:04 +0000   Mon, 13 May 2019 16:27:05 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Mon, 13 May 2019 19:01:04 +0000   Mon, 13 May 2019 16:27:05 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Mon, 13 May 2019 19:01:04 +0000   Mon, 13 May 2019 16:27:35 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.170.219.151\n  ExternalIP:  169.45.211.115\n  Hostname:    10.170.219.151\nCapacity:\n cpu:                4\n ephemeral-storage:  102685624Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             16419940Ki\n pods:               110\nAllocatable:\n cpu:                3910m\n ephemeral-storage:  99892574949\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             13627492Ki\n pods:               110\nSystem Info:\n Machine ID:                 b0d23c58eb874ec6b60fb1f5475b76c1\n System UUID:                8268FCE2-3882-6830-B330-6142D9A697FA\n Boot ID:                    62457096-92c8-4668-8281-cd86fd53efd3\n Kernel Version:             4.15.0-47-generic\n OS Image:                   Ubuntu 18.04.2 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  containerd://1.2.6\n Kubelet Version:            v1.13.6+IKS\n Kube-Proxy Version:         v1.13.6+IKS\nProviderID:                  ibm://d18c889395112a40d2f4e3065f237a7d///0ef1a5f1e33c44fe9c21650356d908ee/kube-wdc04-cr0ef1a5f1e33c44fe9c21650356d908ee-w3\nNon-terminated Pods:         (14 in total)\n  Namespace                  Name                                                              CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                              ------------  ----------  ---------------  -------------  ---\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-8e5ce9bdf4a94ece-nlv42           0 (0%)        0 (0%)      0 (0%)           0 (0%)         20m\n  kube-system                calico-kube-controllers-7dd978d898-r8w74                          10m (0%)      0 (0%)      25Mi (0%)        0 (0%)         162m\n  kube-system                calico-node-d9d6s                                                 250m (6%)     0 (0%)      80Mi (0%)        0 (0%)         154m\n  kube-system                coredns-58d696879-rrkth                                           100m (2%)     0 (0%)      70Mi (0%)        400Mi (3%)     161m\n  kube-system                coredns-58d696879-zmj2g                                           100m (2%)     0 (0%)      70Mi (0%)        400Mi (3%)     153m\n  kube-system                coredns-autoscaler-64f9c5b4df-hzq57                               20m (0%)      0 (0%)      10Mi (0%)        0 (0%)         161m\n  kube-system                ibm-file-plugin-7f6d8979bd-p5smn                                  50m (1%)      200m (5%)   100Mi (0%)       0 (0%)         160m\n  kube-system                ibm-keepalived-watcher-8wshf                                      5m (0%)       0 (0%)      10Mi (0%)        0 (0%)         154m\n  kube-system                ibm-kube-fluentd-6fw9c                                            25m (0%)      300m (7%)   150Mi (1%)       1600M (11%)    148m\n  kube-system                ibm-master-proxy-static-10.170.219.151                            25m (0%)      300m (7%)   32M (0%)         512M (3%)      152m\n  kube-system                ibm-storage-watcher-845946d5b5-knxcm                              50m (1%)      200m (5%)   100Mi (0%)       0 (0%)         160m\n  kube-system                kubernetes-dashboard-7996b848f4-mzbwj                             50m (1%)      0 (0%)      100Mi (0%)       0 (0%)         157m\n  kube-system                public-cr0ef1a5f1e33c44fe9c21650356d908ee-alb1-8f59cf484-9v5pm    0 (0%)        0 (0%)      0 (0%)           0 (0%)         146m\n  kube-system                vpn-774cf5c6d4-6p6cr                                              5m (0%)       0 (0%)      5Mi (0%)         0 (0%)         157m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests       Limits\n  --------           --------       ------\n  cpu                690m (17%)     1 (25%)\n  memory             768530Ki (5%)  2881700Ki (21%)\n  ephemeral-storage  0 (0%)         0 (0%)\nEvents:              <none>\n"
May 13 19:01:07.623: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 describe namespace e2e-tests-kubectl-dpvrq'
May 13 19:01:07.821: INFO: stderr: ""
May 13 19:01:07.821: INFO: stdout: "Name:         e2e-tests-kubectl-dpvrq\nLabels:       e2e-framework=kubectl\n              e2e-run=ad7e8b22-75ae-11e9-8f67-2632f168be36\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:01:07.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-dpvrq" for this suite.
May 13 19:01:31.858: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:01:32.046: INFO: namespace: e2e-tests-kubectl-dpvrq, resource: bindings, ignored listing per whitelist
May 13 19:01:32.249: INFO: namespace e2e-tests-kubectl-dpvrq deletion completed in 24.419041714s

• [SLOW TEST:28.121 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:01:32.250: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replicaset-vvtcp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
May 13 19:01:36.329: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:01:36.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-vvtcp" for this suite.
May 13 19:02:00.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:02:00.555: INFO: namespace: e2e-tests-replicaset-vvtcp, resource: bindings, ignored listing per whitelist
May 13 19:02:00.710: INFO: namespace e2e-tests-replicaset-vvtcp deletion completed in 24.26539389s

• [SLOW TEST:28.460 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:02:00.711: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-2fcc2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 13 19:02:01.161: INFO: Pod name rollover-pod: Found 0 pods out of 1
May 13 19:02:06.182: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
May 13 19:02:06.182: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
May 13 19:02:08.191: INFO: Creating deployment "test-rollover-deployment"
May 13 19:02:08.203: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
May 13 19:02:10.214: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
May 13 19:02:10.227: INFO: Ensure that both replica sets have 1 created replica
May 13 19:02:10.242: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
May 13 19:02:10.254: INFO: Updating deployment test-rollover-deployment
May 13 19:02:10.254: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
May 13 19:02:12.265: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
May 13 19:02:12.281: INFO: Make sure deployment "test-rollover-deployment" is complete
May 13 19:02:12.294: INFO: all replica sets need to contain the pod-template-hash label
May 13 19:02:12.294: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693370928, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693370928, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693370930, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693370928, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 13 19:02:14.308: INFO: all replica sets need to contain the pod-template-hash label
May 13 19:02:14.308: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693370928, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693370928, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693370933, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693370928, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 13 19:02:16.324: INFO: all replica sets need to contain the pod-template-hash label
May 13 19:02:16.324: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693370928, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693370928, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693370933, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693370928, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 13 19:02:18.308: INFO: all replica sets need to contain the pod-template-hash label
May 13 19:02:18.308: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693370928, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693370928, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693370933, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693370928, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 13 19:02:20.308: INFO: all replica sets need to contain the pod-template-hash label
May 13 19:02:20.308: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693370928, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693370928, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693370933, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693370928, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 13 19:02:22.308: INFO: all replica sets need to contain the pod-template-hash label
May 13 19:02:22.309: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693370928, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693370928, loc:(*time.Location)(0x7b33b80)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63693370933, loc:(*time.Location)(0x7b33b80)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693370928, loc:(*time.Location)(0x7b33b80)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6b7f9d6597\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 13 19:02:24.333: INFO: 
May 13 19:02:24.333: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May 13 19:02:24.356: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-2fcc2,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-2fcc2/deployments/test-rollover-deployment,UID:9b0497b7-75b1-11e9-b786-da20024d205c,ResourceVersion:36591,Generation:2,CreationTimestamp:2019-05-13 19:02:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-05-13 19:02:08 +0000 UTC 2019-05-13 19:02:08 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-05-13 19:02:23 +0000 UTC 2019-05-13 19:02:08 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-6b7f9d6597" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

May 13 19:02:24.364: INFO: New ReplicaSet "test-rollover-deployment-6b7f9d6597" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597,GenerateName:,Namespace:e2e-tests-deployment-2fcc2,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-2fcc2/replicasets/test-rollover-deployment-6b7f9d6597,UID:9c3f96c7-75b1-11e9-83a8-7e0242378207,ResourceVersion:36582,Generation:2,CreationTimestamp:2019-05-13 19:02:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 9b0497b7-75b1-11e9-b786-da20024d205c 0xc000b999b7 0xc000b999b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
May 13 19:02:24.364: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
May 13 19:02:24.364: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-2fcc2,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-2fcc2/replicasets/test-rollover-controller,UID:96d15d8f-75b1-11e9-b786-da20024d205c,ResourceVersion:36590,Generation:2,CreationTimestamp:2019-05-13 19:02:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 9b0497b7-75b1-11e9-b786-da20024d205c 0xc000b99827 0xc000b99828}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 13 19:02:24.364: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6586df867b,GenerateName:,Namespace:e2e-tests-deployment-2fcc2,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-2fcc2/replicasets/test-rollover-deployment-6586df867b,UID:9b09b286-75b1-11e9-83a8-7e0242378207,ResourceVersion:36543,Generation:2,CreationTimestamp:2019-05-13 19:02:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 9b0497b7-75b1-11e9-b786-da20024d205c 0xc000b998e7 0xc000b998e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6586df867b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 13 19:02:24.372: INFO: Pod "test-rollover-deployment-6b7f9d6597-csk2h" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6b7f9d6597-csk2h,GenerateName:test-rollover-deployment-6b7f9d6597-,Namespace:e2e-tests-deployment-2fcc2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2fcc2/pods/test-rollover-deployment-6b7f9d6597-csk2h,UID:9c46fce4-75b1-11e9-83a8-7e0242378207,ResourceVersion:36563,Generation:0,CreationTimestamp:2019-05-13 19:02:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6b7f9d6597,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-6b7f9d6597 9c3f96c7-75b1-11e9-83a8-7e0242378207 0xc0013d0b77 0xc0013d0b78}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-zd9mx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-zd9mx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-zd9mx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.177,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0013d0c00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0013d0c20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:02:10 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:02:12 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:02:12 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:02:10 +0000 UTC  }],Message:,Reason:,HostIP:10.170.219.177,PodIP:172.30.227.110,StartTime:2019-05-13 19:02:10 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-05-13 19:02:12 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://0a4cd6e65077caab9430c6d8d7b75bdc3c155772e4bad9accb30615766b6ff81}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:02:24.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-2fcc2" for this suite.
May 13 19:02:30.409: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:02:30.486: INFO: namespace: e2e-tests-deployment-2fcc2, resource: bindings, ignored listing per whitelist
May 13 19:02:30.645: INFO: namespace e2e-tests-deployment-2fcc2 deletion completed in 6.264249525s

• [SLOW TEST:29.933 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:02:30.645: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-wrapper-l22w6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
May 13 19:02:31.395: INFO: Pod name wrapped-volume-race-a8d4d8a6-75b1-11e9-8f67-2632f168be36: Found 0 pods out of 5
May 13 19:02:36.409: INFO: Pod name wrapped-volume-race-a8d4d8a6-75b1-11e9-8f67-2632f168be36: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-a8d4d8a6-75b1-11e9-8f67-2632f168be36 in namespace e2e-tests-emptydir-wrapper-l22w6, will wait for the garbage collector to delete the pods
May 13 19:05:31.416: INFO: Deleting ReplicationController wrapped-volume-race-a8d4d8a6-75b1-11e9-8f67-2632f168be36 took: 19.638259ms
May 13 19:05:31.516: INFO: Terminating ReplicationController wrapped-volume-race-a8d4d8a6-75b1-11e9-8f67-2632f168be36 pods took: 100.210253ms
STEP: Creating RC which spawns configmap-volume pods
May 13 19:06:14.961: INFO: Pod name wrapped-volume-race-2e137194-75b2-11e9-8f67-2632f168be36: Found 0 pods out of 5
May 13 19:06:19.975: INFO: Pod name wrapped-volume-race-2e137194-75b2-11e9-8f67-2632f168be36: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-2e137194-75b2-11e9-8f67-2632f168be36 in namespace e2e-tests-emptydir-wrapper-l22w6, will wait for the garbage collector to delete the pods
May 13 19:08:12.112: INFO: Deleting ReplicationController wrapped-volume-race-2e137194-75b2-11e9-8f67-2632f168be36 took: 21.487831ms
May 13 19:08:12.213: INFO: Terminating ReplicationController wrapped-volume-race-2e137194-75b2-11e9-8f67-2632f168be36 pods took: 100.243481ms
STEP: Creating RC which spawns configmap-volume pods
May 13 19:08:53.056: INFO: Pod name wrapped-volume-race-8c4f1ce3-75b2-11e9-8f67-2632f168be36: Found 0 pods out of 5
May 13 19:08:58.071: INFO: Pod name wrapped-volume-race-8c4f1ce3-75b2-11e9-8f67-2632f168be36: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-8c4f1ce3-75b2-11e9-8f67-2632f168be36 in namespace e2e-tests-emptydir-wrapper-l22w6, will wait for the garbage collector to delete the pods
May 13 19:10:50.258: INFO: Deleting ReplicationController wrapped-volume-race-8c4f1ce3-75b2-11e9-8f67-2632f168be36 took: 20.516259ms
May 13 19:10:50.358: INFO: Terminating ReplicationController wrapped-volume-race-8c4f1ce3-75b2-11e9-8f67-2632f168be36 pods took: 100.193356ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:11:33.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wrapper-l22w6" for this suite.
May 13 19:11:40.586: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:11:40.829: INFO: namespace: e2e-tests-emptydir-wrapper-l22w6, resource: bindings, ignored listing per whitelist
May 13 19:11:40.842: INFO: namespace e2e-tests-emptydir-wrapper-l22w6 deletion completed in 7.056672976s

• [SLOW TEST:550.197 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Slow] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:11:40.843: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-nc6vk
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-fgbbn in namespace e2e-tests-proxy-nc6vk
I0513 19:11:41.145462      16 runners.go:184] Created replication controller with name: proxy-service-fgbbn, namespace: e2e-tests-proxy-nc6vk, replica count: 1
I0513 19:11:42.195792      16 runners.go:184] proxy-service-fgbbn Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0513 19:11:43.196066      16 runners.go:184] proxy-service-fgbbn Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0513 19:11:44.196329      16 runners.go:184] proxy-service-fgbbn Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0513 19:11:45.196582      16 runners.go:184] proxy-service-fgbbn Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0513 19:11:46.196834      16 runners.go:184] proxy-service-fgbbn Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0513 19:11:47.197103      16 runners.go:184] proxy-service-fgbbn Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0513 19:11:48.197405      16 runners.go:184] proxy-service-fgbbn Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0513 19:11:49.197993      16 runners.go:184] proxy-service-fgbbn Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0513 19:11:50.198314      16 runners.go:184] proxy-service-fgbbn Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0513 19:11:51.198708      16 runners.go:184] proxy-service-fgbbn Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0513 19:11:52.199001      16 runners.go:184] proxy-service-fgbbn Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0513 19:11:53.199229      16 runners.go:184] proxy-service-fgbbn Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May 13 19:11:53.221: INFO: setup took 12.106728088s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
May 13 19:11:53.320: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:1080/proxy/... (200; 97.873634ms)
May 13 19:11:53.320: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:160/proxy/: foo (200; 97.87868ms)
May 13 19:11:53.320: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/http:proxy-service-fgbbn:portname1/proxy/: foo (200; 98.134365ms)
May 13 19:11:53.320: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:162/proxy/: bar (200; 97.903852ms)
May 13 19:11:53.320: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv/proxy/rewriteme"... (200; 97.916355ms)
May 13 19:11:53.320: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:162/proxy/: bar (200; 98.176996ms)
May 13 19:11:53.320: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/https:proxy-service-fgbbn:tlsportname2/proxy/: tls qux (200; 98.159538ms)
May 13 19:11:53.320: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:160/proxy/: foo (200; 98.00096ms)
May 13 19:11:53.320: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:1080/proxy/rewri... (200; 98.122141ms)
May 13 19:11:53.320: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/proxy-service-fgbbn:portname1/proxy/: foo (200; 97.902955ms)
May 13 19:11:53.320: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:462/proxy/: tls qux (200; 97.968628ms)
May 13 19:11:53.320: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:460/proxy/: tls baz (200; 97.996986ms)
May 13 19:11:53.320: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/http:proxy-service-fgbbn:portname2/proxy/: bar (200; 98.25449ms)
May 13 19:11:53.320: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/https:proxy-service-fgbbn:tlsportname1/proxy/: tls baz (200; 98.095189ms)
May 13 19:11:53.320: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:443/proxy/... (200; 98.057475ms)
May 13 19:11:53.320: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/proxy-service-fgbbn:portname2/proxy/: bar (200; 97.968671ms)
May 13 19:11:53.332: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:160/proxy/: foo (200; 11.462145ms)
May 13 19:11:53.334: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:162/proxy/: bar (200; 13.469051ms)
May 13 19:11:53.334: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/http:proxy-service-fgbbn:portname1/proxy/: foo (200; 13.577955ms)
May 13 19:11:53.335: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:162/proxy/: bar (200; 14.121121ms)
May 13 19:11:53.335: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:462/proxy/: tls qux (200; 14.256513ms)
May 13 19:11:53.335: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:1080/proxy/... (200; 14.296023ms)
May 13 19:11:53.335: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:460/proxy/: tls baz (200; 14.385644ms)
May 13 19:11:53.335: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:1080/proxy/rewri... (200; 14.378274ms)
May 13 19:11:53.335: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:443/proxy/... (200; 14.547667ms)
May 13 19:11:53.335: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv/proxy/rewriteme"... (200; 14.587611ms)
May 13 19:11:53.335: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:160/proxy/: foo (200; 14.419939ms)
May 13 19:11:53.337: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/http:proxy-service-fgbbn:portname2/proxy/: bar (200; 16.367257ms)
May 13 19:11:53.338: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/proxy-service-fgbbn:portname1/proxy/: foo (200; 17.017905ms)
May 13 19:11:53.338: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/https:proxy-service-fgbbn:tlsportname1/proxy/: tls baz (200; 17.110501ms)
May 13 19:11:53.338: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/proxy-service-fgbbn:portname2/proxy/: bar (200; 17.267664ms)
May 13 19:11:53.338: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/https:proxy-service-fgbbn:tlsportname2/proxy/: tls qux (200; 17.248849ms)
May 13 19:11:53.348: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:162/proxy/: bar (200; 9.952321ms)
May 13 19:11:53.349: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:443/proxy/... (200; 10.526681ms)
May 13 19:11:53.352: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:162/proxy/: bar (200; 13.388787ms)
May 13 19:11:53.353: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:460/proxy/: tls baz (200; 14.406227ms)
May 13 19:11:53.353: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:1080/proxy/... (200; 14.135392ms)
May 13 19:11:53.353: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:160/proxy/: foo (200; 13.597919ms)
May 13 19:11:53.353: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:1080/proxy/rewri... (200; 14.297756ms)
May 13 19:11:53.353: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:462/proxy/: tls qux (200; 14.191813ms)
May 13 19:11:53.353: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv/proxy/rewriteme"... (200; 13.804308ms)
May 13 19:11:53.357: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/proxy-service-fgbbn:portname2/proxy/: bar (200; 18.247288ms)
May 13 19:11:53.357: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/https:proxy-service-fgbbn:tlsportname1/proxy/: tls baz (200; 19.087416ms)
May 13 19:11:53.357: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/https:proxy-service-fgbbn:tlsportname2/proxy/: tls qux (200; 19.041569ms)
May 13 19:11:53.358: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/http:proxy-service-fgbbn:portname1/proxy/: foo (200; 19.362768ms)
May 13 19:11:53.358: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/http:proxy-service-fgbbn:portname2/proxy/: bar (200; 19.812996ms)
May 13 19:11:53.361: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/proxy-service-fgbbn:portname1/proxy/: foo (200; 21.900471ms)
May 13 19:11:53.558: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:160/proxy/: foo (200; 219.55684ms)
May 13 19:11:53.569: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:160/proxy/: foo (200; 10.326455ms)
May 13 19:11:53.571: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:160/proxy/: foo (200; 12.828083ms)
May 13 19:11:53.572: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:1080/proxy/rewri... (200; 13.083492ms)
May 13 19:11:53.572: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:162/proxy/: bar (200; 13.064702ms)
May 13 19:11:53.572: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv/proxy/rewriteme"... (200; 13.32554ms)
May 13 19:11:53.572: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:462/proxy/: tls qux (200; 13.606313ms)
May 13 19:11:53.573: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:443/proxy/... (200; 13.72338ms)
May 13 19:11:53.573: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:460/proxy/: tls baz (200; 14.015909ms)
May 13 19:11:53.573: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:1080/proxy/... (200; 13.865531ms)
May 13 19:11:53.573: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:162/proxy/: bar (200; 14.197133ms)
May 13 19:11:53.574: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/proxy-service-fgbbn:portname2/proxy/: bar (200; 15.835713ms)
May 13 19:11:53.575: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/https:proxy-service-fgbbn:tlsportname1/proxy/: tls baz (200; 15.931482ms)
May 13 19:11:53.575: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/proxy-service-fgbbn:portname1/proxy/: foo (200; 16.015585ms)
May 13 19:11:53.575: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/http:proxy-service-fgbbn:portname1/proxy/: foo (200; 16.01683ms)
May 13 19:11:53.575: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/http:proxy-service-fgbbn:portname2/proxy/: bar (200; 16.176338ms)
May 13 19:11:53.575: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/https:proxy-service-fgbbn:tlsportname2/proxy/: tls qux (200; 16.155438ms)
May 13 19:11:53.585: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:1080/proxy/rewri... (200; 9.442189ms)
May 13 19:11:53.587: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv/proxy/rewriteme"... (200; 11.329714ms)
May 13 19:11:53.588: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:160/proxy/: foo (200; 12.495522ms)
May 13 19:11:53.588: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:160/proxy/: foo (200; 12.838731ms)
May 13 19:11:53.588: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/https:proxy-service-fgbbn:tlsportname1/proxy/: tls baz (200; 13.465091ms)
May 13 19:11:53.589: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:460/proxy/: tls baz (200; 13.162526ms)
May 13 19:11:53.589: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:162/proxy/: bar (200; 12.935185ms)
May 13 19:11:53.589: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:462/proxy/: tls qux (200; 13.075816ms)
May 13 19:11:53.589: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:1080/proxy/... (200; 13.423731ms)
May 13 19:11:53.589: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:443/proxy/... (200; 13.291672ms)
May 13 19:11:53.589: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:162/proxy/: bar (200; 13.404ms)
May 13 19:11:53.590: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/https:proxy-service-fgbbn:tlsportname2/proxy/: tls qux (200; 15.378135ms)
May 13 19:11:53.591: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/http:proxy-service-fgbbn:portname2/proxy/: bar (200; 14.869707ms)
May 13 19:11:53.591: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/proxy-service-fgbbn:portname1/proxy/: foo (200; 16.037436ms)
May 13 19:11:53.591: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/proxy-service-fgbbn:portname2/proxy/: bar (200; 15.287393ms)
May 13 19:11:53.591: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/http:proxy-service-fgbbn:portname1/proxy/: foo (200; 15.570827ms)
May 13 19:11:53.600: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:1080/proxy/rewri... (200; 8.959258ms)
May 13 19:11:53.604: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:460/proxy/: tls baz (200; 12.043623ms)
May 13 19:11:53.604: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:160/proxy/: foo (200; 11.719518ms)
May 13 19:11:53.604: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:162/proxy/: bar (200; 12.352075ms)
May 13 19:11:53.604: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:162/proxy/: bar (200; 12.027087ms)
May 13 19:11:53.604: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv/proxy/rewriteme"... (200; 12.277629ms)
May 13 19:11:53.604: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:160/proxy/: foo (200; 12.551485ms)
May 13 19:11:53.604: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:443/proxy/... (200; 12.815032ms)
May 13 19:11:53.606: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/https:proxy-service-fgbbn:tlsportname1/proxy/: tls baz (200; 14.741613ms)
May 13 19:11:53.606: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:462/proxy/: tls qux (200; 14.22712ms)
May 13 19:11:53.606: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:1080/proxy/... (200; 14.556273ms)
May 13 19:11:53.606: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/https:proxy-service-fgbbn:tlsportname2/proxy/: tls qux (200; 14.976265ms)
May 13 19:11:53.606: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/proxy-service-fgbbn:portname1/proxy/: foo (200; 15.241511ms)
May 13 19:11:53.607: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/http:proxy-service-fgbbn:portname1/proxy/: foo (200; 14.994776ms)
May 13 19:11:53.607: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/proxy-service-fgbbn:portname2/proxy/: bar (200; 14.842737ms)
May 13 19:11:53.607: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/http:proxy-service-fgbbn:portname2/proxy/: bar (200; 14.686368ms)
May 13 19:11:53.616: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:160/proxy/: foo (200; 9.424079ms)
May 13 19:11:53.620: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv/proxy/rewriteme"... (200; 11.864907ms)
May 13 19:11:53.620: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:1080/proxy/... (200; 12.3387ms)
May 13 19:11:53.620: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/proxy-service-fgbbn:portname1/proxy/: foo (200; 12.812562ms)
May 13 19:11:53.620: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:160/proxy/: foo (200; 12.054621ms)
May 13 19:11:53.620: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:162/proxy/: bar (200; 12.188736ms)
May 13 19:11:53.620: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:443/proxy/... (200; 12.566368ms)
May 13 19:11:53.620: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:1080/proxy/rewri... (200; 12.804457ms)
May 13 19:11:53.620: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:462/proxy/: tls qux (200; 12.529558ms)
May 13 19:11:53.620: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:460/proxy/: tls baz (200; 13.221872ms)
May 13 19:11:53.620: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:162/proxy/: bar (200; 12.522784ms)
May 13 19:11:53.622: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/https:proxy-service-fgbbn:tlsportname1/proxy/: tls baz (200; 15.047332ms)
May 13 19:11:53.623: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/http:proxy-service-fgbbn:portname1/proxy/: foo (200; 15.481208ms)
May 13 19:11:53.623: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/http:proxy-service-fgbbn:portname2/proxy/: bar (200; 15.927063ms)
May 13 19:11:53.625: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/https:proxy-service-fgbbn:tlsportname2/proxy/: tls qux (200; 17.917163ms)
May 13 19:11:53.625: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/proxy-service-fgbbn:portname2/proxy/: bar (200; 17.582572ms)
May 13 19:11:53.637: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:162/proxy/: bar (200; 12.086623ms)
May 13 19:11:53.640: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:162/proxy/: bar (200; 14.410353ms)
May 13 19:11:53.640: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:160/proxy/: foo (200; 14.786027ms)
May 13 19:11:53.640: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv/proxy/rewriteme"... (200; 14.733228ms)
May 13 19:11:53.640: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:460/proxy/: tls baz (200; 15.143725ms)
May 13 19:11:53.640: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:160/proxy/: foo (200; 15.020368ms)
May 13 19:11:53.640: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:462/proxy/: tls qux (200; 15.060048ms)
May 13 19:11:53.641: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:1080/proxy/... (200; 15.036282ms)
May 13 19:11:53.641: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:443/proxy/... (200; 15.113852ms)
May 13 19:11:53.641: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:1080/proxy/rewri... (200; 15.110129ms)
May 13 19:11:53.643: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/proxy-service-fgbbn:portname1/proxy/: foo (200; 17.321462ms)
May 13 19:11:53.643: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/http:proxy-service-fgbbn:portname1/proxy/: foo (200; 17.296626ms)
May 13 19:11:53.643: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/https:proxy-service-fgbbn:tlsportname2/proxy/: tls qux (200; 17.419015ms)
May 13 19:11:53.643: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/proxy-service-fgbbn:portname2/proxy/: bar (200; 17.278054ms)
May 13 19:11:53.643: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/http:proxy-service-fgbbn:portname2/proxy/: bar (200; 17.507342ms)
May 13 19:11:53.644: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/https:proxy-service-fgbbn:tlsportname1/proxy/: tls baz (200; 18.639343ms)
May 13 19:11:53.657: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:462/proxy/: tls qux (200; 12.963612ms)
May 13 19:11:53.657: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv/proxy/rewriteme"... (200; 13.129667ms)
May 13 19:11:53.657: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:1080/proxy/rewri... (200; 13.084008ms)
May 13 19:11:53.657: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:160/proxy/: foo (200; 13.144212ms)
May 13 19:11:53.657: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:160/proxy/: foo (200; 12.959361ms)
May 13 19:11:53.657: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:443/proxy/... (200; 12.835921ms)
May 13 19:11:53.657: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:1080/proxy/... (200; 12.900196ms)
May 13 19:11:53.657: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:460/proxy/: tls baz (200; 13.161945ms)
May 13 19:11:53.657: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/http:proxy-service-fgbbn:portname2/proxy/: bar (200; 13.171425ms)
May 13 19:11:53.657: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:162/proxy/: bar (200; 13.109989ms)
May 13 19:11:53.660: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:162/proxy/: bar (200; 15.522463ms)
May 13 19:11:53.661: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/http:proxy-service-fgbbn:portname1/proxy/: foo (200; 17.110372ms)
May 13 19:11:53.661: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/proxy-service-fgbbn:portname2/proxy/: bar (200; 17.187567ms)
May 13 19:11:53.662: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/https:proxy-service-fgbbn:tlsportname1/proxy/: tls baz (200; 17.329557ms)
May 13 19:11:53.662: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/https:proxy-service-fgbbn:tlsportname2/proxy/: tls qux (200; 17.327754ms)
May 13 19:11:53.662: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/proxy-service-fgbbn:portname1/proxy/: foo (200; 17.416553ms)
May 13 19:11:53.672: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:160/proxy/: foo (200; 9.646207ms)
May 13 19:11:53.674: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:162/proxy/: bar (200; 12.194394ms)
May 13 19:11:53.674: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv/proxy/rewriteme"... (200; 12.342824ms)
May 13 19:11:53.674: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:162/proxy/: bar (200; 12.270495ms)
May 13 19:11:53.674: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:160/proxy/: foo (200; 12.484992ms)
May 13 19:11:53.675: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:462/proxy/: tls qux (200; 12.372818ms)
May 13 19:11:53.675: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:1080/proxy/rewri... (200; 12.763585ms)
May 13 19:11:53.675: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:460/proxy/: tls baz (200; 12.623141ms)
May 13 19:11:53.675: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:443/proxy/... (200; 12.673073ms)
May 13 19:11:53.675: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:1080/proxy/... (200; 12.682729ms)
May 13 19:11:53.677: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/proxy-service-fgbbn:portname1/proxy/: foo (200; 14.986018ms)
May 13 19:11:53.677: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/http:proxy-service-fgbbn:portname1/proxy/: foo (200; 15.216378ms)
May 13 19:11:53.677: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/https:proxy-service-fgbbn:tlsportname1/proxy/: tls baz (200; 15.242562ms)
May 13 19:11:53.677: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/proxy-service-fgbbn:portname2/proxy/: bar (200; 15.234711ms)
May 13 19:11:53.677: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/http:proxy-service-fgbbn:portname2/proxy/: bar (200; 15.415815ms)
May 13 19:11:53.678: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/https:proxy-service-fgbbn:tlsportname2/proxy/: tls qux (200; 15.532616ms)
May 13 19:11:53.688: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:462/proxy/: tls qux (200; 10.396827ms)
May 13 19:11:53.691: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:160/proxy/: foo (200; 13.05568ms)
May 13 19:11:53.691: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:443/proxy/... (200; 13.159205ms)
May 13 19:11:53.691: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv/proxy/rewriteme"... (200; 13.272947ms)
May 13 19:11:53.691: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:162/proxy/: bar (200; 13.76168ms)
May 13 19:11:53.691: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:160/proxy/: foo (200; 13.759136ms)
May 13 19:11:53.692: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:162/proxy/: bar (200; 13.858537ms)
May 13 19:11:53.692: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/https:proxy-service-fgbbn:tlsportname1/proxy/: tls baz (200; 13.840395ms)
May 13 19:11:53.692: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:1080/proxy/... (200; 13.851098ms)
May 13 19:11:53.692: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:1080/proxy/rewri... (200; 13.853502ms)
May 13 19:11:53.692: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:460/proxy/: tls baz (200; 14.199808ms)
May 13 19:11:53.694: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/http:proxy-service-fgbbn:portname2/proxy/: bar (200; 16.256831ms)
May 13 19:11:53.694: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/proxy-service-fgbbn:portname1/proxy/: foo (200; 16.108329ms)
May 13 19:11:53.694: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/https:proxy-service-fgbbn:tlsportname2/proxy/: tls qux (200; 16.386655ms)
May 13 19:11:53.694: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/proxy-service-fgbbn:portname2/proxy/: bar (200; 16.316516ms)
May 13 19:11:53.694: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/http:proxy-service-fgbbn:portname1/proxy/: foo (200; 16.492292ms)
May 13 19:11:53.704: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv/proxy/rewriteme"... (200; 9.765995ms)
May 13 19:11:53.706: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:162/proxy/: bar (200; 11.830696ms)
May 13 19:11:53.707: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:160/proxy/: foo (200; 12.189916ms)
May 13 19:11:53.707: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:1080/proxy/rewri... (200; 12.182184ms)
May 13 19:11:53.707: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:160/proxy/: foo (200; 12.347509ms)
May 13 19:11:53.707: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:1080/proxy/... (200; 12.361136ms)
May 13 19:11:53.707: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:162/proxy/: bar (200; 12.384861ms)
May 13 19:11:53.707: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:460/proxy/: tls baz (200; 12.63238ms)
May 13 19:11:53.708: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:462/proxy/: tls qux (200; 12.956057ms)
May 13 19:11:53.708: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:443/proxy/... (200; 13.201358ms)
May 13 19:11:53.709: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/http:proxy-service-fgbbn:portname2/proxy/: bar (200; 14.963911ms)
May 13 19:11:53.710: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/https:proxy-service-fgbbn:tlsportname1/proxy/: tls baz (200; 15.081611ms)
May 13 19:11:53.710: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/proxy-service-fgbbn:portname1/proxy/: foo (200; 15.1434ms)
May 13 19:11:53.710: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/https:proxy-service-fgbbn:tlsportname2/proxy/: tls qux (200; 15.167203ms)
May 13 19:11:53.710: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/http:proxy-service-fgbbn:portname1/proxy/: foo (200; 15.030941ms)
May 13 19:11:53.710: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/proxy-service-fgbbn:portname2/proxy/: bar (200; 15.021877ms)
May 13 19:11:53.720: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:460/proxy/: tls baz (200; 9.806587ms)
May 13 19:11:53.720: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:162/proxy/: bar (200; 9.771743ms)
May 13 19:11:53.720: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:1080/proxy/rewri... (200; 9.903011ms)
May 13 19:11:53.722: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:160/proxy/: foo (200; 12.561886ms)
May 13 19:11:53.723: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv/proxy/rewriteme"... (200; 12.628975ms)
May 13 19:11:53.723: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/http:proxy-service-fgbbn:portname2/proxy/: bar (200; 12.993251ms)
May 13 19:11:53.723: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:462/proxy/: tls qux (200; 13.116555ms)
May 13 19:11:53.723: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:160/proxy/: foo (200; 13.077763ms)
May 13 19:11:53.723: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:162/proxy/: bar (200; 12.903895ms)
May 13 19:11:53.723: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:443/proxy/... (200; 12.966674ms)
May 13 19:11:53.723: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:1080/proxy/... (200; 13.094588ms)
May 13 19:11:53.726: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/http:proxy-service-fgbbn:portname1/proxy/: foo (200; 15.915648ms)
May 13 19:11:53.726: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/https:proxy-service-fgbbn:tlsportname2/proxy/: tls qux (200; 15.891504ms)
May 13 19:11:53.726: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/proxy-service-fgbbn:portname1/proxy/: foo (200; 16.004537ms)
May 13 19:11:53.726: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/proxy-service-fgbbn:portname2/proxy/: bar (200; 16.176053ms)
May 13 19:11:53.726: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/https:proxy-service-fgbbn:tlsportname1/proxy/: tls baz (200; 16.037543ms)
May 13 19:11:53.737: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:1080/proxy/... (200; 10.568674ms)
May 13 19:11:53.739: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/http:proxy-service-fgbbn:portname2/proxy/: bar (200; 12.756072ms)
May 13 19:11:53.740: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:162/proxy/: bar (200; 12.778525ms)
May 13 19:11:53.740: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv/proxy/rewriteme"... (200; 13.140354ms)
May 13 19:11:53.740: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:462/proxy/: tls qux (200; 13.390005ms)
May 13 19:11:53.740: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:1080/proxy/rewri... (200; 13.830104ms)
May 13 19:11:53.741: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:443/proxy/... (200; 14.100041ms)
May 13 19:11:53.741: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:460/proxy/: tls baz (200; 14.068066ms)
May 13 19:11:53.741: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:160/proxy/: foo (200; 13.717871ms)
May 13 19:11:53.741: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:160/proxy/: foo (200; 14.463689ms)
May 13 19:11:53.741: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:162/proxy/: bar (200; 15.038489ms)
May 13 19:11:53.743: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/proxy-service-fgbbn:portname2/proxy/: bar (200; 15.892389ms)
May 13 19:11:53.743: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/https:proxy-service-fgbbn:tlsportname2/proxy/: tls qux (200; 16.192197ms)
May 13 19:11:53.743: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/http:proxy-service-fgbbn:portname1/proxy/: foo (200; 16.331793ms)
May 13 19:11:53.743: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/https:proxy-service-fgbbn:tlsportname1/proxy/: tls baz (200; 16.377647ms)
May 13 19:11:53.743: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/proxy-service-fgbbn:portname1/proxy/: foo (200; 16.760573ms)
May 13 19:11:53.753: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:160/proxy/: foo (200; 9.859595ms)
May 13 19:11:53.756: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:1080/proxy/rewri... (200; 12.511532ms)
May 13 19:11:53.756: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:460/proxy/: tls baz (200; 13.076903ms)
May 13 19:11:53.756: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv/proxy/rewriteme"... (200; 13.046639ms)
May 13 19:11:53.756: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:162/proxy/: bar (200; 13.105076ms)
May 13 19:11:53.756: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/proxy-service-fgbbn:portname2/proxy/: bar (200; 13.206915ms)
May 13 19:11:53.756: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:1080/proxy/... (200; 13.30991ms)
May 13 19:11:53.756: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:160/proxy/: foo (200; 13.183766ms)
May 13 19:11:53.756: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:462/proxy/: tls qux (200; 13.137922ms)
May 13 19:11:53.756: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:443/proxy/... (200; 13.179958ms)
May 13 19:11:53.758: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/https:proxy-service-fgbbn:tlsportname1/proxy/: tls baz (200; 15.211441ms)
May 13 19:11:53.759: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/http:proxy-service-fgbbn:portname2/proxy/: bar (200; 15.480972ms)
May 13 19:11:53.759: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:162/proxy/: bar (200; 15.672269ms)
May 13 19:11:53.759: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/proxy-service-fgbbn:portname1/proxy/: foo (200; 15.908638ms)
May 13 19:11:53.759: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/http:proxy-service-fgbbn:portname1/proxy/: foo (200; 15.850067ms)
May 13 19:11:53.759: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/https:proxy-service-fgbbn:tlsportname2/proxy/: tls qux (200; 15.952554ms)
May 13 19:11:53.769: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:462/proxy/: tls qux (200; 9.983958ms)
May 13 19:11:53.773: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:460/proxy/: tls baz (200; 13.659882ms)
May 13 19:11:53.773: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:160/proxy/: foo (200; 13.842309ms)
May 13 19:11:53.773: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:1080/proxy/rewri... (200; 13.864001ms)
May 13 19:11:53.773: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv/proxy/rewriteme"... (200; 13.856332ms)
May 13 19:11:53.774: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:162/proxy/: bar (200; 14.461935ms)
May 13 19:11:53.776: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:1080/proxy/... (200; 16.216877ms)
May 13 19:11:53.776: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/https:proxy-service-fgbbn:tlsportname2/proxy/: tls qux (200; 16.432207ms)
May 13 19:11:53.776: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:160/proxy/: foo (200; 16.714833ms)
May 13 19:11:53.776: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:443/proxy/... (200; 16.507656ms)
May 13 19:11:53.776: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:162/proxy/: bar (200; 16.73746ms)
May 13 19:11:53.776: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/proxy-service-fgbbn:portname1/proxy/: foo (200; 16.712879ms)
May 13 19:11:53.776: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/https:proxy-service-fgbbn:tlsportname1/proxy/: tls baz (200; 16.740795ms)
May 13 19:11:53.777: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/http:proxy-service-fgbbn:portname2/proxy/: bar (200; 17.226163ms)
May 13 19:11:53.779: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/proxy-service-fgbbn:portname2/proxy/: bar (200; 19.493646ms)
May 13 19:11:53.780: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/http:proxy-service-fgbbn:portname1/proxy/: foo (200; 20.151376ms)
May 13 19:11:53.789: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:162/proxy/: bar (200; 9.255651ms)
May 13 19:11:53.792: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:1080/proxy/... (200; 12.113924ms)
May 13 19:11:53.792: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:462/proxy/: tls qux (200; 12.128442ms)
May 13 19:11:53.795: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:162/proxy/: bar (200; 14.767882ms)
May 13 19:11:53.795: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv/proxy/rewriteme"... (200; 14.771461ms)
May 13 19:11:53.795: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:160/proxy/: foo (200; 14.87398ms)
May 13 19:11:53.796: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/http:proxy-service-fgbbn:portname1/proxy/: foo (200; 15.872832ms)
May 13 19:11:53.796: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:1080/proxy/rewri... (200; 15.750191ms)
May 13 19:11:53.796: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:460/proxy/: tls baz (200; 15.710119ms)
May 13 19:11:53.796: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:443/proxy/... (200; 15.909212ms)
May 13 19:11:53.796: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/https:proxy-service-fgbbn:tlsportname1/proxy/: tls baz (200; 16.297426ms)
May 13 19:11:53.797: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/https:proxy-service-fgbbn:tlsportname2/proxy/: tls qux (200; 17.573404ms)
May 13 19:11:53.797: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/proxy-service-fgbbn:portname2/proxy/: bar (200; 17.51408ms)
May 13 19:11:53.798: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/http:proxy-service-fgbbn:portname2/proxy/: bar (200; 18.194569ms)
May 13 19:11:53.798: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:160/proxy/: foo (200; 18.090836ms)
May 13 19:11:53.798: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/proxy-service-fgbbn:portname1/proxy/: foo (200; 18.081352ms)
May 13 19:11:53.821: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:162/proxy/: bar (200; 21.897136ms)
May 13 19:11:53.821: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:1080/proxy/... (200; 22.0198ms)
May 13 19:11:53.821: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv/proxy/rewriteme"... (200; 21.911535ms)
May 13 19:11:53.821: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:1080/proxy/rewri... (200; 22.062217ms)
May 13 19:11:53.821: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:462/proxy/: tls qux (200; 22.311473ms)
May 13 19:11:53.821: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/https:proxy-service-fgbbn:tlsportname1/proxy/: tls baz (200; 22.525412ms)
May 13 19:11:53.821: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:443/proxy/... (200; 22.606322ms)
May 13 19:11:53.821: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:160/proxy/: foo (200; 22.826277ms)
May 13 19:11:53.821: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:460/proxy/: tls baz (200; 22.593906ms)
May 13 19:11:53.821: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/https:proxy-service-fgbbn:tlsportname2/proxy/: tls qux (200; 22.497717ms)
May 13 19:11:53.821: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:162/proxy/: bar (200; 22.70495ms)
May 13 19:11:53.821: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:160/proxy/: foo (200; 22.602973ms)
May 13 19:11:53.823: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/proxy-service-fgbbn:portname2/proxy/: bar (200; 24.387092ms)
May 13 19:11:53.824: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/http:proxy-service-fgbbn:portname2/proxy/: bar (200; 25.23968ms)
May 13 19:11:53.824: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/proxy-service-fgbbn:portname1/proxy/: foo (200; 25.253505ms)
May 13 19:11:53.824: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/http:proxy-service-fgbbn:portname1/proxy/: foo (200; 25.212853ms)
May 13 19:11:53.833: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:160/proxy/: foo (200; 9.54807ms)
May 13 19:11:53.838: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:162/proxy/: bar (200; 13.764644ms)
May 13 19:11:53.839: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:460/proxy/: tls baz (200; 14.649313ms)
May 13 19:11:53.839: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:443/proxy/... (200; 14.687981ms)
May 13 19:11:53.839: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:1080/proxy/... (200; 14.827761ms)
May 13 19:11:53.839: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:160/proxy/: foo (200; 14.532013ms)
May 13 19:11:53.839: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:462/proxy/: tls qux (200; 14.610532ms)
May 13 19:11:53.839: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:162/proxy/: bar (200; 14.75457ms)
May 13 19:11:53.839: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:1080/proxy/rewri... (200; 14.919235ms)
May 13 19:11:53.839: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv/proxy/rewriteme"... (200; 14.533182ms)
May 13 19:11:53.840: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/http:proxy-service-fgbbn:portname1/proxy/: foo (200; 15.733962ms)
May 13 19:11:53.841: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/https:proxy-service-fgbbn:tlsportname2/proxy/: tls qux (200; 17.29768ms)
May 13 19:11:53.841: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/https:proxy-service-fgbbn:tlsportname1/proxy/: tls baz (200; 17.267235ms)
May 13 19:11:53.841: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/proxy-service-fgbbn:portname2/proxy/: bar (200; 17.199718ms)
May 13 19:11:53.842: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/proxy-service-fgbbn:portname1/proxy/: foo (200; 17.555119ms)
May 13 19:11:53.842: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/http:proxy-service-fgbbn:portname2/proxy/: bar (200; 18.359836ms)
May 13 19:11:53.853: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:1080/proxy/rewri... (200; 9.827436ms)
May 13 19:11:53.855: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/https:proxy-service-fgbbn:tlsportname1/proxy/: tls baz (200; 12.739649ms)
May 13 19:11:53.855: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:443/proxy/... (200; 12.425971ms)
May 13 19:11:53.857: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:162/proxy/: bar (200; 13.295655ms)
May 13 19:11:53.857: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv/proxy/rewriteme"... (200; 13.120223ms)
May 13 19:11:53.857: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:462/proxy/: tls qux (200; 13.727802ms)
May 13 19:11:53.857: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/https:proxy-service-fgbbn-5l2nv:460/proxy/: tls baz (200; 13.841887ms)
May 13 19:11:53.857: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:160/proxy/: foo (200; 13.68866ms)
May 13 19:11:53.857: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:162/proxy/: bar (200; 14.018253ms)
May 13 19:11:53.857: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/http:proxy-service-fgbbn-5l2nv:1080/proxy/... (200; 14.101179ms)
May 13 19:11:53.857: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-nc6vk/pods/proxy-service-fgbbn-5l2nv:160/proxy/: foo (200; 13.571999ms)
May 13 19:11:53.859: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/proxy-service-fgbbn:portname1/proxy/: foo (200; 16.068592ms)
May 13 19:11:53.859: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/https:proxy-service-fgbbn:tlsportname2/proxy/: tls qux (200; 16.348991ms)
May 13 19:11:53.859: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/proxy-service-fgbbn:portname2/proxy/: bar (200; 15.823558ms)
May 13 19:11:53.859: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/http:proxy-service-fgbbn:portname1/proxy/: foo (200; 16.103135ms)
May 13 19:11:53.862: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-nc6vk/services/http:proxy-service-fgbbn:portname2/proxy/: bar (200; 18.277643ms)
STEP: deleting ReplicationController proxy-service-fgbbn in namespace e2e-tests-proxy-nc6vk, will wait for the garbage collector to delete the pods
May 13 19:11:53.940: INFO: Deleting ReplicationController proxy-service-fgbbn took: 19.194483ms
May 13 19:11:54.041: INFO: Terminating ReplicationController proxy-service-fgbbn pods took: 100.200075ms
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:11:55.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-nc6vk" for this suite.
May 13 19:12:02.003: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:12:02.104: INFO: namespace: e2e-tests-proxy-nc6vk, resource: bindings, ignored listing per whitelist
May 13 19:12:02.241: INFO: namespace e2e-tests-proxy-nc6vk deletion completed in 6.289017561s

• [SLOW TEST:21.397 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:12:02.241: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svc-latency-lm64d
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-lm64d
I0513 19:12:02.549373      16 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-lm64d, replica count: 1
I0513 19:12:03.599737      16 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0513 19:12:04.599960      16 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May 13 19:12:04.722: INFO: Created: latency-svc-9wfh9
May 13 19:12:04.754: INFO: Got endpoints: latency-svc-9wfh9 [54.430948ms]
May 13 19:12:04.840: INFO: Created: latency-svc-5rc9p
May 13 19:12:04.848: INFO: Got endpoints: latency-svc-5rc9p [93.182329ms]
May 13 19:12:04.854: INFO: Created: latency-svc-7l7gx
May 13 19:12:04.860: INFO: Got endpoints: latency-svc-7l7gx [105.120469ms]
May 13 19:12:04.867: INFO: Created: latency-svc-stjpd
May 13 19:12:04.873: INFO: Got endpoints: latency-svc-stjpd [118.943449ms]
May 13 19:12:04.879: INFO: Created: latency-svc-hnj9f
May 13 19:12:04.883: INFO: Got endpoints: latency-svc-hnj9f [128.62891ms]
May 13 19:12:04.891: INFO: Created: latency-svc-j92kd
May 13 19:12:04.896: INFO: Got endpoints: latency-svc-j92kd [141.22021ms]
May 13 19:12:04.902: INFO: Created: latency-svc-qwft2
May 13 19:12:04.906: INFO: Got endpoints: latency-svc-qwft2 [151.824777ms]
May 13 19:12:04.914: INFO: Created: latency-svc-8tmv5
May 13 19:12:04.920: INFO: Got endpoints: latency-svc-8tmv5 [165.236232ms]
May 13 19:12:04.926: INFO: Created: latency-svc-6hr4k
May 13 19:12:04.932: INFO: Got endpoints: latency-svc-6hr4k [177.608128ms]
May 13 19:12:04.938: INFO: Created: latency-svc-59m79
May 13 19:12:04.944: INFO: Got endpoints: latency-svc-59m79 [189.479167ms]
May 13 19:12:04.949: INFO: Created: latency-svc-wz796
May 13 19:12:04.955: INFO: Got endpoints: latency-svc-wz796 [200.047441ms]
May 13 19:12:04.961: INFO: Created: latency-svc-xv4pg
May 13 19:12:04.966: INFO: Got endpoints: latency-svc-xv4pg [211.718577ms]
May 13 19:12:04.973: INFO: Created: latency-svc-4c88h
May 13 19:12:04.980: INFO: Got endpoints: latency-svc-4c88h [225.314401ms]
May 13 19:12:04.989: INFO: Created: latency-svc-ll8tc
May 13 19:12:04.994: INFO: Got endpoints: latency-svc-ll8tc [240.074954ms]
May 13 19:12:05.003: INFO: Created: latency-svc-ck7md
May 13 19:12:05.010: INFO: Got endpoints: latency-svc-ck7md [255.017595ms]
May 13 19:12:05.018: INFO: Created: latency-svc-rfb5g
May 13 19:12:05.024: INFO: Got endpoints: latency-svc-rfb5g [269.920041ms]
May 13 19:12:05.031: INFO: Created: latency-svc-xzb6f
May 13 19:12:05.034: INFO: Got endpoints: latency-svc-xzb6f [186.552923ms]
May 13 19:12:05.042: INFO: Created: latency-svc-4s9ws
May 13 19:12:05.047: INFO: Got endpoints: latency-svc-4s9ws [187.156387ms]
May 13 19:12:05.055: INFO: Created: latency-svc-cndns
May 13 19:12:05.060: INFO: Got endpoints: latency-svc-cndns [186.69902ms]
May 13 19:12:05.077: INFO: Created: latency-svc-fc7gb
May 13 19:12:05.082: INFO: Got endpoints: latency-svc-fc7gb [198.976533ms]
May 13 19:12:05.092: INFO: Created: latency-svc-6hvvl
May 13 19:12:05.097: INFO: Got endpoints: latency-svc-6hvvl [201.201521ms]
May 13 19:12:05.104: INFO: Created: latency-svc-559tg
May 13 19:12:05.109: INFO: Got endpoints: latency-svc-559tg [203.181036ms]
May 13 19:12:05.116: INFO: Created: latency-svc-8q9qj
May 13 19:12:05.122: INFO: Got endpoints: latency-svc-8q9qj [201.928244ms]
May 13 19:12:05.127: INFO: Created: latency-svc-5tv89
May 13 19:12:05.132: INFO: Got endpoints: latency-svc-5tv89 [200.418481ms]
May 13 19:12:05.138: INFO: Created: latency-svc-vp4ch
May 13 19:12:05.142: INFO: Got endpoints: latency-svc-vp4ch [197.680969ms]
May 13 19:12:05.149: INFO: Created: latency-svc-629f5
May 13 19:12:05.156: INFO: Got endpoints: latency-svc-629f5 [201.015649ms]
May 13 19:12:05.161: INFO: Created: latency-svc-246v5
May 13 19:12:05.166: INFO: Got endpoints: latency-svc-246v5 [199.891915ms]
May 13 19:12:05.171: INFO: Created: latency-svc-l5q5q
May 13 19:12:05.177: INFO: Got endpoints: latency-svc-l5q5q [196.98303ms]
May 13 19:12:05.182: INFO: Created: latency-svc-4zbgj
May 13 19:12:05.188: INFO: Got endpoints: latency-svc-4zbgj [193.03613ms]
May 13 19:12:05.194: INFO: Created: latency-svc-v4q7r
May 13 19:12:05.200: INFO: Got endpoints: latency-svc-v4q7r [190.876464ms]
May 13 19:12:05.207: INFO: Created: latency-svc-4c6l8
May 13 19:12:05.212: INFO: Got endpoints: latency-svc-4c6l8 [187.863188ms]
May 13 19:12:05.219: INFO: Created: latency-svc-8ct5m
May 13 19:12:05.225: INFO: Got endpoints: latency-svc-8ct5m [190.934967ms]
May 13 19:12:05.230: INFO: Created: latency-svc-ljpk7
May 13 19:12:05.235: INFO: Got endpoints: latency-svc-ljpk7 [188.468772ms]
May 13 19:12:05.242: INFO: Created: latency-svc-4ppw5
May 13 19:12:05.247: INFO: Got endpoints: latency-svc-4ppw5 [186.89939ms]
May 13 19:12:05.254: INFO: Created: latency-svc-kv84f
May 13 19:12:05.260: INFO: Got endpoints: latency-svc-kv84f [177.532721ms]
May 13 19:12:05.268: INFO: Created: latency-svc-t4r2j
May 13 19:12:05.272: INFO: Got endpoints: latency-svc-t4r2j [175.455083ms]
May 13 19:12:05.277: INFO: Created: latency-svc-m8rkt
May 13 19:12:05.283: INFO: Got endpoints: latency-svc-m8rkt [173.032686ms]
May 13 19:12:05.289: INFO: Created: latency-svc-5d2px
May 13 19:12:05.295: INFO: Got endpoints: latency-svc-5d2px [173.750924ms]
May 13 19:12:05.300: INFO: Created: latency-svc-w2kf6
May 13 19:12:05.308: INFO: Got endpoints: latency-svc-w2kf6 [175.963147ms]
May 13 19:12:05.312: INFO: Created: latency-svc-gcltr
May 13 19:12:05.317: INFO: Got endpoints: latency-svc-gcltr [175.346837ms]
May 13 19:12:05.322: INFO: Created: latency-svc-bm7fg
May 13 19:12:05.334: INFO: Created: latency-svc-q9nsc
May 13 19:12:05.349: INFO: Created: latency-svc-bh5b6
May 13 19:12:05.353: INFO: Got endpoints: latency-svc-bm7fg [197.20046ms]
May 13 19:12:05.357: INFO: Created: latency-svc-t8shc
May 13 19:12:05.367: INFO: Created: latency-svc-kkk8q
May 13 19:12:05.379: INFO: Created: latency-svc-x7q7m
May 13 19:12:05.392: INFO: Created: latency-svc-p7mpm
May 13 19:12:05.397: INFO: Got endpoints: latency-svc-q9nsc [230.893183ms]
May 13 19:12:05.407: INFO: Created: latency-svc-w65bq
May 13 19:12:05.417: INFO: Created: latency-svc-k4rsc
May 13 19:12:05.429: INFO: Created: latency-svc-wx7ww
May 13 19:12:05.440: INFO: Created: latency-svc-dbh6l
May 13 19:12:05.469: INFO: Got endpoints: latency-svc-bh5b6 [292.124451ms]
May 13 19:12:05.476: INFO: Created: latency-svc-m82fz
May 13 19:12:05.488: INFO: Created: latency-svc-r9n9q
May 13 19:12:05.497: INFO: Got endpoints: latency-svc-t8shc [309.001007ms]
May 13 19:12:05.501: INFO: Created: latency-svc-fmgpp
May 13 19:12:05.513: INFO: Created: latency-svc-4gcj8
May 13 19:12:05.528: INFO: Created: latency-svc-svv4h
May 13 19:12:05.539: INFO: Created: latency-svc-fglvj
May 13 19:12:05.547: INFO: Got endpoints: latency-svc-kkk8q [346.100178ms]
May 13 19:12:05.550: INFO: Created: latency-svc-l7wqp
May 13 19:12:05.562: INFO: Created: latency-svc-vnwb7
May 13 19:12:05.573: INFO: Created: latency-svc-r5xnv
May 13 19:12:05.597: INFO: Got endpoints: latency-svc-x7q7m [385.232241ms]
May 13 19:12:05.618: INFO: Created: latency-svc-zqlxj
May 13 19:12:05.648: INFO: Got endpoints: latency-svc-p7mpm [422.454801ms]
May 13 19:12:05.669: INFO: Created: latency-svc-twncp
May 13 19:12:05.698: INFO: Got endpoints: latency-svc-w65bq [462.677975ms]
May 13 19:12:05.721: INFO: Created: latency-svc-h42fn
May 13 19:12:05.748: INFO: Got endpoints: latency-svc-k4rsc [500.653197ms]
May 13 19:12:05.769: INFO: Created: latency-svc-lk765
May 13 19:12:05.797: INFO: Got endpoints: latency-svc-wx7ww [537.311488ms]
May 13 19:12:05.818: INFO: Created: latency-svc-wqp5k
May 13 19:12:05.847: INFO: Got endpoints: latency-svc-dbh6l [574.774522ms]
May 13 19:12:05.868: INFO: Created: latency-svc-h7h8t
May 13 19:12:05.898: INFO: Got endpoints: latency-svc-m82fz [614.824167ms]
May 13 19:12:05.920: INFO: Created: latency-svc-hxlgn
May 13 19:12:05.947: INFO: Got endpoints: latency-svc-r9n9q [651.890946ms]
May 13 19:12:05.971: INFO: Created: latency-svc-znqh9
May 13 19:12:05.998: INFO: Got endpoints: latency-svc-fmgpp [689.368202ms]
May 13 19:12:06.020: INFO: Created: latency-svc-f84mr
May 13 19:12:06.047: INFO: Got endpoints: latency-svc-4gcj8 [730.19722ms]
May 13 19:12:06.068: INFO: Created: latency-svc-bhk8k
May 13 19:12:06.097: INFO: Got endpoints: latency-svc-svv4h [744.387609ms]
May 13 19:12:06.118: INFO: Created: latency-svc-9ckh6
May 13 19:12:06.147: INFO: Got endpoints: latency-svc-fglvj [750.139233ms]
May 13 19:12:06.171: INFO: Created: latency-svc-xfv2z
May 13 19:12:06.198: INFO: Got endpoints: latency-svc-l7wqp [728.560479ms]
May 13 19:12:06.218: INFO: Created: latency-svc-c92jj
May 13 19:12:06.247: INFO: Got endpoints: latency-svc-vnwb7 [750.338318ms]
May 13 19:12:06.267: INFO: Created: latency-svc-vnnm5
May 13 19:12:06.304: INFO: Got endpoints: latency-svc-r5xnv [757.381887ms]
May 13 19:12:06.325: INFO: Created: latency-svc-gfgrr
May 13 19:12:06.347: INFO: Got endpoints: latency-svc-zqlxj [749.833946ms]
May 13 19:12:06.370: INFO: Created: latency-svc-vthjm
May 13 19:12:06.397: INFO: Got endpoints: latency-svc-twncp [748.953994ms]
May 13 19:12:06.419: INFO: Created: latency-svc-fkl6w
May 13 19:12:06.447: INFO: Got endpoints: latency-svc-h42fn [749.352456ms]
May 13 19:12:06.469: INFO: Created: latency-svc-7d4sh
May 13 19:12:06.497: INFO: Got endpoints: latency-svc-lk765 [749.619808ms]
May 13 19:12:06.620: INFO: Created: latency-svc-kbpww
May 13 19:12:06.620: INFO: Got endpoints: latency-svc-h7h8t [772.306996ms]
May 13 19:12:06.620: INFO: Got endpoints: latency-svc-wqp5k [822.902659ms]
May 13 19:12:06.641: INFO: Created: latency-svc-66qj5
May 13 19:12:06.647: INFO: Got endpoints: latency-svc-hxlgn [748.967596ms]
May 13 19:12:06.651: INFO: Created: latency-svc-zrdkc
May 13 19:12:06.669: INFO: Created: latency-svc-w5g8p
May 13 19:12:06.697: INFO: Got endpoints: latency-svc-znqh9 [750.094128ms]
May 13 19:12:06.723: INFO: Created: latency-svc-pvl28
May 13 19:12:06.747: INFO: Got endpoints: latency-svc-f84mr [749.217811ms]
May 13 19:12:06.768: INFO: Created: latency-svc-g6bxr
May 13 19:12:06.797: INFO: Got endpoints: latency-svc-bhk8k [749.754345ms]
May 13 19:12:06.818: INFO: Created: latency-svc-w7mxq
May 13 19:12:06.846: INFO: Got endpoints: latency-svc-9ckh6 [749.121334ms]
May 13 19:12:06.867: INFO: Created: latency-svc-dppzq
May 13 19:12:06.897: INFO: Got endpoints: latency-svc-xfv2z [749.806697ms]
May 13 19:12:06.917: INFO: Created: latency-svc-4ddmw
May 13 19:12:06.947: INFO: Got endpoints: latency-svc-c92jj [749.168602ms]
May 13 19:12:06.967: INFO: Created: latency-svc-z4n28
May 13 19:12:06.997: INFO: Got endpoints: latency-svc-vnnm5 [750.437879ms]
May 13 19:12:07.018: INFO: Created: latency-svc-pcs2s
May 13 19:12:07.055: INFO: Got endpoints: latency-svc-gfgrr [751.244567ms]
May 13 19:12:07.080: INFO: Created: latency-svc-zgvfm
May 13 19:12:07.098: INFO: Got endpoints: latency-svc-vthjm [750.672233ms]
May 13 19:12:07.118: INFO: Created: latency-svc-b9xg7
May 13 19:12:07.147: INFO: Got endpoints: latency-svc-fkl6w [749.918235ms]
May 13 19:12:07.168: INFO: Created: latency-svc-l6q9r
May 13 19:12:07.198: INFO: Got endpoints: latency-svc-7d4sh [750.314986ms]
May 13 19:12:07.220: INFO: Created: latency-svc-srncs
May 13 19:12:07.248: INFO: Got endpoints: latency-svc-kbpww [750.139111ms]
May 13 19:12:07.270: INFO: Created: latency-svc-25lsz
May 13 19:12:07.297: INFO: Got endpoints: latency-svc-66qj5 [677.304818ms]
May 13 19:12:07.322: INFO: Created: latency-svc-4qmhg
May 13 19:12:07.349: INFO: Got endpoints: latency-svc-zrdkc [729.248662ms]
May 13 19:12:07.371: INFO: Created: latency-svc-zltst
May 13 19:12:07.398: INFO: Got endpoints: latency-svc-w5g8p [751.284444ms]
May 13 19:12:07.419: INFO: Created: latency-svc-bnhcn
May 13 19:12:07.447: INFO: Got endpoints: latency-svc-pvl28 [749.742941ms]
May 13 19:12:07.468: INFO: Created: latency-svc-7nk79
May 13 19:12:07.504: INFO: Got endpoints: latency-svc-g6bxr [756.57464ms]
May 13 19:12:07.524: INFO: Created: latency-svc-2fns6
May 13 19:12:07.547: INFO: Got endpoints: latency-svc-w7mxq [749.790882ms]
May 13 19:12:07.568: INFO: Created: latency-svc-qzw2j
May 13 19:12:07.597: INFO: Got endpoints: latency-svc-dppzq [750.695128ms]
May 13 19:12:07.618: INFO: Created: latency-svc-5n6nx
May 13 19:12:07.647: INFO: Got endpoints: latency-svc-4ddmw [750.358416ms]
May 13 19:12:07.677: INFO: Created: latency-svc-cvzqf
May 13 19:12:07.697: INFO: Got endpoints: latency-svc-z4n28 [750.548199ms]
May 13 19:12:07.719: INFO: Created: latency-svc-8s55l
May 13 19:12:07.747: INFO: Got endpoints: latency-svc-pcs2s [749.422726ms]
May 13 19:12:07.768: INFO: Created: latency-svc-lhrrp
May 13 19:12:07.797: INFO: Got endpoints: latency-svc-zgvfm [741.70654ms]
May 13 19:12:07.818: INFO: Created: latency-svc-2hddk
May 13 19:12:07.847: INFO: Got endpoints: latency-svc-b9xg7 [749.240659ms]
May 13 19:12:07.883: INFO: Created: latency-svc-df54r
May 13 19:12:07.897: INFO: Got endpoints: latency-svc-l6q9r [750.336588ms]
May 13 19:12:07.918: INFO: Created: latency-svc-xxt28
May 13 19:12:07.948: INFO: Got endpoints: latency-svc-srncs [749.762218ms]
May 13 19:12:07.969: INFO: Created: latency-svc-c9zhr
May 13 19:12:07.998: INFO: Got endpoints: latency-svc-25lsz [750.257493ms]
May 13 19:12:08.019: INFO: Created: latency-svc-5grsf
May 13 19:12:08.047: INFO: Got endpoints: latency-svc-4qmhg [749.937568ms]
May 13 19:12:08.068: INFO: Created: latency-svc-j2854
May 13 19:12:08.097: INFO: Got endpoints: latency-svc-zltst [748.103666ms]
May 13 19:12:08.119: INFO: Created: latency-svc-gdpmr
May 13 19:12:08.148: INFO: Got endpoints: latency-svc-bnhcn [749.653371ms]
May 13 19:12:08.169: INFO: Created: latency-svc-dvz5b
May 13 19:12:08.198: INFO: Got endpoints: latency-svc-7nk79 [750.352207ms]
May 13 19:12:08.218: INFO: Created: latency-svc-mcmc4
May 13 19:12:08.247: INFO: Got endpoints: latency-svc-2fns6 [743.502942ms]
May 13 19:12:08.280: INFO: Created: latency-svc-h25jt
May 13 19:12:08.297: INFO: Got endpoints: latency-svc-qzw2j [750.164014ms]
May 13 19:12:08.317: INFO: Created: latency-svc-jnjqw
May 13 19:12:08.347: INFO: Got endpoints: latency-svc-5n6nx [749.918849ms]
May 13 19:12:08.367: INFO: Created: latency-svc-ddxwb
May 13 19:12:08.397: INFO: Got endpoints: latency-svc-cvzqf [750.119048ms]
May 13 19:12:08.418: INFO: Created: latency-svc-dwtvg
May 13 19:12:08.448: INFO: Got endpoints: latency-svc-8s55l [750.576956ms]
May 13 19:12:08.468: INFO: Created: latency-svc-z6hqb
May 13 19:12:08.497: INFO: Got endpoints: latency-svc-lhrrp [750.349953ms]
May 13 19:12:08.517: INFO: Created: latency-svc-jbsbk
May 13 19:12:08.548: INFO: Got endpoints: latency-svc-2hddk [750.570451ms]
May 13 19:12:08.582: INFO: Created: latency-svc-7bfp2
May 13 19:12:08.597: INFO: Got endpoints: latency-svc-df54r [749.626827ms]
May 13 19:12:08.620: INFO: Created: latency-svc-8s67v
May 13 19:12:08.647: INFO: Got endpoints: latency-svc-xxt28 [749.503148ms]
May 13 19:12:08.667: INFO: Created: latency-svc-d29bv
May 13 19:12:08.697: INFO: Got endpoints: latency-svc-c9zhr [749.008811ms]
May 13 19:12:08.718: INFO: Created: latency-svc-zjp67
May 13 19:12:08.747: INFO: Got endpoints: latency-svc-5grsf [749.182556ms]
May 13 19:12:08.767: INFO: Created: latency-svc-f7n8j
May 13 19:12:08.798: INFO: Got endpoints: latency-svc-j2854 [750.286529ms]
May 13 19:12:08.818: INFO: Created: latency-svc-2ktcq
May 13 19:12:08.847: INFO: Got endpoints: latency-svc-gdpmr [749.883903ms]
May 13 19:12:08.867: INFO: Created: latency-svc-g8992
May 13 19:12:08.899: INFO: Got endpoints: latency-svc-dvz5b [751.585456ms]
May 13 19:12:08.920: INFO: Created: latency-svc-zl99z
May 13 19:12:08.947: INFO: Got endpoints: latency-svc-mcmc4 [749.415971ms]
May 13 19:12:08.969: INFO: Created: latency-svc-47qqt
May 13 19:12:09.000: INFO: Got endpoints: latency-svc-h25jt [752.467286ms]
May 13 19:12:09.020: INFO: Created: latency-svc-mlw4n
May 13 19:12:09.048: INFO: Got endpoints: latency-svc-jnjqw [750.253194ms]
May 13 19:12:09.071: INFO: Created: latency-svc-lfh9t
May 13 19:12:09.099: INFO: Got endpoints: latency-svc-ddxwb [751.655091ms]
May 13 19:12:09.122: INFO: Created: latency-svc-6r8v9
May 13 19:12:09.148: INFO: Got endpoints: latency-svc-dwtvg [750.30322ms]
May 13 19:12:09.170: INFO: Created: latency-svc-jcgcs
May 13 19:12:09.197: INFO: Got endpoints: latency-svc-z6hqb [749.215224ms]
May 13 19:12:09.217: INFO: Created: latency-svc-5hrxs
May 13 19:12:09.248: INFO: Got endpoints: latency-svc-jbsbk [750.536001ms]
May 13 19:12:09.272: INFO: Created: latency-svc-7cvfp
May 13 19:12:09.297: INFO: Got endpoints: latency-svc-7bfp2 [738.07179ms]
May 13 19:12:09.318: INFO: Created: latency-svc-s6xnj
May 13 19:12:09.347: INFO: Got endpoints: latency-svc-8s67v [750.287653ms]
May 13 19:12:09.368: INFO: Created: latency-svc-vrjpt
May 13 19:12:09.398: INFO: Got endpoints: latency-svc-d29bv [751.616266ms]
May 13 19:12:09.421: INFO: Created: latency-svc-qsg6s
May 13 19:12:09.447: INFO: Got endpoints: latency-svc-zjp67 [750.519432ms]
May 13 19:12:09.520: INFO: Got endpoints: latency-svc-f7n8j [772.89061ms]
May 13 19:12:09.520: INFO: Created: latency-svc-pfjwf
May 13 19:12:09.543: INFO: Created: latency-svc-2tsdm
May 13 19:12:09.547: INFO: Got endpoints: latency-svc-2ktcq [749.374254ms]
May 13 19:12:09.567: INFO: Created: latency-svc-qlrgt
May 13 19:12:09.597: INFO: Got endpoints: latency-svc-g8992 [749.889159ms]
May 13 19:12:09.617: INFO: Created: latency-svc-lsj4b
May 13 19:12:09.647: INFO: Got endpoints: latency-svc-zl99z [747.850698ms]
May 13 19:12:09.668: INFO: Created: latency-svc-j96w6
May 13 19:12:09.697: INFO: Got endpoints: latency-svc-47qqt [749.63925ms]
May 13 19:12:09.717: INFO: Created: latency-svc-26s65
May 13 19:12:09.747: INFO: Got endpoints: latency-svc-mlw4n [747.311495ms]
May 13 19:12:09.767: INFO: Created: latency-svc-gdq8x
May 13 19:12:09.796: INFO: Got endpoints: latency-svc-lfh9t [748.889644ms]
May 13 19:12:09.818: INFO: Created: latency-svc-fgmbw
May 13 19:12:09.847: INFO: Got endpoints: latency-svc-6r8v9 [748.045828ms]
May 13 19:12:09.868: INFO: Created: latency-svc-g2rm9
May 13 19:12:09.897: INFO: Got endpoints: latency-svc-jcgcs [749.159104ms]
May 13 19:12:09.918: INFO: Created: latency-svc-4246w
May 13 19:12:09.947: INFO: Got endpoints: latency-svc-5hrxs [749.495611ms]
May 13 19:12:09.968: INFO: Created: latency-svc-6nbvm
May 13 19:12:09.997: INFO: Got endpoints: latency-svc-7cvfp [749.093257ms]
May 13 19:12:10.018: INFO: Created: latency-svc-ft2pl
May 13 19:12:10.048: INFO: Got endpoints: latency-svc-s6xnj [750.664178ms]
May 13 19:12:10.070: INFO: Created: latency-svc-5cwhz
May 13 19:12:10.098: INFO: Got endpoints: latency-svc-vrjpt [750.383633ms]
May 13 19:12:10.119: INFO: Created: latency-svc-t67k7
May 13 19:12:10.147: INFO: Got endpoints: latency-svc-qsg6s [748.139356ms]
May 13 19:12:10.167: INFO: Created: latency-svc-45dfz
May 13 19:12:10.197: INFO: Got endpoints: latency-svc-pfjwf [749.949964ms]
May 13 19:12:10.217: INFO: Created: latency-svc-kgz6j
May 13 19:12:10.247: INFO: Got endpoints: latency-svc-2tsdm [726.448266ms]
May 13 19:12:10.268: INFO: Created: latency-svc-25ptq
May 13 19:12:10.297: INFO: Got endpoints: latency-svc-qlrgt [750.135752ms]
May 13 19:12:10.318: INFO: Created: latency-svc-s6lgw
May 13 19:12:10.347: INFO: Got endpoints: latency-svc-lsj4b [749.642484ms]
May 13 19:12:10.368: INFO: Created: latency-svc-72hdd
May 13 19:12:10.397: INFO: Got endpoints: latency-svc-j96w6 [749.879655ms]
May 13 19:12:10.418: INFO: Created: latency-svc-nvlbd
May 13 19:12:10.447: INFO: Got endpoints: latency-svc-26s65 [750.260674ms]
May 13 19:12:10.468: INFO: Created: latency-svc-tx6br
May 13 19:12:10.497: INFO: Got endpoints: latency-svc-gdq8x [750.055439ms]
May 13 19:12:10.520: INFO: Created: latency-svc-s4prc
May 13 19:12:10.547: INFO: Got endpoints: latency-svc-fgmbw [750.110261ms]
May 13 19:12:10.567: INFO: Created: latency-svc-9xt8q
May 13 19:12:10.597: INFO: Got endpoints: latency-svc-g2rm9 [749.846539ms]
May 13 19:12:10.617: INFO: Created: latency-svc-njhjf
May 13 19:12:10.647: INFO: Got endpoints: latency-svc-4246w [750.112283ms]
May 13 19:12:10.667: INFO: Created: latency-svc-gqs9d
May 13 19:12:10.697: INFO: Got endpoints: latency-svc-6nbvm [750.078413ms]
May 13 19:12:10.717: INFO: Created: latency-svc-69gnk
May 13 19:12:10.747: INFO: Got endpoints: latency-svc-ft2pl [749.977468ms]
May 13 19:12:10.770: INFO: Created: latency-svc-q292n
May 13 19:12:10.797: INFO: Got endpoints: latency-svc-5cwhz [748.277529ms]
May 13 19:12:10.823: INFO: Created: latency-svc-gchln
May 13 19:12:10.847: INFO: Got endpoints: latency-svc-t67k7 [749.60842ms]
May 13 19:12:10.901: INFO: Created: latency-svc-wr85z
May 13 19:12:10.901: INFO: Got endpoints: latency-svc-45dfz [754.458337ms]
May 13 19:12:10.922: INFO: Created: latency-svc-jfz6g
May 13 19:12:10.947: INFO: Got endpoints: latency-svc-kgz6j [749.970926ms]
May 13 19:12:10.967: INFO: Created: latency-svc-vn7sm
May 13 19:12:10.997: INFO: Got endpoints: latency-svc-25ptq [750.614375ms]
May 13 19:12:11.017: INFO: Created: latency-svc-btdpb
May 13 19:12:11.047: INFO: Got endpoints: latency-svc-s6lgw [749.687666ms]
May 13 19:12:11.072: INFO: Created: latency-svc-fzqzj
May 13 19:12:11.098: INFO: Got endpoints: latency-svc-72hdd [750.855789ms]
May 13 19:12:11.120: INFO: Created: latency-svc-485q4
May 13 19:12:11.148: INFO: Got endpoints: latency-svc-nvlbd [750.676929ms]
May 13 19:12:11.170: INFO: Created: latency-svc-p82gb
May 13 19:12:11.197: INFO: Got endpoints: latency-svc-tx6br [749.907462ms]
May 13 19:12:11.422: INFO: Got endpoints: latency-svc-9xt8q [875.357434ms]
May 13 19:12:11.422: INFO: Got endpoints: latency-svc-njhjf [825.297835ms]
May 13 19:12:11.422: INFO: Got endpoints: latency-svc-s4prc [925.098829ms]
May 13 19:12:11.520: INFO: Got endpoints: latency-svc-q292n [772.923033ms]
May 13 19:12:11.520: INFO: Got endpoints: latency-svc-69gnk [823.354169ms]
May 13 19:12:11.520: INFO: Got endpoints: latency-svc-gqs9d [873.241625ms]
May 13 19:12:11.520: INFO: Created: latency-svc-cg2gz
May 13 19:12:11.541: INFO: Created: latency-svc-nf75m
May 13 19:12:11.547: INFO: Got endpoints: latency-svc-gchln [750.661384ms]
May 13 19:12:11.553: INFO: Created: latency-svc-t7dvc
May 13 19:12:11.564: INFO: Created: latency-svc-nb7c4
May 13 19:12:11.577: INFO: Created: latency-svc-64qwt
May 13 19:12:11.589: INFO: Created: latency-svc-zthhj
May 13 19:12:11.597: INFO: Got endpoints: latency-svc-wr85z [749.749073ms]
May 13 19:12:11.601: INFO: Created: latency-svc-jcz2b
May 13 19:12:11.613: INFO: Created: latency-svc-5h2hk
May 13 19:12:11.625: INFO: Created: latency-svc-z6t9l
May 13 19:12:11.647: INFO: Got endpoints: latency-svc-jfz6g [746.32362ms]
May 13 19:12:11.668: INFO: Created: latency-svc-qrktn
May 13 19:12:11.697: INFO: Got endpoints: latency-svc-vn7sm [749.571474ms]
May 13 19:12:11.718: INFO: Created: latency-svc-9z26w
May 13 19:12:11.748: INFO: Got endpoints: latency-svc-btdpb [750.27264ms]
May 13 19:12:11.771: INFO: Created: latency-svc-mxf9h
May 13 19:12:11.797: INFO: Got endpoints: latency-svc-fzqzj [749.705547ms]
May 13 19:12:11.818: INFO: Created: latency-svc-qmx9k
May 13 19:12:11.848: INFO: Got endpoints: latency-svc-485q4 [750.814847ms]
May 13 19:12:11.873: INFO: Created: latency-svc-d9g55
May 13 19:12:11.897: INFO: Got endpoints: latency-svc-p82gb [749.228933ms]
May 13 19:12:11.917: INFO: Created: latency-svc-wzck9
May 13 19:12:11.947: INFO: Got endpoints: latency-svc-cg2gz [749.378514ms]
May 13 19:12:11.968: INFO: Created: latency-svc-cnxh7
May 13 19:12:11.997: INFO: Got endpoints: latency-svc-nf75m [574.251501ms]
May 13 19:12:12.023: INFO: Created: latency-svc-cpvkk
May 13 19:12:12.047: INFO: Got endpoints: latency-svc-t7dvc [624.453951ms]
May 13 19:12:12.067: INFO: Created: latency-svc-fknxm
May 13 19:12:12.097: INFO: Got endpoints: latency-svc-nb7c4 [674.629377ms]
May 13 19:12:12.117: INFO: Created: latency-svc-9654c
May 13 19:12:12.147: INFO: Got endpoints: latency-svc-64qwt [626.798036ms]
May 13 19:12:12.168: INFO: Created: latency-svc-jvjs4
May 13 19:12:12.197: INFO: Got endpoints: latency-svc-zthhj [676.600975ms]
May 13 19:12:12.217: INFO: Created: latency-svc-6m8gd
May 13 19:12:12.247: INFO: Got endpoints: latency-svc-jcz2b [726.709805ms]
May 13 19:12:12.267: INFO: Created: latency-svc-278w7
May 13 19:12:12.297: INFO: Got endpoints: latency-svc-5h2hk [749.453563ms]
May 13 19:12:12.318: INFO: Created: latency-svc-nsznp
May 13 19:12:12.347: INFO: Got endpoints: latency-svc-z6t9l [750.34854ms]
May 13 19:12:12.368: INFO: Created: latency-svc-h9kgl
May 13 19:12:12.398: INFO: Got endpoints: latency-svc-qrktn [749.975497ms]
May 13 19:12:12.420: INFO: Created: latency-svc-4bzhb
May 13 19:12:12.447: INFO: Got endpoints: latency-svc-9z26w [749.785348ms]
May 13 19:12:12.469: INFO: Created: latency-svc-xcvz8
May 13 19:12:12.497: INFO: Got endpoints: latency-svc-mxf9h [749.234483ms]
May 13 19:12:12.518: INFO: Created: latency-svc-42f4h
May 13 19:12:12.547: INFO: Got endpoints: latency-svc-qmx9k [749.723623ms]
May 13 19:12:12.567: INFO: Created: latency-svc-pwwr8
May 13 19:12:12.597: INFO: Got endpoints: latency-svc-d9g55 [748.742584ms]
May 13 19:12:12.618: INFO: Created: latency-svc-dq4j5
May 13 19:12:12.647: INFO: Got endpoints: latency-svc-wzck9 [750.089914ms]
May 13 19:12:12.697: INFO: Got endpoints: latency-svc-cnxh7 [750.340779ms]
May 13 19:12:12.747: INFO: Got endpoints: latency-svc-cpvkk [750.168318ms]
May 13 19:12:12.820: INFO: Got endpoints: latency-svc-fknxm [772.72133ms]
May 13 19:12:12.847: INFO: Got endpoints: latency-svc-9654c [750.025009ms]
May 13 19:12:12.897: INFO: Got endpoints: latency-svc-jvjs4 [750.278003ms]
May 13 19:12:12.948: INFO: Got endpoints: latency-svc-6m8gd [750.511521ms]
May 13 19:12:12.997: INFO: Got endpoints: latency-svc-278w7 [750.12643ms]
May 13 19:12:13.049: INFO: Got endpoints: latency-svc-nsznp [751.465069ms]
May 13 19:12:13.120: INFO: Got endpoints: latency-svc-h9kgl [772.338833ms]
May 13 19:12:13.148: INFO: Got endpoints: latency-svc-4bzhb [750.827965ms]
May 13 19:12:13.197: INFO: Got endpoints: latency-svc-xcvz8 [750.420813ms]
May 13 19:12:13.248: INFO: Got endpoints: latency-svc-42f4h [750.824723ms]
May 13 19:12:13.298: INFO: Got endpoints: latency-svc-pwwr8 [751.08869ms]
May 13 19:12:13.347: INFO: Got endpoints: latency-svc-dq4j5 [749.796745ms]
May 13 19:12:13.347: INFO: Latencies: [93.182329ms 105.120469ms 118.943449ms 128.62891ms 141.22021ms 151.824777ms 165.236232ms 173.032686ms 173.750924ms 175.346837ms 175.455083ms 175.963147ms 177.532721ms 177.608128ms 186.552923ms 186.69902ms 186.89939ms 187.156387ms 187.863188ms 188.468772ms 189.479167ms 190.876464ms 190.934967ms 193.03613ms 196.98303ms 197.20046ms 197.680969ms 198.976533ms 199.891915ms 200.047441ms 200.418481ms 201.015649ms 201.201521ms 201.928244ms 203.181036ms 211.718577ms 225.314401ms 230.893183ms 240.074954ms 255.017595ms 269.920041ms 292.124451ms 309.001007ms 346.100178ms 385.232241ms 422.454801ms 462.677975ms 500.653197ms 537.311488ms 574.251501ms 574.774522ms 614.824167ms 624.453951ms 626.798036ms 651.890946ms 674.629377ms 676.600975ms 677.304818ms 689.368202ms 726.448266ms 726.709805ms 728.560479ms 729.248662ms 730.19722ms 738.07179ms 741.70654ms 743.502942ms 744.387609ms 746.32362ms 747.311495ms 747.850698ms 748.045828ms 748.103666ms 748.139356ms 748.277529ms 748.742584ms 748.889644ms 748.953994ms 748.967596ms 749.008811ms 749.093257ms 749.121334ms 749.159104ms 749.168602ms 749.182556ms 749.215224ms 749.217811ms 749.228933ms 749.234483ms 749.240659ms 749.352456ms 749.374254ms 749.378514ms 749.415971ms 749.422726ms 749.453563ms 749.495611ms 749.503148ms 749.571474ms 749.60842ms 749.619808ms 749.626827ms 749.63925ms 749.642484ms 749.653371ms 749.687666ms 749.705547ms 749.723623ms 749.742941ms 749.749073ms 749.754345ms 749.762218ms 749.785348ms 749.790882ms 749.796745ms 749.806697ms 749.833946ms 749.846539ms 749.879655ms 749.883903ms 749.889159ms 749.907462ms 749.918235ms 749.918849ms 749.937568ms 749.949964ms 749.970926ms 749.975497ms 749.977468ms 750.025009ms 750.055439ms 750.078413ms 750.089914ms 750.094128ms 750.110261ms 750.112283ms 750.119048ms 750.12643ms 750.135752ms 750.139111ms 750.139233ms 750.164014ms 750.168318ms 750.253194ms 750.257493ms 750.260674ms 750.27264ms 750.278003ms 750.286529ms 750.287653ms 750.30322ms 750.314986ms 750.336588ms 750.338318ms 750.340779ms 750.34854ms 750.349953ms 750.352207ms 750.358416ms 750.383633ms 750.420813ms 750.437879ms 750.511521ms 750.519432ms 750.536001ms 750.548199ms 750.570451ms 750.576956ms 750.614375ms 750.661384ms 750.664178ms 750.672233ms 750.676929ms 750.695128ms 750.814847ms 750.824723ms 750.827965ms 750.855789ms 751.08869ms 751.244567ms 751.284444ms 751.465069ms 751.585456ms 751.616266ms 751.655091ms 752.467286ms 754.458337ms 756.57464ms 757.381887ms 772.306996ms 772.338833ms 772.72133ms 772.89061ms 772.923033ms 822.902659ms 823.354169ms 825.297835ms 873.241625ms 875.357434ms 925.098829ms]
May 13 19:12:13.347: INFO: 50 %ile: 749.619808ms
May 13 19:12:13.347: INFO: 90 %ile: 751.284444ms
May 13 19:12:13.347: INFO: 99 %ile: 875.357434ms
May 13 19:12:13.347: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:12:13.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-lm64d" for this suite.
May 13 19:12:29.457: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:12:29.543: INFO: namespace: e2e-tests-svc-latency-lm64d, resource: bindings, ignored listing per whitelist
May 13 19:12:29.742: INFO: namespace e2e-tests-svc-latency-lm64d deletion completed in 16.314634404s

• [SLOW TEST:27.501 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:12:29.742: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-j58m5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
May 13 19:12:30.073: INFO: Waiting up to 5m0s for pod "downward-api-0dad88c0-75b3-11e9-8f67-2632f168be36" in namespace "e2e-tests-downward-api-j58m5" to be "success or failure"
May 13 19:12:30.081: INFO: Pod "downward-api-0dad88c0-75b3-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 7.401613ms
May 13 19:12:32.089: INFO: Pod "downward-api-0dad88c0-75b3-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015270117s
May 13 19:12:34.098: INFO: Pod "downward-api-0dad88c0-75b3-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024297872s
STEP: Saw pod success
May 13 19:12:34.098: INFO: Pod "downward-api-0dad88c0-75b3-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 19:12:34.107: INFO: Trying to get logs from node 10.170.219.153 pod downward-api-0dad88c0-75b3-11e9-8f67-2632f168be36 container dapi-container: <nil>
STEP: delete the pod
May 13 19:12:34.220: INFO: Waiting for pod downward-api-0dad88c0-75b3-11e9-8f67-2632f168be36 to disappear
May 13 19:12:34.228: INFO: Pod downward-api-0dad88c0-75b3-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:12:34.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-j58m5" for this suite.
May 13 19:12:40.264: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:12:40.303: INFO: namespace: e2e-tests-downward-api-j58m5, resource: bindings, ignored listing per whitelist
May 13 19:12:40.597: INFO: namespace e2e-tests-downward-api-j58m5 deletion completed in 6.361772947s

• [SLOW TEST:10.855 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:12:40.598: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-4npj8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-4npj8
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
May 13 19:12:40.894: INFO: Found 0 stateful pods, waiting for 3
May 13 19:12:50.916: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 13 19:12:50.916: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 13 19:12:50.916: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
May 13 19:12:50.958: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
May 13 19:13:01.019: INFO: Updating stateful set ss2
May 13 19:13:01.031: INFO: Waiting for Pod e2e-tests-statefulset-4npj8/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
May 13 19:13:11.127: INFO: Found 2 stateful pods, waiting for 3
May 13 19:13:21.150: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 13 19:13:21.151: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 13 19:13:21.151: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
May 13 19:13:21.227: INFO: Updating stateful set ss2
May 13 19:13:21.239: INFO: Waiting for Pod e2e-tests-statefulset-4npj8/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
May 13 19:13:31.287: INFO: Updating stateful set ss2
May 13 19:13:31.300: INFO: Waiting for StatefulSet e2e-tests-statefulset-4npj8/ss2 to complete update
May 13 19:13:31.300: INFO: Waiting for Pod e2e-tests-statefulset-4npj8/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
May 13 19:13:41.428: INFO: Waiting for StatefulSet e2e-tests-statefulset-4npj8/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 13 19:13:51.316: INFO: Deleting all statefulset in ns e2e-tests-statefulset-4npj8
May 13 19:13:51.333: INFO: Scaling statefulset ss2 to 0
May 13 19:14:11.360: INFO: Waiting for statefulset status.replicas updated to 0
May 13 19:14:11.365: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:14:11.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-4npj8" for this suite.
May 13 19:14:19.427: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:14:19.552: INFO: namespace: e2e-tests-statefulset-4npj8, resource: bindings, ignored listing per whitelist
May 13 19:14:19.774: INFO: namespace e2e-tests-statefulset-4npj8 deletion completed in 8.376672674s

• [SLOW TEST:99.177 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:14:19.776: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-qjl2t
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-qjl2t
May 13 19:14:24.100: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-qjl2t
STEP: checking the pod's current state and verifying that restartCount is present
May 13 19:14:24.109: INFO: Initial restart count of pod liveness-exec is 0
May 13 19:15:09.040: INFO: Restart count of pod e2e-tests-container-probe-qjl2t/liveness-exec is now 1 (44.93137547s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:15:09.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-qjl2t" for this suite.
May 13 19:15:15.160: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:15:15.316: INFO: namespace: e2e-tests-container-probe-qjl2t, resource: bindings, ignored listing per whitelist
May 13 19:15:15.460: INFO: namespace e2e-tests-container-probe-qjl2t deletion completed in 6.340251171s

• [SLOW TEST:55.684 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:15:15.460: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-lxbll
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-706d22b1-75b3-11e9-8f67-2632f168be36
STEP: Creating a pod to test consume secrets
May 13 19:15:15.753: INFO: Waiting up to 5m0s for pod "pod-secrets-706e72d7-75b3-11e9-8f67-2632f168be36" in namespace "e2e-tests-secrets-lxbll" to be "success or failure"
May 13 19:15:15.761: INFO: Pod "pod-secrets-706e72d7-75b3-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 7.785607ms
May 13 19:15:17.769: INFO: Pod "pod-secrets-706e72d7-75b3-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016256283s
STEP: Saw pod success
May 13 19:15:17.769: INFO: Pod "pod-secrets-706e72d7-75b3-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 19:15:17.776: INFO: Trying to get logs from node 10.170.219.177 pod pod-secrets-706e72d7-75b3-11e9-8f67-2632f168be36 container secret-volume-test: <nil>
STEP: delete the pod
May 13 19:15:17.818: INFO: Waiting for pod pod-secrets-706e72d7-75b3-11e9-8f67-2632f168be36 to disappear
May 13 19:15:17.827: INFO: Pod pod-secrets-706e72d7-75b3-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:15:17.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-lxbll" for this suite.
May 13 19:15:23.863: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:15:23.995: INFO: namespace: e2e-tests-secrets-lxbll, resource: bindings, ignored listing per whitelist
May 13 19:15:24.159: INFO: namespace e2e-tests-secrets-lxbll deletion completed in 6.324747219s

• [SLOW TEST:8.699 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:15:24.160: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-xhpc9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-xhpc9 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-xhpc9;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-xhpc9 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-xhpc9;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-xhpc9.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-xhpc9.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-xhpc9.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-xhpc9.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-xhpc9.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-xhpc9.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-xhpc9.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-xhpc9.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-xhpc9.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-xhpc9.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-xhpc9.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-xhpc9.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-xhpc9.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 73.188.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.188.73_udp@PTR;check="$$(dig +tcp +noall +answer +search 73.188.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.188.73_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-xhpc9 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-xhpc9;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-xhpc9 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-xhpc9;check="$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-xhpc9.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-xhpc9.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-xhpc9.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-xhpc9.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-xhpc9.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-xhpc9.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-xhpc9.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-xhpc9.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-xhpc9.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-xhpc9.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-xhpc9.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-xhpc9.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-xhpc9.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 73.188.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.188.73_udp@PTR;check="$$(dig +tcp +noall +answer +search 73.188.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.188.73_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 13 19:15:28.541: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:28.573: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-xhpc9 from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:28.606: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-xhpc9.svc from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:28.621: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-xhpc9.svc from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:28.691: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:28.701: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:28.711: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-xhpc9 from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:28.722: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-xhpc9 from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:28.732: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-xhpc9.svc from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:28.742: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-xhpc9.svc from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:28.751: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-xhpc9.svc from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:28.761: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-xhpc9.svc from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:28.829: INFO: Lookups using e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service.e2e-tests-dns-xhpc9 wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-xhpc9.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-xhpc9.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-xhpc9 jessie_tcp@dns-test-service.e2e-tests-dns-xhpc9 jessie_udp@dns-test-service.e2e-tests-dns-xhpc9.svc jessie_tcp@dns-test-service.e2e-tests-dns-xhpc9.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-xhpc9.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-xhpc9.svc]

May 13 19:15:33.842: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:33.875: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-xhpc9 from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:33.910: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-xhpc9.svc from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:33.920: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-xhpc9.svc from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:33.994: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:34.007: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:34.018: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-xhpc9 from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:34.028: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-xhpc9 from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:34.040: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-xhpc9.svc from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:34.051: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-xhpc9.svc from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:34.061: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-xhpc9.svc from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:34.071: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-xhpc9.svc from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:34.139: INFO: Lookups using e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service.e2e-tests-dns-xhpc9 wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-xhpc9.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-xhpc9.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-xhpc9 jessie_tcp@dns-test-service.e2e-tests-dns-xhpc9 jessie_udp@dns-test-service.e2e-tests-dns-xhpc9.svc jessie_tcp@dns-test-service.e2e-tests-dns-xhpc9.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-xhpc9.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-xhpc9.svc]

May 13 19:15:38.853: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:38.952: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-xhpc9 from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:38.984: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-xhpc9.svc from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:38.994: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-xhpc9.svc from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:39.072: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:39.082: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:39.092: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-xhpc9 from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:39.104: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-xhpc9 from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:39.114: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-xhpc9.svc from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:39.126: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-xhpc9.svc from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:39.137: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-xhpc9.svc from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:39.147: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-xhpc9.svc from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:39.211: INFO: Lookups using e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service.e2e-tests-dns-xhpc9 wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-xhpc9.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-xhpc9.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-xhpc9 jessie_tcp@dns-test-service.e2e-tests-dns-xhpc9 jessie_udp@dns-test-service.e2e-tests-dns-xhpc9.svc jessie_tcp@dns-test-service.e2e-tests-dns-xhpc9.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-xhpc9.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-xhpc9.svc]

May 13 19:15:43.947: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:43.982: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-xhpc9 from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:44.052: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-xhpc9.svc from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:44.062: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-xhpc9.svc from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:44.139: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:44.149: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:44.160: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-xhpc9 from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:44.171: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-xhpc9 from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:44.181: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-xhpc9.svc from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:44.191: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-xhpc9.svc from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:44.203: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-xhpc9.svc from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:44.217: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-xhpc9.svc from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:44.295: INFO: Lookups using e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service.e2e-tests-dns-xhpc9 wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-xhpc9.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-xhpc9.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-xhpc9 jessie_tcp@dns-test-service.e2e-tests-dns-xhpc9 jessie_udp@dns-test-service.e2e-tests-dns-xhpc9.svc jessie_tcp@dns-test-service.e2e-tests-dns-xhpc9.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-xhpc9.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-xhpc9.svc]

May 13 19:15:48.841: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:48.887: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-xhpc9 from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:48.919: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-xhpc9.svc from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:48.932: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-xhpc9.svc from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:49.008: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:49.019: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:49.030: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-xhpc9 from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:49.041: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-xhpc9 from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:49.052: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-xhpc9.svc from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:49.061: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-xhpc9.svc from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:49.071: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-xhpc9.svc from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:49.082: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-xhpc9.svc from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:49.144: INFO: Lookups using e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service.e2e-tests-dns-xhpc9 wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-xhpc9.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-xhpc9.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-xhpc9 jessie_tcp@dns-test-service.e2e-tests-dns-xhpc9 jessie_udp@dns-test-service.e2e-tests-dns-xhpc9.svc jessie_tcp@dns-test-service.e2e-tests-dns-xhpc9.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-xhpc9.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-xhpc9.svc]

May 13 19:15:53.841: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:53.874: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-xhpc9 from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:53.934: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-xhpc9.svc from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:53.946: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-xhpc9.svc from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:54.021: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:54.031: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:54.042: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-xhpc9 from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:54.053: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-xhpc9 from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:54.063: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-xhpc9.svc from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:54.073: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-xhpc9.svc from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:54.083: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-xhpc9.svc from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:54.095: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-xhpc9.svc from pod e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36: the server could not find the requested resource (get pods dns-test-75a159c3-75b3-11e9-8f67-2632f168be36)
May 13 19:15:54.162: INFO: Lookups using e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service.e2e-tests-dns-xhpc9 wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-xhpc9.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-xhpc9.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-xhpc9 jessie_tcp@dns-test-service.e2e-tests-dns-xhpc9 jessie_udp@dns-test-service.e2e-tests-dns-xhpc9.svc jessie_tcp@dns-test-service.e2e-tests-dns-xhpc9.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-xhpc9.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-xhpc9.svc]

May 13 19:15:59.227: INFO: DNS probes using e2e-tests-dns-xhpc9/dns-test-75a159c3-75b3-11e9-8f67-2632f168be36 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:15:59.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-xhpc9" for this suite.
May 13 19:16:05.362: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:16:05.777: INFO: namespace: e2e-tests-dns-xhpc9, resource: bindings, ignored listing per whitelist
May 13 19:16:05.832: INFO: namespace e2e-tests-dns-xhpc9 deletion completed in 6.499923168s

• [SLOW TEST:41.671 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:16:05.832: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-tkq9d
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-8e764299-75b3-11e9-8f67-2632f168be36
STEP: Creating a pod to test consume configMaps
May 13 19:16:06.146: INFO: Waiting up to 5m0s for pod "pod-configmaps-8e779268-75b3-11e9-8f67-2632f168be36" in namespace "e2e-tests-configmap-tkq9d" to be "success or failure"
May 13 19:16:06.154: INFO: Pod "pod-configmaps-8e779268-75b3-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 7.732265ms
May 13 19:16:08.162: INFO: Pod "pod-configmaps-8e779268-75b3-11e9-8f67-2632f168be36": Phase="Running", Reason="", readiness=true. Elapsed: 2.016099431s
May 13 19:16:10.182: INFO: Pod "pod-configmaps-8e779268-75b3-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0358075s
STEP: Saw pod success
May 13 19:16:10.182: INFO: Pod "pod-configmaps-8e779268-75b3-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 19:16:10.190: INFO: Trying to get logs from node 10.170.219.177 pod pod-configmaps-8e779268-75b3-11e9-8f67-2632f168be36 container configmap-volume-test: <nil>
STEP: delete the pod
May 13 19:16:10.236: INFO: Waiting for pod pod-configmaps-8e779268-75b3-11e9-8f67-2632f168be36 to disappear
May 13 19:16:10.243: INFO: Pod pod-configmaps-8e779268-75b3-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:16:10.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-tkq9d" for this suite.
May 13 19:16:16.279: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:16:16.460: INFO: namespace: e2e-tests-configmap-tkq9d, resource: bindings, ignored listing per whitelist
May 13 19:16:16.546: INFO: namespace e2e-tests-configmap-tkq9d deletion completed in 6.295552206s

• [SLOW TEST:10.715 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:16:16.549: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-hostpath-6kkbc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
May 13 19:16:16.840: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-6kkbc" to be "success or failure"
May 13 19:16:16.850: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 9.585843ms
May 13 19:16:18.858: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017797788s
STEP: Saw pod success
May 13 19:16:18.858: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
May 13 19:16:18.866: INFO: Trying to get logs from node 10.170.219.177 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
May 13 19:16:18.906: INFO: Waiting for pod pod-host-path-test to disappear
May 13 19:16:18.913: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:16:18.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-6kkbc" for this suite.
May 13 19:16:24.953: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:16:25.175: INFO: namespace: e2e-tests-hostpath-6kkbc, resource: bindings, ignored listing per whitelist
May 13 19:16:25.264: INFO: namespace e2e-tests-hostpath-6kkbc deletion completed in 6.338408087s

• [SLOW TEST:8.715 seconds]
[sig-storage] HostPath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:16:25.266: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-25npw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 13 19:16:27.851: INFO: Waiting up to 5m0s for pod "client-envvars-9b6882c2-75b3-11e9-8f67-2632f168be36" in namespace "e2e-tests-pods-25npw" to be "success or failure"
May 13 19:16:27.859: INFO: Pod "client-envvars-9b6882c2-75b3-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 7.721469ms
May 13 19:16:29.867: INFO: Pod "client-envvars-9b6882c2-75b3-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015713151s
STEP: Saw pod success
May 13 19:16:29.867: INFO: Pod "client-envvars-9b6882c2-75b3-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 19:16:29.874: INFO: Trying to get logs from node 10.170.219.177 pod client-envvars-9b6882c2-75b3-11e9-8f67-2632f168be36 container env3cont: <nil>
STEP: delete the pod
May 13 19:16:29.913: INFO: Waiting for pod client-envvars-9b6882c2-75b3-11e9-8f67-2632f168be36 to disappear
May 13 19:16:29.921: INFO: Pod client-envvars-9b6882c2-75b3-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:16:29.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-25npw" for this suite.
May 13 19:17:09.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:17:10.121: INFO: namespace: e2e-tests-pods-25npw, resource: bindings, ignored listing per whitelist
May 13 19:17:10.341: INFO: namespace e2e-tests-pods-25npw deletion completed in 40.412397184s

• [SLOW TEST:45.076 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:17:10.342: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-9jx28
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
May 13 19:17:13.199: INFO: Successfully updated pod "annotationupdateb4e75dfa-75b3-11e9-8f67-2632f168be36"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:17:17.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-9jx28" for this suite.
May 13 19:17:35.301: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:17:35.500: INFO: namespace: e2e-tests-downward-api-9jx28, resource: bindings, ignored listing per whitelist
May 13 19:17:35.549: INFO: namespace e2e-tests-downward-api-9jx28 deletion completed in 18.280846578s

• [SLOW TEST:25.207 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:17:35.550: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-qj5jf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
May 13 19:17:35.819: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-555138423 proxy --unix-socket=/tmp/kubectl-proxy-unix058550378/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:17:35.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-qj5jf" for this suite.
May 13 19:17:41.918: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:17:42.065: INFO: namespace: e2e-tests-kubectl-qj5jf, resource: bindings, ignored listing per whitelist
May 13 19:17:42.281: INFO: namespace e2e-tests-kubectl-qj5jf deletion completed in 6.390768653s

• [SLOW TEST:6.731 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:17:42.282: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-sxt2f
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
May 13 19:17:42.547: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-sxt2f'
May 13 19:17:42.845: INFO: stderr: ""
May 13 19:17:42.845: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
May 13 19:17:47.896: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-sxt2f -o json'
May 13 19:17:48.011: INFO: stderr: ""
May 13 19:17:48.011: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"kubernetes.io/psp\": \"e2e-test-privileged-psp\"\n        },\n        \"creationTimestamp\": \"2019-05-13T19:17:42Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-sxt2f\",\n        \"resourceVersion\": \"40772\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-sxt2f/pods/e2e-test-nginx-pod\",\n        \"uid\": \"c81a14bf-75b3-11e9-8e1a-4ad9c8c454e0\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-fbl5r\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"10.170.219.177\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-fbl5r\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-fbl5r\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-05-13T19:17:42Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-05-13T19:17:44Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-05-13T19:17:44Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-05-13T19:17:42Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://9b14c725dec78eeb6cef878824ae32d03177b624f5042f29d13b6cfc7c683831\",\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imageID\": \"docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-05-13T19:17:44Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.170.219.177\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.30.227.117\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-05-13T19:17:42Z\"\n    }\n}\n"
STEP: replace the image in the pod
May 13 19:17:48.012: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 replace -f - --namespace=e2e-tests-kubectl-sxt2f'
May 13 19:17:48.265: INFO: stderr: ""
May 13 19:17:48.265: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1568
May 13 19:17:48.274: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-sxt2f'
May 13 19:18:01.321: INFO: stderr: ""
May 13 19:18:01.321: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:18:01.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-sxt2f" for this suite.
May 13 19:18:07.376: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:18:07.689: INFO: namespace: e2e-tests-kubectl-sxt2f, resource: bindings, ignored listing per whitelist
May 13 19:18:07.836: INFO: namespace e2e-tests-kubectl-sxt2f deletion completed in 6.491615668s

• [SLOW TEST:25.555 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:18:07.837: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-bnrrz
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
May 13 19:18:08.136: INFO: Waiting up to 5m0s for pod "client-containers-d72dd42a-75b3-11e9-8f67-2632f168be36" in namespace "e2e-tests-containers-bnrrz" to be "success or failure"
May 13 19:18:08.144: INFO: Pod "client-containers-d72dd42a-75b3-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 8.48713ms
May 13 19:18:10.152: INFO: Pod "client-containers-d72dd42a-75b3-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016220531s
STEP: Saw pod success
May 13 19:18:10.152: INFO: Pod "client-containers-d72dd42a-75b3-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 19:18:10.229: INFO: Trying to get logs from node 10.170.219.153 pod client-containers-d72dd42a-75b3-11e9-8f67-2632f168be36 container test-container: <nil>
STEP: delete the pod
May 13 19:18:10.273: INFO: Waiting for pod client-containers-d72dd42a-75b3-11e9-8f67-2632f168be36 to disappear
May 13 19:18:10.280: INFO: Pod client-containers-d72dd42a-75b3-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:18:10.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-bnrrz" for this suite.
May 13 19:18:16.315: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:18:16.512: INFO: namespace: e2e-tests-containers-bnrrz, resource: bindings, ignored listing per whitelist
May 13 19:18:16.587: INFO: namespace e2e-tests-containers-bnrrz deletion completed in 6.299171012s

• [SLOW TEST:8.749 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:18:16.587: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-5nwsq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
May 13 19:18:18.916: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-dc629541-75b3-11e9-8f67-2632f168be36", GenerateName:"", Namespace:"e2e-tests-pods-5nwsq", SelfLink:"/api/v1/namespaces/e2e-tests-pods-5nwsq/pods/pod-submit-remove-dc629541-75b3-11e9-8f67-2632f168be36", UID:"dc657334-75b3-11e9-b786-da20024d205c", ResourceVersion:"40941", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63693371896, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"855487199"}, Annotations:map[string]string{"kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-bqmmt", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001219180), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-bqmmt", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0014c8818), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"10.170.219.177", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001a85aa0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0014c8860)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0014c8bb0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0014c8bb8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0014c8bbc)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693371896, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693371898, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693371898, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693371896, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.170.219.177", PodIP:"172.30.227.123", StartTime:(*v1.Time)(0xc001427a20), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc001427a40), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"docker.io/library/nginx:1.14-alpine", ImageID:"docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7", ContainerID:"containerd://663e0b11eff0a86565118312302ebac94275ab95a73e6e60ca2793cb4671828c"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:18:31.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-5nwsq" for this suite.
May 13 19:18:37.364: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:18:37.558: INFO: namespace: e2e-tests-pods-5nwsq, resource: bindings, ignored listing per whitelist
May 13 19:18:37.660: INFO: namespace e2e-tests-pods-5nwsq deletion completed in 6.324462116s

• [SLOW TEST:21.073 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:18:37.662: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-s5zqc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-e8f4b05c-75b3-11e9-8f67-2632f168be36
STEP: Creating a pod to test consume configMaps
May 13 19:18:37.970: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e8f612b1-75b3-11e9-8f67-2632f168be36" in namespace "e2e-tests-projected-s5zqc" to be "success or failure"
May 13 19:18:37.978: INFO: Pod "pod-projected-configmaps-e8f612b1-75b3-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 8.264931ms
May 13 19:18:39.987: INFO: Pod "pod-projected-configmaps-e8f612b1-75b3-11e9-8f67-2632f168be36": Phase="Running", Reason="", readiness=true. Elapsed: 2.017145147s
May 13 19:18:41.995: INFO: Pod "pod-projected-configmaps-e8f612b1-75b3-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025146902s
STEP: Saw pod success
May 13 19:18:41.995: INFO: Pod "pod-projected-configmaps-e8f612b1-75b3-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 19:18:42.020: INFO: Trying to get logs from node 10.170.219.153 pod pod-projected-configmaps-e8f612b1-75b3-11e9-8f67-2632f168be36 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 13 19:18:42.058: INFO: Waiting for pod pod-projected-configmaps-e8f612b1-75b3-11e9-8f67-2632f168be36 to disappear
May 13 19:18:42.066: INFO: Pod pod-projected-configmaps-e8f612b1-75b3-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:18:42.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-s5zqc" for this suite.
May 13 19:18:48.102: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:18:48.234: INFO: namespace: e2e-tests-projected-s5zqc, resource: bindings, ignored listing per whitelist
May 13 19:18:48.349: INFO: namespace e2e-tests-projected-s5zqc deletion completed in 6.275239784s

• [SLOW TEST:10.688 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:18:48.351: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-kvxxq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 13 19:18:48.775: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"ef65f172-75b3-11e9-b786-da20024d205c", Controller:(*bool)(0xc0024a56c2), BlockOwnerDeletion:(*bool)(0xc0024a56c3)}}
May 13 19:18:48.792: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"ef62af6d-75b3-11e9-b786-da20024d205c", Controller:(*bool)(0xc001958fbe), BlockOwnerDeletion:(*bool)(0xc001958fbf)}}
May 13 19:18:48.800: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"ef6456a6-75b3-11e9-b786-da20024d205c", Controller:(*bool)(0xc0024a58d6), BlockOwnerDeletion:(*bool)(0xc0024a58d7)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:18:53.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-kvxxq" for this suite.
May 13 19:18:59.920: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:19:00.034: INFO: namespace: e2e-tests-gc-kvxxq, resource: bindings, ignored listing per whitelist
May 13 19:19:00.202: INFO: namespace e2e-tests-gc-kvxxq deletion completed in 6.369142013s

• [SLOW TEST:11.851 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:19:00.202: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-prestop-ttdzd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-ttdzd
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-ttdzd
STEP: Deleting pre-stop pod
May 13 19:19:09.585: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:19:09.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-ttdzd" for this suite.
May 13 19:19:49.635: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:19:49.726: INFO: namespace: e2e-tests-prestop-ttdzd, resource: bindings, ignored listing per whitelist
May 13 19:19:49.912: INFO: namespace e2e-tests-prestop-ttdzd deletion completed in 40.305565784s

• [SLOW TEST:49.710 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:19:49.913: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-g862n
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-g862n
May 13 19:19:52.222: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-g862n
STEP: checking the pod's current state and verifying that restartCount is present
May 13 19:19:52.231: INFO: Initial restart count of pod liveness-http is 0
May 13 19:20:10.427: INFO: Restart count of pod e2e-tests-container-probe-g862n/liveness-http is now 1 (18.195996991s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:20:10.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-g862n" for this suite.
May 13 19:20:16.492: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:20:16.708: INFO: namespace: e2e-tests-container-probe-g862n, resource: bindings, ignored listing per whitelist
May 13 19:20:16.753: INFO: namespace e2e-tests-container-probe-g862n deletion completed in 6.289098111s

• [SLOW TEST:26.840 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:20:16.754: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-rkzg7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
May 13 19:20:19.692: INFO: Successfully updated pod "pod-update-2411f5f0-75b4-11e9-8f67-2632f168be36"
STEP: verifying the updated pod is in kubernetes
May 13 19:20:19.711: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:20:19.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-rkzg7" for this suite.
May 13 19:20:43.750: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:20:44.120: INFO: namespace: e2e-tests-pods-rkzg7, resource: bindings, ignored listing per whitelist
May 13 19:20:44.174: INFO: namespace e2e-tests-pods-rkzg7 deletion completed in 24.452672156s

• [SLOW TEST:27.420 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:20:44.175: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-hv9gn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
May 13 19:20:47.098: INFO: Successfully updated pod "annotationupdate345b6358-75b4-11e9-8f67-2632f168be36"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:20:51.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hv9gn" for this suite.
May 13 19:21:13.250: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:21:13.489: INFO: namespace: e2e-tests-projected-hv9gn, resource: bindings, ignored listing per whitelist
May 13 19:21:13.577: INFO: namespace e2e-tests-projected-hv9gn deletion completed in 22.357577399s

• [SLOW TEST:29.403 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:21:13.578: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-wg2mx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-45e38c23-75b4-11e9-8f67-2632f168be36
STEP: Creating a pod to test consume configMaps
May 13 19:21:13.888: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-45e4ecdd-75b4-11e9-8f67-2632f168be36" in namespace "e2e-tests-projected-wg2mx" to be "success or failure"
May 13 19:21:13.896: INFO: Pod "pod-projected-configmaps-45e4ecdd-75b4-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 7.82457ms
May 13 19:21:15.904: INFO: Pod "pod-projected-configmaps-45e4ecdd-75b4-11e9-8f67-2632f168be36": Phase="Running", Reason="", readiness=true. Elapsed: 2.015814573s
May 13 19:21:17.913: INFO: Pod "pod-projected-configmaps-45e4ecdd-75b4-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024391058s
STEP: Saw pod success
May 13 19:21:17.913: INFO: Pod "pod-projected-configmaps-45e4ecdd-75b4-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 19:21:17.922: INFO: Trying to get logs from node 10.170.219.177 pod pod-projected-configmaps-45e4ecdd-75b4-11e9-8f67-2632f168be36 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 13 19:21:17.965: INFO: Waiting for pod pod-projected-configmaps-45e4ecdd-75b4-11e9-8f67-2632f168be36 to disappear
May 13 19:21:17.973: INFO: Pod pod-projected-configmaps-45e4ecdd-75b4-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:21:17.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wg2mx" for this suite.
May 13 19:21:24.012: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:21:24.162: INFO: namespace: e2e-tests-projected-wg2mx, resource: bindings, ignored listing per whitelist
May 13 19:21:24.340: INFO: namespace e2e-tests-projected-wg2mx deletion completed in 6.357017524s

• [SLOW TEST:10.762 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:21:24.340: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-vs5zx
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
May 13 19:21:24.633: INFO: Waiting up to 5m0s for pod "pod-4c4cbc91-75b4-11e9-8f67-2632f168be36" in namespace "e2e-tests-emptydir-vs5zx" to be "success or failure"
May 13 19:21:24.642: INFO: Pod "pod-4c4cbc91-75b4-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 8.572466ms
May 13 19:21:26.650: INFO: Pod "pod-4c4cbc91-75b4-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017402596s
May 13 19:21:28.659: INFO: Pod "pod-4c4cbc91-75b4-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026167806s
STEP: Saw pod success
May 13 19:21:28.659: INFO: Pod "pod-4c4cbc91-75b4-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 19:21:28.666: INFO: Trying to get logs from node 10.170.219.153 pod pod-4c4cbc91-75b4-11e9-8f67-2632f168be36 container test-container: <nil>
STEP: delete the pod
May 13 19:21:28.707: INFO: Waiting for pod pod-4c4cbc91-75b4-11e9-8f67-2632f168be36 to disappear
May 13 19:21:28.714: INFO: Pod pod-4c4cbc91-75b4-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:21:28.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-vs5zx" for this suite.
May 13 19:21:35.021: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:21:35.089: INFO: namespace: e2e-tests-emptydir-vs5zx, resource: bindings, ignored listing per whitelist
May 13 19:21:35.314: INFO: namespace e2e-tests-emptydir-vs5zx deletion completed in 6.593212954s

• [SLOW TEST:10.974 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:21:35.315: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-kd994
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-tp5n
STEP: Creating a pod to test atomic-volume-subpath
May 13 19:21:35.657: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-tp5n" in namespace "e2e-tests-subpath-kd994" to be "success or failure"
May 13 19:21:35.664: INFO: Pod "pod-subpath-test-downwardapi-tp5n": Phase="Pending", Reason="", readiness=false. Elapsed: 7.099253ms
May 13 19:21:37.673: INFO: Pod "pod-subpath-test-downwardapi-tp5n": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015886019s
May 13 19:21:39.682: INFO: Pod "pod-subpath-test-downwardapi-tp5n": Phase="Running", Reason="", readiness=false. Elapsed: 4.024979946s
May 13 19:21:41.690: INFO: Pod "pod-subpath-test-downwardapi-tp5n": Phase="Running", Reason="", readiness=false. Elapsed: 6.032963089s
May 13 19:21:43.713: INFO: Pod "pod-subpath-test-downwardapi-tp5n": Phase="Running", Reason="", readiness=false. Elapsed: 8.055535393s
May 13 19:21:45.721: INFO: Pod "pod-subpath-test-downwardapi-tp5n": Phase="Running", Reason="", readiness=false. Elapsed: 10.063635456s
May 13 19:21:47.729: INFO: Pod "pod-subpath-test-downwardapi-tp5n": Phase="Running", Reason="", readiness=false. Elapsed: 12.07210163s
May 13 19:21:49.738: INFO: Pod "pod-subpath-test-downwardapi-tp5n": Phase="Running", Reason="", readiness=false. Elapsed: 14.080570452s
May 13 19:21:51.747: INFO: Pod "pod-subpath-test-downwardapi-tp5n": Phase="Running", Reason="", readiness=false. Elapsed: 16.090059962s
May 13 19:21:53.768: INFO: Pod "pod-subpath-test-downwardapi-tp5n": Phase="Running", Reason="", readiness=false. Elapsed: 18.111152538s
May 13 19:21:55.777: INFO: Pod "pod-subpath-test-downwardapi-tp5n": Phase="Running", Reason="", readiness=false. Elapsed: 20.119769774s
May 13 19:21:57.785: INFO: Pod "pod-subpath-test-downwardapi-tp5n": Phase="Running", Reason="", readiness=false. Elapsed: 22.128134697s
May 13 19:21:59.794: INFO: Pod "pod-subpath-test-downwardapi-tp5n": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.136487579s
STEP: Saw pod success
May 13 19:21:59.794: INFO: Pod "pod-subpath-test-downwardapi-tp5n" satisfied condition "success or failure"
May 13 19:21:59.801: INFO: Trying to get logs from node 10.170.219.177 pod pod-subpath-test-downwardapi-tp5n container test-container-subpath-downwardapi-tp5n: <nil>
STEP: delete the pod
May 13 19:21:59.842: INFO: Waiting for pod pod-subpath-test-downwardapi-tp5n to disappear
May 13 19:21:59.849: INFO: Pod pod-subpath-test-downwardapi-tp5n no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-tp5n
May 13 19:21:59.849: INFO: Deleting pod "pod-subpath-test-downwardapi-tp5n" in namespace "e2e-tests-subpath-kd994"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:21:59.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-kd994" for this suite.
May 13 19:22:05.894: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:22:06.193: INFO: namespace: e2e-tests-subpath-kd994, resource: bindings, ignored listing per whitelist
May 13 19:22:06.229: INFO: namespace e2e-tests-subpath-kd994 deletion completed in 6.362944079s

• [SLOW TEST:30.915 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:22:06.229: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-r7wt6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 13 19:22:06.511: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:22:08.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-r7wt6" for this suite.
May 13 19:22:58.657: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:22:58.821: INFO: namespace: e2e-tests-pods-r7wt6, resource: bindings, ignored listing per whitelist
May 13 19:22:58.938: INFO: namespace e2e-tests-pods-r7wt6 deletion completed in 50.309356307s

• [SLOW TEST:52.709 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:22:58.939: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-6t4v4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
May 13 19:22:59.224: INFO: PodSpec: initContainers in spec.initContainers
May 13 19:23:48.646: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-84b0a898-75b4-11e9-8f67-2632f168be36", GenerateName:"", Namespace:"e2e-tests-init-container-6t4v4", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-6t4v4/pods/pod-init-84b0a898-75b4-11e9-8f67-2632f168be36", UID:"84b207db-75b4-11e9-b786-da20024d205c", ResourceVersion:"41995", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63693372179, loc:(*time.Location)(0x7b33b80)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"224417083"}, Annotations:map[string]string{"kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-bphlg", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0000c6f80), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-bphlg", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-bphlg", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-bphlg", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc000374018), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"10.170.219.177", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00205e180), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0003740a0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0003740c0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0003740c8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0003740cc)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693372179, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693372179, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693372179, loc:(*time.Location)(0x7b33b80)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63693372179, loc:(*time.Location)(0x7b33b80)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.170.219.177", PodIP:"172.30.227.122", StartTime:(*v1.Time)(0xc001ae00e0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc001ae0140), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0002f1420)}, Ready:false, RestartCount:3, Image:"docker.io/library/busybox:1.29", ImageID:"docker.io/library/busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"containerd://6bffd483ad22fd14260b315773dece31fc3f0e2da84406f6419471c057e2e361"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001ae0160), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001ae0100), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:23:48.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-6t4v4" for this suite.
May 13 19:24:12.772: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:24:12.937: INFO: namespace: e2e-tests-init-container-6t4v4, resource: bindings, ignored listing per whitelist
May 13 19:24:13.068: INFO: namespace e2e-tests-init-container-6t4v4 deletion completed in 24.324635794s

• [SLOW TEST:74.129 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:24:13.068: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-hpsw9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
May 13 19:24:13.355: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 create -f - --namespace=e2e-tests-kubectl-hpsw9'
May 13 19:24:13.705: INFO: stderr: ""
May 13 19:24:13.705: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 13 19:24:13.705: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-hpsw9'
May 13 19:24:13.821: INFO: stderr: ""
May 13 19:24:13.821: INFO: stdout: "update-demo-nautilus-wpr65 update-demo-nautilus-wzhx9 "
May 13 19:24:13.821: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 get pods update-demo-nautilus-wpr65 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hpsw9'
May 13 19:24:13.935: INFO: stderr: ""
May 13 19:24:13.935: INFO: stdout: ""
May 13 19:24:13.936: INFO: update-demo-nautilus-wpr65 is created but not running
May 13 19:24:18.936: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-hpsw9'
May 13 19:24:19.061: INFO: stderr: ""
May 13 19:24:19.061: INFO: stdout: "update-demo-nautilus-wpr65 update-demo-nautilus-wzhx9 "
May 13 19:24:19.061: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 get pods update-demo-nautilus-wpr65 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hpsw9'
May 13 19:24:19.156: INFO: stderr: ""
May 13 19:24:19.156: INFO: stdout: "true"
May 13 19:24:19.156: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 get pods update-demo-nautilus-wpr65 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hpsw9'
May 13 19:24:19.258: INFO: stderr: ""
May 13 19:24:19.258: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 13 19:24:19.258: INFO: validating pod update-demo-nautilus-wpr65
May 13 19:24:19.280: INFO: got data: {
  "image": "nautilus.jpg"
}

May 13 19:24:19.280: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 13 19:24:19.280: INFO: update-demo-nautilus-wpr65 is verified up and running
May 13 19:24:19.280: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 get pods update-demo-nautilus-wzhx9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hpsw9'
May 13 19:24:19.384: INFO: stderr: ""
May 13 19:24:19.384: INFO: stdout: "true"
May 13 19:24:19.384: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 get pods update-demo-nautilus-wzhx9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-hpsw9'
May 13 19:24:19.476: INFO: stderr: ""
May 13 19:24:19.476: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 13 19:24:19.476: INFO: validating pod update-demo-nautilus-wzhx9
May 13 19:24:19.490: INFO: got data: {
  "image": "nautilus.jpg"
}

May 13 19:24:19.490: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 13 19:24:19.490: INFO: update-demo-nautilus-wzhx9 is verified up and running
STEP: using delete to clean up resources
May 13 19:24:19.491: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-hpsw9'
May 13 19:24:19.622: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 13 19:24:19.622: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
May 13 19:24:19.622: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-hpsw9'
May 13 19:24:19.744: INFO: stderr: "No resources found.\n"
May 13 19:24:19.744: INFO: stdout: ""
May 13 19:24:19.744: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 get pods -l name=update-demo --namespace=e2e-tests-kubectl-hpsw9 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 13 19:24:19.850: INFO: stderr: ""
May 13 19:24:19.850: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:24:19.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hpsw9" for this suite.
May 13 19:24:43.894: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:24:44.127: INFO: namespace: e2e-tests-kubectl-hpsw9, resource: bindings, ignored listing per whitelist
May 13 19:24:44.168: INFO: namespace e2e-tests-kubectl-hpsw9 deletion completed in 24.304907253s

• [SLOW TEST:31.100 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:24:44.168: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-wzvrx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
May 13 19:24:44.609: INFO: Waiting up to 5m0s for pod "pod-c36e5381-75b4-11e9-8f67-2632f168be36" in namespace "e2e-tests-emptydir-wzvrx" to be "success or failure"
May 13 19:24:44.620: INFO: Pod "pod-c36e5381-75b4-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 11.309201ms
May 13 19:24:46.636: INFO: Pod "pod-c36e5381-75b4-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027308097s
STEP: Saw pod success
May 13 19:24:46.636: INFO: Pod "pod-c36e5381-75b4-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 19:24:46.644: INFO: Trying to get logs from node 10.170.219.153 pod pod-c36e5381-75b4-11e9-8f67-2632f168be36 container test-container: <nil>
STEP: delete the pod
May 13 19:24:46.689: INFO: Waiting for pod pod-c36e5381-75b4-11e9-8f67-2632f168be36 to disappear
May 13 19:24:46.697: INFO: Pod pod-c36e5381-75b4-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:24:46.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wzvrx" for this suite.
May 13 19:24:52.756: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:24:52.920: INFO: namespace: e2e-tests-emptydir-wzvrx, resource: bindings, ignored listing per whitelist
May 13 19:24:53.099: INFO: namespace e2e-tests-emptydir-wzvrx deletion completed in 6.371071965s

• [SLOW TEST:8.930 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:24:53.101: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-pcn7f
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 13 19:24:53.394: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c8bad340-75b4-11e9-8f67-2632f168be36" in namespace "e2e-tests-downward-api-pcn7f" to be "success or failure"
May 13 19:24:53.406: INFO: Pod "downwardapi-volume-c8bad340-75b4-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 12.538494ms
May 13 19:24:55.426: INFO: Pod "downwardapi-volume-c8bad340-75b4-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.032878373s
STEP: Saw pod success
May 13 19:24:55.426: INFO: Pod "downwardapi-volume-c8bad340-75b4-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 19:24:55.528: INFO: Trying to get logs from node 10.170.219.153 pod downwardapi-volume-c8bad340-75b4-11e9-8f67-2632f168be36 container client-container: <nil>
STEP: delete the pod
May 13 19:24:55.566: INFO: Waiting for pod downwardapi-volume-c8bad340-75b4-11e9-8f67-2632f168be36 to disappear
May 13 19:24:55.573: INFO: Pod downwardapi-volume-c8bad340-75b4-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:24:55.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-pcn7f" for this suite.
May 13 19:25:01.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:25:01.821: INFO: namespace: e2e-tests-downward-api-pcn7f, resource: bindings, ignored listing per whitelist
May 13 19:25:01.879: INFO: namespace e2e-tests-downward-api-pcn7f deletion completed in 6.297084832s

• [SLOW TEST:8.779 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:25:01.880: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-zmx24
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0513 19:25:03.264121      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 13 19:25:03.264: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:25:03.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-zmx24" for this suite.
May 13 19:25:11.302: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:25:11.327: INFO: namespace: e2e-tests-gc-zmx24, resource: bindings, ignored listing per whitelist
May 13 19:25:11.623: INFO: namespace e2e-tests-gc-zmx24 deletion completed in 8.35220014s

• [SLOW TEST:9.743 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:25:11.623: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-events-6m5bj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
May 13 19:25:16.035: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-d3c6b603-75b4-11e9-8f67-2632f168be36,GenerateName:,Namespace:e2e-tests-events-6m5bj,SelfLink:/api/v1/namespaces/e2e-tests-events-6m5bj/pods/send-events-d3c6b603-75b4-11e9-8f67-2632f168be36,UID:d3c84ad6-75b4-11e9-b786-da20024d205c,ResourceVersion:42367,Generation:0,CreationTimestamp:2019-05-13 19:25:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 908922510,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dlbb9 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dlbb9,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-dlbb9 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.153,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001959d80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001959da0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:25:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:25:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:25:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:25:11 +0000 UTC  }],Message:,Reason:,HostIP:10.170.219.153,PodIP:172.30.63.32,StartTime:2019-05-13 19:25:11 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-05-13 19:25:13 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 containerd://6aa1104d809be5bdef34bf1f3d031c1498735350697db8fed51a5967447ab2c0}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
May 13 19:25:18.056: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
May 13 19:25:20.063: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:25:20.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-6m5bj" for this suite.
May 13 19:26:00.119: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:26:00.283: INFO: namespace: e2e-tests-events-6m5bj, resource: bindings, ignored listing per whitelist
May 13 19:26:00.455: INFO: namespace e2e-tests-events-6m5bj deletion completed in 40.368618704s

• [SLOW TEST:48.832 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:26:00.455: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-ltvkg
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-f0e124f8-75b4-11e9-8f67-2632f168be36
STEP: Creating secret with name s-test-opt-upd-f0e1259d-75b4-11e9-8f67-2632f168be36
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-f0e124f8-75b4-11e9-8f67-2632f168be36
STEP: Updating secret s-test-opt-upd-f0e1259d-75b4-11e9-8f67-2632f168be36
STEP: Creating secret with name s-test-opt-create-f0e125bb-75b4-11e9-8f67-2632f168be36
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:26:06.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ltvkg" for this suite.
May 13 19:26:31.055: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:26:31.148: INFO: namespace: e2e-tests-projected-ltvkg, resource: bindings, ignored listing per whitelist
May 13 19:26:31.416: INFO: namespace e2e-tests-projected-ltvkg deletion completed in 24.395774311s

• [SLOW TEST:30.961 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:26:31.416: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-pbwqd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-0358efbb-75b5-11e9-8f67-2632f168be36
STEP: Creating a pod to test consume secrets
May 13 19:26:31.746: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-035a6934-75b5-11e9-8f67-2632f168be36" in namespace "e2e-tests-projected-pbwqd" to be "success or failure"
May 13 19:26:31.757: INFO: Pod "pod-projected-secrets-035a6934-75b5-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 10.657002ms
May 13 19:26:33.766: INFO: Pod "pod-projected-secrets-035a6934-75b5-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018988086s
STEP: Saw pod success
May 13 19:26:33.766: INFO: Pod "pod-projected-secrets-035a6934-75b5-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 19:26:33.773: INFO: Trying to get logs from node 10.170.219.153 pod pod-projected-secrets-035a6934-75b5-11e9-8f67-2632f168be36 container projected-secret-volume-test: <nil>
STEP: delete the pod
May 13 19:26:33.919: INFO: Waiting for pod pod-projected-secrets-035a6934-75b5-11e9-8f67-2632f168be36 to disappear
May 13 19:26:33.930: INFO: Pod pod-projected-secrets-035a6934-75b5-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:26:33.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pbwqd" for this suite.
May 13 19:26:39.969: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:26:40.108: INFO: namespace: e2e-tests-projected-pbwqd, resource: bindings, ignored listing per whitelist
May 13 19:26:40.398: INFO: namespace e2e-tests-projected-pbwqd deletion completed in 6.459401889s

• [SLOW TEST:8.982 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:26:40.398: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-k454t
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:26:42.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-k454t" for this suite.
May 13 19:27:22.794: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:27:22.891: INFO: namespace: e2e-tests-kubelet-test-k454t, resource: bindings, ignored listing per whitelist
May 13 19:27:23.121: INFO: namespace e2e-tests-kubelet-test-k454t deletion completed in 40.373193837s

• [SLOW TEST:42.723 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:27:23.121: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-mlsk9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-2230bb2b-75b5-11e9-8f67-2632f168be36
STEP: Creating a pod to test consume secrets
May 13 19:27:23.496: INFO: Waiting up to 5m0s for pod "pod-secrets-2233238d-75b5-11e9-8f67-2632f168be36" in namespace "e2e-tests-secrets-mlsk9" to be "success or failure"
May 13 19:27:23.504: INFO: Pod "pod-secrets-2233238d-75b5-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 7.176266ms
May 13 19:27:25.513: INFO: Pod "pod-secrets-2233238d-75b5-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016238406s
STEP: Saw pod success
May 13 19:27:25.513: INFO: Pod "pod-secrets-2233238d-75b5-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 19:27:25.520: INFO: Trying to get logs from node 10.170.219.153 pod pod-secrets-2233238d-75b5-11e9-8f67-2632f168be36 container secret-volume-test: <nil>
STEP: delete the pod
May 13 19:27:25.820: INFO: Waiting for pod pod-secrets-2233238d-75b5-11e9-8f67-2632f168be36 to disappear
May 13 19:27:25.827: INFO: Pod pod-secrets-2233238d-75b5-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:27:25.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-mlsk9" for this suite.
May 13 19:27:31.866: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:27:31.921: INFO: namespace: e2e-tests-secrets-mlsk9, resource: bindings, ignored listing per whitelist
May 13 19:27:32.152: INFO: namespace e2e-tests-secrets-mlsk9 deletion completed in 6.316469901s

• [SLOW TEST:9.032 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:27:32.154: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-r9jsz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 13 19:27:32.418: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 version'
May 13 19:27:32.508: INFO: stderr: ""
May 13 19:27:32.508: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.0\", GitCommit:\"ddf47ac13c1a9483ea035a79cd7c10005ff21a6d\", GitTreeState:\"clean\", BuildDate:\"2018-12-03T21:04:45Z\", GoVersion:\"go1.11.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"13\", GitVersion:\"v1.13.6+IKS\", GitCommit:\"ac5f7341d5d0ce8ea8f206ba5b030dc9e9d4cc97\", GitTreeState:\"clean\", BuildDate:\"2019-05-09T13:26:51Z\", GoVersion:\"go1.11.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:27:32.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-r9jsz" for this suite.
May 13 19:27:38.548: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:27:38.640: INFO: namespace: e2e-tests-kubectl-r9jsz, resource: bindings, ignored listing per whitelist
May 13 19:27:38.871: INFO: namespace e2e-tests-kubectl-r9jsz deletion completed in 6.355745814s

• [SLOW TEST:6.717 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:27:38.871: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-8s6zb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-8s6zb
May 13 19:27:41.171: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-8s6zb
STEP: checking the pod's current state and verifying that restartCount is present
May 13 19:27:41.179: INFO: Initial restart count of pod liveness-http is 0
May 13 19:27:55.273: INFO: Restart count of pod e2e-tests-container-probe-8s6zb/liveness-http is now 1 (14.093476926s elapsed)
May 13 19:28:15.386: INFO: Restart count of pod e2e-tests-container-probe-8s6zb/liveness-http is now 2 (34.207046824s elapsed)
May 13 19:28:35.962: INFO: Restart count of pod e2e-tests-container-probe-8s6zb/liveness-http is now 3 (54.782986412s elapsed)
May 13 19:28:56.073: INFO: Restart count of pod e2e-tests-container-probe-8s6zb/liveness-http is now 4 (1m14.893546281s elapsed)
May 13 19:29:54.982: INFO: Restart count of pod e2e-tests-container-probe-8s6zb/liveness-http is now 5 (2m13.80255479s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:29:55.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-8s6zb" for this suite.
May 13 19:30:01.045: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:30:01.294: INFO: namespace: e2e-tests-container-probe-8s6zb, resource: bindings, ignored listing per whitelist
May 13 19:30:01.342: INFO: namespace e2e-tests-container-probe-8s6zb deletion completed in 6.324745553s

• [SLOW TEST:142.471 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:30:01.344: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-trswb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
May 13 19:30:01.737: INFO: Waiting up to 5m0s for pod "pod-80846756-75b5-11e9-8f67-2632f168be36" in namespace "e2e-tests-emptydir-trswb" to be "success or failure"
May 13 19:30:01.744: INFO: Pod "pod-80846756-75b5-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 7.796949ms
May 13 19:30:03.753: INFO: Pod "pod-80846756-75b5-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016090026s
STEP: Saw pod success
May 13 19:30:03.753: INFO: Pod "pod-80846756-75b5-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 19:30:03.760: INFO: Trying to get logs from node 10.170.219.153 pod pod-80846756-75b5-11e9-8f67-2632f168be36 container test-container: <nil>
STEP: delete the pod
May 13 19:30:03.880: INFO: Waiting for pod pod-80846756-75b5-11e9-8f67-2632f168be36 to disappear
May 13 19:30:03.887: INFO: Pod pod-80846756-75b5-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:30:03.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-trswb" for this suite.
May 13 19:30:09.923: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:30:10.189: INFO: namespace: e2e-tests-emptydir-trswb, resource: bindings, ignored listing per whitelist
May 13 19:30:10.206: INFO: namespace e2e-tests-emptydir-trswb deletion completed in 6.311474267s

• [SLOW TEST:8.862 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:30:10.206: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-5d84j
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
May 13 19:30:10.464: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May 13 19:30:10.478: INFO: Waiting for terminating namespaces to be deleted...
May 13 19:30:10.485: INFO: 
Logging pods the kubelet thinks is on node 10.170.219.151 before test
May 13 19:30:10.537: INFO: public-cr0ef1a5f1e33c44fe9c21650356d908ee-alb1-8f59cf484-9v5pm from kube-system started at 2019-05-13 16:35:03 +0000 UTC (4 container statuses recorded)
May 13 19:30:10.537: INFO: 	Container ingress-auth-1 ready: true, restart count 0
May 13 19:30:10.537: INFO: 	Container ingress-auth-2 ready: true, restart count 0
May 13 19:30:10.537: INFO: 	Container ingress-auth-3 ready: true, restart count 0
May 13 19:30:10.537: INFO: 	Container nginx-ingress ready: true, restart count 0
May 13 19:30:10.537: INFO: ibm-master-proxy-static-10.170.219.151 from kube-system started at <nil> (0 container statuses recorded)
May 13 19:30:10.537: INFO: calico-kube-controllers-7dd978d898-r8w74 from kube-system started at 2019-05-13 16:27:35 +0000 UTC (1 container statuses recorded)
May 13 19:30:10.537: INFO: 	Container calico-kube-controllers ready: true, restart count 0
May 13 19:30:10.537: INFO: ibm-keepalived-watcher-8wshf from kube-system started at 2019-05-13 16:27:05 +0000 UTC (1 container statuses recorded)
May 13 19:30:10.537: INFO: 	Container keepalived-watcher ready: true, restart count 0
May 13 19:30:10.537: INFO: coredns-58d696879-rrkth from kube-system started at 2019-05-13 16:27:35 +0000 UTC (1 container statuses recorded)
May 13 19:30:10.537: INFO: 	Container coredns ready: true, restart count 0
May 13 19:30:10.537: INFO: ibm-file-plugin-7f6d8979bd-p5smn from kube-system started at 2019-05-13 16:27:35 +0000 UTC (1 container statuses recorded)
May 13 19:30:10.537: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
May 13 19:30:10.537: INFO: coredns-58d696879-zmj2g from kube-system started at 2019-05-13 16:27:49 +0000 UTC (1 container statuses recorded)
May 13 19:30:10.537: INFO: 	Container coredns ready: true, restart count 0
May 13 19:30:10.537: INFO: calico-node-d9d6s from kube-system started at 2019-05-13 16:27:05 +0000 UTC (1 container statuses recorded)
May 13 19:30:10.537: INFO: 	Container calico-node ready: true, restart count 0
May 13 19:30:10.537: INFO: vpn-774cf5c6d4-6p6cr from kube-system started at 2019-05-13 16:27:35 +0000 UTC (1 container statuses recorded)
May 13 19:30:10.537: INFO: 	Container vpn ready: true, restart count 0
May 13 19:30:10.537: INFO: kubernetes-dashboard-7996b848f4-mzbwj from kube-system started at 2019-05-13 16:27:35 +0000 UTC (1 container statuses recorded)
May 13 19:30:10.537: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
May 13 19:30:10.537: INFO: ibm-kube-fluentd-6fw9c from kube-system started at 2019-05-13 16:32:50 +0000 UTC (1 container statuses recorded)
May 13 19:30:10.537: INFO: 	Container fluentd ready: true, restart count 0
May 13 19:30:10.537: INFO: sonobuoy-systemd-logs-daemon-set-8e5ce9bdf4a94ece-nlv42 from heptio-sonobuoy started at 2019-05-13 18:40:58 +0000 UTC (2 container statuses recorded)
May 13 19:30:10.537: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 13 19:30:10.537: INFO: 	Container systemd-logs ready: true, restart count 0
May 13 19:30:10.537: INFO: ibm-storage-watcher-845946d5b5-knxcm from kube-system started at 2019-05-13 16:27:35 +0000 UTC (1 container statuses recorded)
May 13 19:30:10.537: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
May 13 19:30:10.537: INFO: coredns-autoscaler-64f9c5b4df-hzq57 from kube-system started at 2019-05-13 16:27:35 +0000 UTC (1 container statuses recorded)
May 13 19:30:10.537: INFO: 	Container autoscaler ready: true, restart count 0
May 13 19:30:10.537: INFO: 
Logging pods the kubelet thinks is on node 10.170.219.153 before test
May 13 19:30:10.591: INFO: calico-node-phw8q from kube-system started at 2019-05-13 16:27:29 +0000 UTC (1 container statuses recorded)
May 13 19:30:10.591: INFO: 	Container calico-node ready: true, restart count 0
May 13 19:30:10.591: INFO: ibm-cloud-provider-ip-169-45-218-130-66c489dcb-z58z4 from ibm-system started at 2019-05-13 16:30:08 +0000 UTC (1 container statuses recorded)
May 13 19:30:10.591: INFO: 	Container ibm-cloud-provider-ip-169-45-218-130 ready: true, restart count 0
May 13 19:30:10.591: INFO: ibm-kube-fluentd-cdmr5 from kube-system started at 2019-05-13 16:32:50 +0000 UTC (1 container statuses recorded)
May 13 19:30:10.591: INFO: 	Container fluentd ready: true, restart count 0
May 13 19:30:10.591: INFO: sonobuoy from heptio-sonobuoy started at 2019-05-13 18:40:57 +0000 UTC (1 container statuses recorded)
May 13 19:30:10.591: INFO: 	Container kube-sonobuoy ready: true, restart count 0
May 13 19:30:10.591: INFO: metrics-server-58dd96c6bd-sggps from kube-system started at 2019-05-13 16:28:04 +0000 UTC (2 container statuses recorded)
May 13 19:30:10.591: INFO: 	Container metrics-server ready: true, restart count 0
May 13 19:30:10.591: INFO: 	Container metrics-server-nanny ready: true, restart count 0
May 13 19:30:10.591: INFO: test-k8s-e2e-pvg-master-verification from default started at 2019-05-13 18:40:52 +0000 UTC (1 container statuses recorded)
May 13 19:30:10.591: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
May 13 19:30:10.591: INFO: sonobuoy-systemd-logs-daemon-set-8e5ce9bdf4a94ece-tgp2l from heptio-sonobuoy started at 2019-05-13 18:40:58 +0000 UTC (2 container statuses recorded)
May 13 19:30:10.591: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 13 19:30:10.591: INFO: 	Container systemd-logs ready: true, restart count 0
May 13 19:30:10.591: INFO: ibm-master-proxy-static-10.170.219.153 from kube-system started at <nil> (0 container statuses recorded)
May 13 19:30:10.591: INFO: ibm-keepalived-watcher-cwtfg from kube-system started at 2019-05-13 16:27:29 +0000 UTC (1 container statuses recorded)
May 13 19:30:10.591: INFO: 	Container keepalived-watcher ready: true, restart count 0
May 13 19:30:10.591: INFO: 
Logging pods the kubelet thinks is on node 10.170.219.177 before test
May 13 19:30:10.613: INFO: ibm-keepalived-watcher-qszvz from kube-system started at 2019-05-13 16:27:34 +0000 UTC (1 container statuses recorded)
May 13 19:30:10.613: INFO: 	Container keepalived-watcher ready: true, restart count 0
May 13 19:30:10.613: INFO: calico-node-twx7l from kube-system started at 2019-05-13 16:27:34 +0000 UTC (1 container statuses recorded)
May 13 19:30:10.613: INFO: 	Container calico-node ready: true, restart count 0
May 13 19:30:10.613: INFO: ibm-master-proxy-static-10.170.219.177 from kube-system started at <nil> (0 container statuses recorded)
May 13 19:30:10.613: INFO: public-cr0ef1a5f1e33c44fe9c21650356d908ee-alb1-8f59cf484-7r5vq from kube-system started at 2019-05-13 16:35:03 +0000 UTC (4 container statuses recorded)
May 13 19:30:10.613: INFO: 	Container ingress-auth-1 ready: true, restart count 0
May 13 19:30:10.613: INFO: 	Container ingress-auth-2 ready: true, restart count 0
May 13 19:30:10.613: INFO: 	Container ingress-auth-3 ready: true, restart count 0
May 13 19:30:10.613: INFO: 	Container nginx-ingress ready: true, restart count 0
May 13 19:30:10.613: INFO: ibm-cloud-provider-ip-169-45-218-130-66c489dcb-kd74s from ibm-system started at 2019-05-13 16:30:08 +0000 UTC (1 container statuses recorded)
May 13 19:30:10.613: INFO: 	Container ibm-cloud-provider-ip-169-45-218-130 ready: true, restart count 0
May 13 19:30:10.613: INFO: sonobuoy-e2e-job-afa7e83446444f4e from heptio-sonobuoy started at 2019-05-13 18:40:58 +0000 UTC (2 container statuses recorded)
May 13 19:30:10.613: INFO: 	Container e2e ready: true, restart count 0
May 13 19:30:10.613: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 13 19:30:10.613: INFO: ibm-kube-fluentd-zzl5d from kube-system started at 2019-05-13 16:32:50 +0000 UTC (1 container statuses recorded)
May 13 19:30:10.613: INFO: 	Container fluentd ready: true, restart count 0
May 13 19:30:10.613: INFO: sonobuoy-systemd-logs-daemon-set-8e5ce9bdf4a94ece-kjc69 from heptio-sonobuoy started at 2019-05-13 18:40:58 +0000 UTC (2 container statuses recorded)
May 13 19:30:10.613: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 13 19:30:10.613: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-870c4b7d-75b5-11e9-8f67-2632f168be36 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-870c4b7d-75b5-11e9-8f67-2632f168be36 off the node 10.170.219.177
STEP: verifying the node doesn't have the label kubernetes.io/e2e-870c4b7d-75b5-11e9-8f67-2632f168be36
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:30:14.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-5d84j" for this suite.
May 13 19:30:36.860: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:30:36.933: INFO: namespace: e2e-tests-sched-pred-5d84j, resource: bindings, ignored listing per whitelist
May 13 19:30:37.153: INFO: namespace e2e-tests-sched-pred-5d84j deletion completed in 22.320040485s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:26.947 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:30:37.153: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-27hkk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
May 13 19:30:40.021: INFO: Successfully updated pod "labelsupdate95d01c4f-75b5-11e9-8f67-2632f168be36"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:30:42.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-27hkk" for this suite.
May 13 19:31:06.108: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:31:06.197: INFO: namespace: e2e-tests-projected-27hkk, resource: bindings, ignored listing per whitelist
May 13 19:31:06.358: INFO: namespace e2e-tests-projected-27hkk deletion completed in 24.277945764s

• [SLOW TEST:29.205 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:31:06.358: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-qt79p
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
May 13 19:31:13.296: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 13 19:31:13.307: INFO: Pod pod-with-poststart-http-hook still exists
May 13 19:31:15.307: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 13 19:31:15.327: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:31:15.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-qt79p" for this suite.
May 13 19:31:39.449: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:31:39.750: INFO: namespace: e2e-tests-container-lifecycle-hook-qt79p, resource: bindings, ignored listing per whitelist
May 13 19:31:39.758: INFO: namespace e2e-tests-container-lifecycle-hook-qt79p deletion completed in 24.422294059s

• [SLOW TEST:33.400 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:31:39.759: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-27brj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 13 19:31:40.122: INFO: Creating deployment "nginx-deployment"
May 13 19:31:40.129: INFO: Waiting for observed generation 1
May 13 19:31:42.140: INFO: Waiting for all required pods to come up
May 13 19:31:42.150: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
May 13 19:31:46.181: INFO: Waiting for deployment "nginx-deployment" to complete
May 13 19:31:46.194: INFO: Updating deployment "nginx-deployment" with a non-existent image
May 13 19:31:46.219: INFO: Updating deployment nginx-deployment
May 13 19:31:46.219: INFO: Waiting for observed generation 2
May 13 19:31:48.459: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
May 13 19:31:48.466: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
May 13 19:31:48.474: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
May 13 19:31:48.499: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
May 13 19:31:48.499: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
May 13 19:31:48.508: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
May 13 19:31:48.524: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
May 13 19:31:48.524: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
May 13 19:31:48.538: INFO: Updating deployment nginx-deployment
May 13 19:31:48.538: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
May 13 19:31:48.553: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
May 13 19:31:48.561: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May 13 19:31:48.576: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-27brj,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-27brj/deployments/nginx-deployment,UID:bb2bea6a-75b5-11e9-b786-da20024d205c,ResourceVersion:43766,Generation:3,CreationTimestamp:2019-05-13 19:31:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[{Progressing True 2019-05-13 19:31:46 +0000 UTC 2019-05-13 19:31:40 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-65bbdb5f8" is progressing.} {Available False 2019-05-13 19:31:48 +0000 UTC 2019-05-13 19:31:48 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}],ReadyReplicas:8,CollisionCount:nil,},}

May 13 19:31:48.595: INFO: New ReplicaSet "nginx-deployment-65bbdb5f8" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8,GenerateName:,Namespace:e2e-tests-deployment-27brj,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-27brj/replicasets/nginx-deployment-65bbdb5f8,UID:becc99fe-75b5-11e9-83a8-7e0242378207,ResourceVersion:43759,Generation:3,CreationTimestamp:2019-05-13 19:31:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment bb2bea6a-75b5-11e9-b786-da20024d205c 0xc0024bcbf7 0xc0024bcbf8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 13 19:31:48.595: INFO: All old ReplicaSets of Deployment "nginx-deployment":
May 13 19:31:48.595: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965,GenerateName:,Namespace:e2e-tests-deployment-27brj,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-27brj/replicasets/nginx-deployment-555b55d965,UID:bb2fe888-75b5-11e9-83a8-7e0242378207,ResourceVersion:43757,Generation:3,CreationTimestamp:2019-05-13 19:31:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment bb2bea6a-75b5-11e9-b786-da20024d205c 0xc0024bcb37 0xc0024bcb38}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
May 13 19:31:48.612: INFO: Pod "nginx-deployment-555b55d965-2998d" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-2998d,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-27brj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-27brj/pods/nginx-deployment-555b55d965-2998d,UID:bb36a0f5-75b5-11e9-83a8-7e0242378207,ResourceVersion:43603,Generation:0,CreationTimestamp:2019-05-13 19:31:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bb2fe888-75b5-11e9-83a8-7e0242378207 0xc0024bd6f7 0xc0024bd6f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8bx99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8bx99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8bx99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.177,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024bd770} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024bd790}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:40 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:41 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:41 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:40 +0000 UTC  }],Message:,Reason:,HostIP:10.170.219.177,PodIP:172.30.227.76,StartTime:2019-05-13 19:31:40 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-13 19:31:41 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://7eede40d812d0deb8826a0e9e1bac88ecea438993e290cead47e5d038c83d6cd}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:31:48.612: INFO: Pod "nginx-deployment-555b55d965-554km" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-554km,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-27brj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-27brj/pods/nginx-deployment-555b55d965-554km,UID:bb3510f5-75b5-11e9-83a8-7e0242378207,ResourceVersion:43629,Generation:0,CreationTimestamp:2019-05-13 19:31:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bb2fe888-75b5-11e9-83a8-7e0242378207 0xc0024bd917 0xc0024bd918}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8bx99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8bx99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8bx99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.153,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024bd990} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024bd9b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:40 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:42 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:42 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:40 +0000 UTC  }],Message:,Reason:,HostIP:10.170.219.153,PodIP:172.30.63.2,StartTime:2019-05-13 19:31:40 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-13 19:31:41 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://e496a86f07680649c7c9b7bce3edf1537dd7d74f4f6e36b43a7a28db1d35d6f0}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:31:48.612: INFO: Pod "nginx-deployment-555b55d965-77phz" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-77phz,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-27brj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-27brj/pods/nginx-deployment-555b55d965-77phz,UID:bb37b3cc-75b5-11e9-83a8-7e0242378207,ResourceVersion:43618,Generation:0,CreationTimestamp:2019-05-13 19:31:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bb2fe888-75b5-11e9-83a8-7e0242378207 0xc0024bdad0 0xc0024bdad1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8bx99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8bx99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8bx99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.151,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024bdb40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024bdb60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:40 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:41 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:41 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:40 +0000 UTC  }],Message:,Reason:,HostIP:10.170.219.151,PodIP:172.30.19.103,StartTime:2019-05-13 19:31:40 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-13 19:31:41 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://d52e1267c9f87b0ce7ce5c0397d2b9df2617018b6fe1b09b719a238095ce30a7}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:31:48.612: INFO: Pod "nginx-deployment-555b55d965-86wd9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-86wd9,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-27brj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-27brj/pods/nginx-deployment-555b55d965-86wd9,UID:bb365f9f-75b5-11e9-83a8-7e0242378207,ResourceVersion:43641,Generation:0,CreationTimestamp:2019-05-13 19:31:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bb2fe888-75b5-11e9-83a8-7e0242378207 0xc0024bdc77 0xc0024bdc78}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8bx99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8bx99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8bx99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.153,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024bdcf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024bdd10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:40 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:42 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:42 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:40 +0000 UTC  }],Message:,Reason:,HostIP:10.170.219.153,PodIP:172.30.63.3,StartTime:2019-05-13 19:31:40 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-13 19:31:41 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://24ecc598cf97f6ab2180a5008e310f335710ca8d55185c3566b55ea24f227d71}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:31:48.612: INFO: Pod "nginx-deployment-555b55d965-92zkd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-92zkd,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-27brj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-27brj/pods/nginx-deployment-555b55d965-92zkd,UID:c035f44d-75b5-11e9-83a8-7e0242378207,ResourceVersion:43799,Generation:0,CreationTimestamp:2019-05-13 19:31:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bb2fe888-75b5-11e9-83a8-7e0242378207 0xc0024bddd0 0xc0024bddd1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8bx99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8bx99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8bx99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.177,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024bde40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024bde60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:48 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:31:48.612: INFO: Pod "nginx-deployment-555b55d965-cpftm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-cpftm,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-27brj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-27brj/pods/nginx-deployment-555b55d965-cpftm,UID:c03478e3-75b5-11e9-83a8-7e0242378207,ResourceVersion:43779,Generation:0,CreationTimestamp:2019-05-13 19:31:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bb2fe888-75b5-11e9-83a8-7e0242378207 0xc0024bdf50 0xc0024bdf51}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8bx99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8bx99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8bx99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.151,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024bdfc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024bdfe0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:48 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:31:48.612: INFO: Pod "nginx-deployment-555b55d965-h26p8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-h26p8,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-27brj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-27brj/pods/nginx-deployment-555b55d965-h26p8,UID:c035fc70-75b5-11e9-83a8-7e0242378207,ResourceVersion:43802,Generation:0,CreationTimestamp:2019-05-13 19:31:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bb2fe888-75b5-11e9-83a8-7e0242378207 0xc002378050 0xc002378051}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8bx99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8bx99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8bx99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.177,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002378130} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002378150}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:48 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:31:48.612: INFO: Pod "nginx-deployment-555b55d965-hf268" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-hf268,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-27brj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-27brj/pods/nginx-deployment-555b55d965-hf268,UID:c0348611-75b5-11e9-83a8-7e0242378207,ResourceVersion:43781,Generation:0,CreationTimestamp:2019-05-13 19:31:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bb2fe888-75b5-11e9-83a8-7e0242378207 0xc0023781c0 0xc0023781c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8bx99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8bx99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8bx99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.177,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002378230} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002378250}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:48 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:31:48.613: INFO: Pod "nginx-deployment-555b55d965-hqh7q" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-hqh7q,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-27brj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-27brj/pods/nginx-deployment-555b55d965-hqh7q,UID:bb367dac-75b5-11e9-83a8-7e0242378207,ResourceVersion:43638,Generation:0,CreationTimestamp:2019-05-13 19:31:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bb2fe888-75b5-11e9-83a8-7e0242378207 0xc0023782d0 0xc0023782d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8bx99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8bx99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8bx99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.153,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002378350} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002378370}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:40 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:42 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:42 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:40 +0000 UTC  }],Message:,Reason:,HostIP:10.170.219.153,PodIP:172.30.63.41,StartTime:2019-05-13 19:31:40 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-13 19:31:41 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://f6f22defecf54564328f141fffe2a8451f15abb9444065d3bf16e4719e64a47e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:31:48.613: INFO: Pod "nginx-deployment-555b55d965-k2fgw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-k2fgw,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-27brj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-27brj/pods/nginx-deployment-555b55d965-k2fgw,UID:c0319682-75b5-11e9-83a8-7e0242378207,ResourceVersion:43787,Generation:0,CreationTimestamp:2019-05-13 19:31:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bb2fe888-75b5-11e9-83a8-7e0242378207 0xc0023784a7 0xc0023784a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8bx99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8bx99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8bx99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.151,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002378520} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002378540}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:48 +0000 UTC  }],Message:,Reason:,HostIP:10.170.219.151,PodIP:,StartTime:2019-05-13 19:31:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:31:48.613: INFO: Pod "nginx-deployment-555b55d965-kbxp8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-kbxp8,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-27brj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-27brj/pods/nginx-deployment-555b55d965-kbxp8,UID:c0330026-75b5-11e9-83a8-7e0242378207,ResourceVersion:43810,Generation:0,CreationTimestamp:2019-05-13 19:31:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bb2fe888-75b5-11e9-83a8-7e0242378207 0xc0023785f7 0xc0023785f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8bx99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8bx99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8bx99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.153,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002378720} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002378740}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:48 +0000 UTC  }],Message:,Reason:,HostIP:10.170.219.153,PodIP:,StartTime:2019-05-13 19:31:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:31:48.613: INFO: Pod "nginx-deployment-555b55d965-mkm2v" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-mkm2v,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-27brj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-27brj/pods/nginx-deployment-555b55d965-mkm2v,UID:bb366f28-75b5-11e9-83a8-7e0242378207,ResourceVersion:43600,Generation:0,CreationTimestamp:2019-05-13 19:31:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bb2fe888-75b5-11e9-83a8-7e0242378207 0xc0023787f7 0xc0023787f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8bx99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8bx99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8bx99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.177,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002378870} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002378890}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:40 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:41 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:41 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:40 +0000 UTC  }],Message:,Reason:,HostIP:10.170.219.177,PodIP:172.30.227.74,StartTime:2019-05-13 19:31:40 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-13 19:31:41 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://040875ef68a06abcb48a80991443b1312ff3853ce715e7426947ff70bae2a9d7}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:31:48.613: INFO: Pod "nginx-deployment-555b55d965-mwqd7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-mwqd7,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-27brj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-27brj/pods/nginx-deployment-555b55d965-mwqd7,UID:c0347ba3-75b5-11e9-83a8-7e0242378207,ResourceVersion:43788,Generation:0,CreationTimestamp:2019-05-13 19:31:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bb2fe888-75b5-11e9-83a8-7e0242378207 0xc002378957 0xc002378958}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8bx99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8bx99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8bx99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.153,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0023789d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0023789f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:48 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:31:48.613: INFO: Pod "nginx-deployment-555b55d965-nqkw2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-nqkw2,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-27brj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-27brj/pods/nginx-deployment-555b55d965-nqkw2,UID:c035eaac-75b5-11e9-83a8-7e0242378207,ResourceVersion:43796,Generation:0,CreationTimestamp:2019-05-13 19:31:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bb2fe888-75b5-11e9-83a8-7e0242378207 0xc002378a60 0xc002378a61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8bx99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8bx99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8bx99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.151,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002378ad0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002378ba0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:48 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:31:48.613: INFO: Pod "nginx-deployment-555b55d965-q6f9l" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-q6f9l,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-27brj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-27brj/pods/nginx-deployment-555b55d965-q6f9l,UID:c03323cc-75b5-11e9-83a8-7e0242378207,ResourceVersion:43770,Generation:0,CreationTimestamp:2019-05-13 19:31:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bb2fe888-75b5-11e9-83a8-7e0242378207 0xc002378c10 0xc002378c11}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8bx99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8bx99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8bx99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.153,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002378c80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002378ca0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:48 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:31:48.614: INFO: Pod "nginx-deployment-555b55d965-w5fzl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-w5fzl,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-27brj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-27brj/pods/nginx-deployment-555b55d965-w5fzl,UID:c035fbd2-75b5-11e9-83a8-7e0242378207,ResourceVersion:43798,Generation:0,CreationTimestamp:2019-05-13 19:31:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bb2fe888-75b5-11e9-83a8-7e0242378207 0xc002378d10 0xc002378d11}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8bx99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8bx99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8bx99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.153,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002378d80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002378da0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:48 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:31:48.614: INFO: Pod "nginx-deployment-555b55d965-wttt7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-wttt7,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-27brj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-27brj/pods/nginx-deployment-555b55d965-wttt7,UID:c0360ab2-75b5-11e9-83a8-7e0242378207,ResourceVersion:43801,Generation:0,CreationTimestamp:2019-05-13 19:31:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bb2fe888-75b5-11e9-83a8-7e0242378207 0xc002378f50 0xc002378f51}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8bx99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8bx99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8bx99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.151,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002378fc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002378fe0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:48 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:31:48.614: INFO: Pod "nginx-deployment-555b55d965-wx87v" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-wx87v,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-27brj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-27brj/pods/nginx-deployment-555b55d965-wx87v,UID:bb351315-75b5-11e9-83a8-7e0242378207,ResourceVersion:43622,Generation:0,CreationTimestamp:2019-05-13 19:31:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bb2fe888-75b5-11e9-83a8-7e0242378207 0xc002379050 0xc002379051}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8bx99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8bx99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8bx99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.151,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0023790c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0023790e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:40 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:41 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:41 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:40 +0000 UTC  }],Message:,Reason:,HostIP:10.170.219.151,PodIP:172.30.19.101,StartTime:2019-05-13 19:31:40 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-13 19:31:41 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://b69cffd9aaf4c232a491edc3c82dba290b8d4e7052105728422a6a300694cd72}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:31:48.614: INFO: Pod "nginx-deployment-555b55d965-z8nk6" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-z8nk6,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-27brj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-27brj/pods/nginx-deployment-555b55d965-z8nk6,UID:bb33ed79-75b5-11e9-83a8-7e0242378207,ResourceVersion:43607,Generation:0,CreationTimestamp:2019-05-13 19:31:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bb2fe888-75b5-11e9-83a8-7e0242378207 0xc002379287 0xc002379288}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8bx99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8bx99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8bx99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.177,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002379300} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002379320}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:40 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:41 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:41 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:40 +0000 UTC  }],Message:,Reason:,HostIP:10.170.219.177,PodIP:172.30.227.72,StartTime:2019-05-13 19:31:40 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-05-13 19:31:41 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 containerd://4b1fdb1470f6529e8c0ae942ba88238295c45254ac43817136ce6a428cc4180c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:31:48.614: INFO: Pod "nginx-deployment-555b55d965-zpzld" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-555b55d965-zpzld,GenerateName:nginx-deployment-555b55d965-,Namespace:e2e-tests-deployment-27brj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-27brj/pods/nginx-deployment-555b55d965-zpzld,UID:c03488a0-75b5-11e9-83a8-7e0242378207,ResourceVersion:43786,Generation:0,CreationTimestamp:2019-05-13 19:31:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 555b55d965,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-555b55d965 bb2fe888-75b5-11e9-83a8-7e0242378207 0xc0023793e7 0xc0023793e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8bx99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8bx99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-8bx99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.177,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0023794c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0023794e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:48 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:31:48.614: INFO: Pod "nginx-deployment-65bbdb5f8-4xbfd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-4xbfd,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-27brj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-27brj/pods/nginx-deployment-65bbdb5f8-4xbfd,UID:c0367776-75b5-11e9-83a8-7e0242378207,ResourceVersion:43805,Generation:0,CreationTimestamp:2019-05-13 19:31:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 becc99fe-75b5-11e9-83a8-7e0242378207 0xc002379580 0xc002379581}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8bx99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8bx99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8bx99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.151,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002379600} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002379620}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:48 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:31:48.614: INFO: Pod "nginx-deployment-65bbdb5f8-6zxs8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-6zxs8,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-27brj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-27brj/pods/nginx-deployment-65bbdb5f8-6zxs8,UID:c0373023-75b5-11e9-83a8-7e0242378207,ResourceVersion:43808,Generation:0,CreationTimestamp:2019-05-13 19:31:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 becc99fe-75b5-11e9-83a8-7e0242378207 0xc002379690 0xc002379691}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8bx99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8bx99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8bx99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.153,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002379710} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002379730}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:48 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:31:48.614: INFO: Pod "nginx-deployment-65bbdb5f8-7mc6b" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-7mc6b,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-27brj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-27brj/pods/nginx-deployment-65bbdb5f8-7mc6b,UID:c036b96a-75b5-11e9-83a8-7e0242378207,ResourceVersion:43807,Generation:0,CreationTimestamp:2019-05-13 19:31:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 becc99fe-75b5-11e9-83a8-7e0242378207 0xc0023797a0 0xc0023797a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8bx99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8bx99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8bx99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.177,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020da030} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020da050}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:48 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:31:48.615: INFO: Pod "nginx-deployment-65bbdb5f8-9z5ms" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-9z5ms,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-27brj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-27brj/pods/nginx-deployment-65bbdb5f8-9z5ms,UID:bed766b7-75b5-11e9-83a8-7e0242378207,ResourceVersion:43722,Generation:0,CreationTimestamp:2019-05-13 19:31:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 becc99fe-75b5-11e9-83a8-7e0242378207 0xc0020da0c0 0xc0020da0c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8bx99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8bx99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8bx99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.153,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020da140} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020da160}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:46 +0000 UTC  }],Message:,Reason:,HostIP:10.170.219.153,PodIP:,StartTime:2019-05-13 19:31:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:31:48.615: INFO: Pod "nginx-deployment-65bbdb5f8-bkfvq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-bkfvq,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-27brj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-27brj/pods/nginx-deployment-65bbdb5f8-bkfvq,UID:c0367654-75b5-11e9-83a8-7e0242378207,ResourceVersion:43804,Generation:0,CreationTimestamp:2019-05-13 19:31:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 becc99fe-75b5-11e9-83a8-7e0242378207 0xc0020da220 0xc0020da221}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8bx99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8bx99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8bx99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.177,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020da2a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020da2c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:48 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:31:48.615: INFO: Pod "nginx-deployment-65bbdb5f8-ft2jk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-ft2jk,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-27brj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-27brj/pods/nginx-deployment-65bbdb5f8-ft2jk,UID:c03507b9-75b5-11e9-83a8-7e0242378207,ResourceVersion:43789,Generation:0,CreationTimestamp:2019-05-13 19:31:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 becc99fe-75b5-11e9-83a8-7e0242378207 0xc0020da330 0xc0020da331}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8bx99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8bx99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8bx99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.151,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020da3b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020da3d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:48 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:31:48.615: INFO: Pod "nginx-deployment-65bbdb5f8-j82v8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-j82v8,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-27brj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-27brj/pods/nginx-deployment-65bbdb5f8-j82v8,UID:c0387663-75b5-11e9-83a8-7e0242378207,ResourceVersion:43806,Generation:0,CreationTimestamp:2019-05-13 19:31:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 becc99fe-75b5-11e9-83a8-7e0242378207 0xc0020da440 0xc0020da441}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8bx99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8bx99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8bx99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020da4b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020da4d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:31:48.615: INFO: Pod "nginx-deployment-65bbdb5f8-mmsfj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-mmsfj,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-27brj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-27brj/pods/nginx-deployment-65bbdb5f8-mmsfj,UID:c0330ebc-75b5-11e9-83a8-7e0242378207,ResourceVersion:43809,Generation:0,CreationTimestamp:2019-05-13 19:31:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 becc99fe-75b5-11e9-83a8-7e0242378207 0xc0020da527 0xc0020da528}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8bx99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8bx99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8bx99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.177,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020da5a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020da5c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:48 +0000 UTC  }],Message:,Reason:,HostIP:10.170.219.177,PodIP:,StartTime:2019-05-13 19:31:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:31:48.615: INFO: Pod "nginx-deployment-65bbdb5f8-nrzsj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-nrzsj,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-27brj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-27brj/pods/nginx-deployment-65bbdb5f8-nrzsj,UID:becf3e74-75b5-11e9-83a8-7e0242378207,ResourceVersion:43755,Generation:0,CreationTimestamp:2019-05-13 19:31:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 becc99fe-75b5-11e9-83a8-7e0242378207 0xc0020da680 0xc0020da681}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8bx99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8bx99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8bx99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.177,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020da710} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020da730}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:46 +0000 UTC  }],Message:,Reason:,HostIP:10.170.219.177,PodIP:172.30.227.73,StartTime:2019-05-13 19:31:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": no available registry endpoint: docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:31:48.615: INFO: Pod "nginx-deployment-65bbdb5f8-ppx74" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-ppx74,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-27brj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-27brj/pods/nginx-deployment-65bbdb5f8-ppx74,UID:becdf59e-75b5-11e9-83a8-7e0242378207,ResourceVersion:43745,Generation:0,CreationTimestamp:2019-05-13 19:31:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 becc99fe-75b5-11e9-83a8-7e0242378207 0xc0020da820 0xc0020da821}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8bx99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8bx99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8bx99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.153,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020da8a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020da8c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:46 +0000 UTC  }],Message:,Reason:,HostIP:10.170.219.153,PodIP:172.30.63.44,StartTime:2019-05-13 19:31:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": no available registry endpoint: docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:31:48.617: INFO: Pod "nginx-deployment-65bbdb5f8-xnj7x" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-xnj7x,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-27brj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-27brj/pods/nginx-deployment-65bbdb5f8-xnj7x,UID:becf3a2a-75b5-11e9-83a8-7e0242378207,ResourceVersion:43736,Generation:0,CreationTimestamp:2019-05-13 19:31:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 becc99fe-75b5-11e9-83a8-7e0242378207 0xc0020dac00 0xc0020dac01}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8bx99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8bx99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8bx99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.151,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020dac80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020daca0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:46 +0000 UTC  }],Message:,Reason:,HostIP:10.170.219.151,PodIP:172.30.19.104,StartTime:2019-05-13 19:31:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": no available registry endpoint: docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:31:48.617: INFO: Pod "nginx-deployment-65bbdb5f8-xrbrd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-xrbrd,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-27brj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-27brj/pods/nginx-deployment-65bbdb5f8-xrbrd,UID:bed61018-75b5-11e9-83a8-7e0242378207,ResourceVersion:43703,Generation:0,CreationTimestamp:2019-05-13 19:31:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 becc99fe-75b5-11e9-83a8-7e0242378207 0xc0020db550 0xc0020db551}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8bx99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8bx99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8bx99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.153,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020db5e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020db600}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:46 +0000 UTC  }],Message:,Reason:,HostIP:10.170.219.153,PodIP:,StartTime:2019-05-13 19:31:46 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
May 13 19:31:48.617: INFO: Pod "nginx-deployment-65bbdb5f8-zdsgw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-65bbdb5f8-zdsgw,GenerateName:nginx-deployment-65bbdb5f8-,Namespace:e2e-tests-deployment-27brj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-27brj/pods/nginx-deployment-65bbdb5f8-zdsgw,UID:c0356dd0-75b5-11e9-83a8-7e0242378207,ResourceVersion:43793,Generation:0,CreationTimestamp:2019-05-13 19:31:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 65bbdb5f8,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-65bbdb5f8 becc99fe-75b5-11e9-83a8-7e0242378207 0xc0020dba50 0xc0020dba51}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-8bx99 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8bx99,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-8bx99 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.153,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0020dbad0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0020dbaf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:31:48 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:31:48.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-27brj" for this suite.
May 13 19:31:56.669: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:31:56.776: INFO: namespace: e2e-tests-deployment-27brj, resource: bindings, ignored listing per whitelist
May 13 19:31:56.981: INFO: namespace e2e-tests-deployment-27brj deletion completed in 8.357901321s

• [SLOW TEST:17.222 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:31:56.981: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-7wbmf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
May 13 19:31:57.349: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:32:02.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-7wbmf" for this suite.
May 13 19:32:26.528: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:32:26.735: INFO: namespace: e2e-tests-init-container-7wbmf, resource: bindings, ignored listing per whitelist
May 13 19:32:26.775: INFO: namespace e2e-tests-init-container-7wbmf deletion completed in 24.306678168s

• [SLOW TEST:29.794 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:32:26.775: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-rfb5b
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1399
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
May 13 19:32:27.065: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-rfb5b'
May 13 19:32:27.381: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May 13 19:32:27.381: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1404
May 13 19:32:31.411: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-rfb5b'
May 13 19:32:31.547: INFO: stderr: ""
May 13 19:32:31.547: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:32:31.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-rfb5b" for this suite.
May 13 19:32:37.596: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:32:37.708: INFO: namespace: e2e-tests-kubectl-rfb5b, resource: bindings, ignored listing per whitelist
May 13 19:32:37.849: INFO: namespace e2e-tests-kubectl-rfb5b deletion completed in 6.282383058s

• [SLOW TEST:11.074 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:32:37.850: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-c9mkh
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-ddcc6929-75b5-11e9-8f67-2632f168be36
STEP: Creating secret with name s-test-opt-upd-ddcc6975-75b5-11e9-8f67-2632f168be36
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-ddcc6929-75b5-11e9-8f67-2632f168be36
STEP: Updating secret s-test-opt-upd-ddcc6975-75b5-11e9-8f67-2632f168be36
STEP: Creating secret with name s-test-opt-create-ddcc6993-75b5-11e9-8f67-2632f168be36
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:34:06.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-c9mkh" for this suite.
May 13 19:34:30.117: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:34:30.385: INFO: namespace: e2e-tests-secrets-c9mkh, resource: bindings, ignored listing per whitelist
May 13 19:34:30.434: INFO: namespace e2e-tests-secrets-c9mkh deletion completed in 24.344089387s

• [SLOW TEST:112.584 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:34:30.434: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-flv2d
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 13 19:34:30.721: INFO: Waiting up to 5m0s for pod "downwardapi-volume-20d84759-75b6-11e9-8f67-2632f168be36" in namespace "e2e-tests-projected-flv2d" to be "success or failure"
May 13 19:34:30.731: INFO: Pod "downwardapi-volume-20d84759-75b6-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 9.147675ms
May 13 19:34:32.739: INFO: Pod "downwardapi-volume-20d84759-75b6-11e9-8f67-2632f168be36": Phase="Running", Reason="", readiness=true. Elapsed: 2.017380564s
May 13 19:34:34.747: INFO: Pod "downwardapi-volume-20d84759-75b6-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025751229s
STEP: Saw pod success
May 13 19:34:34.747: INFO: Pod "downwardapi-volume-20d84759-75b6-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 19:34:34.754: INFO: Trying to get logs from node 10.170.219.153 pod downwardapi-volume-20d84759-75b6-11e9-8f67-2632f168be36 container client-container: <nil>
STEP: delete the pod
May 13 19:34:34.794: INFO: Waiting for pod downwardapi-volume-20d84759-75b6-11e9-8f67-2632f168be36 to disappear
May 13 19:34:34.801: INFO: Pod downwardapi-volume-20d84759-75b6-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:34:34.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-flv2d" for this suite.
May 13 19:34:40.839: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:34:40.989: INFO: namespace: e2e-tests-projected-flv2d, resource: bindings, ignored listing per whitelist
May 13 19:34:41.141: INFO: namespace e2e-tests-projected-flv2d deletion completed in 6.332352622s

• [SLOW TEST:10.707 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:34:41.143: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-xwpmh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
May 13 19:34:41.535: INFO: Waiting up to 5m0s for pod "pod-273c0f8d-75b6-11e9-8f67-2632f168be36" in namespace "e2e-tests-emptydir-xwpmh" to be "success or failure"
May 13 19:34:41.542: INFO: Pod "pod-273c0f8d-75b6-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 7.503589ms
May 13 19:34:43.551: INFO: Pod "pod-273c0f8d-75b6-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016079158s
STEP: Saw pod success
May 13 19:34:43.551: INFO: Pod "pod-273c0f8d-75b6-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 19:34:43.620: INFO: Trying to get logs from node 10.170.219.153 pod pod-273c0f8d-75b6-11e9-8f67-2632f168be36 container test-container: <nil>
STEP: delete the pod
May 13 19:34:43.661: INFO: Waiting for pod pod-273c0f8d-75b6-11e9-8f67-2632f168be36 to disappear
May 13 19:34:43.669: INFO: Pod pod-273c0f8d-75b6-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:34:43.669: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-xwpmh" for this suite.
May 13 19:34:49.707: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:34:49.737: INFO: namespace: e2e-tests-emptydir-xwpmh, resource: bindings, ignored listing per whitelist
May 13 19:34:49.967: INFO: namespace e2e-tests-emptydir-xwpmh deletion completed in 6.289827803s

• [SLOW TEST:8.825 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:34:49.968: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-namespaces-crlgb
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-czlgx
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
May 13 19:34:59.720: INFO: error from create uninitialized namespace: Internal error occurred: object deleted while waiting for creation
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-57j8x
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:35:17.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-crlgb" for this suite.
May 13 19:35:23.792: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:35:24.219: INFO: namespace: e2e-tests-namespaces-crlgb, resource: bindings, ignored listing per whitelist
May 13 19:35:24.225: INFO: namespace e2e-tests-namespaces-crlgb deletion completed in 6.460832776s
STEP: Destroying namespace "e2e-tests-nsdeletetest-czlgx" for this suite.
May 13 19:35:24.232: INFO: Namespace e2e-tests-nsdeletetest-czlgx was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-57j8x" for this suite.
May 13 19:35:30.281: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:35:30.437: INFO: namespace: e2e-tests-nsdeletetest-57j8x, resource: bindings, ignored listing per whitelist
May 13 19:35:30.538: INFO: namespace e2e-tests-nsdeletetest-57j8x deletion completed in 6.305588102s

• [SLOW TEST:40.570 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:35:30.539: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-kjz4j
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0513 19:36:01.421834      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 13 19:36:01.421: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:36:01.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-kjz4j" for this suite.
May 13 19:36:07.457: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:36:07.515: INFO: namespace: e2e-tests-gc-kjz4j, resource: bindings, ignored listing per whitelist
May 13 19:36:09.391: INFO: namespace e2e-tests-gc-kjz4j deletion completed in 7.964354227s

• [SLOW TEST:38.853 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:36:09.392: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-sc86z
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
May 13 19:36:13.772: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 13 19:36:13.783: INFO: Pod pod-with-prestop-exec-hook still exists
May 13 19:36:15.783: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 13 19:36:15.791: INFO: Pod pod-with-prestop-exec-hook still exists
May 13 19:36:17.783: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 13 19:36:17.796: INFO: Pod pod-with-prestop-exec-hook still exists
May 13 19:36:19.783: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 13 19:36:19.792: INFO: Pod pod-with-prestop-exec-hook still exists
May 13 19:36:21.783: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 13 19:36:21.805: INFO: Pod pod-with-prestop-exec-hook still exists
May 13 19:36:23.783: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 13 19:36:23.791: INFO: Pod pod-with-prestop-exec-hook still exists
May 13 19:36:25.783: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 13 19:36:25.792: INFO: Pod pod-with-prestop-exec-hook still exists
May 13 19:36:27.783: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 13 19:36:27.792: INFO: Pod pod-with-prestop-exec-hook still exists
May 13 19:36:29.783: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 13 19:36:29.792: INFO: Pod pod-with-prestop-exec-hook still exists
May 13 19:36:31.783: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 13 19:36:31.792: INFO: Pod pod-with-prestop-exec-hook still exists
May 13 19:36:33.783: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 13 19:36:33.803: INFO: Pod pod-with-prestop-exec-hook still exists
May 13 19:36:35.783: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 13 19:36:35.792: INFO: Pod pod-with-prestop-exec-hook still exists
May 13 19:36:37.783: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 13 19:36:37.792: INFO: Pod pod-with-prestop-exec-hook still exists
May 13 19:36:39.783: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 13 19:36:39.791: INFO: Pod pod-with-prestop-exec-hook still exists
May 13 19:36:41.783: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 13 19:36:41.791: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:36:41.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-sc86z" for this suite.
May 13 19:37:05.866: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:37:05.911: INFO: namespace: e2e-tests-container-lifecycle-hook-sc86z, resource: bindings, ignored listing per whitelist
May 13 19:37:06.115: INFO: namespace e2e-tests-container-lifecycle-hook-sc86z deletion completed in 24.278478072s

• [SLOW TEST:56.724 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:37:06.116: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-7fgn8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-7da50e3a-75b6-11e9-8f67-2632f168be36
STEP: Creating a pod to test consume secrets
May 13 19:37:06.424: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-7da6874a-75b6-11e9-8f67-2632f168be36" in namespace "e2e-tests-projected-7fgn8" to be "success or failure"
May 13 19:37:06.433: INFO: Pod "pod-projected-secrets-7da6874a-75b6-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 9.101074ms
May 13 19:37:08.441: INFO: Pod "pod-projected-secrets-7da6874a-75b6-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017144216s
STEP: Saw pod success
May 13 19:37:08.441: INFO: Pod "pod-projected-secrets-7da6874a-75b6-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 19:37:08.448: INFO: Trying to get logs from node 10.170.219.153 pod pod-projected-secrets-7da6874a-75b6-11e9-8f67-2632f168be36 container projected-secret-volume-test: <nil>
STEP: delete the pod
May 13 19:37:08.493: INFO: Waiting for pod pod-projected-secrets-7da6874a-75b6-11e9-8f67-2632f168be36 to disappear
May 13 19:37:08.530: INFO: Pod pod-projected-secrets-7da6874a-75b6-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:37:08.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7fgn8" for this suite.
May 13 19:37:14.566: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:37:14.741: INFO: namespace: e2e-tests-projected-7fgn8, resource: bindings, ignored listing per whitelist
May 13 19:37:14.832: INFO: namespace e2e-tests-projected-7fgn8 deletion completed in 6.294169818s

• [SLOW TEST:8.716 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:37:14.833: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-b8bdc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 13 19:37:15.114: INFO: Waiting up to 5m0s for pod "downwardapi-volume-82d431f8-75b6-11e9-8f67-2632f168be36" in namespace "e2e-tests-projected-b8bdc" to be "success or failure"
May 13 19:37:15.121: INFO: Pod "downwardapi-volume-82d431f8-75b6-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 7.269859ms
May 13 19:37:17.142: INFO: Pod "downwardapi-volume-82d431f8-75b6-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.028085372s
STEP: Saw pod success
May 13 19:37:17.142: INFO: Pod "downwardapi-volume-82d431f8-75b6-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 19:37:17.151: INFO: Trying to get logs from node 10.170.219.177 pod downwardapi-volume-82d431f8-75b6-11e9-8f67-2632f168be36 container client-container: <nil>
STEP: delete the pod
May 13 19:37:17.188: INFO: Waiting for pod downwardapi-volume-82d431f8-75b6-11e9-8f67-2632f168be36 to disappear
May 13 19:37:17.198: INFO: Pod downwardapi-volume-82d431f8-75b6-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:37:17.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-b8bdc" for this suite.
May 13 19:37:23.249: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:37:23.471: INFO: namespace: e2e-tests-projected-b8bdc, resource: bindings, ignored listing per whitelist
May 13 19:37:23.557: INFO: namespace e2e-tests-projected-b8bdc deletion completed in 6.335506957s

• [SLOW TEST:8.724 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:37:23.557: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-l6774
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 13 19:37:23.945: INFO: (0) /api/v1/nodes/10.170.219.151/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 15.288773ms)
May 13 19:37:23.954: INFO: (1) /api/v1/nodes/10.170.219.151/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 8.394234ms)
May 13 19:37:23.962: INFO: (2) /api/v1/nodes/10.170.219.151/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 8.304928ms)
May 13 19:37:23.971: INFO: (3) /api/v1/nodes/10.170.219.151/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 8.527692ms)
May 13 19:37:23.979: INFO: (4) /api/v1/nodes/10.170.219.151/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 7.912522ms)
May 13 19:37:23.988: INFO: (5) /api/v1/nodes/10.170.219.151/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 9.342698ms)
May 13 19:37:23.997: INFO: (6) /api/v1/nodes/10.170.219.151/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 8.482543ms)
May 13 19:37:24.005: INFO: (7) /api/v1/nodes/10.170.219.151/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 8.604469ms)
May 13 19:37:24.014: INFO: (8) /api/v1/nodes/10.170.219.151/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 8.417351ms)
May 13 19:37:24.022: INFO: (9) /api/v1/nodes/10.170.219.151/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 8.630109ms)
May 13 19:37:24.031: INFO: (10) /api/v1/nodes/10.170.219.151/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 8.131685ms)
May 13 19:37:24.039: INFO: (11) /api/v1/nodes/10.170.219.151/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 8.257885ms)
May 13 19:37:24.048: INFO: (12) /api/v1/nodes/10.170.219.151/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 8.731738ms)
May 13 19:37:24.057: INFO: (13) /api/v1/nodes/10.170.219.151/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 8.914792ms)
May 13 19:37:24.066: INFO: (14) /api/v1/nodes/10.170.219.151/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 9.655386ms)
May 13 19:37:24.075: INFO: (15) /api/v1/nodes/10.170.219.151/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 8.522576ms)
May 13 19:37:24.084: INFO: (16) /api/v1/nodes/10.170.219.151/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 8.848382ms)
May 13 19:37:24.092: INFO: (17) /api/v1/nodes/10.170.219.151/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 7.946529ms)
May 13 19:37:24.101: INFO: (18) /api/v1/nodes/10.170.219.151/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 9.032523ms)
May 13 19:37:24.109: INFO: (19) /api/v1/nodes/10.170.219.151/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 8.410069ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:37:24.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-l6774" for this suite.
May 13 19:37:30.155: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:37:30.287: INFO: namespace: e2e-tests-proxy-l6774, resource: bindings, ignored listing per whitelist
May 13 19:37:30.473: INFO: namespace e2e-tests-proxy-l6774 deletion completed in 6.356934296s

• [SLOW TEST:6.916 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:37:30.473: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-c6mlp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
May 13 19:37:30.743: INFO: namespace e2e-tests-kubectl-c6mlp
May 13 19:37:30.743: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 create -f - --namespace=e2e-tests-kubectl-c6mlp'
May 13 19:37:31.022: INFO: stderr: ""
May 13 19:37:31.022: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
May 13 19:37:32.031: INFO: Selector matched 1 pods for map[app:redis]
May 13 19:37:32.031: INFO: Found 0 / 1
May 13 19:37:33.032: INFO: Selector matched 1 pods for map[app:redis]
May 13 19:37:33.032: INFO: Found 1 / 1
May 13 19:37:33.032: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May 13 19:37:33.040: INFO: Selector matched 1 pods for map[app:redis]
May 13 19:37:33.040: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May 13 19:37:33.040: INFO: wait on redis-master startup in e2e-tests-kubectl-c6mlp 
May 13 19:37:33.040: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 logs redis-master-ftlmz redis-master --namespace=e2e-tests-kubectl-c6mlp'
May 13 19:37:33.254: INFO: stderr: ""
May 13 19:37:33.254: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 13 May 19:37:32.367 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 13 May 19:37:32.367 # Server started, Redis version 3.2.12\n1:M 13 May 19:37:32.367 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 13 May 19:37:32.367 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
May 13 19:37:33.254: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-c6mlp'
May 13 19:37:33.381: INFO: stderr: ""
May 13 19:37:33.381: INFO: stdout: "service/rm2 exposed\n"
May 13 19:37:33.388: INFO: Service rm2 in namespace e2e-tests-kubectl-c6mlp found.
STEP: exposing service
May 13 19:37:35.402: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-c6mlp'
May 13 19:37:35.520: INFO: stderr: ""
May 13 19:37:35.520: INFO: stdout: "service/rm3 exposed\n"
May 13 19:37:35.528: INFO: Service rm3 in namespace e2e-tests-kubectl-c6mlp found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:37:37.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-c6mlp" for this suite.
May 13 19:38:01.577: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:38:01.978: INFO: namespace: e2e-tests-kubectl-c6mlp, resource: bindings, ignored listing per whitelist
May 13 19:38:02.030: INFO: namespace e2e-tests-kubectl-c6mlp deletion completed in 24.481093261s

• [SLOW TEST:31.558 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:38:02.031: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-runtime-2f899
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:38:26.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-runtime-2f899" for this suite.
May 13 19:38:32.483: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:38:32.664: INFO: namespace: e2e-tests-container-runtime-2f899, resource: bindings, ignored listing per whitelist
May 13 19:38:32.713: INFO: namespace e2e-tests-container-runtime-2f899 deletion completed in 6.257935507s

• [SLOW TEST:30.682 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  blackbox test
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:38:32.713: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-b84tg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
May 13 19:38:33.016: INFO: Waiting up to 5m0s for pod "client-containers-b143ad32-75b6-11e9-8f67-2632f168be36" in namespace "e2e-tests-containers-b84tg" to be "success or failure"
May 13 19:38:33.024: INFO: Pod "client-containers-b143ad32-75b6-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 7.12353ms
May 13 19:38:35.044: INFO: Pod "client-containers-b143ad32-75b6-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027665009s
STEP: Saw pod success
May 13 19:38:35.044: INFO: Pod "client-containers-b143ad32-75b6-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 19:38:35.120: INFO: Trying to get logs from node 10.170.219.177 pod client-containers-b143ad32-75b6-11e9-8f67-2632f168be36 container test-container: <nil>
STEP: delete the pod
May 13 19:38:35.160: INFO: Waiting for pod client-containers-b143ad32-75b6-11e9-8f67-2632f168be36 to disappear
May 13 19:38:35.167: INFO: Pod client-containers-b143ad32-75b6-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:38:35.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-b84tg" for this suite.
May 13 19:38:43.202: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:38:43.262: INFO: namespace: e2e-tests-containers-b84tg, resource: bindings, ignored listing per whitelist
May 13 19:38:43.465: INFO: namespace e2e-tests-containers-b84tg deletion completed in 8.290663869s

• [SLOW TEST:10.752 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:38:43.466: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-namespaces-bt6bn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-4v4kq
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-dfz9l
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:38:50.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-bt6bn" for this suite.
May 13 19:38:56.402: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:38:56.662: INFO: namespace: e2e-tests-namespaces-bt6bn, resource: bindings, ignored listing per whitelist
May 13 19:38:56.734: INFO: namespace e2e-tests-namespaces-bt6bn deletion completed in 6.515934116s
STEP: Destroying namespace "e2e-tests-nsdeletetest-4v4kq" for this suite.
May 13 19:38:56.741: INFO: Namespace e2e-tests-nsdeletetest-4v4kq was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-dfz9l" for this suite.
May 13 19:39:02.769: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:39:02.898: INFO: namespace: e2e-tests-nsdeletetest-dfz9l, resource: bindings, ignored listing per whitelist
May 13 19:39:03.092: INFO: namespace e2e-tests-nsdeletetest-dfz9l deletion completed in 6.350237105s

• [SLOW TEST:19.626 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:39:03.092: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-zppqb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 13 19:39:03.379: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c35c4029-75b6-11e9-8f67-2632f168be36" in namespace "e2e-tests-downward-api-zppqb" to be "success or failure"
May 13 19:39:03.386: INFO: Pod "downwardapi-volume-c35c4029-75b6-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 7.469787ms
May 13 19:39:05.395: INFO: Pod "downwardapi-volume-c35c4029-75b6-11e9-8f67-2632f168be36": Phase="Running", Reason="", readiness=true. Elapsed: 2.016237972s
May 13 19:39:07.416: INFO: Pod "downwardapi-volume-c35c4029-75b6-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037360494s
STEP: Saw pod success
May 13 19:39:07.416: INFO: Pod "downwardapi-volume-c35c4029-75b6-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 19:39:07.423: INFO: Trying to get logs from node 10.170.219.177 pod downwardapi-volume-c35c4029-75b6-11e9-8f67-2632f168be36 container client-container: <nil>
STEP: delete the pod
May 13 19:39:07.476: INFO: Waiting for pod downwardapi-volume-c35c4029-75b6-11e9-8f67-2632f168be36 to disappear
May 13 19:39:07.483: INFO: Pod downwardapi-volume-c35c4029-75b6-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:39:07.483: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-zppqb" for this suite.
May 13 19:39:13.518: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:39:13.587: INFO: namespace: e2e-tests-downward-api-zppqb, resource: bindings, ignored listing per whitelist
May 13 19:39:13.754: INFO: namespace e2e-tests-downward-api-zppqb deletion completed in 6.263650485s

• [SLOW TEST:10.662 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:39:13.755: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-bzhfc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-ca11ea69-75b6-11e9-8f67-2632f168be36
STEP: Creating a pod to test consume configMaps
May 13 19:39:14.642: INFO: Waiting up to 5m0s for pod "pod-configmaps-ca135151-75b6-11e9-8f67-2632f168be36" in namespace "e2e-tests-configmap-bzhfc" to be "success or failure"
May 13 19:39:14.727: INFO: Pod "pod-configmaps-ca135151-75b6-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 84.919358ms
May 13 19:39:16.750: INFO: Pod "pod-configmaps-ca135151-75b6-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.107519838s
STEP: Saw pod success
May 13 19:39:16.750: INFO: Pod "pod-configmaps-ca135151-75b6-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 19:39:16.827: INFO: Trying to get logs from node 10.170.219.153 pod pod-configmaps-ca135151-75b6-11e9-8f67-2632f168be36 container configmap-volume-test: <nil>
STEP: delete the pod
May 13 19:39:16.866: INFO: Waiting for pod pod-configmaps-ca135151-75b6-11e9-8f67-2632f168be36 to disappear
May 13 19:39:16.873: INFO: Pod pod-configmaps-ca135151-75b6-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:39:16.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-bzhfc" for this suite.
May 13 19:39:22.908: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:39:22.950: INFO: namespace: e2e-tests-configmap-bzhfc, resource: bindings, ignored listing per whitelist
May 13 19:39:23.159: INFO: namespace e2e-tests-configmap-bzhfc deletion completed in 6.279244142s

• [SLOW TEST:9.404 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:39:23.160: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-ms6f5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-ms6f5
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 13 19:39:23.419: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 13 19:39:43.642: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.63.63:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-ms6f5 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 13 19:39:43.642: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
May 13 19:39:43.832: INFO: Found all expected endpoints: [netserver-0]
May 13 19:39:43.840: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.227.91:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-ms6f5 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 13 19:39:43.840: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
May 13 19:39:44.012: INFO: Found all expected endpoints: [netserver-1]
May 13 19:39:44.020: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.19.108:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-ms6f5 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 13 19:39:44.020: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
May 13 19:39:44.194: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:39:44.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-ms6f5" for this suite.
May 13 19:40:08.232: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:40:08.493: INFO: namespace: e2e-tests-pod-network-test-ms6f5, resource: bindings, ignored listing per whitelist
May 13 19:40:08.545: INFO: namespace e2e-tests-pod-network-test-ms6f5 deletion completed in 24.341758945s

• [SLOW TEST:45.385 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:40:08.545: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-v5lgc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-ea621e49-75b6-11e9-8f67-2632f168be36
STEP: Creating a pod to test consume configMaps
May 13 19:40:08.854: INFO: Waiting up to 5m0s for pod "pod-configmaps-ea636de2-75b6-11e9-8f67-2632f168be36" in namespace "e2e-tests-configmap-v5lgc" to be "success or failure"
May 13 19:40:08.862: INFO: Pod "pod-configmaps-ea636de2-75b6-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 8.043696ms
May 13 19:40:10.870: INFO: Pod "pod-configmaps-ea636de2-75b6-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015663923s
STEP: Saw pod success
May 13 19:40:10.870: INFO: Pod "pod-configmaps-ea636de2-75b6-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 19:40:10.879: INFO: Trying to get logs from node 10.170.219.177 pod pod-configmaps-ea636de2-75b6-11e9-8f67-2632f168be36 container configmap-volume-test: <nil>
STEP: delete the pod
May 13 19:40:10.921: INFO: Waiting for pod pod-configmaps-ea636de2-75b6-11e9-8f67-2632f168be36 to disappear
May 13 19:40:10.928: INFO: Pod pod-configmaps-ea636de2-75b6-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:40:10.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-v5lgc" for this suite.
May 13 19:40:16.964: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:40:17.037: INFO: namespace: e2e-tests-configmap-v5lgc, resource: bindings, ignored listing per whitelist
May 13 19:40:17.196: INFO: namespace e2e-tests-configmap-v5lgc deletion completed in 6.260380348s

• [SLOW TEST:8.651 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:40:17.197: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-ckcnm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
May 13 19:40:17.524: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-ckcnm,SelfLink:/api/v1/namespaces/e2e-tests-watch-ckcnm/configmaps/e2e-watch-test-resource-version,UID:ef8765bd-75b6-11e9-b786-da20024d205c,ResourceVersion:46098,Generation:0,CreationTimestamp:2019-05-13 19:40:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 13 19:40:17.524: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-ckcnm,SelfLink:/api/v1/namespaces/e2e-tests-watch-ckcnm/configmaps/e2e-watch-test-resource-version,UID:ef8765bd-75b6-11e9-b786-da20024d205c,ResourceVersion:46099,Generation:0,CreationTimestamp:2019-05-13 19:40:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:40:17.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-ckcnm" for this suite.
May 13 19:40:23.557: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:40:23.877: INFO: namespace: e2e-tests-watch-ckcnm, resource: bindings, ignored listing per whitelist
May 13 19:40:23.909: INFO: namespace e2e-tests-watch-ckcnm deletion completed in 6.378830927s

• [SLOW TEST:6.712 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:40:23.909: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-cwd8q
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0513 19:40:34.329427      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 13 19:40:34.329: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:40:34.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-cwd8q" for this suite.
May 13 19:40:42.364: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:40:42.513: INFO: namespace: e2e-tests-gc-cwd8q, resource: bindings, ignored listing per whitelist
May 13 19:40:42.604: INFO: namespace e2e-tests-gc-cwd8q deletion completed in 8.267915179s

• [SLOW TEST:18.694 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:40:42.604: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-4q5qt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
May 13 19:40:42.904: INFO: Waiting up to 5m0s for pod "downward-api-feaf12a2-75b6-11e9-8f67-2632f168be36" in namespace "e2e-tests-downward-api-4q5qt" to be "success or failure"
May 13 19:40:42.912: INFO: Pod "downward-api-feaf12a2-75b6-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 7.778802ms
May 13 19:40:44.921: INFO: Pod "downward-api-feaf12a2-75b6-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016410548s
STEP: Saw pod success
May 13 19:40:44.921: INFO: Pod "downward-api-feaf12a2-75b6-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 19:40:44.929: INFO: Trying to get logs from node 10.170.219.153 pod downward-api-feaf12a2-75b6-11e9-8f67-2632f168be36 container dapi-container: <nil>
STEP: delete the pod
May 13 19:40:45.020: INFO: Waiting for pod downward-api-feaf12a2-75b6-11e9-8f67-2632f168be36 to disappear
May 13 19:40:45.031: INFO: Pod downward-api-feaf12a2-75b6-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:40:45.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-4q5qt" for this suite.
May 13 19:40:51.081: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:40:51.213: INFO: namespace: e2e-tests-downward-api-4q5qt, resource: bindings, ignored listing per whitelist
May 13 19:40:51.363: INFO: namespace e2e-tests-downward-api-4q5qt deletion completed in 6.324245909s

• [SLOW TEST:8.759 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:40:51.363: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-glhcw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-glhcw
May 13 19:40:53.650: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-glhcw
STEP: checking the pod's current state and verifying that restartCount is present
May 13 19:40:53.658: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:44:55.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-glhcw" for this suite.
May 13 19:45:01.547: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:45:01.626: INFO: namespace: e2e-tests-container-probe-glhcw, resource: bindings, ignored listing per whitelist
May 13 19:45:01.783: INFO: namespace e2e-tests-container-probe-glhcw deletion completed in 6.263066514s

• [SLOW TEST:250.419 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:45:01.783: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-98znn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0513 19:45:42.237491      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 13 19:45:42.237: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:45:42.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-98znn" for this suite.
May 13 19:45:50.354: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:45:50.505: INFO: namespace: e2e-tests-gc-98znn, resource: bindings, ignored listing per whitelist
May 13 19:45:50.638: INFO: namespace e2e-tests-gc-98znn deletion completed in 8.312472835s

• [SLOW TEST:48.855 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:45:50.638: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-8bvpx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-8bvpx/configmap-test-b64771e4-75b7-11e9-8f67-2632f168be36
STEP: Creating a pod to test consume configMaps
May 13 19:45:50.937: INFO: Waiting up to 5m0s for pod "pod-configmaps-b648d078-75b7-11e9-8f67-2632f168be36" in namespace "e2e-tests-configmap-8bvpx" to be "success or failure"
May 13 19:45:50.944: INFO: Pod "pod-configmaps-b648d078-75b7-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 7.406289ms
May 13 19:45:52.968: INFO: Pod "pod-configmaps-b648d078-75b7-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.031175045s
STEP: Saw pod success
May 13 19:45:52.968: INFO: Pod "pod-configmaps-b648d078-75b7-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 19:45:52.975: INFO: Trying to get logs from node 10.170.219.153 pod pod-configmaps-b648d078-75b7-11e9-8f67-2632f168be36 container env-test: <nil>
STEP: delete the pod
May 13 19:45:53.020: INFO: Waiting for pod pod-configmaps-b648d078-75b7-11e9-8f67-2632f168be36 to disappear
May 13 19:45:53.029: INFO: Pod pod-configmaps-b648d078-75b7-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:45:53.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-8bvpx" for this suite.
May 13 19:45:59.062: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:45:59.252: INFO: namespace: e2e-tests-configmap-8bvpx, resource: bindings, ignored listing per whitelist
May 13 19:45:59.516: INFO: namespace e2e-tests-configmap-8bvpx deletion completed in 6.479436644s

• [SLOW TEST:8.877 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:45:59.516: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-h2nwr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
May 13 19:45:59.816: INFO: Waiting up to 5m0s for pod "pod-bb9285e0-75b7-11e9-8f67-2632f168be36" in namespace "e2e-tests-emptydir-h2nwr" to be "success or failure"
May 13 19:45:59.824: INFO: Pod "pod-bb9285e0-75b7-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 8.364025ms
May 13 19:46:01.833: INFO: Pod "pod-bb9285e0-75b7-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016939374s
May 13 19:46:03.853: INFO: Pod "pod-bb9285e0-75b7-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037410145s
STEP: Saw pod success
May 13 19:46:03.853: INFO: Pod "pod-bb9285e0-75b7-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 19:46:03.860: INFO: Trying to get logs from node 10.170.219.177 pod pod-bb9285e0-75b7-11e9-8f67-2632f168be36 container test-container: <nil>
STEP: delete the pod
May 13 19:46:03.951: INFO: Waiting for pod pod-bb9285e0-75b7-11e9-8f67-2632f168be36 to disappear
May 13 19:46:03.958: INFO: Pod pod-bb9285e0-75b7-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:46:03.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-h2nwr" for this suite.
May 13 19:46:09.993: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:46:10.292: INFO: namespace: e2e-tests-emptydir-h2nwr, resource: bindings, ignored listing per whitelist
May 13 19:46:10.331: INFO: namespace e2e-tests-emptydir-h2nwr deletion completed in 6.365471555s

• [SLOW TEST:10.815 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:46:10.332: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-lffwg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
May 13 19:46:10.640: INFO: Waiting up to 5m0s for pod "pod-c207a9d7-75b7-11e9-8f67-2632f168be36" in namespace "e2e-tests-emptydir-lffwg" to be "success or failure"
May 13 19:46:10.649: INFO: Pod "pod-c207a9d7-75b7-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 8.267344ms
May 13 19:46:12.657: INFO: Pod "pod-c207a9d7-75b7-11e9-8f67-2632f168be36": Phase="Running", Reason="", readiness=true. Elapsed: 2.016946101s
May 13 19:46:14.681: INFO: Pod "pod-c207a9d7-75b7-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041041615s
STEP: Saw pod success
May 13 19:46:14.681: INFO: Pod "pod-c207a9d7-75b7-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 19:46:14.690: INFO: Trying to get logs from node 10.170.219.177 pod pod-c207a9d7-75b7-11e9-8f67-2632f168be36 container test-container: <nil>
STEP: delete the pod
May 13 19:46:14.731: INFO: Waiting for pod pod-c207a9d7-75b7-11e9-8f67-2632f168be36 to disappear
May 13 19:46:14.740: INFO: Pod pod-c207a9d7-75b7-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:46:14.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-lffwg" for this suite.
May 13 19:46:20.848: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:46:20.993: INFO: namespace: e2e-tests-emptydir-lffwg, resource: bindings, ignored listing per whitelist
May 13 19:46:21.140: INFO: namespace e2e-tests-emptydir-lffwg deletion completed in 6.3205196s

• [SLOW TEST:10.809 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:46:21.141: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-jlvsb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:46:21.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-jlvsb" for this suite.
May 13 19:46:27.507: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:46:27.557: INFO: namespace: e2e-tests-services-jlvsb, resource: bindings, ignored listing per whitelist
May 13 19:46:27.935: INFO: namespace e2e-tests-services-jlvsb deletion completed in 6.45541309s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:6.795 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:46:27.936: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-xsds4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
May 13 19:46:28.228: INFO: Waiting up to 5m0s for pod "pod-cc83162e-75b7-11e9-8f67-2632f168be36" in namespace "e2e-tests-emptydir-xsds4" to be "success or failure"
May 13 19:46:28.237: INFO: Pod "pod-cc83162e-75b7-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 8.478597ms
May 13 19:46:30.245: INFO: Pod "pod-cc83162e-75b7-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016889938s
STEP: Saw pod success
May 13 19:46:30.245: INFO: Pod "pod-cc83162e-75b7-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 19:46:30.252: INFO: Trying to get logs from node 10.170.219.153 pod pod-cc83162e-75b7-11e9-8f67-2632f168be36 container test-container: <nil>
STEP: delete the pod
May 13 19:46:30.291: INFO: Waiting for pod pod-cc83162e-75b7-11e9-8f67-2632f168be36 to disappear
May 13 19:46:30.298: INFO: Pod pod-cc83162e-75b7-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:46:30.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-xsds4" for this suite.
May 13 19:46:36.347: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:46:36.485: INFO: namespace: e2e-tests-emptydir-xsds4, resource: bindings, ignored listing per whitelist
May 13 19:46:36.701: INFO: namespace e2e-tests-emptydir-xsds4 deletion completed in 6.395214572s

• [SLOW TEST:8.765 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:46:36.702: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-z5z64
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-d1bbd050-75b7-11e9-8f67-2632f168be36
STEP: Creating a pod to test consume configMaps
May 13 19:46:36.996: INFO: Waiting up to 5m0s for pod "pod-configmaps-d1bd190c-75b7-11e9-8f67-2632f168be36" in namespace "e2e-tests-configmap-z5z64" to be "success or failure"
May 13 19:46:37.004: INFO: Pod "pod-configmaps-d1bd190c-75b7-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 7.904391ms
May 13 19:46:39.012: INFO: Pod "pod-configmaps-d1bd190c-75b7-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016089297s
May 13 19:46:41.021: INFO: Pod "pod-configmaps-d1bd190c-75b7-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024957527s
STEP: Saw pod success
May 13 19:46:41.021: INFO: Pod "pod-configmaps-d1bd190c-75b7-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 19:46:41.029: INFO: Trying to get logs from node 10.170.219.153 pod pod-configmaps-d1bd190c-75b7-11e9-8f67-2632f168be36 container configmap-volume-test: <nil>
STEP: delete the pod
May 13 19:46:41.120: INFO: Waiting for pod pod-configmaps-d1bd190c-75b7-11e9-8f67-2632f168be36 to disappear
May 13 19:46:41.129: INFO: Pod pod-configmaps-d1bd190c-75b7-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:46:41.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-z5z64" for this suite.
May 13 19:46:47.176: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:46:47.387: INFO: namespace: e2e-tests-configmap-z5z64, resource: bindings, ignored listing per whitelist
May 13 19:46:47.497: INFO: namespace e2e-tests-configmap-z5z64 deletion completed in 6.35999882s

• [SLOW TEST:10.795 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:46:47.501: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-6mclt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-d82d8c89-75b7-11e9-8f67-2632f168be36
STEP: Creating a pod to test consume configMaps
May 13 19:46:47.809: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d82efa67-75b7-11e9-8f67-2632f168be36" in namespace "e2e-tests-projected-6mclt" to be "success or failure"
May 13 19:46:47.819: INFO: Pod "pod-projected-configmaps-d82efa67-75b7-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 10.31962ms
May 13 19:46:49.828: INFO: Pod "pod-projected-configmaps-d82efa67-75b7-11e9-8f67-2632f168be36": Phase="Running", Reason="", readiness=true. Elapsed: 2.01885252s
May 13 19:46:51.837: INFO: Pod "pod-projected-configmaps-d82efa67-75b7-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027711716s
STEP: Saw pod success
May 13 19:46:51.837: INFO: Pod "pod-projected-configmaps-d82efa67-75b7-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 19:46:51.932: INFO: Trying to get logs from node 10.170.219.177 pod pod-projected-configmaps-d82efa67-75b7-11e9-8f67-2632f168be36 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 13 19:46:51.982: INFO: Waiting for pod pod-projected-configmaps-d82efa67-75b7-11e9-8f67-2632f168be36 to disappear
May 13 19:46:51.989: INFO: Pod pod-projected-configmaps-d82efa67-75b7-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:46:51.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6mclt" for this suite.
May 13 19:46:58.038: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:46:58.130: INFO: namespace: e2e-tests-projected-6mclt, resource: bindings, ignored listing per whitelist
May 13 19:46:58.303: INFO: namespace e2e-tests-projected-6mclt deletion completed in 6.305661521s

• [SLOW TEST:10.803 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:46:58.304: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-nm754
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
May 13 19:46:59.164: INFO: created pod pod-service-account-defaultsa
May 13 19:46:59.164: INFO: pod pod-service-account-defaultsa service account token volume mount: true
May 13 19:46:59.175: INFO: created pod pod-service-account-mountsa
May 13 19:46:59.175: INFO: pod pod-service-account-mountsa service account token volume mount: true
May 13 19:46:59.185: INFO: created pod pod-service-account-nomountsa
May 13 19:46:59.185: INFO: pod pod-service-account-nomountsa service account token volume mount: false
May 13 19:46:59.194: INFO: created pod pod-service-account-defaultsa-mountspec
May 13 19:46:59.194: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
May 13 19:46:59.203: INFO: created pod pod-service-account-mountsa-mountspec
May 13 19:46:59.203: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
May 13 19:46:59.214: INFO: created pod pod-service-account-nomountsa-mountspec
May 13 19:46:59.214: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
May 13 19:46:59.223: INFO: created pod pod-service-account-defaultsa-nomountspec
May 13 19:46:59.223: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
May 13 19:46:59.232: INFO: created pod pod-service-account-mountsa-nomountspec
May 13 19:46:59.232: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
May 13 19:46:59.241: INFO: created pod pod-service-account-nomountsa-nomountspec
May 13 19:46:59.241: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:46:59.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-nm754" for this suite.
May 13 19:47:05.283: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:47:05.371: INFO: namespace: e2e-tests-svcaccounts-nm754, resource: bindings, ignored listing per whitelist
May 13 19:47:05.534: INFO: namespace e2e-tests-svcaccounts-nm754 deletion completed in 6.284504016s

• [SLOW TEST:7.231 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:47:05.535: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-6dbfv
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-e2edc438-75b7-11e9-8f67-2632f168be36
STEP: Creating a pod to test consume secrets
May 13 19:47:05.844: INFO: Waiting up to 5m0s for pod "pod-secrets-e2ef374b-75b7-11e9-8f67-2632f168be36" in namespace "e2e-tests-secrets-6dbfv" to be "success or failure"
May 13 19:47:05.851: INFO: Pod "pod-secrets-e2ef374b-75b7-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 6.959364ms
May 13 19:47:07.859: INFO: Pod "pod-secrets-e2ef374b-75b7-11e9-8f67-2632f168be36": Phase="Running", Reason="", readiness=true. Elapsed: 2.015084349s
May 13 19:47:09.880: INFO: Pod "pod-secrets-e2ef374b-75b7-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035975489s
STEP: Saw pod success
May 13 19:47:09.880: INFO: Pod "pod-secrets-e2ef374b-75b7-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 19:47:09.888: INFO: Trying to get logs from node 10.170.219.177 pod pod-secrets-e2ef374b-75b7-11e9-8f67-2632f168be36 container secret-volume-test: <nil>
STEP: delete the pod
May 13 19:47:09.929: INFO: Waiting for pod pod-secrets-e2ef374b-75b7-11e9-8f67-2632f168be36 to disappear
May 13 19:47:09.936: INFO: Pod pod-secrets-e2ef374b-75b7-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:47:09.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-6dbfv" for this suite.
May 13 19:47:15.974: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:47:16.086: INFO: namespace: e2e-tests-secrets-6dbfv, resource: bindings, ignored listing per whitelist
May 13 19:47:16.278: INFO: namespace e2e-tests-secrets-6dbfv deletion completed in 6.334023844s

• [SLOW TEST:10.744 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:47:16.279: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-rmc5x
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
May 13 19:47:16.577: INFO: Waiting up to 5m0s for pod "downward-api-e954b79f-75b7-11e9-8f67-2632f168be36" in namespace "e2e-tests-downward-api-rmc5x" to be "success or failure"
May 13 19:47:16.585: INFO: Pod "downward-api-e954b79f-75b7-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 7.598266ms
May 13 19:47:18.593: INFO: Pod "downward-api-e954b79f-75b7-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01611317s
STEP: Saw pod success
May 13 19:47:18.594: INFO: Pod "downward-api-e954b79f-75b7-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 19:47:18.601: INFO: Trying to get logs from node 10.170.219.153 pod downward-api-e954b79f-75b7-11e9-8f67-2632f168be36 container dapi-container: <nil>
STEP: delete the pod
May 13 19:47:18.641: INFO: Waiting for pod downward-api-e954b79f-75b7-11e9-8f67-2632f168be36 to disappear
May 13 19:47:18.727: INFO: Pod downward-api-e954b79f-75b7-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:47:18.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-rmc5x" for this suite.
May 13 19:47:24.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:47:24.937: INFO: namespace: e2e-tests-downward-api-rmc5x, resource: bindings, ignored listing per whitelist
May 13 19:47:25.073: INFO: namespace e2e-tests-downward-api-rmc5x deletion completed in 6.337942305s

• [SLOW TEST:8.794 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:47:25.074: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-p5mb9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-gb6h
STEP: Creating a pod to test atomic-volume-subpath
May 13 19:47:25.420: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-gb6h" in namespace "e2e-tests-subpath-p5mb9" to be "success or failure"
May 13 19:47:25.430: INFO: Pod "pod-subpath-test-configmap-gb6h": Phase="Pending", Reason="", readiness=false. Elapsed: 9.021553ms
May 13 19:47:27.446: INFO: Pod "pod-subpath-test-configmap-gb6h": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025497979s
May 13 19:47:29.455: INFO: Pod "pod-subpath-test-configmap-gb6h": Phase="Running", Reason="", readiness=false. Elapsed: 4.034529607s
May 13 19:47:31.476: INFO: Pod "pod-subpath-test-configmap-gb6h": Phase="Running", Reason="", readiness=false. Elapsed: 6.055482007s
May 13 19:47:33.484: INFO: Pod "pod-subpath-test-configmap-gb6h": Phase="Running", Reason="", readiness=false. Elapsed: 8.063461487s
May 13 19:47:35.493: INFO: Pod "pod-subpath-test-configmap-gb6h": Phase="Running", Reason="", readiness=false. Elapsed: 10.071950442s
May 13 19:47:37.501: INFO: Pod "pod-subpath-test-configmap-gb6h": Phase="Running", Reason="", readiness=false. Elapsed: 12.08049209s
May 13 19:47:39.512: INFO: Pod "pod-subpath-test-configmap-gb6h": Phase="Running", Reason="", readiness=false. Elapsed: 14.090989565s
May 13 19:47:41.534: INFO: Pod "pod-subpath-test-configmap-gb6h": Phase="Running", Reason="", readiness=false. Elapsed: 16.113164438s
May 13 19:47:43.547: INFO: Pod "pod-subpath-test-configmap-gb6h": Phase="Running", Reason="", readiness=false. Elapsed: 18.12594685s
May 13 19:47:45.555: INFO: Pod "pod-subpath-test-configmap-gb6h": Phase="Running", Reason="", readiness=false. Elapsed: 20.134177391s
May 13 19:47:47.564: INFO: Pod "pod-subpath-test-configmap-gb6h": Phase="Running", Reason="", readiness=false. Elapsed: 22.143052742s
May 13 19:47:49.572: INFO: Pod "pod-subpath-test-configmap-gb6h": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.151368183s
STEP: Saw pod success
May 13 19:47:49.572: INFO: Pod "pod-subpath-test-configmap-gb6h" satisfied condition "success or failure"
May 13 19:47:49.628: INFO: Trying to get logs from node 10.170.219.177 pod pod-subpath-test-configmap-gb6h container test-container-subpath-configmap-gb6h: <nil>
STEP: delete the pod
May 13 19:47:49.668: INFO: Waiting for pod pod-subpath-test-configmap-gb6h to disappear
May 13 19:47:49.678: INFO: Pod pod-subpath-test-configmap-gb6h no longer exists
STEP: Deleting pod pod-subpath-test-configmap-gb6h
May 13 19:47:49.678: INFO: Deleting pod "pod-subpath-test-configmap-gb6h" in namespace "e2e-tests-subpath-p5mb9"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:47:49.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-p5mb9" for this suite.
May 13 19:47:55.721: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:47:56.091: INFO: namespace: e2e-tests-subpath-p5mb9, resource: bindings, ignored listing per whitelist
May 13 19:47:56.158: INFO: namespace e2e-tests-subpath-p5mb9 deletion completed in 6.465234122s

• [SLOW TEST:31.084 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:47:56.158: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-rrhgf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
May 13 19:47:56.449: INFO: Waiting up to 5m0s for pod "pod-01189750-75b8-11e9-8f67-2632f168be36" in namespace "e2e-tests-emptydir-rrhgf" to be "success or failure"
May 13 19:47:56.530: INFO: Pod "pod-01189750-75b8-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 81.517197ms
May 13 19:47:58.539: INFO: Pod "pod-01189750-75b8-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.089952903s
STEP: Saw pod success
May 13 19:47:58.539: INFO: Pod "pod-01189750-75b8-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 19:47:58.547: INFO: Trying to get logs from node 10.170.219.153 pod pod-01189750-75b8-11e9-8f67-2632f168be36 container test-container: <nil>
STEP: delete the pod
May 13 19:47:58.588: INFO: Waiting for pod pod-01189750-75b8-11e9-8f67-2632f168be36 to disappear
May 13 19:47:58.598: INFO: Pod pod-01189750-75b8-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:47:58.598: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-rrhgf" for this suite.
May 13 19:48:04.634: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:48:04.858: INFO: namespace: e2e-tests-emptydir-rrhgf, resource: bindings, ignored listing per whitelist
May 13 19:48:04.971: INFO: namespace e2e-tests-emptydir-rrhgf deletion completed in 6.365083969s

• [SLOW TEST:8.813 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:48:04.971: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-chvth
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-0673ee15-75b8-11e9-8f67-2632f168be36
STEP: Creating a pod to test consume configMaps
May 13 19:48:05.446: INFO: Waiting up to 5m0s for pod "pod-configmaps-0675692f-75b8-11e9-8f67-2632f168be36" in namespace "e2e-tests-configmap-chvth" to be "success or failure"
May 13 19:48:05.454: INFO: Pod "pod-configmaps-0675692f-75b8-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 8.38333ms
May 13 19:48:07.463: INFO: Pod "pod-configmaps-0675692f-75b8-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016977816s
STEP: Saw pod success
May 13 19:48:07.463: INFO: Pod "pod-configmaps-0675692f-75b8-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 19:48:07.471: INFO: Trying to get logs from node 10.170.219.177 pod pod-configmaps-0675692f-75b8-11e9-8f67-2632f168be36 container configmap-volume-test: <nil>
STEP: delete the pod
May 13 19:48:07.512: INFO: Waiting for pod pod-configmaps-0675692f-75b8-11e9-8f67-2632f168be36 to disappear
May 13 19:48:07.519: INFO: Pod pod-configmaps-0675692f-75b8-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:48:07.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-chvth" for this suite.
May 13 19:48:13.570: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:48:13.661: INFO: namespace: e2e-tests-configmap-chvth, resource: bindings, ignored listing per whitelist
May 13 19:48:13.815: INFO: namespace e2e-tests-configmap-chvth deletion completed in 6.289781074s

• [SLOW TEST:8.844 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:48:13.816: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-dc5kt
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
May 13 19:48:14.114: INFO: Waiting up to 5m0s for pod "pod-0ba02a21-75b8-11e9-8f67-2632f168be36" in namespace "e2e-tests-emptydir-dc5kt" to be "success or failure"
May 13 19:48:14.125: INFO: Pod "pod-0ba02a21-75b8-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 11.081995ms
May 13 19:48:16.134: INFO: Pod "pod-0ba02a21-75b8-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020029883s
May 13 19:48:18.143: INFO: Pod "pod-0ba02a21-75b8-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028816742s
STEP: Saw pod success
May 13 19:48:18.143: INFO: Pod "pod-0ba02a21-75b8-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 19:48:18.151: INFO: Trying to get logs from node 10.170.219.177 pod pod-0ba02a21-75b8-11e9-8f67-2632f168be36 container test-container: <nil>
STEP: delete the pod
May 13 19:48:18.191: INFO: Waiting for pod pod-0ba02a21-75b8-11e9-8f67-2632f168be36 to disappear
May 13 19:48:18.198: INFO: Pod pod-0ba02a21-75b8-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:48:18.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-dc5kt" for this suite.
May 13 19:48:24.248: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:48:24.385: INFO: namespace: e2e-tests-emptydir-dc5kt, resource: bindings, ignored listing per whitelist
May 13 19:48:24.582: INFO: namespace e2e-tests-emptydir-dc5kt deletion completed in 6.375489128s

• [SLOW TEST:10.766 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:48:24.582: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-4n8l5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-4n8l5
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-4n8l5
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-4n8l5
May 13 19:48:24.996: INFO: Found 0 stateful pods, waiting for 1
May 13 19:48:35.020: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
May 13 19:48:35.029: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 exec --namespace=e2e-tests-statefulset-4n8l5 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 13 19:48:35.313: INFO: stderr: ""
May 13 19:48:35.313: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 13 19:48:35.313: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 13 19:48:35.321: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
May 13 19:48:45.342: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 13 19:48:45.342: INFO: Waiting for statefulset status.replicas updated to 0
May 13 19:48:45.369: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
May 13 19:48:45.369: INFO: ss-0  10.170.219.153  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:25 +0000 UTC  }]
May 13 19:48:45.369: INFO: 
May 13 19:48:45.369: INFO: StatefulSet ss has not reached scale 3, at 1
May 13 19:48:46.377: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.992316371s
May 13 19:48:47.386: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.984211635s
May 13 19:48:48.395: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.975341753s
May 13 19:48:49.404: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.966139026s
May 13 19:48:50.413: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.957365721s
May 13 19:48:51.425: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.948940175s
May 13 19:48:52.520: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.937002083s
May 13 19:48:53.567: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.841826943s
May 13 19:48:54.575: INFO: Verifying statefulset ss doesn't scale past 3 for another 795.081253ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-4n8l5
May 13 19:48:55.620: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 exec --namespace=e2e-tests-statefulset-4n8l5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 13 19:48:55.998: INFO: stderr: ""
May 13 19:48:55.999: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 13 19:48:55.999: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 13 19:48:55.999: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 exec --namespace=e2e-tests-statefulset-4n8l5 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 13 19:48:56.274: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
May 13 19:48:56.274: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 13 19:48:56.274: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 13 19:48:56.274: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 exec --namespace=e2e-tests-statefulset-4n8l5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
May 13 19:48:56.753: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
May 13 19:48:56.753: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
May 13 19:48:56.753: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

May 13 19:48:56.762: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
May 13 19:48:56.762: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
May 13 19:48:56.762: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
May 13 19:48:56.769: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 exec --namespace=e2e-tests-statefulset-4n8l5 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 13 19:48:57.069: INFO: stderr: ""
May 13 19:48:57.069: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 13 19:48:57.069: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 13 19:48:57.070: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 exec --namespace=e2e-tests-statefulset-4n8l5 ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 13 19:48:57.320: INFO: stderr: ""
May 13 19:48:57.320: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 13 19:48:57.320: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 13 19:48:57.320: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 exec --namespace=e2e-tests-statefulset-4n8l5 ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
May 13 19:48:57.612: INFO: stderr: ""
May 13 19:48:57.612: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
May 13 19:48:57.612: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

May 13 19:48:57.612: INFO: Waiting for statefulset status.replicas updated to 0
May 13 19:48:57.625: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
May 13 19:49:07.652: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 13 19:49:07.652: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
May 13 19:49:07.652: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
May 13 19:49:07.672: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
May 13 19:49:07.672: INFO: ss-0  10.170.219.153  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:25 +0000 UTC  }]
May 13 19:49:07.672: INFO: ss-1  10.170.219.177  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:45 +0000 UTC  }]
May 13 19:49:07.672: INFO: ss-2  10.170.219.151  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:45 +0000 UTC  }]
May 13 19:49:07.672: INFO: 
May 13 19:49:07.672: INFO: StatefulSet ss has not reached scale 0, at 3
May 13 19:49:08.680: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
May 13 19:49:08.680: INFO: ss-0  10.170.219.153  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:25 +0000 UTC  }]
May 13 19:49:08.680: INFO: ss-1  10.170.219.177  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:45 +0000 UTC  }]
May 13 19:49:08.680: INFO: ss-2  10.170.219.151  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:45 +0000 UTC  }]
May 13 19:49:08.680: INFO: 
May 13 19:49:08.680: INFO: StatefulSet ss has not reached scale 0, at 3
May 13 19:49:09.689: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
May 13 19:49:09.689: INFO: ss-0  10.170.219.153  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:25 +0000 UTC  }]
May 13 19:49:09.689: INFO: ss-2  10.170.219.151  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:45 +0000 UTC  }]
May 13 19:49:09.689: INFO: 
May 13 19:49:09.689: INFO: StatefulSet ss has not reached scale 0, at 2
May 13 19:49:10.698: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
May 13 19:49:10.698: INFO: ss-0  10.170.219.153  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:25 +0000 UTC  }]
May 13 19:49:10.698: INFO: ss-2  10.170.219.151  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:45 +0000 UTC  }]
May 13 19:49:10.698: INFO: 
May 13 19:49:10.698: INFO: StatefulSet ss has not reached scale 0, at 2
May 13 19:49:11.713: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
May 13 19:49:11.713: INFO: ss-0  10.170.219.153  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:25 +0000 UTC  }]
May 13 19:49:11.713: INFO: ss-2  10.170.219.151  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:45 +0000 UTC  }]
May 13 19:49:11.713: INFO: 
May 13 19:49:11.713: INFO: StatefulSet ss has not reached scale 0, at 2
May 13 19:49:12.721: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
May 13 19:49:12.721: INFO: ss-0  10.170.219.153  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:25 +0000 UTC  }]
May 13 19:49:12.721: INFO: 
May 13 19:49:12.721: INFO: StatefulSet ss has not reached scale 0, at 1
May 13 19:49:13.732: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
May 13 19:49:13.732: INFO: ss-0  10.170.219.153  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:25 +0000 UTC  }]
May 13 19:49:13.732: INFO: 
May 13 19:49:13.732: INFO: StatefulSet ss has not reached scale 0, at 1
May 13 19:49:14.741: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
May 13 19:49:14.741: INFO: ss-0  10.170.219.153  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:25 +0000 UTC  }]
May 13 19:49:14.741: INFO: 
May 13 19:49:14.741: INFO: StatefulSet ss has not reached scale 0, at 1
May 13 19:49:15.749: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
May 13 19:49:15.749: INFO: ss-0  10.170.219.153  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:57 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 19:48:25 +0000 UTC  }]
May 13 19:49:15.750: INFO: 
May 13 19:49:15.750: INFO: StatefulSet ss has not reached scale 0, at 1
May 13 19:49:16.758: INFO: Verifying statefulset ss doesn't scale past 0 for another 914.500424ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-4n8l5
May 13 19:49:17.782: INFO: Scaling statefulset ss to 0
May 13 19:49:17.800: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 13 19:49:17.805: INFO: Deleting all statefulset in ns e2e-tests-statefulset-4n8l5
May 13 19:49:17.810: INFO: Scaling statefulset ss to 0
May 13 19:49:17.832: INFO: Waiting for statefulset status.replicas updated to 0
May 13 19:49:17.837: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:49:17.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-4n8l5" for this suite.
May 13 19:49:23.902: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:49:24.518: INFO: namespace: e2e-tests-statefulset-4n8l5, resource: bindings, ignored listing per whitelist
May 13 19:49:24.522: INFO: namespace e2e-tests-statefulset-4n8l5 deletion completed in 6.651491215s

• [SLOW TEST:59.941 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:49:24.523: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-pgzg2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:295
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
May 13 19:49:24.805: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 create -f - --namespace=e2e-tests-kubectl-pgzg2'
May 13 19:49:25.114: INFO: stderr: ""
May 13 19:49:25.114: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 13 19:49:25.114: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-pgzg2'
May 13 19:49:25.224: INFO: stderr: ""
May 13 19:49:25.224: INFO: stdout: "update-demo-nautilus-5vddr update-demo-nautilus-77b5n "
May 13 19:49:25.224: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 get pods update-demo-nautilus-5vddr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-pgzg2'
May 13 19:49:25.332: INFO: stderr: ""
May 13 19:49:25.332: INFO: stdout: ""
May 13 19:49:25.332: INFO: update-demo-nautilus-5vddr is created but not running
May 13 19:49:30.332: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-pgzg2'
May 13 19:49:30.439: INFO: stderr: ""
May 13 19:49:30.439: INFO: stdout: "update-demo-nautilus-5vddr update-demo-nautilus-77b5n "
May 13 19:49:30.439: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 get pods update-demo-nautilus-5vddr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-pgzg2'
May 13 19:49:30.557: INFO: stderr: ""
May 13 19:49:30.557: INFO: stdout: "true"
May 13 19:49:30.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 get pods update-demo-nautilus-5vddr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-pgzg2'
May 13 19:49:30.663: INFO: stderr: ""
May 13 19:49:30.663: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 13 19:49:30.663: INFO: validating pod update-demo-nautilus-5vddr
May 13 19:49:30.676: INFO: got data: {
  "image": "nautilus.jpg"
}

May 13 19:49:30.676: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 13 19:49:30.676: INFO: update-demo-nautilus-5vddr is verified up and running
May 13 19:49:30.676: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 get pods update-demo-nautilus-77b5n -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-pgzg2'
May 13 19:49:30.798: INFO: stderr: ""
May 13 19:49:30.798: INFO: stdout: "true"
May 13 19:49:30.798: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 get pods update-demo-nautilus-77b5n -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-pgzg2'
May 13 19:49:30.899: INFO: stderr: ""
May 13 19:49:30.899: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May 13 19:49:30.899: INFO: validating pod update-demo-nautilus-77b5n
May 13 19:49:30.913: INFO: got data: {
  "image": "nautilus.jpg"
}

May 13 19:49:30.913: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 13 19:49:30.913: INFO: update-demo-nautilus-77b5n is verified up and running
STEP: rolling-update to new replication controller
May 13 19:49:30.914: INFO: scanned /root for discovery docs: <nil>
May 13 19:49:30.914: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-pgzg2'
May 13 19:49:53.653: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
May 13 19:49:53.653: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 13 19:49:53.653: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-pgzg2'
May 13 19:49:53.757: INFO: stderr: ""
May 13 19:49:53.757: INFO: stdout: "update-demo-kitten-pr4jj update-demo-kitten-zrqpg "
May 13 19:49:53.757: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 get pods update-demo-kitten-pr4jj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-pgzg2'
May 13 19:49:53.865: INFO: stderr: ""
May 13 19:49:53.865: INFO: stdout: "true"
May 13 19:49:53.865: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 get pods update-demo-kitten-pr4jj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-pgzg2'
May 13 19:49:53.986: INFO: stderr: ""
May 13 19:49:53.986: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
May 13 19:49:53.986: INFO: validating pod update-demo-kitten-pr4jj
May 13 19:49:54.001: INFO: got data: {
  "image": "kitten.jpg"
}

May 13 19:49:54.001: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
May 13 19:49:54.001: INFO: update-demo-kitten-pr4jj is verified up and running
May 13 19:49:54.001: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 get pods update-demo-kitten-zrqpg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-pgzg2'
May 13 19:49:54.109: INFO: stderr: ""
May 13 19:49:54.109: INFO: stdout: "true"
May 13 19:49:54.109: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 get pods update-demo-kitten-zrqpg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-pgzg2'
May 13 19:49:54.209: INFO: stderr: ""
May 13 19:49:54.209: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
May 13 19:49:54.209: INFO: validating pod update-demo-kitten-zrqpg
May 13 19:49:54.223: INFO: got data: {
  "image": "kitten.jpg"
}

May 13 19:49:54.223: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
May 13 19:49:54.223: INFO: update-demo-kitten-zrqpg is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:49:54.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-pgzg2" for this suite.
May 13 19:50:18.259: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:50:18.397: INFO: namespace: e2e-tests-kubectl-pgzg2, resource: bindings, ignored listing per whitelist
May 13 19:50:18.580: INFO: namespace e2e-tests-kubectl-pgzg2 deletion completed in 24.349268678s

• [SLOW TEST:54.058 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:50:18.581: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-w6ql2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-wfpf
STEP: Creating a pod to test atomic-volume-subpath
May 13 19:50:18.885: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-wfpf" in namespace "e2e-tests-subpath-w6ql2" to be "success or failure"
May 13 19:50:18.892: INFO: Pod "pod-subpath-test-configmap-wfpf": Phase="Pending", Reason="", readiness=false. Elapsed: 7.176846ms
May 13 19:50:20.900: INFO: Pod "pod-subpath-test-configmap-wfpf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015260407s
May 13 19:50:22.909: INFO: Pod "pod-subpath-test-configmap-wfpf": Phase="Running", Reason="", readiness=false. Elapsed: 4.023581469s
May 13 19:50:24.918: INFO: Pod "pod-subpath-test-configmap-wfpf": Phase="Running", Reason="", readiness=false. Elapsed: 6.033058687s
May 13 19:50:26.938: INFO: Pod "pod-subpath-test-configmap-wfpf": Phase="Running", Reason="", readiness=false. Elapsed: 8.05341209s
May 13 19:50:28.947: INFO: Pod "pod-subpath-test-configmap-wfpf": Phase="Running", Reason="", readiness=false. Elapsed: 10.061868565s
May 13 19:50:30.959: INFO: Pod "pod-subpath-test-configmap-wfpf": Phase="Running", Reason="", readiness=false. Elapsed: 12.073587455s
May 13 19:50:32.967: INFO: Pod "pod-subpath-test-configmap-wfpf": Phase="Running", Reason="", readiness=false. Elapsed: 14.081845352s
May 13 19:50:34.975: INFO: Pod "pod-subpath-test-configmap-wfpf": Phase="Running", Reason="", readiness=false. Elapsed: 16.090466074s
May 13 19:50:36.997: INFO: Pod "pod-subpath-test-configmap-wfpf": Phase="Running", Reason="", readiness=false. Elapsed: 18.111783855s
May 13 19:50:39.005: INFO: Pod "pod-subpath-test-configmap-wfpf": Phase="Running", Reason="", readiness=false. Elapsed: 20.11998139s
May 13 19:50:41.015: INFO: Pod "pod-subpath-test-configmap-wfpf": Phase="Running", Reason="", readiness=false. Elapsed: 22.129921764s
May 13 19:50:43.023: INFO: Pod "pod-subpath-test-configmap-wfpf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.138425502s
STEP: Saw pod success
May 13 19:50:43.023: INFO: Pod "pod-subpath-test-configmap-wfpf" satisfied condition "success or failure"
May 13 19:50:43.031: INFO: Trying to get logs from node 10.170.219.153 pod pod-subpath-test-configmap-wfpf container test-container-subpath-configmap-wfpf: <nil>
STEP: delete the pod
May 13 19:50:43.076: INFO: Waiting for pod pod-subpath-test-configmap-wfpf to disappear
May 13 19:50:43.084: INFO: Pod pod-subpath-test-configmap-wfpf no longer exists
STEP: Deleting pod pod-subpath-test-configmap-wfpf
May 13 19:50:43.084: INFO: Deleting pod "pod-subpath-test-configmap-wfpf" in namespace "e2e-tests-subpath-w6ql2"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:50:43.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-w6ql2" for this suite.
May 13 19:50:49.129: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:50:49.331: INFO: namespace: e2e-tests-subpath-w6ql2, resource: bindings, ignored listing per whitelist
May 13 19:50:49.489: INFO: namespace e2e-tests-subpath-w6ql2 deletion completed in 6.38877072s

• [SLOW TEST:30.908 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:50:49.489: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-wk59n
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-6872250f-75b8-11e9-8f67-2632f168be36
STEP: Creating a pod to test consume configMaps
May 13 19:50:49.850: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-6873aa08-75b8-11e9-8f67-2632f168be36" in namespace "e2e-tests-projected-wk59n" to be "success or failure"
May 13 19:50:49.859: INFO: Pod "pod-projected-configmaps-6873aa08-75b8-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 8.278532ms
May 13 19:50:51.870: INFO: Pod "pod-projected-configmaps-6873aa08-75b8-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019884982s
STEP: Saw pod success
May 13 19:50:51.870: INFO: Pod "pod-projected-configmaps-6873aa08-75b8-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 19:50:51.878: INFO: Trying to get logs from node 10.170.219.177 pod pod-projected-configmaps-6873aa08-75b8-11e9-8f67-2632f168be36 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 13 19:50:51.918: INFO: Waiting for pod pod-projected-configmaps-6873aa08-75b8-11e9-8f67-2632f168be36 to disappear
May 13 19:50:51.925: INFO: Pod pod-projected-configmaps-6873aa08-75b8-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:50:51.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wk59n" for this suite.
May 13 19:50:57.973: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:50:58.685: INFO: namespace: e2e-tests-projected-wk59n, resource: bindings, ignored listing per whitelist
May 13 19:50:58.819: INFO: namespace e2e-tests-projected-wk59n deletion completed in 6.885788297s

• [SLOW TEST:9.329 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:50:58.819: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-qm6vt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-8lsl
STEP: Creating a pod to test atomic-volume-subpath
May 13 19:50:59.122: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-8lsl" in namespace "e2e-tests-subpath-qm6vt" to be "success or failure"
May 13 19:50:59.130: INFO: Pod "pod-subpath-test-secret-8lsl": Phase="Pending", Reason="", readiness=false. Elapsed: 8.543061ms
May 13 19:51:01.138: INFO: Pod "pod-subpath-test-secret-8lsl": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01646935s
May 13 19:51:03.146: INFO: Pod "pod-subpath-test-secret-8lsl": Phase="Running", Reason="", readiness=false. Elapsed: 4.024811009s
May 13 19:51:05.155: INFO: Pod "pod-subpath-test-secret-8lsl": Phase="Running", Reason="", readiness=false. Elapsed: 6.033014571s
May 13 19:51:07.164: INFO: Pod "pod-subpath-test-secret-8lsl": Phase="Running", Reason="", readiness=false. Elapsed: 8.042165069s
May 13 19:51:09.184: INFO: Pod "pod-subpath-test-secret-8lsl": Phase="Running", Reason="", readiness=false. Elapsed: 10.062576912s
May 13 19:51:11.193: INFO: Pod "pod-subpath-test-secret-8lsl": Phase="Running", Reason="", readiness=false. Elapsed: 12.070973229s
May 13 19:51:13.201: INFO: Pod "pod-subpath-test-secret-8lsl": Phase="Running", Reason="", readiness=false. Elapsed: 14.079338422s
May 13 19:51:15.209: INFO: Pod "pod-subpath-test-secret-8lsl": Phase="Running", Reason="", readiness=false. Elapsed: 16.08779422s
May 13 19:51:17.218: INFO: Pod "pod-subpath-test-secret-8lsl": Phase="Running", Reason="", readiness=false. Elapsed: 18.096325497s
May 13 19:51:19.238: INFO: Pod "pod-subpath-test-secret-8lsl": Phase="Running", Reason="", readiness=false. Elapsed: 20.116455764s
May 13 19:51:21.246: INFO: Pod "pod-subpath-test-secret-8lsl": Phase="Running", Reason="", readiness=false. Elapsed: 22.124810257s
May 13 19:51:23.256: INFO: Pod "pod-subpath-test-secret-8lsl": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.134035928s
STEP: Saw pod success
May 13 19:51:23.256: INFO: Pod "pod-subpath-test-secret-8lsl" satisfied condition "success or failure"
May 13 19:51:23.264: INFO: Trying to get logs from node 10.170.219.153 pod pod-subpath-test-secret-8lsl container test-container-subpath-secret-8lsl: <nil>
STEP: delete the pod
May 13 19:51:23.420: INFO: Waiting for pod pod-subpath-test-secret-8lsl to disappear
May 13 19:51:23.427: INFO: Pod pod-subpath-test-secret-8lsl no longer exists
STEP: Deleting pod pod-subpath-test-secret-8lsl
May 13 19:51:23.427: INFO: Deleting pod "pod-subpath-test-secret-8lsl" in namespace "e2e-tests-subpath-qm6vt"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:51:23.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-qm6vt" for this suite.
May 13 19:51:29.489: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:51:29.617: INFO: namespace: e2e-tests-subpath-qm6vt, resource: bindings, ignored listing per whitelist
May 13 19:51:29.741: INFO: namespace e2e-tests-subpath-qm6vt deletion completed in 6.299127879s

• [SLOW TEST:30.922 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:51:29.741: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-fvw4p
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
May 13 19:51:30.033: INFO: Waiting up to 5m0s for pod "pod-8066ac0a-75b8-11e9-8f67-2632f168be36" in namespace "e2e-tests-emptydir-fvw4p" to be "success or failure"
May 13 19:51:30.042: INFO: Pod "pod-8066ac0a-75b8-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 8.642363ms
May 13 19:51:32.051: INFO: Pod "pod-8066ac0a-75b8-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017488705s
STEP: Saw pod success
May 13 19:51:32.051: INFO: Pod "pod-8066ac0a-75b8-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 19:51:32.058: INFO: Trying to get logs from node 10.170.219.177 pod pod-8066ac0a-75b8-11e9-8f67-2632f168be36 container test-container: <nil>
STEP: delete the pod
May 13 19:51:32.103: INFO: Waiting for pod pod-8066ac0a-75b8-11e9-8f67-2632f168be36 to disappear
May 13 19:51:32.112: INFO: Pod pod-8066ac0a-75b8-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:51:32.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-fvw4p" for this suite.
May 13 19:51:38.157: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:51:38.309: INFO: namespace: e2e-tests-emptydir-fvw4p, resource: bindings, ignored listing per whitelist
May 13 19:51:38.469: INFO: namespace e2e-tests-emptydir-fvw4p deletion completed in 6.348340353s

• [SLOW TEST:8.728 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:51:38.471: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-nzhq9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
May 13 19:51:38.749: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 api-versions'
May 13 19:51:38.878: INFO: stderr: ""
May 13 19:51:38.879: INFO: stdout: "admissionregistration.k8s.io/v1alpha1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\nbatch/v2alpha1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:51:38.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-nzhq9" for this suite.
May 13 19:51:44.917: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:51:45.143: INFO: namespace: e2e-tests-kubectl-nzhq9, resource: bindings, ignored listing per whitelist
May 13 19:51:45.268: INFO: namespace e2e-tests-kubectl-nzhq9 deletion completed in 6.381483792s

• [SLOW TEST:6.797 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:51:45.269: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-5rb82
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-5rb82.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-5rb82.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-5rb82.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default;check="$$(dig +tcp +noall +answer +search kubernetes.default A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc;check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-5rb82.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-5rb82.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-5rb82.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 13 19:51:50.045: INFO: DNS probes using e2e-tests-dns-5rb82/dns-test-89c6372b-75b8-11e9-8f67-2632f168be36 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:51:50.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-5rb82" for this suite.
May 13 19:51:56.106: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:51:56.282: INFO: namespace: e2e-tests-dns-5rb82, resource: bindings, ignored listing per whitelist
May 13 19:51:56.364: INFO: namespace e2e-tests-dns-5rb82 deletion completed in 6.284869766s

• [SLOW TEST:11.094 seconds]
[sig-network] DNS
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:51:56.364: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-qg8j4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
May 13 19:51:56.682: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-qg8j4,SelfLink:/api/v1/namespaces/e2e-tests-watch-qg8j4/configmaps/e2e-watch-test-label-changed,UID:9045931d-75b8-11e9-b786-da20024d205c,ResourceVersion:49188,Generation:0,CreationTimestamp:2019-05-13 19:51:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 13 19:51:56.682: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-qg8j4,SelfLink:/api/v1/namespaces/e2e-tests-watch-qg8j4/configmaps/e2e-watch-test-label-changed,UID:9045931d-75b8-11e9-b786-da20024d205c,ResourceVersion:49189,Generation:0,CreationTimestamp:2019-05-13 19:51:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
May 13 19:51:56.682: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-qg8j4,SelfLink:/api/v1/namespaces/e2e-tests-watch-qg8j4/configmaps/e2e-watch-test-label-changed,UID:9045931d-75b8-11e9-b786-da20024d205c,ResourceVersion:49190,Generation:0,CreationTimestamp:2019-05-13 19:51:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
May 13 19:52:06.765: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-qg8j4,SelfLink:/api/v1/namespaces/e2e-tests-watch-qg8j4/configmaps/e2e-watch-test-label-changed,UID:9045931d-75b8-11e9-b786-da20024d205c,ResourceVersion:49208,Generation:0,CreationTimestamp:2019-05-13 19:51:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 13 19:52:06.765: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-qg8j4,SelfLink:/api/v1/namespaces/e2e-tests-watch-qg8j4/configmaps/e2e-watch-test-label-changed,UID:9045931d-75b8-11e9-b786-da20024d205c,ResourceVersion:49209,Generation:0,CreationTimestamp:2019-05-13 19:51:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
May 13 19:52:06.766: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-qg8j4,SelfLink:/api/v1/namespaces/e2e-tests-watch-qg8j4/configmaps/e2e-watch-test-label-changed,UID:9045931d-75b8-11e9-b786-da20024d205c,ResourceVersion:49210,Generation:0,CreationTimestamp:2019-05-13 19:51:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:52:06.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-qg8j4" for this suite.
May 13 19:52:13.091: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:52:13.352: INFO: namespace: e2e-tests-watch-qg8j4, resource: bindings, ignored listing per whitelist
May 13 19:52:13.382: INFO: namespace e2e-tests-watch-qg8j4 deletion completed in 6.608007725s

• [SLOW TEST:17.018 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:52:13.382: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-tz26c
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-6rb5
STEP: Creating a pod to test atomic-volume-subpath
May 13 19:52:13.801: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-6rb5" in namespace "e2e-tests-subpath-tz26c" to be "success or failure"
May 13 19:52:13.815: INFO: Pod "pod-subpath-test-projected-6rb5": Phase="Pending", Reason="", readiness=false. Elapsed: 13.824851ms
May 13 19:52:15.823: INFO: Pod "pod-subpath-test-projected-6rb5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022192867s
May 13 19:52:17.843: INFO: Pod "pod-subpath-test-projected-6rb5": Phase="Running", Reason="", readiness=false. Elapsed: 4.042386873s
May 13 19:52:19.920: INFO: Pod "pod-subpath-test-projected-6rb5": Phase="Running", Reason="", readiness=false. Elapsed: 6.118921612s
May 13 19:52:21.928: INFO: Pod "pod-subpath-test-projected-6rb5": Phase="Running", Reason="", readiness=false. Elapsed: 8.127395905s
May 13 19:52:23.937: INFO: Pod "pod-subpath-test-projected-6rb5": Phase="Running", Reason="", readiness=false. Elapsed: 10.1358199s
May 13 19:52:25.944: INFO: Pod "pod-subpath-test-projected-6rb5": Phase="Running", Reason="", readiness=false. Elapsed: 12.143618048s
May 13 19:52:27.969: INFO: Pod "pod-subpath-test-projected-6rb5": Phase="Running", Reason="", readiness=false. Elapsed: 14.168120401s
May 13 19:52:29.978: INFO: Pod "pod-subpath-test-projected-6rb5": Phase="Running", Reason="", readiness=false. Elapsed: 16.177079967s
May 13 19:52:32.020: INFO: Pod "pod-subpath-test-projected-6rb5": Phase="Running", Reason="", readiness=false. Elapsed: 18.218860916s
May 13 19:52:34.028: INFO: Pod "pod-subpath-test-projected-6rb5": Phase="Running", Reason="", readiness=false. Elapsed: 20.227529823s
May 13 19:52:36.037: INFO: Pod "pod-subpath-test-projected-6rb5": Phase="Running", Reason="", readiness=false. Elapsed: 22.235858008s
May 13 19:52:38.059: INFO: Pod "pod-subpath-test-projected-6rb5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.258126792s
STEP: Saw pod success
May 13 19:52:38.059: INFO: Pod "pod-subpath-test-projected-6rb5" satisfied condition "success or failure"
May 13 19:52:38.067: INFO: Trying to get logs from node 10.170.219.177 pod pod-subpath-test-projected-6rb5 container test-container-subpath-projected-6rb5: <nil>
STEP: delete the pod
May 13 19:52:38.107: INFO: Waiting for pod pod-subpath-test-projected-6rb5 to disappear
May 13 19:52:38.115: INFO: Pod pod-subpath-test-projected-6rb5 no longer exists
STEP: Deleting pod pod-subpath-test-projected-6rb5
May 13 19:52:38.115: INFO: Deleting pod "pod-subpath-test-projected-6rb5" in namespace "e2e-tests-subpath-tz26c"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:52:38.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-tz26c" for this suite.
May 13 19:52:44.159: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:52:44.231: INFO: namespace: e2e-tests-subpath-tz26c, resource: bindings, ignored listing per whitelist
May 13 19:52:44.407: INFO: namespace e2e-tests-subpath-tz26c deletion completed in 6.27630348s

• [SLOW TEST:31.025 seconds]
[sig-storage] Subpath
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:52:44.407: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-79kkb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1052
STEP: creating the pod
May 13 19:52:44.699: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 create -f - --namespace=e2e-tests-kubectl-79kkb'
May 13 19:52:45.003: INFO: stderr: ""
May 13 19:52:45.004: INFO: stdout: "pod/pause created\n"
May 13 19:52:45.004: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
May 13 19:52:45.004: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-79kkb" to be "running and ready"
May 13 19:52:45.014: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 10.512575ms
May 13 19:52:47.023: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.01910176s
May 13 19:52:47.023: INFO: Pod "pause" satisfied condition "running and ready"
May 13 19:52:47.023: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
May 13 19:52:47.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-79kkb'
May 13 19:52:47.121: INFO: stderr: ""
May 13 19:52:47.121: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
May 13 19:52:47.121: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 get pod pause -L testing-label --namespace=e2e-tests-kubectl-79kkb'
May 13 19:52:47.228: INFO: stderr: ""
May 13 19:52:47.228: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    testing-label-value\n"
STEP: removing the label testing-label of a pod
May 13 19:52:47.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 label pods pause testing-label- --namespace=e2e-tests-kubectl-79kkb'
May 13 19:52:47.336: INFO: stderr: ""
May 13 19:52:47.336: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
May 13 19:52:47.336: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 get pod pause -L testing-label --namespace=e2e-tests-kubectl-79kkb'
May 13 19:52:47.431: INFO: stderr: ""
May 13 19:52:47.431: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1059
STEP: using delete to clean up resources
May 13 19:52:47.431: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-79kkb'
May 13 19:52:47.553: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 13 19:52:47.553: INFO: stdout: "pod \"pause\" force deleted\n"
May 13 19:52:47.553: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-79kkb'
May 13 19:52:47.658: INFO: stderr: "No resources found.\n"
May 13 19:52:47.658: INFO: stdout: ""
May 13 19:52:47.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 get pods -l name=pause --namespace=e2e-tests-kubectl-79kkb -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 13 19:52:47.760: INFO: stderr: ""
May 13 19:52:47.760: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:52:47.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-79kkb" for this suite.
May 13 19:52:53.797: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:52:53.941: INFO: namespace: e2e-tests-kubectl-79kkb, resource: bindings, ignored listing per whitelist
May 13 19:52:54.062: INFO: namespace e2e-tests-kubectl-79kkb deletion completed in 6.292229533s

• [SLOW TEST:9.654 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:52:54.062: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-qzhjj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-b2a76ecb-75b8-11e9-8f67-2632f168be36
STEP: Creating a pod to test consume secrets
May 13 19:52:54.444: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b2b71d11-75b8-11e9-8f67-2632f168be36" in namespace "e2e-tests-projected-qzhjj" to be "success or failure"
May 13 19:52:54.452: INFO: Pod "pod-projected-secrets-b2b71d11-75b8-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 8.076596ms
May 13 19:52:56.462: INFO: Pod "pod-projected-secrets-b2b71d11-75b8-11e9-8f67-2632f168be36": Phase="Running", Reason="", readiness=true. Elapsed: 2.017654026s
May 13 19:52:58.470: INFO: Pod "pod-projected-secrets-b2b71d11-75b8-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026169653s
STEP: Saw pod success
May 13 19:52:58.470: INFO: Pod "pod-projected-secrets-b2b71d11-75b8-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 19:52:58.478: INFO: Trying to get logs from node 10.170.219.177 pod pod-projected-secrets-b2b71d11-75b8-11e9-8f67-2632f168be36 container projected-secret-volume-test: <nil>
STEP: delete the pod
May 13 19:52:58.520: INFO: Waiting for pod pod-projected-secrets-b2b71d11-75b8-11e9-8f67-2632f168be36 to disappear
May 13 19:52:58.529: INFO: Pod pod-projected-secrets-b2b71d11-75b8-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:52:58.529: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qzhjj" for this suite.
May 13 19:53:04.565: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:53:04.702: INFO: namespace: e2e-tests-projected-qzhjj, resource: bindings, ignored listing per whitelist
May 13 19:53:04.848: INFO: namespace e2e-tests-projected-qzhjj deletion completed in 6.311259505s

• [SLOW TEST:10.786 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:53:04.848: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-64d7k
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
May 13 19:53:05.223: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-64d7k'
May 13 19:53:05.359: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May 13 19:53:05.359: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
May 13 19:53:05.364: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-64d7k'
May 13 19:53:05.468: INFO: stderr: ""
May 13 19:53:05.468: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:53:05.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-64d7k" for this suite.
May 13 19:53:27.504: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:53:27.635: INFO: namespace: e2e-tests-kubectl-64d7k, resource: bindings, ignored listing per whitelist
May 13 19:53:27.886: INFO: namespace e2e-tests-kubectl-64d7k deletion completed in 22.411192476s

• [SLOW TEST:23.038 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:53:27.886: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-4mnk5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 13 19:53:28.260: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c6df10d5-75b8-11e9-8f67-2632f168be36" in namespace "e2e-tests-projected-4mnk5" to be "success or failure"
May 13 19:53:28.268: INFO: Pod "downwardapi-volume-c6df10d5-75b8-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 7.391072ms
May 13 19:53:30.276: INFO: Pod "downwardapi-volume-c6df10d5-75b8-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01561409s
May 13 19:53:32.284: INFO: Pod "downwardapi-volume-c6df10d5-75b8-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023976113s
STEP: Saw pod success
May 13 19:53:32.285: INFO: Pod "downwardapi-volume-c6df10d5-75b8-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 19:53:32.292: INFO: Trying to get logs from node 10.170.219.153 pod downwardapi-volume-c6df10d5-75b8-11e9-8f67-2632f168be36 container client-container: <nil>
STEP: delete the pod
May 13 19:53:32.330: INFO: Waiting for pod downwardapi-volume-c6df10d5-75b8-11e9-8f67-2632f168be36 to disappear
May 13 19:53:32.337: INFO: Pod downwardapi-volume-c6df10d5-75b8-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:53:32.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4mnk5" for this suite.
May 13 19:53:38.372: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:53:38.501: INFO: namespace: e2e-tests-projected-4mnk5, resource: bindings, ignored listing per whitelist
May 13 19:53:38.650: INFO: namespace e2e-tests-projected-4mnk5 deletion completed in 6.3052817s

• [SLOW TEST:10.764 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:53:38.650: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-k56rn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
May 13 19:53:38.978: INFO: Number of nodes with available pods: 0
May 13 19:53:38.978: INFO: Node 10.170.219.151 is running more than one daemon pod
May 13 19:53:39.995: INFO: Number of nodes with available pods: 0
May 13 19:53:39.995: INFO: Node 10.170.219.151 is running more than one daemon pod
May 13 19:53:40.995: INFO: Number of nodes with available pods: 3
May 13 19:53:40.995: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
May 13 19:53:41.038: INFO: Number of nodes with available pods: 2
May 13 19:53:41.038: INFO: Node 10.170.219.177 is running more than one daemon pod
May 13 19:53:42.120: INFO: Number of nodes with available pods: 2
May 13 19:53:42.120: INFO: Node 10.170.219.177 is running more than one daemon pod
May 13 19:53:43.059: INFO: Number of nodes with available pods: 2
May 13 19:53:43.059: INFO: Node 10.170.219.177 is running more than one daemon pod
May 13 19:53:44.058: INFO: Number of nodes with available pods: 2
May 13 19:53:44.058: INFO: Node 10.170.219.177 is running more than one daemon pod
May 13 19:53:45.120: INFO: Number of nodes with available pods: 2
May 13 19:53:45.120: INFO: Node 10.170.219.177 is running more than one daemon pod
May 13 19:53:46.056: INFO: Number of nodes with available pods: 2
May 13 19:53:46.056: INFO: Node 10.170.219.177 is running more than one daemon pod
May 13 19:53:47.057: INFO: Number of nodes with available pods: 2
May 13 19:53:47.057: INFO: Node 10.170.219.177 is running more than one daemon pod
May 13 19:53:48.079: INFO: Number of nodes with available pods: 2
May 13 19:53:48.079: INFO: Node 10.170.219.177 is running more than one daemon pod
May 13 19:53:49.056: INFO: Number of nodes with available pods: 2
May 13 19:53:49.056: INFO: Node 10.170.219.177 is running more than one daemon pod
May 13 19:53:50.057: INFO: Number of nodes with available pods: 2
May 13 19:53:50.057: INFO: Node 10.170.219.177 is running more than one daemon pod
May 13 19:53:51.129: INFO: Number of nodes with available pods: 2
May 13 19:53:51.129: INFO: Node 10.170.219.177 is running more than one daemon pod
May 13 19:53:52.056: INFO: Number of nodes with available pods: 2
May 13 19:53:52.056: INFO: Node 10.170.219.177 is running more than one daemon pod
May 13 19:53:53.055: INFO: Number of nodes with available pods: 2
May 13 19:53:53.055: INFO: Node 10.170.219.177 is running more than one daemon pod
May 13 19:53:54.057: INFO: Number of nodes with available pods: 2
May 13 19:53:54.057: INFO: Node 10.170.219.177 is running more than one daemon pod
May 13 19:53:55.057: INFO: Number of nodes with available pods: 2
May 13 19:53:55.057: INFO: Node 10.170.219.177 is running more than one daemon pod
May 13 19:53:56.067: INFO: Number of nodes with available pods: 2
May 13 19:53:56.067: INFO: Node 10.170.219.177 is running more than one daemon pod
May 13 19:53:57.054: INFO: Number of nodes with available pods: 2
May 13 19:53:57.055: INFO: Node 10.170.219.177 is running more than one daemon pod
May 13 19:53:58.061: INFO: Number of nodes with available pods: 2
May 13 19:53:58.061: INFO: Node 10.170.219.177 is running more than one daemon pod
May 13 19:53:59.128: INFO: Number of nodes with available pods: 2
May 13 19:53:59.128: INFO: Node 10.170.219.177 is running more than one daemon pod
May 13 19:54:00.056: INFO: Number of nodes with available pods: 2
May 13 19:54:00.056: INFO: Node 10.170.219.177 is running more than one daemon pod
May 13 19:54:01.056: INFO: Number of nodes with available pods: 2
May 13 19:54:01.056: INFO: Node 10.170.219.177 is running more than one daemon pod
May 13 19:54:02.055: INFO: Number of nodes with available pods: 2
May 13 19:54:02.056: INFO: Node 10.170.219.177 is running more than one daemon pod
May 13 19:54:03.059: INFO: Number of nodes with available pods: 2
May 13 19:54:03.059: INFO: Node 10.170.219.177 is running more than one daemon pod
May 13 19:54:04.056: INFO: Number of nodes with available pods: 2
May 13 19:54:04.056: INFO: Node 10.170.219.177 is running more than one daemon pod
May 13 19:54:05.056: INFO: Number of nodes with available pods: 2
May 13 19:54:05.056: INFO: Node 10.170.219.177 is running more than one daemon pod
May 13 19:54:06.141: INFO: Number of nodes with available pods: 2
May 13 19:54:06.141: INFO: Node 10.170.219.177 is running more than one daemon pod
May 13 19:54:07.060: INFO: Number of nodes with available pods: 2
May 13 19:54:07.060: INFO: Node 10.170.219.177 is running more than one daemon pod
May 13 19:54:08.120: INFO: Number of nodes with available pods: 2
May 13 19:54:08.120: INFO: Node 10.170.219.177 is running more than one daemon pod
May 13 19:54:09.055: INFO: Number of nodes with available pods: 2
May 13 19:54:09.055: INFO: Node 10.170.219.177 is running more than one daemon pod
May 13 19:54:10.056: INFO: Number of nodes with available pods: 2
May 13 19:54:10.056: INFO: Node 10.170.219.177 is running more than one daemon pod
May 13 19:54:11.060: INFO: Number of nodes with available pods: 2
May 13 19:54:11.060: INFO: Node 10.170.219.177 is running more than one daemon pod
May 13 19:54:12.532: INFO: Number of nodes with available pods: 2
May 13 19:54:12.532: INFO: Node 10.170.219.177 is running more than one daemon pod
May 13 19:54:13.055: INFO: Number of nodes with available pods: 2
May 13 19:54:13.055: INFO: Node 10.170.219.177 is running more than one daemon pod
May 13 19:54:14.055: INFO: Number of nodes with available pods: 2
May 13 19:54:14.055: INFO: Node 10.170.219.177 is running more than one daemon pod
May 13 19:54:15.060: INFO: Number of nodes with available pods: 2
May 13 19:54:15.060: INFO: Node 10.170.219.177 is running more than one daemon pod
May 13 19:54:16.131: INFO: Number of nodes with available pods: 2
May 13 19:54:16.131: INFO: Node 10.170.219.177 is running more than one daemon pod
May 13 19:54:17.071: INFO: Number of nodes with available pods: 2
May 13 19:54:17.071: INFO: Node 10.170.219.177 is running more than one daemon pod
May 13 19:54:18.055: INFO: Number of nodes with available pods: 2
May 13 19:54:18.055: INFO: Node 10.170.219.177 is running more than one daemon pod
May 13 19:54:19.058: INFO: Number of nodes with available pods: 2
May 13 19:54:19.058: INFO: Node 10.170.219.177 is running more than one daemon pod
May 13 19:54:20.055: INFO: Number of nodes with available pods: 2
May 13 19:54:20.055: INFO: Node 10.170.219.177 is running more than one daemon pod
May 13 19:54:21.056: INFO: Number of nodes with available pods: 2
May 13 19:54:21.056: INFO: Node 10.170.219.177 is running more than one daemon pod
May 13 19:54:22.055: INFO: Number of nodes with available pods: 2
May 13 19:54:22.055: INFO: Node 10.170.219.177 is running more than one daemon pod
May 13 19:54:23.060: INFO: Number of nodes with available pods: 3
May 13 19:54:23.060: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-k56rn, will wait for the garbage collector to delete the pods
May 13 19:54:23.220: INFO: Deleting DaemonSet.extensions daemon-set took: 97.210624ms
May 13 19:54:23.220: INFO: Terminating DaemonSet.extensions daemon-set pods took: 76.045µs
May 13 19:55:06.343: INFO: Number of nodes with available pods: 0
May 13 19:55:06.343: INFO: Number of running nodes: 0, number of available pods: 0
May 13 19:55:06.350: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-k56rn/daemonsets","resourceVersion":"49842"},"items":null}

May 13 19:55:06.360: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-k56rn/pods","resourceVersion":"49842"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:55:06.384: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-k56rn" for this suite.
May 13 19:55:12.419: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:55:12.535: INFO: namespace: e2e-tests-daemonsets-k56rn, resource: bindings, ignored listing per whitelist
May 13 19:55:12.738: INFO: namespace e2e-tests-daemonsets-k56rn deletion completed in 6.347801582s

• [SLOW TEST:94.088 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:55:12.739: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replication-controller-hh2rm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-0551a4b0-75b9-11e9-8f67-2632f168be36
May 13 19:55:13.030: INFO: Pod name my-hostname-basic-0551a4b0-75b9-11e9-8f67-2632f168be36: Found 0 pods out of 1
May 13 19:55:18.051: INFO: Pod name my-hostname-basic-0551a4b0-75b9-11e9-8f67-2632f168be36: Found 1 pods out of 1
May 13 19:55:18.051: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-0551a4b0-75b9-11e9-8f67-2632f168be36" are running
May 13 19:55:18.059: INFO: Pod "my-hostname-basic-0551a4b0-75b9-11e9-8f67-2632f168be36-bbkpf" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-13 19:55:13 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-13 19:55:14 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-13 19:55:14 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-05-13 19:55:13 +0000 UTC Reason: Message:}])
May 13 19:55:18.059: INFO: Trying to dial the pod
May 13 19:55:23.141: INFO: Controller my-hostname-basic-0551a4b0-75b9-11e9-8f67-2632f168be36: Got expected result from replica 1 [my-hostname-basic-0551a4b0-75b9-11e9-8f67-2632f168be36-bbkpf]: "my-hostname-basic-0551a4b0-75b9-11e9-8f67-2632f168be36-bbkpf", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:55:23.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-hh2rm" for this suite.
May 13 19:55:29.188: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:55:29.460: INFO: namespace: e2e-tests-replication-controller-hh2rm, resource: bindings, ignored listing per whitelist
May 13 19:55:29.488: INFO: namespace e2e-tests-replication-controller-hh2rm deletion completed in 6.339455626s

• [SLOW TEST:16.749 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:55:29.490: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-t7ppg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 13 19:55:29.780: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0f4d79c4-75b9-11e9-8f67-2632f168be36" in namespace "e2e-tests-downward-api-t7ppg" to be "success or failure"
May 13 19:55:29.788: INFO: Pod "downwardapi-volume-0f4d79c4-75b9-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 7.332019ms
May 13 19:55:31.797: INFO: Pod "downwardapi-volume-0f4d79c4-75b9-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016028159s
STEP: Saw pod success
May 13 19:55:31.797: INFO: Pod "downwardapi-volume-0f4d79c4-75b9-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 19:55:31.805: INFO: Trying to get logs from node 10.170.219.153 pod downwardapi-volume-0f4d79c4-75b9-11e9-8f67-2632f168be36 container client-container: <nil>
STEP: delete the pod
May 13 19:55:31.846: INFO: Waiting for pod downwardapi-volume-0f4d79c4-75b9-11e9-8f67-2632f168be36 to disappear
May 13 19:55:31.853: INFO: Pod downwardapi-volume-0f4d79c4-75b9-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:55:31.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-t7ppg" for this suite.
May 13 19:55:37.890: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:55:37.949: INFO: namespace: e2e-tests-downward-api-t7ppg, resource: bindings, ignored listing per whitelist
May 13 19:55:38.132: INFO: namespace e2e-tests-downward-api-t7ppg deletion completed in 6.271911473s

• [SLOW TEST:8.642 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:55:38.133: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-m4mnx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:56:38.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-m4mnx" for this suite.
May 13 19:57:02.452: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:57:02.744: INFO: namespace: e2e-tests-container-probe-m4mnx, resource: bindings, ignored listing per whitelist
May 13 19:57:02.744: INFO: namespace e2e-tests-container-probe-m4mnx deletion completed in 24.319474875s

• [SLOW TEST:84.612 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:57:02.744: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-qcvkt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 13 19:57:03.039: INFO: Waiting up to 5m0s for pod "downwardapi-volume-46e3a0ee-75b9-11e9-8f67-2632f168be36" in namespace "e2e-tests-downward-api-qcvkt" to be "success or failure"
May 13 19:57:03.048: INFO: Pod "downwardapi-volume-46e3a0ee-75b9-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 8.802663ms
May 13 19:57:05.057: INFO: Pod "downwardapi-volume-46e3a0ee-75b9-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017823105s
STEP: Saw pod success
May 13 19:57:05.057: INFO: Pod "downwardapi-volume-46e3a0ee-75b9-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 19:57:05.066: INFO: Trying to get logs from node 10.170.219.153 pod downwardapi-volume-46e3a0ee-75b9-11e9-8f67-2632f168be36 container client-container: <nil>
STEP: delete the pod
May 13 19:57:05.119: INFO: Waiting for pod downwardapi-volume-46e3a0ee-75b9-11e9-8f67-2632f168be36 to disappear
May 13 19:57:05.127: INFO: Pod downwardapi-volume-46e3a0ee-75b9-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:57:05.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-qcvkt" for this suite.
May 13 19:57:11.167: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:57:11.200: INFO: namespace: e2e-tests-downward-api-qcvkt, resource: bindings, ignored listing per whitelist
May 13 19:57:11.424: INFO: namespace e2e-tests-downward-api-qcvkt deletion completed in 6.289128494s

• [SLOW TEST:8.680 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:57:11.424: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-wbs8c
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-4c0d14f3-75b9-11e9-8f67-2632f168be36
STEP: Creating a pod to test consume secrets
May 13 19:57:11.708: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-4c0e77a3-75b9-11e9-8f67-2632f168be36" in namespace "e2e-tests-projected-wbs8c" to be "success or failure"
May 13 19:57:11.716: INFO: Pod "pod-projected-secrets-4c0e77a3-75b9-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 7.932816ms
May 13 19:57:13.738: INFO: Pod "pod-projected-secrets-4c0e77a3-75b9-11e9-8f67-2632f168be36": Phase="Running", Reason="", readiness=true. Elapsed: 2.030160128s
May 13 19:57:15.747: INFO: Pod "pod-projected-secrets-4c0e77a3-75b9-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038424434s
STEP: Saw pod success
May 13 19:57:15.747: INFO: Pod "pod-projected-secrets-4c0e77a3-75b9-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 19:57:15.755: INFO: Trying to get logs from node 10.170.219.153 pod pod-projected-secrets-4c0e77a3-75b9-11e9-8f67-2632f168be36 container projected-secret-volume-test: <nil>
STEP: delete the pod
May 13 19:57:15.792: INFO: Waiting for pod pod-projected-secrets-4c0e77a3-75b9-11e9-8f67-2632f168be36 to disappear
May 13 19:57:15.799: INFO: Pod pod-projected-secrets-4c0e77a3-75b9-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:57:15.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wbs8c" for this suite.
May 13 19:57:21.837: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:57:22.040: INFO: namespace: e2e-tests-projected-wbs8c, resource: bindings, ignored listing per whitelist
May 13 19:57:22.091: INFO: namespace e2e-tests-projected-wbs8c deletion completed in 6.284271551s

• [SLOW TEST:10.667 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:57:22.092: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-vkbr6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-vkbr6/secret-test-5273bff6-75b9-11e9-8f67-2632f168be36
STEP: Creating a pod to test consume secrets
May 13 19:57:22.446: INFO: Waiting up to 5m0s for pod "pod-configmaps-52750d93-75b9-11e9-8f67-2632f168be36" in namespace "e2e-tests-secrets-vkbr6" to be "success or failure"
May 13 19:57:22.453: INFO: Pod "pod-configmaps-52750d93-75b9-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 7.332405ms
May 13 19:57:24.478: INFO: Pod "pod-configmaps-52750d93-75b9-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.031641361s
STEP: Saw pod success
May 13 19:57:24.478: INFO: Pod "pod-configmaps-52750d93-75b9-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 19:57:24.485: INFO: Trying to get logs from node 10.170.219.153 pod pod-configmaps-52750d93-75b9-11e9-8f67-2632f168be36 container env-test: <nil>
STEP: delete the pod
May 13 19:57:24.526: INFO: Waiting for pod pod-configmaps-52750d93-75b9-11e9-8f67-2632f168be36 to disappear
May 13 19:57:24.533: INFO: Pod pod-configmaps-52750d93-75b9-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:57:24.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-vkbr6" for this suite.
May 13 19:57:30.683: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:57:30.733: INFO: namespace: e2e-tests-secrets-vkbr6, resource: bindings, ignored listing per whitelist
May 13 19:57:30.919: INFO: namespace e2e-tests-secrets-vkbr6 deletion completed in 6.298993701s

• [SLOW TEST:8.827 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:57:30.919: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replication-controller-w2csw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
May 13 19:57:31.229: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:57:32.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-w2csw" for this suite.
May 13 19:57:38.352: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:57:38.684: INFO: namespace: e2e-tests-replication-controller-w2csw, resource: bindings, ignored listing per whitelist
May 13 19:57:38.766: INFO: namespace e2e-tests-replication-controller-w2csw deletion completed in 6.445500618s

• [SLOW TEST:7.847 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:57:38.766: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-g2ms6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-5c5be95c-75b9-11e9-8f67-2632f168be36
STEP: Creating a pod to test consume configMaps
May 13 19:57:39.071: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5c5dd29b-75b9-11e9-8f67-2632f168be36" in namespace "e2e-tests-projected-g2ms6" to be "success or failure"
May 13 19:57:39.080: INFO: Pod "pod-projected-configmaps-5c5dd29b-75b9-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 8.72581ms
May 13 19:57:41.088: INFO: Pod "pod-projected-configmaps-5c5dd29b-75b9-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017158439s
May 13 19:57:43.096: INFO: Pod "pod-projected-configmaps-5c5dd29b-75b9-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025501505s
STEP: Saw pod success
May 13 19:57:43.096: INFO: Pod "pod-projected-configmaps-5c5dd29b-75b9-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 19:57:43.104: INFO: Trying to get logs from node 10.170.219.177 pod pod-projected-configmaps-5c5dd29b-75b9-11e9-8f67-2632f168be36 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 13 19:57:43.220: INFO: Waiting for pod pod-projected-configmaps-5c5dd29b-75b9-11e9-8f67-2632f168be36 to disappear
May 13 19:57:43.228: INFO: Pod pod-projected-configmaps-5c5dd29b-75b9-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:57:43.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-g2ms6" for this suite.
May 13 19:57:49.265: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:57:49.408: INFO: namespace: e2e-tests-projected-g2ms6, resource: bindings, ignored listing per whitelist
May 13 19:57:49.566: INFO: namespace e2e-tests-projected-g2ms6 deletion completed in 6.330140424s

• [SLOW TEST:10.800 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:57:49.567: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-ckp8r
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1262
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
May 13 19:57:49.847: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-ckp8r'
May 13 19:57:49.967: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May 13 19:57:49.967: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1268
May 13 19:57:51.983: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-ckp8r'
May 13 19:57:52.101: INFO: stderr: ""
May 13 19:57:52.101: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:57:52.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ckp8r" for this suite.
May 13 19:58:16.157: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:58:16.343: INFO: namespace: e2e-tests-kubectl-ckp8r, resource: bindings, ignored listing per whitelist
May 13 19:58:16.439: INFO: namespace e2e-tests-kubectl-ckp8r deletion completed in 24.3189894s

• [SLOW TEST:26.872 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:58:16.439: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-ngxn8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 13 19:58:16.732: INFO: Waiting up to 5m0s for pod "downwardapi-volume-72d018be-75b9-11e9-8f67-2632f168be36" in namespace "e2e-tests-projected-ngxn8" to be "success or failure"
May 13 19:58:16.740: INFO: Pod "downwardapi-volume-72d018be-75b9-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 7.84252ms
May 13 19:58:18.748: INFO: Pod "downwardapi-volume-72d018be-75b9-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015936379s
STEP: Saw pod success
May 13 19:58:18.748: INFO: Pod "downwardapi-volume-72d018be-75b9-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 19:58:18.756: INFO: Trying to get logs from node 10.170.219.153 pod downwardapi-volume-72d018be-75b9-11e9-8f67-2632f168be36 container client-container: <nil>
STEP: delete the pod
May 13 19:58:18.853: INFO: Waiting for pod downwardapi-volume-72d018be-75b9-11e9-8f67-2632f168be36 to disappear
May 13 19:58:18.865: INFO: Pod downwardapi-volume-72d018be-75b9-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:58:18.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ngxn8" for this suite.
May 13 19:58:24.902: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:58:25.189: INFO: namespace: e2e-tests-projected-ngxn8, resource: bindings, ignored listing per whitelist
May 13 19:58:25.224: INFO: namespace e2e-tests-projected-ngxn8 deletion completed in 6.350731671s

• [SLOW TEST:8.785 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:58:25.224: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-w2dx7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
May 13 19:58:28.067: INFO: Successfully updated pod "labelsupdate780b3f06-75b9-11e9-8f67-2632f168be36"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:58:30.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-w2dx7" for this suite.
May 13 19:58:54.136: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:58:54.373: INFO: namespace: e2e-tests-downward-api-w2dx7, resource: bindings, ignored listing per whitelist
May 13 19:58:54.491: INFO: namespace e2e-tests-downward-api-w2dx7 deletion completed in 24.384658496s

• [SLOW TEST:29.267 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:58:54.491: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-rvmjf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 13 19:58:54.785: INFO: Waiting up to 5m0s for pod "downwardapi-volume-897e85e0-75b9-11e9-8f67-2632f168be36" in namespace "e2e-tests-downward-api-rvmjf" to be "success or failure"
May 13 19:58:54.794: INFO: Pod "downwardapi-volume-897e85e0-75b9-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 8.646249ms
May 13 19:58:56.803: INFO: Pod "downwardapi-volume-897e85e0-75b9-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017610568s
STEP: Saw pod success
May 13 19:58:56.803: INFO: Pod "downwardapi-volume-897e85e0-75b9-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 19:58:56.810: INFO: Trying to get logs from node 10.170.219.153 pod downwardapi-volume-897e85e0-75b9-11e9-8f67-2632f168be36 container client-container: <nil>
STEP: delete the pod
May 13 19:58:56.848: INFO: Waiting for pod downwardapi-volume-897e85e0-75b9-11e9-8f67-2632f168be36 to disappear
May 13 19:58:56.857: INFO: Pod downwardapi-volume-897e85e0-75b9-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:58:56.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-rvmjf" for this suite.
May 13 19:59:02.947: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:59:03.029: INFO: namespace: e2e-tests-downward-api-rvmjf, resource: bindings, ignored listing per whitelist
May 13 19:59:03.182: INFO: namespace e2e-tests-downward-api-rvmjf deletion completed in 6.262192467s

• [SLOW TEST:8.691 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:59:03.183: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-h6vbc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 13 19:59:03.563: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:59:05.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-h6vbc" for this suite.
May 13 19:59:45.798: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:59:45.880: INFO: namespace: e2e-tests-pods-h6vbc, resource: bindings, ignored listing per whitelist
May 13 19:59:46.049: INFO: namespace e2e-tests-pods-h6vbc deletion completed in 40.279156052s

• [SLOW TEST:42.866 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:59:46.050: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-d24rb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
May 13 19:59:46.329: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-555138423 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:59:46.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-d24rb" for this suite.
May 13 19:59:52.527: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 19:59:52.713: INFO: namespace: e2e-tests-kubectl-d24rb, resource: bindings, ignored listing per whitelist
May 13 19:59:52.759: INFO: namespace e2e-tests-kubectl-d24rb deletion completed in 6.342470518s

• [SLOW TEST:6.709 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 19:59:52.759: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-cntzj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
May 13 19:59:53.039: INFO: Waiting up to 5m0s for pod "downward-api-ac37c00d-75b9-11e9-8f67-2632f168be36" in namespace "e2e-tests-downward-api-cntzj" to be "success or failure"
May 13 19:59:53.047: INFO: Pod "downward-api-ac37c00d-75b9-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 8.092401ms
May 13 19:59:55.055: INFO: Pod "downward-api-ac37c00d-75b9-11e9-8f67-2632f168be36": Phase="Running", Reason="", readiness=true. Elapsed: 2.01601739s
May 13 19:59:57.064: INFO: Pod "downward-api-ac37c00d-75b9-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024859971s
STEP: Saw pod success
May 13 19:59:57.064: INFO: Pod "downward-api-ac37c00d-75b9-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 19:59:57.072: INFO: Trying to get logs from node 10.170.219.153 pod downward-api-ac37c00d-75b9-11e9-8f67-2632f168be36 container dapi-container: <nil>
STEP: delete the pod
May 13 19:59:57.110: INFO: Waiting for pod downward-api-ac37c00d-75b9-11e9-8f67-2632f168be36 to disappear
May 13 19:59:57.117: INFO: Pod downward-api-ac37c00d-75b9-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 19:59:57.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-cntzj" for this suite.
May 13 20:00:03.227: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 20:00:03.452: INFO: namespace: e2e-tests-downward-api-cntzj, resource: bindings, ignored listing per whitelist
May 13 20:00:03.466: INFO: namespace e2e-tests-downward-api-cntzj deletion completed in 6.341130274s

• [SLOW TEST:10.707 seconds]
[sig-node] Downward API
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 20:00:03.466: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-6q52l
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-b29b2530-75b9-11e9-8f67-2632f168be36
STEP: Creating a pod to test consume configMaps
May 13 20:00:03.765: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b29c5ad2-75b9-11e9-8f67-2632f168be36" in namespace "e2e-tests-projected-6q52l" to be "success or failure"
May 13 20:00:03.773: INFO: Pod "pod-projected-configmaps-b29c5ad2-75b9-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 8.373414ms
May 13 20:00:05.781: INFO: Pod "pod-projected-configmaps-b29c5ad2-75b9-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016295649s
STEP: Saw pod success
May 13 20:00:05.781: INFO: Pod "pod-projected-configmaps-b29c5ad2-75b9-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 20:00:05.789: INFO: Trying to get logs from node 10.170.219.177 pod pod-projected-configmaps-b29c5ad2-75b9-11e9-8f67-2632f168be36 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 13 20:00:05.828: INFO: Waiting for pod pod-projected-configmaps-b29c5ad2-75b9-11e9-8f67-2632f168be36 to disappear
May 13 20:00:05.835: INFO: Pod pod-projected-configmaps-b29c5ad2-75b9-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 20:00:05.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6q52l" for this suite.
May 13 20:00:12.248: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 20:00:12.471: INFO: namespace: e2e-tests-projected-6q52l, resource: bindings, ignored listing per whitelist
May 13 20:00:12.590: INFO: namespace e2e-tests-projected-6q52l deletion completed in 6.747296669s

• [SLOW TEST:9.124 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 20:00:12.591: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-4mhl5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-4mhl5
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-4mhl5
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-4mhl5
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-4mhl5
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-4mhl5
May 13 20:00:16.929: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-4mhl5, name: ss-0, uid: ba3b3aaa-75b9-11e9-83a8-7e0242378207, status phase: Pending. Waiting for statefulset controller to delete.
May 13 20:00:17.116: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-4mhl5, name: ss-0, uid: ba3b3aaa-75b9-11e9-83a8-7e0242378207, status phase: Failed. Waiting for statefulset controller to delete.
May 13 20:00:17.126: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-4mhl5, name: ss-0, uid: ba3b3aaa-75b9-11e9-83a8-7e0242378207, status phase: Failed. Waiting for statefulset controller to delete.
May 13 20:00:17.132: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-4mhl5
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-4mhl5
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-4mhl5 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
May 13 20:00:21.180: INFO: Deleting all statefulset in ns e2e-tests-statefulset-4mhl5
May 13 20:00:21.186: INFO: Scaling statefulset ss to 0
May 13 20:00:41.214: INFO: Waiting for statefulset status.replicas updated to 0
May 13 20:00:41.219: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 20:00:41.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-4mhl5" for this suite.
May 13 20:00:47.348: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 20:00:47.638: INFO: namespace: e2e-tests-statefulset-4mhl5, resource: bindings, ignored listing per whitelist
May 13 20:00:47.661: INFO: namespace e2e-tests-statefulset-4mhl5 deletion completed in 6.393557254s

• [SLOW TEST:35.070 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 20:00:47.661: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-742sl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 13 20:00:47.955: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ccf30a9a-75b9-11e9-8f67-2632f168be36" in namespace "e2e-tests-downward-api-742sl" to be "success or failure"
May 13 20:00:47.962: INFO: Pod "downwardapi-volume-ccf30a9a-75b9-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 7.399791ms
May 13 20:00:49.971: INFO: Pod "downwardapi-volume-ccf30a9a-75b9-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015669105s
STEP: Saw pod success
May 13 20:00:49.971: INFO: Pod "downwardapi-volume-ccf30a9a-75b9-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 20:00:49.979: INFO: Trying to get logs from node 10.170.219.153 pod downwardapi-volume-ccf30a9a-75b9-11e9-8f67-2632f168be36 container client-container: <nil>
STEP: delete the pod
May 13 20:00:50.018: INFO: Waiting for pod downwardapi-volume-ccf30a9a-75b9-11e9-8f67-2632f168be36 to disappear
May 13 20:00:50.025: INFO: Pod downwardapi-volume-ccf30a9a-75b9-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 20:00:50.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-742sl" for this suite.
May 13 20:00:56.062: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 20:00:56.268: INFO: namespace: e2e-tests-downward-api-742sl, resource: bindings, ignored listing per whitelist
May 13 20:00:56.351: INFO: namespace e2e-tests-downward-api-742sl deletion completed in 6.318203541s

• [SLOW TEST:8.690 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 20:00:56.352: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-mvcq4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
May 13 20:00:56.692: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-mvcq4,SelfLink:/api/v1/namespaces/e2e-tests-watch-mvcq4/configmaps/e2e-watch-test-watch-closed,UID:d2278eac-75b9-11e9-b786-da20024d205c,ResourceVersion:51297,Generation:0,CreationTimestamp:2019-05-13 20:00:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 13 20:00:56.692: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-mvcq4,SelfLink:/api/v1/namespaces/e2e-tests-watch-mvcq4/configmaps/e2e-watch-test-watch-closed,UID:d2278eac-75b9-11e9-b786-da20024d205c,ResourceVersion:51298,Generation:0,CreationTimestamp:2019-05-13 20:00:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
May 13 20:00:56.729: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-mvcq4,SelfLink:/api/v1/namespaces/e2e-tests-watch-mvcq4/configmaps/e2e-watch-test-watch-closed,UID:d2278eac-75b9-11e9-b786-da20024d205c,ResourceVersion:51299,Generation:0,CreationTimestamp:2019-05-13 20:00:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 13 20:00:56.729: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-mvcq4,SelfLink:/api/v1/namespaces/e2e-tests-watch-mvcq4/configmaps/e2e-watch-test-watch-closed,UID:d2278eac-75b9-11e9-b786-da20024d205c,ResourceVersion:51300,Generation:0,CreationTimestamp:2019-05-13 20:00:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 20:00:56.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-mvcq4" for this suite.
May 13 20:01:02.776: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 20:01:02.879: INFO: namespace: e2e-tests-watch-mvcq4, resource: bindings, ignored listing per whitelist
May 13 20:01:03.070: INFO: namespace e2e-tests-watch-mvcq4 deletion completed in 6.334509854s

• [SLOW TEST:6.718 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 20:01:03.070: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-z7ns7
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-d623afcd-75b9-11e9-8f67-2632f168be36
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 20:01:07.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-z7ns7" for this suite.
May 13 20:01:31.469: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 20:01:31.630: INFO: namespace: e2e-tests-configmap-z7ns7, resource: bindings, ignored listing per whitelist
May 13 20:01:31.802: INFO: namespace e2e-tests-configmap-z7ns7 deletion completed in 24.362249204s

• [SLOW TEST:28.732 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 20:01:31.804: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-l8677
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1134
STEP: creating an rc
May 13 20:01:32.123: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 create -f - --namespace=e2e-tests-kubectl-l8677'
May 13 20:01:32.534: INFO: stderr: ""
May 13 20:01:32.534: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
May 13 20:01:33.543: INFO: Selector matched 1 pods for map[app:redis]
May 13 20:01:33.543: INFO: Found 0 / 1
May 13 20:01:34.620: INFO: Selector matched 1 pods for map[app:redis]
May 13 20:01:34.620: INFO: Found 1 / 1
May 13 20:01:34.620: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May 13 20:01:34.633: INFO: Selector matched 1 pods for map[app:redis]
May 13 20:01:34.633: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
May 13 20:01:34.633: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 logs redis-master-974kk redis-master --namespace=e2e-tests-kubectl-l8677'
May 13 20:01:34.750: INFO: stderr: ""
May 13 20:01:34.750: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 13 May 20:01:33.722 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 13 May 20:01:33.722 # Server started, Redis version 3.2.12\n1:M 13 May 20:01:33.722 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 13 May 20:01:33.722 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
May 13 20:01:34.750: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 log redis-master-974kk redis-master --namespace=e2e-tests-kubectl-l8677 --tail=1'
May 13 20:01:34.884: INFO: stderr: ""
May 13 20:01:34.884: INFO: stdout: "1:M 13 May 20:01:33.722 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
May 13 20:01:34.884: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 log redis-master-974kk redis-master --namespace=e2e-tests-kubectl-l8677 --limit-bytes=1'
May 13 20:01:34.999: INFO: stderr: ""
May 13 20:01:35.000: INFO: stdout: " "
STEP: exposing timestamps
May 13 20:01:35.000: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 log redis-master-974kk redis-master --namespace=e2e-tests-kubectl-l8677 --tail=1 --timestamps'
May 13 20:01:35.123: INFO: stderr: ""
May 13 20:01:35.123: INFO: stdout: "2019-05-13T20:01:33.722286286Z 1:M 13 May 20:01:33.722 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
May 13 20:01:37.623: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 log redis-master-974kk redis-master --namespace=e2e-tests-kubectl-l8677 --since=1s'
May 13 20:01:37.840: INFO: stderr: ""
May 13 20:01:37.840: INFO: stdout: ""
May 13 20:01:37.841: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 log redis-master-974kk redis-master --namespace=e2e-tests-kubectl-l8677 --since=24h'
May 13 20:01:37.961: INFO: stderr: ""
May 13 20:01:37.961: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 13 May 20:01:33.722 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 13 May 20:01:33.722 # Server started, Redis version 3.2.12\n1:M 13 May 20:01:33.722 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 13 May 20:01:33.722 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1140
STEP: using delete to clean up resources
May 13 20:01:37.961: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-l8677'
May 13 20:01:38.083: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 13 20:01:38.083: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
May 13 20:01:38.083: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-l8677'
May 13 20:01:38.189: INFO: stderr: "No resources found.\n"
May 13 20:01:38.189: INFO: stdout: ""
May 13 20:01:38.189: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 get pods -l name=nginx --namespace=e2e-tests-kubectl-l8677 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 13 20:01:38.287: INFO: stderr: ""
May 13 20:01:38.287: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 20:01:38.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-l8677" for this suite.
May 13 20:01:44.324: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 20:01:44.532: INFO: namespace: e2e-tests-kubectl-l8677, resource: bindings, ignored listing per whitelist
May 13 20:01:44.734: INFO: namespace e2e-tests-kubectl-l8677 deletion completed in 6.4388628s

• [SLOW TEST:12.930 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 20:01:44.734: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-r6z8h
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 13 20:01:45.035: INFO: Waiting up to 5m0s for pod "downwardapi-volume-eef892b0-75b9-11e9-8f67-2632f168be36" in namespace "e2e-tests-downward-api-r6z8h" to be "success or failure"
May 13 20:01:45.043: INFO: Pod "downwardapi-volume-eef892b0-75b9-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 7.951622ms
May 13 20:01:47.053: INFO: Pod "downwardapi-volume-eef892b0-75b9-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018206066s
STEP: Saw pod success
May 13 20:01:47.053: INFO: Pod "downwardapi-volume-eef892b0-75b9-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 20:01:47.061: INFO: Trying to get logs from node 10.170.219.177 pod downwardapi-volume-eef892b0-75b9-11e9-8f67-2632f168be36 container client-container: <nil>
STEP: delete the pod
May 13 20:01:47.101: INFO: Waiting for pod downwardapi-volume-eef892b0-75b9-11e9-8f67-2632f168be36 to disappear
May 13 20:01:47.109: INFO: Pod downwardapi-volume-eef892b0-75b9-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 20:01:47.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-r6z8h" for this suite.
May 13 20:01:53.151: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 20:01:53.414: INFO: namespace: e2e-tests-downward-api-r6z8h, resource: bindings, ignored listing per whitelist
May 13 20:01:53.437: INFO: namespace e2e-tests-downward-api-r6z8h deletion completed in 6.320109789s

• [SLOW TEST:8.703 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 20:01:53.438: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-fjv5b
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-f42639a6-75b9-11e9-8f67-2632f168be36
STEP: Creating a pod to test consume secrets
May 13 20:01:53.731: INFO: Waiting up to 5m0s for pod "pod-secrets-f427ad56-75b9-11e9-8f67-2632f168be36" in namespace "e2e-tests-secrets-fjv5b" to be "success or failure"
May 13 20:01:53.742: INFO: Pod "pod-secrets-f427ad56-75b9-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 10.591861ms
May 13 20:01:55.749: INFO: Pod "pod-secrets-f427ad56-75b9-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01845387s
STEP: Saw pod success
May 13 20:01:55.749: INFO: Pod "pod-secrets-f427ad56-75b9-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 20:01:55.757: INFO: Trying to get logs from node 10.170.219.153 pod pod-secrets-f427ad56-75b9-11e9-8f67-2632f168be36 container secret-volume-test: <nil>
STEP: delete the pod
May 13 20:01:55.798: INFO: Waiting for pod pod-secrets-f427ad56-75b9-11e9-8f67-2632f168be36 to disappear
May 13 20:01:55.805: INFO: Pod pod-secrets-f427ad56-75b9-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 20:01:55.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-fjv5b" for this suite.
May 13 20:02:01.843: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 20:02:02.091: INFO: namespace: e2e-tests-secrets-fjv5b, resource: bindings, ignored listing per whitelist
May 13 20:02:02.138: INFO: namespace e2e-tests-secrets-fjv5b deletion completed in 6.324254546s

• [SLOW TEST:8.700 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 20:02:02.139: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-vsgzr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 13 20:02:02.425: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
May 13 20:02:02.441: INFO: Pod name sample-pod: Found 0 pods out of 1
May 13 20:02:07.450: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
May 13 20:02:07.450: INFO: Creating deployment "test-rolling-update-deployment"
May 13 20:02:07.533: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
May 13 20:02:07.547: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
May 13 20:02:09.561: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
May 13 20:02:09.566: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May 13 20:02:09.584: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-vsgzr,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-vsgzr/deployments/test-rolling-update-deployment,UID:fc62864c-75b9-11e9-b786-da20024d205c,ResourceVersion:51644,Generation:1,CreationTimestamp:2019-05-13 20:02:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-05-13 20:02:07 +0000 UTC 2019-05-13 20:02:07 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-05-13 20:02:08 +0000 UTC 2019-05-13 20:02:07 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-68b55d7bc6" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

May 13 20:02:09.591: INFO: New ReplicaSet "test-rolling-update-deployment-68b55d7bc6" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6,GenerateName:,Namespace:e2e-tests-deployment-vsgzr,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-vsgzr/replicasets/test-rolling-update-deployment-68b55d7bc6,UID:fc67b49b-75b9-11e9-83a8-7e0242378207,ResourceVersion:51635,Generation:1,CreationTimestamp:2019-05-13 20:02:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment fc62864c-75b9-11e9-b786-da20024d205c 0xc000d28117 0xc000d28118}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
May 13 20:02:09.591: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
May 13 20:02:09.591: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-vsgzr,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-vsgzr/replicasets/test-rolling-update-controller,UID:f959494b-75b9-11e9-b786-da20024d205c,ResourceVersion:51643,Generation:2,CreationTimestamp:2019-05-13 20:02:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment fc62864c-75b9-11e9-b786-da20024d205c 0xc001df3f67 0xc001df3f68}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
May 13 20:02:09.599: INFO: Pod "test-rolling-update-deployment-68b55d7bc6-xxznx" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-68b55d7bc6-xxznx,GenerateName:test-rolling-update-deployment-68b55d7bc6-,Namespace:e2e-tests-deployment-vsgzr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-vsgzr/pods/test-rolling-update-deployment-68b55d7bc6-xxznx,UID:fc693028-75b9-11e9-83a8-7e0242378207,ResourceVersion:51634,Generation:0,CreationTimestamp:2019-05-13 20:02:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 68b55d7bc6,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-68b55d7bc6 fc67b49b-75b9-11e9-83a8-7e0242378207 0xc001c52987 0xc001c52988}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-c7v8v {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-c7v8v,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-c7v8v true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.170.219.153,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c52a90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c52ab0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 20:02:07 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 20:02:08 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 20:02:08 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-05-13 20:02:07 +0000 UTC  }],Message:,Reason:,HostIP:10.170.219.153,PodIP:172.30.63.46,StartTime:2019-05-13 20:02:07 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-05-13 20:02:08 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://cd38f4553f3bef5fc9fdd0114c85b6295708fd2b92d939e79ca76e8248a90c16}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 20:02:09.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-vsgzr" for this suite.
May 13 20:02:15.638: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 20:02:15.857: INFO: namespace: e2e-tests-deployment-vsgzr, resource: bindings, ignored listing per whitelist
May 13 20:02:16.080: INFO: namespace e2e-tests-deployment-vsgzr deletion completed in 6.472995899s

• [SLOW TEST:13.941 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 20:02:16.082: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-2fqf8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-01a851a0-75ba-11e9-8f67-2632f168be36
STEP: Creating secret with name secret-projected-all-test-volume-01a85185-75ba-11e9-8f67-2632f168be36
STEP: Creating a pod to test Check all projections for projected volume plugin
May 13 20:02:16.401: INFO: Waiting up to 5m0s for pod "projected-volume-01a85147-75ba-11e9-8f67-2632f168be36" in namespace "e2e-tests-projected-2fqf8" to be "success or failure"
May 13 20:02:16.409: INFO: Pod "projected-volume-01a85147-75ba-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 7.585263ms
May 13 20:02:18.417: INFO: Pod "projected-volume-01a85147-75ba-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015795469s
STEP: Saw pod success
May 13 20:02:18.417: INFO: Pod "projected-volume-01a85147-75ba-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 20:02:18.426: INFO: Trying to get logs from node 10.170.219.177 pod projected-volume-01a85147-75ba-11e9-8f67-2632f168be36 container projected-all-volume-test: <nil>
STEP: delete the pod
May 13 20:02:18.472: INFO: Waiting for pod projected-volume-01a85147-75ba-11e9-8f67-2632f168be36 to disappear
May 13 20:02:18.479: INFO: Pod projected-volume-01a85147-75ba-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 20:02:18.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2fqf8" for this suite.
May 13 20:02:24.521: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 20:02:24.534: INFO: namespace: e2e-tests-projected-2fqf8, resource: bindings, ignored listing per whitelist
May 13 20:02:24.759: INFO: namespace e2e-tests-projected-2fqf8 deletion completed in 6.271633448s

• [SLOW TEST:8.677 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 20:02:24.759: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-2jchj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
May 13 20:02:25.034: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 20:02:29.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-2jchj" for this suite.
May 13 20:02:35.995: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 20:02:36.139: INFO: namespace: e2e-tests-init-container-2jchj, resource: bindings, ignored listing per whitelist
May 13 20:02:36.523: INFO: namespace e2e-tests-init-container-2jchj deletion completed in 6.558950599s

• [SLOW TEST:11.764 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 20:02:36.523: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-g7ls7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0513 20:02:43.028261      16 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 13 20:02:43.028: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 20:02:43.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-g7ls7" for this suite.
May 13 20:02:51.076: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 20:02:51.369: INFO: namespace: e2e-tests-gc-g7ls7, resource: bindings, ignored listing per whitelist
May 13 20:02:51.532: INFO: namespace e2e-tests-gc-g7ls7 deletion completed in 8.498316354s

• [SLOW TEST:15.009 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 20:02:51.533: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-r2n9h
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
May 13 20:02:55.911: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 13 20:02:55.918: INFO: Pod pod-with-prestop-http-hook still exists
May 13 20:02:57.918: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 13 20:02:57.927: INFO: Pod pod-with-prestop-http-hook still exists
May 13 20:02:59.918: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 13 20:02:59.927: INFO: Pod pod-with-prestop-http-hook still exists
May 13 20:03:01.918: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 13 20:03:01.927: INFO: Pod pod-with-prestop-http-hook still exists
May 13 20:03:03.918: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 13 20:03:03.928: INFO: Pod pod-with-prestop-http-hook still exists
May 13 20:03:05.918: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 13 20:03:05.939: INFO: Pod pod-with-prestop-http-hook still exists
May 13 20:03:07.918: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 13 20:03:07.928: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 20:03:07.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-r2n9h" for this suite.
May 13 20:03:32.052: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 20:03:32.270: INFO: namespace: e2e-tests-container-lifecycle-hook-r2n9h, resource: bindings, ignored listing per whitelist
May 13 20:03:32.335: INFO: namespace e2e-tests-container-lifecycle-hook-r2n9h deletion completed in 24.380732071s

• [SLOW TEST:40.802 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 20:03:32.336: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-cm8h2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
May 13 20:03:32.666: INFO: Number of nodes with available pods: 0
May 13 20:03:32.666: INFO: Node 10.170.219.151 is running more than one daemon pod
May 13 20:03:33.684: INFO: Number of nodes with available pods: 0
May 13 20:03:33.684: INFO: Node 10.170.219.151 is running more than one daemon pod
May 13 20:03:34.682: INFO: Number of nodes with available pods: 3
May 13 20:03:34.682: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
May 13 20:03:34.719: INFO: Number of nodes with available pods: 2
May 13 20:03:34.719: INFO: Node 10.170.219.153 is running more than one daemon pod
May 13 20:03:35.735: INFO: Number of nodes with available pods: 2
May 13 20:03:35.735: INFO: Node 10.170.219.153 is running more than one daemon pod
May 13 20:03:36.736: INFO: Number of nodes with available pods: 3
May 13 20:03:36.736: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-cm8h2, will wait for the garbage collector to delete the pods
May 13 20:03:36.819: INFO: Deleting DaemonSet.extensions daemon-set took: 11.937268ms
May 13 20:03:36.919: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.293141ms
May 13 20:04:12.541: INFO: Number of nodes with available pods: 0
May 13 20:04:12.541: INFO: Number of running nodes: 0, number of available pods: 0
May 13 20:04:12.548: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-cm8h2/daemonsets","resourceVersion":"52447"},"items":null}

May 13 20:04:12.555: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-cm8h2/pods","resourceVersion":"52447"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 20:04:12.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-cm8h2" for this suite.
May 13 20:04:18.617: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 20:04:19.092: INFO: namespace: e2e-tests-daemonsets-cm8h2, resource: bindings, ignored listing per whitelist
May 13 20:04:19.141: INFO: namespace e2e-tests-daemonsets-cm8h2 deletion completed in 6.557642783s

• [SLOW TEST:46.805 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 20:04:19.141: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-custom-resource-definition-qz292
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 13 20:04:19.528: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 20:04:20.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-qz292" for this suite.
May 13 20:04:26.858: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 20:04:26.963: INFO: namespace: e2e-tests-custom-resource-definition-qz292, resource: bindings, ignored listing per whitelist
May 13 20:04:27.333: INFO: namespace e2e-tests-custom-resource-definition-qz292 deletion completed in 6.708989062s

• [SLOW TEST:8.192 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 20:04:27.336: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-4zktd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-4fe7ee08-75ba-11e9-8f67-2632f168be36
STEP: Creating a pod to test consume secrets
May 13 20:04:27.736: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-4ff2f61b-75ba-11e9-8f67-2632f168be36" in namespace "e2e-tests-projected-4zktd" to be "success or failure"
May 13 20:04:27.744: INFO: Pod "pod-projected-secrets-4ff2f61b-75ba-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 7.112537ms
May 13 20:04:29.752: INFO: Pod "pod-projected-secrets-4ff2f61b-75ba-11e9-8f67-2632f168be36": Phase="Running", Reason="", readiness=true. Elapsed: 2.01530147s
May 13 20:04:31.763: INFO: Pod "pod-projected-secrets-4ff2f61b-75ba-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026605478s
STEP: Saw pod success
May 13 20:04:31.763: INFO: Pod "pod-projected-secrets-4ff2f61b-75ba-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 20:04:31.771: INFO: Trying to get logs from node 10.170.219.177 pod pod-projected-secrets-4ff2f61b-75ba-11e9-8f67-2632f168be36 container projected-secret-volume-test: <nil>
STEP: delete the pod
May 13 20:04:31.816: INFO: Waiting for pod pod-projected-secrets-4ff2f61b-75ba-11e9-8f67-2632f168be36 to disappear
May 13 20:04:31.826: INFO: Pod pod-projected-secrets-4ff2f61b-75ba-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 20:04:31.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4zktd" for this suite.
May 13 20:04:37.863: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 20:04:38.002: INFO: namespace: e2e-tests-projected-4zktd, resource: bindings, ignored listing per whitelist
May 13 20:04:38.181: INFO: namespace e2e-tests-projected-4zktd deletion completed in 6.347752119s

• [SLOW TEST:10.846 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 20:04:38.182: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-8h94c
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
May 13 20:04:38.484: INFO: Waiting up to 5m0s for pod "client-containers-565adc94-75ba-11e9-8f67-2632f168be36" in namespace "e2e-tests-containers-8h94c" to be "success or failure"
May 13 20:04:38.492: INFO: Pod "client-containers-565adc94-75ba-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 7.968175ms
May 13 20:04:40.520: INFO: Pod "client-containers-565adc94-75ba-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.035577737s
STEP: Saw pod success
May 13 20:04:40.520: INFO: Pod "client-containers-565adc94-75ba-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 20:04:40.527: INFO: Trying to get logs from node 10.170.219.153 pod client-containers-565adc94-75ba-11e9-8f67-2632f168be36 container test-container: <nil>
STEP: delete the pod
May 13 20:04:40.581: INFO: Waiting for pod client-containers-565adc94-75ba-11e9-8f67-2632f168be36 to disappear
May 13 20:04:40.590: INFO: Pod client-containers-565adc94-75ba-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 20:04:40.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-8h94c" for this suite.
May 13 20:04:46.628: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 20:04:46.686: INFO: namespace: e2e-tests-containers-8h94c, resource: bindings, ignored listing per whitelist
May 13 20:04:46.855: INFO: namespace e2e-tests-containers-8h94c deletion completed in 6.256348638s

• [SLOW TEST:8.674 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 20:04:46.855: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-tzfhp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-5b831681-75ba-11e9-8f67-2632f168be36
STEP: Creating a pod to test consume secrets
May 13 20:04:47.143: INFO: Waiting up to 5m0s for pod "pod-secrets-5b848186-75ba-11e9-8f67-2632f168be36" in namespace "e2e-tests-secrets-tzfhp" to be "success or failure"
May 13 20:04:47.151: INFO: Pod "pod-secrets-5b848186-75ba-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 7.809287ms
May 13 20:04:49.159: INFO: Pod "pod-secrets-5b848186-75ba-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015407416s
STEP: Saw pod success
May 13 20:04:49.159: INFO: Pod "pod-secrets-5b848186-75ba-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 20:04:49.166: INFO: Trying to get logs from node 10.170.219.177 pod pod-secrets-5b848186-75ba-11e9-8f67-2632f168be36 container secret-volume-test: <nil>
STEP: delete the pod
May 13 20:04:49.204: INFO: Waiting for pod pod-secrets-5b848186-75ba-11e9-8f67-2632f168be36 to disappear
May 13 20:04:49.211: INFO: Pod pod-secrets-5b848186-75ba-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 20:04:49.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-tzfhp" for this suite.
May 13 20:04:55.260: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 20:04:55.407: INFO: namespace: e2e-tests-secrets-tzfhp, resource: bindings, ignored listing per whitelist
May 13 20:04:55.541: INFO: namespace e2e-tests-secrets-tzfhp deletion completed in 6.322287677s

• [SLOW TEST:8.686 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 20:04:55.543: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-qm97t
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 20:04:57.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-qm97t" for this suite.
May 13 20:05:51.975: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 20:05:52.027: INFO: namespace: e2e-tests-kubelet-test-qm97t, resource: bindings, ignored listing per whitelist
May 13 20:05:52.243: INFO: namespace e2e-tests-kubelet-test-qm97t deletion completed in 54.29948035s

• [SLOW TEST:56.700 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a read only busybox container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:186
    should not write to root filesystem [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 20:05:52.244: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-zv4cp
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-828db74e-75ba-11e9-8f67-2632f168be36
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-828db74e-75ba-11e9-8f67-2632f168be36
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 20:05:56.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zv4cp" for this suite.
May 13 20:06:18.849: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 20:06:18.927: INFO: namespace: e2e-tests-projected-zv4cp, resource: bindings, ignored listing per whitelist
May 13 20:06:19.101: INFO: namespace e2e-tests-projected-zv4cp deletion completed in 22.28158403s

• [SLOW TEST:26.858 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 20:06:19.103: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-5c9hh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 13 20:06:19.446: INFO: (0) /api/v1/nodes/10.170.219.151:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 17.264338ms)
May 13 20:06:19.455: INFO: (1) /api/v1/nodes/10.170.219.151:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 9.298611ms)
May 13 20:06:19.465: INFO: (2) /api/v1/nodes/10.170.219.151:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 9.136183ms)
May 13 20:06:19.473: INFO: (3) /api/v1/nodes/10.170.219.151:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 8.744928ms)
May 13 20:06:19.482: INFO: (4) /api/v1/nodes/10.170.219.151:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 8.70234ms)
May 13 20:06:19.491: INFO: (5) /api/v1/nodes/10.170.219.151:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 9.101358ms)
May 13 20:06:19.502: INFO: (6) /api/v1/nodes/10.170.219.151:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 10.537645ms)
May 13 20:06:19.510: INFO: (7) /api/v1/nodes/10.170.219.151:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 8.627342ms)
May 13 20:06:19.519: INFO: (8) /api/v1/nodes/10.170.219.151:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 9.023938ms)
May 13 20:06:19.528: INFO: (9) /api/v1/nodes/10.170.219.151:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 8.520474ms)
May 13 20:06:19.538: INFO: (10) /api/v1/nodes/10.170.219.151:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 9.869383ms)
May 13 20:06:19.547: INFO: (11) /api/v1/nodes/10.170.219.151:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 9.108429ms)
May 13 20:06:19.556: INFO: (12) /api/v1/nodes/10.170.219.151:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 8.875025ms)
May 13 20:06:19.565: INFO: (13) /api/v1/nodes/10.170.219.151:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 8.734339ms)
May 13 20:06:19.574: INFO: (14) /api/v1/nodes/10.170.219.151:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 9.035131ms)
May 13 20:06:19.582: INFO: (15) /api/v1/nodes/10.170.219.151:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 8.243345ms)
May 13 20:06:19.590: INFO: (16) /api/v1/nodes/10.170.219.151:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 8.036773ms)
May 13 20:06:19.601: INFO: (17) /api/v1/nodes/10.170.219.151:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 10.532091ms)
May 13 20:06:19.610: INFO: (18) /api/v1/nodes/10.170.219.151:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 9.463155ms)
May 13 20:06:19.620: INFO: (19) /api/v1/nodes/10.170.219.151:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 9.380762ms)
[AfterEach] version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 20:06:19.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-5c9hh" for this suite.
May 13 20:06:25.672: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 20:06:25.836: INFO: namespace: e2e-tests-proxy-5c9hh, resource: bindings, ignored listing per whitelist
May 13 20:06:25.961: INFO: namespace e2e-tests-proxy-5c9hh deletion completed in 6.334547988s

• [SLOW TEST:6.859 seconds]
[sig-network] Proxy
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 20:06:25.962: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-xgwn2
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-9695cb7d-75ba-11e9-8f67-2632f168be36
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-9695cb7d-75ba-11e9-8f67-2632f168be36
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 20:06:30.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-xgwn2" for this suite.
May 13 20:06:54.454: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 20:06:54.658: INFO: namespace: e2e-tests-configmap-xgwn2, resource: bindings, ignored listing per whitelist
May 13 20:06:54.700: INFO: namespace e2e-tests-configmap-xgwn2 deletion completed in 24.280403818s

• [SLOW TEST:28.739 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 20:06:54.702: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubelet-test-88b2w
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 20:06:55.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubelet-test-88b2w" for this suite.
May 13 20:07:17.095: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 20:07:17.162: INFO: namespace: e2e-tests-kubelet-test-88b2w, resource: bindings, ignored listing per whitelist
May 13 20:07:17.331: INFO: namespace e2e-tests-kubelet-test-88b2w deletion completed in 22.265671568s

• [SLOW TEST:22.629 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 20:07:17.332: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-d5pqr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 13 20:07:17.747: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
May 13 20:07:17.763: INFO: Number of nodes with available pods: 0
May 13 20:07:17.763: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
May 13 20:07:17.790: INFO: Number of nodes with available pods: 0
May 13 20:07:17.790: INFO: Node 10.170.219.151 is running more than one daemon pod
May 13 20:07:18.798: INFO: Number of nodes with available pods: 0
May 13 20:07:18.798: INFO: Node 10.170.219.151 is running more than one daemon pod
May 13 20:07:19.798: INFO: Number of nodes with available pods: 1
May 13 20:07:19.798: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
May 13 20:07:19.833: INFO: Number of nodes with available pods: 1
May 13 20:07:19.833: INFO: Number of running nodes: 0, number of available pods: 1
May 13 20:07:20.842: INFO: Number of nodes with available pods: 0
May 13 20:07:20.842: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
May 13 20:07:20.860: INFO: Number of nodes with available pods: 0
May 13 20:07:20.860: INFO: Node 10.170.219.151 is running more than one daemon pod
May 13 20:07:21.882: INFO: Number of nodes with available pods: 0
May 13 20:07:21.882: INFO: Node 10.170.219.151 is running more than one daemon pod
May 13 20:07:22.920: INFO: Number of nodes with available pods: 0
May 13 20:07:22.920: INFO: Node 10.170.219.151 is running more than one daemon pod
May 13 20:07:23.883: INFO: Number of nodes with available pods: 0
May 13 20:07:23.883: INFO: Node 10.170.219.151 is running more than one daemon pod
May 13 20:07:24.868: INFO: Number of nodes with available pods: 0
May 13 20:07:24.868: INFO: Node 10.170.219.151 is running more than one daemon pod
May 13 20:07:25.868: INFO: Number of nodes with available pods: 0
May 13 20:07:25.868: INFO: Node 10.170.219.151 is running more than one daemon pod
May 13 20:07:26.868: INFO: Number of nodes with available pods: 0
May 13 20:07:26.868: INFO: Node 10.170.219.151 is running more than one daemon pod
May 13 20:07:27.920: INFO: Number of nodes with available pods: 0
May 13 20:07:27.920: INFO: Node 10.170.219.151 is running more than one daemon pod
May 13 20:07:28.879: INFO: Number of nodes with available pods: 0
May 13 20:07:28.879: INFO: Node 10.170.219.151 is running more than one daemon pod
May 13 20:07:29.870: INFO: Number of nodes with available pods: 0
May 13 20:07:29.871: INFO: Node 10.170.219.151 is running more than one daemon pod
May 13 20:07:30.888: INFO: Number of nodes with available pods: 0
May 13 20:07:30.888: INFO: Node 10.170.219.151 is running more than one daemon pod
May 13 20:07:31.874: INFO: Number of nodes with available pods: 0
May 13 20:07:31.874: INFO: Node 10.170.219.151 is running more than one daemon pod
May 13 20:07:32.893: INFO: Number of nodes with available pods: 0
May 13 20:07:32.893: INFO: Node 10.170.219.151 is running more than one daemon pod
May 13 20:07:33.868: INFO: Number of nodes with available pods: 0
May 13 20:07:33.868: INFO: Node 10.170.219.151 is running more than one daemon pod
May 13 20:07:34.930: INFO: Number of nodes with available pods: 0
May 13 20:07:34.930: INFO: Node 10.170.219.151 is running more than one daemon pod
May 13 20:07:35.873: INFO: Number of nodes with available pods: 0
May 13 20:07:35.873: INFO: Node 10.170.219.151 is running more than one daemon pod
May 13 20:07:36.880: INFO: Number of nodes with available pods: 0
May 13 20:07:36.880: INFO: Node 10.170.219.151 is running more than one daemon pod
May 13 20:07:37.868: INFO: Number of nodes with available pods: 0
May 13 20:07:37.868: INFO: Node 10.170.219.151 is running more than one daemon pod
May 13 20:07:38.870: INFO: Number of nodes with available pods: 0
May 13 20:07:38.870: INFO: Node 10.170.219.151 is running more than one daemon pod
May 13 20:07:39.868: INFO: Number of nodes with available pods: 0
May 13 20:07:39.868: INFO: Node 10.170.219.151 is running more than one daemon pod
May 13 20:07:40.868: INFO: Number of nodes with available pods: 0
May 13 20:07:40.869: INFO: Node 10.170.219.151 is running more than one daemon pod
May 13 20:07:41.869: INFO: Number of nodes with available pods: 0
May 13 20:07:41.869: INFO: Node 10.170.219.151 is running more than one daemon pod
May 13 20:07:42.868: INFO: Number of nodes with available pods: 0
May 13 20:07:42.868: INFO: Node 10.170.219.151 is running more than one daemon pod
May 13 20:07:43.893: INFO: Number of nodes with available pods: 0
May 13 20:07:43.893: INFO: Node 10.170.219.151 is running more than one daemon pod
May 13 20:07:44.868: INFO: Number of nodes with available pods: 0
May 13 20:07:44.868: INFO: Node 10.170.219.151 is running more than one daemon pod
May 13 20:07:45.868: INFO: Number of nodes with available pods: 0
May 13 20:07:45.868: INFO: Node 10.170.219.151 is running more than one daemon pod
May 13 20:07:46.868: INFO: Number of nodes with available pods: 0
May 13 20:07:46.868: INFO: Node 10.170.219.151 is running more than one daemon pod
May 13 20:07:47.920: INFO: Number of nodes with available pods: 0
May 13 20:07:47.920: INFO: Node 10.170.219.151 is running more than one daemon pod
May 13 20:07:49.681: INFO: Number of nodes with available pods: 0
May 13 20:07:49.681: INFO: Node 10.170.219.151 is running more than one daemon pod
May 13 20:07:49.868: INFO: Number of nodes with available pods: 0
May 13 20:07:49.868: INFO: Node 10.170.219.151 is running more than one daemon pod
May 13 20:07:50.869: INFO: Number of nodes with available pods: 0
May 13 20:07:50.869: INFO: Node 10.170.219.151 is running more than one daemon pod
May 13 20:07:51.872: INFO: Number of nodes with available pods: 0
May 13 20:07:51.872: INFO: Node 10.170.219.151 is running more than one daemon pod
May 13 20:07:52.869: INFO: Number of nodes with available pods: 0
May 13 20:07:52.869: INFO: Node 10.170.219.151 is running more than one daemon pod
May 13 20:07:53.868: INFO: Number of nodes with available pods: 0
May 13 20:07:53.868: INFO: Node 10.170.219.151 is running more than one daemon pod
May 13 20:07:54.881: INFO: Number of nodes with available pods: 0
May 13 20:07:54.881: INFO: Node 10.170.219.151 is running more than one daemon pod
May 13 20:07:55.874: INFO: Number of nodes with available pods: 1
May 13 20:07:55.875: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace e2e-tests-daemonsets-d5pqr, will wait for the garbage collector to delete the pods
May 13 20:07:55.958: INFO: Deleting DaemonSet.extensions daemon-set took: 10.529376ms
May 13 20:07:56.058: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.20647ms
May 13 20:08:29.278: INFO: Number of nodes with available pods: 0
May 13 20:08:29.279: INFO: Number of running nodes: 0, number of available pods: 0
May 13 20:08:29.286: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-d5pqr/daemonsets","resourceVersion":"53288"},"items":null}

May 13 20:08:29.293: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-d5pqr/pods","resourceVersion":"53288"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 20:08:29.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-d5pqr" for this suite.
May 13 20:08:35.361: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 20:08:35.616: INFO: namespace: e2e-tests-daemonsets-d5pqr, resource: bindings, ignored listing per whitelist
May 13 20:08:35.669: INFO: namespace e2e-tests-daemonsets-d5pqr deletion completed in 6.33831091s

• [SLOW TEST:78.337 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 20:08:35.670: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-82kcd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 13 20:08:36.039: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e3f309b1-75ba-11e9-8f67-2632f168be36" in namespace "e2e-tests-downward-api-82kcd" to be "success or failure"
May 13 20:08:36.048: INFO: Pod "downwardapi-volume-e3f309b1-75ba-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 8.173881ms
May 13 20:08:38.058: INFO: Pod "downwardapi-volume-e3f309b1-75ba-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018206904s
STEP: Saw pod success
May 13 20:08:38.058: INFO: Pod "downwardapi-volume-e3f309b1-75ba-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 20:08:38.065: INFO: Trying to get logs from node 10.170.219.153 pod downwardapi-volume-e3f309b1-75ba-11e9-8f67-2632f168be36 container client-container: <nil>
STEP: delete the pod
May 13 20:08:38.107: INFO: Waiting for pod downwardapi-volume-e3f309b1-75ba-11e9-8f67-2632f168be36 to disappear
May 13 20:08:38.126: INFO: Pod downwardapi-volume-e3f309b1-75ba-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 20:08:38.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-82kcd" for this suite.
May 13 20:08:44.163: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 20:08:44.456: INFO: namespace: e2e-tests-downward-api-82kcd, resource: bindings, ignored listing per whitelist
May 13 20:08:44.505: INFO: namespace e2e-tests-downward-api-82kcd deletion completed in 6.370818392s

• [SLOW TEST:8.836 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 20:08:44.507: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-kvtfd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-kvtfd/configmap-test-e929fc5b-75ba-11e9-8f67-2632f168be36
STEP: Creating a pod to test consume configMaps
May 13 20:08:44.797: INFO: Waiting up to 5m0s for pod "pod-configmaps-e92b5c06-75ba-11e9-8f67-2632f168be36" in namespace "e2e-tests-configmap-kvtfd" to be "success or failure"
May 13 20:08:44.809: INFO: Pod "pod-configmaps-e92b5c06-75ba-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 11.585756ms
May 13 20:08:46.816: INFO: Pod "pod-configmaps-e92b5c06-75ba-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019531545s
May 13 20:08:48.826: INFO: Pod "pod-configmaps-e92b5c06-75ba-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029234296s
STEP: Saw pod success
May 13 20:08:48.826: INFO: Pod "pod-configmaps-e92b5c06-75ba-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 20:08:48.834: INFO: Trying to get logs from node 10.170.219.153 pod pod-configmaps-e92b5c06-75ba-11e9-8f67-2632f168be36 container env-test: <nil>
STEP: delete the pod
May 13 20:08:48.875: INFO: Waiting for pod pod-configmaps-e92b5c06-75ba-11e9-8f67-2632f168be36 to disappear
May 13 20:08:48.882: INFO: Pod pod-configmaps-e92b5c06-75ba-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 20:08:48.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-kvtfd" for this suite.
May 13 20:08:54.920: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 20:08:55.358: INFO: namespace: e2e-tests-configmap-kvtfd, resource: bindings, ignored listing per whitelist
May 13 20:08:55.460: INFO: namespace e2e-tests-configmap-kvtfd deletion completed in 6.569515609s

• [SLOW TEST:10.953 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 20:08:55.460: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-kgw8x
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1358
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
May 13 20:08:55.729: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-kgw8x'
May 13 20:08:55.847: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May 13 20:08:55.847: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
May 13 20:08:55.858: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
May 13 20:08:55.877: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
May 13 20:08:55.889: INFO: scanned /root for discovery docs: <nil>
May 13 20:08:55.889: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-kgw8x'
May 13 20:09:11.804: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
May 13 20:09:11.804: INFO: stdout: "Created e2e-test-nginx-rc-656ee7a55f091ff84ed8bf35f4c4f106\nScaling up e2e-test-nginx-rc-656ee7a55f091ff84ed8bf35f4c4f106 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-656ee7a55f091ff84ed8bf35f4c4f106 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-656ee7a55f091ff84ed8bf35f4c4f106 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
May 13 20:09:11.804: INFO: stdout: "Created e2e-test-nginx-rc-656ee7a55f091ff84ed8bf35f4c4f106\nScaling up e2e-test-nginx-rc-656ee7a55f091ff84ed8bf35f4c4f106 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-656ee7a55f091ff84ed8bf35f4c4f106 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-656ee7a55f091ff84ed8bf35f4c4f106 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
May 13 20:09:11.804: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-kgw8x'
May 13 20:09:11.911: INFO: stderr: ""
May 13 20:09:11.911: INFO: stdout: "e2e-test-nginx-rc-656ee7a55f091ff84ed8bf35f4c4f106-xf7fm "
May 13 20:09:11.911: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 get pods e2e-test-nginx-rc-656ee7a55f091ff84ed8bf35f4c4f106-xf7fm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-kgw8x'
May 13 20:09:12.032: INFO: stderr: ""
May 13 20:09:12.032: INFO: stdout: "true"
May 13 20:09:12.032: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 get pods e2e-test-nginx-rc-656ee7a55f091ff84ed8bf35f4c4f106-xf7fm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-kgw8x'
May 13 20:09:12.130: INFO: stderr: ""
May 13 20:09:12.130: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
May 13 20:09:12.130: INFO: e2e-test-nginx-rc-656ee7a55f091ff84ed8bf35f4c4f106-xf7fm is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1364
May 13 20:09:12.130: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-kgw8x'
May 13 20:09:12.250: INFO: stderr: ""
May 13 20:09:12.250: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 20:09:12.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-kgw8x" for this suite.
May 13 20:09:18.356: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 20:09:18.744: INFO: namespace: e2e-tests-kubectl-kgw8x, resource: bindings, ignored listing per whitelist
May 13 20:09:18.831: INFO: namespace e2e-tests-kubectl-kgw8x deletion completed in 6.502925597s

• [SLOW TEST:23.371 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 20:09:18.831: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-ctk8q
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
May 13 20:09:21.164: INFO: Pod pod-hostip-fda1c021-75ba-11e9-8f67-2632f168be36 has hostIP: 10.170.219.153
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 20:09:21.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-ctk8q" for this suite.
May 13 20:09:45.251: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 20:09:45.401: INFO: namespace: e2e-tests-pods-ctk8q, resource: bindings, ignored listing per whitelist
May 13 20:09:45.554: INFO: namespace e2e-tests-pods-ctk8q deletion completed in 24.380793794s

• [SLOW TEST:26.723 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 20:09:45.554: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-tc48m
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-0d9cecd6-75bb-11e9-8f67-2632f168be36
STEP: Creating a pod to test consume secrets
May 13 20:09:45.947: INFO: Waiting up to 5m0s for pod "pod-secrets-0d9e6160-75bb-11e9-8f67-2632f168be36" in namespace "e2e-tests-secrets-tc48m" to be "success or failure"
May 13 20:09:45.955: INFO: Pod "pod-secrets-0d9e6160-75bb-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 7.293741ms
May 13 20:09:47.975: INFO: Pod "pod-secrets-0d9e6160-75bb-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02724385s
STEP: Saw pod success
May 13 20:09:47.975: INFO: Pod "pod-secrets-0d9e6160-75bb-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 20:09:48.020: INFO: Trying to get logs from node 10.170.219.177 pod pod-secrets-0d9e6160-75bb-11e9-8f67-2632f168be36 container secret-volume-test: <nil>
STEP: delete the pod
May 13 20:09:48.062: INFO: Waiting for pod pod-secrets-0d9e6160-75bb-11e9-8f67-2632f168be36 to disappear
May 13 20:09:48.070: INFO: Pod pod-secrets-0d9e6160-75bb-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 20:09:48.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-tc48m" for this suite.
May 13 20:09:54.105: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 20:09:54.423: INFO: namespace: e2e-tests-secrets-tc48m, resource: bindings, ignored listing per whitelist
May 13 20:09:54.501: INFO: namespace e2e-tests-secrets-tc48m deletion completed in 6.423705141s

• [SLOW TEST:8.947 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 20:09:54.501: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-srbl6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 20:09:54.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-srbl6" for this suite.
May 13 20:10:16.830: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 20:10:17.055: INFO: namespace: e2e-tests-pods-srbl6, resource: bindings, ignored listing per whitelist
May 13 20:10:17.182: INFO: namespace e2e-tests-pods-srbl6 deletion completed in 22.379752585s

• [SLOW TEST:22.681 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 20:10:17.185: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-mshcx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-mshcx
May 13 20:10:19.497: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-mshcx
STEP: checking the pod's current state and verifying that restartCount is present
May 13 20:10:19.504: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 20:14:22.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-mshcx" for this suite.
May 13 20:14:28.358: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 20:14:28.600: INFO: namespace: e2e-tests-container-probe-mshcx, resource: bindings, ignored listing per whitelist
May 13 20:14:28.655: INFO: namespace e2e-tests-container-probe-mshcx deletion completed in 6.327500146s

• [SLOW TEST:251.471 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 20:14:28.656: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-5rsmm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
May 13 20:14:29.037: INFO: Waiting up to 5m0s for pod "pod-b65a7534-75bb-11e9-8f67-2632f168be36" in namespace "e2e-tests-emptydir-5rsmm" to be "success or failure"
May 13 20:14:29.047: INFO: Pod "pod-b65a7534-75bb-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 10.414405ms
May 13 20:14:31.059: INFO: Pod "pod-b65a7534-75bb-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021794917s
STEP: Saw pod success
May 13 20:14:31.059: INFO: Pod "pod-b65a7534-75bb-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 20:14:31.067: INFO: Trying to get logs from node 10.170.219.153 pod pod-b65a7534-75bb-11e9-8f67-2632f168be36 container test-container: <nil>
STEP: delete the pod
May 13 20:14:31.111: INFO: Waiting for pod pod-b65a7534-75bb-11e9-8f67-2632f168be36 to disappear
May 13 20:14:31.117: INFO: Pod pod-b65a7534-75bb-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 20:14:31.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-5rsmm" for this suite.
May 13 20:14:37.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 20:14:37.432: INFO: namespace: e2e-tests-emptydir-5rsmm, resource: bindings, ignored listing per whitelist
May 13 20:14:37.552: INFO: namespace e2e-tests-emptydir-5rsmm deletion completed in 6.426595809s

• [SLOW TEST:8.896 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 20:14:37.552: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-4ffsr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 13 20:14:37.899: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bba27aa9-75bb-11e9-8f67-2632f168be36" in namespace "e2e-tests-projected-4ffsr" to be "success or failure"
May 13 20:14:37.911: INFO: Pod "downwardapi-volume-bba27aa9-75bb-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 11.990284ms
May 13 20:14:39.919: INFO: Pod "downwardapi-volume-bba27aa9-75bb-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019870367s
STEP: Saw pod success
May 13 20:14:39.919: INFO: Pod "downwardapi-volume-bba27aa9-75bb-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 20:14:39.928: INFO: Trying to get logs from node 10.170.219.153 pod downwardapi-volume-bba27aa9-75bb-11e9-8f67-2632f168be36 container client-container: <nil>
STEP: delete the pod
May 13 20:14:39.968: INFO: Waiting for pod downwardapi-volume-bba27aa9-75bb-11e9-8f67-2632f168be36 to disappear
May 13 20:14:39.974: INFO: Pod downwardapi-volume-bba27aa9-75bb-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 20:14:39.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4ffsr" for this suite.
May 13 20:14:46.022: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 20:14:46.257: INFO: namespace: e2e-tests-projected-4ffsr, resource: bindings, ignored listing per whitelist
May 13 20:14:46.350: INFO: namespace e2e-tests-projected-4ffsr deletion completed in 6.368171089s

• [SLOW TEST:8.798 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 20:14:46.351: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-chxwn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secret-namespace-mxrzk
STEP: Creating secret with name secret-test-c0d82497-75bb-11e9-8f67-2632f168be36
STEP: Creating a pod to test consume secrets
May 13 20:14:46.869: INFO: Waiting up to 5m0s for pod "pod-secrets-c0fb5fda-75bb-11e9-8f67-2632f168be36" in namespace "e2e-tests-secrets-chxwn" to be "success or failure"
May 13 20:14:46.876: INFO: Pod "pod-secrets-c0fb5fda-75bb-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 7.50352ms
May 13 20:14:48.885: INFO: Pod "pod-secrets-c0fb5fda-75bb-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015557265s
STEP: Saw pod success
May 13 20:14:48.885: INFO: Pod "pod-secrets-c0fb5fda-75bb-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 20:14:48.892: INFO: Trying to get logs from node 10.170.219.153 pod pod-secrets-c0fb5fda-75bb-11e9-8f67-2632f168be36 container secret-volume-test: <nil>
STEP: delete the pod
May 13 20:14:49.020: INFO: Waiting for pod pod-secrets-c0fb5fda-75bb-11e9-8f67-2632f168be36 to disappear
May 13 20:14:49.030: INFO: Pod pod-secrets-c0fb5fda-75bb-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 20:14:49.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-chxwn" for this suite.
May 13 20:14:55.067: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 20:14:55.380: INFO: namespace: e2e-tests-secrets-chxwn, resource: bindings, ignored listing per whitelist
May 13 20:14:55.395: INFO: namespace e2e-tests-secrets-chxwn deletion completed in 6.357320184s
STEP: Destroying namespace "e2e-tests-secret-namespace-mxrzk" for this suite.
May 13 20:15:01.427: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 20:15:01.576: INFO: namespace: e2e-tests-secret-namespace-mxrzk, resource: bindings, ignored listing per whitelist
May 13 20:15:01.816: INFO: namespace e2e-tests-secret-namespace-mxrzk deletion completed in 6.421426597s

• [SLOW TEST:15.465 seconds]
[sig-storage] Secrets
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 20:15:01.819: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-c2jf8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 13 20:15:22.220: INFO: Container started at 2019-05-13 20:15:03 +0000 UTC, pod became ready at 2019-05-13 20:15:20 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 20:15:22.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-c2jf8" for this suite.
May 13 20:15:44.258: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 20:15:44.351: INFO: namespace: e2e-tests-container-probe-c2jf8, resource: bindings, ignored listing per whitelist
May 13 20:15:44.489: INFO: namespace e2e-tests-container-probe-c2jf8 deletion completed in 22.261130375s

• [SLOW TEST:42.671 seconds]
[k8s.io] Probing container
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 20:15:44.489: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-r9fqs
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-e3896e31-75bb-11e9-8f67-2632f168be36
STEP: Creating a pod to test consume configMaps
May 13 20:15:44.852: INFO: Waiting up to 5m0s for pod "pod-configmaps-e38acc3f-75bb-11e9-8f67-2632f168be36" in namespace "e2e-tests-configmap-r9fqs" to be "success or failure"
May 13 20:15:44.984: INFO: Pod "pod-configmaps-e38acc3f-75bb-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 132.309598ms
May 13 20:15:46.992: INFO: Pod "pod-configmaps-e38acc3f-75bb-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.139894166s
STEP: Saw pod success
May 13 20:15:46.992: INFO: Pod "pod-configmaps-e38acc3f-75bb-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 20:15:46.999: INFO: Trying to get logs from node 10.170.219.177 pod pod-configmaps-e38acc3f-75bb-11e9-8f67-2632f168be36 container configmap-volume-test: <nil>
STEP: delete the pod
May 13 20:15:47.048: INFO: Waiting for pod pod-configmaps-e38acc3f-75bb-11e9-8f67-2632f168be36 to disappear
May 13 20:15:47.058: INFO: Pod pod-configmaps-e38acc3f-75bb-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 20:15:47.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-r9fqs" for this suite.
May 13 20:15:53.109: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 20:15:53.371: INFO: namespace: e2e-tests-configmap-r9fqs, resource: bindings, ignored listing per whitelist
May 13 20:15:53.428: INFO: namespace e2e-tests-configmap-r9fqs deletion completed in 6.362596071s

• [SLOW TEST:8.939 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 20:15:53.428: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-dzc9t
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
May 13 20:15:53.726: INFO: Waiting up to 5m0s for pod "var-expansion-e8d4d3a7-75bb-11e9-8f67-2632f168be36" in namespace "e2e-tests-var-expansion-dzc9t" to be "success or failure"
May 13 20:15:53.733: INFO: Pod "var-expansion-e8d4d3a7-75bb-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 7.498608ms
May 13 20:15:55.741: INFO: Pod "var-expansion-e8d4d3a7-75bb-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015254516s
STEP: Saw pod success
May 13 20:15:55.741: INFO: Pod "var-expansion-e8d4d3a7-75bb-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 20:15:55.748: INFO: Trying to get logs from node 10.170.219.153 pod var-expansion-e8d4d3a7-75bb-11e9-8f67-2632f168be36 container dapi-container: <nil>
STEP: delete the pod
May 13 20:15:55.846: INFO: Waiting for pod var-expansion-e8d4d3a7-75bb-11e9-8f67-2632f168be36 to disappear
May 13 20:15:55.853: INFO: Pod var-expansion-e8d4d3a7-75bb-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 20:15:55.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-dzc9t" for this suite.
May 13 20:16:01.892: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 20:16:02.013: INFO: namespace: e2e-tests-var-expansion-dzc9t, resource: bindings, ignored listing per whitelist
May 13 20:16:02.189: INFO: namespace e2e-tests-var-expansion-dzc9t deletion completed in 6.326041024s

• [SLOW TEST:8.760 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 20:16:02.189: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-vvr62
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
May 13 20:16:02.543: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-vvr62'
May 13 20:16:02.870: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May 13 20:16:02.870: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
May 13 20:16:04.907: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-bvrtz]
May 13 20:16:04.907: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-bvrtz" in namespace "e2e-tests-kubectl-vvr62" to be "running and ready"
May 13 20:16:04.914: INFO: Pod "e2e-test-nginx-rc-bvrtz": Phase="Running", Reason="", readiness=true. Elapsed: 7.466876ms
May 13 20:16:04.914: INFO: Pod "e2e-test-nginx-rc-bvrtz" satisfied condition "running and ready"
May 13 20:16:04.914: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-bvrtz]
May 13 20:16:04.914: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-vvr62'
May 13 20:16:05.232: INFO: stderr: ""
May 13 20:16:05.232: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1303
May 13 20:16:05.232: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-vvr62'
May 13 20:16:05.365: INFO: stderr: ""
May 13 20:16:05.365: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 20:16:05.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-vvr62" for this suite.
May 13 20:16:29.401: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 20:16:29.640: INFO: namespace: e2e-tests-kubectl-vvr62, resource: bindings, ignored listing per whitelist
May 13 20:16:29.651: INFO: namespace e2e-tests-kubectl-vvr62 deletion completed in 24.277262501s

• [SLOW TEST:27.462 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 20:16:29.652: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-c9jvv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
May 13 20:16:32.621: INFO: Successfully updated pod "pod-update-activedeadlineseconds-fe7d78cb-75bb-11e9-8f67-2632f168be36"
May 13 20:16:32.621: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-fe7d78cb-75bb-11e9-8f67-2632f168be36" in namespace "e2e-tests-pods-c9jvv" to be "terminated due to deadline exceeded"
May 13 20:16:32.630: INFO: Pod "pod-update-activedeadlineseconds-fe7d78cb-75bb-11e9-8f67-2632f168be36": Phase="Running", Reason="", readiness=true. Elapsed: 9.330431ms
May 13 20:16:34.639: INFO: Pod "pod-update-activedeadlineseconds-fe7d78cb-75bb-11e9-8f67-2632f168be36": Phase="Running", Reason="", readiness=true. Elapsed: 2.017776709s
May 13 20:16:36.647: INFO: Pod "pod-update-activedeadlineseconds-fe7d78cb-75bb-11e9-8f67-2632f168be36": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.026009315s
May 13 20:16:36.647: INFO: Pod "pod-update-activedeadlineseconds-fe7d78cb-75bb-11e9-8f67-2632f168be36" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 20:16:36.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-c9jvv" for this suite.
May 13 20:16:42.685: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 20:16:42.915: INFO: namespace: e2e-tests-pods-c9jvv, resource: bindings, ignored listing per whitelist
May 13 20:16:42.924: INFO: namespace e2e-tests-pods-c9jvv deletion completed in 6.268454428s

• [SLOW TEST:13.272 seconds]
[k8s.io] Pods
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 20:16:42.925: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-65vck
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
May 13 20:16:43.223: INFO: Waiting up to 5m0s for pod "pod-065585ae-75bc-11e9-8f67-2632f168be36" in namespace "e2e-tests-emptydir-65vck" to be "success or failure"
May 13 20:16:43.231: INFO: Pod "pod-065585ae-75bc-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 8.156224ms
May 13 20:16:45.239: INFO: Pod "pod-065585ae-75bc-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015874661s
STEP: Saw pod success
May 13 20:16:45.239: INFO: Pod "pod-065585ae-75bc-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 20:16:45.246: INFO: Trying to get logs from node 10.170.219.153 pod pod-065585ae-75bc-11e9-8f67-2632f168be36 container test-container: <nil>
STEP: delete the pod
May 13 20:16:45.345: INFO: Waiting for pod pod-065585ae-75bc-11e9-8f67-2632f168be36 to disappear
May 13 20:16:45.353: INFO: Pod pod-065585ae-75bc-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 20:16:45.353: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-65vck" for this suite.
May 13 20:16:51.391: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 20:16:51.489: INFO: namespace: e2e-tests-emptydir-65vck, resource: bindings, ignored listing per whitelist
May 13 20:16:51.620: INFO: namespace e2e-tests-emptydir-65vck deletion completed in 6.258516218s

• [SLOW TEST:8.696 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 20:16:51.620: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-kjfjj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-kjfjj
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 13 20:16:51.890: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 13 20:17:14.065: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 172.30.227.80 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-kjfjj PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 13 20:17:14.065: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
May 13 20:17:15.275: INFO: Found all expected endpoints: [netserver-0]
May 13 20:17:15.283: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 172.30.19.125 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-kjfjj PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 13 20:17:15.283: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
May 13 20:17:16.477: INFO: Found all expected endpoints: [netserver-1]
May 13 20:17:16.528: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | nc -w 1 -u 172.30.63.20 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-kjfjj PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 13 20:17:16.528: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
May 13 20:17:17.687: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 20:17:17.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-kjfjj" for this suite.
May 13 20:17:35.725: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 20:17:35.849: INFO: namespace: e2e-tests-pod-network-test-kjfjj, resource: bindings, ignored listing per whitelist
May 13 20:17:36.049: INFO: namespace e2e-tests-pod-network-test-kjfjj deletion completed in 18.352794377s

• [SLOW TEST:44.428 seconds]
[sig-network] Networking
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 20:17:36.049: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-khddf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:85
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-khddf
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-khddf to expose endpoints map[]
May 13 20:17:36.367: INFO: Get endpoints failed (5.133695ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
May 13 20:17:37.373: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-khddf exposes endpoints map[] (1.01171746s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-khddf
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-khddf to expose endpoints map[pod1:[100]]
May 13 20:17:39.432: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-khddf exposes endpoints map[pod1:[100]] (2.041965415s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-khddf
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-khddf to expose endpoints map[pod1:[100] pod2:[101]]
May 13 20:17:41.639: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-khddf exposes endpoints map[pod1:[100] pod2:[101]] (2.119316868s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-khddf
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-khddf to expose endpoints map[pod2:[101]]
May 13 20:17:42.678: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-khddf exposes endpoints map[pod2:[101]] (1.02579511s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-khddf
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-khddf to expose endpoints map[]
May 13 20:17:43.703: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-khddf exposes endpoints map[] (1.011492866s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 20:17:43.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-khddf" for this suite.
May 13 20:17:49.794: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 20:17:49.987: INFO: namespace: e2e-tests-services-khddf, resource: bindings, ignored listing per whitelist
May 13 20:17:50.042: INFO: namespace e2e-tests-services-khddf deletion completed in 6.276098868s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:90

• [SLOW TEST:13.993 seconds]
[sig-network] Services
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 20:17:50.044: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-h4qgj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
May 13 20:17:50.430: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
May 13 20:17:52.447: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
May 13 20:17:52.549: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-h4qgj,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-h4qgj/deployments/test-cleanup-deployment,UID:2fa6a224-75bc-11e9-b786-da20024d205c,ResourceVersion:55171,Generation:1,CreationTimestamp:2019-05-13 20:17:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

May 13 20:17:52.556: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 20:17:52.563: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-h4qgj" for this suite.
May 13 20:17:58.600: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 20:17:58.741: INFO: namespace: e2e-tests-deployment-h4qgj, resource: bindings, ignored listing per whitelist
May 13 20:17:58.885: INFO: namespace e2e-tests-deployment-h4qgj deletion completed in 6.313801321s

• [SLOW TEST:8.841 seconds]
[sig-apps] Deployment
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 20:17:58.885: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-4xfpc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
May 13 20:17:59.145: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May 13 20:17:59.226: INFO: Waiting for terminating namespaces to be deleted...
May 13 20:17:59.234: INFO: 
Logging pods the kubelet thinks is on node 10.170.219.151 before test
May 13 20:17:59.270: INFO: coredns-58d696879-rrkth from kube-system started at 2019-05-13 16:27:35 +0000 UTC (1 container statuses recorded)
May 13 20:17:59.270: INFO: 	Container coredns ready: true, restart count 0
May 13 20:17:59.270: INFO: ibm-file-plugin-7f6d8979bd-p5smn from kube-system started at 2019-05-13 16:27:35 +0000 UTC (1 container statuses recorded)
May 13 20:17:59.270: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
May 13 20:17:59.270: INFO: coredns-58d696879-zmj2g from kube-system started at 2019-05-13 16:27:49 +0000 UTC (1 container statuses recorded)
May 13 20:17:59.270: INFO: 	Container coredns ready: true, restart count 0
May 13 20:17:59.270: INFO: calico-node-d9d6s from kube-system started at 2019-05-13 16:27:05 +0000 UTC (1 container statuses recorded)
May 13 20:17:59.270: INFO: 	Container calico-node ready: true, restart count 0
May 13 20:17:59.270: INFO: vpn-774cf5c6d4-6p6cr from kube-system started at 2019-05-13 16:27:35 +0000 UTC (1 container statuses recorded)
May 13 20:17:59.270: INFO: 	Container vpn ready: true, restart count 0
May 13 20:17:59.270: INFO: ibm-keepalived-watcher-8wshf from kube-system started at 2019-05-13 16:27:05 +0000 UTC (1 container statuses recorded)
May 13 20:17:59.270: INFO: 	Container keepalived-watcher ready: true, restart count 0
May 13 20:17:59.270: INFO: kubernetes-dashboard-7996b848f4-mzbwj from kube-system started at 2019-05-13 16:27:35 +0000 UTC (1 container statuses recorded)
May 13 20:17:59.270: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
May 13 20:17:59.270: INFO: ibm-kube-fluentd-6fw9c from kube-system started at 2019-05-13 16:32:50 +0000 UTC (1 container statuses recorded)
May 13 20:17:59.270: INFO: 	Container fluentd ready: true, restart count 0
May 13 20:17:59.270: INFO: ibm-storage-watcher-845946d5b5-knxcm from kube-system started at 2019-05-13 16:27:35 +0000 UTC (1 container statuses recorded)
May 13 20:17:59.270: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
May 13 20:17:59.270: INFO: coredns-autoscaler-64f9c5b4df-hzq57 from kube-system started at 2019-05-13 16:27:35 +0000 UTC (1 container statuses recorded)
May 13 20:17:59.270: INFO: 	Container autoscaler ready: true, restart count 0
May 13 20:17:59.270: INFO: sonobuoy-systemd-logs-daemon-set-8e5ce9bdf4a94ece-nlv42 from heptio-sonobuoy started at 2019-05-13 18:40:58 +0000 UTC (2 container statuses recorded)
May 13 20:17:59.270: INFO: 	Container sonobuoy-worker ready: true, restart count 1
May 13 20:17:59.270: INFO: 	Container systemd-logs ready: true, restart count 1
May 13 20:17:59.270: INFO: ibm-master-proxy-static-10.170.219.151 from kube-system started at <nil> (0 container statuses recorded)
May 13 20:17:59.270: INFO: calico-kube-controllers-7dd978d898-r8w74 from kube-system started at 2019-05-13 16:27:35 +0000 UTC (1 container statuses recorded)
May 13 20:17:59.270: INFO: 	Container calico-kube-controllers ready: true, restart count 0
May 13 20:17:59.270: INFO: public-cr0ef1a5f1e33c44fe9c21650356d908ee-alb1-8f59cf484-9v5pm from kube-system started at 2019-05-13 16:35:03 +0000 UTC (4 container statuses recorded)
May 13 20:17:59.270: INFO: 	Container ingress-auth-1 ready: true, restart count 0
May 13 20:17:59.270: INFO: 	Container ingress-auth-2 ready: true, restart count 0
May 13 20:17:59.270: INFO: 	Container ingress-auth-3 ready: true, restart count 0
May 13 20:17:59.270: INFO: 	Container nginx-ingress ready: true, restart count 0
May 13 20:17:59.270: INFO: 
Logging pods the kubelet thinks is on node 10.170.219.153 before test
May 13 20:17:59.299: INFO: sonobuoy-systemd-logs-daemon-set-8e5ce9bdf4a94ece-tgp2l from heptio-sonobuoy started at 2019-05-13 18:40:58 +0000 UTC (2 container statuses recorded)
May 13 20:17:59.299: INFO: 	Container sonobuoy-worker ready: true, restart count 1
May 13 20:17:59.299: INFO: 	Container systemd-logs ready: true, restart count 1
May 13 20:17:59.299: INFO: metrics-server-58dd96c6bd-sggps from kube-system started at 2019-05-13 16:28:04 +0000 UTC (2 container statuses recorded)
May 13 20:17:59.299: INFO: 	Container metrics-server ready: true, restart count 0
May 13 20:17:59.299: INFO: 	Container metrics-server-nanny ready: true, restart count 0
May 13 20:17:59.299: INFO: test-k8s-e2e-pvg-master-verification from default started at 2019-05-13 18:40:52 +0000 UTC (1 container statuses recorded)
May 13 20:17:59.299: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
May 13 20:17:59.299: INFO: ibm-master-proxy-static-10.170.219.153 from kube-system started at <nil> (0 container statuses recorded)
May 13 20:17:59.299: INFO: ibm-keepalived-watcher-cwtfg from kube-system started at 2019-05-13 16:27:29 +0000 UTC (1 container statuses recorded)
May 13 20:17:59.299: INFO: 	Container keepalived-watcher ready: true, restart count 0
May 13 20:17:59.299: INFO: ibm-kube-fluentd-cdmr5 from kube-system started at 2019-05-13 16:32:50 +0000 UTC (1 container statuses recorded)
May 13 20:17:59.299: INFO: 	Container fluentd ready: true, restart count 0
May 13 20:17:59.299: INFO: sonobuoy from heptio-sonobuoy started at 2019-05-13 18:40:57 +0000 UTC (1 container statuses recorded)
May 13 20:17:59.299: INFO: 	Container kube-sonobuoy ready: true, restart count 0
May 13 20:17:59.299: INFO: calico-node-phw8q from kube-system started at 2019-05-13 16:27:29 +0000 UTC (1 container statuses recorded)
May 13 20:17:59.299: INFO: 	Container calico-node ready: true, restart count 0
May 13 20:17:59.299: INFO: ibm-cloud-provider-ip-169-45-218-130-66c489dcb-z58z4 from ibm-system started at 2019-05-13 16:30:08 +0000 UTC (1 container statuses recorded)
May 13 20:17:59.299: INFO: 	Container ibm-cloud-provider-ip-169-45-218-130 ready: true, restart count 0
May 13 20:17:59.299: INFO: 
Logging pods the kubelet thinks is on node 10.170.219.177 before test
May 13 20:17:59.319: INFO: ibm-cloud-provider-ip-169-45-218-130-66c489dcb-kd74s from ibm-system started at 2019-05-13 16:30:08 +0000 UTC (1 container statuses recorded)
May 13 20:17:59.319: INFO: 	Container ibm-cloud-provider-ip-169-45-218-130 ready: true, restart count 0
May 13 20:17:59.319: INFO: public-cr0ef1a5f1e33c44fe9c21650356d908ee-alb1-8f59cf484-7r5vq from kube-system started at 2019-05-13 16:35:03 +0000 UTC (4 container statuses recorded)
May 13 20:17:59.319: INFO: 	Container ingress-auth-1 ready: true, restart count 0
May 13 20:17:59.319: INFO: 	Container ingress-auth-2 ready: true, restart count 0
May 13 20:17:59.319: INFO: 	Container ingress-auth-3 ready: true, restart count 0
May 13 20:17:59.319: INFO: 	Container nginx-ingress ready: true, restart count 0
May 13 20:17:59.319: INFO: ibm-kube-fluentd-zzl5d from kube-system started at 2019-05-13 16:32:50 +0000 UTC (1 container statuses recorded)
May 13 20:17:59.319: INFO: 	Container fluentd ready: true, restart count 0
May 13 20:17:59.319: INFO: sonobuoy-e2e-job-afa7e83446444f4e from heptio-sonobuoy started at 2019-05-13 18:40:58 +0000 UTC (2 container statuses recorded)
May 13 20:17:59.319: INFO: 	Container e2e ready: true, restart count 0
May 13 20:17:59.319: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 13 20:17:59.319: INFO: sonobuoy-systemd-logs-daemon-set-8e5ce9bdf4a94ece-kjc69 from heptio-sonobuoy started at 2019-05-13 18:40:58 +0000 UTC (2 container statuses recorded)
May 13 20:17:59.319: INFO: 	Container sonobuoy-worker ready: true, restart count 1
May 13 20:17:59.319: INFO: 	Container systemd-logs ready: true, restart count 1
May 13 20:17:59.319: INFO: ibm-master-proxy-static-10.170.219.177 from kube-system started at <nil> (0 container statuses recorded)
May 13 20:17:59.319: INFO: ibm-keepalived-watcher-qszvz from kube-system started at 2019-05-13 16:27:34 +0000 UTC (1 container statuses recorded)
May 13 20:17:59.319: INFO: 	Container keepalived-watcher ready: true, restart count 0
May 13 20:17:59.319: INFO: calico-node-twx7l from kube-system started at 2019-05-13 16:27:34 +0000 UTC (1 container statuses recorded)
May 13 20:17:59.319: INFO: 	Container calico-node ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.159e577495dff002], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 20:18:00.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-4xfpc" for this suite.
May 13 20:18:06.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 20:18:06.776: INFO: namespace: e2e-tests-sched-pred-4xfpc, resource: bindings, ignored listing per whitelist
May 13 20:18:06.904: INFO: namespace e2e-tests-sched-pred-4xfpc deletion completed in 6.484047823s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:8.020 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 20:18:06.905: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replication-controller-8vtxs
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 20:18:10.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-8vtxs" for this suite.
May 13 20:18:32.381: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 20:18:32.475: INFO: namespace: e2e-tests-replication-controller-8vtxs, resource: bindings, ignored listing per whitelist
May 13 20:18:32.678: INFO: namespace e2e-tests-replication-controller-8vtxs deletion completed in 22.324904654s

• [SLOW TEST:25.773 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 20:18:32.678: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-82g8b
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 13 20:18:33.038: INFO: Waiting up to 5m0s for pod "downwardapi-volume-47c9edf5-75bc-11e9-8f67-2632f168be36" in namespace "e2e-tests-downward-api-82g8b" to be "success or failure"
May 13 20:18:33.046: INFO: Pod "downwardapi-volume-47c9edf5-75bc-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 7.626196ms
May 13 20:18:35.054: INFO: Pod "downwardapi-volume-47c9edf5-75bc-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015991812s
May 13 20:18:37.063: INFO: Pod "downwardapi-volume-47c9edf5-75bc-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025137572s
STEP: Saw pod success
May 13 20:18:37.063: INFO: Pod "downwardapi-volume-47c9edf5-75bc-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 20:18:37.071: INFO: Trying to get logs from node 10.170.219.153 pod downwardapi-volume-47c9edf5-75bc-11e9-8f67-2632f168be36 container client-container: <nil>
STEP: delete the pod
May 13 20:18:37.115: INFO: Waiting for pod downwardapi-volume-47c9edf5-75bc-11e9-8f67-2632f168be36 to disappear
May 13 20:18:37.122: INFO: Pod downwardapi-volume-47c9edf5-75bc-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 20:18:37.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-82g8b" for this suite.
May 13 20:18:43.160: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 20:18:43.184: INFO: namespace: e2e-tests-downward-api-82g8b, resource: bindings, ignored listing per whitelist
May 13 20:18:43.453: INFO: namespace e2e-tests-downward-api-82g8b deletion completed in 6.323095867s

• [SLOW TEST:10.775 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 20:18:43.453: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-jq2l8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
May 13 20:18:43.838: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4e398d27-75bc-11e9-8f67-2632f168be36" in namespace "e2e-tests-projected-jq2l8" to be "success or failure"
May 13 20:18:43.847: INFO: Pod "downwardapi-volume-4e398d27-75bc-11e9-8f67-2632f168be36": Phase="Pending", Reason="", readiness=false. Elapsed: 8.696323ms
May 13 20:18:46.304: INFO: Pod "downwardapi-volume-4e398d27-75bc-11e9-8f67-2632f168be36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.4652717s
STEP: Saw pod success
May 13 20:18:46.304: INFO: Pod "downwardapi-volume-4e398d27-75bc-11e9-8f67-2632f168be36" satisfied condition "success or failure"
May 13 20:18:46.312: INFO: Trying to get logs from node 10.170.219.153 pod downwardapi-volume-4e398d27-75bc-11e9-8f67-2632f168be36 container client-container: <nil>
STEP: delete the pod
May 13 20:18:46.353: INFO: Waiting for pod downwardapi-volume-4e398d27-75bc-11e9-8f67-2632f168be36 to disappear
May 13 20:18:46.360: INFO: Pod downwardapi-volume-4e398d27-75bc-11e9-8f67-2632f168be36 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 20:18:46.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jq2l8" for this suite.
May 13 20:18:52.408: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 20:18:52.454: INFO: namespace: e2e-tests-projected-jq2l8, resource: bindings, ignored listing per whitelist
May 13 20:18:52.673: INFO: namespace e2e-tests-projected-jq2l8 deletion completed in 6.305204466s

• [SLOW TEST:9.220 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 20:18:52.673: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-t8x9k
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:243
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
May 13 20:18:52.944: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-555138423 --namespace=e2e-tests-kubectl-t8x9k run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
May 13 20:18:54.919: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
May 13 20:18:54.919: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 20:18:56.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-t8x9k" for this suite.
May 13 20:19:02.977: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 20:19:03.163: INFO: namespace: e2e-tests-kubectl-t8x9k, resource: bindings, ignored listing per whitelist
May 13 20:19:03.266: INFO: namespace e2e-tests-kubectl-t8x9k deletion completed in 6.329119229s

• [SLOW TEST:10.593 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:153
STEP: Creating a kubernetes client
May 13 20:19:03.267: INFO: >>> kubeConfig: /tmp/kubeconfig-555138423
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-5t98x
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
May 13 20:19:03.543: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May 13 20:19:03.556: INFO: Waiting for terminating namespaces to be deleted...
May 13 20:19:03.564: INFO: 
Logging pods the kubelet thinks is on node 10.170.219.151 before test
May 13 20:19:03.589: INFO: calico-kube-controllers-7dd978d898-r8w74 from kube-system started at 2019-05-13 16:27:35 +0000 UTC (1 container statuses recorded)
May 13 20:19:03.589: INFO: 	Container calico-kube-controllers ready: true, restart count 0
May 13 20:19:03.589: INFO: public-cr0ef1a5f1e33c44fe9c21650356d908ee-alb1-8f59cf484-9v5pm from kube-system started at 2019-05-13 16:35:03 +0000 UTC (4 container statuses recorded)
May 13 20:19:03.589: INFO: 	Container ingress-auth-1 ready: true, restart count 0
May 13 20:19:03.589: INFO: 	Container ingress-auth-2 ready: true, restart count 0
May 13 20:19:03.589: INFO: 	Container ingress-auth-3 ready: true, restart count 0
May 13 20:19:03.589: INFO: 	Container nginx-ingress ready: true, restart count 0
May 13 20:19:03.589: INFO: ibm-master-proxy-static-10.170.219.151 from kube-system started at <nil> (0 container statuses recorded)
May 13 20:19:03.589: INFO: vpn-774cf5c6d4-6p6cr from kube-system started at 2019-05-13 16:27:35 +0000 UTC (1 container statuses recorded)
May 13 20:19:03.589: INFO: 	Container vpn ready: true, restart count 0
May 13 20:19:03.589: INFO: ibm-keepalived-watcher-8wshf from kube-system started at 2019-05-13 16:27:05 +0000 UTC (1 container statuses recorded)
May 13 20:19:03.589: INFO: 	Container keepalived-watcher ready: true, restart count 0
May 13 20:19:03.589: INFO: coredns-58d696879-rrkth from kube-system started at 2019-05-13 16:27:35 +0000 UTC (1 container statuses recorded)
May 13 20:19:03.589: INFO: 	Container coredns ready: true, restart count 0
May 13 20:19:03.589: INFO: ibm-file-plugin-7f6d8979bd-p5smn from kube-system started at 2019-05-13 16:27:35 +0000 UTC (1 container statuses recorded)
May 13 20:19:03.589: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
May 13 20:19:03.589: INFO: coredns-58d696879-zmj2g from kube-system started at 2019-05-13 16:27:49 +0000 UTC (1 container statuses recorded)
May 13 20:19:03.589: INFO: 	Container coredns ready: true, restart count 0
May 13 20:19:03.589: INFO: calico-node-d9d6s from kube-system started at 2019-05-13 16:27:05 +0000 UTC (1 container statuses recorded)
May 13 20:19:03.589: INFO: 	Container calico-node ready: true, restart count 0
May 13 20:19:03.589: INFO: ibm-kube-fluentd-6fw9c from kube-system started at 2019-05-13 16:32:50 +0000 UTC (1 container statuses recorded)
May 13 20:19:03.589: INFO: 	Container fluentd ready: true, restart count 0
May 13 20:19:03.589: INFO: kubernetes-dashboard-7996b848f4-mzbwj from kube-system started at 2019-05-13 16:27:35 +0000 UTC (1 container statuses recorded)
May 13 20:19:03.589: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
May 13 20:19:03.589: INFO: coredns-autoscaler-64f9c5b4df-hzq57 from kube-system started at 2019-05-13 16:27:35 +0000 UTC (1 container statuses recorded)
May 13 20:19:03.589: INFO: 	Container autoscaler ready: true, restart count 0
May 13 20:19:03.589: INFO: sonobuoy-systemd-logs-daemon-set-8e5ce9bdf4a94ece-nlv42 from heptio-sonobuoy started at 2019-05-13 18:40:58 +0000 UTC (2 container statuses recorded)
May 13 20:19:03.589: INFO: 	Container sonobuoy-worker ready: true, restart count 1
May 13 20:19:03.589: INFO: 	Container systemd-logs ready: true, restart count 1
May 13 20:19:03.589: INFO: ibm-storage-watcher-845946d5b5-knxcm from kube-system started at 2019-05-13 16:27:35 +0000 UTC (1 container statuses recorded)
May 13 20:19:03.589: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
May 13 20:19:03.589: INFO: 
Logging pods the kubelet thinks is on node 10.170.219.153 before test
May 13 20:19:03.610: INFO: metrics-server-58dd96c6bd-sggps from kube-system started at 2019-05-13 16:28:04 +0000 UTC (2 container statuses recorded)
May 13 20:19:03.610: INFO: 	Container metrics-server ready: true, restart count 0
May 13 20:19:03.610: INFO: 	Container metrics-server-nanny ready: true, restart count 0
May 13 20:19:03.610: INFO: test-k8s-e2e-pvg-master-verification from default started at 2019-05-13 18:40:52 +0000 UTC (1 container statuses recorded)
May 13 20:19:03.610: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
May 13 20:19:03.610: INFO: sonobuoy-systemd-logs-daemon-set-8e5ce9bdf4a94ece-tgp2l from heptio-sonobuoy started at 2019-05-13 18:40:58 +0000 UTC (2 container statuses recorded)
May 13 20:19:03.610: INFO: 	Container sonobuoy-worker ready: true, restart count 1
May 13 20:19:03.610: INFO: 	Container systemd-logs ready: true, restart count 1
May 13 20:19:03.610: INFO: ibm-master-proxy-static-10.170.219.153 from kube-system started at <nil> (0 container statuses recorded)
May 13 20:19:03.610: INFO: ibm-keepalived-watcher-cwtfg from kube-system started at 2019-05-13 16:27:29 +0000 UTC (1 container statuses recorded)
May 13 20:19:03.610: INFO: 	Container keepalived-watcher ready: true, restart count 0
May 13 20:19:03.610: INFO: calico-node-phw8q from kube-system started at 2019-05-13 16:27:29 +0000 UTC (1 container statuses recorded)
May 13 20:19:03.610: INFO: 	Container calico-node ready: true, restart count 0
May 13 20:19:03.610: INFO: ibm-cloud-provider-ip-169-45-218-130-66c489dcb-z58z4 from ibm-system started at 2019-05-13 16:30:08 +0000 UTC (1 container statuses recorded)
May 13 20:19:03.610: INFO: 	Container ibm-cloud-provider-ip-169-45-218-130 ready: true, restart count 0
May 13 20:19:03.610: INFO: ibm-kube-fluentd-cdmr5 from kube-system started at 2019-05-13 16:32:50 +0000 UTC (1 container statuses recorded)
May 13 20:19:03.610: INFO: 	Container fluentd ready: true, restart count 0
May 13 20:19:03.610: INFO: sonobuoy from heptio-sonobuoy started at 2019-05-13 18:40:57 +0000 UTC (1 container statuses recorded)
May 13 20:19:03.610: INFO: 	Container kube-sonobuoy ready: true, restart count 0
May 13 20:19:03.610: INFO: 
Logging pods the kubelet thinks is on node 10.170.219.177 before test
May 13 20:19:03.628: INFO: sonobuoy-systemd-logs-daemon-set-8e5ce9bdf4a94ece-kjc69 from heptio-sonobuoy started at 2019-05-13 18:40:58 +0000 UTC (2 container statuses recorded)
May 13 20:19:03.629: INFO: 	Container sonobuoy-worker ready: true, restart count 1
May 13 20:19:03.629: INFO: 	Container systemd-logs ready: true, restart count 1
May 13 20:19:03.629: INFO: ibm-master-proxy-static-10.170.219.177 from kube-system started at <nil> (0 container statuses recorded)
May 13 20:19:03.629: INFO: ibm-keepalived-watcher-qszvz from kube-system started at 2019-05-13 16:27:34 +0000 UTC (1 container statuses recorded)
May 13 20:19:03.629: INFO: 	Container keepalived-watcher ready: true, restart count 0
May 13 20:19:03.629: INFO: calico-node-twx7l from kube-system started at 2019-05-13 16:27:34 +0000 UTC (1 container statuses recorded)
May 13 20:19:03.629: INFO: 	Container calico-node ready: true, restart count 0
May 13 20:19:03.629: INFO: ibm-cloud-provider-ip-169-45-218-130-66c489dcb-kd74s from ibm-system started at 2019-05-13 16:30:08 +0000 UTC (1 container statuses recorded)
May 13 20:19:03.629: INFO: 	Container ibm-cloud-provider-ip-169-45-218-130 ready: true, restart count 0
May 13 20:19:03.629: INFO: public-cr0ef1a5f1e33c44fe9c21650356d908ee-alb1-8f59cf484-7r5vq from kube-system started at 2019-05-13 16:35:03 +0000 UTC (4 container statuses recorded)
May 13 20:19:03.629: INFO: 	Container ingress-auth-1 ready: true, restart count 0
May 13 20:19:03.629: INFO: 	Container ingress-auth-2 ready: true, restart count 0
May 13 20:19:03.629: INFO: 	Container ingress-auth-3 ready: true, restart count 0
May 13 20:19:03.629: INFO: 	Container nginx-ingress ready: true, restart count 0
May 13 20:19:03.629: INFO: ibm-kube-fluentd-zzl5d from kube-system started at 2019-05-13 16:32:50 +0000 UTC (1 container statuses recorded)
May 13 20:19:03.629: INFO: 	Container fluentd ready: true, restart count 0
May 13 20:19:03.629: INFO: sonobuoy-e2e-job-afa7e83446444f4e from heptio-sonobuoy started at 2019-05-13 18:40:58 +0000 UTC (2 container statuses recorded)
May 13 20:19:03.629: INFO: 	Container e2e ready: true, restart count 0
May 13 20:19:03.629: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node 10.170.219.151
STEP: verifying the node has the label node 10.170.219.153
STEP: verifying the node has the label node 10.170.219.177
May 13 20:19:03.706: INFO: Pod test-k8s-e2e-pvg-master-verification requesting resource cpu=0m on Node 10.170.219.153
May 13 20:19:03.706: INFO: Pod sonobuoy requesting resource cpu=0m on Node 10.170.219.153
May 13 20:19:03.706: INFO: Pod sonobuoy-e2e-job-afa7e83446444f4e requesting resource cpu=0m on Node 10.170.219.177
May 13 20:19:03.706: INFO: Pod sonobuoy-systemd-logs-daemon-set-8e5ce9bdf4a94ece-kjc69 requesting resource cpu=0m on Node 10.170.219.177
May 13 20:19:03.706: INFO: Pod sonobuoy-systemd-logs-daemon-set-8e5ce9bdf4a94ece-nlv42 requesting resource cpu=0m on Node 10.170.219.151
May 13 20:19:03.706: INFO: Pod sonobuoy-systemd-logs-daemon-set-8e5ce9bdf4a94ece-tgp2l requesting resource cpu=0m on Node 10.170.219.153
May 13 20:19:03.706: INFO: Pod ibm-cloud-provider-ip-169-45-218-130-66c489dcb-kd74s requesting resource cpu=5m on Node 10.170.219.177
May 13 20:19:03.706: INFO: Pod ibm-cloud-provider-ip-169-45-218-130-66c489dcb-z58z4 requesting resource cpu=5m on Node 10.170.219.153
May 13 20:19:03.706: INFO: Pod calico-kube-controllers-7dd978d898-r8w74 requesting resource cpu=10m on Node 10.170.219.151
May 13 20:19:03.706: INFO: Pod calico-node-d9d6s requesting resource cpu=250m on Node 10.170.219.151
May 13 20:19:03.706: INFO: Pod calico-node-phw8q requesting resource cpu=250m on Node 10.170.219.153
May 13 20:19:03.706: INFO: Pod calico-node-twx7l requesting resource cpu=250m on Node 10.170.219.177
May 13 20:19:03.706: INFO: Pod coredns-58d696879-rrkth requesting resource cpu=100m on Node 10.170.219.151
May 13 20:19:03.706: INFO: Pod coredns-58d696879-zmj2g requesting resource cpu=100m on Node 10.170.219.151
May 13 20:19:03.706: INFO: Pod coredns-autoscaler-64f9c5b4df-hzq57 requesting resource cpu=20m on Node 10.170.219.151
May 13 20:19:03.706: INFO: Pod ibm-file-plugin-7f6d8979bd-p5smn requesting resource cpu=50m on Node 10.170.219.151
May 13 20:19:03.706: INFO: Pod ibm-keepalived-watcher-8wshf requesting resource cpu=5m on Node 10.170.219.151
May 13 20:19:03.706: INFO: Pod ibm-keepalived-watcher-cwtfg requesting resource cpu=5m on Node 10.170.219.153
May 13 20:19:03.706: INFO: Pod ibm-keepalived-watcher-qszvz requesting resource cpu=5m on Node 10.170.219.177
May 13 20:19:03.706: INFO: Pod ibm-kube-fluentd-6fw9c requesting resource cpu=25m on Node 10.170.219.151
May 13 20:19:03.706: INFO: Pod ibm-kube-fluentd-cdmr5 requesting resource cpu=25m on Node 10.170.219.153
May 13 20:19:03.707: INFO: Pod ibm-kube-fluentd-zzl5d requesting resource cpu=25m on Node 10.170.219.177
May 13 20:19:03.707: INFO: Pod ibm-master-proxy-static-10.170.219.151 requesting resource cpu=25m on Node 10.170.219.151
May 13 20:19:03.707: INFO: Pod ibm-master-proxy-static-10.170.219.153 requesting resource cpu=25m on Node 10.170.219.153
May 13 20:19:03.707: INFO: Pod ibm-master-proxy-static-10.170.219.177 requesting resource cpu=25m on Node 10.170.219.177
May 13 20:19:03.707: INFO: Pod ibm-storage-watcher-845946d5b5-knxcm requesting resource cpu=50m on Node 10.170.219.151
May 13 20:19:03.707: INFO: Pod kubernetes-dashboard-7996b848f4-mzbwj requesting resource cpu=50m on Node 10.170.219.151
May 13 20:19:03.707: INFO: Pod metrics-server-58dd96c6bd-sggps requesting resource cpu=53m on Node 10.170.219.153
May 13 20:19:03.707: INFO: Pod public-cr0ef1a5f1e33c44fe9c21650356d908ee-alb1-8f59cf484-7r5vq requesting resource cpu=0m on Node 10.170.219.177
May 13 20:19:03.707: INFO: Pod public-cr0ef1a5f1e33c44fe9c21650356d908ee-alb1-8f59cf484-9v5pm requesting resource cpu=0m on Node 10.170.219.151
May 13 20:19:03.707: INFO: Pod vpn-774cf5c6d4-6p6cr requesting resource cpu=5m on Node 10.170.219.151
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5a14051f-75bc-11e9-8f67-2632f168be36.159e578392ca77bb], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-5t98x/filler-pod-5a14051f-75bc-11e9-8f67-2632f168be36 to 10.170.219.153]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5a14051f-75bc-11e9-8f67-2632f168be36.159e5783ced9aafa], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5a14051f-75bc-11e9-8f67-2632f168be36.159e5783d1803979], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5a14051f-75bc-11e9-8f67-2632f168be36.159e5783d9b6c056], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5a16ac72-75bc-11e9-8f67-2632f168be36.159e578393433592], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-5t98x/filler-pod-5a16ac72-75bc-11e9-8f67-2632f168be36 to 10.170.219.177]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5a16ac72-75bc-11e9-8f67-2632f168be36.159e5783cdadfbd7], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5a16ac72-75bc-11e9-8f67-2632f168be36.159e5783d0fd8abf], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5a16ac72-75bc-11e9-8f67-2632f168be36.159e5783d9ae8f43], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5a17ffab-75bc-11e9-8f67-2632f168be36.159e578393cd4319], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-5t98x/filler-pod-5a17ffab-75bc-11e9-8f67-2632f168be36 to 10.170.219.151]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5a17ffab-75bc-11e9-8f67-2632f168be36.159e5783cda0aca4], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5a17ffab-75bc-11e9-8f67-2632f168be36.159e5783d0fc9b99], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5a17ffab-75bc-11e9-8f67-2632f168be36.159e5783d9a373f2], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.159e578485602a3d], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node 10.170.219.151
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.170.219.153
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.170.219.177
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:154
May 13 20:19:09.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-5t98x" for this suite.
May 13 20:19:15.302: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 13 20:19:15.542: INFO: namespace: e2e-tests-sched-pred-5t98x, resource: bindings, ignored listing per whitelist
May 13 20:19:15.575: INFO: namespace e2e-tests-sched-pred-5t98x deletion completed in 6.303793619s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:12.309 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.13.0-rc.2.1+ddf47ac13c1a94/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSMay 13 20:19:15.575: INFO: Running AfterSuite actions on all nodes
May 13 20:19:15.576: INFO: Running AfterSuite actions on node 1
May 13 20:19:15.576: INFO: Skipping dumping logs from cluster

Ran 200 of 1946 Specs in 5884.208 seconds
SUCCESS! -- 200 Passed | 0 Failed | 0 Pending | 1746 Skipped PASS

Ginkgo ran 1 suite in 1h38m4.94310774s
Test Suite Passed
