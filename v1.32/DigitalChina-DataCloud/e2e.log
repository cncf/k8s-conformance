  I0115 01:17:24.769635      24 e2e.go:109] Starting e2e run "e51f20a0-d7bf-4a6e-8c2b-350d70a722da" on Ginkgo node 1
Running Suite: Kubernetes e2e suite - /usr/local/bin
====================================================
Random Seed: 1736903840 - will randomize all specs

Will run 411 of 6622 specs
------------------------------
[ReportBeforeSuite] 
k8s.io/kubernetes/test/e2e/e2e_test.go:154
[ReportBeforeSuite] PASSED [0.000 seconds]
------------------------------
[SynchronizedBeforeSuite] 
k8s.io/kubernetes/test/e2e/e2e.go:69
  I0115 01:17:25.451660 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  I0115 01:17:25.469172 24 helper.go:51] Waiting up to 30m0s for all (but 0) nodes to be schedulable
  I0115 01:17:25.668937 24 e2e.go:142] Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
  I0115 01:17:25.695035 24 e2e.go:153] 2 / 2 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
  I0115 01:17:25.695686 24 e2e.go:153] 2 / 2 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
  I0115 01:17:25.695969 24 e2e.go:245] e2e test version: v1.32.0
  I0115 01:17:25.703578 24 e2e.go:254] kube-apiserver version: v1.32.0
  I0115 01:17:25.704103 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  I0115 01:17:25.728863 24 e2e.go:383] Cluster IP family: ipv4
[SynchronizedBeforeSuite] PASSED [0.279 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:489
  STEP: Creating a kubernetes client @ 01/15/25 01:17:26.36
  I0115 01:17:26.360221 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename security-context-test @ 01/15/25 01:17:26.367
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:17:26.417
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:17:26.433
  I0115 01:17:32.614877 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-2438" for this suite. @ 01/15/25 01:17:32.649
• [6.326 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:46
  STEP: Creating a kubernetes client @ 01/15/25 01:17:32.684
  I0115 01:17:32.684190 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename downward-api @ 01/15/25 01:17:32.686
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:17:32.72
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:17:32.728
  STEP: Creating a pod to test downward api env vars @ 01/15/25 01:17:32.738
  STEP: Saw pod success @ 01/15/25 01:17:38.794
  I0115 01:17:38.797940 24 output.go:207] Trying to get logs from node 192.168.18.92 pod downward-api-9b826e27-d19f-4f8b-9520-e8aca5ce38c7 container dapi-container: <nil>
  STEP: delete the pod @ 01/15/25 01:17:38.834
  I0115 01:17:38.858279 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-6883" for this suite. @ 01/15/25 01:17:38.866
• [6.191 seconds]
------------------------------
SSS
------------------------------
[sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:97
  STEP: Creating a kubernetes client @ 01/15/25 01:17:38.875
  I0115 01:17:38.875448 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename secrets @ 01/15/25 01:17:38.876
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:17:38.902
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:17:38.909
  STEP: creating secret secrets-415/secret-test-e7b39e78-0653-43c8-a2a2-1ef3362aa2b8 @ 01/15/25 01:17:38.916
  STEP: Creating a pod to test consume secrets @ 01/15/25 01:17:38.923
  STEP: Saw pod success @ 01/15/25 01:17:42.964
  I0115 01:17:42.971364 24 output.go:207] Trying to get logs from node 192.168.18.92 pod pod-configmaps-c5aba625-c6af-4258-bc79-4491d807ee4f container env-test: <nil>
  STEP: delete the pod @ 01/15/25 01:17:42.988
  I0115 01:17:43.021662 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-415" for this suite. @ 01/15/25 01:17:43.032
• [4.171 seconds]
------------------------------
[sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:195
  STEP: Creating a kubernetes client @ 01/15/25 01:17:43.047
  I0115 01:17:43.047210 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename downward-api @ 01/15/25 01:17:43.049
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:17:43.074
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:17:43.083
  STEP: Creating a pod to test downward API volume plugin @ 01/15/25 01:17:43.091
  STEP: Saw pod success @ 01/15/25 01:17:49.159
  I0115 01:17:49.170182 24 output.go:207] Trying to get logs from node 192.168.18.92 pod downwardapi-volume-8049145b-b174-4027-95f7-94bd2c969139 container client-container: <nil>
  STEP: delete the pod @ 01/15/25 01:17:49.198
  I0115 01:17:49.263996 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-6553" for this suite. @ 01/15/25 01:17:49.277
• [6.255 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/events.go:98
  STEP: Creating a kubernetes client @ 01/15/25 01:17:49.305
  I0115 01:17:49.305181 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename events @ 01/15/25 01:17:49.307
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:17:49.378
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:17:49.401
  STEP: creating a test event @ 01/15/25 01:17:49.418
  STEP: listing events in all namespaces @ 01/15/25 01:17:49.434
  STEP: listing events in test namespace @ 01/15/25 01:17:49.45
  STEP: listing events with field selection filtering on source @ 01/15/25 01:17:49.461
  STEP: listing events with field selection filtering on reportingController @ 01/15/25 01:17:49.475
  STEP: getting the test event @ 01/15/25 01:17:49.486
  STEP: patching the test event @ 01/15/25 01:17:49.498
  STEP: getting the test event @ 01/15/25 01:17:49.52
  STEP: updating the test event @ 01/15/25 01:17:49.532
  STEP: getting the test event @ 01/15/25 01:17:49.56
  STEP: deleting the test event @ 01/15/25 01:17:49.593
  STEP: listing events in all namespaces @ 01/15/25 01:17:49.655
  STEP: listing events in test namespace @ 01/15/25 01:17:49.685
  I0115 01:17:49.728203 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-6302" for this suite. @ 01/15/25 01:17:49.784
• [0.554 seconds]
------------------------------
SSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:332
  STEP: Creating a kubernetes client @ 01/15/25 01:17:49.859
  I0115 01:17:49.859200 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename sched-pred @ 01/15/25 01:17:49.861
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:17:49.924
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:17:49.946
  I0115 01:17:49.960050 24 helper.go:125] Waiting up to 1m0s for all (but 0) nodes to be ready
  I0115 01:17:49.987201 24 util.go:396] Waiting for terminating namespaces to be deleted...
  I0115 01:17:49.997626 24 predicates.go:119] 
  Logging pods the apiserver thinks is on node 192.168.18.91 before test
  I0115 01:17:50.026005 24 predicates.go:957] calico-kube-controllers-7498b9bb4c-crlbm from kube-system started at 2025-01-14 15:20:19 +0000 UTC (1 container statuses recorded)
  I0115 01:17:50.026166 24 predicates.go:959] 	Container calico-kube-controllers ready: true, restart count 0
  I0115 01:17:50.026283 24 predicates.go:957] calico-node-zs5fv from kube-system started at 2025-01-14 13:30:35 +0000 UTC (1 container statuses recorded)
  I0115 01:17:50.026329 24 predicates.go:959] 	Container calico-node ready: true, restart count 0
  I0115 01:17:50.026366 24 predicates.go:957] coredns-668d6bf9bc-2fn8q from kube-system started at 2025-01-14 15:16:36 +0000 UTC (1 container statuses recorded)
  I0115 01:17:50.026389 24 predicates.go:959] 	Container coredns ready: true, restart count 0
  I0115 01:17:50.026432 24 predicates.go:957] coredns-668d6bf9bc-mpkf9 from kube-system started at 2025-01-14 15:16:35 +0000 UTC (1 container statuses recorded)
  I0115 01:17:50.026464 24 predicates.go:959] 	Container coredns ready: true, restart count 0
  I0115 01:17:50.026493 24 predicates.go:957] etcd-192.168.18.91 from kube-system started at 2025-01-14 07:47:31 +0000 UTC (1 container statuses recorded)
  I0115 01:17:50.026513 24 predicates.go:959] 	Container etcd ready: true, restart count 2
  I0115 01:17:50.026538 24 predicates.go:957] kube-apiserver-192.168.18.91 from kube-system started at 2025-01-14 07:47:31 +0000 UTC (1 container statuses recorded)
  I0115 01:17:50.026558 24 predicates.go:959] 	Container kube-apiserver ready: true, restart count 2
  I0115 01:17:50.026579 24 predicates.go:957] kube-controller-manager-192.168.18.91 from kube-system started at 2025-01-14 07:47:31 +0000 UTC (1 container statuses recorded)
  I0115 01:17:50.026600 24 predicates.go:959] 	Container kube-controller-manager ready: true, restart count 2
  I0115 01:17:50.026622 24 predicates.go:957] kube-proxy-nlmsc from kube-system started at 2025-01-14 13:23:11 +0000 UTC (1 container statuses recorded)
  I0115 01:17:50.026641 24 predicates.go:959] 	Container kube-proxy ready: true, restart count 0
  I0115 01:17:50.026665 24 predicates.go:957] kube-scheduler-192.168.18.91 from kube-system started at 2025-01-14 07:47:31 +0000 UTC (1 container statuses recorded)
  I0115 01:17:50.026685 24 predicates.go:959] 	Container kube-scheduler ready: true, restart count 2
  I0115 01:17:50.026708 24 predicates.go:957] sonobuoy-systemd-logs-daemon-set-7cfa3cb4906a48cc-vmmwc from sonobuoy started at 2025-01-15 01:17:18 +0000 UTC (2 container statuses recorded)
  I0115 01:17:50.026728 24 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I0115 01:17:50.026746 24 predicates.go:959] 	Container systemd-logs ready: true, restart count 0
  I0115 01:17:50.026768 24 predicates.go:119] 
  Logging pods the apiserver thinks is on node 192.168.18.92 before test
  I0115 01:17:50.177025 24 predicates.go:957] calico-node-9mtz6 from kube-system started at 2025-01-14 13:30:35 +0000 UTC (1 container statuses recorded)
  I0115 01:17:50.177116 24 predicates.go:959] 	Container calico-node ready: true, restart count 0
  I0115 01:17:50.177155 24 predicates.go:957] kube-proxy-tf5gf from kube-system started at 2025-01-14 13:23:11 +0000 UTC (1 container statuses recorded)
  I0115 01:17:50.177177 24 predicates.go:959] 	Container kube-proxy ready: true, restart count 0
  I0115 01:17:50.177200 24 predicates.go:957] sonobuoy from sonobuoy started at 2025-01-15 01:17:16 +0000 UTC (1 container statuses recorded)
  I0115 01:17:50.177220 24 predicates.go:959] 	Container kube-sonobuoy ready: true, restart count 0
  I0115 01:17:50.177245 24 predicates.go:957] sonobuoy-e2e-job-62b29f02b7114b6e from sonobuoy started at 2025-01-15 01:17:17 +0000 UTC (2 container statuses recorded)
  I0115 01:17:50.177273 24 predicates.go:959] 	Container e2e ready: true, restart count 0
  I0115 01:17:50.177295 24 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I0115 01:17:50.177320 24 predicates.go:957] sonobuoy-systemd-logs-daemon-set-7cfa3cb4906a48cc-ljwvq from sonobuoy started at 2025-01-15 01:17:18 +0000 UTC (2 container statuses recorded)
  I0115 01:17:50.177341 24 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I0115 01:17:50.177360 24 predicates.go:959] 	Container systemd-logs ready: true, restart count 0
  STEP: verifying the node has the label node 192.168.18.91 @ 01/15/25 01:17:50.378
  STEP: verifying the node has the label node 192.168.18.92 @ 01/15/25 01:17:50.464
  I0115 01:17:50.538725 24 predicates.go:372] Pod calico-kube-controllers-7498b9bb4c-crlbm requesting resource cpu=0m on Node 192.168.18.91
  I0115 01:17:50.538817 24 predicates.go:372] Pod calico-node-9mtz6 requesting resource cpu=250m on Node 192.168.18.92
  I0115 01:17:50.538844 24 predicates.go:372] Pod calico-node-zs5fv requesting resource cpu=250m on Node 192.168.18.91
  I0115 01:17:50.538930 24 predicates.go:372] Pod coredns-668d6bf9bc-2fn8q requesting resource cpu=100m on Node 192.168.18.91
  I0115 01:17:50.538963 24 predicates.go:372] Pod coredns-668d6bf9bc-mpkf9 requesting resource cpu=100m on Node 192.168.18.91
  I0115 01:17:50.538989 24 predicates.go:372] Pod etcd-192.168.18.91 requesting resource cpu=100m on Node 192.168.18.91
  I0115 01:17:50.539008 24 predicates.go:372] Pod kube-apiserver-192.168.18.91 requesting resource cpu=250m on Node 192.168.18.91
  I0115 01:17:50.539029 24 predicates.go:372] Pod kube-controller-manager-192.168.18.91 requesting resource cpu=200m on Node 192.168.18.91
  I0115 01:17:50.539049 24 predicates.go:372] Pod kube-proxy-nlmsc requesting resource cpu=0m on Node 192.168.18.91
  I0115 01:17:50.539080 24 predicates.go:372] Pod kube-proxy-tf5gf requesting resource cpu=0m on Node 192.168.18.92
  I0115 01:17:50.539100 24 predicates.go:372] Pod kube-scheduler-192.168.18.91 requesting resource cpu=100m on Node 192.168.18.91
  I0115 01:17:50.539123 24 predicates.go:372] Pod sonobuoy requesting resource cpu=0m on Node 192.168.18.92
  I0115 01:17:50.539143 24 predicates.go:372] Pod sonobuoy-e2e-job-62b29f02b7114b6e requesting resource cpu=0m on Node 192.168.18.92
  I0115 01:17:50.539162 24 predicates.go:372] Pod sonobuoy-systemd-logs-daemon-set-7cfa3cb4906a48cc-ljwvq requesting resource cpu=0m on Node 192.168.18.92
  I0115 01:17:50.539180 24 predicates.go:372] Pod sonobuoy-systemd-logs-daemon-set-7cfa3cb4906a48cc-vmmwc requesting resource cpu=0m on Node 192.168.18.91
  STEP: Starting Pods to consume most of the cluster CPU. @ 01/15/25 01:17:50.539
  I0115 01:17:50.539259 24 predicates.go:382] Creating a pod which consumes cpu=2030m on Node 192.168.18.91
  I0115 01:17:50.570722 24 predicates.go:382] Creating a pod which consumes cpu=2625m on Node 192.168.18.92
  STEP: Creating another pod that requires unavailable amount of CPU. @ 01/15/25 01:17:54.712
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-827ab6c8-beb8-49a0-9790-3cd54ee96bee.181ab8de2c661c47], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3103/filler-pod-827ab6c8-beb8-49a0-9790-3cd54ee96bee to 192.168.18.92] @ 01/15/25 01:17:54.718
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-827ab6c8-beb8-49a0-9790-3cd54ee96bee.181ab8de91fc8587], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.10" already present on machine] @ 01/15/25 01:17:54.718
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-827ab6c8-beb8-49a0-9790-3cd54ee96bee.181ab8de93fff843], Reason = [Created], Message = [Created container: filler-pod-827ab6c8-beb8-49a0-9790-3cd54ee96bee] @ 01/15/25 01:17:54.718
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-827ab6c8-beb8-49a0-9790-3cd54ee96bee.181ab8deb48b8225], Reason = [Started], Message = [Started container filler-pod-827ab6c8-beb8-49a0-9790-3cd54ee96bee] @ 01/15/25 01:17:54.718
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-915e5a71-031d-442b-ba72-a9af2268f8a6.181ab8de26a0653d], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3103/filler-pod-915e5a71-031d-442b-ba72-a9af2268f8a6 to 192.168.18.91] @ 01/15/25 01:17:54.718
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-915e5a71-031d-442b-ba72-a9af2268f8a6.181ab8dea37f5d3c], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.10" already present on machine] @ 01/15/25 01:17:54.718
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-915e5a71-031d-442b-ba72-a9af2268f8a6.181ab8deaab2e654], Reason = [Created], Message = [Created container: filler-pod-915e5a71-031d-442b-ba72-a9af2268f8a6] @ 01/15/25 01:17:54.718
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-915e5a71-031d-442b-ba72-a9af2268f8a6.181ab8decee5b15e], Reason = [Started], Message = [Started container filler-pod-915e5a71-031d-442b-ba72-a9af2268f8a6] @ 01/15/25 01:17:54.718
  STEP: Considering event: 
  Type = [Warning], Name = [additional-pod.181ab8df1d4d142f], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu. preemption: 0/2 nodes are available: 2 No preemption victims found for incoming pod.] @ 01/15/25 01:17:54.735
  STEP: removing the label node off the node 192.168.18.91 @ 01/15/25 01:17:55.738
  STEP: verifying the node doesn't have the label node @ 01/15/25 01:17:55.755
  STEP: removing the label node off the node 192.168.18.92 @ 01/15/25 01:17:55.761
  STEP: verifying the node doesn't have the label node @ 01/15/25 01:17:55.777
  I0115 01:17:55.787750 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-3103" for this suite. @ 01/15/25 01:17:55.792
• [5.946 seconds]
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose should create services for rc [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1527
  STEP: Creating a kubernetes client @ 01/15/25 01:17:55.805
  I0115 01:17:55.805403 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename kubectl @ 01/15/25 01:17:55.806
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:17:55.827
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:17:55.836
  STEP: creating Agnhost RC @ 01/15/25 01:17:55.844
  I0115 01:17:55.844332 24 kubectl.go:1534] namespace kubectl-4099
  I0115 01:17:55.844700 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-4099 create -f -'
  I0115 01:17:56.350265 24 builder.go:146] stderr: ""
  I0115 01:17:56.350340 24 builder.go:147] stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 01/15/25 01:17:56.35
  I0115 01:17:57.366648 24 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0115 01:17:57.366756 24 framework.go:733] Found 0 / 1
  I0115 01:17:58.357188 24 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0115 01:17:58.357273 24 framework.go:733] Found 1 / 1
  I0115 01:17:58.357307 24 framework.go:742] WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  I0115 01:17:58.362784 24 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0115 01:17:58.362898 24 framework.go:765] ForEach: Found 1 pods from the filter.  Now looping through them.
  I0115 01:17:58.362916 24 kubectl.go:1541] wait on agnhost-primary startup in kubectl-4099 
  I0115 01:17:58.362976 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-4099 logs agnhost-primary-xtknm agnhost-primary'
  I0115 01:17:58.493622 24 builder.go:146] stderr: ""
  I0115 01:17:58.493744 24 builder.go:147] stdout: "Paused\n"
  STEP: exposing RC @ 01/15/25 01:17:58.493
  I0115 01:17:58.493868 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-4099 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
  I0115 01:17:58.746094 24 builder.go:146] stderr: ""
  I0115 01:17:58.746162 24 builder.go:147] stdout: "service/rm2 exposed\n"
  I0115 01:17:58.763292 24 utils.go:1203] Service rm2 in namespace kubectl-4099 found.
  STEP: exposing service @ 01/15/25 01:18:00.773
  I0115 01:18:00.773771 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-4099 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
  I0115 01:18:00.939245 24 builder.go:146] stderr: ""
  I0115 01:18:00.939306 24 builder.go:147] stdout: "service/rm3 exposed\n"
  I0115 01:18:00.946078 24 utils.go:1203] Service rm3 in namespace kubectl-4099 found.
  I0115 01:18:02.974760 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-4099" for this suite. @ 01/15/25 01:18:02.998
• [7.216 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate everything except 'skip-me' configmaps [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:863
  STEP: Creating a kubernetes client @ 01/15/25 01:18:03.025
  I0115 01:18:03.025737 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename webhook @ 01/15/25 01:18:03.028
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:18:03.051
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:18:03.06
  STEP: Setting up server cert @ 01/15/25 01:18:03.147
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 01/15/25 01:18:04.085
  STEP: Deploying the webhook pod @ 01/15/25 01:18:04.099
  STEP: Wait for the deployment to be ready @ 01/15/25 01:18:04.117
  I0115 01:18:04.127907 24 deployment.go:223] new replicaset for deployment "sample-webhook-deployment" is yet to be created
  STEP: Deploying the webhook service @ 01/15/25 01:18:06.169
  STEP: Verifying the service has paired with the endpoint @ 01/15/25 01:18:06.242
  I0115 01:18:07.244861 24 util.go:423] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: creating a mutating webhook with match conditions @ 01/15/25 01:18:07.269
  STEP: create the configmap with a random name @ 01/15/25 01:18:07.385
  STEP: verify the configmap is mutated @ 01/15/25 01:18:07.405
  STEP: create the configmap with 'skip-me' name @ 01/15/25 01:18:07.405
  I0115 01:18:07.475459 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-4645" for this suite. @ 01/15/25 01:18:07.485
  STEP: Destroying namespace "webhook-markers-7329" for this suite. @ 01/15/25 01:18:07.493
• [4.477 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:270
  STEP: Creating a kubernetes client @ 01/15/25 01:18:07.502
  I0115 01:18:07.502619 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename custom-resource-definition @ 01/15/25 01:18:07.504
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:18:07.528
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:18:07.535
  I0115 01:18:07.542127 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  I0115 01:18:10.705355 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-9702" for this suite. @ 01/15/25 01:18:10.713
• [3.221 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:195
  STEP: Creating a kubernetes client @ 01/15/25 01:18:10.724
  I0115 01:18:10.724407 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename crd-publish-openapi @ 01/15/25 01:18:10.726
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:18:10.749
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:18:10.757
  I0115 01:18:10.765844 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 01/15/25 01:18:12.299
  I0115 01:18:12.299298 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=crd-publish-openapi-3422 --namespace=crd-publish-openapi-3422 create -f -'
  I0115 01:18:12.455445 24 builder.go:146] stderr: ""
  I0115 01:18:12.455536 24 builder.go:147] stdout: "e2e-test-crd-publish-openapi-5920-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  I0115 01:18:12.455607 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=crd-publish-openapi-3422 --namespace=crd-publish-openapi-3422 delete e2e-test-crd-publish-openapi-5920-crds test-cr'
  I0115 01:18:12.666759 24 builder.go:146] stderr: ""
  I0115 01:18:12.666930 24 builder.go:147] stdout: "e2e-test-crd-publish-openapi-5920-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
  I0115 01:18:12.667024 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=crd-publish-openapi-3422 --namespace=crd-publish-openapi-3422 apply -f -'
  I0115 01:18:12.824706 24 builder.go:146] stderr: ""
  I0115 01:18:12.824807 24 builder.go:147] stdout: "e2e-test-crd-publish-openapi-5920-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  I0115 01:18:12.824890 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=crd-publish-openapi-3422 --namespace=crd-publish-openapi-3422 delete e2e-test-crd-publish-openapi-5920-crds test-cr'
  I0115 01:18:12.984072 24 builder.go:146] stderr: ""
  I0115 01:18:12.984148 24 builder.go:147] stdout: "e2e-test-crd-publish-openapi-5920-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR @ 01/15/25 01:18:12.984
  I0115 01:18:12.984483 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=crd-publish-openapi-3422 explain e2e-test-crd-publish-openapi-5920-crds'
  I0115 01:18:13.157559 24 builder.go:146] stderr: ""
  I0115 01:18:13.157652 24 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-unknown-at-root.example.com\nKIND:       e2e-test-crd-publish-openapi-5920-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties at root for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  I0115 01:18:14.883789 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-3422" for this suite. @ 01/15/25 01:18:14.898
• [4.182 seconds]
------------------------------
[sig-cli] Kubectl client Proxy server should support proxy with --port 0 [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1830
  STEP: Creating a kubernetes client @ 01/15/25 01:18:14.906
  I0115 01:18:14.906886 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename kubectl @ 01/15/25 01:18:14.908
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:18:14.926
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:18:14.932
  STEP: starting the proxy server @ 01/15/25 01:18:14.94
  I0115 01:18:14.940277 24 util.go:590] Asynchronously running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-6686 proxy -p 0 --disable-filter'
  STEP: curling proxy /api/ output @ 01/15/25 01:18:15.043
  I0115 01:18:15.062620 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  I0115 01:18:15.066424 24 kubectl.go:2221] kubectl proxy stdout: Starting to serve on 127.0.0.1:41933

  I0115 01:18:15.066507 24 kubectl.go:2226] kubectl proxy stderr: W0115 01:18:15.042296      92 proxy.go:177] Request filter disabled, your proxy is vulnerable to XSRF attacks, please be cautious

  STEP: Destroying namespace "kubectl-6686" for this suite. @ 01/15/25 01:18:15.068
• [0.169 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:130
  STEP: Creating a kubernetes client @ 01/15/25 01:18:15.076
  I0115 01:18:15.076374 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename dns @ 01/15/25 01:18:15.077
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:18:15.095
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:18:15.101
  STEP: Running these commands on agnhost: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-382.svc.cluster.local)" && echo OK > /results/agnhost_hosts@dns-querier-1.dns-test-service.dns-382.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/agnhost_hosts@dns-querier-1;sleep 1; done
   @ 01/15/25 01:18:15.108
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-382.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-382.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
   @ 01/15/25 01:18:15.108
  STEP: creating a pod to probe /etc/hosts @ 01/15/25 01:18:15.108
  STEP: submitting the pod to kubernetes @ 01/15/25 01:18:15.108
  STEP: retrieving the pod @ 01/15/25 01:18:17.153
  STEP: looking for the results for each expected name from probers @ 01/15/25 01:18:17.173
  I0115 01:18:17.221835 24 dns_common.go:546] DNS probes using dns-382/dns-test-50c233ee-5fb8-47c6-b99b-20bafbaf6c1e succeeded

  STEP: deleting the pod @ 01/15/25 01:18:17.222
  I0115 01:18:17.247032 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-382" for this suite. @ 01/15/25 01:18:17.262
• [2.228 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:46
  STEP: Creating a kubernetes client @ 01/15/25 01:18:17.304
  I0115 01:18:17.304700 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename projected @ 01/15/25 01:18:17.306
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:18:17.41
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:18:17.435
  STEP: Creating projection with secret that has name projected-secret-test-6ad3b2ed-b1df-4711-ac42-1ce788036c53 @ 01/15/25 01:18:17.45
  STEP: Creating a pod to test consume secrets @ 01/15/25 01:18:17.46
  STEP: Saw pod success @ 01/15/25 01:18:23.518
  I0115 01:18:23.522351 24 output.go:207] Trying to get logs from node 192.168.18.92 pod pod-projected-secrets-a2fe099b-35df-49ff-82cb-15ad8218d889 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 01/15/25 01:18:23.53
  I0115 01:18:23.555497 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1972" for this suite. @ 01/15/25 01:18:23.561
• [6.263 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should delete a job [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:832
  STEP: Creating a kubernetes client @ 01/15/25 01:18:23.568
  I0115 01:18:23.568497 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename job @ 01/15/25 01:18:23.569
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:18:23.589
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:18:23.594
  STEP: Creating a job @ 01/15/25 01:18:23.602
  STEP: Ensuring active pods == parallelism @ 01/15/25 01:18:23.611
  STEP: delete a job @ 01/15/25 01:18:27.64
  STEP: deleting Job.batch foo in namespace job-3298, will wait for the garbage collector to delete the pods @ 01/15/25 01:18:27.64
  I0115 01:18:27.703697 24 resources.go:139] Deleting Job.batch foo took: 7.650721ms
  I0115 01:18:27.804521 24 resources.go:163] Terminating Job.batch foo pods took: 100.820757ms
  STEP: Ensuring job was deleted @ 01/15/25 01:18:29.105
  I0115 01:18:29.109872 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-3298" for this suite. @ 01/15/25 01:18:29.118
• [5.561 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:190
  STEP: Creating a kubernetes client @ 01/15/25 01:18:29.129
  I0115 01:18:29.129840 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename var-expansion @ 01/15/25 01:18:29.132
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:18:29.15
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:18:29.156
  I0115 01:18:31.205850 24 delete.go:62] Deleting pod "var-expansion-e8d3c562-e310-4522-9716-64d7cc2d5ecb" in namespace "var-expansion-9404"
  I0115 01:18:31.216320 24 delete.go:70] Wait up to 5m0s for pod "var-expansion-e8d3c562-e310-4522-9716-64d7cc2d5ecb" to be fully deleted
  I0115 01:18:35.232690 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-9404" for this suite. @ 01/15/25 01:18:35.237
• [6.113 seconds]
------------------------------
[sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:99
  STEP: Creating a kubernetes client @ 01/15/25 01:18:35.242
  I0115 01:18:35.242948 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename secrets @ 01/15/25 01:18:35.243
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:18:35.257
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:18:35.262
  STEP: Creating secret with name secret-test-8670bac8-73f7-4667-b811-311288ba9ab9 @ 01/15/25 01:18:35.376
  STEP: Creating a pod to test consume secrets @ 01/15/25 01:18:35.382
  STEP: Saw pod success @ 01/15/25 01:18:39.414
  I0115 01:18:39.418355 24 output.go:207] Trying to get logs from node 192.168.18.92 pod pod-secrets-05945104-333d-4288-aa65-e4bf0a91378b container secret-volume-test: <nil>
  STEP: delete the pod @ 01/15/25 01:18:39.424
  I0115 01:18:39.439330 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-5187" for this suite. @ 01/15/25 01:18:39.444
  STEP: Destroying namespace "secret-namespace-3221" for this suite. @ 01/15/25 01:18:39.449
• [4.213 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] PersistentVolumes CSI Conformance should apply changes to a pv/pvc status [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/persistent_volumes.go:668
  STEP: Creating a kubernetes client @ 01/15/25 01:18:39.456
  I0115 01:18:39.456484 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename pv @ 01/15/25 01:18:39.457
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:18:39.475
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:18:39.48
  STEP: Creating initial PV and PVC @ 01/15/25 01:18:39.484
  I0115 01:18:39.484841 24 pv.go:394] Creating a PV followed by a PVC
  STEP: Listing all PVs with the labelSelector: "e2e-pv-pool=pv-6484" @ 01/15/25 01:18:39.497
  STEP: Listing PVCs in namespace "pv-6484" @ 01/15/25 01:18:39.501
  STEP: Reading "pvc-zgmtf" Status @ 01/15/25 01:18:39.505
  STEP: Reading "pv-6484-nkchq" Status @ 01/15/25 01:18:39.509
  STEP: Patching "pvc-zgmtf" Status @ 01/15/25 01:18:39.514
  STEP: Patching "pv-6484-nkchq" Status @ 01/15/25 01:18:39.519
  STEP: Updating "pvc-zgmtf" Status @ 01/15/25 01:18:39.528
  STEP: Updating "pv-6484-nkchq" Status @ 01/15/25 01:18:39.537
  I0115 01:18:39.546945 24 persistent_volumes.go:406] AfterEach: deleting 1 PVCs and 1 PVs...
  I0115 01:18:39.547036 24 pv.go:205] Deleting PersistentVolumeClaim "pvc-zgmtf"
  I0115 01:18:39.553846 24 pv.go:193] Deleting PersistentVolume "pv-6484-nkchq"
  I0115 01:18:39.559873 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pv-6484" for this suite. @ 01/15/25 01:18:39.566
• [0.116 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Services should provide secure master service [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:750
  STEP: Creating a kubernetes client @ 01/15/25 01:18:39.572
  I0115 01:18:39.572273 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename services @ 01/15/25 01:18:39.573
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:18:39.591
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:18:39.596
  I0115 01:18:39.606028 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-794" for this suite. @ 01/15/25 01:18:39.665
• [0.099 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should delete a collection of pods [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:846
  STEP: Creating a kubernetes client @ 01/15/25 01:18:39.671
  I0115 01:18:39.671778 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename pods @ 01/15/25 01:18:39.673
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:18:39.686
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:18:39.69
  STEP: Create set of pods @ 01/15/25 01:18:39.696
  I0115 01:18:39.706664 24 pods.go:871] created test-pod-1
  I0115 01:18:39.714660 24 pods.go:871] created test-pod-2
  I0115 01:18:39.724390 24 pods.go:871] created test-pod-3
  STEP: waiting for all 3 pods to be running @ 01/15/25 01:18:39.724
  STEP: waiting for all pods to be deleted @ 01/15/25 01:18:43.83
  I0115 01:18:43.837834 24 pods.go:1140] Pod quantity 3 is different from expected quantity 0
  I0115 01:18:44.839111 24 pods.go:1140] Pod quantity 2 is different from expected quantity 0
  I0115 01:18:45.836961 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-2363" for this suite. @ 01/15/25 01:18:45.842
• [6.180 seconds]
------------------------------
SSS
------------------------------
[sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:199
  STEP: Creating a kubernetes client @ 01/15/25 01:18:45.854
  I0115 01:18:45.854453 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename container-probe @ 01/15/25 01:18:45.856
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:18:45.878
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:18:45.885
  STEP: Creating pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662 @ 01/15/25 01:18:45.893
  STEP: checking the pod's current state and verifying that restartCount is present @ 01/15/25 01:18:47.916
  I0115 01:18:47.919742 24 container_probe.go:1749] Initial restart count of pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 is 0
  I0115 01:18:47.926283 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:18:49.933193 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:18:51.937951 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:18:53.942683 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:18:55.960557 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:18:57.968267 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:18:59.978970 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:19:01.983474 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:19:03.989364 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:19:05.994550 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:19:08.009877 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:19:08.010071 24 container_probe.go:1763] Restart count of pod container-probe-6662/liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 is now 1 (20.090248298s elapsed)
  I0115 01:19:10.024297 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:19:12.034708 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:19:14.052759 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:19:16.060616 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:19:18.065186 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:19:20.081828 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:19:22.087421 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:19:24.093728 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:19:26.098032 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:19:28.102847 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:19:28.102907 24 container_probe.go:1763] Restart count of pod container-probe-6662/liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 is now 2 (40.183096579s elapsed)
  I0115 01:19:30.108477 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:19:32.112799 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:19:34.116711 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:19:36.121606 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:19:38.135576 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:19:40.155464 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:19:42.160155 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:19:44.164643 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:19:46.171577 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:19:48.176444 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:19:48.176511 24 container_probe.go:1763] Restart count of pod container-probe-6662/liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 is now 3 (1m0.256700243s elapsed)
  I0115 01:19:50.201770 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:19:52.211406 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:19:54.218002 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:19:56.222280 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:19:58.237793 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:20:00.244121 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:20:02.249611 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:20:04.253444 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:20:06.262113 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:20:08.267241 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:20:08.267370 24 container_probe.go:1763] Restart count of pod container-probe-6662/liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 is now 4 (1m20.347558567s elapsed)
  I0115 01:20:10.281506 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:20:12.294655 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:20:14.300576 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:20:16.308167 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:20:18.319964 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:20:20.324660 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:20:22.333214 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:20:24.347122 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:20:26.354955 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:20:28.369479 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:20:30.373498 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:20:32.387723 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:20:34.400625 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:20:36.405577 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:20:38.418054 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:20:40.421918 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:20:42.435424 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:20:44.442656 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:20:46.455343 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:20:48.472049 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:20:50.476943 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:20:52.493349 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:20:54.509833 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:20:56.514760 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:20:58.531517 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:21:00.544755 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:21:02.559779 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:21:04.576817 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:21:06.590847 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:21:08.609271 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:21:10.618701 24 container_probe.go:1759] Get pod liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 in namespace container-probe-6662
  I0115 01:21:10.618863 24 container_probe.go:1763] Restart count of pod container-probe-6662/liveness-eeea9425-8741-4551-bf4b-754badf6c6a6 is now 5 (2m22.699043834s elapsed)
  STEP: deleting the pod @ 01/15/25 01:21:10.619
  I0115 01:21:10.648528 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-6662" for this suite. @ 01/15/25 01:21:10.664
• [144.821 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:612
  STEP: Creating a kubernetes client @ 01/15/25 01:21:10.675
  I0115 01:21:10.675417 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename security-context-test @ 01/15/25 01:21:10.677
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:21:10.699
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:21:10.707
  I0115 01:21:14.808823 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-2523" for this suite. @ 01/15/25 01:21:14.823
• [4.179 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:178
  STEP: Creating a kubernetes client @ 01/15/25 01:21:14.856
  I0115 01:21:14.856377 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename init-container @ 01/15/25 01:21:14.861
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:21:14.893
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:21:14.899
  STEP: creating the pod @ 01/15/25 01:21:14.904
  I0115 01:21:14.904476 24 init_container.go:213] PodSpec: initContainers in spec.initContainers
  I0115 01:21:19.313575 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-7199" for this suite. @ 01/15/25 01:21:19.319
• [4.470 seconds]
------------------------------
SSSSS
------------------------------
[sig-auth] SubjectReview should support SubjectReview API operations [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/subjectreviews.go:50
  STEP: Creating a kubernetes client @ 01/15/25 01:21:19.326
  I0115 01:21:19.326224 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename subjectreview @ 01/15/25 01:21:19.327
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:21:19.34
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:21:19.346
  STEP: Creating a Serviceaccount "e2e" in namespace "subjectreview-2859" @ 01/15/25 01:21:19.351
  I0115 01:21:19.355901 24 subjectreviews.go:66] saUsername: "system:serviceaccount:subjectreview-2859:e2e"
  I0115 01:21:19.356055 24 subjectreviews.go:69] saGroups: []string{"system:authenticated", "system:serviceaccounts", "system:serviceaccounts:subjectreview-2859"}
  I0115 01:21:19.356077 24 subjectreviews.go:71] saUID: "5d84e133-8532-42ce-b8d3-05ea8cc0cb3c"
  STEP: Creating clientset to impersonate "system:serviceaccount:subjectreview-2859:e2e" @ 01/15/25 01:21:19.356
  STEP: Creating SubjectAccessReview for "system:serviceaccount:subjectreview-2859:e2e" @ 01/15/25 01:21:19.356
  I0115 01:21:19.360477 24 subjectreviews.go:102] sarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  STEP: Verifying as "system:serviceaccount:subjectreview-2859:e2e" api 'list' configmaps in "subjectreview-2859" namespace @ 01/15/25 01:21:19.36
  I0115 01:21:19.363120 24 subjectreviews.go:121] SubjectAccessReview has been verified
  STEP: Creating a LocalSubjectAccessReview for "system:serviceaccount:subjectreview-2859:e2e" @ 01/15/25 01:21:19.363
  I0115 01:21:19.366131 24 subjectreviews.go:144] lsarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  I0115 01:21:19.366211 24 subjectreviews.go:150] LocalSubjectAccessReview has been verified
  I0115 01:21:19.366354 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subjectreview-2859" for this suite. @ 01/15/25 01:21:19.42
• [0.100 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:199
  STEP: Creating a kubernetes client @ 01/15/25 01:21:19.426
  I0115 01:21:19.426301 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename custom-resource-definition @ 01/15/25 01:21:19.427
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:21:19.442
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:21:19.446
  STEP: fetching the /apis discovery document @ 01/15/25 01:21:19.45
  STEP: finding the apiextensions.k8s.io API group in the /apis discovery document @ 01/15/25 01:21:19.452
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document @ 01/15/25 01:21:19.452
  STEP: fetching the /apis/apiextensions.k8s.io discovery document @ 01/15/25 01:21:19.452
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document @ 01/15/25 01:21:19.454
  STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document @ 01/15/25 01:21:19.454
  STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document @ 01/15/25 01:21:19.457
  I0115 01:21:19.457319 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-6524" for this suite. @ 01/15/25 01:21:19.519
• [0.099 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet Replace and Patch tests [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:155
  STEP: Creating a kubernetes client @ 01/15/25 01:21:19.526
  I0115 01:21:19.526374 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename replicaset @ 01/15/25 01:21:19.527
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:21:19.541
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:21:19.548
  I0115 01:21:19.564974 24 resource.go:87] Pod name sample-pod: Found 0 pods out of 1
  I0115 01:21:24.573106 24 resource.go:87] Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 01/15/25 01:21:24.573
  STEP: Scaling up "test-rs" replicaset @ 01/15/25 01:21:24.573
  I0115 01:21:24.581730 24 replicaset.go:44] Updating replica set "test-rs"
  STEP: patching the ReplicaSet @ 01/15/25 01:21:24.581
  I0115 01:21:24.588750 24 replica_set.go:542] observed ReplicaSet test-rs in namespace replicaset-1466 with ReadyReplicas 1, AvailableReplicas 1
  I0115 01:21:24.604856 24 replica_set.go:542] observed ReplicaSet test-rs in namespace replicaset-1466 with ReadyReplicas 1, AvailableReplicas 1
  I0115 01:21:24.627153 24 replica_set.go:542] observed ReplicaSet test-rs in namespace replicaset-1466 with ReadyReplicas 1, AvailableReplicas 1
  I0115 01:21:24.643879 24 replica_set.go:542] observed ReplicaSet test-rs in namespace replicaset-1466 with ReadyReplicas 1, AvailableReplicas 1
  I0115 01:21:25.928265 24 replica_set.go:542] observed ReplicaSet test-rs in namespace replicaset-1466 with ReadyReplicas 2, AvailableReplicas 2
  I0115 01:21:26.166679 24 replica_set.go:545] observed Replicaset test-rs in namespace replicaset-1466 with ReadyReplicas 3 found true
  I0115 01:21:26.167010 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-1466" for this suite. @ 01/15/25 01:21:26.174
• [6.656 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery should locate the groupVersion and a resource within each APIGroup [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/discovery.go:172
  STEP: Creating a kubernetes client @ 01/15/25 01:21:26.182
  I0115 01:21:26.182731 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename discovery @ 01/15/25 01:21:26.184
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:21:26.2
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:21:26.205
  STEP: Setting up server cert @ 01/15/25 01:21:26.216
  STEP: Requesting APIResourceList from "/api/v1" @ 01/15/25 01:21:26.64
  STEP: Requesting APIResourceList from "/apis/admissionregistration.k8s.io/v1" @ 01/15/25 01:21:26.642
  STEP: Requesting APIResourceList from "/apis/apiextensions.k8s.io/v1" @ 01/15/25 01:21:26.644
  STEP: Requesting APIResourceList from "/apis/apiregistration.k8s.io/v1" @ 01/15/25 01:21:26.645
  STEP: Requesting APIResourceList from "/apis/apps/v1" @ 01/15/25 01:21:26.647
  STEP: Requesting APIResourceList from "/apis/authentication.k8s.io/v1" @ 01/15/25 01:21:26.65
  STEP: Requesting APIResourceList from "/apis/authorization.k8s.io/v1" @ 01/15/25 01:21:26.652
  STEP: Requesting APIResourceList from "/apis/autoscaling/v1" @ 01/15/25 01:21:26.654
  STEP: Requesting APIResourceList from "/apis/autoscaling/v2" @ 01/15/25 01:21:26.655
  STEP: Requesting APIResourceList from "/apis/batch/v1" @ 01/15/25 01:21:26.657
  STEP: Requesting APIResourceList from "/apis/certificates.k8s.io/v1" @ 01/15/25 01:21:26.658
  STEP: Requesting APIResourceList from "/apis/coordination.k8s.io/v1" @ 01/15/25 01:21:26.66
  STEP: Requesting APIResourceList from "/apis/discovery.k8s.io/v1" @ 01/15/25 01:21:26.662
  STEP: Requesting APIResourceList from "/apis/events.k8s.io/v1" @ 01/15/25 01:21:26.664
  STEP: Requesting APIResourceList from "/apis/networking.k8s.io/v1" @ 01/15/25 01:21:26.666
  STEP: Requesting APIResourceList from "/apis/node.k8s.io/v1" @ 01/15/25 01:21:26.669
  STEP: Requesting APIResourceList from "/apis/policy/v1" @ 01/15/25 01:21:26.67
  STEP: Requesting APIResourceList from "/apis/scheduling.k8s.io/v1" @ 01/15/25 01:21:26.672
  STEP: Requesting APIResourceList from "/apis/storage.k8s.io/v1" @ 01/15/25 01:21:26.673
  I0115 01:21:26.675305 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "discovery-9588" for this suite. @ 01/15/25 01:21:26.68
• [0.503 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:152
  STEP: Creating a kubernetes client @ 01/15/25 01:21:26.686
  I0115 01:21:26.686537 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename container-probe @ 01/15/25 01:21:26.687
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:21:26.7
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:21:26.704
  STEP: Creating pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488 @ 01/15/25 01:21:26.708
  STEP: checking the pod's current state and verifying that restartCount is present @ 01/15/25 01:21:28.725
  I0115 01:21:28.728870 24 container_probe.go:1749] Initial restart count of pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 is 0
  I0115 01:21:28.732743 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:21:30.739691 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:21:32.763146 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:21:34.779867 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:21:36.785333 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:21:38.790687 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:21:40.803775 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:21:42.821121 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:21:44.826282 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:21:46.833866 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:21:48.841130 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:21:50.846603 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:21:52.854348 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:21:54.869614 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:21:56.874847 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:21:58.879828 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:22:00.892347 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:22:02.907921 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:22:04.925886 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:22:06.940330 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:22:08.948446 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:22:10.961520 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:22:12.976767 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:22:14.980622 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:22:16.986231 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:22:18.990971 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:22:20.997573 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:22:23.005560 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:22:25.018366 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:22:27.036630 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:22:29.049413 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:22:31.060813 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:22:33.075249 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:22:35.080253 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:22:37.086455 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:22:39.097394 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:22:41.102316 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:22:43.112313 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:22:45.128745 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:22:47.143839 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:22:49.149871 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:22:51.155043 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:22:53.160516 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:22:55.164939 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:22:57.183514 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:22:59.187672 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:23:01.194743 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:23:03.200845 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:23:05.204576 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:23:07.211681 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:23:09.221741 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:23:11.237968 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:23:13.250202 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:23:15.266130 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:23:17.280940 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:23:19.285302 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:23:21.291990 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:23:23.301870 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:23:25.312923 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:23:27.327971 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:23:29.336321 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:23:31.343269 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:23:33.367688 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:23:35.384416 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:23:37.398195 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:23:39.412034 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:23:41.426117 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:23:43.443698 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:23:45.455430 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:23:47.462215 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:23:49.467783 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:23:51.479392 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:23:53.485548 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:23:55.492956 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:23:57.499849 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:23:59.504086 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:24:01.520615 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:24:03.526302 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:24:05.538170 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:24:07.545122 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:24:09.556498 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:24:11.562076 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:24:13.567539 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:24:15.582295 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:24:17.593842 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:24:19.608745 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:24:21.627357 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:24:23.640292 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:24:25.646638 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:24:27.652616 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:24:29.668211 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:24:31.678138 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:24:33.683987 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:24:35.690605 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:24:37.703343 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:24:39.710234 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:24:41.722755 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:24:43.739033 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:24:45.751472 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:24:47.758283 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:24:49.773632 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:24:51.785457 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:24:53.794390 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:24:55.806665 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:24:57.822213 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:24:59.834246 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:25:01.840654 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:25:03.845550 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:25:05.850649 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:25:07.855335 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:25:09.864420 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:25:11.878897 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:25:13.894503 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:25:15.904959 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:25:17.917268 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:25:19.931195 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:25:21.936407 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:25:23.950930 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:25:25.962652 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  I0115 01:25:27.977587 24 container_probe.go:1759] Get pod busybox-bcc464f5-3eb6-4dc5-b2d5-91bc1fc42856 in namespace container-probe-4488
  STEP: deleting the pod @ 01/15/25 01:25:29.978
  I0115 01:25:29.992009 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-4488" for this suite. @ 01/15/25 01:25:29.998
• [243.319 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] CSIInlineVolumes should run through the lifecycle of a CSIDriver [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/csi_inline.go:157
  STEP: Creating a kubernetes client @ 01/15/25 01:25:30.005
  I0115 01:25:30.005378 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename csiinlinevolumes @ 01/15/25 01:25:30.006
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:25:30.021
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:25:30.026
  STEP: Creating two CSIDrivers @ 01/15/25 01:25:30.032
  STEP: Getting "inline-driver-6fe71df7-cda3-4bd7-94ce-46fcffde90f2" & "inline-driver-ef6a4fe3-a44b-4b31-9183-b080efdaba33" @ 01/15/25 01:25:30.047
  STEP: Patching the CSIDriver "inline-driver-ef6a4fe3-a44b-4b31-9183-b080efdaba33" @ 01/15/25 01:25:30.053
  STEP: Updating the CSIDriver "inline-driver-ef6a4fe3-a44b-4b31-9183-b080efdaba33" @ 01/15/25 01:25:30.058
  STEP: Listing all CSIDrivers with the labelSelector: "e2e-test=csiinlinevolumes-9710" @ 01/15/25 01:25:30.068
  STEP: Deleting CSIDriver "inline-driver-6fe71df7-cda3-4bd7-94ce-46fcffde90f2" @ 01/15/25 01:25:30.071
  STEP: Confirm deletion of CSIDriver "inline-driver-6fe71df7-cda3-4bd7-94ce-46fcffde90f2" @ 01/15/25 01:25:30.076
  STEP: Deleting CSIDriver "inline-driver-ef6a4fe3-a44b-4b31-9183-b080efdaba33" via DeleteCollection @ 01/15/25 01:25:30.079
  STEP: Confirm deletion of CSIDriver "inline-driver-ef6a4fe3-a44b-4b31-9183-b080efdaba33" @ 01/15/25 01:25:30.084
  I0115 01:25:30.087780 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-9710" for this suite. @ 01/15/25 01:25:30.098
• [0.098 seconds]
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:164
  STEP: Creating a kubernetes client @ 01/15/25 01:25:30.103
  I0115 01:25:30.103168 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename projected @ 01/15/25 01:25:30.104
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:25:30.12
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:25:30.124
  STEP: Creating the pod @ 01/15/25 01:25:30.129
  I0115 01:25:32.709077 24 pod_client.go:173] Successfully updated pod "annotationupdate48aa8d17-3a7e-4ce1-9b34-08c207727248"
  I0115 01:25:36.734061 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6872" for this suite. @ 01/15/25 01:25:36.738
• [6.640 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Services should test the lifecycle of an Endpoint [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3189
  STEP: Creating a kubernetes client @ 01/15/25 01:25:36.743
  I0115 01:25:36.743576 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename services @ 01/15/25 01:25:36.744
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:25:36.757
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:25:36.762
  STEP: creating an Endpoint @ 01/15/25 01:25:36.77
  STEP: waiting for available Endpoint @ 01/15/25 01:25:36.774
  STEP: listing all Endpoints @ 01/15/25 01:25:36.776
  STEP: updating the Endpoint @ 01/15/25 01:25:36.779
  STEP: fetching the Endpoint @ 01/15/25 01:25:36.787
  STEP: patching the Endpoint @ 01/15/25 01:25:36.789
  STEP: fetching the Endpoint @ 01/15/25 01:25:36.796
  STEP: deleting the Endpoint by Collection @ 01/15/25 01:25:36.801
  STEP: waiting for Endpoint deletion @ 01/15/25 01:25:36.807
  STEP: fetching the Endpoint @ 01/15/25 01:25:36.809
  I0115 01:25:36.811738 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-3481" for this suite. @ 01/15/25 01:25:36.844
• [0.123 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:195
  STEP: Creating a kubernetes client @ 01/15/25 01:25:36.868
  I0115 01:25:36.868419 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename projected @ 01/15/25 01:25:36.872
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:25:36.89
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:25:36.896
  STEP: Creating a pod to test downward API volume plugin @ 01/15/25 01:25:36.901
  STEP: Saw pod success @ 01/15/25 01:25:40.939
  I0115 01:25:40.953274 24 output.go:207] Trying to get logs from node 192.168.18.92 pod downwardapi-volume-897ee470-3ff7-4816-9175-e16899105ea1 container client-container: <nil>
  STEP: delete the pod @ 01/15/25 01:25:40.979
  I0115 01:25:41.032065 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-78" for this suite. @ 01/15/25 01:25:41.041
• [4.183 seconds]
------------------------------
SSSS
------------------------------
[sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:678
  STEP: Creating a kubernetes client @ 01/15/25 01:25:41.05
  I0115 01:25:41.051018 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename svcaccounts @ 01/15/25 01:25:41.052
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:25:41.069
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:25:41.075
  STEP: creating a ServiceAccount @ 01/15/25 01:25:41.081
  STEP: watching for the ServiceAccount to be added @ 01/15/25 01:25:41.092
  STEP: patching the ServiceAccount @ 01/15/25 01:25:41.097
  STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) @ 01/15/25 01:25:41.104
  STEP: deleting the ServiceAccount @ 01/15/25 01:25:41.108
  I0115 01:25:41.125541 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-3329" for this suite. @ 01/15/25 01:25:41.141
• [0.098 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:334
  STEP: Creating a kubernetes client @ 01/15/25 01:25:41.148
  I0115 01:25:41.148911 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename watch @ 01/15/25 01:25:41.15
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:25:41.169
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:25:41.174
  STEP: getting a starting resourceVersion @ 01/15/25 01:25:41.18
  STEP: starting a background goroutine to produce watch events @ 01/15/25 01:25:41.184
  STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order @ 01/15/25 01:25:41.184
  I0115 01:25:43.971394 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-8539" for this suite. @ 01/15/25 01:25:44.006
• [2.909 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:329
  STEP: Creating a kubernetes client @ 01/15/25 01:25:44.058
  I0115 01:25:44.058909 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename webhook @ 01/15/25 01:25:44.059
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:25:44.076
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:25:44.082
  STEP: Setting up server cert @ 01/15/25 01:25:44.178
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 01/15/25 01:25:45.176
  STEP: Deploying the webhook pod @ 01/15/25 01:25:45.22
  STEP: Wait for the deployment to be ready @ 01/15/25 01:25:45.255
  I0115 01:25:45.303810 24 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  I0115 01:25:47.348237 24 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.January, 15, 1, 25, 45, 0, time.Local), LastTransitionTime:time.Date(2025, time.January, 15, 1, 25, 45, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.January, 15, 1, 25, 45, 0, time.Local), LastTransitionTime:time.Date(2025, time.January, 15, 1, 25, 45, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-bcbfc85d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  STEP: Deploying the webhook service @ 01/15/25 01:25:49.353
  STEP: Verifying the service has paired with the endpoint @ 01/15/25 01:25:49.375
  I0115 01:25:50.376115 24 util.go:423] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  I0115 01:25:50.405342 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-4945-crds.webhook.example.com via the AdmissionRegistration API @ 01/15/25 01:25:50.957
  STEP: Creating a custom resource that should be mutated by the webhook @ 01/15/25 01:25:50.978
  I0115 01:25:53.657929 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6496" for this suite. @ 01/15/25 01:25:53.662
  STEP: Destroying namespace "webhook-markers-8337" for this suite. @ 01/15/25 01:25:53.668
• [9.615 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/sysctl.go:125
  STEP: Creating a kubernetes client @ 01/15/25 01:25:53.674
  I0115 01:25:53.674792 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename sysctl @ 01/15/25 01:25:53.675
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:25:53.689
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:25:53.693
  STEP: Creating a pod with one valid and two invalid sysctls @ 01/15/25 01:25:53.697
  I0115 01:25:53.704852 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-884" for this suite. @ 01/15/25 01:25:53.763
• [0.096 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/proxy.go:286
  STEP: Creating a kubernetes client @ 01/15/25 01:25:53.77
  I0115 01:25:53.770921 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename proxy @ 01/15/25 01:25:53.771
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:25:53.794
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:25:53.799
  I0115 01:25:53.803779 24 proxy.go:293] Creating pod...
  I0115 01:25:55.831551 24 proxy.go:317] Creating service...
  I0115 01:25:55.843551 24 proxy.go:354] Starting http.Client for https://169.169.0.1:443/api/v1/namespaces/proxy-1507/pods/agnhost/proxy/some/path/with/DELETE
  I0115 01:25:55.860845 24 proxy.go:530] http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  I0115 01:25:55.860932 24 proxy.go:354] Starting http.Client for https://169.169.0.1:443/api/v1/namespaces/proxy-1507/pods/agnhost/proxy/some/path/with/GET
  I0115 01:25:55.874521 24 proxy.go:530] http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  I0115 01:25:55.874628 24 proxy.go:354] Starting http.Client for https://169.169.0.1:443/api/v1/namespaces/proxy-1507/pods/agnhost/proxy/some/path/with/HEAD
  I0115 01:25:55.880633 24 proxy.go:517] http.Client request:HEAD | StatusCode:200
  I0115 01:25:55.880711 24 proxy.go:354] Starting http.Client for https://169.169.0.1:443/api/v1/namespaces/proxy-1507/pods/agnhost/proxy/some/path/with/OPTIONS
  I0115 01:25:55.890663 24 proxy.go:530] http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  I0115 01:25:55.890738 24 proxy.go:354] Starting http.Client for https://169.169.0.1:443/api/v1/namespaces/proxy-1507/pods/agnhost/proxy/some/path/with/PATCH
  I0115 01:25:55.896563 24 proxy.go:530] http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  I0115 01:25:55.896639 24 proxy.go:354] Starting http.Client for https://169.169.0.1:443/api/v1/namespaces/proxy-1507/pods/agnhost/proxy/some/path/with/POST
  I0115 01:25:55.903895 24 proxy.go:530] http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  I0115 01:25:55.904006 24 proxy.go:354] Starting http.Client for https://169.169.0.1:443/api/v1/namespaces/proxy-1507/pods/agnhost/proxy/some/path/with/PUT
  I0115 01:25:55.910568 24 proxy.go:530] http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  I0115 01:25:55.910670 24 proxy.go:365] Starting http.Client for https://169.169.0.1:443/api/v1/namespaces/proxy-1507/services/test-service/proxy/some/path/with/DELETE
  I0115 01:25:55.919477 24 proxy.go:530] http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  I0115 01:25:55.919558 24 proxy.go:365] Starting http.Client for https://169.169.0.1:443/api/v1/namespaces/proxy-1507/services/test-service/proxy/some/path/with/GET
  I0115 01:25:55.929135 24 proxy.go:530] http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  I0115 01:25:55.929247 24 proxy.go:365] Starting http.Client for https://169.169.0.1:443/api/v1/namespaces/proxy-1507/services/test-service/proxy/some/path/with/HEAD
  I0115 01:25:55.937213 24 proxy.go:517] http.Client request:HEAD | StatusCode:200
  I0115 01:25:55.937365 24 proxy.go:365] Starting http.Client for https://169.169.0.1:443/api/v1/namespaces/proxy-1507/services/test-service/proxy/some/path/with/OPTIONS
  I0115 01:25:55.946013 24 proxy.go:530] http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  I0115 01:25:55.946073 24 proxy.go:365] Starting http.Client for https://169.169.0.1:443/api/v1/namespaces/proxy-1507/services/test-service/proxy/some/path/with/PATCH
  I0115 01:25:55.954815 24 proxy.go:530] http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  I0115 01:25:55.954939 24 proxy.go:365] Starting http.Client for https://169.169.0.1:443/api/v1/namespaces/proxy-1507/services/test-service/proxy/some/path/with/POST
  I0115 01:25:55.963354 24 proxy.go:530] http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  I0115 01:25:55.963504 24 proxy.go:365] Starting http.Client for https://169.169.0.1:443/api/v1/namespaces/proxy-1507/services/test-service/proxy/some/path/with/PUT
  I0115 01:25:55.973136 24 proxy.go:530] http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  I0115 01:25:55.973618 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-1507" for this suite. @ 01/15/25 01:25:55.98
• [2.219 seconds]
------------------------------
[sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:295
  STEP: Creating a kubernetes client @ 01/15/25 01:25:55.99
  I0115 01:25:55.990350 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename downward-api @ 01/15/25 01:25:55.991
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:25:56.011
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:25:56.018
  STEP: Creating a pod to test downward api env vars @ 01/15/25 01:25:56.026
  STEP: Saw pod success @ 01/15/25 01:26:02.076
  I0115 01:26:02.087018 24 output.go:207] Trying to get logs from node 192.168.18.92 pod downward-api-706384de-1143-4eab-b16d-7f6b9e33deab container dapi-container: <nil>
  STEP: delete the pod @ 01/15/25 01:26:02.099
  I0115 01:26:02.123320 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-2847" for this suite. @ 01/15/25 01:26:02.131
• [6.149 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:125
  STEP: Creating a kubernetes client @ 01/15/25 01:26:02.139
  I0115 01:26:02.139805 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename cronjob @ 01/15/25 01:26:02.141
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:26:02.182
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:26:02.208
  STEP: Creating a ForbidConcurrent cronjob @ 01/15/25 01:26:02.231
  STEP: Ensuring a job is scheduled @ 01/15/25 01:26:02.253
  STEP: Ensuring exactly one is scheduled @ 01/15/25 01:27:00.261
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 01/15/25 01:27:00.267
  STEP: Ensuring no more jobs are scheduled @ 01/15/25 01:27:00.273
  STEP: Removing cronjob @ 01/15/25 01:27:00.277
  I0115 01:27:00.284266 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-2981" for this suite. @ 01/15/25 01:27:00.289
• [58.155 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:130
  STEP: Creating a kubernetes client @ 01/15/25 01:27:00.294
  I0115 01:27:00.294474 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename emptydir @ 01/15/25 01:27:00.295
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:27:00.33
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:27:00.351
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 01/15/25 01:27:00.36
  STEP: Saw pod success @ 01/15/25 01:27:04.393
  I0115 01:27:04.398370 24 output.go:207] Trying to get logs from node 192.168.18.92 pod pod-bcf9ac09-215f-48ce-9f87-aac8617896b8 container test-container: <nil>
  STEP: delete the pod @ 01/15/25 01:27:04.409
  I0115 01:27:04.483445 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-7185" for this suite. @ 01/15/25 01:27:04.487
• [4.199 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:257
  STEP: Creating a kubernetes client @ 01/15/25 01:27:04.493
  I0115 01:27:04.493401 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename watch @ 01/15/25 01:27:04.494
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:27:04.504
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:27:04.51
  STEP: creating a watch on configmaps with a certain label @ 01/15/25 01:27:04.514
  STEP: creating a new configmap @ 01/15/25 01:27:04.517
  STEP: modifying the configmap once @ 01/15/25 01:27:04.521
  STEP: changing the label value of the configmap @ 01/15/25 01:27:04.528
  STEP: Expecting to observe a delete notification for the watched object @ 01/15/25 01:27:04.535
  I0115 01:27:04.535278 24 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1737  344e1b87-15dd-4344-aa90-e3fd8dd4c456 158237 0 2025-01-15 01:27:04 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2025-01-15 01:27:04 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I0115 01:27:04.535607 24 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1737  344e1b87-15dd-4344-aa90-e3fd8dd4c456 158238 0 2025-01-15 01:27:04 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2025-01-15 01:27:04 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0115 01:27:04.535779 24 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1737  344e1b87-15dd-4344-aa90-e3fd8dd4c456 158239 0 2025-01-15 01:27:04 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2025-01-15 01:27:04 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time @ 01/15/25 01:27:04.535
  STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements @ 01/15/25 01:27:04.543
  STEP: changing the label value of the configmap back @ 01/15/25 01:27:14.543
  STEP: modifying the configmap a third time @ 01/15/25 01:27:14.552
  STEP: deleting the configmap @ 01/15/25 01:27:14.56
  STEP: Expecting to observe an add notification for the watched object when the label value was restored @ 01/15/25 01:27:14.566
  I0115 01:27:14.566208 24 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1737  344e1b87-15dd-4344-aa90-e3fd8dd4c456 158270 0 2025-01-15 01:27:04 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2025-01-15 01:27:14 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0115 01:27:14.566478 24 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1737  344e1b87-15dd-4344-aa90-e3fd8dd4c456 158271 0 2025-01-15 01:27:04 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2025-01-15 01:27:14 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0115 01:27:14.566616 24 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1737  344e1b87-15dd-4344-aa90-e3fd8dd4c456 158272 0 2025-01-15 01:27:04 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2025-01-15 01:27:14 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0115 01:27:14.566716 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-1737" for this suite. @ 01/15/25 01:27:14.571
• [10.083 seconds]
------------------------------
SS
------------------------------
[sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:742
  STEP: Creating a kubernetes client @ 01/15/25 01:27:14.576
  I0115 01:27:14.576977 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename job @ 01/15/25 01:27:14.577
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:27:14.593
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:27:14.598
  STEP: Creating a job @ 01/15/25 01:27:14.604
  STEP: Ensuring job reaches completions @ 01/15/25 01:27:14.608
  I0115 01:27:24.672034 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-5432" for this suite. @ 01/15/25 01:27:24.69
• [10.138 seconds]
------------------------------
S
------------------------------
[sig-auth] ServiceAccounts should create a serviceAccountToken and ensure a successful TokenReview [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:878
  STEP: Creating a kubernetes client @ 01/15/25 01:27:24.715
  I0115 01:27:24.715616 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename svcaccounts @ 01/15/25 01:27:24.716
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:27:24.738
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:27:24.743
  STEP: Creating a Serviceaccount "e2e-sa-zt2nf" in namespace "svcaccounts-7101" @ 01/15/25 01:27:24.747
  STEP: Creating a ServiceaccountToken "e2e-sa-zt2nf" in namespace "svcaccounts-7101" @ 01/15/25 01:27:24.752
  STEP: Creating a TokenReview for "e2e-sa-zt2nf" in namespace "svcaccounts-7101" @ 01/15/25 01:27:24.758
  I0115 01:27:24.761681 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-7101" for this suite. @ 01/15/25 01:27:24.793
• [0.099 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:647
  STEP: Creating a kubernetes client @ 01/15/25 01:27:24.815
  I0115 01:27:24.815350 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename statefulset @ 01/15/25 01:27:24.821
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:27:24.869
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:27:24.876
  STEP: Creating service test in namespace statefulset-6737 @ 01/15/25 01:27:24.883
  STEP: Initializing watcher for selector baz=blah,foo=bar @ 01/15/25 01:27:24.888
  STEP: Creating stateful set ss in namespace statefulset-6737 @ 01/15/25 01:27:24.897
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-6737 @ 01/15/25 01:27:24.904
  I0115 01:27:24.932290 24 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
  I0115 01:27:34.909793 24 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod @ 01/15/25 01:27:34.909
  I0115 01:27:34.913050 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=statefulset-6737 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0115 01:27:35.059514 24 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0115 01:27:35.059571 24 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0115 01:27:35.059582 24 rest.go:263] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0115 01:27:35.065431 24 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  I0115 01:27:45.076202 24 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  I0115 01:27:45.076376 24 wait.go:101] Waiting for statefulset status.readyReplicas updated to 0
  I0115 01:27:45.180398 24 statefulset.go:2421] Verifying statefulset ss doesn't scale past 1 for another 9.999999338s
  I0115 01:27:46.185104 24 statefulset.go:2421] Verifying statefulset ss doesn't scale past 1 for another 8.913735325s
  I0115 01:27:47.203498 24 statefulset.go:2421] Verifying statefulset ss doesn't scale past 1 for another 7.908871156s
  I0115 01:27:48.218881 24 statefulset.go:2421] Verifying statefulset ss doesn't scale past 1 for another 6.890289532s
  I0115 01:27:49.235042 24 statefulset.go:2421] Verifying statefulset ss doesn't scale past 1 for another 5.874095831s
  I0115 01:27:50.253241 24 statefulset.go:2421] Verifying statefulset ss doesn't scale past 1 for another 4.858433746s
  I0115 01:27:51.265850 24 statefulset.go:2421] Verifying statefulset ss doesn't scale past 1 for another 3.840325809s
  I0115 01:27:52.280939 24 statefulset.go:2421] Verifying statefulset ss doesn't scale past 1 for another 2.827213803s
  I0115 01:27:53.296028 24 statefulset.go:2421] Verifying statefulset ss doesn't scale past 1 for another 1.812864541s
  I0115 01:27:54.300522 24 statefulset.go:2421] Verifying statefulset ss doesn't scale past 1 for another 798.256509ms
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-6737 @ 01/15/25 01:27:55.301
  I0115 01:27:55.313442 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=statefulset-6737 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0115 01:27:55.528583 24 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0115 01:27:55.528642 24 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0115 01:27:55.528661 24 rest.go:263] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0115 01:27:55.532479 24 wait.go:40] Found 1 stateful pods, waiting for 3
  I0115 01:28:05.549952 24 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  I0115 01:28:05.550106 24 wait.go:50] Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  I0115 01:28:05.550161 24 wait.go:50] Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Verifying that stateful set ss was scaled up in order @ 01/15/25 01:28:05.55
  STEP: Scale down will halt with unhealthy stateful pod @ 01/15/25 01:28:05.55
  I0115 01:28:05.579523 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=statefulset-6737 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0115 01:28:05.724271 24 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0115 01:28:05.724344 24 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0115 01:28:05.724363 24 rest.go:263] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0115 01:28:05.724406 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=statefulset-6737 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0115 01:28:05.846009 24 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0115 01:28:05.846056 24 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0115 01:28:05.846067 24 rest.go:263] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0115 01:28:05.846104 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=statefulset-6737 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0115 01:28:05.989454 24 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0115 01:28:05.989518 24 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0115 01:28:05.989540 24 rest.go:263] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0115 01:28:05.989552 24 wait.go:101] Waiting for statefulset status.readyReplicas updated to 0
  I0115 01:28:05.993074 24 wait.go:114] Waiting for statefulset status.readyReplicas to become 0, currently 2
  I0115 01:28:15.999018 24 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  I0115 01:28:15.999119 24 wait.go:50] Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  I0115 01:28:15.999141 24 wait.go:50] Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  I0115 01:28:16.100325 24 statefulset.go:2421] Verifying statefulset ss doesn't scale past 3 for another 9.99999965s
  I0115 01:28:17.120435 24 statefulset.go:2421] Verifying statefulset ss doesn't scale past 3 for another 8.907037582s
  I0115 01:28:18.142300 24 statefulset.go:2421] Verifying statefulset ss doesn't scale past 3 for another 7.886090524s
  I0115 01:28:19.156017 24 statefulset.go:2421] Verifying statefulset ss doesn't scale past 3 for another 6.864303995s
  I0115 01:28:20.162418 24 statefulset.go:2421] Verifying statefulset ss doesn't scale past 3 for another 5.851120167s
  I0115 01:28:21.187087 24 statefulset.go:2421] Verifying statefulset ss doesn't scale past 3 for another 4.844562207s
  I0115 01:28:22.197415 24 statefulset.go:2421] Verifying statefulset ss doesn't scale past 3 for another 3.819631296s
  I0115 01:28:23.202603 24 statefulset.go:2421] Verifying statefulset ss doesn't scale past 3 for another 2.810129245s
  I0115 01:28:24.207891 24 statefulset.go:2421] Verifying statefulset ss doesn't scale past 3 for another 1.804362532s
  I0115 01:28:25.214249 24 statefulset.go:2421] Verifying statefulset ss doesn't scale past 3 for another 800.093451ms
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-6737 @ 01/15/25 01:28:26.214
  I0115 01:28:26.219043 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=statefulset-6737 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0115 01:28:26.366966 24 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0115 01:28:26.367003 24 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0115 01:28:26.367018 24 rest.go:263] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0115 01:28:26.367064 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=statefulset-6737 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0115 01:28:26.506122 24 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0115 01:28:26.506191 24 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0115 01:28:26.506217 24 rest.go:263] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0115 01:28:26.506265 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=statefulset-6737 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0115 01:28:26.742133 24 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0115 01:28:26.742276 24 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0115 01:28:26.742333 24 rest.go:263] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0115 01:28:26.742577 24 rest.go:152] Scaling statefulset ss to 0
  STEP: Verifying that stateful set ss was scaled down in reverse order @ 01/15/25 01:28:36.771
  I0115 01:28:36.771579 24 statefulset.go:138] Deleting all statefulset in ns statefulset-6737
  I0115 01:28:36.780239 24 rest.go:152] Scaling statefulset ss to 0
  I0115 01:28:36.790083 24 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I0115 01:28:36.793933 24 rest.go:90] Deleting statefulset ss
  I0115 01:28:36.807685 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-6737" for this suite. @ 01/15/25 01:28:36.812
• [72.005 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:539
  STEP: Creating a kubernetes client @ 01/15/25 01:28:36.819
  I0115 01:28:36.819870 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename gc @ 01/15/25 01:28:36.82
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:28:36.836
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:28:36.84
  STEP: create the deployment @ 01/15/25 01:28:36.847
  W0115 01:28:36.852117      24 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: Wait for the Deployment to create new ReplicaSet @ 01/15/25 01:28:36.852
  STEP: delete the deployment @ 01/15/25 01:28:37.358
  STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs @ 01/15/25 01:28:37.363
  STEP: Gathering metrics @ 01/15/25 01:28:37.885
  I0115 01:28:38.011656 24 garbage_collector.go:265] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0115 01:28:38.011871 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-5956" for this suite. @ 01/15/25 01:28:38.015
• [1.201 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:196
  STEP: Creating a kubernetes client @ 01/15/25 01:28:38.02
  I0115 01:28:38.020797 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename webhook @ 01/15/25 01:28:38.021
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:28:38.035
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:28:38.039
  STEP: Setting up server cert @ 01/15/25 01:28:38.168
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 01/15/25 01:28:39.398
  STEP: Deploying the webhook pod @ 01/15/25 01:28:39.442
  STEP: Wait for the deployment to be ready @ 01/15/25 01:28:39.487
  I0115 01:28:39.506813 24 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  I0115 01:28:41.555976 24 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.January, 15, 1, 28, 39, 0, time.Local), LastTransitionTime:time.Date(2025, time.January, 15, 1, 28, 39, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.January, 15, 1, 28, 39, 0, time.Local), LastTransitionTime:time.Date(2025, time.January, 15, 1, 28, 39, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-bcbfc85d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  STEP: Deploying the webhook service @ 01/15/25 01:28:43.572
  STEP: Verifying the service has paired with the endpoint @ 01/15/25 01:28:43.611
  I0115 01:28:44.613515 24 util.go:423] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the webhook via the AdmissionRegistration API @ 01/15/25 01:28:44.638
  STEP: create a pod that should be denied by the webhook @ 01/15/25 01:28:44.701
  STEP: create a pod that causes the webhook to hang @ 01/15/25 01:28:44.718
  STEP: create a configmap that should be denied by the webhook @ 01/15/25 01:28:54.725
  STEP: create a configmap that should be admitted by the webhook @ 01/15/25 01:28:54.736
  STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook @ 01/15/25 01:28:54.748
  STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook @ 01/15/25 01:28:54.758
  STEP: create a namespace that bypass the webhook @ 01/15/25 01:28:54.763
  STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace @ 01/15/25 01:28:54.775
  I0115 01:28:54.828707 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-3074" for this suite. @ 01/15/25 01:28:54.835
  STEP: Destroying namespace "webhook-markers-7439" for this suite. @ 01/15/25 01:28:54.85
  STEP: Destroying namespace "exempted-namespace-6961" for this suite. @ 01/15/25 01:28:54.859
• [16.848 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:47
  STEP: Creating a kubernetes client @ 01/15/25 01:28:54.869
  I0115 01:28:54.869501 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename configmap @ 01/15/25 01:28:54.87
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:28:54.894
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:28:54.9
  STEP: Creating configMap configmap-9434/configmap-test-10dde299-c07e-4043-88cb-847461110340 @ 01/15/25 01:28:54.906
  STEP: Creating a pod to test consume configMaps @ 01/15/25 01:28:54.912
  STEP: Saw pod success @ 01/15/25 01:28:58.963
  I0115 01:28:58.974967 24 output.go:207] Trying to get logs from node 192.168.18.92 pod pod-configmaps-29f60f44-36af-4f77-a166-8bb408c9047f container env-test: <nil>
  STEP: delete the pod @ 01/15/25 01:28:59.002
  I0115 01:28:59.016950 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-9434" for this suite. @ 01/15/25 01:28:59.021
• [4.157 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:86
  STEP: Creating a kubernetes client @ 01/15/25 01:28:59.026
  I0115 01:28:59.026808 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename custom-resource-definition @ 01/15/25 01:28:59.028
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:28:59.039
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:28:59.043
  I0115 01:28:59.047742 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  I0115 01:29:05.332223 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-6681" for this suite. @ 01/15/25 01:29:05.335
• [6.313 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1435
  STEP: Creating a kubernetes client @ 01/15/25 01:29:05.34
  I0115 01:29:05.340777 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename services @ 01/15/25 01:29:05.341
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:29:05.355
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:29:05.359
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-4465 @ 01/15/25 01:29:05.364
  STEP: changing the ExternalName service to type=NodePort @ 01/15/25 01:29:05.368
  STEP: creating replication controller externalname-service in namespace services-4465 @ 01/15/25 01:29:05.381
  I0115 01:29:05.391905      24 runners.go:193] Created replication controller with name: externalname-service, namespace: services-4465, replica count: 2
  I0115 01:29:08.443022      24 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0115 01:29:08.443146 24 resource.go:361] Creating new exec pod
  I0115 01:29:11.464725 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-4465 exec execpodnnnzb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  I0115 01:29:11.626654 24 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service (169.169.71.219) 80 port [tcp/http] succeeded!\n"
  I0115 01:29:11.626750 24 builder.go:147] stdout: ""
  I0115 01:29:12.466347 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-4465 exec execpodnnnzb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  I0115 01:29:12.725591 24 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service (169.169.71.219) 80 port [tcp/http] succeeded!\n"
  I0115 01:29:12.725703 24 builder.go:147] stdout: "externalname-service-mn5qr"
  I0115 01:29:12.725880 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-4465 exec execpodnnnzb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 169.169.71.219 80'
  I0115 01:29:12.894571 24 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 169.169.71.219 80\nConnection to 169.169.71.219 80 port [tcp/http] succeeded!\n"
  I0115 01:29:12.894648 24 builder.go:147] stdout: "externalname-service-8zj62"
  I0115 01:29:12.894779 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-4465 exec execpodnnnzb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.18.91 30432'
  I0115 01:29:13.092629 24 builder.go:146] stderr: "+ nc -v -t -w 2 192.168.18.91 30432\n+ echo hostName\nConnection to 192.168.18.91 30432 port [tcp/*] succeeded!\n"
  I0115 01:29:13.092702 24 builder.go:147] stdout: "externalname-service-8zj62"
  I0115 01:29:13.092838 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-4465 exec execpodnnnzb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.18.92 30432'
  I0115 01:29:13.285565 24 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.18.92 30432\nConnection to 192.168.18.92 30432 port [tcp/*] succeeded!\n"
  I0115 01:29:13.285649 24 builder.go:147] stdout: ""
  I0115 01:29:14.094264 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-4465 exec execpodnnnzb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.18.92 30432'
  I0115 01:29:14.387840 24 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.18.92 30432\nConnection to 192.168.18.92 30432 port [tcp/*] succeeded!\n"
  I0115 01:29:14.388030 24 builder.go:147] stdout: ""
  I0115 01:29:15.093811 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-4465 exec execpodnnnzb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.18.92 30432'
  I0115 01:29:15.385517 24 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.18.92 30432\nConnection to 192.168.18.92 30432 port [tcp/*] succeeded!\n"
  I0115 01:29:15.385684 24 builder.go:147] stdout: ""
  I0115 01:29:16.093874 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-4465 exec execpodnnnzb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.18.92 30432'
  I0115 01:29:16.354502 24 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.18.92 30432\nConnection to 192.168.18.92 30432 port [tcp/*] succeeded!\n"
  I0115 01:29:16.354700 24 builder.go:147] stdout: "externalname-service-8zj62"
  I0115 01:29:16.354965 24 service.go:1444] Cleaning up the ExternalName to NodePort test service
  I0115 01:29:16.401430 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-4465" for this suite. @ 01/15/25 01:29:16.408
• [11.080 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:207
  STEP: Creating a kubernetes client @ 01/15/25 01:29:16.421
  I0115 01:29:16.421105 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename webhook @ 01/15/25 01:29:16.422
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:29:16.44
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:29:16.446
  STEP: Setting up server cert @ 01/15/25 01:29:16.576
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 01/15/25 01:29:17.825
  STEP: Deploying the webhook pod @ 01/15/25 01:29:17.835
  STEP: Wait for the deployment to be ready @ 01/15/25 01:29:17.851
  I0115 01:29:17.862150 24 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  I0115 01:29:19.876016 24 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.January, 15, 1, 29, 17, 0, time.Local), LastTransitionTime:time.Date(2025, time.January, 15, 1, 29, 17, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.January, 15, 1, 29, 17, 0, time.Local), LastTransitionTime:time.Date(2025, time.January, 15, 1, 29, 17, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-bcbfc85d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  STEP: Deploying the webhook service @ 01/15/25 01:29:21.882
  STEP: Verifying the service has paired with the endpoint @ 01/15/25 01:29:21.896
  I0115 01:29:22.897038 24 util.go:423] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the webhook via the AdmissionRegistration API @ 01/15/25 01:29:22.922
  STEP: create a pod @ 01/15/25 01:29:22.954
  STEP: 'kubectl attach' the pod, should be denied by the webhook @ 01/15/25 01:29:27.023
  I0115 01:29:27.023546 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=webhook-2429 attach --namespace=webhook-2429 to-be-attached-pod -i -c=container1'
  I0115 01:29:27.257049 24 builder.go:135] rc: 1
  I0115 01:29:27.405846 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-2429" for this suite. @ 01/15/25 01:29:27.458
  STEP: Destroying namespace "webhook-markers-7778" for this suite. @ 01/15/25 01:29:27.551
• [11.193 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:60
  STEP: Creating a kubernetes client @ 01/15/25 01:29:27.614
  I0115 01:29:27.614773 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename watch @ 01/15/25 01:29:27.617
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:29:27.66
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:29:27.674
  STEP: creating a watch on configmaps with label A @ 01/15/25 01:29:27.686
  STEP: creating a watch on configmaps with label B @ 01/15/25 01:29:27.693
  STEP: creating a watch on configmaps with label A or B @ 01/15/25 01:29:27.7
  STEP: creating a configmap with label A and ensuring the correct watchers observe the notification @ 01/15/25 01:29:27.705
  I0115 01:29:27.716387 24 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8964  cb1bb6e1-717c-4085-95ae-3a9df3e44a9e 159270 0 2025-01-15 01:29:27 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2025-01-15 01:29:27 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I0115 01:29:27.716673 24 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8964  cb1bb6e1-717c-4085-95ae-3a9df3e44a9e 159270 0 2025-01-15 01:29:27 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2025-01-15 01:29:27 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A and ensuring the correct watchers observe the notification @ 01/15/25 01:29:27.716
  I0115 01:29:27.733756 24 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8964  cb1bb6e1-717c-4085-95ae-3a9df3e44a9e 159271 0 2025-01-15 01:29:27 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2025-01-15 01:29:27 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0115 01:29:27.734020 24 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8964  cb1bb6e1-717c-4085-95ae-3a9df3e44a9e 159271 0 2025-01-15 01:29:27 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2025-01-15 01:29:27 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A again and ensuring the correct watchers observe the notification @ 01/15/25 01:29:27.734
  I0115 01:29:27.755194 24 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8964  cb1bb6e1-717c-4085-95ae-3a9df3e44a9e 159272 0 2025-01-15 01:29:27 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2025-01-15 01:29:27 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0115 01:29:27.756092 24 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8964  cb1bb6e1-717c-4085-95ae-3a9df3e44a9e 159272 0 2025-01-15 01:29:27 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2025-01-15 01:29:27 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: deleting configmap A and ensuring the correct watchers observe the notification @ 01/15/25 01:29:27.756
  I0115 01:29:27.772995 24 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8964  cb1bb6e1-717c-4085-95ae-3a9df3e44a9e 159273 0 2025-01-15 01:29:27 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2025-01-15 01:29:27 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0115 01:29:27.773220 24 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8964  cb1bb6e1-717c-4085-95ae-3a9df3e44a9e 159273 0 2025-01-15 01:29:27 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2025-01-15 01:29:27 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: creating a configmap with label B and ensuring the correct watchers observe the notification @ 01/15/25 01:29:27.773
  I0115 01:29:27.783300 24 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-8964  61526e6f-0b31-4f51-adb2-07b1266a01c4 159274 0 2025-01-15 01:29:27 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2025-01-15 01:29:27 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I0115 01:29:27.783563 24 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-8964  61526e6f-0b31-4f51-adb2-07b1266a01c4 159274 0 2025-01-15 01:29:27 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2025-01-15 01:29:27 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: deleting configmap B and ensuring the correct watchers observe the notification @ 01/15/25 01:29:37.786
  I0115 01:29:37.792935 24 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-8964  61526e6f-0b31-4f51-adb2-07b1266a01c4 159318 0 2025-01-15 01:29:27 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2025-01-15 01:29:27 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I0115 01:29:37.793044 24 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-8964  61526e6f-0b31-4f51-adb2-07b1266a01c4 159318 0 2025-01-15 01:29:27 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2025-01-15 01:29:27 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I0115 01:29:47.796815 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-8964" for this suite. @ 01/15/25 01:29:47.818
• [20.226 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:142
  STEP: Creating a kubernetes client @ 01/15/25 01:29:47.841
  I0115 01:29:47.841928 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename watch @ 01/15/25 01:29:47.846
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:29:47.89
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:29:47.896
  STEP: creating a new configmap @ 01/15/25 01:29:47.903
  STEP: modifying the configmap once @ 01/15/25 01:29:47.908
  STEP: modifying the configmap a second time @ 01/15/25 01:29:47.916
  STEP: deleting the configmap @ 01/15/25 01:29:47.923
  STEP: creating a watch on configmaps from the resource version returned by the first update @ 01/15/25 01:29:47.928
  STEP: Expecting to observe notifications for all changes to the configmap after the first update @ 01/15/25 01:29:47.93
  I0115 01:29:47.930286 24 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-3918  cdebd56e-06db-4947-8c89-4e036b2f0b9e 159341 0 2025-01-15 01:29:47 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2025-01-15 01:29:47 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0115 01:29:47.930450 24 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-3918  cdebd56e-06db-4947-8c89-4e036b2f0b9e 159342 0 2025-01-15 01:29:47 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2025-01-15 01:29:47 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0115 01:29:47.930564 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-3918" for this suite. @ 01/15/25 01:29:47.934
• [0.098 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:148
  STEP: Creating a kubernetes client @ 01/15/25 01:29:47.939
  I0115 01:29:47.939572 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename kubelet-test @ 01/15/25 01:29:47.94
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:29:47.973
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:29:47.978
  STEP: Waiting for pod completion @ 01/15/25 01:29:47.992
  I0115 01:29:52.025907 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-1590" for this suite. @ 01/15/25 01:29:52.031
• [4.099 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] Job should manage the lifecycle of a job [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:1102
  STEP: Creating a kubernetes client @ 01/15/25 01:29:52.038
  I0115 01:29:52.038565 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename job @ 01/15/25 01:29:52.039
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:29:52.051
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:29:52.056
  STEP: Creating a suspended job @ 01/15/25 01:29:52.065
  STEP: Patching the Job @ 01/15/25 01:29:52.07
  STEP: Watching for Job to be patched @ 01/15/25 01:29:52.083
  I0115 01:29:52.085965 24 job.go:1309] Event ADDED observed for Job e2e-wrhmr in namespace job-3777 with labels: map[e2e-job-label:e2e-wrhmr] and annotations: map[]
  I0115 01:29:52.086060 24 job.go:1309] Event MODIFIED observed for Job e2e-wrhmr in namespace job-3777 with labels: map[e2e-job-label:e2e-wrhmr] and annotations: map[]
  I0115 01:29:52.086083 24 job.go:1312] Event MODIFIED found for Job e2e-wrhmr in namespace job-3777 with labels: map[e2e-job-label:e2e-wrhmr e2e-wrhmr:patched] and annotations: map[]
  STEP: Updating the job @ 01/15/25 01:29:52.086
  STEP: Watching for Job to be updated @ 01/15/25 01:29:52.095
  I0115 01:29:52.098303 24 job.go:1312] Event MODIFIED found for Job e2e-wrhmr in namespace job-3777 with labels: map[e2e-job-label:e2e-wrhmr e2e-wrhmr:patched] and annotations: map[updated:true]
  I0115 01:29:52.098372 24 job.go:1180] Found Job annotations: map[string]string{"updated":"true"}
  STEP: Listing all Jobs with LabelSelector @ 01/15/25 01:29:52.098
  I0115 01:29:52.101364 24 job.go:1187] Job: e2e-wrhmr as labels: map[e2e-job-label:e2e-wrhmr e2e-wrhmr:patched]
  STEP: Waiting for job to complete @ 01/15/25 01:29:52.101
  STEP: Delete a job collection with a labelselector @ 01/15/25 01:30:02.154
  STEP: Watching for Job to be deleted @ 01/15/25 01:30:02.162
  I0115 01:30:02.165951 24 job.go:1309] Event MODIFIED observed for Job e2e-wrhmr in namespace job-3777 with labels: map[e2e-job-label:e2e-wrhmr e2e-wrhmr:patched] and annotations: map[updated:true]
  I0115 01:30:02.166284 24 job.go:1309] Event MODIFIED observed for Job e2e-wrhmr in namespace job-3777 with labels: map[e2e-job-label:e2e-wrhmr e2e-wrhmr:patched] and annotations: map[updated:true]
  I0115 01:30:02.166394 24 job.go:1309] Event MODIFIED observed for Job e2e-wrhmr in namespace job-3777 with labels: map[e2e-job-label:e2e-wrhmr e2e-wrhmr:patched] and annotations: map[updated:true]
  I0115 01:30:02.166837 24 job.go:1309] Event MODIFIED observed for Job e2e-wrhmr in namespace job-3777 with labels: map[e2e-job-label:e2e-wrhmr e2e-wrhmr:patched] and annotations: map[updated:true]
  I0115 01:30:02.166931 24 job.go:1309] Event MODIFIED observed for Job e2e-wrhmr in namespace job-3777 with labels: map[e2e-job-label:e2e-wrhmr e2e-wrhmr:patched] and annotations: map[updated:true]
  I0115 01:30:02.167140 24 job.go:1309] Event MODIFIED observed for Job e2e-wrhmr in namespace job-3777 with labels: map[e2e-job-label:e2e-wrhmr e2e-wrhmr:patched] and annotations: map[updated:true]
  I0115 01:30:02.167593 24 job.go:1309] Event MODIFIED observed for Job e2e-wrhmr in namespace job-3777 with labels: map[e2e-job-label:e2e-wrhmr e2e-wrhmr:patched] and annotations: map[updated:true]
  I0115 01:30:02.167632 24 job.go:1309] Event MODIFIED observed for Job e2e-wrhmr in namespace job-3777 with labels: map[e2e-job-label:e2e-wrhmr e2e-wrhmr:patched] and annotations: map[updated:true]
  I0115 01:30:02.167744 24 job.go:1309] Event MODIFIED observed for Job e2e-wrhmr in namespace job-3777 with labels: map[e2e-job-label:e2e-wrhmr e2e-wrhmr:patched] and annotations: map[updated:true]
  I0115 01:30:02.168007 24 job.go:1309] Event MODIFIED observed for Job e2e-wrhmr in namespace job-3777 with labels: map[e2e-job-label:e2e-wrhmr e2e-wrhmr:patched] and annotations: map[updated:true]
  I0115 01:30:02.168162 24 job.go:1312] Event DELETED found for Job e2e-wrhmr in namespace job-3777 with labels: map[e2e-job-label:e2e-wrhmr e2e-wrhmr:patched] and annotations: map[updated:true]
  STEP: Relist jobs to confirm deletion @ 01/15/25 01:30:02.168
  I0115 01:30:02.171438 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-3777" for this suite. @ 01/15/25 01:30:02.178
• [10.154 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:851
  STEP: Creating a kubernetes client @ 01/15/25 01:30:02.193
  I0115 01:30:02.193097 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename daemonsets @ 01/15/25 01:30:02.195
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:30:02.22
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:30:02.226
  STEP: Creating simple DaemonSet "daemon-set" @ 01/15/25 01:30:02.284
  STEP: Check that daemon pods launch on every node of the cluster. @ 01/15/25 01:30:02.291
  I0115 01:30:02.389598 24 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0115 01:30:02.389693 24 fixtures.go:131] Node 192.168.18.91 is running 0 daemon pod, expected 1
  I0115 01:30:03.311068 24 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0115 01:30:03.311157 24 fixtures.go:131] Node 192.168.18.91 is running 0 daemon pod, expected 1
  I0115 01:30:04.303990 24 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0115 01:30:04.304063 24 fixtures.go:136] Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: listing all DaemonSets @ 01/15/25 01:30:04.308
  STEP: DeleteCollection of the DaemonSets @ 01/15/25 01:30:04.315
  STEP: Verify that ReplicaSets have been deleted @ 01/15/25 01:30:04.324
  I0115 01:30:04.421853 24 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"159543"},"items":null}

  I0115 01:30:04.427073 24 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"159543"},"items":[{"metadata":{"name":"daemon-set-7x4xr","generateName":"daemon-set-","namespace":"daemonsets-7580","uid":"34e510b1-4b22-4751-9875-307c02f41e62","resourceVersion":"159543","creationTimestamp":"2025-01-15T01:30:02Z","deletionTimestamp":"2025-01-15T01:30:34Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"9f4489974","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"452d9090bf0ffafb77bc7db8522e2feb4d57f7090a2b79631452fbf45b912522","cni.projectcalico.org/podIP":"10.1.155.1/32","cni.projectcalico.org/podIPs":"10.1.155.1/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"0338847f-3498-4257-9251-f4937d498a52","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2025-01-15T01:30:02Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2025-01-15T01:30:02Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0338847f-3498-4257-9251-f4937d498a52\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2025-01-15T01:30:03Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodReadyToStartContainers\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:hostIPs":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.1.155.1\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-nckfm","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-nckfm","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"192.168.18.92","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["192.168.18.92"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","status":"True","lastProbeTime":null,"lastTransitionTime":"2025-01-15T01:30:03Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2025-01-15T01:30:02Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2025-01-15T01:30:03Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2025-01-15T01:30:03Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2025-01-15T01:30:02Z"}],"hostIP":"192.168.18.92","hostIPs":[{"ip":"192.168.18.92"}],"podIP":"10.1.155.1","podIPs":[{"ip":"10.1.155.1"}],"startTime":"2025-01-15T01:30:02Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2025-01-15T01:30:03Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"containerd://a0bb6194697df07ccc608b4286493f44afc381b1c4c6f0e169d8fdb6eab7dfae","started":true,"volumeMounts":[{"name":"kube-api-access-nckfm","mountPath":"/var/run/secrets/kubernetes.io/serviceaccount","readOnly":true,"recursiveReadOnly":"Disabled"}]}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-99qr2","generateName":"daemon-set-","namespace":"daemonsets-7580","uid":"7212d6c6-adc4-4d30-a2cb-2448e25f98eb","resourceVersion":"159542","creationTimestamp":"2025-01-15T01:30:02Z","deletionTimestamp":"2025-01-15T01:30:34Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"9f4489974","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"82300b8ce5a7e283ed12244530b6bdb66fc9679785a1bdbd995c69a3a0f9ca44","cni.projectcalico.org/podIP":"10.1.213.98/32","cni.projectcalico.org/podIPs":"10.1.213.98/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"0338847f-3498-4257-9251-f4937d498a52","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2025-01-15T01:30:02Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2025-01-15T01:30:02Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0338847f-3498-4257-9251-f4937d498a52\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2025-01-15T01:30:03Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodReadyToStartContainers\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:hostIPs":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"10.1.213.98\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-r9ts9","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-r9ts9","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"192.168.18.91","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["192.168.18.91"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"PodReadyToStartContainers","status":"True","lastProbeTime":null,"lastTransitionTime":"2025-01-15T01:30:03Z"},{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2025-01-15T01:30:02Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2025-01-15T01:30:03Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2025-01-15T01:30:03Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2025-01-15T01:30:02Z"}],"hostIP":"192.168.18.91","hostIPs":[{"ip":"192.168.18.91"}],"podIP":"10.1.213.98","podIPs":[{"ip":"10.1.213.98"}],"startTime":"2025-01-15T01:30:02Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2025-01-15T01:30:03Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"containerd://0d4b470a5c0b566ee59136299d8f0f14a51fafb253a9da0c94547e18f7ab0c21","started":true,"volumeMounts":[{"name":"kube-api-access-r9ts9","mountPath":"/var/run/secrets/kubernetes.io/serviceaccount","readOnly":true,"recursiveReadOnly":"Disabled"}]}],"qosClass":"BestEffort"}}]}

  I0115 01:30:04.443305 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-7580" for this suite. @ 01/15/25 01:30:04.448
• [2.262 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2179
  STEP: Creating a kubernetes client @ 01/15/25 01:30:04.455
  I0115 01:30:04.455825 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename services @ 01/15/25 01:30:04.457
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:30:04.474
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:30:04.481
  STEP: creating service in namespace services-8158 @ 01/15/25 01:30:04.487
  STEP: creating service affinity-clusterip-transition in namespace services-8158 @ 01/15/25 01:30:04.487
  STEP: creating replication controller affinity-clusterip-transition in namespace services-8158 @ 01/15/25 01:30:04.497
  I0115 01:30:04.510644      24 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-8158, replica count: 3
  I0115 01:30:07.561635      24 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0115 01:30:07.571773 24 resource.go:361] Creating new exec pod
  I0115 01:30:10.594499 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-8158 exec execpod-affinityf67tp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
  I0115 01:30:10.880503 24 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition (169.169.33.38) 80 port [tcp/http] succeeded!\n"
  I0115 01:30:10.880564 24 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0115 01:30:10.880686 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-8158 exec execpod-affinityf67tp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 169.169.33.38 80'
  I0115 01:30:11.107692 24 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 169.169.33.38 80\nConnection to 169.169.33.38 80 port [tcp/http] succeeded!\n"
  I0115 01:30:11.107803 24 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0115 01:30:11.121278 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-8158 exec execpod-affinityf67tp -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://169.169.33.38:80/ ; done'
  I0115 01:30:11.676462 24 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://169.169.33.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://169.169.33.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://169.169.33.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://169.169.33.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://169.169.33.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://169.169.33.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://169.169.33.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://169.169.33.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://169.169.33.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://169.169.33.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://169.169.33.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://169.169.33.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://169.169.33.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://169.169.33.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://169.169.33.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://169.169.33.38:80/\n"
  I0115 01:30:11.676581 24 builder.go:147] stdout: "\naffinity-clusterip-transition-7pcxb\naffinity-clusterip-transition-jbkn5\naffinity-clusterip-transition-jbkn5\naffinity-clusterip-transition-jbkn5\naffinity-clusterip-transition-phn2t\naffinity-clusterip-transition-phn2t\naffinity-clusterip-transition-jbkn5\naffinity-clusterip-transition-7pcxb\naffinity-clusterip-transition-jbkn5\naffinity-clusterip-transition-jbkn5\naffinity-clusterip-transition-phn2t\naffinity-clusterip-transition-phn2t\naffinity-clusterip-transition-jbkn5\naffinity-clusterip-transition-phn2t\naffinity-clusterip-transition-7pcxb\naffinity-clusterip-transition-phn2t"
  I0115 01:30:11.676923 24 service.go:242] Received response from host: affinity-clusterip-transition-7pcxb
  I0115 01:30:11.676947 24 service.go:242] Received response from host: affinity-clusterip-transition-jbkn5
  I0115 01:30:11.676966 24 service.go:242] Received response from host: affinity-clusterip-transition-jbkn5
  I0115 01:30:11.676983 24 service.go:242] Received response from host: affinity-clusterip-transition-jbkn5
  I0115 01:30:11.677007 24 service.go:242] Received response from host: affinity-clusterip-transition-phn2t
  I0115 01:30:11.677024 24 service.go:242] Received response from host: affinity-clusterip-transition-phn2t
  I0115 01:30:11.677040 24 service.go:242] Received response from host: affinity-clusterip-transition-jbkn5
  I0115 01:30:11.677056 24 service.go:242] Received response from host: affinity-clusterip-transition-7pcxb
  I0115 01:30:11.677075 24 service.go:242] Received response from host: affinity-clusterip-transition-jbkn5
  I0115 01:30:11.677090 24 service.go:242] Received response from host: affinity-clusterip-transition-jbkn5
  I0115 01:30:11.677105 24 service.go:242] Received response from host: affinity-clusterip-transition-phn2t
  I0115 01:30:11.677121 24 service.go:242] Received response from host: affinity-clusterip-transition-phn2t
  I0115 01:30:11.677136 24 service.go:242] Received response from host: affinity-clusterip-transition-jbkn5
  I0115 01:30:11.677152 24 service.go:242] Received response from host: affinity-clusterip-transition-phn2t
  I0115 01:30:11.677168 24 service.go:242] Received response from host: affinity-clusterip-transition-7pcxb
  I0115 01:30:11.677183 24 service.go:242] Received response from host: affinity-clusterip-transition-phn2t
  I0115 01:30:11.691910 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-8158 exec execpod-affinityf67tp -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://169.169.33.38:80/ ; done'
  I0115 01:30:12.099005 24 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://169.169.33.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://169.169.33.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://169.169.33.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://169.169.33.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://169.169.33.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://169.169.33.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://169.169.33.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://169.169.33.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://169.169.33.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://169.169.33.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://169.169.33.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://169.169.33.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://169.169.33.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://169.169.33.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://169.169.33.38:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://169.169.33.38:80/\n"
  I0115 01:30:12.099135 24 builder.go:147] stdout: "\naffinity-clusterip-transition-7pcxb\naffinity-clusterip-transition-7pcxb\naffinity-clusterip-transition-7pcxb\naffinity-clusterip-transition-7pcxb\naffinity-clusterip-transition-7pcxb\naffinity-clusterip-transition-7pcxb\naffinity-clusterip-transition-7pcxb\naffinity-clusterip-transition-7pcxb\naffinity-clusterip-transition-7pcxb\naffinity-clusterip-transition-7pcxb\naffinity-clusterip-transition-7pcxb\naffinity-clusterip-transition-7pcxb\naffinity-clusterip-transition-7pcxb\naffinity-clusterip-transition-7pcxb\naffinity-clusterip-transition-7pcxb\naffinity-clusterip-transition-7pcxb"
  I0115 01:30:12.099180 24 service.go:242] Received response from host: affinity-clusterip-transition-7pcxb
  I0115 01:30:12.099207 24 service.go:242] Received response from host: affinity-clusterip-transition-7pcxb
  I0115 01:30:12.099228 24 service.go:242] Received response from host: affinity-clusterip-transition-7pcxb
  I0115 01:30:12.099246 24 service.go:242] Received response from host: affinity-clusterip-transition-7pcxb
  I0115 01:30:12.099265 24 service.go:242] Received response from host: affinity-clusterip-transition-7pcxb
  I0115 01:30:12.099283 24 service.go:242] Received response from host: affinity-clusterip-transition-7pcxb
  I0115 01:30:12.099306 24 service.go:242] Received response from host: affinity-clusterip-transition-7pcxb
  I0115 01:30:12.099324 24 service.go:242] Received response from host: affinity-clusterip-transition-7pcxb
  I0115 01:30:12.099343 24 service.go:242] Received response from host: affinity-clusterip-transition-7pcxb
  I0115 01:30:12.099359 24 service.go:242] Received response from host: affinity-clusterip-transition-7pcxb
  I0115 01:30:12.099377 24 service.go:242] Received response from host: affinity-clusterip-transition-7pcxb
  I0115 01:30:12.099394 24 service.go:242] Received response from host: affinity-clusterip-transition-7pcxb
  I0115 01:30:12.099412 24 service.go:242] Received response from host: affinity-clusterip-transition-7pcxb
  I0115 01:30:12.099430 24 service.go:242] Received response from host: affinity-clusterip-transition-7pcxb
  I0115 01:30:12.099448 24 service.go:242] Received response from host: affinity-clusterip-transition-7pcxb
  I0115 01:30:12.099465 24 service.go:242] Received response from host: affinity-clusterip-transition-7pcxb
  I0115 01:30:12.099565 24 service.go:4203] Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-8158, will wait for the garbage collector to delete the pods @ 01/15/25 01:30:12.118
  I0115 01:30:12.188696 24 resources.go:139] Deleting ReplicationController affinity-clusterip-transition took: 9.080959ms
  I0115 01:30:12.289384 24 resources.go:163] Terminating ReplicationController affinity-clusterip-transition pods took: 100.587087ms
  I0115 01:30:15.716097 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-8158" for this suite. @ 01/15/25 01:30:15.726
• [11.280 seconds]
------------------------------
S
------------------------------
[sig-network] Services should complete a service status lifecycle [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3373
  STEP: Creating a kubernetes client @ 01/15/25 01:30:15.735
  I0115 01:30:15.735937 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename services @ 01/15/25 01:30:15.737
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:30:15.764
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:30:15.77
  STEP: creating a Service @ 01/15/25 01:30:15.783
  STEP: watching for the Service to be added @ 01/15/25 01:30:15.802
  I0115 01:30:15.805924 24 service.go:3425] Found Service test-service-9qs6v in namespace services-729 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 30471}]
  I0115 01:30:15.805996 24 service.go:3432] Service test-service-9qs6v created
  STEP: Getting /status @ 01/15/25 01:30:15.806
  I0115 01:30:15.810901 24 service.go:3443] Service test-service-9qs6v has LoadBalancer: {[]}
  STEP: patching the ServiceStatus @ 01/15/25 01:30:15.811
  STEP: watching for the Service to be patched @ 01/15/25 01:30:15.819
  I0115 01:30:15.822954 24 service.go:3466] observed Service test-service-9qs6v in namespace services-729 with annotations: map[] & LoadBalancer: {[]}
  I0115 01:30:15.823061 24 service.go:3469] Found Service test-service-9qs6v in namespace services-729 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  0xc000c30820 []}]}
  I0115 01:30:15.823091 24 service.go:3476] Service test-service-9qs6v has service status patched
  STEP: updating the ServiceStatus @ 01/15/25 01:30:15.823
  I0115 01:30:15.835988 24 service.go:3496] updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Service to be updated @ 01/15/25 01:30:15.836
  I0115 01:30:15.839273 24 service.go:3507] Observed Service test-service-9qs6v in namespace services-729 with annotations: map[] & Conditions: []
  I0115 01:30:15.839451 24 service.go:3518] Observed Service test-service-9qs6v in namespace services-729 with annotations: map[patchedstatus:true] & Conditions: []
  I0115 01:30:15.839582 24 service.go:3514] Found Service test-service-9qs6v in namespace services-729 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  I0115 01:30:15.839667 24 service.go:3525] Service test-service-9qs6v has service status updated
  STEP: patching the service @ 01/15/25 01:30:15.839
  STEP: watching for the Service to be patched @ 01/15/25 01:30:15.85
  I0115 01:30:15.853228 24 service.go:3548] observed Service test-service-9qs6v in namespace services-729 with labels: map[test-service-static:true]
  I0115 01:30:15.853811 24 service.go:3548] observed Service test-service-9qs6v in namespace services-729 with labels: map[test-service-static:true]
  I0115 01:30:15.853907 24 service.go:3548] observed Service test-service-9qs6v in namespace services-729 with labels: map[test-service-static:true]
  I0115 01:30:15.853948 24 service.go:3551] Found Service test-service-9qs6v in namespace services-729 with labels: map[test-service:patched test-service-static:true]
  I0115 01:30:15.853968 24 service.go:3558] Service test-service-9qs6v patched
  STEP: deleting the service @ 01/15/25 01:30:15.854
  STEP: watching for the Service to be deleted @ 01/15/25 01:30:15.873
  I0115 01:30:15.877745 24 service.go:3582] Observed event: ADDED
  I0115 01:30:15.877853 24 service.go:3582] Observed event: MODIFIED
  I0115 01:30:15.877900 24 service.go:3582] Observed event: MODIFIED
  I0115 01:30:15.878242 24 service.go:3582] Observed event: MODIFIED
  I0115 01:30:15.879033 24 service.go:3578] Found Service test-service-9qs6v in namespace services-729 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
  I0115 01:30:15.879129 24 service.go:3587] Service test-service-9qs6v deleted
  I0115 01:30:15.879325 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-729" for this suite. @ 01/15/25 01:30:15.887
• [0.163 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:69
  STEP: Creating a kubernetes client @ 01/15/25 01:30:15.899
  I0115 01:30:15.899123 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename subpath @ 01/15/25 01:30:15.9
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:30:15.92
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:30:15.927
  STEP: Setting up data @ 01/15/25 01:30:15.934
  STEP: Creating pod pod-subpath-test-configmap-sdtp @ 01/15/25 01:30:15.948
  STEP: Creating a pod to test atomic-volume-subpath @ 01/15/25 01:30:15.948
  STEP: Saw pod success @ 01/15/25 01:30:40.059
  I0115 01:30:40.062919 24 output.go:207] Trying to get logs from node 192.168.18.92 pod pod-subpath-test-configmap-sdtp container test-container-subpath-configmap-sdtp: <nil>
  STEP: delete the pod @ 01/15/25 01:30:40.075
  STEP: Deleting pod pod-subpath-test-configmap-sdtp @ 01/15/25 01:30:40.088
  I0115 01:30:40.088224 24 delete.go:62] Deleting pod "pod-subpath-test-configmap-sdtp" in namespace "subpath-6513"
  I0115 01:30:40.091330 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-6513" for this suite. @ 01/15/25 01:30:40.095
• [24.203 seconds]
------------------------------
SSS
------------------------------
[sig-node] PreStop should call prestop when killing a pod [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/pre_stop.go:169
  STEP: Creating a kubernetes client @ 01/15/25 01:30:40.101
  I0115 01:30:40.102018 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename prestop @ 01/15/25 01:30:40.103
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:30:40.117
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:30:40.121
  STEP: Creating server pod server in namespace prestop-8174 @ 01/15/25 01:30:40.125
  STEP: Waiting for pods to come up. @ 01/15/25 01:30:40.133
  STEP: Creating tester pod tester in namespace prestop-8174 @ 01/15/25 01:30:42.149
  STEP: Deleting pre-stop pod @ 01/15/25 01:30:44.174
  I0115 01:30:49.220399 24 pre_stop.go:140] Saw: {
  	"Hostname": "server",
  	"Sent": null,
  	"Received": {
  		"prestop": 1
  	},
  	"Errors": null,
  	"Log": [
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
  	],
  	"StillContactingPeers": true
  }
  STEP: Deleting the server pod @ 01/15/25 01:30:49.22
  I0115 01:30:49.236705 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "prestop-8174" for this suite. @ 01/15/25 01:30:49.241
• [9.150 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject validating webhook configurations with invalid match conditions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:814
  STEP: Creating a kubernetes client @ 01/15/25 01:30:49.251
  I0115 01:30:49.251646 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename webhook @ 01/15/25 01:30:49.252
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:30:49.269
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:30:49.274
  STEP: Setting up server cert @ 01/15/25 01:30:49.369
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 01/15/25 01:30:49.88
  STEP: Deploying the webhook pod @ 01/15/25 01:30:49.889
  STEP: Wait for the deployment to be ready @ 01/15/25 01:30:49.9
  I0115 01:30:49.906211 24 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 01/15/25 01:30:51.921
  STEP: Verifying the service has paired with the endpoint @ 01/15/25 01:30:51.936
  I0115 01:30:52.938211 24 util.go:423] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: creating a validating webhook with match conditions @ 01/15/25 01:30:52.963
  I0115 01:30:53.055701 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6128" for this suite. @ 01/15/25 01:30:53.061
  STEP: Destroying namespace "webhook-markers-8872" for this suite. @ 01/15/25 01:30:53.071
• [3.828 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:245
  STEP: Creating a kubernetes client @ 01/15/25 01:30:53.081
  I0115 01:30:53.081202 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename namespaces @ 01/15/25 01:30:53.083
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:30:53.101
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:30:53.107
  STEP: Creating a test namespace @ 01/15/25 01:30:53.113
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:30:53.237
  STEP: Creating a pod in the namespace @ 01/15/25 01:30:53.259
  STEP: Waiting for the pod to have running status @ 01/15/25 01:30:53.291
  STEP: Deleting the namespace @ 01/15/25 01:30:55.316
  STEP: Waiting for the namespace to be removed. @ 01/15/25 01:30:55.364
  STEP: Recreating the namespace @ 01/15/25 01:31:06.381
  STEP: Verifying there are no pods in the namespace @ 01/15/25 01:31:06.433
  I0115 01:31:06.446452 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-882" for this suite. @ 01/15/25 01:31:06.458
  STEP: Destroying namespace "nsdeletetest-1667" for this suite. @ 01/15/25 01:31:06.469
  I0115 01:31:06.472998 24 framework.go:370] Namespace nsdeletetest-1667 was already deleted
  STEP: Destroying namespace "nsdeletetest-6444" for this suite. @ 01/15/25 01:31:06.473
• [13.398 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:200
  STEP: Creating a kubernetes client @ 01/15/25 01:31:06.479
  I0115 01:31:06.479886 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename emptydir @ 01/15/25 01:31:06.481
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:31:06.506
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:31:06.51
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 01/15/25 01:31:06.515
  STEP: Saw pod success @ 01/15/25 01:31:10.536
  I0115 01:31:10.539912 24 output.go:207] Trying to get logs from node 192.168.18.92 pod pod-7646dc1a-f46c-4481-9dce-97599d92aac1 container test-container: <nil>
  STEP: delete the pod @ 01/15/25 01:31:10.546
  I0115 01:31:10.560889 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-7135" for this suite. @ 01/15/25 01:31:10.565
• [4.092 seconds]
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:467
  STEP: Creating a kubernetes client @ 01/15/25 01:31:10.572
  I0115 01:31:10.572325 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename sched-pred @ 01/15/25 01:31:10.573
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:31:10.585
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:31:10.59
  I0115 01:31:10.593478 24 helper.go:125] Waiting up to 1m0s for all (but 0) nodes to be ready
  I0115 01:31:10.668599 24 util.go:396] Waiting for terminating namespaces to be deleted...
  I0115 01:31:10.672304 24 predicates.go:119] 
  Logging pods the apiserver thinks is on node 192.168.18.91 before test
  I0115 01:31:10.679084 24 predicates.go:957] calico-kube-controllers-7498b9bb4c-crlbm from kube-system started at 2025-01-14 15:20:19 +0000 UTC (1 container statuses recorded)
  I0115 01:31:10.679146 24 predicates.go:959] 	Container calico-kube-controllers ready: true, restart count 0
  I0115 01:31:10.679163 24 predicates.go:957] calico-node-zs5fv from kube-system started at 2025-01-14 13:30:35 +0000 UTC (1 container statuses recorded)
  I0115 01:31:10.679170 24 predicates.go:959] 	Container calico-node ready: true, restart count 0
  I0115 01:31:10.679182 24 predicates.go:957] coredns-668d6bf9bc-2fn8q from kube-system started at 2025-01-14 15:16:36 +0000 UTC (1 container statuses recorded)
  I0115 01:31:10.679188 24 predicates.go:959] 	Container coredns ready: true, restart count 0
  I0115 01:31:10.679194 24 predicates.go:957] coredns-668d6bf9bc-mpkf9 from kube-system started at 2025-01-14 15:16:35 +0000 UTC (1 container statuses recorded)
  I0115 01:31:10.679198 24 predicates.go:959] 	Container coredns ready: true, restart count 0
  I0115 01:31:10.679204 24 predicates.go:957] etcd-192.168.18.91 from kube-system started at 2025-01-14 07:47:31 +0000 UTC (1 container statuses recorded)
  I0115 01:31:10.679210 24 predicates.go:959] 	Container etcd ready: true, restart count 2
  I0115 01:31:10.679219 24 predicates.go:957] kube-apiserver-192.168.18.91 from kube-system started at 2025-01-14 07:47:31 +0000 UTC (1 container statuses recorded)
  I0115 01:31:10.679224 24 predicates.go:959] 	Container kube-apiserver ready: true, restart count 2
  I0115 01:31:10.679233 24 predicates.go:957] kube-controller-manager-192.168.18.91 from kube-system started at 2025-01-14 07:47:31 +0000 UTC (1 container statuses recorded)
  I0115 01:31:10.679240 24 predicates.go:959] 	Container kube-controller-manager ready: true, restart count 2
  I0115 01:31:10.679251 24 predicates.go:957] kube-proxy-nlmsc from kube-system started at 2025-01-14 13:23:11 +0000 UTC (1 container statuses recorded)
  I0115 01:31:10.679259 24 predicates.go:959] 	Container kube-proxy ready: true, restart count 0
  I0115 01:31:10.679267 24 predicates.go:957] kube-scheduler-192.168.18.91 from kube-system started at 2025-01-14 07:47:31 +0000 UTC (1 container statuses recorded)
  I0115 01:31:10.679274 24 predicates.go:959] 	Container kube-scheduler ready: true, restart count 2
  I0115 01:31:10.679283 24 predicates.go:957] sonobuoy-systemd-logs-daemon-set-7cfa3cb4906a48cc-vmmwc from sonobuoy started at 2025-01-15 01:17:18 +0000 UTC (2 container statuses recorded)
  I0115 01:31:10.679290 24 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I0115 01:31:10.679297 24 predicates.go:959] 	Container systemd-logs ready: true, restart count 0
  I0115 01:31:10.679304 24 predicates.go:119] 
  Logging pods the apiserver thinks is on node 192.168.18.92 before test
  I0115 01:31:10.683831 24 predicates.go:957] calico-node-9mtz6 from kube-system started at 2025-01-14 13:30:35 +0000 UTC (1 container statuses recorded)
  I0115 01:31:10.683900 24 predicates.go:959] 	Container calico-node ready: true, restart count 0
  I0115 01:31:10.683916 24 predicates.go:957] kube-proxy-tf5gf from kube-system started at 2025-01-14 13:23:11 +0000 UTC (1 container statuses recorded)
  I0115 01:31:10.683924 24 predicates.go:959] 	Container kube-proxy ready: true, restart count 0
  I0115 01:31:10.683934 24 predicates.go:957] tester from prestop-8174 started at 2025-01-15 01:30:42 +0000 UTC (1 container statuses recorded)
  I0115 01:31:10.683941 24 predicates.go:959] 	Container tester ready: true, restart count 0
  I0115 01:31:10.683951 24 predicates.go:957] sonobuoy from sonobuoy started at 2025-01-15 01:17:16 +0000 UTC (1 container statuses recorded)
  I0115 01:31:10.683962 24 predicates.go:959] 	Container kube-sonobuoy ready: true, restart count 0
  I0115 01:31:10.683971 24 predicates.go:957] sonobuoy-e2e-job-62b29f02b7114b6e from sonobuoy started at 2025-01-15 01:17:17 +0000 UTC (2 container statuses recorded)
  I0115 01:31:10.683978 24 predicates.go:959] 	Container e2e ready: true, restart count 0
  I0115 01:31:10.683986 24 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I0115 01:31:10.683996 24 predicates.go:957] sonobuoy-systemd-logs-daemon-set-7cfa3cb4906a48cc-ljwvq from sonobuoy started at 2025-01-15 01:17:18 +0000 UTC (2 container statuses recorded)
  I0115 01:31:10.684003 24 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I0115 01:31:10.684010 24 predicates.go:959] 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 01/15/25 01:31:10.684
  STEP: Explicitly delete pod here to free the resource it takes. @ 01/15/25 01:31:12.718
  STEP: Trying to apply a random label on the found node. @ 01/15/25 01:31:12.755
  STEP: verifying the node has the label kubernetes.io/e2e-cce86f77-31bf-4cc2-85fa-d8400eabfe65 42 @ 01/15/25 01:31:12.775
  STEP: Trying to relaunch the pod, now with labels. @ 01/15/25 01:31:12.782
  STEP: removing the label kubernetes.io/e2e-cce86f77-31bf-4cc2-85fa-d8400eabfe65 off the node 192.168.18.92 @ 01/15/25 01:31:14.812
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-cce86f77-31bf-4cc2-85fa-d8400eabfe65 @ 01/15/25 01:31:14.823
  I0115 01:31:14.830172 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-3371" for this suite. @ 01/15/25 01:31:14.834
• [4.268 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:376
  STEP: Creating a kubernetes client @ 01/15/25 01:31:14.84
  I0115 01:31:14.840493 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename projected @ 01/15/25 01:31:14.841
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:31:14.859
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:31:14.866
  STEP: Creating configMap with name projected-configmap-test-volume-a8e591b0-90a5-4709-82de-dd0a893e8db7 @ 01/15/25 01:31:14.872
  STEP: Creating a pod to test consume configMaps @ 01/15/25 01:31:14.877
  STEP: Saw pod success @ 01/15/25 01:31:18.905
  I0115 01:31:18.910131 24 output.go:207] Trying to get logs from node 192.168.18.92 pod pod-projected-configmaps-1d7edf26-4a75-4b7d-8615-5cb68dfaade9 container projected-configmap-volume-test: <nil>
  STEP: delete the pod @ 01/15/25 01:31:18.919
  I0115 01:31:18.935499 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1863" for this suite. @ 01/15/25 01:31:18.942
• [4.110 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:757
  STEP: Creating a kubernetes client @ 01/15/25 01:31:18.95
  I0115 01:31:18.950923 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename statefulset @ 01/15/25 01:31:18.951
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:31:18.971
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:31:18.977
  STEP: Creating service test in namespace statefulset-3731 @ 01/15/25 01:31:18.984
  STEP: Creating stateful set ss in namespace statefulset-3731 @ 01/15/25 01:31:18.991
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-3731 @ 01/15/25 01:31:18.999
  I0115 01:31:19.005668 24 wait.go:40] Found 0 stateful pods, waiting for 1
  I0115 01:31:29.018508 24 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod @ 01/15/25 01:31:29.018
  I0115 01:31:29.034096 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=statefulset-3731 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0115 01:31:29.248059 24 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0115 01:31:29.248117 24 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0115 01:31:29.248131 24 rest.go:263] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0115 01:31:29.251080 24 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  I0115 01:31:39.255578 24 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  I0115 01:31:39.255681 24 wait.go:101] Waiting for statefulset status.readyReplicas updated to 0
  I0115 01:31:39.279840 24 resource.go:168] POD   NODE           PHASE    GRACE  CONDITIONS
  I0115 01:31:39.280113 24 resource.go:175] ss-0  192.168.18.92  Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2025-01-15 01:31:20 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2025-01-15 01:31:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2025-01-15 01:31:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2025-01-15 01:31:29 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2025-01-15 01:31:19 +0000 UTC  }]
  I0115 01:31:39.280189 24 resource.go:178] 
  I0115 01:31:39.280218 24 statefulset.go:2416] StatefulSet ss has not reached scale 3, at 1
  I0115 01:31:40.289772 24 statefulset.go:2421] Verifying statefulset ss doesn't scale past 3 for another 8.992805384s
  I0115 01:31:41.320583 24 statefulset.go:2421] Verifying statefulset ss doesn't scale past 3 for another 7.983404514s
  I0115 01:31:42.327024 24 statefulset.go:2421] Verifying statefulset ss doesn't scale past 3 for another 6.952613855s
  I0115 01:31:43.349235 24 statefulset.go:2421] Verifying statefulset ss doesn't scale past 3 for another 5.944926816s
  I0115 01:31:44.353729 24 statefulset.go:2421] Verifying statefulset ss doesn't scale past 3 for another 4.92398175s
  I0115 01:31:45.361073 24 statefulset.go:2421] Verifying statefulset ss doesn't scale past 3 for another 3.919084263s
  I0115 01:31:46.376345 24 statefulset.go:2421] Verifying statefulset ss doesn't scale past 3 for another 2.911750978s
  I0115 01:31:47.381704 24 statefulset.go:2421] Verifying statefulset ss doesn't scale past 3 for another 1.896526547s
  I0115 01:31:48.385660 24 statefulset.go:2421] Verifying statefulset ss doesn't scale past 3 for another 891.368367ms
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-3731 @ 01/15/25 01:31:49.386
  I0115 01:31:49.391409 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=statefulset-3731 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0115 01:31:49.608904 24 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0115 01:31:49.608971 24 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0115 01:31:49.608993 24 rest.go:263] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0115 01:31:49.609039 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=statefulset-3731 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0115 01:31:49.819442 24 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
  I0115 01:31:49.819579 24 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0115 01:31:49.819638 24 rest.go:263] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0115 01:31:49.819812 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=statefulset-3731 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0115 01:31:50.096111 24 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
  I0115 01:31:50.096445 24 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0115 01:31:50.096482 24 rest.go:263] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  I0115 01:31:50.100253 24 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  I0115 01:31:50.100333 24 wait.go:50] Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  I0115 01:31:50.100350 24 wait.go:50] Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Scale down will not halt with unhealthy stateful pod @ 01/15/25 01:31:50.1
  I0115 01:31:50.104299 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=statefulset-3731 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0115 01:31:50.235587 24 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0115 01:31:50.235642 24 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0115 01:31:50.235662 24 rest.go:263] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0115 01:31:50.235711 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=statefulset-3731 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0115 01:31:50.364648 24 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0115 01:31:50.364765 24 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0115 01:31:50.364785 24 rest.go:263] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0115 01:31:50.364836 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=statefulset-3731 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0115 01:31:50.484997 24 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0115 01:31:50.485057 24 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0115 01:31:50.485075 24 rest.go:263] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  I0115 01:31:50.485086 24 wait.go:101] Waiting for statefulset status.readyReplicas updated to 0
  I0115 01:31:50.487672 24 wait.go:114] Waiting for statefulset status.readyReplicas to become 0, currently 3
  I0115 01:32:00.493182 24 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  I0115 01:32:00.493242 24 wait.go:50] Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  I0115 01:32:00.493257 24 wait.go:50] Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  I0115 01:32:00.508196 24 resource.go:168] POD   NODE           PHASE    GRACE  CONDITIONS
  I0115 01:32:00.508310 24 resource.go:175] ss-0  192.168.18.92  Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2025-01-15 01:31:20 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2025-01-15 01:31:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2025-01-15 01:31:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2025-01-15 01:31:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2025-01-15 01:31:19 +0000 UTC  }]
  I0115 01:32:00.508350 24 resource.go:175] ss-1  192.168.18.92  Running         [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2025-01-15 01:31:41 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2025-01-15 01:31:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2025-01-15 01:31:51 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2025-01-15 01:31:51 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2025-01-15 01:31:39 +0000 UTC  }]
  I0115 01:32:00.508377 24 resource.go:175] ss-2  192.168.18.91  Running  30s    [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2025-01-15 01:31:41 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2025-01-15 01:31:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2025-01-15 01:31:51 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2025-01-15 01:31:51 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2025-01-15 01:31:39 +0000 UTC  }]
  I0115 01:32:00.508386 24 resource.go:178] 
  I0115 01:32:00.508395 24 statefulset.go:2416] StatefulSet ss has not reached scale 0, at 3
  I0115 01:32:01.512931 24 statefulset.go:2421] Verifying statefulset ss doesn't scale past 0 for another 8.992556509s
  I0115 01:32:02.529243 24 statefulset.go:2421] Verifying statefulset ss doesn't scale past 0 for another 7.98791976s
  I0115 01:32:03.546071 24 statefulset.go:2421] Verifying statefulset ss doesn't scale past 0 for another 6.971425479s
  I0115 01:32:04.560470 24 statefulset.go:2421] Verifying statefulset ss doesn't scale past 0 for another 5.954553469s
  I0115 01:32:05.566272 24 statefulset.go:2421] Verifying statefulset ss doesn't scale past 0 for another 4.940597814s
  I0115 01:32:06.569520 24 statefulset.go:2421] Verifying statefulset ss doesn't scale past 0 for another 3.934852272s
  I0115 01:32:07.574000 24 statefulset.go:2421] Verifying statefulset ss doesn't scale past 0 for another 2.931258388s
  I0115 01:32:08.580303 24 statefulset.go:2421] Verifying statefulset ss doesn't scale past 0 for another 1.927352874s
  I0115 01:32:09.595518 24 statefulset.go:2421] Verifying statefulset ss doesn't scale past 0 for another 921.208885ms
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-3731 @ 01/15/25 01:32:10.596
  I0115 01:32:10.600298 24 rest.go:152] Scaling statefulset ss to 0
  I0115 01:32:10.605487 24 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I0115 01:32:10.608038 24 statefulset.go:138] Deleting all statefulset in ns statefulset-3731
  I0115 01:32:10.611265 24 rest.go:152] Scaling statefulset ss to 0
  I0115 01:32:10.616192 24 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I0115 01:32:10.618565 24 rest.go:90] Deleting statefulset ss
  I0115 01:32:10.629778 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-3731" for this suite. @ 01/15/25 01:32:10.634
• [51.688 seconds]
------------------------------
[sig-network] Proxy version v1 should proxy through a service and a pod [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/proxy.go:101
  STEP: Creating a kubernetes client @ 01/15/25 01:32:10.638
  I0115 01:32:10.639049 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename proxy @ 01/15/25 01:32:10.64
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:32:10.652
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:32:10.657
  STEP: starting an echo server on multiple ports @ 01/15/25 01:32:10.671
  STEP: creating replication controller proxy-service-2m4rj in namespace proxy-9085 @ 01/15/25 01:32:10.671
  I0115 01:32:10.681772      24 runners.go:193] Created replication controller with name: proxy-service-2m4rj, namespace: proxy-9085, replica count: 1
  I0115 01:32:11.733485      24 runners.go:193] proxy-service-2m4rj Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0115 01:32:12.735360      24 runners.go:193] proxy-service-2m4rj Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0115 01:32:12.748012 24 proxy.go:230] setup took 2.086502179s, starting test cases
  STEP: running 16 cases, 20 attempts per case, 320 total attempts @ 01/15/25 01:32:12.748
  I0115 01:32:12.802772 24 proxy.go:558] (0) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss/proxy/rewriteme">test</a> (200; 52.178522ms)
  I0115 01:32:12.806890 24 proxy.go:558] (0) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:160/proxy/: foo (200; 55.625412ms)
  I0115 01:32:12.806980 24 proxy.go:558] (0) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:160/proxy/: foo (200; 57.824363ms)
  I0115 01:32:12.808688 24 proxy.go:558] (0) /api/v1/namespaces/proxy-9085/services/proxy-service-2m4rj:portname2/proxy/: bar (200; 57.147547ms)
  I0115 01:32:12.808765 24 proxy.go:558] (0) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:162/proxy/: bar (200; 57.774528ms)
  I0115 01:32:12.809155 24 proxy.go:558] (0) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:1080/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:1080/proxy/rewriteme">test<... (200; 59.610247ms)
  I0115 01:32:12.813259 24 proxy.go:558] (0) /api/v1/namespaces/proxy-9085/services/http:proxy-service-2m4rj:portname2/proxy/: bar (200; 63.860142ms)
  I0115 01:32:12.813599 24 proxy.go:558] (0) /api/v1/namespaces/proxy-9085/services/proxy-service-2m4rj:portname1/proxy/: foo (200; 61.960294ms)
  I0115 01:32:12.818805 24 proxy.go:558] (0) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:1080/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:1080/proxy/rewriteme">... (200; 67.653211ms)
  I0115 01:32:12.818885 24 proxy.go:558] (0) /api/v1/namespaces/proxy-9085/services/http:proxy-service-2m4rj:portname1/proxy/: foo (200; 68.579386ms)
  I0115 01:32:12.818927 24 proxy.go:558] (0) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:162/proxy/: bar (200; 67.543202ms)
  I0115 01:32:12.818953 24 proxy.go:558] (0) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:462/proxy/: tls qux (200; 69.146656ms)
  I0115 01:32:12.819143 24 proxy.go:558] (0) /api/v1/namespaces/proxy-9085/services/https:proxy-service-2m4rj:tlsportname2/proxy/: tls qux (200; 68.673134ms)
  I0115 01:32:12.821535 24 proxy.go:558] (0) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:460/proxy/: tls baz (200; 71.870281ms)
  I0115 01:32:12.821636 24 proxy.go:558] (0) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:443/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:443/proxy/tlsrewritem... (200; 73.183123ms)
  I0115 01:32:12.821886 24 proxy.go:558] (0) /api/v1/namespaces/proxy-9085/services/https:proxy-service-2m4rj:tlsportname1/proxy/: tls baz (200; 70.267362ms)
  I0115 01:32:12.832960 24 proxy.go:558] (1) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:160/proxy/: foo (200; 11.007894ms)
  I0115 01:32:12.832960 24 proxy.go:558] (1) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:460/proxy/: tls baz (200; 10.466385ms)
  I0115 01:32:12.833016 24 proxy.go:558] (1) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:443/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:443/proxy/tlsrewritem... (200; 10.947448ms)
  I0115 01:32:12.833805 24 proxy.go:558] (1) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:160/proxy/: foo (200; 11.516252ms)
  I0115 01:32:12.835674 24 proxy.go:558] (1) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:462/proxy/: tls qux (200; 13.250186ms)
  I0115 01:32:12.835750 24 proxy.go:558] (1) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss/proxy/rewriteme">test</a> (200; 13.185569ms)
  I0115 01:32:12.835786 24 proxy.go:558] (1) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:1080/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:1080/proxy/rewriteme">test<... (200; 13.329961ms)
  I0115 01:32:12.835821 24 proxy.go:558] (1) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:162/proxy/: bar (200; 13.482148ms)
  I0115 01:32:12.835844 24 proxy.go:558] (1) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:1080/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:1080/proxy/rewriteme">... (200; 13.698922ms)
  I0115 01:32:12.835850 24 proxy.go:558] (1) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:162/proxy/: bar (200; 13.678744ms)
  I0115 01:32:12.840413 24 proxy.go:558] (1) /api/v1/namespaces/proxy-9085/services/proxy-service-2m4rj:portname1/proxy/: foo (200; 18.185273ms)
  I0115 01:32:12.840416 24 proxy.go:558] (1) /api/v1/namespaces/proxy-9085/services/https:proxy-service-2m4rj:tlsportname2/proxy/: tls qux (200; 17.92378ms)
  I0115 01:32:12.840560 24 proxy.go:558] (1) /api/v1/namespaces/proxy-9085/services/http:proxy-service-2m4rj:portname2/proxy/: bar (200; 18.104663ms)
  I0115 01:32:12.840643 24 proxy.go:558] (1) /api/v1/namespaces/proxy-9085/services/https:proxy-service-2m4rj:tlsportname1/proxy/: tls baz (200; 18.262417ms)
  I0115 01:32:12.841345 24 proxy.go:558] (1) /api/v1/namespaces/proxy-9085/services/proxy-service-2m4rj:portname2/proxy/: bar (200; 19.005223ms)
  I0115 01:32:12.841352 24 proxy.go:558] (1) /api/v1/namespaces/proxy-9085/services/http:proxy-service-2m4rj:portname1/proxy/: foo (200; 18.827902ms)
  I0115 01:32:12.847510 24 proxy.go:558] (2) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:162/proxy/: bar (200; 6.043802ms)
  I0115 01:32:12.847589 24 proxy.go:558] (2) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:462/proxy/: tls qux (200; 6.09554ms)
  I0115 01:32:12.854075 24 proxy.go:558] (2) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:160/proxy/: foo (200; 12.121362ms)
  I0115 01:32:12.854178 24 proxy.go:558] (2) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:162/proxy/: bar (200; 12.555707ms)
  I0115 01:32:12.854209 24 proxy.go:558] (2) /api/v1/namespaces/proxy-9085/services/proxy-service-2m4rj:portname1/proxy/: foo (200; 12.551943ms)
  I0115 01:32:12.854233 24 proxy.go:558] (2) /api/v1/namespaces/proxy-9085/services/http:proxy-service-2m4rj:portname2/proxy/: bar (200; 12.585153ms)
  I0115 01:32:12.854258 24 proxy.go:558] (2) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:1080/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:1080/proxy/rewriteme">test<... (200; 12.434722ms)
  I0115 01:32:12.854488 24 proxy.go:558] (2) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:443/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:443/proxy/tlsrewritem... (200; 12.879101ms)
  I0115 01:32:12.854531 24 proxy.go:558] (2) /api/v1/namespaces/proxy-9085/services/https:proxy-service-2m4rj:tlsportname1/proxy/: tls baz (200; 12.991356ms)
  I0115 01:32:12.855679 24 proxy.go:558] (2) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:160/proxy/: foo (200; 13.747009ms)
  I0115 01:32:12.855771 24 proxy.go:558] (2) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:460/proxy/: tls baz (200; 13.931106ms)
  I0115 01:32:12.855798 24 proxy.go:558] (2) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:1080/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:1080/proxy/rewriteme">... (200; 13.883984ms)
  I0115 01:32:12.855820 24 proxy.go:558] (2) /api/v1/namespaces/proxy-9085/services/proxy-service-2m4rj:portname2/proxy/: bar (200; 14.032913ms)
  I0115 01:32:12.855850 24 proxy.go:558] (2) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss/proxy/rewriteme">test</a> (200; 13.986365ms)
  I0115 01:32:12.857424 24 proxy.go:558] (2) /api/v1/namespaces/proxy-9085/services/http:proxy-service-2m4rj:portname1/proxy/: foo (200; 15.541551ms)
  I0115 01:32:12.857504 24 proxy.go:558] (2) /api/v1/namespaces/proxy-9085/services/https:proxy-service-2m4rj:tlsportname2/proxy/: tls qux (200; 15.607123ms)
  I0115 01:32:12.864553 24 proxy.go:558] (3) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:160/proxy/: foo (200; 6.992767ms)
  I0115 01:32:12.864760 24 proxy.go:558] (3) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss/proxy/rewriteme">test</a> (200; 6.823615ms)
  I0115 01:32:12.865601 24 proxy.go:558] (3) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:1080/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:1080/proxy/rewriteme">... (200; 7.882365ms)
  I0115 01:32:12.865622 24 proxy.go:558] (3) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:462/proxy/: tls qux (200; 7.963806ms)
  I0115 01:32:12.865624 24 proxy.go:558] (3) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:1080/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:1080/proxy/rewriteme">test<... (200; 7.864066ms)
  I0115 01:32:12.865643 24 proxy.go:558] (3) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:162/proxy/: bar (200; 7.859406ms)
  I0115 01:32:12.865651 24 proxy.go:558] (3) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:460/proxy/: tls baz (200; 7.86186ms)
  I0115 01:32:12.865654 24 proxy.go:558] (3) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:160/proxy/: foo (200; 7.900051ms)
  I0115 01:32:12.865669 24 proxy.go:558] (3) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:443/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:443/proxy/tlsrewritem... (200; 8.057135ms)
  I0115 01:32:12.865670 24 proxy.go:558] (3) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:162/proxy/: bar (200; 7.855139ms)
  I0115 01:32:12.868785 24 proxy.go:558] (3) /api/v1/namespaces/proxy-9085/services/proxy-service-2m4rj:portname1/proxy/: foo (200; 10.927124ms)
  I0115 01:32:12.868804 24 proxy.go:558] (3) /api/v1/namespaces/proxy-9085/services/http:proxy-service-2m4rj:portname1/proxy/: foo (200; 10.948782ms)
  I0115 01:32:12.868851 24 proxy.go:558] (3) /api/v1/namespaces/proxy-9085/services/http:proxy-service-2m4rj:portname2/proxy/: bar (200; 11.131363ms)
  I0115 01:32:12.868866 24 proxy.go:558] (3) /api/v1/namespaces/proxy-9085/services/https:proxy-service-2m4rj:tlsportname2/proxy/: tls qux (200; 11.04566ms)
  I0115 01:32:12.868864 24 proxy.go:558] (3) /api/v1/namespaces/proxy-9085/services/https:proxy-service-2m4rj:tlsportname1/proxy/: tls baz (200; 10.951416ms)
  I0115 01:32:12.868872 24 proxy.go:558] (3) /api/v1/namespaces/proxy-9085/services/proxy-service-2m4rj:portname2/proxy/: bar (200; 10.982387ms)
  I0115 01:32:12.878670 24 proxy.go:558] (4) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:160/proxy/: foo (200; 9.484753ms)
  I0115 01:32:12.878751 24 proxy.go:558] (4) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:1080/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:1080/proxy/rewriteme">... (200; 9.652586ms)
  I0115 01:32:12.878780 24 proxy.go:558] (4) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss/proxy/rewriteme">test</a> (200; 9.636272ms)
  I0115 01:32:12.879895 24 proxy.go:558] (4) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:460/proxy/: tls baz (200; 10.707319ms)
  I0115 01:32:12.880057 24 proxy.go:558] (4) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:162/proxy/: bar (200; 11.127063ms)
  I0115 01:32:12.880097 24 proxy.go:558] (4) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:443/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:443/proxy/tlsrewritem... (200; 11.014394ms)
  I0115 01:32:12.880124 24 proxy.go:558] (4) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:1080/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:1080/proxy/rewriteme">test<... (200; 10.972952ms)
  I0115 01:32:12.881070 24 proxy.go:558] (4) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:462/proxy/: tls qux (200; 11.854578ms)
  I0115 01:32:12.881160 24 proxy.go:558] (4) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:162/proxy/: bar (200; 11.94431ms)
  I0115 01:32:12.881193 24 proxy.go:558] (4) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:160/proxy/: foo (200; 11.948898ms)
  I0115 01:32:12.882524 24 proxy.go:558] (4) /api/v1/namespaces/proxy-9085/services/proxy-service-2m4rj:portname2/proxy/: bar (200; 13.500851ms)
  I0115 01:32:12.882564 24 proxy.go:558] (4) /api/v1/namespaces/proxy-9085/services/https:proxy-service-2m4rj:tlsportname2/proxy/: tls qux (200; 13.522095ms)
  I0115 01:32:12.882581 24 proxy.go:558] (4) /api/v1/namespaces/proxy-9085/services/http:proxy-service-2m4rj:portname1/proxy/: foo (200; 13.341549ms)
  I0115 01:32:12.882729 24 proxy.go:558] (4) /api/v1/namespaces/proxy-9085/services/http:proxy-service-2m4rj:portname2/proxy/: bar (200; 13.608206ms)
  I0115 01:32:12.882761 24 proxy.go:558] (4) /api/v1/namespaces/proxy-9085/services/https:proxy-service-2m4rj:tlsportname1/proxy/: tls baz (200; 13.825528ms)
  I0115 01:32:12.882786 24 proxy.go:558] (4) /api/v1/namespaces/proxy-9085/services/proxy-service-2m4rj:portname1/proxy/: foo (200; 13.797203ms)
  I0115 01:32:12.888262 24 proxy.go:558] (5) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:162/proxy/: bar (200; 5.436067ms)
  I0115 01:32:12.888422 24 proxy.go:558] (5) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:443/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:443/proxy/tlsrewritem... (200; 4.874802ms)
  I0115 01:32:12.890339 24 proxy.go:558] (5) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:160/proxy/: foo (200; 6.828101ms)
  I0115 01:32:12.891604 24 proxy.go:558] (5) /api/v1/namespaces/proxy-9085/services/proxy-service-2m4rj:portname1/proxy/: foo (200; 8.564768ms)
  I0115 01:32:12.892245 24 proxy.go:558] (5) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:462/proxy/: tls qux (200; 8.590039ms)
  I0115 01:32:12.892288 24 proxy.go:558] (5) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:460/proxy/: tls baz (200; 8.651697ms)
  I0115 01:32:12.893514 24 proxy.go:558] (5) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:1080/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:1080/proxy/rewriteme">... (200; 9.787871ms)
  I0115 01:32:12.893518 24 proxy.go:558] (5) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:1080/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:1080/proxy/rewriteme">test<... (200; 9.831668ms)
  I0115 01:32:12.893550 24 proxy.go:558] (5) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss/proxy/rewriteme">test</a> (200; 9.789777ms)
  I0115 01:32:12.894447 24 proxy.go:558] (5) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:160/proxy/: foo (200; 10.75291ms)
  I0115 01:32:12.894756 24 proxy.go:558] (5) /api/v1/namespaces/proxy-9085/services/https:proxy-service-2m4rj:tlsportname2/proxy/: tls qux (200; 11.17527ms)
  I0115 01:32:12.894765 24 proxy.go:558] (5) /api/v1/namespaces/proxy-9085/services/proxy-service-2m4rj:portname2/proxy/: bar (200; 11.560984ms)
  I0115 01:32:12.894787 24 proxy.go:558] (5) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:162/proxy/: bar (200; 11.068012ms)
  I0115 01:32:12.896265 24 proxy.go:558] (5) /api/v1/namespaces/proxy-9085/services/http:proxy-service-2m4rj:portname1/proxy/: foo (200; 12.797382ms)
  I0115 01:32:12.896265 24 proxy.go:558] (5) /api/v1/namespaces/proxy-9085/services/https:proxy-service-2m4rj:tlsportname1/proxy/: tls baz (200; 12.867323ms)
  I0115 01:32:12.896320 24 proxy.go:558] (5) /api/v1/namespaces/proxy-9085/services/http:proxy-service-2m4rj:portname2/proxy/: bar (200; 12.718923ms)
  I0115 01:32:12.902041 24 proxy.go:558] (6) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:443/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:443/proxy/tlsrewritem... (200; 5.619989ms)
  I0115 01:32:12.903506 24 proxy.go:558] (6) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:160/proxy/: foo (200; 6.886093ms)
  I0115 01:32:12.903494 24 proxy.go:558] (6) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:1080/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:1080/proxy/rewriteme">test<... (200; 6.942441ms)
  I0115 01:32:12.905984 24 proxy.go:558] (6) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:460/proxy/: tls baz (200; 9.394771ms)
  I0115 01:32:12.906219 24 proxy.go:558] (6) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss/proxy/rewriteme">test</a> (200; 9.499037ms)
  I0115 01:32:12.906886 24 proxy.go:558] (6) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:160/proxy/: foo (200; 10.134509ms)
  I0115 01:32:12.907044 24 proxy.go:558] (6) /api/v1/namespaces/proxy-9085/services/http:proxy-service-2m4rj:portname2/proxy/: bar (200; 10.550117ms)
  I0115 01:32:12.907036 24 proxy.go:558] (6) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:1080/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:1080/proxy/rewriteme">... (200; 10.250893ms)
  I0115 01:32:12.908180 24 proxy.go:558] (6) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:162/proxy/: bar (200; 11.325098ms)
  I0115 01:32:12.911261 24 proxy.go:558] (6) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:462/proxy/: tls qux (200; 14.839985ms)
  I0115 01:32:12.911279 24 proxy.go:558] (6) /api/v1/namespaces/proxy-9085/services/https:proxy-service-2m4rj:tlsportname1/proxy/: tls baz (200; 14.299468ms)
  I0115 01:32:12.911313 24 proxy.go:558] (6) /api/v1/namespaces/proxy-9085/services/proxy-service-2m4rj:portname1/proxy/: foo (200; 14.508301ms)
  I0115 01:32:12.913956 24 proxy.go:558] (6) /api/v1/namespaces/proxy-9085/services/proxy-service-2m4rj:portname2/proxy/: bar (200; 16.928264ms)
  I0115 01:32:12.914384 24 proxy.go:558] (6) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:162/proxy/: bar (200; 17.551379ms)
  I0115 01:32:12.914976 24 proxy.go:558] (6) /api/v1/namespaces/proxy-9085/services/http:proxy-service-2m4rj:portname1/proxy/: foo (200; 18.320833ms)
  I0115 01:32:12.915798 24 proxy.go:558] (6) /api/v1/namespaces/proxy-9085/services/https:proxy-service-2m4rj:tlsportname2/proxy/: tls qux (200; 19.109799ms)
  I0115 01:32:12.921966 24 proxy.go:558] (7) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:162/proxy/: bar (200; 6.053391ms)
  I0115 01:32:12.922053 24 proxy.go:558] (7) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:462/proxy/: tls qux (200; 6.133378ms)
  I0115 01:32:12.930025 24 proxy.go:558] (7) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:160/proxy/: foo (200; 13.896265ms)
  I0115 01:32:12.931112 24 proxy.go:558] (7) /api/v1/namespaces/proxy-9085/services/http:proxy-service-2m4rj:portname1/proxy/: foo (200; 14.916795ms)
  I0115 01:32:12.931178 24 proxy.go:558] (7) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:1080/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:1080/proxy/rewriteme">test<... (200; 15.134931ms)
  I0115 01:32:12.932243 24 proxy.go:558] (7) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:460/proxy/: tls baz (200; 16.15944ms)
  I0115 01:32:12.932742 24 proxy.go:558] (7) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss/proxy/rewriteme">test</a> (200; 16.579331ms)
  I0115 01:32:12.933015 24 proxy.go:558] (7) /api/v1/namespaces/proxy-9085/services/http:proxy-service-2m4rj:portname2/proxy/: bar (200; 16.873616ms)
  I0115 01:32:12.933161 24 proxy.go:558] (7) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:162/proxy/: bar (200; 16.938275ms)
  I0115 01:32:12.933189 24 proxy.go:558] (7) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:1080/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:1080/proxy/rewriteme">... (200; 16.92513ms)
  I0115 01:32:12.933209 24 proxy.go:558] (7) /api/v1/namespaces/proxy-9085/services/https:proxy-service-2m4rj:tlsportname1/proxy/: tls baz (200; 17.091303ms)
  I0115 01:32:12.933031 24 proxy.go:558] (7) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:160/proxy/: foo (200; 16.836843ms)
  I0115 01:32:12.933234 24 proxy.go:558] (7) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:443/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:443/proxy/tlsrewritem... (200; 17.254794ms)
  I0115 01:32:12.933248 24 proxy.go:558] (7) /api/v1/namespaces/proxy-9085/services/https:proxy-service-2m4rj:tlsportname2/proxy/: tls qux (200; 17.092567ms)
  I0115 01:32:12.933496 24 proxy.go:558] (7) /api/v1/namespaces/proxy-9085/services/proxy-service-2m4rj:portname1/proxy/: foo (200; 17.44981ms)
  I0115 01:32:12.933534 24 proxy.go:558] (7) /api/v1/namespaces/proxy-9085/services/proxy-service-2m4rj:portname2/proxy/: bar (200; 17.450384ms)
  I0115 01:32:12.939530 24 proxy.go:558] (8) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:462/proxy/: tls qux (200; 5.863343ms)
  I0115 01:32:12.939532 24 proxy.go:558] (8) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:443/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:443/proxy/tlsrewritem... (200; 5.752541ms)
  I0115 01:32:12.939571 24 proxy.go:558] (8) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:162/proxy/: bar (200; 6.001596ms)
  I0115 01:32:12.943930 24 proxy.go:558] (8) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:162/proxy/: bar (200; 9.938376ms)
  I0115 01:32:12.944851 24 proxy.go:558] (8) /api/v1/namespaces/proxy-9085/services/proxy-service-2m4rj:portname2/proxy/: bar (200; 11.015842ms)
  I0115 01:32:12.944964 24 proxy.go:558] (8) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:460/proxy/: tls baz (200; 11.098352ms)
  I0115 01:32:12.945094 24 proxy.go:558] (8) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:1080/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:1080/proxy/rewriteme">... (200; 11.152774ms)
  I0115 01:32:12.945143 24 proxy.go:558] (8) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:160/proxy/: foo (200; 11.273877ms)
  I0115 01:32:12.945140 24 proxy.go:558] (8) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss/proxy/rewriteme">test</a> (200; 11.227188ms)
  I0115 01:32:12.945184 24 proxy.go:558] (8) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:160/proxy/: foo (200; 11.274032ms)
  I0115 01:32:12.947247 24 proxy.go:558] (8) /api/v1/namespaces/proxy-9085/services/http:proxy-service-2m4rj:portname2/proxy/: bar (200; 13.449437ms)
  I0115 01:32:12.947966 24 proxy.go:558] (8) /api/v1/namespaces/proxy-9085/services/proxy-service-2m4rj:portname1/proxy/: foo (200; 14.220736ms)
  I0115 01:32:12.947966 24 proxy.go:558] (8) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:1080/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:1080/proxy/rewriteme">test<... (200; 14.134604ms)
  I0115 01:32:12.948011 24 proxy.go:558] (8) /api/v1/namespaces/proxy-9085/services/http:proxy-service-2m4rj:portname1/proxy/: foo (200; 14.06205ms)
  I0115 01:32:12.948222 24 proxy.go:558] (8) /api/v1/namespaces/proxy-9085/services/https:proxy-service-2m4rj:tlsportname2/proxy/: tls qux (200; 14.312777ms)
  I0115 01:32:12.948534 24 proxy.go:558] (8) /api/v1/namespaces/proxy-9085/services/https:proxy-service-2m4rj:tlsportname1/proxy/: tls baz (200; 14.700239ms)
  I0115 01:32:12.957889 24 proxy.go:558] (9) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:1080/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:1080/proxy/rewriteme">... (200; 9.1304ms)
  I0115 01:32:12.959337 24 proxy.go:558] (9) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:462/proxy/: tls qux (200; 10.278818ms)
  I0115 01:32:12.959401 24 proxy.go:558] (9) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:1080/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:1080/proxy/rewriteme">test<... (200; 10.306749ms)
  I0115 01:32:12.959670 24 proxy.go:558] (9) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:443/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:443/proxy/tlsrewritem... (200; 10.993277ms)
  I0115 01:32:12.959715 24 proxy.go:558] (9) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:160/proxy/: foo (200; 10.848751ms)
  I0115 01:32:12.959741 24 proxy.go:558] (9) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:160/proxy/: foo (200; 11.144039ms)
  I0115 01:32:12.959763 24 proxy.go:558] (9) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss/proxy/rewriteme">test</a> (200; 10.536019ms)
  I0115 01:32:12.960220 24 proxy.go:558] (9) /api/v1/namespaces/proxy-9085/services/proxy-service-2m4rj:portname2/proxy/: bar (200; 11.22115ms)
  I0115 01:32:12.961231 24 proxy.go:558] (9) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:162/proxy/: bar (200; 12.184763ms)
  I0115 01:32:12.961295 24 proxy.go:558] (9) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:460/proxy/: tls baz (200; 12.172284ms)
  I0115 01:32:12.961335 24 proxy.go:558] (9) /api/v1/namespaces/proxy-9085/services/http:proxy-service-2m4rj:portname1/proxy/: foo (200; 12.146865ms)
  I0115 01:32:12.961807 24 proxy.go:558] (9) /api/v1/namespaces/proxy-9085/services/http:proxy-service-2m4rj:portname2/proxy/: bar (200; 12.728535ms)
  I0115 01:32:12.962099 24 proxy.go:558] (9) /api/v1/namespaces/proxy-9085/services/proxy-service-2m4rj:portname1/proxy/: foo (200; 13.121513ms)
  I0115 01:32:12.962149 24 proxy.go:558] (9) /api/v1/namespaces/proxy-9085/services/https:proxy-service-2m4rj:tlsportname1/proxy/: tls baz (200; 13.126459ms)
  I0115 01:32:12.962302 24 proxy.go:558] (9) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:162/proxy/: bar (200; 13.347056ms)
  I0115 01:32:12.962390 24 proxy.go:558] (9) /api/v1/namespaces/proxy-9085/services/https:proxy-service-2m4rj:tlsportname2/proxy/: tls qux (200; 13.23325ms)
  I0115 01:32:12.969908 24 proxy.go:558] (10) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:443/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:443/proxy/tlsrewritem... (200; 7.443775ms)
  I0115 01:32:12.970119 24 proxy.go:558] (10) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:460/proxy/: tls baz (200; 7.613891ms)
  I0115 01:32:12.972235 24 proxy.go:558] (10) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:462/proxy/: tls qux (200; 9.623157ms)
  I0115 01:32:12.972498 24 proxy.go:558] (10) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:1080/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:1080/proxy/rewriteme">... (200; 9.607521ms)
  I0115 01:32:12.972781 24 proxy.go:558] (10) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:162/proxy/: bar (200; 10.057599ms)
  I0115 01:32:12.973208 24 proxy.go:558] (10) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:1080/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:1080/proxy/rewriteme">test<... (200; 10.604576ms)
  I0115 01:32:12.973266 24 proxy.go:558] (10) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss/proxy/rewriteme">test</a> (200; 10.524052ms)
  I0115 01:32:12.973418 24 proxy.go:558] (10) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:160/proxy/: foo (200; 10.640529ms)
  I0115 01:32:12.976162 24 proxy.go:558] (10) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:160/proxy/: foo (200; 13.26921ms)
  I0115 01:32:12.976175 24 proxy.go:558] (10) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:162/proxy/: bar (200; 13.207692ms)
  I0115 01:32:12.979148 24 proxy.go:558] (10) /api/v1/namespaces/proxy-9085/services/https:proxy-service-2m4rj:tlsportname2/proxy/: tls qux (200; 16.617062ms)
  I0115 01:32:12.982093 24 proxy.go:558] (10) /api/v1/namespaces/proxy-9085/services/http:proxy-service-2m4rj:portname2/proxy/: bar (200; 19.527303ms)
  I0115 01:32:12.987283 24 proxy.go:558] (10) /api/v1/namespaces/proxy-9085/services/proxy-service-2m4rj:portname1/proxy/: foo (200; 24.354789ms)
  I0115 01:32:12.987422 24 proxy.go:558] (10) /api/v1/namespaces/proxy-9085/services/proxy-service-2m4rj:portname2/proxy/: bar (200; 24.462265ms)
  I0115 01:32:12.987675 24 proxy.go:558] (10) /api/v1/namespaces/proxy-9085/services/https:proxy-service-2m4rj:tlsportname1/proxy/: tls baz (200; 24.678567ms)
  I0115 01:32:12.988804 24 proxy.go:558] (10) /api/v1/namespaces/proxy-9085/services/http:proxy-service-2m4rj:portname1/proxy/: foo (200; 26.165059ms)
  I0115 01:32:13.006922 24 proxy.go:558] (11) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:162/proxy/: bar (200; 18.024326ms)
  I0115 01:32:13.006992 24 proxy.go:558] (11) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:443/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:443/proxy/tlsrewritem... (200; 17.33573ms)
  I0115 01:32:13.019000 24 proxy.go:558] (11) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:160/proxy/: foo (200; 28.576006ms)
  I0115 01:32:13.019549 24 proxy.go:558] (11) /api/v1/namespaces/proxy-9085/services/https:proxy-service-2m4rj:tlsportname1/proxy/: tls baz (200; 30.053253ms)
  I0115 01:32:13.020458 24 proxy.go:558] (11) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:1080/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:1080/proxy/rewriteme">test<... (200; 30.420655ms)
  I0115 01:32:13.020538 24 proxy.go:558] (11) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:462/proxy/: tls qux (200; 30.153477ms)
  I0115 01:32:13.020598 24 proxy.go:558] (11) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:160/proxy/: foo (200; 30.025395ms)
  I0115 01:32:13.020624 24 proxy.go:558] (11) /api/v1/namespaces/proxy-9085/services/proxy-service-2m4rj:portname2/proxy/: bar (200; 31.313539ms)
  I0115 01:32:13.020642 24 proxy.go:558] (11) /api/v1/namespaces/proxy-9085/services/proxy-service-2m4rj:portname1/proxy/: foo (200; 31.502439ms)
  I0115 01:32:13.021746 24 proxy.go:558] (11) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss/proxy/rewriteme">test</a> (200; 31.254308ms)
  I0115 01:32:13.021819 24 proxy.go:558] (11) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:162/proxy/: bar (200; 31.206466ms)
  I0115 01:32:13.021843 24 proxy.go:558] (11) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:1080/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:1080/proxy/rewriteme">... (200; 31.266508ms)
  I0115 01:32:13.021925 24 proxy.go:558] (11) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:460/proxy/: tls baz (200; 31.715883ms)
  I0115 01:32:13.032755 24 proxy.go:558] (11) /api/v1/namespaces/proxy-9085/services/http:proxy-service-2m4rj:portname1/proxy/: foo (200; 42.212751ms)
  I0115 01:32:13.032872 24 proxy.go:558] (11) /api/v1/namespaces/proxy-9085/services/http:proxy-service-2m4rj:portname2/proxy/: bar (200; 43.048728ms)
  I0115 01:32:13.032977 24 proxy.go:558] (11) /api/v1/namespaces/proxy-9085/services/https:proxy-service-2m4rj:tlsportname2/proxy/: tls qux (200; 42.474976ms)
  I0115 01:32:13.052128 24 proxy.go:558] (12) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:1080/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:1080/proxy/rewriteme">test<... (200; 18.274261ms)
  I0115 01:32:13.052197 24 proxy.go:558] (12) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:460/proxy/: tls baz (200; 18.153682ms)
  I0115 01:32:13.052228 24 proxy.go:558] (12) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss/proxy/rewriteme">test</a> (200; 16.794961ms)
  I0115 01:32:13.052249 24 proxy.go:558] (12) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:462/proxy/: tls qux (200; 18.96042ms)
  I0115 01:32:13.052292 24 proxy.go:558] (12) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:443/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:443/proxy/tlsrewritem... (200; 15.688815ms)
  I0115 01:32:13.052328 24 proxy.go:558] (12) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:160/proxy/: foo (200; 16.132339ms)
  I0115 01:32:13.054979 24 proxy.go:558] (12) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:162/proxy/: bar (200; 18.545551ms)
  I0115 01:32:13.055051 24 proxy.go:558] (12) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:160/proxy/: foo (200; 20.500419ms)
  I0115 01:32:13.055080 24 proxy.go:558] (12) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:1080/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:1080/proxy/rewriteme">... (200; 19.135575ms)
  I0115 01:32:13.055541 24 proxy.go:558] (12) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:162/proxy/: bar (200; 19.801211ms)
  I0115 01:32:13.055676 24 proxy.go:558] (12) /api/v1/namespaces/proxy-9085/services/https:proxy-service-2m4rj:tlsportname1/proxy/: tls baz (200; 22.630179ms)
  I0115 01:32:13.055673 24 proxy.go:558] (12) /api/v1/namespaces/proxy-9085/services/http:proxy-service-2m4rj:portname2/proxy/: bar (200; 22.110279ms)
  I0115 01:32:13.060866 24 proxy.go:558] (12) /api/v1/namespaces/proxy-9085/services/proxy-service-2m4rj:portname1/proxy/: foo (200; 23.964436ms)
  I0115 01:32:13.064023 24 proxy.go:558] (12) /api/v1/namespaces/proxy-9085/services/https:proxy-service-2m4rj:tlsportname2/proxy/: tls qux (200; 28.866353ms)
  I0115 01:32:13.065121 24 proxy.go:558] (12) /api/v1/namespaces/proxy-9085/services/http:proxy-service-2m4rj:portname1/proxy/: foo (200; 30.204057ms)
  I0115 01:32:13.069953 24 proxy.go:558] (12) /api/v1/namespaces/proxy-9085/services/proxy-service-2m4rj:portname2/proxy/: bar (200; 32.78351ms)
  I0115 01:32:13.092996 24 proxy.go:558] (13) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:160/proxy/: foo (200; 22.921503ms)
  I0115 01:32:13.093009 24 proxy.go:558] (13) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:1080/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:1080/proxy/rewriteme">test<... (200; 22.359628ms)
  I0115 01:32:13.093064 24 proxy.go:558] (13) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:162/proxy/: bar (200; 22.68233ms)
  I0115 01:32:13.093078 24 proxy.go:558] (13) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:462/proxy/: tls qux (200; 22.480508ms)
  I0115 01:32:13.093091 24 proxy.go:558] (13) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:443/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:443/proxy/tlsrewritem... (200; 22.90733ms)
  I0115 01:32:13.095764 24 proxy.go:558] (13) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:160/proxy/: foo (200; 25.448063ms)
  I0115 01:32:13.095834 24 proxy.go:558] (13) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss/proxy/rewriteme">test</a> (200; 25.058886ms)
  I0115 01:32:13.095870 24 proxy.go:558] (13) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:1080/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:1080/proxy/rewriteme">... (200; 25.613852ms)
  I0115 01:32:13.095881 24 proxy.go:558] (13) /api/v1/namespaces/proxy-9085/services/http:proxy-service-2m4rj:portname1/proxy/: foo (200; 25.012605ms)
  I0115 01:32:13.096306 24 proxy.go:558] (13) /api/v1/namespaces/proxy-9085/services/https:proxy-service-2m4rj:tlsportname1/proxy/: tls baz (200; 25.804552ms)
  I0115 01:32:13.096319 24 proxy.go:558] (13) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:162/proxy/: bar (200; 25.968528ms)
  I0115 01:32:13.099112 24 proxy.go:558] (13) /api/v1/namespaces/proxy-9085/services/proxy-service-2m4rj:portname2/proxy/: bar (200; 28.644524ms)
  I0115 01:32:13.100449 24 proxy.go:558] (13) /api/v1/namespaces/proxy-9085/services/http:proxy-service-2m4rj:portname2/proxy/: bar (200; 29.849211ms)
  I0115 01:32:13.100582 24 proxy.go:558] (13) /api/v1/namespaces/proxy-9085/services/proxy-service-2m4rj:portname1/proxy/: foo (200; 30.159336ms)
  I0115 01:32:13.100586 24 proxy.go:558] (13) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:460/proxy/: tls baz (200; 29.907326ms)
  I0115 01:32:13.102620 24 proxy.go:558] (13) /api/v1/namespaces/proxy-9085/services/https:proxy-service-2m4rj:tlsportname2/proxy/: tls qux (200; 31.904146ms)
  I0115 01:32:13.113895 24 proxy.go:558] (14) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:162/proxy/: bar (200; 11.163148ms)
  I0115 01:32:13.113891 24 proxy.go:558] (14) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:462/proxy/: tls qux (200; 11.136413ms)
  I0115 01:32:13.119690 24 proxy.go:558] (14) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:160/proxy/: foo (200; 16.31083ms)
  I0115 01:32:13.119727 24 proxy.go:558] (14) /api/v1/namespaces/proxy-9085/services/proxy-service-2m4rj:portname1/proxy/: foo (200; 16.903963ms)
  I0115 01:32:13.119690 24 proxy.go:558] (14) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:162/proxy/: bar (200; 16.198514ms)
  I0115 01:32:13.120696 24 proxy.go:558] (14) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:160/proxy/: foo (200; 17.568183ms)
  I0115 01:32:13.120696 24 proxy.go:558] (14) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:443/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:443/proxy/tlsrewritem... (200; 17.725363ms)
  I0115 01:32:13.120758 24 proxy.go:558] (14) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss/proxy/rewriteme">test</a> (200; 17.51923ms)
  I0115 01:32:13.120805 24 proxy.go:558] (14) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:1080/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:1080/proxy/rewriteme">... (200; 17.370141ms)
  I0115 01:32:13.120807 24 proxy.go:558] (14) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:1080/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:1080/proxy/rewriteme">test<... (200; 17.777882ms)
  I0115 01:32:13.120843 24 proxy.go:558] (14) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:460/proxy/: tls baz (200; 17.771882ms)
  I0115 01:32:13.123746 24 proxy.go:558] (14) /api/v1/namespaces/proxy-9085/services/https:proxy-service-2m4rj:tlsportname1/proxy/: tls baz (200; 20.825323ms)
  I0115 01:32:13.123843 24 proxy.go:558] (14) /api/v1/namespaces/proxy-9085/services/proxy-service-2m4rj:portname2/proxy/: bar (200; 20.968058ms)
  I0115 01:32:13.124075 24 proxy.go:558] (14) /api/v1/namespaces/proxy-9085/services/http:proxy-service-2m4rj:portname1/proxy/: foo (200; 20.914382ms)
  I0115 01:32:13.124080 24 proxy.go:558] (14) /api/v1/namespaces/proxy-9085/services/https:proxy-service-2m4rj:tlsportname2/proxy/: tls qux (200; 20.87766ms)
  I0115 01:32:13.124181 24 proxy.go:558] (14) /api/v1/namespaces/proxy-9085/services/http:proxy-service-2m4rj:portname2/proxy/: bar (200; 21.190117ms)
  I0115 01:32:13.131598 24 proxy.go:558] (15) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:162/proxy/: bar (200; 7.358624ms)
  I0115 01:32:13.132048 24 proxy.go:558] (15) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:460/proxy/: tls baz (200; 7.618336ms)
  I0115 01:32:13.132128 24 proxy.go:558] (15) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:1080/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:1080/proxy/rewriteme">test<... (200; 7.741094ms)
  I0115 01:32:13.139939 24 proxy.go:558] (15) /api/v1/namespaces/proxy-9085/services/proxy-service-2m4rj:portname1/proxy/: foo (200; 15.588977ms)
  I0115 01:32:13.140022 24 proxy.go:558] (15) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:162/proxy/: bar (200; 15.418241ms)
  I0115 01:32:13.140054 24 proxy.go:558] (15) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss/proxy/rewriteme">test</a> (200; 15.508092ms)
  I0115 01:32:13.140096 24 proxy.go:558] (15) /api/v1/namespaces/proxy-9085/services/http:proxy-service-2m4rj:portname2/proxy/: bar (200; 15.84371ms)
  I0115 01:32:13.140332 24 proxy.go:558] (15) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:160/proxy/: foo (200; 15.768308ms)
  I0115 01:32:13.140395 24 proxy.go:558] (15) /api/v1/namespaces/proxy-9085/services/https:proxy-service-2m4rj:tlsportname1/proxy/: tls baz (200; 15.96779ms)
  I0115 01:32:13.140425 24 proxy.go:558] (15) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:462/proxy/: tls qux (200; 15.958928ms)
  I0115 01:32:13.140473 24 proxy.go:558] (15) /api/v1/namespaces/proxy-9085/services/https:proxy-service-2m4rj:tlsportname2/proxy/: tls qux (200; 16.152389ms)
  I0115 01:32:13.140511 24 proxy.go:558] (15) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:443/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:443/proxy/tlsrewritem... (200; 16.045433ms)
  I0115 01:32:13.140749 24 proxy.go:558] (15) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:160/proxy/: foo (200; 16.161529ms)
  I0115 01:32:13.140945 24 proxy.go:558] (15) /api/v1/namespaces/proxy-9085/services/proxy-service-2m4rj:portname2/proxy/: bar (200; 16.558299ms)
  I0115 01:32:13.141771 24 proxy.go:558] (15) /api/v1/namespaces/proxy-9085/services/http:proxy-service-2m4rj:portname1/proxy/: foo (200; 17.251741ms)
  I0115 01:32:13.141771 24 proxy.go:558] (15) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:1080/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:1080/proxy/rewriteme">... (200; 17.261416ms)
  I0115 01:32:13.150171 24 proxy.go:558] (16) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:162/proxy/: bar (200; 8.112007ms)
  I0115 01:32:13.150187 24 proxy.go:558] (16) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss/proxy/rewriteme">test</a> (200; 8.184254ms)
  I0115 01:32:13.153338 24 proxy.go:558] (16) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:160/proxy/: foo (200; 11.183476ms)
  I0115 01:32:13.153410 24 proxy.go:558] (16) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:1080/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:1080/proxy/rewriteme">... (200; 11.313405ms)
  I0115 01:32:13.153977 24 proxy.go:558] (16) /api/v1/namespaces/proxy-9085/services/https:proxy-service-2m4rj:tlsportname2/proxy/: tls qux (200; 12.024632ms)
  I0115 01:32:13.154111 24 proxy.go:558] (16) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:462/proxy/: tls qux (200; 11.592737ms)
  I0115 01:32:13.155538 24 proxy.go:558] (16) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:1080/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:1080/proxy/rewriteme">test<... (200; 13.169321ms)
  I0115 01:32:13.156021 24 proxy.go:558] (16) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:160/proxy/: foo (200; 13.404897ms)
  I0115 01:32:13.156451 24 proxy.go:558] (16) /api/v1/namespaces/proxy-9085/services/http:proxy-service-2m4rj:portname1/proxy/: foo (200; 14.580085ms)
  I0115 01:32:13.157412 24 proxy.go:558] (16) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:162/proxy/: bar (200; 15.208833ms)
  I0115 01:32:13.157474 24 proxy.go:558] (16) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:460/proxy/: tls baz (200; 14.82226ms)
  I0115 01:32:13.157499 24 proxy.go:558] (16) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:443/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:443/proxy/tlsrewritem... (200; 15.257246ms)
  I0115 01:32:13.157754 24 proxy.go:558] (16) /api/v1/namespaces/proxy-9085/services/https:proxy-service-2m4rj:tlsportname1/proxy/: tls baz (200; 15.893986ms)
  I0115 01:32:13.157807 24 proxy.go:558] (16) /api/v1/namespaces/proxy-9085/services/http:proxy-service-2m4rj:portname2/proxy/: bar (200; 15.232771ms)
  I0115 01:32:13.158600 24 proxy.go:558] (16) /api/v1/namespaces/proxy-9085/services/proxy-service-2m4rj:portname1/proxy/: foo (200; 16.320346ms)
  I0115 01:32:13.158827 24 proxy.go:558] (16) /api/v1/namespaces/proxy-9085/services/proxy-service-2m4rj:portname2/proxy/: bar (200; 16.506982ms)
  I0115 01:32:13.170621 24 proxy.go:558] (17) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:162/proxy/: bar (200; 11.497039ms)
  I0115 01:32:13.171065 24 proxy.go:558] (17) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:1080/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:1080/proxy/rewriteme">... (200; 11.893626ms)
  I0115 01:32:13.171137 24 proxy.go:558] (17) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:162/proxy/: bar (200; 12.075342ms)
  I0115 01:32:13.173619 24 proxy.go:558] (17) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:160/proxy/: foo (200; 14.404315ms)
  I0115 01:32:13.173722 24 proxy.go:558] (17) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:443/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:443/proxy/tlsrewritem... (200; 14.444797ms)
  I0115 01:32:13.173684 24 proxy.go:558] (17) /api/v1/namespaces/proxy-9085/services/https:proxy-service-2m4rj:tlsportname1/proxy/: tls baz (200; 14.43727ms)
  I0115 01:32:13.173773 24 proxy.go:558] (17) /api/v1/namespaces/proxy-9085/services/proxy-service-2m4rj:portname1/proxy/: foo (200; 14.467437ms)
  I0115 01:32:13.173774 24 proxy.go:558] (17) /api/v1/namespaces/proxy-9085/services/http:proxy-service-2m4rj:portname2/proxy/: bar (200; 14.309219ms)
  I0115 01:32:13.173816 24 proxy.go:558] (17) /api/v1/namespaces/proxy-9085/services/proxy-service-2m4rj:portname2/proxy/: bar (200; 14.867663ms)
  I0115 01:32:13.173843 24 proxy.go:558] (17) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:460/proxy/: tls baz (200; 14.456303ms)
  I0115 01:32:13.173809 24 proxy.go:558] (17) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:1080/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:1080/proxy/rewriteme">test<... (200; 14.457694ms)
  I0115 01:32:13.173874 24 proxy.go:558] (17) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:462/proxy/: tls qux (200; 14.440417ms)
  I0115 01:32:13.175786 24 proxy.go:558] (17) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss/proxy/rewriteme">test</a> (200; 16.14247ms)
  I0115 01:32:13.175862 24 proxy.go:558] (17) /api/v1/namespaces/proxy-9085/services/https:proxy-service-2m4rj:tlsportname2/proxy/: tls qux (200; 16.939785ms)
  I0115 01:32:13.176195 24 proxy.go:558] (17) /api/v1/namespaces/proxy-9085/services/http:proxy-service-2m4rj:portname1/proxy/: foo (200; 16.49685ms)
  I0115 01:32:13.176233 24 proxy.go:558] (17) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:160/proxy/: foo (200; 16.656219ms)
  I0115 01:32:13.183435 24 proxy.go:558] (18) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:1080/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:1080/proxy/rewriteme">... (200; 7.163128ms)
  I0115 01:32:13.183923 24 proxy.go:558] (18) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:443/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:443/proxy/tlsrewritem... (200; 6.835053ms)
  I0115 01:32:13.190446 24 proxy.go:558] (18) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:162/proxy/: bar (200; 12.190253ms)
  I0115 01:32:13.190582 24 proxy.go:558] (18) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:460/proxy/: tls baz (200; 12.043472ms)
  I0115 01:32:13.190618 24 proxy.go:558] (18) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:160/proxy/: foo (200; 12.612662ms)
  I0115 01:32:13.190810 24 proxy.go:558] (18) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:1080/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:1080/proxy/rewriteme">test<... (200; 13.256955ms)
  I0115 01:32:13.191203 24 proxy.go:558] (18) /api/v1/namespaces/proxy-9085/services/proxy-service-2m4rj:portname1/proxy/: foo (200; 13.905223ms)
  I0115 01:32:13.191203 24 proxy.go:558] (18) /api/v1/namespaces/proxy-9085/services/https:proxy-service-2m4rj:tlsportname1/proxy/: tls baz (200; 14.372937ms)
  I0115 01:32:13.191242 24 proxy.go:558] (18) /api/v1/namespaces/proxy-9085/services/proxy-service-2m4rj:portname2/proxy/: bar (200; 14.627902ms)
  I0115 01:32:13.191288 24 proxy.go:558] (18) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:462/proxy/: tls qux (200; 12.807012ms)
  I0115 01:32:13.191317 24 proxy.go:558] (18) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:160/proxy/: foo (200; 13.571807ms)
  I0115 01:32:13.191343 24 proxy.go:558] (18) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss/proxy/rewriteme">test</a> (200; 13.735497ms)
  I0115 01:32:13.191372 24 proxy.go:558] (18) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:162/proxy/: bar (200; 12.974748ms)
  I0115 01:32:13.195265 24 proxy.go:558] (18) /api/v1/namespaces/proxy-9085/services/http:proxy-service-2m4rj:portname1/proxy/: foo (200; 17.320095ms)
  I0115 01:32:13.195382 24 proxy.go:558] (18) /api/v1/namespaces/proxy-9085/services/http:proxy-service-2m4rj:portname2/proxy/: bar (200; 16.596519ms)
  I0115 01:32:13.195420 24 proxy.go:558] (18) /api/v1/namespaces/proxy-9085/services/https:proxy-service-2m4rj:tlsportname2/proxy/: tls qux (200; 16.493065ms)
  I0115 01:32:13.204950 24 proxy.go:558] (19) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:160/proxy/: foo (200; 8.865798ms)
  I0115 01:32:13.205071 24 proxy.go:558] (19) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:1080/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:1080/proxy/rewriteme">... (200; 9.342595ms)
  I0115 01:32:13.205110 24 proxy.go:558] (19) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:160/proxy/: foo (200; 9.640474ms)
  I0115 01:32:13.209494 24 proxy.go:558] (19) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:162/proxy/: bar (200; 13.030123ms)
  I0115 01:32:13.209681 24 proxy.go:558] (19) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss/proxy/rewriteme">test</a> (200; 9.998793ms)
  I0115 01:32:13.209740 24 proxy.go:558] (19) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:462/proxy/: tls qux (200; 10.836238ms)
  I0115 01:32:13.210923 24 proxy.go:558] (19) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:443/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:443/proxy/tlsrewritem... (200; 13.118416ms)
  I0115 01:32:13.211008 24 proxy.go:558] (19) /api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:1080/proxy/: <a href="/api/v1/namespaces/proxy-9085/pods/proxy-service-2m4rj-dznss:1080/proxy/rewriteme">test<... (200; 12.715038ms)
  I0115 01:32:13.211702 24 proxy.go:558] (19) /api/v1/namespaces/proxy-9085/pods/http:proxy-service-2m4rj-dznss:162/proxy/: bar (200; 15.093963ms)
  I0115 01:32:13.211848 24 proxy.go:558] (19) /api/v1/namespaces/proxy-9085/pods/https:proxy-service-2m4rj-dznss:460/proxy/: tls baz (200; 13.306159ms)
  I0115 01:32:13.211896 24 proxy.go:558] (19) /api/v1/namespaces/proxy-9085/services/proxy-service-2m4rj:portname2/proxy/: bar (200; 14.782593ms)
  I0115 01:32:13.211936 24 proxy.go:558] (19) /api/v1/namespaces/proxy-9085/services/http:proxy-service-2m4rj:portname2/proxy/: bar (200; 13.863225ms)
  I0115 01:32:13.211976 24 proxy.go:558] (19) /api/v1/namespaces/proxy-9085/services/https:proxy-service-2m4rj:tlsportname1/proxy/: tls baz (200; 14.561874ms)
  I0115 01:32:13.212042 24 proxy.go:558] (19) /api/v1/namespaces/proxy-9085/services/http:proxy-service-2m4rj:portname1/proxy/: foo (200; 12.839429ms)
  I0115 01:32:13.212096 24 proxy.go:558] (19) /api/v1/namespaces/proxy-9085/services/https:proxy-service-2m4rj:tlsportname2/proxy/: tls qux (200; 12.643794ms)
  I0115 01:32:13.212682 24 proxy.go:558] (19) /api/v1/namespaces/proxy-9085/services/proxy-service-2m4rj:portname1/proxy/: foo (200; 15.835663ms)
  STEP: deleting ReplicationController proxy-service-2m4rj in namespace proxy-9085, will wait for the garbage collector to delete the pods @ 01/15/25 01:32:13.212
  I0115 01:32:13.275213 24 resources.go:139] Deleting ReplicationController proxy-service-2m4rj took: 7.167548ms
  I0115 01:32:13.376214 24 resources.go:163] Terminating ReplicationController proxy-service-2m4rj pods took: 101.005217ms
  I0115 01:32:16.378521 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-9085" for this suite. @ 01/15/25 01:32:16.401
• [5.785 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceFieldSelectors [Privileged:ClusterAdmin] CustomResourceFieldSelectors MUST list and watch custom resources matching the field selector [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_selectable_fields.go:124
  STEP: Creating a kubernetes client @ 01/15/25 01:32:16.427
  I0115 01:32:16.427871 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename crd-selectable-fields @ 01/15/25 01:32:16.43
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:32:16.449
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:32:16.456
  STEP: Setting up server cert @ 01/15/25 01:32:16.464
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 01/15/25 01:32:16.961
  STEP: Deploying the custom resource conversion webhook pod @ 01/15/25 01:32:16.972
  STEP: Wait for the deployment to be ready @ 01/15/25 01:32:16.989
  I0115 01:32:17.004643 24 deployment.go:223] deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 01/15/25 01:32:19.021
  STEP: Verifying the service has paired with the endpoint @ 01/15/25 01:32:19.032
  I0115 01:32:20.032824 24 util.go:423] Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  STEP: Creating a custom resource definition with selectable fields @ 01/15/25 01:32:20.043
  I0115 01:32:20.043976 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Creating a custom resource conversion webhook @ 01/15/25 01:32:20.566
  STEP: Watching with field selectors @ 01/15/25 01:32:22.673
  STEP: Registering informers with field selectors @ 01/15/25 01:32:22.685
  STEP: Creating custom resources @ 01/15/25 01:32:22.685
  STEP: Listing v2 custom resources with field selector host=host1 @ 01/15/25 01:32:22.713
  STEP: Listing v2 custom resources with field selector host=host1,port=80 @ 01/15/25 01:32:22.717
  STEP: Listing v1 custom resources with field selector hostPort=host1:80 @ 01/15/25 01:32:22.721
  STEP: Listing v1 custom resources with field selector hostPort=host1:8080 @ 01/15/25 01:32:22.725
  STEP: Waiting for watch events to contain v2 custom resources for field selector host=host1 @ 01/15/25 01:32:22.729
  STEP: Waiting for watch events to contain v2 custom resources for field selector host=host1,port=80 @ 01/15/25 01:32:22.735
  STEP: Waiting for watch events to contain v1 custom resources for field selector hostPort=host1:80 @ 01/15/25 01:32:22.735
  STEP: Waiting for informer events to contain v2 custom resources for field selector host=host1 @ 01/15/25 01:32:22.735
  STEP: Waiting for informer events to contain v2 custom resources for field selector host=host1,port=80 @ 01/15/25 01:32:22.735
  STEP: Deleting one custom resources to ensure that deletions are observed @ 01/15/25 01:32:22.735
  STEP: Updating one custom resources to ensure that deletions are observed @ 01/15/25 01:32:22.748
  STEP: Listing v2 custom resources after updates and deletes for field selector host=host1 @ 01/15/25 01:32:22.766
  STEP: Listing v2 custom resources after updates and deletes for field selector host=host1,port=80 @ 01/15/25 01:32:22.769
  STEP: Waiting for v2 watch events after updates and deletes for field selector host=host1 @ 01/15/25 01:32:22.773
  STEP: Waiting for v2 watch events after updates and deletes for field selector host=host1,port=80 @ 01/15/25 01:32:22.779
  STEP: Waiting for v1 watch events after updates and deletes for field selector hostPort=host1:80 @ 01/15/25 01:32:22.779
  STEP: Waiting for v2 informer events after updates and deletes for field selector host=host1 @ 01/15/25 01:32:22.779
  STEP: Waiting for v2 informer events after updates and deletes for field selector host=host1,port=80 @ 01/15/25 01:32:22.78
  I0115 01:32:23.401725 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-selectable-fields-5398" for this suite. @ 01/15/25 01:32:23.408
• [6.990 seconds]
------------------------------
[sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:92
  STEP: Creating a kubernetes client @ 01/15/25 01:32:23.417
  I0115 01:32:23.417633 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename downward-api @ 01/15/25 01:32:23.419
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:32:23.492
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:32:23.511
  STEP: Creating a pod to test downward api env vars @ 01/15/25 01:32:23.517
  STEP: Saw pod success @ 01/15/25 01:32:27.57
  I0115 01:32:27.576574 24 output.go:207] Trying to get logs from node 192.168.18.92 pod downward-api-2e211f03-9536-4004-ae97-81ed347f439c container dapi-container: <nil>
  STEP: delete the pod @ 01/15/25 01:32:27.588
  I0115 01:32:27.605741 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-7583" for this suite. @ 01/15/25 01:32:27.611
• [4.199 seconds]
------------------------------
[sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:480
  STEP: Creating a kubernetes client @ 01/15/25 01:32:27.616
  I0115 01:32:27.616606 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename gc @ 01/15/25 01:32:27.617
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:32:27.631
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:32:27.636
  STEP: create the deployment @ 01/15/25 01:32:27.641
  W0115 01:32:27.646468      24 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: Wait for the Deployment to create new ReplicaSet @ 01/15/25 01:32:27.646
  STEP: delete the deployment @ 01/15/25 01:32:28.152
  STEP: wait for all rs to be garbage collected @ 01/15/25 01:32:28.159
  STEP: expected 0 pods, got 2 pods @ 01/15/25 01:32:28.173
  STEP: Gathering metrics @ 01/15/25 01:32:28.676
  I0115 01:32:29.004825 24 garbage_collector.go:265] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0115 01:32:29.005232 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-4289" for this suite. @ 01/15/25 01:32:29.014
• [1.407 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:166
  STEP: Creating a kubernetes client @ 01/15/25 01:32:29.024
  I0115 01:32:29.024302 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename replicaset @ 01/15/25 01:32:29.025
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:32:29.05
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:32:29.057
  STEP: Create a ReplicaSet @ 01/15/25 01:32:29.064
  STEP: Verify that the required pods have come up @ 01/15/25 01:32:29.074
  I0115 01:32:29.080483 24 resource.go:87] Pod name sample-pod: Found 0 pods out of 3
  I0115 01:32:34.093687 24 resource.go:87] Pod name sample-pod: Found 3 pods out of 3
  STEP: ensuring each pod is running @ 01/15/25 01:32:34.093
  I0115 01:32:34.100894 24 replica_set.go:583] Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
  STEP: Listing all ReplicaSets @ 01/15/25 01:32:34.101
  STEP: DeleteCollection of the ReplicaSets @ 01/15/25 01:32:34.112
  STEP: After DeleteCollection verify that ReplicaSets have been deleted @ 01/15/25 01:32:34.127
  I0115 01:32:34.133177 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-6113" for this suite. @ 01/15/25 01:32:34.141
• [5.129 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:215
  STEP: Creating a kubernetes client @ 01/15/25 01:32:34.154
  I0115 01:32:34.154353 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 01/15/25 01:32:34.156
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:32:34.205
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:32:34.212
  STEP: create the container to handle the HTTPGet hook request. @ 01/15/25 01:32:34.244
  STEP: create the pod with lifecycle hook @ 01/15/25 01:32:38.289
  STEP: delete the pod with lifecycle hook @ 01/15/25 01:32:42.331
  STEP: check prestop hook @ 01/15/25 01:32:44.369
  I0115 01:32:44.383932 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-3251" for this suite. @ 01/15/25 01:32:44.39
• [10.244 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:113
  STEP: Creating a kubernetes client @ 01/15/25 01:32:44.398
  I0115 01:32:44.398303 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename replication-controller @ 01/15/25 01:32:44.399
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:32:44.412
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:32:44.416
  STEP: creating a ReplicationController @ 01/15/25 01:32:44.425
  STEP: waiting for RC to be added @ 01/15/25 01:32:44.432
  STEP: waiting for available Replicas @ 01/15/25 01:32:44.433
  STEP: patching ReplicationController @ 01/15/25 01:32:45.649
  STEP: waiting for RC to be modified @ 01/15/25 01:32:45.659
  STEP: patching ReplicationController status @ 01/15/25 01:32:45.659
  STEP: waiting for RC to be modified @ 01/15/25 01:32:45.689
  STEP: waiting for available Replicas @ 01/15/25 01:32:45.689
  STEP: fetching ReplicationController status @ 01/15/25 01:32:45.726
  STEP: patching ReplicationController scale @ 01/15/25 01:32:45.736
  STEP: waiting for RC to be modified @ 01/15/25 01:32:45.751
  STEP: waiting for ReplicationController's scale to be the max amount @ 01/15/25 01:32:45.751
  STEP: fetching ReplicationController; ensuring that it's patched @ 01/15/25 01:32:47.729
  STEP: updating ReplicationController status @ 01/15/25 01:32:47.734
  STEP: waiting for RC to be modified @ 01/15/25 01:32:47.743
  STEP: listing all ReplicationControllers @ 01/15/25 01:32:47.743
  STEP: checking that ReplicationController has expected values @ 01/15/25 01:32:47.749
  STEP: deleting ReplicationControllers by collection @ 01/15/25 01:32:47.749
  STEP: waiting for ReplicationController to have a DELETED watchEvent @ 01/15/25 01:32:47.759
  I0115 01:32:47.814237 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  E0115 01:32:47.814788      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Destroying namespace "replication-controller-306" for this suite. @ 01/15/25 01:32:47.82
• [3.429 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:705
  STEP: Creating a kubernetes client @ 01/15/25 01:32:47.827
  I0115 01:32:47.827751 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename sched-pred @ 01/15/25 01:32:47.828
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:32:47.843
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:32:47.848
  I0115 01:32:47.853938 24 helper.go:125] Waiting up to 1m0s for all (but 0) nodes to be ready
  I0115 01:32:47.926277 24 util.go:396] Waiting for terminating namespaces to be deleted...
  I0115 01:32:47.931024 24 predicates.go:119] 
  Logging pods the apiserver thinks is on node 192.168.18.91 before test
  I0115 01:32:47.938515 24 predicates.go:957] calico-kube-controllers-7498b9bb4c-crlbm from kube-system started at 2025-01-14 15:20:19 +0000 UTC (1 container statuses recorded)
  I0115 01:32:47.938612 24 predicates.go:959] 	Container calico-kube-controllers ready: true, restart count 0
  I0115 01:32:47.938682 24 predicates.go:957] calico-node-zs5fv from kube-system started at 2025-01-14 13:30:35 +0000 UTC (1 container statuses recorded)
  I0115 01:32:47.938697 24 predicates.go:959] 	Container calico-node ready: true, restart count 0
  I0115 01:32:47.938718 24 predicates.go:957] coredns-668d6bf9bc-2fn8q from kube-system started at 2025-01-14 15:16:36 +0000 UTC (1 container statuses recorded)
  I0115 01:32:47.938729 24 predicates.go:959] 	Container coredns ready: true, restart count 0
  I0115 01:32:47.938741 24 predicates.go:957] coredns-668d6bf9bc-mpkf9 from kube-system started at 2025-01-14 15:16:35 +0000 UTC (1 container statuses recorded)
  I0115 01:32:47.938753 24 predicates.go:959] 	Container coredns ready: true, restart count 0
  I0115 01:32:47.938766 24 predicates.go:957] etcd-192.168.18.91 from kube-system started at 2025-01-14 07:47:31 +0000 UTC (1 container statuses recorded)
  I0115 01:32:47.938793 24 predicates.go:959] 	Container etcd ready: true, restart count 2
  I0115 01:32:47.938806 24 predicates.go:957] kube-apiserver-192.168.18.91 from kube-system started at 2025-01-14 07:47:31 +0000 UTC (1 container statuses recorded)
  I0115 01:32:47.938816 24 predicates.go:959] 	Container kube-apiserver ready: true, restart count 2
  I0115 01:32:47.938828 24 predicates.go:957] kube-controller-manager-192.168.18.91 from kube-system started at 2025-01-14 07:47:31 +0000 UTC (1 container statuses recorded)
  I0115 01:32:47.938839 24 predicates.go:959] 	Container kube-controller-manager ready: true, restart count 2
  I0115 01:32:47.938851 24 predicates.go:957] kube-proxy-nlmsc from kube-system started at 2025-01-14 13:23:11 +0000 UTC (1 container statuses recorded)
  I0115 01:32:47.938861 24 predicates.go:959] 	Container kube-proxy ready: true, restart count 0
  I0115 01:32:47.938873 24 predicates.go:957] kube-scheduler-192.168.18.91 from kube-system started at 2025-01-14 07:47:31 +0000 UTC (1 container statuses recorded)
  I0115 01:32:47.938884 24 predicates.go:959] 	Container kube-scheduler ready: true, restart count 2
  I0115 01:32:47.938897 24 predicates.go:957] rc-test-dtvks from replication-controller-306 started at 2025-01-15 01:32:45 +0000 UTC (1 container statuses recorded)
  I0115 01:32:47.938907 24 predicates.go:959] 	Container rc-test ready: true, restart count 0
  I0115 01:32:47.938919 24 predicates.go:957] sonobuoy-systemd-logs-daemon-set-7cfa3cb4906a48cc-vmmwc from sonobuoy started at 2025-01-15 01:17:18 +0000 UTC (2 container statuses recorded)
  I0115 01:32:47.938931 24 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I0115 01:32:47.938941 24 predicates.go:959] 	Container systemd-logs ready: true, restart count 0
  I0115 01:32:47.938962 24 predicates.go:119] 
  Logging pods the apiserver thinks is on node 192.168.18.92 before test
  I0115 01:32:47.944513 24 predicates.go:957] pod-handle-http-request from container-lifecycle-hook-3251 started at 2025-01-15 01:32:34 +0000 UTC (2 container statuses recorded)
  I0115 01:32:47.944620 24 predicates.go:959] 	Container container-handle-http-request ready: true, restart count 0
  I0115 01:32:47.944637 24 predicates.go:959] 	Container container-handle-https-request ready: true, restart count 0
  I0115 01:32:47.944654 24 predicates.go:957] calico-node-9mtz6 from kube-system started at 2025-01-14 13:30:35 +0000 UTC (1 container statuses recorded)
  I0115 01:32:47.944668 24 predicates.go:959] 	Container calico-node ready: true, restart count 0
  I0115 01:32:47.944678 24 predicates.go:957] kube-proxy-tf5gf from kube-system started at 2025-01-14 13:23:11 +0000 UTC (1 container statuses recorded)
  I0115 01:32:47.944688 24 predicates.go:959] 	Container kube-proxy ready: true, restart count 0
  I0115 01:32:47.944699 24 predicates.go:957] rc-test-v5dbf from replication-controller-306 started at 2025-01-15 01:32:44 +0000 UTC (1 container statuses recorded)
  I0115 01:32:47.944706 24 predicates.go:959] 	Container rc-test ready: true, restart count 0
  I0115 01:32:47.944713 24 predicates.go:957] sonobuoy from sonobuoy started at 2025-01-15 01:17:16 +0000 UTC (1 container statuses recorded)
  I0115 01:32:47.944720 24 predicates.go:959] 	Container kube-sonobuoy ready: true, restart count 0
  I0115 01:32:47.944727 24 predicates.go:957] sonobuoy-e2e-job-62b29f02b7114b6e from sonobuoy started at 2025-01-15 01:17:17 +0000 UTC (2 container statuses recorded)
  I0115 01:32:47.944741 24 predicates.go:959] 	Container e2e ready: true, restart count 0
  I0115 01:32:47.944754 24 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I0115 01:32:47.944770 24 predicates.go:957] sonobuoy-systemd-logs-daemon-set-7cfa3cb4906a48cc-ljwvq from sonobuoy started at 2025-01-15 01:17:18 +0000 UTC (2 container statuses recorded)
  I0115 01:32:47.944777 24 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I0115 01:32:47.944783 24 predicates.go:959] 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 01/15/25 01:32:47.944
  E0115 01:32:48.815343      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:32:49.816212      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 01/15/25 01:32:49.984
  STEP: Trying to apply a random label on the found node. @ 01/15/25 01:32:50.038
  STEP: verifying the node has the label kubernetes.io/e2e-20c2b0e3-b625-4080-a6ae-2d73e9e97c0c 95 @ 01/15/25 01:32:50.08
  STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled @ 01/15/25 01:32:50.089
  E0115 01:32:50.816412      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:32:51.816833      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:32:52.817800      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:32:53.818298      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 192.168.18.92 on the node which pod4 resides and expect not scheduled @ 01/15/25 01:32:54.142
  E0115 01:32:54.818785      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:32:55.819271      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:32:56.820084      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:32:57.820575      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:32:58.821566      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:32:59.822564      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:00.822711      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:01.823535      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:02.824132      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:03.825845      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:04.826259      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:05.827981      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:06.828728      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:07.829667      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:08.830717      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:09.831549      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:10.832721      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:11.834217      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:12.834968      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:13.835948      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:14.836679      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:15.837379      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:16.839144      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:17.840386      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:18.841304      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:19.842200      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:20.842836      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:21.842985      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:22.843297      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:23.844661      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:24.844913      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:25.846410      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:26.847036      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:27.848554      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:28.850298      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:29.850965      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:30.851802      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:31.852875      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:32.852943      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:33.855499      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:34.855994      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:35.857188      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:36.858276      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:37.859982      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:38.860584      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:39.861462      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:40.861798      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:41.862977      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:42.864739      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:43.865697      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:44.865724      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:45.867003      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:46.868410      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:47.869878      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:48.870290      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:49.871521      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:50.873341      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:51.874537      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:52.875878      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:53.876941      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:54.877223      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:55.877425      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:56.878801      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:57.879980      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:58.880355      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:33:59.880773      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:00.882423      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:01.882935      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:02.883355      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:03.884366      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:04.885061      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:05.886200      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:06.886720      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:07.887847      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:08.889342      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:09.890489      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:10.891141      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:11.892056      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:12.893151      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:13.894588      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:14.895485      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:15.896527      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:16.897164      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:17.898844      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:18.900133      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:19.901713      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:20.903870      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:21.904755      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:22.906597      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:23.907678      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:24.908464      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:25.910092      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:26.912916      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:27.914102      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:28.914885      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:29.915855      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:30.916696      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:31.918687      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:32.920850      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:33.921888      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:34.923403      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:35.923825      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:36.924151      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:37.925853      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:38.927596      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:39.927783      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:40.928076      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:41.928972      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:42.929876      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:43.931266      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:44.932049      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:45.936221      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:46.936779      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:47.938863      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:48.940078      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:49.943712      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:50.944610      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:51.945226      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:52.945602      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:53.947711      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:54.949561      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:55.950465      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:56.951114      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:57.952141      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:58.953864      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:34:59.954239      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:35:00.954126      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:35:01.955452      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:35:02.956869      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:35:03.957298      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:35:04.959022      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:35:05.961034      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:35:06.963944      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:35:07.965361      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:35:08.965924      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:35:09.967608      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:35:10.969239      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:35:11.970771      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:35:12.971380      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:35:13.972252      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:35:14.973343      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:35:15.974596      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:35:16.976170      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:35:17.976926      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:35:18.977443      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:35:19.979092      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:35:20.979386      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:35:21.980476      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:35:22.981064      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:35:23.982813      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:35:24.982563      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:35:25.983596      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:35:26.983800      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:35:27.984465      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:35:28.985669      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:35:29.986481      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:35:30.986875      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:35:31.989195      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:35:32.989527      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:35:33.990276      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:35:34.990447      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:35:35.992025      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:35:36.993199      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:35:37.995291      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:35:38.997306      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:35:39.999038      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:35:41.000003      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:35:42.000971      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:35:43.002114      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:35:44.002818      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:35:45.003401      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:35:46.004187      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:35:47.005214      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:35:48.006494      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:35:49.007600      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:35:50.009125      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:35:51.010472      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:35:52.012228      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:35:53.014655      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:35:54.016057      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:35:55.016517      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:35:56.017140      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:35:57.018260      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:35:58.020130      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:35:59.021842      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:00.023910      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:01.024930      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:02.026130      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:03.027379      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:04.029018      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:05.029860      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:06.031413      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:07.032541      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:08.035276      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:09.036813      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:10.037535      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:11.038710      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:12.039198      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:13.039615      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:14.041610      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:15.042233      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:16.043925      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:17.045191      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:18.045811      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:19.046186      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:20.047903      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:21.048904      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:22.050991      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:23.052089      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:24.053351      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:25.054105      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:26.054809      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:27.056394      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:28.058063      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:29.060012      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:30.060126      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:31.062208      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:32.063417      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:33.065479      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:34.068806      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:35.069635      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:36.072048      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:37.072184      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:38.074302      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:39.075936      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:40.077505      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:41.078142      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:42.079529      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:43.080874      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:44.081311      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:45.082438      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:46.086971      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:47.089250      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:48.090708      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:49.092545      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:50.093297      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:51.093506      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:52.095852      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:53.099102      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:54.100300      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:55.100759      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:56.101820      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:57.103110      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:58.103266      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:36:59.104185      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:37:00.106294      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:37:01.107189      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:37:02.108009      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:37:03.108759      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:37:04.110804      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:37:05.110899      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:37:06.114433      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:37:07.114504      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:37:08.115180      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:37:09.115490      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:37:10.116157      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:37:11.116937      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:37:12.117903      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:37:13.118315      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:37:14.118661      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:37:15.118866      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:37:16.118953      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:37:17.120363      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:37:18.122951      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:37:19.123913      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:37:20.125338      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:37:21.126268      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:37:22.127586      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:37:23.129037      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:37:24.129929      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:37:25.130755      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:37:26.132578      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:37:27.133178      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:37:28.134219      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:37:29.136160      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:37:30.136868      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:37:31.138768      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:37:32.139322      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:37:33.139898      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:37:34.140416      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:37:35.141307      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:37:36.141772      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:37:37.142690      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:37:38.144042      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:37:39.145709      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:37:40.147146      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:37:41.147777      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:37:42.149928      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:37:43.150822      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:37:44.151556      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:37:45.152078      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:37:46.153252      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:37:47.153929      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:37:48.154933      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:37:49.156837      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:37:50.158396      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:37:51.159808      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:37:52.160208      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:37:53.161882      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: removing the label kubernetes.io/e2e-20c2b0e3-b625-4080-a6ae-2d73e9e97c0c off the node 192.168.18.92 @ 01/15/25 01:37:54.158
  E0115 01:37:54.163600      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-20c2b0e3-b625-4080-a6ae-2d73e9e97c0c @ 01/15/25 01:37:54.206
  I0115 01:37:54.214932 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-5399" for this suite. @ 01/15/25 01:37:54.222
• [306.402 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/security_context.go:302
  STEP: Creating a kubernetes client @ 01/15/25 01:37:54.23
  I0115 01:37:54.230672 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename security-context @ 01/15/25 01:37:54.232
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:37:54.248
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:37:54.254
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 01/15/25 01:37:54.259
  E0115 01:37:55.164031      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:37:56.164684      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:37:57.165586      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:37:58.166175      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 01:37:58.287
  I0115 01:37:58.291138 24 output.go:207] Trying to get logs from node 192.168.18.92 pod security-context-4f4ee6eb-320b-4c93-90cb-3b8a39c328ae container test-container: <nil>
  STEP: delete the pod @ 01/15/25 01:37:58.309
  I0115 01:37:58.321778 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-7229" for this suite. @ 01/15/25 01:37:58.327
• [4.103 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:52
  STEP: Creating a kubernetes client @ 01/15/25 01:37:58.333
  I0115 01:37:58.333616 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename container-runtime @ 01/15/25 01:37:58.334
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:37:58.351
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:37:58.354
  STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' @ 01/15/25 01:37:58.382
  E0115 01:37:59.166950      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:38:00.168071      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:38:01.167882      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:38:02.169552      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:38:03.169658      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:38:04.170464      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:38:05.173873      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:38:06.174725      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:38:07.175373      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:38:08.176450      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:38:09.177139      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:38:10.178238      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:38:11.179909      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:38:12.180185      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:38:13.181163      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' @ 01/15/25 01:38:13.54
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition @ 01/15/25 01:38:13.552
  STEP: Container 'terminate-cmd-rpa': should get the expected 'State' @ 01/15/25 01:38:13.574
  STEP: Container 'terminate-cmd-rpa': should be possible to delete @ 01/15/25 01:38:13.575
  STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' @ 01/15/25 01:38:13.615
  E0115 01:38:14.181599      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:38:15.182267      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:38:16.184511      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' @ 01/15/25 01:38:16.65
  E0115 01:38:17.186211      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition @ 01/15/25 01:38:17.672
  STEP: Container 'terminate-cmd-rpof': should get the expected 'State' @ 01/15/25 01:38:17.698
  STEP: Container 'terminate-cmd-rpof': should be possible to delete @ 01/15/25 01:38:17.698
  STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' @ 01/15/25 01:38:17.738
  E0115 01:38:18.186935      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' @ 01/15/25 01:38:18.749
  E0115 01:38:19.187165      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:38:20.189224      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition @ 01/15/25 01:38:20.763
  STEP: Container 'terminate-cmd-rpn': should get the expected 'State' @ 01/15/25 01:38:20.77
  STEP: Container 'terminate-cmd-rpn': should be possible to delete @ 01/15/25 01:38:20.77
  I0115 01:38:20.793557 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-763" for this suite. @ 01/15/25 01:38:20.798
• [22.469 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:254
  STEP: Creating a kubernetes client @ 01/15/25 01:38:20.803
  I0115 01:38:20.803213 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename namespaces @ 01/15/25 01:38:20.804
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:38:20.817
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:38:20.823
  STEP: Creating a test namespace @ 01/15/25 01:38:20.827
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:38:20.923
  STEP: Creating a service in the namespace @ 01/15/25 01:38:20.927
  STEP: Deleting the namespace @ 01/15/25 01:38:20.938
  STEP: Waiting for the namespace to be removed. @ 01/15/25 01:38:20.959
  E0115 01:38:21.191959      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:38:22.193339      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:38:23.194202      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:38:24.194366      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:38:25.194900      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:38:26.195049      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Recreating the namespace @ 01/15/25 01:38:26.962
  STEP: Verifying there is no service in the namespace @ 01/15/25 01:38:26.974
  I0115 01:38:26.978574 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-4643" for this suite. @ 01/15/25 01:38:26.982
  STEP: Destroying namespace "nsdeletetest-8355" for this suite. @ 01/15/25 01:38:26.988
  I0115 01:38:26.992454 24 framework.go:370] Namespace nsdeletetest-8355 was already deleted
  STEP: Destroying namespace "nsdeletetest-2881" for this suite. @ 01/15/25 01:38:26.992
• [6.195 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AggregatedDiscovery should support aggregated discovery interface [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregated_discovery.go:259
  STEP: Creating a kubernetes client @ 01/15/25 01:38:26.998
  I0115 01:38:26.998550 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename aggregateddiscovery @ 01/15/25 01:38:26.999
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:38:27.078
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:38:27.083
  I0115 01:38:27.096073 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregateddiscovery-1720" for this suite. @ 01/15/25 01:38:27.101
• [0.109 seconds]
------------------------------
S
------------------------------
[sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance] [sig-scheduling, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/limit_range.go:62
  STEP: Creating a kubernetes client @ 01/15/25 01:38:27.107
  I0115 01:38:27.107083 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename limitrange @ 01/15/25 01:38:27.107
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:38:27.157
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:38:27.162
  STEP: Creating a LimitRange @ 01/15/25 01:38:27.167
  STEP: Setting up watch @ 01/15/25 01:38:27.167
  E0115 01:38:27.196158      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Submitting a LimitRange @ 01/15/25 01:38:27.273
  STEP: Verifying LimitRange creation was observed @ 01/15/25 01:38:27.295
  STEP: Fetching the LimitRange to ensure it has proper values @ 01/15/25 01:38:27.296
  I0115 01:38:27.309446 24 limit_range.go:355] Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  I0115 01:38:27.309881 24 limit_range.go:360] Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with no resource requirements @ 01/15/25 01:38:27.309
  STEP: Ensuring Pod has resource requirements applied from LimitRange @ 01/15/25 01:38:27.34
  I0115 01:38:27.352818 24 limit_range.go:355] Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  I0115 01:38:27.353000 24 limit_range.go:360] Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with partial resource requirements @ 01/15/25 01:38:27.353
  STEP: Ensuring Pod has merged resource requirements applied from LimitRange @ 01/15/25 01:38:27.369
  I0115 01:38:27.378017 24 limit_range.go:355] Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
  I0115 01:38:27.378161 24 limit_range.go:360] Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Failing to create a Pod with less than min resources @ 01/15/25 01:38:27.378
  STEP: Failing to create a Pod with more than max resources @ 01/15/25 01:38:27.384
  STEP: Updating a LimitRange @ 01/15/25 01:38:27.388
  STEP: Verifying LimitRange updating is effective @ 01/15/25 01:38:27.397
  E0115 01:38:28.197256      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:38:29.197346      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Creating a Pod with less than former min resources @ 01/15/25 01:38:29.411
  STEP: Failing to create a Pod with more than max resources @ 01/15/25 01:38:29.434
  STEP: Deleting a LimitRange @ 01/15/25 01:38:29.445
  STEP: Verifying the LimitRange was deleted @ 01/15/25 01:38:29.459
  E0115 01:38:30.198415      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:38:31.199237      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:38:32.199530      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:38:33.200465      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:38:34.201141      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:38:34.464525 24 limit_range.go:211] limitRange is already deleted
  STEP: Creating a Pod with more than former max resources @ 01/15/25 01:38:34.464
  I0115 01:38:34.470413 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-1815" for this suite. @ 01/15/25 01:38:34.475
• [7.373 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:55
  STEP: Creating a kubernetes client @ 01/15/25 01:38:34.48
  I0115 01:38:34.480380 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename downward-api @ 01/15/25 01:38:34.481
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:38:34.493
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:38:34.498
  STEP: Creating a pod to test downward API volume plugin @ 01/15/25 01:38:34.503
  E0115 01:38:35.201975      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:38:36.204285      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:38:37.205795      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:38:38.206697      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 01:38:38.616
  I0115 01:38:38.621052 24 output.go:207] Trying to get logs from node 192.168.18.92 pod downwardapi-volume-aa62f9ba-d7cf-4141-8b4d-b07402db3795 container client-container: <nil>
  STEP: delete the pod @ 01/15/25 01:38:38.626
  I0115 01:38:38.640617 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-9871" for this suite. @ 01/15/25 01:38:38.645
• [4.170 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:132
  STEP: Creating a kubernetes client @ 01/15/25 01:38:38.65
  I0115 01:38:38.650575 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename projected @ 01/15/25 01:38:38.651
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:38:38.663
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:38:38.667
  STEP: Creating the pod @ 01/15/25 01:38:38.672
  E0115 01:38:39.207389      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:38:40.208371      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:38:41.209473      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:38:41.216315 24 pod_client.go:173] Successfully updated pod "labelsupdated497448a-6525-4525-bb1b-80b99f480ef2"
  E0115 01:38:42.210571      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:38:43.210970      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:38:44.214353      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:38:45.214784      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:38:45.262230 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3611" for this suite. @ 01/15/25 01:38:45.267
• [6.623 seconds]
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:75
  STEP: Creating a kubernetes client @ 01/15/25 01:38:45.274
  I0115 01:38:45.274050 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename configmap @ 01/15/25 01:38:45.274
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:38:45.289
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:38:45.294
  STEP: Creating configMap with name configmap-test-volume-70eaa6c0-5645-4f2c-bf35-88f80a476cac @ 01/15/25 01:38:45.3
  STEP: Creating a pod to test consume configMaps @ 01/15/25 01:38:45.304
  E0115 01:38:46.215556      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:38:47.217660      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:38:48.219297      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:38:49.219968      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 01:38:49.333
  I0115 01:38:49.339276 24 output.go:207] Trying to get logs from node 192.168.18.92 pod pod-configmaps-8569684b-68ed-435d-94b4-a4afc5ad9cd3 container agnhost-container: <nil>
  STEP: delete the pod @ 01/15/25 01:38:49.362
  I0115 01:38:49.422504 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-9744" for this suite. @ 01/15/25 01:38:49.432
• [4.167 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a GRPC liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:528
  STEP: Creating a kubernetes client @ 01/15/25 01:38:49.441
  I0115 01:38:49.441152 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename container-probe @ 01/15/25 01:38:49.442
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:38:49.459
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:38:49.465
  STEP: Creating pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482 @ 01/15/25 01:38:49.471
  E0115 01:38:50.220684      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:38:51.221950      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 01/15/25 01:38:51.501
  I0115 01:38:51.513558 24 container_probe.go:1749] Initial restart count of pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 is 0
  I0115 01:38:51.527731 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:38:52.223568      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:38:53.224301      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:38:53.532224 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:38:54.225197      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:38:55.225866      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:38:55.550317 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:38:56.226558      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:38:57.227551      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:38:57.563178 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:38:58.228755      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:38:59.231893      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:38:59.567170 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:39:00.231969      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:39:01.232643      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:39:01.570642 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:39:02.233373      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:39:03.234568      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:39:03.574816 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:39:04.234600      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:39:05.235426      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:39:05.587805 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:39:06.236227      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:39:07.238127      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:39:07.599783 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:39:08.239175      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:39:09.240899      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:39:09.603734 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:39:10.241178      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:39:11.242341      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:39:11.611205 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:39:12.243427      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:39:13.244719      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:39:13.615667 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:39:14.246150      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:39:15.247920      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:39:15.624633 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:39:16.246760      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:39:17.248240      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:39:17.634088 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:39:18.248591      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:39:19.249414      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:39:19.640261 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:39:20.252238      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:39:21.250952      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:39:21.655475 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:39:22.251187      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:39:23.252502      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:39:23.668852 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:39:24.252921      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:39:25.253507      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:39:25.685546 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:39:26.254425      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:39:27.255863      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:39:27.691325 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:39:28.257113      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:39:29.258127      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:39:29.696044 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:39:30.258361      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:39:31.259637      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:39:31.700869 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:39:32.260434      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:39:33.260994      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:39:33.706307 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:39:34.262181      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:39:35.263883      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:39:35.719506 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:39:36.264874      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:39:37.266257      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:39:37.732334 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:39:38.274753      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:39:39.268876      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:39:39.735446 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:39:40.269754      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:39:41.270357      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:39:41.739647 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:39:42.270462      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:39:43.271061      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:39:43.747861 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:39:44.272833      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:39:45.273873      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:39:45.761704 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:39:46.273832      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:39:47.275643      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:39:47.775020 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:39:48.278294      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:39:49.278460      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:39:49.795486 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:39:50.279368      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:39:51.280426      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:39:51.800460 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:39:52.281053      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:39:53.282763      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:39:53.809435 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:39:54.284154      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:39:55.285248      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:39:55.814244 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:39:56.287533      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:39:57.288492      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:39:57.823657 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:39:58.289433      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:39:59.291097      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:39:59.841425 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:40:00.293106      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:40:01.294189      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:40:01.846635 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:40:02.294595      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:40:03.295422      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:40:03.866900 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:40:04.295924      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:40:05.296744      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:40:05.878352 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:40:06.297218      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:40:07.297760      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:40:07.890991 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:40:08.299309      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:40:09.301068      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:40:09.902841 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:40:10.301891      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:40:11.302309      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:40:11.915178 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:40:12.302163      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:40:13.302930      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:40:13.924044 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:40:14.304188      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:40:15.305904      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:40:15.928557 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:40:16.306681      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:40:17.309036      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:40:17.943691 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:40:18.309539      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:40:19.310132      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:40:19.956003 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:40:20.310603      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:40:21.311447      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:40:21.963364 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:40:22.314191      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:40:23.315607      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:40:23.978736 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:40:24.316650      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:40:25.317805      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:40:25.987713 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:40:26.320212      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:40:27.320548      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:40:27.992904 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:40:28.321611      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:40:29.324479      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:40:29.997808 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:40:30.324693      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:40:31.325540      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:40:32.002078 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:40:32.325754      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:40:33.327079      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:40:34.006928 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:40:34.328733      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:40:35.329480      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:40:36.016408 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:40:36.329836      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:40:37.331726      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:40:38.032136 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:40:38.333236      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:40:39.336014      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:40:40.045139 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:40:40.338012      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:40:41.338012      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:40:42.050101 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:40:42.338683      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:40:43.339820      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:40:44.063366 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:40:44.341596      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:40:45.342044      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:40:46.086673 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:40:46.342925      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:40:47.343597      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:40:48.096005 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:40:48.343681      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:40:49.344976      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:40:50.105183 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:40:50.346366      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:40:51.350473      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:40:52.122183 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:40:52.349642      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:40:53.350399      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:40:54.130910 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:40:54.350581      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:40:55.351574      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:40:56.138551 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:40:56.352112      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:40:57.353986      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:40:58.150344 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:40:58.355292      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:40:59.356370      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:41:00.166999 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:41:00.358782      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:41:01.360122      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:41:02.177603 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:41:02.365269      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:41:03.366227      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:41:04.182175 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:41:04.366182      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:41:05.366541      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:41:06.189846 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:41:06.367909      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:41:07.368478      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:41:08.203054 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:41:08.369362      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:41:09.371261      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:41:10.218316 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:41:10.372559      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:41:11.374119      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:41:12.224328 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:41:12.375132      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:41:13.375924      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:41:14.237033 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:41:14.377280      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:41:15.377844      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:41:16.249647 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:41:16.378727      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:41:17.379705      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:41:18.255564 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:41:18.380949      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:41:19.381865      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:41:20.259568 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:41:20.382361      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:41:21.383197      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:41:22.266947 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:41:22.387660      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:41:23.388266      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:41:24.281942 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:41:24.389613      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:41:25.390463      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:41:26.286710 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:41:26.391621      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:41:27.392002      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:41:28.290286 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:41:28.392040      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:41:29.394179      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:41:30.295216 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:41:30.394708      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:41:31.396945      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:41:32.299988 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:41:32.397937      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:41:33.399679      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:41:34.306041 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:41:34.402011      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:41:35.403460      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:41:36.309922 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:41:36.404234      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:41:37.405406      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:41:38.321809 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:41:38.406025      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:41:39.406496      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:41:40.325941 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:41:40.407599      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:41:41.408454      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:41:42.329974 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:41:42.409523      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:41:43.410657      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:41:44.334234 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:41:44.411872      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:41:45.413158      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:41:46.343101 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:41:46.413767      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:41:47.415019      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:41:48.348114 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:41:48.415265      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:41:49.416147      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:41:50.381472 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:41:50.416084      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:41:51.417040      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:41:52.386794 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:41:52.418924      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:41:53.419931      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:41:54.390973 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:41:54.420089      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:41:55.421755      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:41:56.405164 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:41:56.423812      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:41:57.425557      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:41:58.409747 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:41:58.425281      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:41:59.425532      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:42:00.412961 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:42:00.425756      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:42:01.427209      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:42:02.426964 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:42:02.427343      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:42:03.429335      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:42:04.430142      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:42:04.434623 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:42:05.431125      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:42:06.433365      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:42:06.448343 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:42:07.434852      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:42:08.436469      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:42:08.452904 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:42:09.437896      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:42:10.437851      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:42:10.465682 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:42:11.437949      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:42:12.438378      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:42:12.476248 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:42:13.439108      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:42:14.440800      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:42:14.482141 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:42:15.441215      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:42:16.442002      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:42:16.496201 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:42:17.443884      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:42:18.444134      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:42:18.506104 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:42:19.445383      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:42:20.446862      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:42:20.511884 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:42:21.448122      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:42:22.448123      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:42:22.519026 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:42:23.449826      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:42:24.451291      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:42:24.523761 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:42:25.454202      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:42:26.455435      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:42:26.539487 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:42:27.457646      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:42:28.459493      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:42:28.551051 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:42:29.459823      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:42:30.462667      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:42:30.563920 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:42:31.465125      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:42:32.465506      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:42:32.583582 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:42:33.466986      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:42:34.467728      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:42:34.588527 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:42:35.469018      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:42:36.469044      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:42:36.600863 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:42:37.470181      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:42:38.471332      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:42:38.614480 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:42:39.471754      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:42:40.472658      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:42:40.627121 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:42:41.474298      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:42:42.475736      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:42:42.631928 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:42:43.476420      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:42:44.478392      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:42:44.637261 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:42:45.478516      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:42:46.480780      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:42:46.641074 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:42:47.481229      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:42:48.482156      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:42:48.644527 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:42:49.483327      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:42:50.485007      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:42:50.655933 24 container_probe.go:1759] Get pod test-grpc-5a89c7d7-cc25-47e4-b9e9-cc5e3613a407 in namespace container-probe-4482
  E0115 01:42:51.486299      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:42:52.486945      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 01/15/25 01:42:52.656
  I0115 01:42:52.674359 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-4482" for this suite. @ 01/15/25 01:42:52.689
• [243.262 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:392
  STEP: Creating a kubernetes client @ 01/15/25 01:42:52.703
  I0115 01:42:52.703628 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename crd-publish-openapi @ 01/15/25 01:42:52.711
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:42:52.729
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:42:52.737
  STEP: set up a multi version CRD @ 01/15/25 01:42:52.743
  I0115 01:42:52.744832 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  E0115 01:42:53.488770      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:42:54.489645      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:42:55.490188      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: rename a version @ 01/15/25 01:42:56.448
  STEP: check the new version name is served @ 01/15/25 01:42:56.46
  E0115 01:42:56.491932      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: check the old version name is removed @ 01/15/25 01:42:57.292
  E0115 01:42:57.492319      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: check the other version is not changed @ 01/15/25 01:42:58.021
  E0115 01:42:58.493112      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:42:59.494998      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:43:00.496292      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:43:01.246667 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-7992" for this suite. @ 01/15/25 01:43:01.26
• [8.567 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:210
  STEP: Creating a kubernetes client @ 01/15/25 01:43:01.271
  I0115 01:43:01.271909 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename emptydir @ 01/15/25 01:43:01.274
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:43:01.291
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:43:01.298
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 01/15/25 01:43:01.305
  E0115 01:43:01.497120      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:43:02.498909      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:43:03.499822      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:43:04.500304      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 01:43:05.352
  I0115 01:43:05.368562 24 output.go:207] Trying to get logs from node 192.168.18.92 pod pod-2778c77f-0a0d-467c-95a3-69f26cbcaa2b container test-container: <nil>
  STEP: delete the pod @ 01/15/25 01:43:05.398
  I0115 01:43:05.453650 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-4672" for this suite. @ 01/15/25 01:43:05.471
• [4.212 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates pod disruption condition is added to the preempted pod [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:469
  STEP: Creating a kubernetes client @ 01/15/25 01:43:05.486
  I0115 01:43:05.486446 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename sched-preemption @ 01/15/25 01:43:05.493
  E0115 01:43:05.501232      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:43:05.521
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:43:05.528
  I0115 01:43:05.557035 24 wait.go:51] Waiting up to 1m0s for all nodes to be ready
  E0115 01:43:06.501988      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:43:07.507853      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:43:08.512081      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:43:09.512571      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:43:10.512802      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:43:11.515778      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:43:12.518620      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:43:13.519953      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:43:14.525038      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:43:15.523209      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:43:16.524154      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:43:17.524902      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:43:18.525614      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:43:19.526121      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:43:20.527265      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:43:21.528537      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:43:22.529833      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:43:23.530877      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:43:24.532396      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:43:25.536206      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:43:26.536970      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:43:27.537332      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:43:28.537924      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:43:29.539596      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:43:30.540651      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:43:31.542336      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:43:32.543951      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:43:33.545019      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:43:34.546283      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:43:35.547159      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:43:36.549149      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:43:37.550136      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:43:38.550235      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:43:39.552042      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:43:40.553302      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:43:41.554734      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:43:42.557533      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:43:43.556051      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:43:44.558194      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:43:45.558605      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:43:46.559455      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:43:47.559652      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:43:48.561488      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:43:49.563180      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:43:50.564003      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:43:51.565530      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:43:52.567071      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:43:53.566898      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:43:54.567925      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:43:55.568273      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:43:56.569808      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:43:57.569863      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:43:58.570563      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:43:59.572066      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:44:00.572966      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:44:01.573051      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:44:02.574184      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:44:03.575790      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:44:04.576320      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:44:05.561242 24 util.go:396] Waiting for terminating namespaces to be deleted...
  E0115 01:44:05.577010      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Select a node to run the lower and higher priority pods @ 01/15/25 01:44:05.583
  STEP: Adding a custom resource @ 01/15/25 01:44:05.583
  STEP: Create a low priority pod that consumes 1/1 of node resources @ 01/15/25 01:44:05.606
  I0115 01:44:05.631132 24 preemption.go:503] Created pod: victim-pod
  STEP: Wait for the victim pod to be scheduled @ 01/15/25 01:44:05.631
  E0115 01:44:06.578498      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:44:07.579026      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Create a high priority pod to trigger preemption of the lower priority pod @ 01/15/25 01:44:07.639
  I0115 01:44:07.645580 24 preemption.go:521] Created pod: preemptor-pod
  STEP: Waiting for the victim pod to be terminating @ 01/15/25 01:44:07.645
  E0115 01:44:08.581045      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:44:09.582897      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Verifying the pod has the pod disruption condition @ 01/15/25 01:44:09.655
  I0115 01:44:09.666756 24 pod_client.go:383] Removing pod's "victim-pod" finalizer: "example.com/test-finalizer"
  I0115 01:44:10.227729 24 pod_client.go:173] Successfully updated pod "victim-pod"
  STEP: Removing a custom resource @ 01/15/25 01:44:10.273
  STEP: Removing a custom resource @ 01/15/25 01:44:10.31
  I0115 01:44:10.326030 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-5159" for this suite. @ 01/15/25 01:44:10.331
• [64.860 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:48
  STEP: Creating a kubernetes client @ 01/15/25 01:44:10.346
  I0115 01:44:10.346794 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename projected @ 01/15/25 01:44:10.348
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:44:10.376
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:44:10.383
  STEP: Creating configMap with name projected-configmap-test-volume-41535bf4-2aba-4691-8e80-ccef2d10488d @ 01/15/25 01:44:10.391
  STEP: Creating a pod to test consume configMaps @ 01/15/25 01:44:10.398
  E0115 01:44:10.584765      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:44:11.585352      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:44:12.586650      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:44:13.589911      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 01:44:14.458
  I0115 01:44:14.470433 24 output.go:207] Trying to get logs from node 192.168.18.92 pod pod-projected-configmaps-d3b40f00-dda3-464c-a5be-7d7defd3515b container agnhost-container: <nil>
  STEP: delete the pod @ 01/15/25 01:44:14.498
  I0115 01:44:14.517902 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8060" for this suite. @ 01/15/25 01:44:14.522
• [4.183 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:106
  STEP: Creating a kubernetes client @ 01/15/25 01:44:14.53
  I0115 01:44:14.530730 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename runtimeclass @ 01/15/25 01:44:14.531
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:44:14.551
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:44:14.556
  E0115 01:44:14.590075      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:44:15.590826      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:44:16.592512      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:44:16.618423 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-7639" for this suite. @ 01/15/25 01:44:16.628
• [2.107 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] PersistentVolumes CSI Conformance should run through the lifecycle of a PV and a PVC [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/persistent_volumes.go:429
  STEP: Creating a kubernetes client @ 01/15/25 01:44:16.638
  I0115 01:44:16.638131 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename pv @ 01/15/25 01:44:16.639
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:44:16.662
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:44:16.667
  STEP: Creating initial PV and PVC @ 01/15/25 01:44:16.675
  I0115 01:44:16.675739 24 pv.go:394] Creating a PV followed by a PVC
  STEP: Listing all PVs with the labelSelector: "e2e-pv-pool=pv-5230" @ 01/15/25 01:44:16.692
  STEP: Listing PVCs in namespace "pv-5230" @ 01/15/25 01:44:16.698
  STEP: Patching the PV "pv-5230-pssrn" @ 01/15/25 01:44:16.703
  STEP: Patching the PVC "pvc-f5697" @ 01/15/25 01:44:16.716
  STEP: Getting PV "pv-5230-pssrn" @ 01/15/25 01:44:16.725
  STEP: Getting PVC "pvc-f5697" @ 01/15/25 01:44:16.73
  STEP: Deleting PVC "pvc-f5697" @ 01/15/25 01:44:16.734
  STEP: Confirm deletion of PVC "pvc-f5697" @ 01/15/25 01:44:16.741
  E0115 01:44:17.593222      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:44:18.595151      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Deleting PV "pv-5230-pssrn" @ 01/15/25 01:44:18.768
  STEP: Confirm deletion of PV "pv-5230-pssrn" @ 01/15/25 01:44:18.78
  E0115 01:44:19.595581      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:44:20.596813      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Recreating another PV & PVC @ 01/15/25 01:44:20.798
  I0115 01:44:20.798155 24 pv.go:394] Creating a PV followed by a PVC
  STEP: Updating the PV "pv-5230-h8lbt" @ 01/15/25 01:44:20.829
  STEP: Updating the PVC "pvc-xbvq5" @ 01/15/25 01:44:20.89
  STEP: Listing PVCs in all namespaces with the labelSelector: "pvc-xbvq5=updated" @ 01/15/25 01:44:20.917
  STEP: Deleting PVC "pvc-xbvq5" via DeleteCollection @ 01/15/25 01:44:20.93
  STEP: Confirm deletion of PVC "pvc-xbvq5" @ 01/15/25 01:44:20.945
  E0115 01:44:21.597817      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:44:22.599204      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Deleting PV "pv-5230-h8lbt" via DeleteCollection @ 01/15/25 01:44:22.956
  STEP: Confirm deletion of PV "pv-5230-h8lbt" @ 01/15/25 01:44:22.965
  E0115 01:44:23.599472      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:44:24.600458      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:44:24.989274 24 persistent_volumes.go:406] AfterEach: deleting 1 PVCs and 1 PVs...
  I0115 01:44:24.989993 24 pv.go:205] Deleting PersistentVolumeClaim "pvc-xbvq5"
  I0115 01:44:25.008736 24 pv.go:193] Deleting PersistentVolume "pv-5230-h8lbt"
  I0115 01:44:25.025216 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pv-5230" for this suite. @ 01/15/25 01:44:25.039
• [8.412 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields of a typed object [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:115
  STEP: Creating a kubernetes client @ 01/15/25 01:44:25.052
  I0115 01:44:25.052066 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename field-validation @ 01/15/25 01:44:25.053
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:44:25.076
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:44:25.082
  STEP: apply creating a deployment @ 01/15/25 01:44:25.088
  I0115 01:44:25.109970 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-439" for this suite. @ 01/15/25 01:44:25.136
• [0.090 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:174
  STEP: Creating a kubernetes client @ 01/15/25 01:44:25.142
  I0115 01:44:25.142126 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename crd-webhook @ 01/15/25 01:44:25.143
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:44:25.203
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:44:25.224
  STEP: Setting up server cert @ 01/15/25 01:44:25.242
  E0115 01:44:25.601222      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 01/15/25 01:44:26.005
  STEP: Deploying the custom resource conversion webhook pod @ 01/15/25 01:44:26.015
  STEP: Wait for the deployment to be ready @ 01/15/25 01:44:26.031
  I0115 01:44:26.042862 24 deployment.go:223] deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
  E0115 01:44:26.601615      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:44:27.602530      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 01/15/25 01:44:28.079
  STEP: Verifying the service has paired with the endpoint @ 01/15/25 01:44:28.114
  E0115 01:44:28.604285      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:44:29.115675 24 util.go:423] Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  I0115 01:44:29.140041 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  E0115 01:44:29.603634      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:44:30.607023      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:44:31.608180      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Creating a v1 custom resource @ 01/15/25 01:44:31.702
  STEP: Create a v2 custom resource @ 01/15/25 01:44:31.724
  STEP: List CRs in v1 @ 01/15/25 01:44:31.778
  STEP: List CRs in v2 @ 01/15/25 01:44:31.785
  I0115 01:44:32.439971 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-webhook-9760" for this suite. @ 01/15/25 01:44:32.502
  E0115 01:44:32.613972      24 retrywatcher.go:160] "Watch failed" err="context canceled"
• [7.508 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:818
  STEP: Creating a kubernetes client @ 01/15/25 01:44:32.672
  I0115 01:44:32.672511 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename gc @ 01/15/25 01:44:32.684
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:44:32.834
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:44:32.883
  I0115 01:44:33.031126 24 garbage_collector.go:840] pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"d47e04be-576f-4f81-984c-2fbde6a42718", Controller:(*bool)(0xc00442873a), BlockOwnerDeletion:(*bool)(0xc00442873b)}}
  I0115 01:44:33.062177 24 garbage_collector.go:844] pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"4be58203-f16f-4262-bcb4-c07db7cc0384", Controller:(*bool)(0xc0044289d2), BlockOwnerDeletion:(*bool)(0xc0044289d3)}}
  I0115 01:44:33.095861 24 garbage_collector.go:848] pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"030c711d-41d0-4f38-a114-4534f243a459", Controller:(*bool)(0xc003d046fa), BlockOwnerDeletion:(*bool)(0xc003d046fb)}}
  E0115 01:44:33.615731      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:44:34.616342      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:44:35.617620      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:44:36.618075      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:44:37.620360      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:44:38.117054 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-4665" for this suite. @ 01/15/25 01:44:38.125
• [5.464 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:144
  STEP: Creating a kubernetes client @ 01/15/25 01:44:38.136
  I0115 01:44:38.136732 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename replicaset @ 01/15/25 01:44:38.138
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:44:38.159
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:44:38.166
  STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota @ 01/15/25 01:44:38.174
  I0115 01:44:38.196725 24 resource.go:87] Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 01/15/25 01:44:38.196
  E0115 01:44:38.621336      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:44:39.624398      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:44:40.624439      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:44:41.625249      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: getting scale subresource @ 01/15/25 01:44:42.247
  STEP: updating a scale subresource @ 01/15/25 01:44:42.265
  STEP: verifying the replicaset Spec.Replicas was modified @ 01/15/25 01:44:42.281
  STEP: Patch a scale subresource @ 01/15/25 01:44:42.288
  I0115 01:44:42.316358 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-4789" for this suite. @ 01/15/25 01:44:42.336
• [4.213 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] StorageClasses CSI Conformance should run through the lifecycle of a StorageClass [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/storageclass.go:53
  STEP: Creating a kubernetes client @ 01/15/25 01:44:42.351
  I0115 01:44:42.351497 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename csi-storageclass @ 01/15/25 01:44:42.353
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:44:42.373
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:44:42.381
  STEP: Creating a StorageClass @ 01/15/25 01:44:42.389
  STEP: Get StorageClass "e2e-f7w6q" @ 01/15/25 01:44:42.399
  STEP: Patching the StorageClass "e2e-f7w6q" @ 01/15/25 01:44:42.404
  STEP: Delete StorageClass "e2e-f7w6q" @ 01/15/25 01:44:42.422
  STEP: Confirm deletion of StorageClass "e2e-f7w6q" @ 01/15/25 01:44:42.471
  STEP: Create a replacement StorageClass @ 01/15/25 01:44:42.486
  STEP: Updating StorageClass "e2e-v2-6rsvx" @ 01/15/25 01:44:42.505
  STEP: Listing all StorageClass with the labelSelector: "e2e-v2-6rsvx=updated" @ 01/15/25 01:44:42.528
  STEP: Deleting StorageClass "e2e-v2-6rsvx" via DeleteCollection @ 01/15/25 01:44:42.548
  STEP: Confirm deletion of StorageClass "e2e-v2-6rsvx" @ 01/15/25 01:44:42.586
  I0115 01:44:42.613285 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  E0115 01:44:42.631647      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Destroying namespace "csi-storageclass-8552" for this suite. @ 01/15/25 01:44:42.637
• [0.304 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:194
  STEP: Creating a kubernetes client @ 01/15/25 01:44:42.655
  I0115 01:44:42.655550 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename downward-api @ 01/15/25 01:44:42.658
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:44:42.692
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:44:42.702
  STEP: Creating a pod to test downward api env vars @ 01/15/25 01:44:42.718
  E0115 01:44:43.632769      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:44:44.639927      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:44:45.641670      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:44:46.641937      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:44:47.643442      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:44:48.644377      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 01:44:48.813
  I0115 01:44:48.824581 24 output.go:207] Trying to get logs from node 192.168.18.92 pod downward-api-37adc349-19fb-40f3-8c72-de3f4bdac2cb container dapi-container: <nil>
  STEP: delete the pod @ 01/15/25 01:44:48.847
  I0115 01:44:48.883647 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-387" for this suite. @ 01/15/25 01:44:48.896
• [6.255 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:125
  STEP: Creating a kubernetes client @ 01/15/25 01:44:48.911
  I0115 01:44:48.911069 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename pod-network-test @ 01/15/25 01:44:48.913
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:44:48.947
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:44:48.957
  STEP: Performing setup for networking test in namespace pod-network-test-8113 @ 01/15/25 01:44:48.967
  STEP: creating a selector @ 01/15/25 01:44:48.967
  STEP: Creating the service pods in kubernetes @ 01/15/25 01:44:48.967
  I0115 01:44:48.968098 24 helper.go:51] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0115 01:44:49.645687      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:44:50.648616      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:44:51.646704      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:44:52.647900      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:44:53.647929      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:44:54.648902      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:44:55.649885      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:44:56.657210      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:44:57.651730      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:44:58.652458      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:44:59.652912      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:45:00.653692      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:45:01.655413      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:45:02.655828      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 01/15/25 01:45:03.094
  E0115 01:45:03.656014      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:45:04.657647      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:45:05.163213 24 utils.go:803] Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
  I0115 01:45:05.163677 24 utils.go:496] Going to poll 10.1.213.92 on port 8081 at least 0 times, with a maximum of 34 tries before failing
  I0115 01:45:05.179328 24 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.1.213.92 8081 | grep -v '^\s*$'] Namespace:pod-network-test-8113 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0115 01:45:05.179456 24 exec_util.go:64] ExecWithOptions: Clientset creation
  I0115 01:45:05.179701 24 exec_util.go:80] ExecWithOptions: execute(POST https://169.169.0.1:443/api/v1/namespaces/pod-network-test-8113/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.1.213.92+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&stderr=true&stdout=true)
  E0115 01:45:05.658415      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:45:06.282874 24 utils.go:513] Found all 1 expected endpoints: [netserver-0]
  I0115 01:45:06.283003 24 utils.go:496] Going to poll 10.1.155.37 on port 8081 at least 0 times, with a maximum of 34 tries before failing
  I0115 01:45:06.287809 24 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.1.155.37 8081 | grep -v '^\s*$'] Namespace:pod-network-test-8113 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0115 01:45:06.287912 24 exec_util.go:64] ExecWithOptions: Clientset creation
  I0115 01:45:06.288035 24 exec_util.go:80] ExecWithOptions: execute(POST https://169.169.0.1:443/api/v1/namespaces/pod-network-test-8113/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+10.1.155.37+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&stderr=true&stdout=true)
  E0115 01:45:06.658994      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:45:07.453364 24 utils.go:513] Found all 1 expected endpoints: [netserver-1]
  I0115 01:45:07.453503 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-8113" for this suite. @ 01/15/25 01:45:07.471
• [18.579 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:235
  STEP: Creating a kubernetes client @ 01/15/25 01:45:07.489
  I0115 01:45:07.489770 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename resourcequota @ 01/15/25 01:45:07.49
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:45:07.505
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:45:07.51
  STEP: Counting existing ResourceQuota @ 01/15/25 01:45:07.515
  E0115 01:45:07.659475      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:45:08.659247      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:45:09.659889      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:45:10.659851      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:45:11.661502      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 01/15/25 01:45:12.519
  STEP: Ensuring resource quota status is calculated @ 01/15/25 01:45:12.524
  E0115 01:45:12.661640      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:45:13.664269      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Creating a Pod that fits quota @ 01/15/25 01:45:14.534
  STEP: Ensuring ResourceQuota status captures the pod usage @ 01/15/25 01:45:14.579
  E0115 01:45:14.665691      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:45:15.666519      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Not allowing a pod to be created that exceeds remaining quota @ 01/15/25 01:45:16.596
  STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) @ 01/15/25 01:45:16.62
  STEP: Ensuring a pod cannot update its resource requirements @ 01/15/25 01:45:16.636
  STEP: Ensuring attempts to update pod resource requirements did not change quota usage @ 01/15/25 01:45:16.65
  E0115 01:45:16.666363      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:45:17.667159      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 01/15/25 01:45:18.665
  E0115 01:45:18.668005      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota status released the pod usage @ 01/15/25 01:45:18.707
  E0115 01:45:19.667895      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:45:20.669305      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:45:20.721931 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-1856" for this suite. @ 01/15/25 01:45:20.738
• [13.290 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] API priority and fairness should support PriorityLevelConfiguration API operations [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/flowcontrol.go:514
  STEP: Creating a kubernetes client @ 01/15/25 01:45:20.78
  I0115 01:45:20.780561 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename apf @ 01/15/25 01:45:20.784
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:45:20.81
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:45:20.816
  STEP: getting /apis @ 01/15/25 01:45:20.822
  STEP: getting /apis/flowcontrol.apiserver.k8s.io @ 01/15/25 01:45:20.829
  STEP: getting /apis/flowcontrol.apiserver.k8s.io/v1 @ 01/15/25 01:45:20.832
  STEP: creating @ 01/15/25 01:45:20.834
  STEP: getting @ 01/15/25 01:45:20.848
  STEP: listing @ 01/15/25 01:45:20.852
  STEP: watching @ 01/15/25 01:45:20.855
  I0115 01:45:20.855696 24 flowcontrol.go:620] starting watch
  STEP: patching @ 01/15/25 01:45:20.857
  STEP: updating @ 01/15/25 01:45:20.863
  I0115 01:45:20.872066 24 flowcontrol.go:648] waiting for watch events with expected annotations
  STEP: getting /status @ 01/15/25 01:45:20.872
  STEP: patching /status @ 01/15/25 01:45:20.875
  STEP: updating /status @ 01/15/25 01:45:20.881
  STEP: deleting @ 01/15/25 01:45:20.889
  STEP: deleting a collection @ 01/15/25 01:45:20.899
  I0115 01:45:20.913666 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "apf-6288" for this suite. @ 01/15/25 01:45:20.917
• [0.144 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:95
  STEP: Creating a kubernetes client @ 01/15/25 01:45:20.924
  I0115 01:45:20.924930 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename configmap @ 01/15/25 01:45:20.925
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:45:20.937
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:45:20.942
  STEP: Creating configMap configmap-4481/configmap-test-50406592-863f-42b6-9760-8c6c2c0a0f9d @ 01/15/25 01:45:20.947
  STEP: Creating a pod to test consume configMaps @ 01/15/25 01:45:20.952
  E0115 01:45:21.669346      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:45:22.670546      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:45:23.672369      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:45:24.672858      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 01:45:24.972
  I0115 01:45:24.976664 24 output.go:207] Trying to get logs from node 192.168.18.92 pod pod-configmaps-e1243ee8-5b85-4805-af5b-caf362166594 container env-test: <nil>
  STEP: delete the pod @ 01/15/25 01:45:24.985
  I0115 01:45:25.001199 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-4481" for this suite. @ 01/15/25 01:45:25.007
• [4.089 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AggregatedDiscovery should support aggregated discovery interface for CRDs [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregated_discovery.go:303
  STEP: Creating a kubernetes client @ 01/15/25 01:45:25.014
  I0115 01:45:25.014224 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename aggregateddiscovery @ 01/15/25 01:45:25.016
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:45:25.03
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:45:25.036
  I0115 01:45:25.041272 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  E0115 01:45:25.674207      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:45:26.674752      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:45:27.675229      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:45:28.211268 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregateddiscovery-6381" for this suite. @ 01/15/25 01:45:28.233
• [3.249 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1075
  STEP: Creating a kubernetes client @ 01/15/25 01:45:28.266
  I0115 01:45:28.267072 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename kubectl @ 01/15/25 01:45:28.275
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:45:28.303
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:45:28.31
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 01/15/25 01:45:28.316
  I0115 01:45:28.316497 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-5779 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
  I0115 01:45:28.435332 24 builder.go:146] stderr: ""
  I0115 01:45:28.435412 24 builder.go:147] stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: replace the image in the pod with server-side dry-run @ 01/15/25 01:45:28.435
  I0115 01:45:28.435507 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-5779 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.36.1-1"}]}} --dry-run=server'
  I0115 01:45:28.529770 24 builder.go:146] stderr: ""
  I0115 01:45:28.529840 24 builder.go:147] stdout: "pod/e2e-test-httpd-pod patched\n"
  STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 01/15/25 01:45:28.529
  I0115 01:45:28.533530 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-5779 delete pods e2e-test-httpd-pod'
  E0115 01:45:28.676214      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:45:29.677023      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:45:29.789833 24 builder.go:146] stderr: ""
  I0115 01:45:29.789901 24 builder.go:147] stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  I0115 01:45:29.790021 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-5779" for this suite. @ 01/15/25 01:45:29.796
• [1.538 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:215
  STEP: Creating a kubernetes client @ 01/15/25 01:45:29.804
  I0115 01:45:29.804375 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename container-probe @ 01/15/25 01:45:29.805
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:45:29.821
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:45:29.826
  STEP: Creating pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961 @ 01/15/25 01:45:29.833
  E0115 01:45:30.677477      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:45:31.685023      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 01/15/25 01:45:31.854
  I0115 01:45:31.860485 24 container_probe.go:1749] Initial restart count of pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 is 0
  I0115 01:45:31.866521 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:45:32.680722      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:45:33.680907      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:45:33.871113 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:45:34.681939      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:45:35.688701      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:45:35.875675 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:45:36.689792      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:45:37.692001      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:45:37.885574 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:45:38.694268      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:45:39.696560      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:45:39.891876 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:45:40.696774      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:45:41.698249      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:45:41.907580 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:45:42.700191      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:45:43.706837      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:45:43.920050 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:45:44.708114      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:45:45.709386      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:45:45.923838 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:45:46.714919      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:45:47.715774      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:45:47.928654 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:45:48.719506      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:45:49.721901      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:45:49.940186 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:45:50.723671      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:45:51.724796      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:45:51.951316 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:45:52.726152      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:45:53.727385      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:45:53.967219 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:45:54.729142      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:45:55.730241      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:45:55.974708 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:45:56.730607      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:45:57.732696      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:45:57.982352 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:45:58.733779      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:45:59.735096      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:45:59.989725 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:46:00.736026      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:46:01.743395      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:46:02.004612 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:46:02.744794      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:46:03.745004      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:46:04.016594 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:46:04.745547      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:46:05.747452      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:46:06.028882 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:46:06.748550      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:46:07.749839      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:46:08.040378 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:46:08.750665      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:46:09.750981      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:46:10.060607 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:46:10.752322      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:46:11.752960      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:46:12.078740 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:46:12.753140      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:46:13.753589      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:46:14.083633 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:46:14.756258      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:46:15.757857      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:46:16.088069 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:46:16.757843      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:46:17.758566      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:46:18.101629 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:46:18.761463      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:46:19.762268      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:46:20.116855 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:46:20.764126      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:46:21.765931      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:46:22.130332 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:46:22.767141      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:46:23.767457      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:46:24.134245 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:46:24.768451      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:46:25.769913      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:46:26.149298 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:46:26.770039      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:46:27.772039      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:46:28.152982 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:46:28.773531      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:46:29.773563      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:46:30.157855 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:46:30.774792      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:46:31.775269      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:46:32.171548 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:46:32.775839      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:46:33.777373      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:46:34.175981 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:46:34.777783      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:46:35.779405      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:46:36.181178 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:46:36.780149      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:46:37.783912      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:46:38.192853 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:46:38.785283      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:46:39.785670      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:46:40.209731 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:46:40.787206      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:46:41.787723      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:46:42.214448 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:46:42.788606      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:46:43.789105      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:46:44.221846 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:46:44.789235      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:46:45.789735      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:46:46.227004 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:46:46.790732      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:46:47.794195      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:46:48.238520 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:46:48.795525      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:46:49.796104      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:46:50.252120 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:46:50.796422      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:46:51.798585      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:46:52.267433 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:46:52.799109      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:46:53.800492      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:46:54.281833 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:46:54.801206      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:46:55.802483      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:46:56.287609 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:46:56.803611      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:46:57.806351      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:46:58.301787 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:46:58.806065      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:46:59.806724      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:47:00.319988 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:47:00.807826      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:47:01.808594      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:47:02.325579 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:47:02.809224      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:47:03.810020      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:47:04.330362 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:47:04.812805      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:47:05.813186      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:47:06.337686 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:47:06.814380      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:47:07.815460      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:47:08.346240 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:47:08.816602      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:47:09.818342      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:47:10.790174 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:47:10.823528      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:47:11.820043      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:47:12.803152 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:47:12.820674      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:47:13.821282      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:47:14.811460 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:47:14.821765      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:47:15.824933      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:47:16.825118      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:47:16.858343 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:47:17.826481      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:47:18.837143      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:47:18.986343 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:47:19.831677      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:47:20.834765      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:47:21.045900 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:47:21.835551      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:47:22.836323      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:47:23.058924 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:47:23.838269      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:47:24.842785      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:47:25.097274 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:47:25.838784      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:47:26.839768      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:47:27.105987 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:47:27.840135      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:47:28.846545      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:47:29.113306 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:47:29.848275      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:47:30.849230      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:47:31.122195 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:47:31.850505      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:47:32.850659      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:47:33.130948 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:47:33.852153      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:47:34.854158      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:47:35.138589 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:47:35.854536      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:47:36.855897      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:47:37.146618 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:47:37.857211      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:47:38.858188      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:47:39.163732 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:47:39.860391      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:47:40.861184      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:47:41.238455 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:47:41.862103      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:47:42.863503      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:47:43.266160 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:47:43.867977      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:47:44.868409      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:47:45.281854 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:47:45.874326      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:47:46.879486      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:47:47.330359 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:47:47.876073      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:47:48.877410      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:47:49.363670 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:47:49.879307      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:47:50.879134      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:47:51.399063 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:47:51.880132      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:47:52.880694      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:47:53.419084 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:47:53.880847      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:47:54.881088      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:47:55.425098 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:47:55.882035      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:47:56.882986      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:47:57.458918 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:47:57.883757      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:47:58.884477      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:47:59.480293 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:47:59.884739      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:48:00.885770      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:48:01.495371 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:48:01.887105      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:48:02.888672      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:48:03.520123 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:48:03.889751      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:48:04.891334      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:48:05.526146 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:48:05.893177      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:48:06.894938      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:48:07.533673 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:48:07.896132      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:48:08.896780      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:48:09.570695 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:48:09.898313      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:48:10.899079      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:48:11.650054 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:48:11.899377      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:48:12.902370      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:48:13.702173 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:48:13.902911      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:48:14.905001      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:48:15.730358 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:48:15.906260      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:48:16.907139      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:48:17.755800 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:48:17.908865      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:48:18.910335      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:48:19.761663 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:48:19.910339      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:48:20.912451      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:48:21.765716 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:48:21.915034      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:48:22.916060      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:48:23.773359 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:48:23.916175      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:48:24.916848      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:48:25.779847 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:48:25.917625      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:48:26.919313      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:48:27.791022 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:48:27.921848      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:48:28.923973      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:48:29.797121 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:48:29.924343      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:48:30.925951      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:48:31.810858 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:48:31.926458      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:48:32.928652      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:48:33.829572 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:48:33.929120      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:48:34.932603      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:48:35.836973 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:48:35.932995      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:48:36.935788      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:48:37.848202 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:48:37.936219      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:48:38.937949      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:48:39.859753 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:48:39.940159      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:48:40.940664      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:48:41.874937 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:48:41.942278      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:48:42.944719      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:48:43.883500 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:48:43.945131      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:48:44.947362      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:48:45.892270 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:48:45.947433      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:48:46.948690      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:48:47.903039 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:48:47.949107      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:48:48.949996      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:48:49.919800 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:48:49.951483      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:48:50.952322      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:48:51.933074 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:48:51.953783      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:48:52.954851      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:48:53.943977 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:48:53.955018      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:48:54.956488      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:48:55.956330 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:48:55.956680      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:48:56.956940      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:48:57.957841      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:48:57.963492 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:48:58.959114      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:48:59.960946      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:48:59.969201 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:49:00.962685      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:49:01.966829      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:49:01.996950 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:49:02.968835      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:49:03.969459      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:49:04.015035 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:49:04.970298      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:49:05.970980      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:49:06.019595 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:49:06.972159      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:49:07.973661      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:49:08.032526 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:49:08.974307      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:49:09.974651      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:49:10.046599 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:49:10.976115      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:49:11.978142      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:49:12.061105 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:49:12.978830      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:49:13.979955      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:49:14.076164 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:49:14.981276      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:49:15.982443      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:49:16.088781 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:49:16.983093      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:49:17.985011      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:49:18.097856 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:49:18.986237      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:49:19.987706      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:49:20.110377 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:49:20.989193      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:49:21.990434      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:49:22.132066 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:49:22.991536      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:49:23.991943      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:49:24.135997 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:49:24.992774      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:49:25.993841      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:49:26.164169 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:49:26.994740      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:49:27.997084      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:49:28.181625 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:49:28.998940      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:49:30.000327      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:49:30.205020 24 container_probe.go:1759] Get pod test-webserver-da8ea4ec-fd3a-4956-b7fa-2359fe57b452 in namespace container-probe-3961
  E0115 01:49:31.002740      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:49:32.005321      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 01/15/25 01:49:32.207
  I0115 01:49:32.289391 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-3961" for this suite. @ 01/15/25 01:49:32.301
• [242.515 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:96
  STEP: Creating a kubernetes client @ 01/15/25 01:49:32.32
  I0115 01:49:32.320427 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename pod-network-test @ 01/15/25 01:49:32.323
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:49:32.362
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:49:32.367
  STEP: Performing setup for networking test in namespace pod-network-test-8200 @ 01/15/25 01:49:32.375
  STEP: creating a selector @ 01/15/25 01:49:32.375
  STEP: Creating the service pods in kubernetes @ 01/15/25 01:49:32.375
  I0115 01:49:32.375206 24 helper.go:51] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0115 01:49:33.005822      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:49:34.008628      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:49:35.007884      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:49:36.008489      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:49:37.009365      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:49:38.010243      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:49:39.010976      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:49:40.012073      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:49:41.012301      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:49:42.012779      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:49:43.014781      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:49:44.015345      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:49:45.016234      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:49:46.017801      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 01/15/25 01:49:46.53
  E0115 01:49:47.018024      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:49:48.018699      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:49:48.579541 24 utils.go:803] Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
  I0115 01:49:48.579616 24 networking.go:42] Breadth first check of 10.1.213.106 on host 192.168.18.91...
  I0115 01:49:48.598749 24 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.1.155.32:9080/dial?request=hostname&protocol=udp&host=10.1.213.106&port=8081&tries=1'] Namespace:pod-network-test-8200 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0115 01:49:48.598829 24 exec_util.go:64] ExecWithOptions: Clientset creation
  I0115 01:49:48.598913 24 exec_util.go:80] ExecWithOptions: execute(POST https://169.169.0.1:443/api/v1/namespaces/pod-network-test-8200/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.1.155.32%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.1.213.106%26port%3D8081%26tries%3D1%27&container=webserver&stderr=true&stdout=true)
  I0115 01:49:48.750237 24 utils.go:356] Waiting for responses: map[]
  I0115 01:49:48.750312 24 utils.go:360] reached 10.1.213.106 after 0/1 tries
  I0115 01:49:48.750333 24 networking.go:42] Breadth first check of 10.1.155.28 on host 192.168.18.92...
  I0115 01:49:48.755398 24 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.1.155.32:9080/dial?request=hostname&protocol=udp&host=10.1.155.28&port=8081&tries=1'] Namespace:pod-network-test-8200 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0115 01:49:48.755502 24 exec_util.go:64] ExecWithOptions: Clientset creation
  I0115 01:49:48.755607 24 exec_util.go:80] ExecWithOptions: execute(POST https://169.169.0.1:443/api/v1/namespaces/pod-network-test-8200/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.1.155.32%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D10.1.155.28%26port%3D8081%26tries%3D1%27&container=webserver&stderr=true&stdout=true)
  I0115 01:49:48.862126 24 utils.go:356] Waiting for responses: map[]
  I0115 01:49:48.862235 24 utils.go:360] reached 10.1.155.28 after 0/1 tries
  I0115 01:49:48.862261 24 networking.go:53] Going to retry 0 out of 2 pods....
  I0115 01:49:48.862408 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-8200" for this suite. @ 01/15/25 01:49:48.867
• [16.555 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:282
  STEP: Creating a kubernetes client @ 01/15/25 01:49:48.876
  I0115 01:49:48.876608 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename webhook @ 01/15/25 01:49:48.877
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:49:48.928
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:49:48.939
  E0115 01:49:49.019188      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Setting up server cert @ 01/15/25 01:49:49.029
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 01/15/25 01:49:49.62
  STEP: Deploying the webhook pod @ 01/15/25 01:49:49.628
  STEP: Wait for the deployment to be ready @ 01/15/25 01:49:49.641
  I0115 01:49:49.648292 24 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0115 01:49:50.019647      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:49:51.019761      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 01/15/25 01:49:51.69
  STEP: Verifying the service has paired with the endpoint @ 01/15/25 01:49:51.707
  E0115 01:49:52.020332      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:49:52.708075 24 util.go:423] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  I0115 01:49:52.734271 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  E0115 01:49:53.021397      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-2789-crds.webhook.example.com via the AdmissionRegistration API @ 01/15/25 01:49:53.268
  STEP: Creating a custom resource that should be mutated by the webhook @ 01/15/25 01:49:53.304
  E0115 01:49:54.021872      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:49:55.023640      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:49:55.958638 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-3637" for this suite. @ 01/15/25 01:49:55.971
  STEP: Destroying namespace "webhook-markers-1800" for this suite. @ 01/15/25 01:49:55.982
• [7.116 seconds]
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1044
  STEP: Creating a kubernetes client @ 01/15/25 01:49:55.992
  I0115 01:49:55.992896 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename kubectl @ 01/15/25 01:49:55.994
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:49:56.018
  E0115 01:49:56.027754      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:49:56.031
  STEP: create deployment with httpd image @ 01/15/25 01:49:56.037
  I0115 01:49:56.037886 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-2076 create -f -'
  I0115 01:49:56.212835 24 builder.go:146] stderr: ""
  I0115 01:49:56.212938 24 builder.go:147] stdout: "deployment.apps/httpd-deployment created\n"
  STEP: verify diff finds difference between live and declared image @ 01/15/25 01:49:56.212
  I0115 01:49:56.213074 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-2076 diff -f -'
  I0115 01:49:56.403927 24 builder.go:135] rc: 1
  I0115 01:49:56.404069 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-2076 delete -f -'
  I0115 01:49:56.500148 24 builder.go:146] stderr: ""
  I0115 01:49:56.500223 24 builder.go:147] stdout: "deployment.apps \"httpd-deployment\" deleted\n"
  I0115 01:49:56.500529 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-2076" for this suite. @ 01/15/25 01:49:56.506
• [0.520 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:146
  STEP: Creating a kubernetes client @ 01/15/25 01:49:56.516
  I0115 01:49:56.516593 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename custom-resource-definition @ 01/15/25 01:49:56.518
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:49:56.54
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:49:56.546
  I0115 01:49:56.551951 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  E0115 01:49:57.030710      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:49:57.117665 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-3351" for this suite. @ 01/15/25 01:49:57.133
• [0.648 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should allow opting out of API token automount [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:192
  STEP: Creating a kubernetes client @ 01/15/25 01:49:57.164
  I0115 01:49:57.164646 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename svcaccounts @ 01/15/25 01:49:57.166
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:49:57.386
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:49:57.404
  I0115 01:49:57.460582 24 service_accounts.go:282] created pod pod-service-account-defaultsa
  I0115 01:49:57.460718 24 service_accounts.go:296] pod pod-service-account-defaultsa service account token volume mount: true
  I0115 01:49:57.474124 24 service_accounts.go:282] created pod pod-service-account-mountsa
  I0115 01:49:57.474183 24 service_accounts.go:296] pod pod-service-account-mountsa service account token volume mount: true
  I0115 01:49:57.501175 24 service_accounts.go:282] created pod pod-service-account-nomountsa
  I0115 01:49:57.501240 24 service_accounts.go:296] pod pod-service-account-nomountsa service account token volume mount: false
  I0115 01:49:57.512924 24 service_accounts.go:282] created pod pod-service-account-defaultsa-mountspec
  I0115 01:49:57.512976 24 service_accounts.go:296] pod pod-service-account-defaultsa-mountspec service account token volume mount: true
  I0115 01:49:57.527856 24 service_accounts.go:282] created pod pod-service-account-mountsa-mountspec
  I0115 01:49:57.527921 24 service_accounts.go:296] pod pod-service-account-mountsa-mountspec service account token volume mount: true
  I0115 01:49:57.556936 24 service_accounts.go:282] created pod pod-service-account-nomountsa-mountspec
  I0115 01:49:57.556999 24 service_accounts.go:296] pod pod-service-account-nomountsa-mountspec service account token volume mount: true
  I0115 01:49:57.587252 24 service_accounts.go:282] created pod pod-service-account-defaultsa-nomountspec
  I0115 01:49:57.587608 24 service_accounts.go:296] pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
  I0115 01:49:57.618695 24 service_accounts.go:282] created pod pod-service-account-mountsa-nomountspec
  I0115 01:49:57.618767 24 service_accounts.go:296] pod pod-service-account-mountsa-nomountspec service account token volume mount: false
  I0115 01:49:57.652536 24 service_accounts.go:282] created pod pod-service-account-nomountsa-nomountspec
  I0115 01:49:57.652590 24 service_accounts.go:296] pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
  I0115 01:49:57.652741 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-5639" for this suite. @ 01/15/25 01:49:57.711
• [0.604 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:90
  STEP: Creating a kubernetes client @ 01/15/25 01:49:57.776
  I0115 01:49:57.776256 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename disruption @ 01/15/25 01:49:57.787
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:49:57.876
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:49:57.9
  STEP: Creating a kubernetes client @ 01/15/25 01:49:57.919
  I0115 01:49:57.919533 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename disruption-2 @ 01/15/25 01:49:57.921
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:49:58.015
  E0115 01:49:58.059670      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:49:58.107
  STEP: Waiting for the pdb to be processed @ 01/15/25 01:49:58.171
  E0115 01:49:59.061920      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:50:00.066109      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Waiting for the pdb to be processed @ 01/15/25 01:50:00.183
  STEP: Waiting for the pdb to be processed @ 01/15/25 01:50:00.198
  E0115 01:50:01.067759      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:50:02.069077      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: listing a collection of PDBs across all namespaces @ 01/15/25 01:50:02.203
  STEP: listing a collection of PDBs in namespace disruption-6220 @ 01/15/25 01:50:02.212
  STEP: deleting a collection of PDBs @ 01/15/25 01:50:02.218
  STEP: Waiting for the PDB collection to be deleted @ 01/15/25 01:50:02.24
  I0115 01:50:02.247524 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-2-3666" for this suite. @ 01/15/25 01:50:02.262
  I0115 01:50:02.279548 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-6220" for this suite. @ 01/15/25 01:50:02.399
• [4.666 seconds]
------------------------------
S
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:338
  STEP: Creating a kubernetes client @ 01/15/25 01:50:02.442
  I0115 01:50:02.442052 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename statefulset @ 01/15/25 01:50:02.449
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:50:02.486
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:50:02.493
  STEP: Creating service test in namespace statefulset-6900 @ 01/15/25 01:50:02.5
  STEP: Creating a new StatefulSet @ 01/15/25 01:50:02.513
  I0115 01:50:02.533590 24 wait.go:40] Found 0 stateful pods, waiting for 3
  E0115 01:50:03.068952      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:50:04.069104      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:50:05.091267      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:50:06.098288      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:50:07.104295      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:50:08.108439      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:50:09.111501      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:50:10.110873      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:50:11.113891      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:50:12.114726      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:50:12.535654 24 wait.go:40] Found 2 stateful pods, waiting for 3
  E0115 01:50:13.115305      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:50:14.116960      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:50:15.117079      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:50:16.118424      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:50:17.127933      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:50:18.128605      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:50:19.129796      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:50:20.130684      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:50:21.131445      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:50:22.133222      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:50:22.532898 24 wait.go:50] Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  I0115 01:50:22.532985 24 wait.go:50] Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  I0115 01:50:22.533009 24 wait.go:50] Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 @ 01/15/25 01:50:22.549
  I0115 01:50:22.564148 24 statefulset.go:2510] Updating stateful set ss2
  STEP: Creating a new revision @ 01/15/25 01:50:22.564
  E0115 01:50:23.133269      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:50:24.135183      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:50:25.135553      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:50:26.142118      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:50:27.143882      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:50:28.144869      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:50:29.145678      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:50:30.146275      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:50:31.149960      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:50:32.147892      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Not applying an update when the partition is greater than the number of replicas @ 01/15/25 01:50:32.59
  STEP: Performing a canary update @ 01/15/25 01:50:32.591
  I0115 01:50:32.629606 24 statefulset.go:2510] Updating stateful set ss2
  I0115 01:50:32.665718 24 wait.go:74] Waiting for Pod statefulset-6900/ss2-2 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0115 01:50:33.149108      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:50:34.149925      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:50:35.157901      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:50:36.158991      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:50:37.159996      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:50:38.160465      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:50:39.161868      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:50:40.161816      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:50:41.163147      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:50:42.164564      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Restoring Pods to the correct revision when they are deleted @ 01/15/25 01:50:42.665
  I0115 01:50:42.747878 24 wait.go:40] Found 2 stateful pods, waiting for 3
  E0115 01:50:43.165159      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:50:44.166089      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:50:45.166796      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:50:46.167417      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:50:47.167896      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:50:48.167983      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:50:49.169103      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:50:50.169878      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:50:51.176675      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:50:52.180298      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:50:52.747233 24 wait.go:50] Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  I0115 01:50:52.747523 24 wait.go:50] Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  I0115 01:50:52.747591 24 wait.go:50] Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Performing a phased rolling update @ 01/15/25 01:50:52.781
  I0115 01:50:52.816092 24 statefulset.go:2510] Updating stateful set ss2
  I0115 01:50:52.883452 24 wait.go:74] Waiting for Pod statefulset-6900/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0115 01:50:53.180887      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:50:54.184627      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:50:55.185258      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:50:56.187122      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:50:57.188564      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:50:58.189439      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:50:59.190090      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:51:00.191251      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:51:01.192325      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:51:02.193058      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:51:02.832280 24 statefulset.go:2510] Updating stateful set ss2
  I0115 01:51:02.841207 24 wait.go:56] Waiting for StatefulSet statefulset-6900/ss2 to complete update
  I0115 01:51:02.841312 24 wait.go:63] Waiting for Pod statefulset-6900/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E0115 01:51:03.193408      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:51:04.194341      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:51:05.194932      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:51:06.196354      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:51:07.197940      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:51:08.199819      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:51:09.201140      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:51:10.203365      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:51:11.204258      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:51:12.206057      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:51:12.860365 24 statefulset.go:138] Deleting all statefulset in ns statefulset-6900
  I0115 01:51:12.876021 24 rest.go:152] Scaling statefulset ss2 to 0
  E0115 01:51:13.207476      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:51:14.208418      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:51:15.209022      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:51:16.208995      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:51:17.209689      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:51:18.213477      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:51:19.214412      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:51:20.231675      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:51:21.231748      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:51:22.231429      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:51:22.924555 24 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I0115 01:51:22.929276 24 rest.go:90] Deleting statefulset ss2
  I0115 01:51:22.951030 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-6900" for this suite. @ 01/15/25 01:51:22.958
• [80.527 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect duplicates in a CR when preserving unknown fields [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:620
  STEP: Creating a kubernetes client @ 01/15/25 01:51:22.969
  I0115 01:51:22.969972 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename field-validation @ 01/15/25 01:51:22.971
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:51:22.991
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:51:23
  I0115 01:51:23.008142 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  E0115 01:51:23.231970      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:51:24.237418      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:51:25.237646      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  W0115 01:51:25.567520      24 warnings.go:70] unknown field "alpha"
  W0115 01:51:25.567688      24 warnings.go:70] unknown field "beta"
  W0115 01:51:25.567721      24 warnings.go:70] unknown field "delta"
  W0115 01:51:25.567738      24 warnings.go:70] unknown field "epsilon"
  W0115 01:51:25.567755      24 warnings.go:70] unknown field "gamma"
  I0115 01:51:26.182011 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-2548" for this suite. @ 01/15/25 01:51:26.197
• [3.238 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:443
  STEP: Creating a kubernetes client @ 01/15/25 01:51:26.208
  I0115 01:51:26.208879 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename crd-publish-openapi @ 01/15/25 01:51:26.214
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:51:26.235
  E0115 01:51:26.238357      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:51:26.243
  STEP: set up a multi version CRD @ 01/15/25 01:51:26.249
  I0115 01:51:26.250313 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  E0115 01:51:27.238402      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:51:28.240479      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:51:29.241443      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:51:30.241803      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: mark a version not serverd @ 01/15/25 01:51:30.338
  STEP: check the unserved version gets removed @ 01/15/25 01:51:30.36
  E0115 01:51:31.243064      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: check the other version is not changed @ 01/15/25 01:51:31.37
  E0115 01:51:32.243342      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:51:33.244312      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:51:34.246809      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:51:34.493194 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-175" for this suite. @ 01/15/25 01:51:34.504
• [8.302 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:890
  STEP: Creating a kubernetes client @ 01/15/25 01:51:34.511
  I0115 01:51:34.511050 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename daemonsets @ 01/15/25 01:51:34.513
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:51:34.527
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:51:34.533
  STEP: Creating simple DaemonSet "daemon-set" @ 01/15/25 01:51:34.617
  STEP: Check that daemon pods launch on every node of the cluster. @ 01/15/25 01:51:34.624
  I0115 01:51:34.778927 24 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0115 01:51:34.779122 24 fixtures.go:131] Node 192.168.18.91 is running 0 daemon pod, expected 1
  E0115 01:51:35.247084      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:51:35.644734 24 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0115 01:51:35.644835 24 fixtures.go:131] Node 192.168.18.91 is running 0 daemon pod, expected 1
  E0115 01:51:36.247341      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:51:36.638520 24 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0115 01:51:36.638596 24 fixtures.go:136] Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Getting /status @ 01/15/25 01:51:36.643
  I0115 01:51:36.649967 24 daemon_set.go:927] Daemon Set daemon-set has Conditions: []
  STEP: updating the DaemonSet Status @ 01/15/25 01:51:36.65
  I0115 01:51:36.662369 24 daemon_set.go:947] updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the daemon set status to be updated @ 01/15/25 01:51:36.662
  I0115 01:51:36.666614 24 daemon_set.go:972] Observed &DaemonSet event: ADDED
  I0115 01:51:36.666834 24 daemon_set.go:972] Observed &DaemonSet event: MODIFIED
  I0115 01:51:36.666928 24 daemon_set.go:972] Observed &DaemonSet event: MODIFIED
  I0115 01:51:36.667404 24 daemon_set.go:972] Observed &DaemonSet event: MODIFIED
  I0115 01:51:36.667545 24 daemon_set.go:972] Observed &DaemonSet event: MODIFIED
  I0115 01:51:36.667571 24 daemon_set.go:965] Found daemon set daemon-set in namespace daemonsets-4173 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  I0115 01:51:36.667586 24 daemon_set.go:976] Daemon set daemon-set has an updated status
  STEP: patching the DaemonSet Status @ 01/15/25 01:51:36.667
  STEP: watching for the daemon set status to be patched @ 01/15/25 01:51:36.677
  I0115 01:51:36.680943 24 daemon_set.go:1016] Observed &DaemonSet event: ADDED
  I0115 01:51:36.681156 24 daemon_set.go:1016] Observed &DaemonSet event: MODIFIED
  I0115 01:51:36.681282 24 daemon_set.go:1016] Observed &DaemonSet event: MODIFIED
  I0115 01:51:36.681646 24 daemon_set.go:1016] Observed &DaemonSet event: MODIFIED
  I0115 01:51:36.681898 24 daemon_set.go:1016] Observed &DaemonSet event: MODIFIED
  I0115 01:51:36.681944 24 daemon_set.go:1012] Observed daemon set daemon-set in namespace daemonsets-4173 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  I0115 01:51:36.682161 24 daemon_set.go:1016] Observed &DaemonSet event: MODIFIED
  I0115 01:51:36.682206 24 daemon_set.go:1009] Found daemon set daemon-set in namespace daemonsets-4173 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
  I0115 01:51:36.682308 24 daemon_set.go:1020] Daemon set daemon-set has a patched status
  STEP: Deleting DaemonSet "daemon-set" @ 01/15/25 01:51:36.687
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4173, will wait for the garbage collector to delete the pods @ 01/15/25 01:51:36.687
  I0115 01:51:36.749449 24 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 6.264395ms
  I0115 01:51:36.851027 24 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 101.57179ms
  E0115 01:51:37.247730      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:51:38.249238      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:51:39.249804      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:51:39.369050 24 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0115 01:51:39.369207 24 fixtures.go:136] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0115 01:51:39.392629 24 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"164409"},"items":null}

  I0115 01:51:39.413959 24 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"164409"},"items":null}

  I0115 01:51:39.441203 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-4173" for this suite. @ 01/15/25 01:51:39.447
• [4.945 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:208
  STEP: Creating a kubernetes client @ 01/15/25 01:51:39.457
  I0115 01:51:39.457105 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename dns @ 01/15/25 01:51:39.459
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:51:39.524
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:51:39.544
  STEP: Creating a test headless service @ 01/15/25 01:51:39.552
  STEP: Running these commands on agnhost: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/agnhost_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/agnhost_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6617 A)" && test -n "$$check" && echo OK > /results/agnhost_udp@dns-test-service.dns-6617;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6617 A)" && test -n "$$check" && echo OK > /results/agnhost_tcp@dns-test-service.dns-6617;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6617.svc A)" && test -n "$$check" && echo OK > /results/agnhost_udp@dns-test-service.dns-6617.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6617.svc A)" && test -n "$$check" && echo OK > /results/agnhost_tcp@dns-test-service.dns-6617.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6617.svc SRV)" && test -n "$$check" && echo OK > /results/agnhost_udp@_http._tcp.dns-test-service.dns-6617.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6617.svc SRV)" && test -n "$$check" && echo OK > /results/agnhost_tcp@_http._tcp.dns-test-service.dns-6617.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6617.svc SRV)" && test -n "$$check" && echo OK > /results/agnhost_udp@_http._tcp.test-service-2.dns-6617.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6617.svc SRV)" && test -n "$$check" && echo OK > /results/agnhost_tcp@_http._tcp.test-service-2.dns-6617.svc;check="$$(dig +notcp +noall +answer +search 60.114.169.169.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/169.169.114.60_udp@PTR;check="$$(dig +tcp +noall +answer +search 60.114.169.169.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/169.169.114.60_tcp@PTR;sleep 1; done
   @ 01/15/25 01:51:39.571
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6617 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-6617;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6617 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-6617;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6617.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-6617.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6617.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-6617.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6617.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-6617.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6617.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-6617.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6617.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-6617.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6617.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-6617.svc;check="$$(dig +notcp +noall +answer +search 60.114.169.169.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/169.169.114.60_udp@PTR;check="$$(dig +tcp +noall +answer +search 60.114.169.169.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/169.169.114.60_tcp@PTR;sleep 1; done
   @ 01/15/25 01:51:39.571
  STEP: creating a pod to probe DNS @ 01/15/25 01:51:39.571
  STEP: submitting the pod to kubernetes @ 01/15/25 01:51:39.571
  E0115 01:51:40.250504      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:51:41.257586      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 01/15/25 01:51:41.616
  STEP: looking for the results for each expected name from probers @ 01/15/25 01:51:41.626
  I0115 01:51:41.640662 24 dns_common.go:495] Unable to read agnhost_udp@dns-test-service from pod dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca: the server could not find the requested resource (get pods dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca)
  I0115 01:51:41.651332 24 dns_common.go:495] Unable to read agnhost_tcp@dns-test-service from pod dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca: the server could not find the requested resource (get pods dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca)
  I0115 01:51:41.663233 24 dns_common.go:495] Unable to read agnhost_udp@dns-test-service.dns-6617 from pod dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca: the server could not find the requested resource (get pods dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca)
  I0115 01:51:41.670856 24 dns_common.go:495] Unable to read agnhost_tcp@dns-test-service.dns-6617 from pod dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca: the server could not find the requested resource (get pods dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca)
  I0115 01:51:41.677258 24 dns_common.go:495] Unable to read agnhost_udp@dns-test-service.dns-6617.svc from pod dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca: the server could not find the requested resource (get pods dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca)
  I0115 01:51:41.682791 24 dns_common.go:495] Unable to read agnhost_tcp@dns-test-service.dns-6617.svc from pod dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca: the server could not find the requested resource (get pods dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca)
  I0115 01:51:41.688222 24 dns_common.go:495] Unable to read agnhost_udp@_http._tcp.dns-test-service.dns-6617.svc from pod dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca: the server could not find the requested resource (get pods dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca)
  I0115 01:51:41.693519 24 dns_common.go:495] Unable to read agnhost_tcp@_http._tcp.dns-test-service.dns-6617.svc from pod dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca: the server could not find the requested resource (get pods dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca)
  I0115 01:51:41.698285 24 dns_common.go:495] Unable to read agnhost_udp@_http._tcp.test-service-2.dns-6617.svc from pod dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca: the server could not find the requested resource (get pods dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca)
  I0115 01:51:41.702798 24 dns_common.go:495] Unable to read agnhost_tcp@_http._tcp.test-service-2.dns-6617.svc from pod dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca: the server could not find the requested resource (get pods dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca)
  I0115 01:51:41.708527 24 dns_common.go:495] Unable to read 169.169.114.60_udp@PTR from pod dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca: the server could not find the requested resource (get pods dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca)
  I0115 01:51:41.713674 24 dns_common.go:495] Unable to read 169.169.114.60_tcp@PTR from pod dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca: the server could not find the requested resource (get pods dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca)
  I0115 01:51:41.719281 24 dns_common.go:495] Unable to read jessie_udp@dns-test-service from pod dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca: the server could not find the requested resource (get pods dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca)
  I0115 01:51:41.725245 24 dns_common.go:495] Unable to read jessie_tcp@dns-test-service from pod dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca: the server could not find the requested resource (get pods dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca)
  I0115 01:51:41.730444 24 dns_common.go:495] Unable to read jessie_udp@dns-test-service.dns-6617 from pod dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca: the server could not find the requested resource (get pods dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca)
  I0115 01:51:41.735405 24 dns_common.go:495] Unable to read jessie_tcp@dns-test-service.dns-6617 from pod dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca: the server could not find the requested resource (get pods dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca)
  I0115 01:51:41.741139 24 dns_common.go:495] Unable to read jessie_udp@dns-test-service.dns-6617.svc from pod dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca: the server could not find the requested resource (get pods dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca)
  I0115 01:51:41.746156 24 dns_common.go:495] Unable to read jessie_tcp@dns-test-service.dns-6617.svc from pod dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca: the server could not find the requested resource (get pods dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca)
  I0115 01:51:41.751632 24 dns_common.go:495] Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6617.svc from pod dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca: the server could not find the requested resource (get pods dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca)
  I0115 01:51:41.756865 24 dns_common.go:495] Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6617.svc from pod dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca: the server could not find the requested resource (get pods dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca)
  I0115 01:51:41.762307 24 dns_common.go:495] Unable to read jessie_udp@_http._tcp.test-service-2.dns-6617.svc from pod dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca: the server could not find the requested resource (get pods dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca)
  I0115 01:51:41.766806 24 dns_common.go:495] Unable to read jessie_tcp@_http._tcp.test-service-2.dns-6617.svc from pod dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca: the server could not find the requested resource (get pods dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca)
  I0115 01:51:41.772900 24 dns_common.go:495] Unable to read 169.169.114.60_udp@PTR from pod dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca: the server could not find the requested resource (get pods dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca)
  I0115 01:51:41.778194 24 dns_common.go:495] Unable to read 169.169.114.60_tcp@PTR from pod dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca: the server could not find the requested resource (get pods dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca)
  I0115 01:51:41.778289 24 dns_common.go:506] Lookups using dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca failed for: [agnhost_udp@dns-test-service agnhost_tcp@dns-test-service agnhost_udp@dns-test-service.dns-6617 agnhost_tcp@dns-test-service.dns-6617 agnhost_udp@dns-test-service.dns-6617.svc agnhost_tcp@dns-test-service.dns-6617.svc agnhost_udp@_http._tcp.dns-test-service.dns-6617.svc agnhost_tcp@_http._tcp.dns-test-service.dns-6617.svc agnhost_udp@_http._tcp.test-service-2.dns-6617.svc agnhost_tcp@_http._tcp.test-service-2.dns-6617.svc 169.169.114.60_udp@PTR 169.169.114.60_tcp@PTR jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6617 jessie_tcp@dns-test-service.dns-6617 jessie_udp@dns-test-service.dns-6617.svc jessie_tcp@dns-test-service.dns-6617.svc jessie_udp@_http._tcp.dns-test-service.dns-6617.svc jessie_tcp@_http._tcp.dns-test-service.dns-6617.svc jessie_udp@_http._tcp.test-service-2.dns-6617.svc jessie_tcp@_http._tcp.test-service-2.dns-6617.svc 169.169.114.60_udp@PTR 169.169.114.60_tcp@PTR]

  I0115 01:51:41.790132 24 dns_common.go:514] Pod client logs for webserver: 
  I0115 01:51:41.797057 24 dns_common.go:514] Pod client logs for agnhost-querier: 
  I0115 01:51:41.806323 24 dns_common.go:514] Pod client logs for jessie-querier: 
  E0115 01:51:42.258061      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:51:43.259155      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:51:44.259681      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:51:45.261057      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:51:46.261771      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:51:46.686282 24 dns_common.go:495] Unable to read jessie_udp@dns-test-service from pod dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca: the server could not find the requested resource (get pods dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca)
  I0115 01:51:46.691870 24 dns_common.go:495] Unable to read jessie_tcp@dns-test-service from pod dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca: the server could not find the requested resource (get pods dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca)
  I0115 01:51:46.696841 24 dns_common.go:495] Unable to read jessie_udp@dns-test-service.dns-6617 from pod dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca: the server could not find the requested resource (get pods dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca)
  I0115 01:51:46.702220 24 dns_common.go:495] Unable to read jessie_tcp@dns-test-service.dns-6617 from pod dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca: the server could not find the requested resource (get pods dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca)
  I0115 01:51:46.708326 24 dns_common.go:495] Unable to read jessie_udp@dns-test-service.dns-6617.svc from pod dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca: the server could not find the requested resource (get pods dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca)
  I0115 01:51:46.712860 24 dns_common.go:495] Unable to read jessie_tcp@dns-test-service.dns-6617.svc from pod dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca: the server could not find the requested resource (get pods dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca)
  I0115 01:51:46.716721 24 dns_common.go:495] Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6617.svc from pod dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca: the server could not find the requested resource (get pods dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca)
  I0115 01:51:46.721555 24 dns_common.go:495] Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6617.svc from pod dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca: the server could not find the requested resource (get pods dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca)
  I0115 01:51:46.726234 24 dns_common.go:495] Unable to read jessie_udp@_http._tcp.test-service-2.dns-6617.svc from pod dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca: the server could not find the requested resource (get pods dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca)
  I0115 01:51:46.730514 24 dns_common.go:495] Unable to read jessie_tcp@_http._tcp.test-service-2.dns-6617.svc from pod dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca: the server could not find the requested resource (get pods dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca)
  I0115 01:51:46.739869 24 dns_common.go:506] Lookups using dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca failed for: [jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6617 jessie_tcp@dns-test-service.dns-6617 jessie_udp@dns-test-service.dns-6617.svc jessie_tcp@dns-test-service.dns-6617.svc jessie_udp@_http._tcp.dns-test-service.dns-6617.svc jessie_tcp@_http._tcp.dns-test-service.dns-6617.svc jessie_udp@_http._tcp.test-service-2.dns-6617.svc jessie_tcp@_http._tcp.test-service-2.dns-6617.svc]

  I0115 01:51:46.747020 24 dns_common.go:514] Pod client logs for webserver: 
  I0115 01:51:46.756826 24 dns_common.go:514] Pod client logs for agnhost-querier: 
  I0115 01:51:46.763153 24 dns_common.go:514] Pod client logs for jessie-querier: 
  E0115 01:51:47.262125      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:51:48.264122      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:51:49.265352      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:51:50.265348      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:51:51.267662      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:51:51.730146 24 dns_common.go:495] Unable to read jessie_udp@dns-test-service from pod dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca: the server could not find the requested resource (get pods dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca)
  I0115 01:51:51.734901 24 dns_common.go:495] Unable to read jessie_tcp@dns-test-service from pod dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca: the server could not find the requested resource (get pods dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca)
  I0115 01:51:51.740906 24 dns_common.go:495] Unable to read jessie_udp@dns-test-service.dns-6617 from pod dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca: the server could not find the requested resource (get pods dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca)
  I0115 01:51:51.746407 24 dns_common.go:495] Unable to read jessie_tcp@dns-test-service.dns-6617 from pod dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca: the server could not find the requested resource (get pods dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca)
  I0115 01:51:51.751921 24 dns_common.go:495] Unable to read jessie_udp@dns-test-service.dns-6617.svc from pod dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca: the server could not find the requested resource (get pods dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca)
  I0115 01:51:51.756658 24 dns_common.go:495] Unable to read jessie_tcp@dns-test-service.dns-6617.svc from pod dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca: the server could not find the requested resource (get pods dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca)
  I0115 01:51:51.762304 24 dns_common.go:495] Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6617.svc from pod dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca: the server could not find the requested resource (get pods dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca)
  I0115 01:51:51.767427 24 dns_common.go:495] Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6617.svc from pod dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca: the server could not find the requested resource (get pods dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca)
  I0115 01:51:51.772386 24 dns_common.go:495] Unable to read jessie_udp@_http._tcp.test-service-2.dns-6617.svc from pod dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca: the server could not find the requested resource (get pods dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca)
  I0115 01:51:51.777833 24 dns_common.go:495] Unable to read jessie_tcp@_http._tcp.test-service-2.dns-6617.svc from pod dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca: the server could not find the requested resource (get pods dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca)
  I0115 01:51:51.788269 24 dns_common.go:506] Lookups using dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca failed for: [jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6617 jessie_tcp@dns-test-service.dns-6617 jessie_udp@dns-test-service.dns-6617.svc jessie_tcp@dns-test-service.dns-6617.svc jessie_udp@_http._tcp.dns-test-service.dns-6617.svc jessie_tcp@_http._tcp.dns-test-service.dns-6617.svc jessie_udp@_http._tcp.test-service-2.dns-6617.svc jessie_tcp@_http._tcp.test-service-2.dns-6617.svc]

  I0115 01:51:51.795953 24 dns_common.go:514] Pod client logs for webserver: 
  I0115 01:51:51.803719 24 dns_common.go:514] Pod client logs for agnhost-querier: 
  I0115 01:51:51.811599 24 dns_common.go:514] Pod client logs for jessie-querier: 
  E0115 01:51:52.270330      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:51:53.281302      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:51:54.286462      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:51:55.284959      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:51:56.286211      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:51:56.678877 24 dns_common.go:495] Unable to read jessie_udp@dns-test-service from pod dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca: the server could not find the requested resource (get pods dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca)
  I0115 01:51:56.683554 24 dns_common.go:495] Unable to read jessie_tcp@dns-test-service from pod dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca: the server could not find the requested resource (get pods dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca)
  I0115 01:51:56.688936 24 dns_common.go:495] Unable to read jessie_udp@dns-test-service.dns-6617 from pod dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca: the server could not find the requested resource (get pods dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca)
  I0115 01:51:56.694024 24 dns_common.go:495] Unable to read jessie_tcp@dns-test-service.dns-6617 from pod dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca: the server could not find the requested resource (get pods dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca)
  I0115 01:51:56.698344 24 dns_common.go:495] Unable to read jessie_udp@dns-test-service.dns-6617.svc from pod dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca: the server could not find the requested resource (get pods dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca)
  I0115 01:51:56.703010 24 dns_common.go:495] Unable to read jessie_tcp@dns-test-service.dns-6617.svc from pod dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca: the server could not find the requested resource (get pods dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca)
  I0115 01:51:56.707643 24 dns_common.go:495] Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6617.svc from pod dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca: the server could not find the requested resource (get pods dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca)
  I0115 01:51:56.715704 24 dns_common.go:495] Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6617.svc from pod dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca: the server could not find the requested resource (get pods dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca)
  I0115 01:51:56.721559 24 dns_common.go:495] Unable to read jessie_udp@_http._tcp.test-service-2.dns-6617.svc from pod dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca: the server could not find the requested resource (get pods dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca)
  I0115 01:51:56.726177 24 dns_common.go:495] Unable to read jessie_tcp@_http._tcp.test-service-2.dns-6617.svc from pod dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca: the server could not find the requested resource (get pods dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca)
  I0115 01:51:56.737307 24 dns_common.go:506] Lookups using dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca failed for: [jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-6617 jessie_tcp@dns-test-service.dns-6617 jessie_udp@dns-test-service.dns-6617.svc jessie_tcp@dns-test-service.dns-6617.svc jessie_udp@_http._tcp.dns-test-service.dns-6617.svc jessie_tcp@_http._tcp.dns-test-service.dns-6617.svc jessie_udp@_http._tcp.test-service-2.dns-6617.svc jessie_tcp@_http._tcp.test-service-2.dns-6617.svc]

  I0115 01:51:56.745150 24 dns_common.go:514] Pod client logs for webserver: 
  I0115 01:51:56.752821 24 dns_common.go:514] Pod client logs for agnhost-querier: 
  I0115 01:51:56.760108 24 dns_common.go:514] Pod client logs for jessie-querier: 
  E0115 01:51:57.287142      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:51:58.289130      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:51:59.290246      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:52:00.291608      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:52:01.295348      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:52:01.836244 24 dns_common.go:495] Unable to read jessie_udp@dns-test-service from pod dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca: the server could not find the requested resource (get pods dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca)
  I0115 01:52:01.849751 24 dns_common.go:495] Unable to read jessie_tcp@dns-test-service from pod dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca: the server could not find the requested resource (get pods dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca)
  I0115 01:52:02.017967 24 dns_common.go:495] Unable to read jessie_udp@_http._tcp.test-service-2.dns-6617.svc from pod dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca: the server could not find the requested resource (get pods dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca)
  I0115 01:52:02.050230 24 dns_common.go:495] Unable to read jessie_tcp@_http._tcp.test-service-2.dns-6617.svc from pod dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca: the server could not find the requested resource (get pods dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca)
  I0115 01:52:02.125710 24 dns_common.go:506] Lookups using dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca failed for: [jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@_http._tcp.test-service-2.dns-6617.svc jessie_tcp@_http._tcp.test-service-2.dns-6617.svc]

  I0115 01:52:02.215122 24 dns_common.go:514] Pod client logs for webserver: 
  I0115 01:52:02.272244 24 dns_common.go:514] Pod client logs for agnhost-querier: 
  E0115 01:52:02.294915      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:52:02.312439 24 dns_common.go:514] Pod client logs for jessie-querier: 
  E0115 01:52:03.295973      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:52:04.297767      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:52:05.297291      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:52:06.299707      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:52:06.752713 24 dns_common.go:546] DNS probes using dns-6617/dns-test-5632b5d8-1a0a-486e-bb21-fd684ca7ecca succeeded

  STEP: deleting the pod @ 01/15/25 01:52:06.752
  STEP: deleting the test service @ 01/15/25 01:52:06.776
  STEP: deleting the test headless service @ 01/15/25 01:52:06.828
  I0115 01:52:06.842389 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-6617" for this suite. @ 01/15/25 01:52:06.848
• [27.400 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for pods for Subdomain [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:307
  STEP: Creating a kubernetes client @ 01/15/25 01:52:06.857
  I0115 01:52:06.857748 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename dns @ 01/15/25 01:52:06.859
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:52:06.881
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:52:06.889
  STEP: Creating a test headless service @ 01/15/25 01:52:06.897
  STEP: Running these commands on agnhost: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9421.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/agnhost_udp@dns-querier-2.dns-test-service-2.dns-9421.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9421.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/agnhost_tcp@dns-querier-2.dns-test-service-2.dns-9421.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-9421.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/agnhost_udp@dns-test-service-2.dns-9421.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-9421.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/agnhost_tcp@dns-test-service-2.dns-9421.svc.cluster.local;sleep 1; done
   @ 01/15/25 01:52:06.907
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9421.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-9421.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9421.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-9421.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-9421.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-9421.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-9421.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-9421.svc.cluster.local;sleep 1; done
   @ 01/15/25 01:52:06.907
  STEP: creating a pod to probe DNS @ 01/15/25 01:52:06.907
  STEP: submitting the pod to kubernetes @ 01/15/25 01:52:06.907
  E0115 01:52:07.300265      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:52:08.300634      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:52:09.301559      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:52:10.303354      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 01/15/25 01:52:10.943
  STEP: looking for the results for each expected name from probers @ 01/15/25 01:52:10.947
  I0115 01:52:10.992085 24 dns_common.go:546] DNS probes using dns-9421/dns-test-749cfab6-ecde-4216-94fe-69bc0693b598 succeeded

  STEP: deleting the pod @ 01/15/25 01:52:10.992
  STEP: deleting the test headless service @ 01/15/25 01:52:11.016
  I0115 01:52:11.035461 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-9421" for this suite. @ 01/15/25 01:52:11.041
• [4.197 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:878
  STEP: Creating a kubernetes client @ 01/15/25 01:52:11.054
  I0115 01:52:11.054926 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename kubectl @ 01/15/25 01:52:11.055
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:52:11.072
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:52:11.076
  STEP: validating api versions @ 01/15/25 01:52:11.081
  I0115 01:52:11.081824 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-4877 api-versions'
  I0115 01:52:11.181782 24 builder.go:146] stderr: ""
  I0115 01:52:11.181848 24 builder.go:147] stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ncrd.projectcalico.org/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\nv1\n"
  I0115 01:52:11.182029 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-4877" for this suite. @ 01/15/25 01:52:11.189
• [0.142 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] server version should find the server version [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/server_version.go:41
  STEP: Creating a kubernetes client @ 01/15/25 01:52:11.197
  I0115 01:52:11.197445 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename server-version @ 01/15/25 01:52:11.198
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:52:11.213
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:52:11.219
  STEP: Request ServerVersion @ 01/15/25 01:52:11.225
  STEP: Confirm major version @ 01/15/25 01:52:11.228
  I0115 01:52:11.228215 24 server_version.go:52] Major version: 1
  STEP: Confirm minor version @ 01/15/25 01:52:11.228
  I0115 01:52:11.228274 24 server_version.go:58] cleanMinorVersion: 32
  I0115 01:52:11.228297 24 server_version.go:62] Minor version: 32
  I0115 01:52:11.228498 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "server-version-2393" for this suite. @ 01/15/25 01:52:11.294
  E0115 01:52:11.304613      24 retrywatcher.go:160] "Watch failed" err="context canceled"
• [0.133 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should apply changes to a resourcequota status [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:1066
  STEP: Creating a kubernetes client @ 01/15/25 01:52:11.33
  I0115 01:52:11.330463 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename resourcequota @ 01/15/25 01:52:11.333
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:52:11.357
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:52:11.365
  STEP: Creating resourceQuota "e2e-rq-status-n72v9" @ 01/15/25 01:52:11.446
  I0115 01:52:11.470613 24 resource_quota.go:1102] Resource quota "e2e-rq-status-n72v9" reports spec: hard cpu limit of 500m
  I0115 01:52:11.470687 24 resource_quota.go:1104] Resource quota "e2e-rq-status-n72v9" reports spec: hard memory limit of 500Mi
  STEP: Updating resourceQuota "e2e-rq-status-n72v9" /status @ 01/15/25 01:52:11.47
  STEP: Confirm /status for "e2e-rq-status-n72v9" resourceQuota via watch @ 01/15/25 01:52:11.489
  I0115 01:52:11.493062 24 resource_quota.go:1131] observed resourceQuota "e2e-rq-status-n72v9" in namespace "resourcequota-533" with hard status: v1.ResourceList(nil)
  I0115 01:52:11.493167 24 resource_quota.go:1134] Found resourceQuota "e2e-rq-status-n72v9" in namespace "resourcequota-533" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  I0115 01:52:11.493185 24 resource_quota.go:1141] ResourceQuota "e2e-rq-status-n72v9" /status was updated
  STEP: Patching hard spec values for cpu & memory @ 01/15/25 01:52:11.499
  I0115 01:52:11.510474 24 resource_quota.go:1152] Resource quota "e2e-rq-status-n72v9" reports spec: hard cpu limit of 1
  I0115 01:52:11.510593 24 resource_quota.go:1153] Resource quota "e2e-rq-status-n72v9" reports spec: hard memory limit of 1Gi
  STEP: Patching "e2e-rq-status-n72v9" /status @ 01/15/25 01:52:11.51
  STEP: Confirm /status for "e2e-rq-status-n72v9" resourceQuota via watch @ 01/15/25 01:52:11.52
  I0115 01:52:11.524555 24 resource_quota.go:1175] observed resourceQuota "e2e-rq-status-n72v9" in namespace "resourcequota-533" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  I0115 01:52:11.524681 24 resource_quota.go:1178] Found resourceQuota "e2e-rq-status-n72v9" in namespace "resourcequota-533" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}
  I0115 01:52:11.524725 24 resource_quota.go:1185] ResourceQuota "e2e-rq-status-n72v9" /status was patched
  STEP: Get "e2e-rq-status-n72v9" /status @ 01/15/25 01:52:11.524
  I0115 01:52:11.531984 24 resource_quota.go:1196] Resourcequota "e2e-rq-status-n72v9" reports status: hard cpu of 1
  I0115 01:52:11.532091 24 resource_quota.go:1198] Resourcequota "e2e-rq-status-n72v9" reports status: hard memory of 1Gi
  STEP: Repatching "e2e-rq-status-n72v9" /status before checking Spec is unchanged @ 01/15/25 01:52:11.538
  I0115 01:52:11.547628 24 resource_quota.go:1218] Resourcequota "e2e-rq-status-n72v9" reports status: hard cpu of 2
  I0115 01:52:11.547704 24 resource_quota.go:1220] Resourcequota "e2e-rq-status-n72v9" reports status: hard memory of 2Gi
  I0115 01:52:11.551913 24 resource_quota.go:1232] Found resourceQuota "e2e-rq-status-n72v9" in namespace "resourcequota-533" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}
  I0115 01:52:11.558413 24 resource_quota.go:1263] ResourceQuota "e2e-rq-status-n72v9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-n72v9", GenerateName:"", Namespace:"resourcequota-533", SelfLink:"", UID:"90fbccb5-1f0a-4657-a3dd-265f595babd6", ResourceVersion:"164579", Generation:0, CreationTimestamp:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-n72v9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00454ebd0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00454ec00), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00454ec30), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0115 01:52:12.305055      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:52:13.305589      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:52:14.305807      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:52:15.305990      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:52:16.306499      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:52:16.560155 24 resource_quota.go:1263] ResourceQuota "e2e-rq-status-n72v9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-n72v9", GenerateName:"", Namespace:"resourcequota-533", SelfLink:"", UID:"90fbccb5-1f0a-4657-a3dd-265f595babd6", ResourceVersion:"164579", Generation:0, CreationTimestamp:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-n72v9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00408fde8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00408fe48), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00408fe78), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0115 01:52:17.307419      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:52:18.307997      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:52:19.309341      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:52:20.309416      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:52:21.310125      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:52:21.558386 24 resource_quota.go:1263] ResourceQuota "e2e-rq-status-n72v9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-n72v9", GenerateName:"", Namespace:"resourcequota-533", SelfLink:"", UID:"90fbccb5-1f0a-4657-a3dd-265f595babd6", ResourceVersion:"164579", Generation:0, CreationTimestamp:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-n72v9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00454ed80), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00454edb0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00454ede0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0115 01:52:22.310361      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:52:23.311329      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:52:24.312189      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:52:25.314107      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:52:26.314430      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:52:26.556679 24 resource_quota.go:1263] ResourceQuota "e2e-rq-status-n72v9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-n72v9", GenerateName:"", Namespace:"resourcequota-533", SelfLink:"", UID:"90fbccb5-1f0a-4657-a3dd-265f595babd6", ResourceVersion:"164579", Generation:0, CreationTimestamp:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-n72v9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e1e078), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e1e0a8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e1e0d8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0115 01:52:27.314896      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:52:28.317186      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:52:29.318348      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:52:30.319777      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:52:31.320459      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:52:31.558633 24 resource_quota.go:1263] ResourceQuota "e2e-rq-status-n72v9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-n72v9", GenerateName:"", Namespace:"resourcequota-533", SelfLink:"", UID:"90fbccb5-1f0a-4657-a3dd-265f595babd6", ResourceVersion:"164579", Generation:0, CreationTimestamp:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-n72v9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00454ef48), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00454ef78), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00454efa8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0115 01:52:32.320541      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:52:33.322246      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:52:34.323729      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:52:35.324759      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:52:36.327810      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:52:36.583760 24 resource_quota.go:1263] ResourceQuota "e2e-rq-status-n72v9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-n72v9", GenerateName:"", Namespace:"resourcequota-533", SelfLink:"", UID:"90fbccb5-1f0a-4657-a3dd-265f595babd6", ResourceVersion:"164579", Generation:0, CreationTimestamp:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-n72v9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00454f110), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00454f140), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00454f170), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0115 01:52:37.326620      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:52:38.327308      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:52:39.327808      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:52:40.328117      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:52:41.328831      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:52:41.570872 24 resource_quota.go:1263] ResourceQuota "e2e-rq-status-n72v9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-n72v9", GenerateName:"", Namespace:"resourcequota-533", SelfLink:"", UID:"90fbccb5-1f0a-4657-a3dd-265f595babd6", ResourceVersion:"164579", Generation:0, CreationTimestamp:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-n72v9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e1e240), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e1e270), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e1e2a0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0115 01:52:42.328783      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:52:43.330806      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:52:44.332053      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:52:45.335051      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:52:46.337039      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:52:46.582036 24 resource_quota.go:1263] ResourceQuota "e2e-rq-status-n72v9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-n72v9", GenerateName:"", Namespace:"resourcequota-533", SelfLink:"", UID:"90fbccb5-1f0a-4657-a3dd-265f595babd6", ResourceVersion:"164579", Generation:0, CreationTimestamp:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-n72v9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e1e3d8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e1e408), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e1e438), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0115 01:52:47.337694      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:52:48.339256      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:52:49.339293      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:52:50.339501      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:52:51.341271      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:52:51.566937 24 resource_quota.go:1263] ResourceQuota "e2e-rq-status-n72v9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-n72v9", GenerateName:"", Namespace:"resourcequota-533", SelfLink:"", UID:"90fbccb5-1f0a-4657-a3dd-265f595babd6", ResourceVersion:"164579", Generation:0, CreationTimestamp:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-n72v9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00454f320), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00454f350), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00454f380), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0115 01:52:52.342118      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:52:53.343279      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:52:54.343731      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:52:55.344491      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:52:56.345669      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:52:56.565494 24 resource_quota.go:1263] ResourceQuota "e2e-rq-status-n72v9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-n72v9", GenerateName:"", Namespace:"resourcequota-533", SelfLink:"", UID:"90fbccb5-1f0a-4657-a3dd-265f595babd6", ResourceVersion:"164579", Generation:0, CreationTimestamp:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-n72v9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e1e5d0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e1e600), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e1e630), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0115 01:52:57.346883      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:52:58.347920      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:52:59.349220      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:53:00.351053      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:53:01.351671      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:53:01.562567 24 resource_quota.go:1263] ResourceQuota "e2e-rq-status-n72v9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-n72v9", GenerateName:"", Namespace:"resourcequota-533", SelfLink:"", UID:"90fbccb5-1f0a-4657-a3dd-265f595babd6", ResourceVersion:"164579", Generation:0, CreationTimestamp:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-n72v9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004375c68), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004375c98), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004375cc8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0115 01:53:02.352116      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:53:03.353490      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:53:04.355485      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:53:05.356925      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:53:06.357445      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:53:06.567688 24 resource_quota.go:1263] ResourceQuota "e2e-rq-status-n72v9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-n72v9", GenerateName:"", Namespace:"resourcequota-533", SelfLink:"", UID:"90fbccb5-1f0a-4657-a3dd-265f595babd6", ResourceVersion:"164579", Generation:0, CreationTimestamp:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-n72v9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e1e780), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e1e7c8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e1e7f8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0115 01:53:07.358212      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:53:08.359392      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:53:09.359649      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:53:10.361496      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:53:11.361883      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:53:11.558316 24 resource_quota.go:1263] ResourceQuota "e2e-rq-status-n72v9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-n72v9", GenerateName:"", Namespace:"resourcequota-533", SelfLink:"", UID:"90fbccb5-1f0a-4657-a3dd-265f595babd6", ResourceVersion:"164579", Generation:0, CreationTimestamp:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-n72v9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e1e918), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e1e948), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e1e978), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0115 01:53:12.363381      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:53:13.364405      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:53:14.365529      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:53:15.366031      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:53:16.366573      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:53:16.572033 24 resource_quota.go:1263] ResourceQuota "e2e-rq-status-n72v9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-n72v9", GenerateName:"", Namespace:"resourcequota-533", SelfLink:"", UID:"90fbccb5-1f0a-4657-a3dd-265f595babd6", ResourceVersion:"164579", Generation:0, CreationTimestamp:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-n72v9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e1eab0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e1eae0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e1eb10), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0115 01:53:17.368254      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:53:18.369838      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:53:19.370263      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:53:20.372018      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:53:21.373970      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:53:21.563715 24 resource_quota.go:1263] ResourceQuota "e2e-rq-status-n72v9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-n72v9", GenerateName:"", Namespace:"resourcequota-533", SelfLink:"", UID:"90fbccb5-1f0a-4657-a3dd-265f595babd6", ResourceVersion:"164579", Generation:0, CreationTimestamp:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-n72v9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e1ec90), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e1ecc0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e1ecf0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0115 01:53:22.376053      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:53:23.377413      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:53:24.384656      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:53:25.379286      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:53:26.381049      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:53:26.562658 24 resource_quota.go:1263] ResourceQuota "e2e-rq-status-n72v9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-n72v9", GenerateName:"", Namespace:"resourcequota-533", SelfLink:"", UID:"90fbccb5-1f0a-4657-a3dd-265f595babd6", ResourceVersion:"164579", Generation:0, CreationTimestamp:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-n72v9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004375f08), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004375f50), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0036ca000), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0115 01:53:27.381643      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:53:28.383344      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:53:29.383481      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:53:30.384167      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:53:31.384888      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:53:31.556029 24 resource_quota.go:1263] ResourceQuota "e2e-rq-status-n72v9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-n72v9", GenerateName:"", Namespace:"resourcequota-533", SelfLink:"", UID:"90fbccb5-1f0a-4657-a3dd-265f595babd6", ResourceVersion:"164579", Generation:0, CreationTimestamp:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-n72v9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0036ca168), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0036ca1e0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0036ca228), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0115 01:53:32.385112      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:53:33.385953      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:53:34.387644      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:53:35.388350      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:53:36.389586      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:53:36.556796 24 resource_quota.go:1263] ResourceQuota "e2e-rq-status-n72v9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-n72v9", GenerateName:"", Namespace:"resourcequota-533", SelfLink:"", UID:"90fbccb5-1f0a-4657-a3dd-265f595babd6", ResourceVersion:"164579", Generation:0, CreationTimestamp:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-n72v9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e1e030), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e1e060), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e1e090), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0115 01:53:37.390835      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:53:38.392313      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:53:39.392549      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:53:40.392640      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:53:41.392946      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:53:41.563684 24 resource_quota.go:1263] ResourceQuota "e2e-rq-status-n72v9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-n72v9", GenerateName:"", Namespace:"resourcequota-533", SelfLink:"", UID:"90fbccb5-1f0a-4657-a3dd-265f595babd6", ResourceVersion:"164579", Generation:0, CreationTimestamp:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-n72v9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0044ec120), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0044ec168), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0044ec198), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0115 01:53:42.393578      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:53:43.395203      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:53:44.396870      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:53:45.398593      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:53:46.398893      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:53:46.560783 24 resource_quota.go:1263] ResourceQuota "e2e-rq-status-n72v9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-n72v9", GenerateName:"", Namespace:"resourcequota-533", SelfLink:"", UID:"90fbccb5-1f0a-4657-a3dd-265f595babd6", ResourceVersion:"164579", Generation:0, CreationTimestamp:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-n72v9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e1e1e0), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e1e210), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e1e240), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0115 01:53:47.399495      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:53:48.399840      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:53:49.400168      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:53:50.401562      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:53:51.402461      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:53:51.570574 24 resource_quota.go:1263] ResourceQuota "e2e-rq-status-n72v9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-n72v9", GenerateName:"", Namespace:"resourcequota-533", SelfLink:"", UID:"90fbccb5-1f0a-4657-a3dd-265f595babd6", ResourceVersion:"164579", Generation:0, CreationTimestamp:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-n72v9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e1e3a8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e1e3d8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e1e408), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0115 01:53:52.403563      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:53:53.404296      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:53:54.404856      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:53:55.406185      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:53:56.407062      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:53:56.561339 24 resource_quota.go:1263] ResourceQuota "e2e-rq-status-n72v9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-n72v9", GenerateName:"", Namespace:"resourcequota-533", SelfLink:"", UID:"90fbccb5-1f0a-4657-a3dd-265f595babd6", ResourceVersion:"164579", Generation:0, CreationTimestamp:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-n72v9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0044ec330), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0044ec360), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0044ec390), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0115 01:53:57.407680      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:53:58.410172      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:53:59.410102      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:54:00.410660      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:54:01.411689      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:54:01.566139 24 resource_quota.go:1263] ResourceQuota "e2e-rq-status-n72v9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-n72v9", GenerateName:"", Namespace:"resourcequota-533", SelfLink:"", UID:"90fbccb5-1f0a-4657-a3dd-265f595babd6", ResourceVersion:"164579", Generation:0, CreationTimestamp:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-n72v9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e1e570), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e1e5a0), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e1e5d0), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0115 01:54:02.412438      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:54:03.413271      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:54:04.414972      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:54:05.415479      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:54:06.417053      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:54:06.558563 24 resource_quota.go:1263] ResourceQuota "e2e-rq-status-n72v9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-n72v9", GenerateName:"", Namespace:"resourcequota-533", SelfLink:"", UID:"90fbccb5-1f0a-4657-a3dd-265f595babd6", ResourceVersion:"164579", Generation:0, CreationTimestamp:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-n72v9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e1e720), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e1e750), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc003e1e780), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0115 01:54:07.418622      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:54:08.419388      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:54:09.422720      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:54:10.423089      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:54:11.423719      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:54:11.565206 24 resource_quota.go:1263] ResourceQuota "e2e-rq-status-n72v9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-n72v9", GenerateName:"", Namespace:"resourcequota-533", SelfLink:"", UID:"90fbccb5-1f0a-4657-a3dd-265f595babd6", ResourceVersion:"164579", Generation:0, CreationTimestamp:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-n72v9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0044ec5b8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0044ec5e8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0044ec618), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0115 01:54:12.425030      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:54:13.426485      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:54:14.426880      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:54:15.427177      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:54:16.428679      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:54:16.556898 24 resource_quota.go:1263] ResourceQuota "e2e-rq-status-n72v9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-n72v9", GenerateName:"", Namespace:"resourcequota-533", SelfLink:"", UID:"90fbccb5-1f0a-4657-a3dd-265f595babd6", ResourceVersion:"164579", Generation:0, CreationTimestamp:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-n72v9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0044ec708), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0044ec738), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0044ec768), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0115 01:54:17.429708      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:54:18.430259      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:54:19.432268      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:54:20.432287      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:54:21.434054      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:54:21.556686 24 resource_quota.go:1263] ResourceQuota "e2e-rq-status-n72v9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-n72v9", GenerateName:"", Namespace:"resourcequota-533", SelfLink:"", UID:"90fbccb5-1f0a-4657-a3dd-265f595babd6", ResourceVersion:"164579", Generation:0, CreationTimestamp:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-n72v9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00454e078), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00454e0a8), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00454e0d8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0115 01:54:22.433870      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:54:23.435753      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:54:24.436962      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:54:25.437311      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:54:26.438747      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:54:26.566632 24 resource_quota.go:1263] ResourceQuota "e2e-rq-status-n72v9" Spec and Status does not match: &v1.ResourceQuota{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"e2e-rq-status-n72v9", GenerateName:"", Namespace:"resourcequota-533", SelfLink:"", UID:"90fbccb5-1f0a-4657-a3dd-265f595babd6", ResourceVersion:"164579", Generation:0, CreationTimestamp:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"e2e-rq-label":"e2e-rq-status-n72v9"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0044ec948), Subresource:""}, v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0044ec978), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kube-controller-manager", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 1, 52, 11, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0044ec9a8), Subresource:"status"}}}, Spec:v1.ResourceQuotaSpec{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}, Scopes:[]v1.ResourceQuotaScope(nil), ScopeSelector:(*v1.ScopeSelector)(nil)}, Status:v1.ResourceQuotaStatus{Hard:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}, Used:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:0, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"0", Format:"DecimalSI"}}}}
  E0115 01:54:27.441113      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:54:28.441616      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:54:29.442558      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:54:30.444000      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:54:31.445768      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:54:31.561343 24 resource_quota.go:1260] ResourceQuota "e2e-rq-status-n72v9" Spec was unchanged and /status reset
  I0115 01:54:31.561959 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-533" for this suite. @ 01/15/25 01:54:31.578
• [140.274 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:59
  STEP: Creating a kubernetes client @ 01/15/25 01:54:31.606
  I0115 01:54:31.606379 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename custom-resource-definition @ 01/15/25 01:54:31.609
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:54:31.657
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:54:31.664
  I0115 01:54:31.670538 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  E0115 01:54:32.446151      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:54:32.715848 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-4472" for this suite. @ 01/15/25 01:54:32.723
• [1.129 seconds]
------------------------------
SSS
------------------------------
[sig-node] Pods should be submitted and removed [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:227
  STEP: Creating a kubernetes client @ 01/15/25 01:54:32.734
  I0115 01:54:32.734384 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename pods @ 01/15/25 01:54:32.738
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:54:32.764
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:54:32.772
  STEP: creating the pod @ 01/15/25 01:54:32.78
  STEP: setting up watch @ 01/15/25 01:54:32.78
  STEP: submitting the pod to kubernetes @ 01/15/25 01:54:32.887
  STEP: verifying the pod is in kubernetes @ 01/15/25 01:54:32.923
  STEP: verifying pod creation was observed @ 01/15/25 01:54:32.951
  E0115 01:54:33.446891      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:54:34.448088      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: deleting the pod gracefully @ 01/15/25 01:54:34.985
  STEP: verifying pod deletion was observed @ 01/15/25 01:54:35.016
  E0115 01:54:35.449825      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:54:36.449868      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:54:37.350458 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-7506" for this suite. @ 01/15/25 01:54:37.355
• [4.627 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:312
  STEP: Creating a kubernetes client @ 01/15/25 01:54:37.361
  I0115 01:54:37.361422 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename webhook @ 01/15/25 01:54:37.362
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:54:37.376
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:54:37.381
  E0115 01:54:37.450724      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Setting up server cert @ 01/15/25 01:54:37.498
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 01/15/25 01:54:38.054
  STEP: Deploying the webhook pod @ 01/15/25 01:54:38.061
  STEP: Wait for the deployment to be ready @ 01/15/25 01:54:38.073
  I0115 01:54:38.088812 24 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0115 01:54:38.451618      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:54:39.451803      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 01/15/25 01:54:40.122
  STEP: Verifying the service has paired with the endpoint @ 01/15/25 01:54:40.137
  E0115 01:54:40.463437      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:54:41.164619 24 util.go:423] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  I0115 01:54:41.188796 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  E0115 01:54:41.467235      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-3467-crds.webhook.example.com via the AdmissionRegistration API @ 01/15/25 01:54:41.702
  STEP: Creating a custom resource while v1 is storage version @ 01/15/25 01:54:41.72
  E0115 01:54:42.469645      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:54:43.468187      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Patching Custom Resource Definition to set v2 as storage @ 01/15/25 01:54:43.765
  STEP: Patching the custom resource while v2 is storage version @ 01/15/25 01:54:43.777
  I0115 01:54:44.464249 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  E0115 01:54:44.469535      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Destroying namespace "webhook-6365" for this suite. @ 01/15/25 01:54:44.491
  STEP: Destroying namespace "webhook-markers-7677" for this suite. @ 01/15/25 01:54:44.506
• [7.153 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should succeed in writing subpaths in container [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:301
  STEP: Creating a kubernetes client @ 01/15/25 01:54:44.515
  I0115 01:54:44.515236 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename var-expansion @ 01/15/25 01:54:44.516
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:54:44.532
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:54:44.537
  STEP: creating the pod @ 01/15/25 01:54:44.542
  STEP: waiting for pod running @ 01/15/25 01:54:44.551
  E0115 01:54:45.470917      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:54:46.471463      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: creating a file in subpath @ 01/15/25 01:54:46.561
  I0115 01:54:46.565946 24 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-3417 PodName:var-expansion-801bd413-7ddb-4b6f-b06f-035fb119bc88 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0115 01:54:46.565986 24 exec_util.go:64] ExecWithOptions: Clientset creation
  I0115 01:54:46.566034 24 exec_util.go:80] ExecWithOptions: execute(POST https://169.169.0.1:443/api/v1/namespaces/var-expansion-3417/pods/var-expansion-801bd413-7ddb-4b6f-b06f-035fb119bc88/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&stderr=true&stdout=true)
  STEP: test for file in mounted path @ 01/15/25 01:54:46.643
  I0115 01:54:46.646947 24 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-3417 PodName:var-expansion-801bd413-7ddb-4b6f-b06f-035fb119bc88 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0115 01:54:46.647008 24 exec_util.go:64] ExecWithOptions: Clientset creation
  I0115 01:54:46.647074 24 exec_util.go:80] ExecWithOptions: execute(POST https://169.169.0.1:443/api/v1/namespaces/var-expansion-3417/pods/var-expansion-801bd413-7ddb-4b6f-b06f-035fb119bc88/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&stderr=true&stdout=true)
  STEP: updating the annotation value @ 01/15/25 01:54:46.759
  I0115 01:54:47.281731 24 pod_client.go:173] Successfully updated pod "var-expansion-801bd413-7ddb-4b6f-b06f-035fb119bc88"
  STEP: waiting for annotated pod running @ 01/15/25 01:54:47.281
  STEP: deleting the pod gracefully @ 01/15/25 01:54:47.292
  I0115 01:54:47.292424 24 delete.go:62] Deleting pod "var-expansion-801bd413-7ddb-4b6f-b06f-035fb119bc88" in namespace "var-expansion-3417"
  I0115 01:54:47.310878 24 delete.go:70] Wait up to 5m0s for pod "var-expansion-801bd413-7ddb-4b6f-b06f-035fb119bc88" to be fully deleted
  E0115 01:54:47.471375      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:54:48.472130      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:54:49.472371      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:54:50.473217      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:54:51.473230      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:54:52.474260      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:54:53.474595      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:54:54.475442      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:54:55.476111      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:54:56.476789      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:54:57.478011      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:54:58.479703      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:54:59.480532      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:55:00.482115      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:55:01.484310      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:55:02.485481      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:55:03.486622      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:55:04.487452      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:55:05.487746      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:55:06.490037      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:55:07.490334      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:55:08.491031      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:55:09.491148      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:55:10.491762      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:55:11.492457      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:55:12.494158      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:55:13.498464      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:55:14.497398      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:55:15.497762      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:55:16.499106      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:55:17.499831      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:55:18.500314      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:55:19.501046      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:55:20.501137      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:55:21.499244 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  E0115 01:55:21.504381      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Destroying namespace "var-expansion-3417" for this suite. @ 01/15/25 01:55:21.514
• [37.022 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:639
  STEP: Creating a kubernetes client @ 01/15/25 01:55:21.536
  I0115 01:55:21.536987 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename gc @ 01/15/25 01:55:21.539
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:55:21.555
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:55:21.559
  STEP: create the rc @ 01/15/25 01:55:21.609
  W0115 01:55:21.614995      24 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E0115 01:55:22.504865      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:55:23.535511      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:55:24.542664      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:55:25.564095      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:55:26.561537      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:55:27.565899      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: delete the rc @ 01/15/25 01:55:27.677
  STEP: wait for the rc to be deleted @ 01/15/25 01:55:27.745
  E0115 01:55:28.574653      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:55:29.209986 24 garbage_collector.go:670] 81 pods remaining
  I0115 01:55:29.210103 24 garbage_collector.go:677] 80 pods has nil DeletionTimestamp
  I0115 01:55:29.210131 24 garbage_collector.go:678] 
  E0115 01:55:29.581294      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:55:30.113551 24 garbage_collector.go:670] 76 pods remaining
  I0115 01:55:30.113661 24 garbage_collector.go:677] 71 pods has nil DeletionTimestamp
  I0115 01:55:30.113690 24 garbage_collector.go:678] 
  E0115 01:55:30.603272      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:55:31.033483 24 garbage_collector.go:670] 57 pods remaining
  I0115 01:55:31.033977 24 garbage_collector.go:677] 57 pods has nil DeletionTimestamp
  I0115 01:55:31.034027 24 garbage_collector.go:678] 
  E0115 01:55:31.614835      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:55:32.026347 24 garbage_collector.go:670] 49 pods remaining
  I0115 01:55:32.027145 24 garbage_collector.go:677] 41 pods has nil DeletionTimestamp
  I0115 01:55:32.027197 24 garbage_collector.go:678] 
  E0115 01:55:32.616675      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:55:33.043427 24 garbage_collector.go:670] 30 pods remaining
  I0115 01:55:33.043517 24 garbage_collector.go:677] 30 pods has nil DeletionTimestamp
  I0115 01:55:33.043545 24 garbage_collector.go:678] 
  E0115 01:55:33.618823      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:55:34.173735 24 garbage_collector.go:670] 18 pods remaining
  I0115 01:55:34.173846 24 garbage_collector.go:677] 14 pods has nil DeletionTimestamp
  I0115 01:55:34.173872 24 garbage_collector.go:678] 
  E0115 01:55:34.665275      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:55:35.054878 24 garbage_collector.go:670] 0 pods remaining
  I0115 01:55:35.054969 24 garbage_collector.go:677] 0 pods has nil DeletionTimestamp
  I0115 01:55:35.054995 24 garbage_collector.go:678] 
  E0115 01:55:35.672054      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 01/15/25 01:55:36.027
  E0115 01:55:36.672514      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:55:37.674456      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:55:38.019481 24 garbage_collector.go:265] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0115 01:55:38.019905 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-481" for this suite. @ 01/15/25 01:55:38.054
• [16.564 seconds]
------------------------------
S
------------------------------
[sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:68
  STEP: Creating a kubernetes client @ 01/15/25 01:55:38.101
  I0115 01:55:38.101637 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename secrets @ 01/15/25 01:55:38.116
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:55:38.213
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:55:38.281
  STEP: Creating secret with name secret-test-b0239067-e74e-4050-8c35-506e1c64470a @ 01/15/25 01:55:38.335
  STEP: Creating a pod to test consume secrets @ 01/15/25 01:55:38.438
  E0115 01:55:38.677423      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:55:39.678473      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:55:40.679979      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:55:41.681040      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:55:42.707662      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:55:43.709817      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:55:44.712619      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:55:45.742824      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:55:46.748710      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:55:47.753199      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:55:48.753676      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:55:49.756171      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:55:50.760344      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:55:51.761090      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:55:52.769132      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:55:53.769460      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:55:54.770338      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:55:55.780371      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:55:56.775133      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:55:57.776148      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:55:58.778329      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:55:59.781093      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:56:00.781529      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:56:01.792943      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:56:02.793979      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:56:03.796503      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:56:04.796880      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:56:05.797343      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:56:06.797612      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 01:56:07.226
  I0115 01:56:07.237212 24 output.go:207] Trying to get logs from node 192.168.18.92 pod pod-secrets-c0576775-c0b5-4749-a8fb-b160569af69c container secret-volume-test: <nil>
  STEP: delete the pod @ 01/15/25 01:56:07.254
  I0115 01:56:07.282941 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-4747" for this suite. @ 01/15/25 01:56:07.297
• [29.228 seconds]
------------------------------
[sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1687
  STEP: Creating a kubernetes client @ 01/15/25 01:56:07.332
  I0115 01:56:07.332531 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename kubectl @ 01/15/25 01:56:07.334
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:56:07.367
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:56:07.377
  STEP: creating Agnhost RC @ 01/15/25 01:56:07.39
  I0115 01:56:07.390941 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-6491 create -f -'
  E0115 01:56:07.805961      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:56:08.026192 24 builder.go:146] stderr: ""
  I0115 01:56:08.027092 24 builder.go:147] stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 01/15/25 01:56:08.027
  E0115 01:56:08.817653      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:56:09.038167 24 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0115 01:56:09.038354 24 framework.go:733] Found 0 / 1
  E0115 01:56:09.818721      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:56:10.042248 24 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0115 01:56:10.042339 24 framework.go:733] Found 1 / 1
  I0115 01:56:10.042377 24 framework.go:742] WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  STEP: patching all pods @ 01/15/25 01:56:10.042
  I0115 01:56:10.049248 24 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0115 01:56:10.049402 24 framework.go:765] ForEach: Found 1 pods from the filter.  Now looping through them.
  I0115 01:56:10.049500 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-6491 patch pod agnhost-primary-28rcm -p {"metadata":{"annotations":{"x":"y"}}}'
  I0115 01:56:10.216751 24 builder.go:146] stderr: ""
  I0115 01:56:10.216886 24 builder.go:147] stdout: "pod/agnhost-primary-28rcm patched\n"
  STEP: checking annotations @ 01/15/25 01:56:10.216
  I0115 01:56:10.223275 24 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0115 01:56:10.223331 24 framework.go:765] ForEach: Found 1 pods from the filter.  Now looping through them.
  I0115 01:56:10.223673 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-6491" for this suite. @ 01/15/25 01:56:10.231
• [2.912 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:79
  STEP: Creating a kubernetes client @ 01/15/25 01:56:10.244
  I0115 01:56:10.244557 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename resourcequota @ 01/15/25 01:56:10.246
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:56:10.271
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:56:10.278
  STEP: Counting existing ResourceQuota @ 01/15/25 01:56:10.286
  E0115 01:56:10.819545      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:56:11.820868      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:56:12.822661      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:56:13.823894      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:56:14.828436      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 01/15/25 01:56:15.308
  STEP: Ensuring resource quota status is calculated @ 01/15/25 01:56:15.341
  E0115 01:56:15.829808      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:56:16.830517      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:56:17.347886 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-4602" for this suite. @ 01/15/25 01:56:17.355
• [7.120 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:125
  STEP: Creating a kubernetes client @ 01/15/25 01:56:17.365
  I0115 01:56:17.365738 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename secrets @ 01/15/25 01:56:17.367
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:56:17.404
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:56:17.451
  STEP: Creating secret with name secret-test-87e9004f-5ab7-476d-a662-a0d64b219b22 @ 01/15/25 01:56:17.471
  STEP: Creating a pod to test consume secrets @ 01/15/25 01:56:17.484
  E0115 01:56:17.831699      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:56:18.832898      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:56:19.834271      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:56:20.839240      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 01:56:21.554
  I0115 01:56:21.582396 24 output.go:207] Trying to get logs from node 192.168.18.92 pod pod-secrets-9c2529bd-ea7d-4c00-91b5-ca7147311652 container secret-volume-test: <nil>
  STEP: delete the pod @ 01/15/25 01:56:21.602
  I0115 01:56:21.634002 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-2186" for this suite. @ 01/15/25 01:56:21.645
• [4.293 seconds]
------------------------------
S
------------------------------
[sig-node] Node Lifecycle should run through the lifecycle of a node [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/node_lifecycle.go:51
  STEP: Creating a kubernetes client @ 01/15/25 01:56:21.657
  I0115 01:56:21.657850 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename fake-node @ 01/15/25 01:56:21.659
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:56:21.69
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:56:21.698
  STEP: Create "e2e-fake-node-zxqdx" @ 01/15/25 01:56:21.708
  STEP: Getting "e2e-fake-node-zxqdx" @ 01/15/25 01:56:21.728
  STEP: Patching "e2e-fake-node-zxqdx" @ 01/15/25 01:56:21.746
  STEP: Listing nodes with LabelSelector "e2e-fake-node-zxqdx=patched" @ 01/15/25 01:56:21.768
  STEP: Updating "e2e-fake-node-zxqdx" @ 01/15/25 01:56:21.785
  STEP: Delete "e2e-fake-node-zxqdx" @ 01/15/25 01:56:21.823
  STEP: Confirm deletion of "e2e-fake-node-zxqdx" @ 01/15/25 01:56:21.835
  E0115 01:56:21.842171      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:56:21.849076 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "fake-node-8386" for this suite. @ 01/15/25 01:56:21.86
• [0.215 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] API priority and fairness should support FlowSchema API operations [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/flowcontrol.go:270
  STEP: Creating a kubernetes client @ 01/15/25 01:56:21.873
  I0115 01:56:21.873581 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename apf @ 01/15/25 01:56:21.875
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:56:21.959
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:56:21.966
  STEP: getting /apis @ 01/15/25 01:56:21.98
  STEP: getting /apis/flowcontrol.apiserver.k8s.io @ 01/15/25 01:56:22.003
  STEP: getting /apis/flowcontrol.apiserver.k8s.io/v1 @ 01/15/25 01:56:22.011
  STEP: creating @ 01/15/25 01:56:22.019
  STEP: getting @ 01/15/25 01:56:22.06
  STEP: listing @ 01/15/25 01:56:22.076
  STEP: watching @ 01/15/25 01:56:22.089
  I0115 01:56:22.089807 24 flowcontrol.go:394] starting watch
  STEP: patching @ 01/15/25 01:56:22.096
  STEP: updating @ 01/15/25 01:56:22.112
  I0115 01:56:22.142858 24 flowcontrol.go:422] waiting for watch events with expected annotations
  STEP: getting /status @ 01/15/25 01:56:22.143
  STEP: patching /status @ 01/15/25 01:56:22.15
  STEP: updating /status @ 01/15/25 01:56:22.162
  STEP: deleting @ 01/15/25 01:56:22.205
  STEP: deleting a collection @ 01/15/25 01:56:22.227
  I0115 01:56:22.262862 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "apf-8332" for this suite. @ 01/15/25 01:56:22.273
• [0.415 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:55
  STEP: Creating a kubernetes client @ 01/15/25 01:56:22.288
  I0115 01:56:22.288882 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename projected @ 01/15/25 01:56:22.291
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:56:22.319
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:56:22.33
  STEP: Creating a pod to test downward API volume plugin @ 01/15/25 01:56:22.339
  E0115 01:56:22.843647      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:56:23.844167      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:56:24.845536      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:56:25.846759      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 01:56:26.381
  I0115 01:56:26.385289 24 output.go:207] Trying to get logs from node 192.168.18.92 pod downwardapi-volume-33af2be8-0dca-4234-841b-66085736a968 container client-container: <nil>
  STEP: delete the pod @ 01/15/25 01:56:26.393
  I0115 01:56:26.412518 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3479" for this suite. @ 01/15/25 01:56:26.418
• [4.138 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance] [sig-node, Slow, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:229
  STEP: Creating a kubernetes client @ 01/15/25 01:56:26.427
  I0115 01:56:26.427110 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename var-expansion @ 01/15/25 01:56:26.428
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:56:26.446
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:56:26.452
  STEP: creating the pod with failed condition @ 01/15/25 01:56:26.458
  E0115 01:56:26.848036      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:56:27.849332      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:56:28.849881      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:56:29.850328      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:56:30.850876      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:56:31.852742      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:56:32.853302      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:56:33.855024      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:56:34.855121      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:56:35.855833      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:56:36.857325      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:56:37.858990      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:56:38.859749      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:56:39.860842      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:56:40.860163      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:56:41.860627      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:56:42.861744      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:56:43.861763      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:56:44.862594      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:56:45.863270      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:56:46.864255      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:56:47.865537      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:56:48.874489      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:56:49.876030      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:56:50.876902      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:56:51.877979      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:56:52.878464      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:56:53.878899      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:56:54.880262      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:56:55.881092      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:56:56.882091      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:56:57.883769      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:56:58.883922      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:56:59.885016      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:00.885129      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:01.886373      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:02.886666      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:03.887361      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:04.887918      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:05.888440      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:06.888860      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:07.890219      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:08.891802      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:09.892735      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:10.893732      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:11.893910      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:12.895544      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:13.896674      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:14.897122      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:15.898371      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:16.900955      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:17.901633      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:18.902147      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:19.903910      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:20.905306      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:21.906928      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:22.908174      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:23.909023      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:24.913725      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:25.915515      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:26.916327      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:27.917837      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:28.918025      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:29.918161      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:30.921837      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:31.921870      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:32.923883      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:33.924735      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:34.925443      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:35.926687      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:36.927802      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:37.929384      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:38.931064      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:39.933437      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:40.933776      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:41.934829      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:42.935552      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:43.936047      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:44.938189      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:45.939998      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:46.941041      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:47.941691      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:48.942161      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:49.944182      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:50.944881      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:51.945201      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:52.945821      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:53.946687      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:54.946799      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:55.948835      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:56.949804      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:57.960298      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:58.960949      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:57:59.961253      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:58:00.963535      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:58:01.964225      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:58:02.965281      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:58:03.966607      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:58:04.967121      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:58:05.967981      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:58:06.968956      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:58:07.969635      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:58:08.969677      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:58:09.971361      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:58:10.972806      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:58:11.973112      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:58:12.973913      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:58:13.974777      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:58:14.975921      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:58:15.976909      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:58:16.977525      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:58:17.978152      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:58:18.995976      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:58:19.998022      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:58:20.999959      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:58:22.000370      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:58:23.001360      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:58:24.003124      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:58:25.004163      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:58:26.004844      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: updating the pod @ 01/15/25 01:58:26.47
  I0115 01:58:27.004336 24 pod_client.go:173] Successfully updated pod "var-expansion-2f0f4844-9b6b-4b08-b65e-6ee67b187ae5"
  STEP: waiting for pod running @ 01/15/25 01:58:27.004
  E0115 01:58:27.005121      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:58:28.005610      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:58:29.006751      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: deleting the pod gracefully @ 01/15/25 01:58:29.049
  I0115 01:58:29.049599 24 delete.go:62] Deleting pod "var-expansion-2f0f4844-9b6b-4b08-b65e-6ee67b187ae5" in namespace "var-expansion-8410"
  I0115 01:58:29.098052 24 delete.go:70] Wait up to 5m0s for pod "var-expansion-2f0f4844-9b6b-4b08-b65e-6ee67b187ae5" to be fully deleted
  E0115 01:58:30.008220      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:58:31.008963      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:58:32.010330      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:58:33.011429      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:58:34.013371      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:58:35.014250      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:58:36.015754      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:58:37.016905      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:58:38.018171      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:58:39.018667      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:58:40.021689      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:58:41.021491      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:58:42.023723      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:58:43.026780      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:58:44.027946      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:58:45.028768      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:58:46.029837      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:58:47.031567      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:58:48.032792      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:58:49.033632      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:58:50.034702      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:58:51.035926      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:58:52.037528      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:58:53.038715      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:58:54.039495      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:58:55.039740      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:58:56.041130      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:58:57.043114      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:58:58.043259      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:58:59.044047      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:59:00.044206      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:59:01.044740      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:59:01.316229 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-8410" for this suite. @ 01/15/25 01:59:01.321
• [154.902 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:169
  STEP: Creating a kubernetes client @ 01/15/25 01:59:01.331
  I0115 01:59:01.331498 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename container-probe @ 01/15/25 01:59:01.332
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:59:01.35
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:59:01.356
  STEP: Creating pod liveness-143dbf71-a0a2-4609-8483-c6c4527a938a in namespace container-probe-3889 @ 01/15/25 01:59:01.363
  E0115 01:59:02.047066      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:59:03.047046      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 01/15/25 01:59:03.395
  I0115 01:59:03.410625 24 container_probe.go:1749] Initial restart count of pod liveness-143dbf71-a0a2-4609-8483-c6c4527a938a is 0
  I0115 01:59:03.423346 24 container_probe.go:1759] Get pod liveness-143dbf71-a0a2-4609-8483-c6c4527a938a in namespace container-probe-3889
  E0115 01:59:04.047256      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:59:05.049840      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:59:05.443064 24 container_probe.go:1759] Get pod liveness-143dbf71-a0a2-4609-8483-c6c4527a938a in namespace container-probe-3889
  E0115 01:59:06.049981      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:59:07.051214      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:59:07.462472 24 container_probe.go:1759] Get pod liveness-143dbf71-a0a2-4609-8483-c6c4527a938a in namespace container-probe-3889
  E0115 01:59:08.052054      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:59:09.052965      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:59:09.469004 24 container_probe.go:1759] Get pod liveness-143dbf71-a0a2-4609-8483-c6c4527a938a in namespace container-probe-3889
  E0115 01:59:10.052900      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:59:11.053329      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:59:11.474581 24 container_probe.go:1759] Get pod liveness-143dbf71-a0a2-4609-8483-c6c4527a938a in namespace container-probe-3889
  E0115 01:59:12.054246      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:59:13.054901      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:59:13.479489 24 container_probe.go:1759] Get pod liveness-143dbf71-a0a2-4609-8483-c6c4527a938a in namespace container-probe-3889
  E0115 01:59:14.056248      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:59:15.056979      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:59:15.495999 24 container_probe.go:1759] Get pod liveness-143dbf71-a0a2-4609-8483-c6c4527a938a in namespace container-probe-3889
  E0115 01:59:16.057432      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:59:17.057900      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:59:17.506868 24 container_probe.go:1759] Get pod liveness-143dbf71-a0a2-4609-8483-c6c4527a938a in namespace container-probe-3889
  E0115 01:59:18.058915      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:59:19.061582      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:59:19.510805 24 container_probe.go:1759] Get pod liveness-143dbf71-a0a2-4609-8483-c6c4527a938a in namespace container-probe-3889
  E0115 01:59:20.062021      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:59:21.062634      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:59:21.524391 24 container_probe.go:1759] Get pod liveness-143dbf71-a0a2-4609-8483-c6c4527a938a in namespace container-probe-3889
  E0115 01:59:22.063035      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:59:23.069681      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:59:23.546506 24 container_probe.go:1759] Get pod liveness-143dbf71-a0a2-4609-8483-c6c4527a938a in namespace container-probe-3889
  I0115 01:59:23.547134 24 container_probe.go:1763] Restart count of pod container-probe-3889/liveness-143dbf71-a0a2-4609-8483-c6c4527a938a is now 1 (20.136157384s elapsed)
  STEP: deleting the pod @ 01/15/25 01:59:23.548
  I0115 01:59:23.600503 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-3889" for this suite. @ 01/15/25 01:59:23.61
• [22.292 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply a valid CR for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:166
  STEP: Creating a kubernetes client @ 01/15/25 01:59:23.623
  I0115 01:59:23.623582 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename field-validation @ 01/15/25 01:59:23.625
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:59:23.716
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:59:23.724
  I0115 01:59:23.731271 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  E0115 01:59:24.066085      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:59:25.066539      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:59:26.067600      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  W0115 01:59:26.297829      24 warnings.go:70] unknown field "alpha"
  W0115 01:59:26.297975      24 warnings.go:70] unknown field "beta"
  W0115 01:59:26.298001      24 warnings.go:70] unknown field "delta"
  W0115 01:59:26.298018      24 warnings.go:70] unknown field "epsilon"
  W0115 01:59:26.298034      24 warnings.go:70] unknown field "gamma"
  I0115 01:59:26.929904 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-7896" for this suite. @ 01/15/25 01:59:26.947
• [3.346 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply an invalid CR with extra properties for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:348
  STEP: Creating a kubernetes client @ 01/15/25 01:59:26.969
  I0115 01:59:26.969864 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename field-validation @ 01/15/25 01:59:26.972
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:59:26.995
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:59:27
  I0115 01:59:27.006157 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  W0115 01:59:27.007015      24 field_validation.go:421] props: &JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{spec: {  <nil>  object   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[cronSpec:{  <nil>  string   nil <nil> false <nil> false <nil> <nil> ^(\d+|\*)(/\d+)?(\s+(\d+|\*)(/\d+)?){4}$ <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} foo:{  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} ports:{  <nil>  array   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] &JSONSchemaPropsOrArray{Schema:&JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[containerPort protocol],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{containerPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostIP: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},name: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},protocol: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},},JSONSchemas:[]JSONSchemaProps{},} [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [containerPort protocol] 0xc0044e47c0 <nil> []}] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},}
  E0115 01:59:27.067735      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:59:28.068566      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:59:29.068774      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  W0115 01:59:29.620370      24 warnings.go:70] unknown field "alpha"
  W0115 01:59:29.620391      24 warnings.go:70] unknown field "beta"
  W0115 01:59:29.620395      24 warnings.go:70] unknown field "delta"
  W0115 01:59:29.620401      24 warnings.go:70] unknown field "epsilon"
  W0115 01:59:29.620405      24 warnings.go:70] unknown field "gamma"
  E0115 01:59:30.069095      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:59:30.169708 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-2109" for this suite. @ 01/15/25 01:59:30.176
• [3.214 seconds]
------------------------------
SS
------------------------------
[sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:251
  STEP: Creating a kubernetes client @ 01/15/25 01:59:30.184
  I0115 01:59:30.184066 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename downward-api @ 01/15/25 01:59:30.185
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:59:30.205
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:59:30.211
  STEP: Creating a pod to test downward API volume plugin @ 01/15/25 01:59:30.217
  E0115 01:59:31.070570      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:59:32.071520      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:59:33.072067      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:59:34.072834      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 01:59:34.308
  I0115 01:59:34.311160 24 output.go:207] Trying to get logs from node 192.168.18.92 pod downwardapi-volume-b29a314f-d4cb-41f4-88f9-93c11fc87a61 container client-container: <nil>
  STEP: delete the pod @ 01/15/25 01:59:34.32
  I0115 01:59:34.332264 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-7762" for this suite. @ 01/15/25 01:59:34.337
• [4.160 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:298
  STEP: Creating a kubernetes client @ 01/15/25 01:59:34.344
  I0115 01:59:34.344719 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename webhook @ 01/15/25 01:59:34.345
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:59:34.36
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:59:34.367
  STEP: Setting up server cert @ 01/15/25 01:59:34.491
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 01/15/25 01:59:34.777
  STEP: Deploying the webhook pod @ 01/15/25 01:59:34.784
  STEP: Wait for the deployment to be ready @ 01/15/25 01:59:34.796
  I0115 01:59:34.803054 24 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0115 01:59:35.073803      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:59:36.074992      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 01/15/25 01:59:36.848
  STEP: Verifying the service has paired with the endpoint @ 01/15/25 01:59:36.878
  E0115 01:59:37.075214      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:59:37.880203 24 util.go:423] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the crd webhook via the AdmissionRegistration API @ 01/15/25 01:59:37.89
  STEP: Creating a custom resource definition that should be denied by the webhook @ 01/15/25 01:59:37.908
  I0115 01:59:37.908860 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  I0115 01:59:37.962744 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-7988" for this suite. @ 01/15/25 01:59:37.972
  STEP: Destroying namespace "webhook-markers-2138" for this suite. @ 01/15/25 01:59:37.978
• [3.642 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] CSIStorageCapacity should support CSIStorageCapacities API operations [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/csistoragecapacity.go:50
  STEP: Creating a kubernetes client @ 01/15/25 01:59:37.987
  I0115 01:59:37.987297 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename csistoragecapacity @ 01/15/25 01:59:37.988
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:59:38.007
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:59:38.014
  STEP: getting /apis @ 01/15/25 01:59:38.02
  STEP: getting /apis/storage.k8s.io @ 01/15/25 01:59:38.03
  STEP: getting /apis/storage.k8s.io/v1 @ 01/15/25 01:59:38.034
  STEP: creating @ 01/15/25 01:59:38.039
  STEP: watching @ 01/15/25 01:59:38.055
  I0115 01:59:38.055245 24 csistoragecapacity.go:143] starting watch
  STEP: getting @ 01/15/25 01:59:38.066
  STEP: listing in namespace @ 01/15/25 01:59:38.069
  STEP: listing across namespaces @ 01/15/25 01:59:38.073
  E0115 01:59:38.075878      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: patching @ 01/15/25 01:59:38.077
  STEP: updating @ 01/15/25 01:59:38.083
  I0115 01:59:38.089165 24 csistoragecapacity.go:181] waiting for watch events with expected annotations in namespace
  I0115 01:59:38.089466 24 csistoragecapacity.go:181] waiting for watch events with expected annotations across namespace
  STEP: deleting @ 01/15/25 01:59:38.089
  STEP: deleting a collection @ 01/15/25 01:59:38.118
  I0115 01:59:38.144759 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csistoragecapacity-2146" for this suite. @ 01/15/25 01:59:38.149
• [0.171 seconds]
------------------------------
[sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:351
  STEP: Creating a kubernetes client @ 01/15/25 01:59:38.158
  I0115 01:59:38.159366 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename disruption @ 01/15/25 01:59:38.16
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:59:38.187
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:59:38.193
  STEP: Creating a pdb that targets all three pods in a test replica set @ 01/15/25 01:59:38.2
  STEP: Waiting for the pdb to be processed @ 01/15/25 01:59:38.206
  E0115 01:59:39.077568      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:59:40.079020      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: First trying to evict a pod which shouldn't be evictable @ 01/15/25 01:59:40.22
  STEP: Waiting for all pods to be running @ 01/15/25 01:59:40.22
  I0115 01:59:40.225115 24 disruption.go:680] pods: 0 < 3
  E0115 01:59:41.080563      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:59:42.081734      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:59:42.261373 24 disruption.go:691] running pods: 2 < 3
  E0115 01:59:43.082153      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:59:44.082780      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: locating a running pod @ 01/15/25 01:59:44.225
  STEP: Updating the pdb to allow a pod to be evicted @ 01/15/25 01:59:44.238
  STEP: Waiting for the pdb to be processed @ 01/15/25 01:59:44.249
  E0115 01:59:45.083938      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:59:46.085293      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 01/15/25 01:59:46.267
  STEP: Waiting for all pods to be running @ 01/15/25 01:59:46.267
  STEP: Waiting for the pdb to observed all healthy pods @ 01/15/25 01:59:46.289
  STEP: Patching the pdb to disallow a pod to be evicted @ 01/15/25 01:59:46.314
  STEP: Waiting for the pdb to be processed @ 01/15/25 01:59:46.362
  E0115 01:59:47.085878      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:59:48.086204      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Waiting for all pods to be running @ 01/15/25 01:59:48.377
  STEP: locating a running pod @ 01/15/25 01:59:48.393
  STEP: Deleting the pdb to allow a pod to be evicted @ 01/15/25 01:59:48.424
  STEP: Waiting for the pdb to be deleted @ 01/15/25 01:59:48.432
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 01/15/25 01:59:48.436
  STEP: Waiting for all pods to be running @ 01/15/25 01:59:48.436
  I0115 01:59:48.506138 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-6495" for this suite. @ 01/15/25 01:59:48.512
• [10.359 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:445
  STEP: Creating a kubernetes client @ 01/15/25 01:59:48.518
  I0115 01:59:48.518097 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename pods @ 01/15/25 01:59:48.519
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:59:48.543
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:59:48.547
  E0115 01:59:49.086844      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:59:50.089878      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:59:51.090970      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:59:52.092020      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:59:53.092288      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:59:54.092939      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 01:59:54.699
  I0115 01:59:54.711372 24 output.go:207] Trying to get logs from node 192.168.18.92 pod client-envvars-27dd70e4-f2fc-4374-92e8-e101784b0c14 container env3cont: <nil>
  STEP: delete the pod @ 01/15/25 01:59:54.734
  I0115 01:59:54.779858 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-5222" for this suite. @ 01/15/25 01:59:54.799
• [6.300 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should get and update a ReplicationController scale [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:425
  STEP: Creating a kubernetes client @ 01/15/25 01:59:54.818
  I0115 01:59:54.818870 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename replication-controller @ 01/15/25 01:59:54.821
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:59:54.871
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:59:54.883
  STEP: Creating ReplicationController "e2e-rc-d6n68" @ 01/15/25 01:59:54.897
  I0115 01:59:54.909987 24 rc.go:792] Get Replication Controller "e2e-rc-d6n68" to confirm replicas
  E0115 01:59:55.094066      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:59:55.910823 24 rc.go:792] Get Replication Controller "e2e-rc-d6n68" to confirm replicas
  I0115 01:59:55.918503 24 rc.go:801] Found 1 replicas for "e2e-rc-d6n68" replication controller
  STEP: Getting scale subresource for ReplicationController "e2e-rc-d6n68" @ 01/15/25 01:59:55.918
  STEP: Updating a scale subresource @ 01/15/25 01:59:55.928
  STEP: Verifying replicas where modified for replication controller "e2e-rc-d6n68" @ 01/15/25 01:59:55.942
  I0115 01:59:55.942687 24 rc.go:792] Get Replication Controller "e2e-rc-d6n68" to confirm replicas
  E0115 01:59:56.094736      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 01:59:56.943799 24 rc.go:792] Get Replication Controller "e2e-rc-d6n68" to confirm replicas
  I0115 01:59:56.960680 24 rc.go:801] Found 2 replicas for "e2e-rc-d6n68" replication controller
  I0115 01:59:56.960966 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-9844" for this suite. @ 01/15/25 01:59:56.977
• [2.173 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-apps] Deployment deployment should support rollover [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:132
  STEP: Creating a kubernetes client @ 01/15/25 01:59:56.992
  I0115 01:59:56.992524 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename deployment @ 01/15/25 01:59:56.994
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 01:59:57.026
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 01:59:57.036
  I0115 01:59:57.073712 24 resource.go:87] Pod name rollover-pod: Found 0 pods out of 1
  E0115 01:59:57.096046      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:59:58.096810      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 01:59:59.096994      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:00:00.097998      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:00:01.098206      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:00:02.080809 24 resource.go:87] Pod name rollover-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 01/15/25 02:00:02.08
  I0115 02:00:02.080954 24 deployment.go:911] Waiting for pods owned by replica set "test-rollover-controller" to become ready
  E0115 02:00:02.099540      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:00:03.101168      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:00:04.101061      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:00:04.104954 24 deployment.go:921] Creating deployment "test-rollover-deployment"
  I0115 02:00:04.163628 24 deployment.go:934] Make sure deployment "test-rollover-deployment" performs scaling operations
  E0115 02:00:05.102025      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:00:06.102886      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:00:06.186180 24 deployment.go:939] Check revision of new replica set for deployment "test-rollover-deployment"
  I0115 02:00:06.207182 24 deployment.go:943] Ensure that both replica sets have 1 created replica
  I0115 02:00:06.306602 24 deployment.go:952] Rollover old replica sets for deployment "test-rollover-deployment" with new image update
  I0115 02:00:06.344993 24 deployment.go:314] Updating deployment test-rollover-deployment
  I0115 02:00:06.345706 24 deployment.go:961] Wait deployment "test-rollover-deployment" to be observed by the deployment controller
  E0115 02:00:07.104936      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:00:08.106631      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:00:08.375954 24 deployment.go:966] Wait for revision update of deployment "test-rollover-deployment" to 2
  I0115 02:00:08.405358 24 deployment.go:970] Make sure deployment "test-rollover-deployment" is complete
  I0115 02:00:08.444444 24 deployment.go:95] all replica sets need to contain the pod-template-hash label
  I0115 02:00:08.444541 24 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2025, time.January, 15, 2, 0, 4, 0, time.Local), LastTransitionTime:time.Date(2025, time.January, 15, 2, 0, 4, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.January, 15, 2, 0, 7, 0, time.Local), LastTransitionTime:time.Date(2025, time.January, 15, 2, 0, 4, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7fb4c746bc\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0115 02:00:09.107201      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:00:10.109222      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:00:10.471838 24 deployment.go:95] all replica sets need to contain the pod-template-hash label
  I0115 02:00:10.472245 24 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2025, time.January, 15, 2, 0, 4, 0, time.Local), LastTransitionTime:time.Date(2025, time.January, 15, 2, 0, 4, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.January, 15, 2, 0, 7, 0, time.Local), LastTransitionTime:time.Date(2025, time.January, 15, 2, 0, 4, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7fb4c746bc\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0115 02:00:11.110461      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:00:12.112160      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:00:12.470250 24 deployment.go:95] all replica sets need to contain the pod-template-hash label
  I0115 02:00:12.470656 24 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2025, time.January, 15, 2, 0, 4, 0, time.Local), LastTransitionTime:time.Date(2025, time.January, 15, 2, 0, 4, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.January, 15, 2, 0, 7, 0, time.Local), LastTransitionTime:time.Date(2025, time.January, 15, 2, 0, 4, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7fb4c746bc\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0115 02:00:13.116948      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:00:14.117718      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:00:14.454765 24 deployment.go:95] all replica sets need to contain the pod-template-hash label
  I0115 02:00:14.454908 24 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2025, time.January, 15, 2, 0, 4, 0, time.Local), LastTransitionTime:time.Date(2025, time.January, 15, 2, 0, 4, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.January, 15, 2, 0, 7, 0, time.Local), LastTransitionTime:time.Date(2025, time.January, 15, 2, 0, 4, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7fb4c746bc\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0115 02:00:15.118832      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:00:16.123546      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:00:16.483470 24 deployment.go:95] all replica sets need to contain the pod-template-hash label
  I0115 02:00:16.483627 24 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2025, time.January, 15, 2, 0, 4, 0, time.Local), LastTransitionTime:time.Date(2025, time.January, 15, 2, 0, 4, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.January, 15, 2, 0, 7, 0, time.Local), LastTransitionTime:time.Date(2025, time.January, 15, 2, 0, 4, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7fb4c746bc\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0115 02:00:17.124218      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:00:18.124773      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:00:18.499373 24 deployment.go:95] 
  I0115 02:00:18.499669 24 deployment.go:974] Ensure that both old replica sets have no replicas
  I0115 02:00:18.577839 24 deployment.go:633] Deployment "test-rollover-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-rollover-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-9882",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "eaee738c-b0d2-4406-b76a-75046bc4dcba",
      ResourceVersion: (string) (len=6) "167368",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872503204,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872503206,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000040  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000050  2c 22 66 3a 70 72 6f 67  72 65 73 73 44 65 61 64  |,"f:progressDead|
              00000060  6c 69 6e 65 53 65 63 6f  6e 64 73 22 3a 7b 7d 2c  |lineSeconds":{},|
              00000070  22 66 3a 72 65 70 6c 69  63 61 73 22 3a 7b 7d 2c  |"f:replicas":{},|
              00000080  22 66 3a 72 65 76 69 73  69 6f 6e 48 69 73 74 6f  |"f:revisionHisto|
              00000090  72 79 4c 69 6d 69 74 22  3a 7b 7d 2c 22 66 3a 73  |ryLimit":{},"f:s|
              000000a0  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 73  |elector":{},"f:s|
              000000b0  74 72 61 74 65 67 79 22  3a 7b 22 66 3a 72 6f 6c  |trategy":{"f:rol|
              000000c0  6c 69 6e 67 55 70 64 61  74 65 22 3a 7b 22 2e 22  |lingUpdate":{"."|
              000000d0  3a 7b 7d 2c 22 66 3a 6d  61 78 53 75 72 67 65 22  |:{},"f:maxSurge"|
              000000e0  3a 7b 7d 2c 22 66 3a 6d  61 78 55 6e 61 76 61 69  |:{},"f:maxUnavai|
              000000f0  6c 61 62 6c 65 22 3a 7b  7d 7d 2c 22 66 3a 74 79  |lable":{}},"f:ty|
              00000100  70 65 22 3a 7b 7d 7d 2c  22 66 3a 74 65 6d 70 6c  |pe":{}},"f:templ|
              00000110  61 74 65 22 3a 7b 22 66  3a 6d 65 74 61 64 61 74  |ate":{"f:metadat|
              00000120  61 22 3a 7b 22 66 3a 6c  61 62 65 6c 73 22 3a 7b  |a":{"f:labels":{|
              00000130  22 2e 22 3a 7b 7d 2c 22  66 3a 6e 61 6d 65 22 3a  |".":{},"f:name":|
              00000140  7b 7d 7d 7d 2c 22 66 3a  73 70 65 63 22 3a 7b 22  |{}}},"f:spec":{"|
              00000150  66 3a 63 6f 6e 74 61 69  6e 65 72 73 22 3a 7b 22  |f:containers":{"|
              00000160  6b 3a 7b 5c 22 6e 61 6d  65 5c 22 3a 5c 22 61 67  |k:{\"name\":\"ag|
              00000170  6e 68 6f 73 74 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |nhost\"}":{".":{|
              00000180  7d 2c 22 66 3a 69 6d 61  67 65 22 3a 7b 7d 2c 22  |},"f:image":{},"|
              00000190  66 3a 69 6d 61 67 65 50  75 6c 6c 50 6f 6c 69 63  |f:imagePullPolic|
              000001a0  79 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |y":{},"f:name":{|
              000001b0  7d 2c 22 66 3a 72 65 73  6f 75 72 63 65 73 22 3a  |},"f:resources":|
              000001c0  7b 7d 2c 22 66 3a 73 65  63 75 72 69 74 79 43 6f  |{},"f:securityCo|
              000001d0  6e 74 65 78 74 22 3a 7b  7d 2c 22 66 3a 74 65 72  |ntext":{},"f:ter|
              000001e0  6d 69 6e 61 74 69 6f 6e  4d 65 73 73 61 67 65 50  |minationMessageP|
              000001f0  61 74 68 22 3a 7b 7d 2c  22 66 3a 74 65 72 6d 69  |ath":{},"f:termi|
              00000200  6e 61 74 69 6f 6e 4d 65  73 73 61 67 65 50 6f 6c  |nationMessagePol|
              00000210  69 63 79 22 3a 7b 7d 7d  7d 2c 22 66 3a 64 6e 73  |icy":{}}},"f:dns|
              00000220  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 72 65  |Policy":{},"f:re|
              00000230  73 74 61 72 74 50 6f 6c  69 63 79 22 3a 7b 7d 2c  |startPolicy":{},|
              00000240  22 66 3a 73 63 68 65 64  75 6c 65 72 4e 61 6d 65  |"f:schedulerName|
              00000250  22 3a 7b 7d 2c 22 66 3a  73 65 63 75 72 69 74 79  |":{},"f:security|
              00000260  43 6f 6e 74 65 78 74 22  3a 7b 7d 2c 22 66 3a 74  |Context":{},"f:t|
              00000270  65 72 6d 69 6e 61 74 69  6f 6e 47 72 61 63 65 50  |erminationGraceP|
              00000280  65 72 69 6f 64 53 65 63  6f 6e 64 73 22 3a 7b 7d  |eriodSeconds":{}|
              00000290  7d 7d 7d 7d                                       |}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872503217,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.53",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 0,
            StrVal: (string) ""
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 1,
            StrVal: (string) ""
          })
        })
      },
      MinReadySeconds: (int32) 10,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872503204,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872503204,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872503217,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872503204,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=77) "ReplicaSet \"test-rollover-deployment-7fb4c746bc\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0115 02:00:18.612679 24 deployment.go:40] New ReplicaSet "test-rollover-deployment-7fb4c746bc" of Deployment "test-rollover-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-rollover-deployment-7fb4c746bc",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-9882",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "b5439721-69ca-408a-9473-43d1789bd561",
      ResourceVersion: (string) (len=6) "167357",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872503206,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "7fb4c746bc"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "eaee738c-b0d2-4406-b76a-75046bc4dcba",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872503206,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=806) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 65 61 65 65 37 33  38 63 2d 62 30 64 32 2d  |\"eaee738c-b0d2-|
              00000120  34 34 30 36 2d 62 37 36  61 2d 37 35 30 34 36 62  |4406-b76a-75046b|
              00000130  63 34 64 63 62 61 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |c4dcba\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000150  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000160  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000170  2c 22 66 3a 73 65 6c 65  63 74 6f 72 22 3a 7b 7d  |,"f:selector":{}|
              00000180  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000190  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              000001a0  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              000001b0  22 66 3a 6e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 70  |"f:name":{},"f:p|
              000001c0  6f 64 2d 74 65 6d 70 6c  61 74 65 2d 68 61 73 68  |od-template-hash|
              000001d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000001e0  7b 22 66 3a 63 6f 6e 74  61 69 6e 65 72 73 22 3a  |{"f:containers":|
              000001f0  7b 22 6b 3a 7b 5c 22 6e  61 6d 65 5c 22 3a 5c 22  |{"k:{\"name\":\"|
              00000200  61 67 6e 68 6f 73 74 5c  22 7d 22 3a 7b 22 2e 22  |agnhost\"}":{"."|
              00000210  3a 7b 7d 2c 22 66 3a 69  6d 61 67 65 22 3a 7b 7d  |:{},"f:image":{}|
              00000220  2c 22 66 3a 69 6d 61 67  65 50 75 6c 6c 50 6f 6c  |,"f:imagePullPol|
              00000230  69 63 79 22 3a 7b 7d 2c  22 66 3a 6e 61 6d 65 22  |icy":{},"f:name"|
              00000240  3a 7b 7d 2c 22 66 3a 72  65 73 6f 75 72 63 65 73  |:{},"f:resources|
              00000250  22 3a 7b 7d 2c 22 66 3a  73 65 63 75 72 69 74 79  |":{},"f:security|
              00000260  43 6f 6e 74 65 78 74 22  3a 7b 7d 2c 22 66 3a 74  |Context":{},"f:t|
              00000270  65 72 6d 69 6e 61 74 69  6f 6e 4d 65 73 73 61 67  |erminationMessag|
              00000280  65 50 61 74 68 22 3a 7b  7d 2c 22 66 3a 74 65 72  |ePath":{},"f:ter|
              00000290  6d 69 6e 61 74 69 6f 6e  4d 65 73 73 61 67 65 50  |minationMessageP|
              000002a0  6f 6c 69 63 79 22 3a 7b  7d 7d 7d 2c 22 66 3a 64  |olicy":{}}},"f:d|
              000002b0  6e 73 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |nsPolicy":{},"f:|
              000002c0  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000002d0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000002e0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000002f0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              00000300  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              00000310  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              00000320  7b 7d 7d 7d 7d 7d                                 |{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872503217,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 10,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "7fb4c746bc"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "7fb4c746bc"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.53",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0115 02:00:18.616656 24 deployment.go:45] All old ReplicaSets of Deployment "test-rollover-deployment":
  I0115 02:00:18.617640 24 deployment.go:48] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-rollover-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-9882",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "52c1aa9a-dc58-46f0-a467-ee324c086ed9",
      ResourceVersion: (string) (len=6) "167367",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872503197,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=2) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "eaee738c-b0d2-4406-b76a-75046bc4dcba",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872503197,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=467) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              00000030  3a 70 6f 64 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |:pod":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  73 65 6c 65 63 74 6f 72  |ec":{"f:selector|
              00000050  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000060  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000070  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              00000080  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              00000090  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              000000a0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              000000b0  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              000000c0  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              000000d0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              000000e0  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              000000f0  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000100  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000110  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |rces":{},"f:term|
              00000120  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000130  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000140  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000150  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000160  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              00000170  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              00000180  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              00000190  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000001a0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              000001b0  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              000001c0  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              000001d0  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872503217,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=249) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 7d 2c 22 66  3a 6f 77 6e 65 72 52 65  |":{}},"f:ownerRe|
              00000090  66 65 72 65 6e 63 65 73  22 3a 7b 22 2e 22 3a 7b  |ferences":{".":{|
              000000a0  7d 2c 22 6b 3a 7b 5c 22  75 69 64 5c 22 3a 5c 22  |},"k:{\"uid\":\"|
              000000b0  65 61 65 65 37 33 38 63  2d 62 30 64 32 2d 34 34  |eaee738c-b0d2-44|
              000000c0  30 36 2d 62 37 36 61 2d  37 35 30 34 36 62 63 34  |06-b76a-75046bc4|
              000000d0  64 63 62 61 5c 22 7d 22  3a 7b 7d 7d 7d 2c 22 66  |dcba\"}":{}}},"f|
              000000e0  3a 73 70 65 63 22 3a 7b  22 66 3a 72 65 70 6c 69  |:spec":{"f:repli|
              000000f0  63 61 73 22 3a 7b 7d 7d  7d                       |cas":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872503217,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=3) "pod": (string) (len=5) "httpd",
          (string) (len=4) "name": (string) (len=12) "rollover-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=3) "pod": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0115 02:00:18.620185 24 deployment.go:48] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-rollover-deployment-6f6c9688c5",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-9882",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "e3c254cc-c289-46c5-a17f-1af8224e4903",
      ResourceVersion: (string) (len=6) "167318",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872503204,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6f6c9688c5"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "eaee738c-b0d2-4406-b76a-75046bc4dcba",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872503206,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=810) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 65 61 65 65 37 33  38 63 2d 62 30 64 32 2d  |\"eaee738c-b0d2-|
              00000120  34 34 30 36 2d 62 37 36  61 2d 37 35 30 34 36 62  |4406-b76a-75046b|
              00000130  63 34 64 63 62 61 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |c4dcba\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000150  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000160  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000170  2c 22 66 3a 73 65 6c 65  63 74 6f 72 22 3a 7b 7d  |,"f:selector":{}|
              00000180  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000190  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              000001a0  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              000001b0  22 66 3a 6e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 70  |"f:name":{},"f:p|
              000001c0  6f 64 2d 74 65 6d 70 6c  61 74 65 2d 68 61 73 68  |od-template-hash|
              000001d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000001e0  7b 22 66 3a 63 6f 6e 74  61 69 6e 65 72 73 22 3a  |{"f:containers":|
              000001f0  7b 22 6b 3a 7b 5c 22 6e  61 6d 65 5c 22 3a 5c 22  |{"k:{\"name\":\"|
              00000200  72 65 64 69 73 2d 73 6c  61 76 65 5c 22 7d 22 3a  |redis-slave\"}":|
              00000210  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              00000220  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000230  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000240  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000250  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 73 65 63 75  |rces":{},"f:secu|
              00000260  72 69 74 79 43 6f 6e 74  65 78 74 22 3a 7b 7d 2c  |rityContext":{},|
              00000270  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000280  73 73 61 67 65 50 61 74  68 22 3a 7b 7d 2c 22 66  |ssagePath":{},"f|
              00000290  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 4d 65 73 73  |:terminationMess|
              000002a0  61 67 65 50 6f 6c 69 63  79 22 3a 7b 7d 7d 7d 2c  |agePolicy":{}}},|
              000002b0  22 66 3a 64 6e 73 50 6f  6c 69 63 79 22 3a 7b 7d  |"f:dnsPolicy":{}|
              000002c0  2c 22 66 3a 72 65 73 74  61 72 74 50 6f 6c 69 63  |,"f:restartPolic|
              000002d0  79 22 3a 7b 7d 2c 22 66  3a 73 63 68 65 64 75 6c  |y":{},"f:schedul|
              000002e0  65 72 4e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 73 65  |erName":{},"f:se|
              000002f0  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000300  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000310  47 72 61 63 65 50 65 72  69 6f 64 53 65 63 6f 6e  |GracePeriodSecon|
              00000320  64 73 22 3a 7b 7d 7d 7d  7d 7d                    |ds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872503206,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 10,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "6f6c9688c5"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "6f6c9688c5"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=11) "redis-slave",
              Image: (string) (len=47) "gcr.io/google_samples/gb-redisslave:nonexistent",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0115 02:00:18.767148 24 deployment.go:68] Pod "test-rollover-deployment-7fb4c746bc-4xms8" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=41) "test-rollover-deployment-7fb4c746bc-4xms8",
      GenerateName: (string) (len=36) "test-rollover-deployment-7fb4c746bc-",
      Namespace: (string) (len=15) "deployment-9882",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "7a6b3250-d7e7-486e-81c5-34a2664b1b1e",
      ResourceVersion: (string) (len=6) "167338",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872503206,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "7fb4c746bc"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "771d16d428b575d358bf6e3b7741bd490df5b535c617ca31edb6c49f84a0d7da",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=14) "10.1.155.33/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=14) "10.1.155.33/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=35) "test-rollover-deployment-7fb4c746bc",
          UID: (types.UID) (len=36) "b5439721-69ca-408a-9473-43d1789bd561",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872503206,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 62 35  34 33 39 37 32 31 2d 36  |d\":\"b5439721-6|
              00000090  39 63 61 2d 34 30 38 61  2d 39 34 37 33 2d 34 33  |9ca-408a-9473-43|
              000000a0  64 31 37 38 39 62 64 35  36 31 5c 22 7d 22 3a 7b  |d1789bd561\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872503207,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872503207,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 31 2e 31 35 35 2e 33  33 5c 22 7d 22 3a 7b 22  |.1.155.33\"}":{"|
              00000270  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000280  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000290  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-nczbd",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.53",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-nczbd",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=13) "192.168.18.92",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872503207,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872503206,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872503207,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872503207,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872503206,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "192.168.18.92",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "192.168.18.92"
        }
      },
      PodIP: (string) (len=11) "10.1.155.33",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.1.155.33"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872503206,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63872503207,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.53",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:99c6b4bb4a1e1df3f0b3752168c89358794d02258ebebc26bf21c29399011a85",
          ContainerID: (string) (len=77) "containerd://ebe64b6cc921d7b76513b21ada5221d4ed08f1664be78fe9652b9ee6ca3d1bce",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-nczbd",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0115 02:00:18.793127 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-9882" for this suite. @ 01/15/25 02:00:18.861
• [21.901 seconds]
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:57
  STEP: Creating a kubernetes client @ 01/15/25 02:00:18.895
  I0115 02:00:18.895613 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename runtimeclass @ 01/15/25 02:00:18.897
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:00:18.948
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:00:18.961
  I0115 02:00:18.982694 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-9677" for this suite. @ 01/15/25 02:00:18.991
• [0.107 seconds]
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl logs logs should be able to retrieve and filter logs [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/logs.go:167
  STEP: Creating a kubernetes client @ 01/15/25 02:00:19
  I0115 02:00:19.000745 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename kubectl-logs @ 01/15/25 02:00:19.002
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:00:19.033
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:00:19.042
  STEP: creating a pod @ 01/15/25 02:00:19.051
  I0115 02:00:19.051805 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-logs-2770 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.53 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
  E0115 02:00:19.125779      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:00:19.211069 24 builder.go:146] stderr: ""
  I0115 02:00:19.211171 24 builder.go:147] stdout: "pod/logs-generator created\n"
  STEP: Waiting for log generator to start. @ 01/15/25 02:00:19.211
  I0115 02:00:19.211510 24 resource.go:413] Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
  E0115 02:00:20.126912      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:00:21.128869      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:00:21.231473 24 resource.go:435] Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
  STEP: checking for a matching strings @ 01/15/25 02:00:21.231
  I0115 02:00:21.232403 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-logs-2770 logs logs-generator logs-generator'
  I0115 02:00:21.545366 24 builder.go:146] stderr: ""
  I0115 02:00:21.545475 24 builder.go:147] stdout: "I0115 02:00:20.454903       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/kube-system/pods/s98 370\nI0115 02:00:20.656607       1 logs_generator.go:76] 1 POST /api/v1/namespaces/ns/pods/mbz 528\nI0115 02:00:20.856304       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/ns/pods/pqn 295\nI0115 02:00:21.054990       1 logs_generator.go:76] 3 GET /api/v1/namespaces/ns/pods/jn84 434\nI0115 02:00:21.255936       1 logs_generator.go:76] 4 POST /api/v1/namespaces/default/pods/cslk 288\nI0115 02:00:21.455999       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/default/pods/5wb 589\n"
  STEP: limiting log lines @ 01/15/25 02:00:21.545
  I0115 02:00:21.545586 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-logs-2770 logs logs-generator logs-generator --tail=1'
  I0115 02:00:21.731119 24 builder.go:146] stderr: ""
  I0115 02:00:21.731187 24 builder.go:147] stdout: "I0115 02:00:21.683642       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/kube-system/pods/5dz 367\n"
  I0115 02:00:21.731217 24 logs.go:180] got output "I0115 02:00:21.683642       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/kube-system/pods/5dz 367\n"
  STEP: limiting log bytes @ 01/15/25 02:00:21.731
  I0115 02:00:21.731307 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-logs-2770 logs logs-generator logs-generator --limit-bytes=1'
  I0115 02:00:21.815081 24 builder.go:146] stderr: ""
  I0115 02:00:21.815148 24 builder.go:147] stdout: "I"
  I0115 02:00:21.815166 24 logs.go:186] got output "I"
  STEP: exposing timestamps @ 01/15/25 02:00:21.815
  I0115 02:00:21.815253 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-logs-2770 logs logs-generator logs-generator --tail=1 --timestamps'
  I0115 02:00:21.908818 24 builder.go:146] stderr: ""
  I0115 02:00:21.908873 24 builder.go:147] stdout: "2025-01-15T10:00:21.855579792+08:00 I0115 02:00:21.855384       1 logs_generator.go:76] 7 GET /api/v1/namespaces/default/pods/hppf 412\n"
  I0115 02:00:21.908888 24 logs.go:192] got output "2025-01-15T10:00:21.855579792+08:00 I0115 02:00:21.855384       1 logs_generator.go:76] 7 GET /api/v1/namespaces/default/pods/hppf 412\n"
  STEP: restricting to a time range @ 01/15/25 02:00:21.908
  E0115 02:00:22.128967      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:00:23.129690      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:00:24.131899      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:00:24.410695 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-logs-2770 logs logs-generator logs-generator --since=1s'
  I0115 02:00:24.573206 24 builder.go:146] stderr: ""
  I0115 02:00:24.573263 24 builder.go:147] stdout: "I0115 02:00:23.655862       1 logs_generator.go:76] 16 GET /api/v1/namespaces/ns/pods/vxf 395\nI0115 02:00:23.855949       1 logs_generator.go:76] 17 GET /api/v1/namespaces/ns/pods/qgd 277\nI0115 02:00:24.055148       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/kube-system/pods/v48 288\nI0115 02:00:24.255949       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/ns/pods/dbq 258\nI0115 02:00:24.455932       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/ns/pods/7mwj 413\n"
  I0115 02:00:24.573307 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-logs-2770 logs logs-generator logs-generator --since=24h'
  I0115 02:00:24.680842 24 builder.go:146] stderr: ""
  I0115 02:00:24.680944 24 builder.go:147] stdout: "I0115 02:00:20.454903       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/kube-system/pods/s98 370\nI0115 02:00:20.656607       1 logs_generator.go:76] 1 POST /api/v1/namespaces/ns/pods/mbz 528\nI0115 02:00:20.856304       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/ns/pods/pqn 295\nI0115 02:00:21.054990       1 logs_generator.go:76] 3 GET /api/v1/namespaces/ns/pods/jn84 434\nI0115 02:00:21.255936       1 logs_generator.go:76] 4 POST /api/v1/namespaces/default/pods/cslk 288\nI0115 02:00:21.455999       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/default/pods/5wb 589\nI0115 02:00:21.683642       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/kube-system/pods/5dz 367\nI0115 02:00:21.855384       1 logs_generator.go:76] 7 GET /api/v1/namespaces/default/pods/hppf 412\nI0115 02:00:22.055180       1 logs_generator.go:76] 8 POST /api/v1/namespaces/kube-system/pods/ndw9 540\nI0115 02:00:22.256776       1 logs_generator.go:76] 9 PUT /api/v1/namespaces/kube-system/pods/7w4 263\nI0115 02:00:22.456845       1 logs_generator.go:76] 10 GET /api/v1/namespaces/ns/pods/787 311\nI0115 02:00:22.657162       1 logs_generator.go:76] 11 GET /api/v1/namespaces/default/pods/bj49 360\nI0115 02:00:22.867801       1 logs_generator.go:76] 12 PUT /api/v1/namespaces/ns/pods/9kw 357\nI0115 02:00:23.055625       1 logs_generator.go:76] 13 GET /api/v1/namespaces/default/pods/xfzx 277\nI0115 02:00:23.255652       1 logs_generator.go:76] 14 GET /api/v1/namespaces/default/pods/vm6q 356\nI0115 02:00:23.455795       1 logs_generator.go:76] 15 GET /api/v1/namespaces/default/pods/d2b 414\nI0115 02:00:23.655862       1 logs_generator.go:76] 16 GET /api/v1/namespaces/ns/pods/vxf 395\nI0115 02:00:23.855949       1 logs_generator.go:76] 17 GET /api/v1/namespaces/ns/pods/qgd 277\nI0115 02:00:24.055148       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/kube-system/pods/v48 288\nI0115 02:00:24.255949       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/ns/pods/dbq 258\nI0115 02:00:24.455932       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/ns/pods/7mwj 413\nI0115 02:00:24.656222       1 logs_generator.go:76] 21 POST /api/v1/namespaces/ns/pods/t94g 411\n"
  I0115 02:00:24.681066 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-logs-2770 delete pod logs-generator'
  E0115 02:00:25.132140      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:00:25.935336 24 builder.go:146] stderr: ""
  I0115 02:00:25.935434 24 builder.go:147] stdout: "pod \"logs-generator\" deleted\n"
  I0115 02:00:25.935603 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-logs-2770" for this suite. @ 01/15/25 02:00:25.943
• [6.955 seconds]
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:218
  STEP: Creating a kubernetes client @ 01/15/25 02:00:25.956
  I0115 02:00:25.956195 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename webhook @ 01/15/25 02:00:25.957
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:00:25.975
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:00:25.981
  STEP: Setting up server cert @ 01/15/25 02:00:26.098
  E0115 02:00:26.132478      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 01/15/25 02:00:26.882
  STEP: Deploying the webhook pod @ 01/15/25 02:00:26.894
  STEP: Wait for the deployment to be ready @ 01/15/25 02:00:26.917
  I0115 02:00:26.928327 24 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0115 02:00:27.132724      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:00:28.134322      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:00:28.945086 24 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.January, 15, 2, 0, 26, 0, time.Local), LastTransitionTime:time.Date(2025, time.January, 15, 2, 0, 26, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.January, 15, 2, 0, 26, 0, time.Local), LastTransitionTime:time.Date(2025, time.January, 15, 2, 0, 26, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-bcbfc85d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0115 02:00:29.134704      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:00:30.136325      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 01/15/25 02:00:30.959
  STEP: Verifying the service has paired with the endpoint @ 01/15/25 02:00:30.993
  E0115 02:00:31.137628      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:00:31.995010 24 util.go:423] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  I0115 02:00:32.014052 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  E0115 02:00:32.139775      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Registering the custom resource webhook via the AdmissionRegistration API @ 01/15/25 02:00:32.543
  STEP: Creating a custom resource that should be denied by the webhook @ 01/15/25 02:00:32.619
  E0115 02:00:33.140357      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:00:34.143691      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Creating a custom resource whose deletion would be denied by the webhook @ 01/15/25 02:00:34.693
  STEP: Updating the custom resource with disallowed data should be denied @ 01/15/25 02:00:34.706
  STEP: Deleting the custom resource should be denied @ 01/15/25 02:00:34.72
  STEP: Remove the offending key and value from the custom resource data @ 01/15/25 02:00:34.728
  STEP: Deleting the updated custom resource should be successful @ 01/15/25 02:00:34.739
  E0115 02:00:35.144175      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:00:35.327056 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-7076" for this suite. @ 01/15/25 02:00:35.338
  STEP: Destroying namespace "webhook-markers-8724" for this suite. @ 01/15/25 02:00:35.348
• [9.400 seconds]
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:177
  STEP: Creating a kubernetes client @ 01/15/25 02:00:35.356
  I0115 02:00:35.356816 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename daemonsets @ 01/15/25 02:00:35.359
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:00:35.375
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:00:35.382
  STEP: Creating simple DaemonSet "daemon-set" @ 01/15/25 02:00:35.446
  STEP: Check that daemon pods launch on every node of the cluster. @ 01/15/25 02:00:35.468
  I0115 02:00:35.579004 24 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0115 02:00:35.579110 24 fixtures.go:131] Node 192.168.18.91 is running 0 daemon pod, expected 1
  E0115 02:00:36.145522      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:00:36.485302 24 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0115 02:00:36.485433 24 fixtures.go:131] Node 192.168.18.91 is running 0 daemon pod, expected 1
  E0115 02:00:37.146020      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:00:37.485503 24 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0115 02:00:37.485704 24 fixtures.go:131] Node 192.168.18.91 is running 0 daemon pod, expected 1
  E0115 02:00:38.146011      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:00:38.496233 24 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0115 02:00:38.496369 24 fixtures.go:136] Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Stop a daemon pod, check that the daemon pod is revived. @ 01/15/25 02:00:38.507
  I0115 02:00:38.586110 24 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0115 02:00:38.586216 24 fixtures.go:131] Node 192.168.18.92 is running 0 daemon pod, expected 1
  E0115 02:00:39.146472      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:00:39.554129 24 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0115 02:00:39.554203 24 fixtures.go:131] Node 192.168.18.92 is running 0 daemon pod, expected 1
  E0115 02:00:40.147060      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:00:40.547618 24 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0115 02:00:40.547688 24 fixtures.go:131] Node 192.168.18.92 is running 0 daemon pod, expected 1
  E0115 02:00:41.147579      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:00:41.582501 24 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0115 02:00:41.583383 24 fixtures.go:136] Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 01/15/25 02:00:41.599
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7078, will wait for the garbage collector to delete the pods @ 01/15/25 02:00:41.599
  I0115 02:00:41.673563 24 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 12.714092ms
  I0115 02:00:41.774436 24 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 100.7126ms
  E0115 02:00:42.149273      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:00:43.150586      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:00:44.152729      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:00:44.186700 24 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0115 02:00:44.186776 24 fixtures.go:136] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0115 02:00:44.204400 24 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"167641"},"items":null}

  I0115 02:00:44.212867 24 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"167641"},"items":null}

  I0115 02:00:44.236052 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-7078" for this suite. @ 01/15/25 02:00:44.242
• [8.895 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] PodTemplates should replace a pod template [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/podtemplates.go:177
  STEP: Creating a kubernetes client @ 01/15/25 02:00:44.252
  I0115 02:00:44.252391 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename podtemplate @ 01/15/25 02:00:44.253
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:00:44.274
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:00:44.28
  STEP: Create a pod template @ 01/15/25 02:00:44.287
  STEP: Replace a pod template @ 01/15/25 02:00:44.294
  I0115 02:00:44.307605 24 podtemplates.go:210] Found updated podtemplate annotation: "true"

  I0115 02:00:44.307832 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-8610" for this suite. @ 01/15/25 02:00:44.323
• [0.082 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for services [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:152
  STEP: Creating a kubernetes client @ 01/15/25 02:00:44.335
  I0115 02:00:44.335923 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename dns @ 01/15/25 02:00:44.339
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:00:44.444
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:00:44.458
  STEP: Creating a test headless service @ 01/15/25 02:00:44.476
  STEP: Running these commands on agnhost: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4069.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/agnhost_udp@dns-test-service.dns-4069.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4069.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/agnhost_tcp@dns-test-service.dns-4069.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4069.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/agnhost_udp@_http._tcp.dns-test-service.dns-4069.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4069.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/agnhost_tcp@_http._tcp.dns-test-service.dns-4069.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4069.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/agnhost_udp@_http._tcp.test-service-2.dns-4069.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4069.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/agnhost_tcp@_http._tcp.test-service-2.dns-4069.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 9.65.169.169.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/169.169.65.9_udp@PTR;check="$$(dig +tcp +noall +answer +search 9.65.169.169.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/169.169.65.9_tcp@PTR;sleep 1; done
   @ 01/15/25 02:00:44.517
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4069.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-4069.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4069.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-4069.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4069.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-4069.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4069.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-4069.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4069.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-4069.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4069.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-4069.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 9.65.169.169.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/169.169.65.9_udp@PTR;check="$$(dig +tcp +noall +answer +search 9.65.169.169.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/169.169.65.9_tcp@PTR;sleep 1; done
   @ 01/15/25 02:00:44.517
  STEP: creating a pod to probe DNS @ 01/15/25 02:00:44.517
  STEP: submitting the pod to kubernetes @ 01/15/25 02:00:44.517
  E0115 02:00:45.154110      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:00:46.154905      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:00:47.156213      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:00:48.157033      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 01/15/25 02:00:48.607
  STEP: looking for the results for each expected name from probers @ 01/15/25 02:00:48.614
  I0115 02:00:48.729912 24 dns_common.go:546] DNS probes using dns-4069/dns-test-9e776153-beee-4761-b3fc-a5f41db9192e succeeded

  STEP: deleting the pod @ 01/15/25 02:00:48.73
  STEP: deleting the test service @ 01/15/25 02:00:48.756
  STEP: deleting the test headless service @ 01/15/25 02:00:48.795
  I0115 02:00:48.821476 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-4069" for this suite. @ 01/15/25 02:00:48.837
• [4.515 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:120
  STEP: Creating a kubernetes client @ 01/15/25 02:00:48.851
  I0115 02:00:48.852090 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename emptydir @ 01/15/25 02:00:48.854
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:00:48.899
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:00:48.918
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 01/15/25 02:00:48.929
  E0115 02:00:49.159695      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:00:50.161805      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:00:51.161204      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:00:52.162145      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 02:00:53.008
  I0115 02:00:53.039572 24 output.go:207] Trying to get logs from node 192.168.18.92 pod pod-97411cc4-8949-4199-91c4-8a89e0e922ef container test-container: <nil>
  STEP: delete the pod @ 01/15/25 02:00:53.073
  I0115 02:00:53.132897 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-38" for this suite. @ 01/15/25 02:00:53.139
• [4.297 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:164
  STEP: Creating a kubernetes client @ 01/15/25 02:00:53.148
  I0115 02:00:53.148377 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename resourcequota @ 01/15/25 02:00:53.149
  E0115 02:00:53.162958      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:00:53.168
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:00:53.174
  STEP: Discovering how many secrets are in namespace by default @ 01/15/25 02:00:53.181
  E0115 02:00:54.163731      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:00:55.165513      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:00:56.167147      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:00:57.168185      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:00:58.169456      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Counting existing ResourceQuota @ 01/15/25 02:00:58.209
  E0115 02:00:59.169281      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:01:00.170856      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:01:01.170783      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:01:02.171930      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:01:03.173156      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 01/15/25 02:01:03.213
  STEP: Ensuring resource quota status is calculated @ 01/15/25 02:01:03.218
  E0115 02:01:04.174189      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:01:05.174500      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Creating a Secret @ 01/15/25 02:01:05.225
  STEP: Ensuring resource quota status captures secret creation @ 01/15/25 02:01:05.24
  E0115 02:01:06.179056      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:01:07.180500      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Deleting a secret @ 01/15/25 02:01:07.261
  STEP: Ensuring resource quota status released usage @ 01/15/25 02:01:07.288
  E0115 02:01:08.180726      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:01:09.182447      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:01:09.306762 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-5591" for this suite. @ 01/15/25 02:01:09.328
• [16.192 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-instrumentation] Events should delete a collection of events [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/core_events.go:176
  STEP: Creating a kubernetes client @ 01/15/25 02:01:09.34
  I0115 02:01:09.340904 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename events @ 01/15/25 02:01:09.342
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:01:09.359
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:01:09.365
  STEP: Create set of events @ 01/15/25 02:01:09.37
  I0115 02:01:09.378294 24 core_events.go:198] created test-event-1
  I0115 02:01:09.383641 24 core_events.go:198] created test-event-2
  I0115 02:01:09.388780 24 core_events.go:198] created test-event-3
  STEP: get a list of Events with a label in the current namespace @ 01/15/25 02:01:09.388
  STEP: delete collection of events @ 01/15/25 02:01:09.393
  I0115 02:01:09.393758 24 core_events.go:213] requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 01/15/25 02:01:09.412
  I0115 02:01:09.412481 24 core_events.go:230] requesting list of events to confirm quantity
  I0115 02:01:09.418350 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-1979" for this suite. @ 01/15/25 02:01:09.424
• [0.092 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services should serve multiport endpoints from pods [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:821
  STEP: Creating a kubernetes client @ 01/15/25 02:01:09.433
  I0115 02:01:09.433252 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename services @ 01/15/25 02:01:09.435
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:01:09.465
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:01:09.47
  STEP: creating service multi-endpoint-test in namespace services-7829 @ 01/15/25 02:01:09.476
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7829 to expose endpoints map[] @ 01/15/25 02:01:09.488
  I0115 02:01:09.552464 24 service.go:4460] successfully validated that service multi-endpoint-test in namespace services-7829 exposes endpoints map[]
  STEP: Creating pod pod1 in namespace services-7829 @ 01/15/25 02:01:09.552
  E0115 02:01:10.182820      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:01:11.186145      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7829 to expose endpoints map[pod1:[100]] @ 01/15/25 02:01:11.626
  I0115 02:01:11.657932 24 service.go:4460] successfully validated that service multi-endpoint-test in namespace services-7829 exposes endpoints map[pod1:[100]]
  STEP: Creating pod pod2 in namespace services-7829 @ 01/15/25 02:01:11.658
  E0115 02:01:12.186842      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:01:13.188861      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7829 to expose endpoints map[pod1:[100] pod2:[101]] @ 01/15/25 02:01:13.697
  I0115 02:01:13.727331 24 service.go:4460] successfully validated that service multi-endpoint-test in namespace services-7829 exposes endpoints map[pod1:[100] pod2:[101]]
  STEP: Checking if the Service forwards traffic to pods @ 01/15/25 02:01:13.727
  I0115 02:01:13.727446 24 resource.go:361] Creating new exec pod
  E0115 02:01:14.188908      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:01:15.189300      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:01:16.190813      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:01:16.757849 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-7829 exec execpod6f9ld -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
  I0115 02:01:17.082761 24 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test (169.169.217.160) 80 port [tcp/http] succeeded!\n"
  I0115 02:01:17.082924 24 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0115 02:01:17.083072 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-7829 exec execpod6f9ld -- /bin/sh -x -c echo hostName | nc -v -t -w 2 169.169.217.160 80'
  E0115 02:01:17.192088      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:01:17.655503 24 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 169.169.217.160 80\nConnection to 169.169.217.160 80 port [tcp/http] succeeded!\n"
  I0115 02:01:17.655788 24 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0115 02:01:17.655963 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-7829 exec execpod6f9ld -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
  I0115 02:01:18.038776 24 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test (169.169.217.160) 81 port [tcp/*] succeeded!\n"
  I0115 02:01:18.038881 24 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0115 02:01:18.039073 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-7829 exec execpod6f9ld -- /bin/sh -x -c echo hostName | nc -v -t -w 2 169.169.217.160 81'
  E0115 02:01:18.191997      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:01:18.403654 24 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 169.169.217.160 81\nConnection to 169.169.217.160 81 port [tcp/*] succeeded!\n"
  I0115 02:01:18.403793 24 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod1 in namespace services-7829 @ 01/15/25 02:01:18.403
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7829 to expose endpoints map[pod2:[101]] @ 01/15/25 02:01:18.542
  I0115 02:01:18.658725 24 service.go:4460] successfully validated that service multi-endpoint-test in namespace services-7829 exposes endpoints map[pod2:[101]]
  STEP: Deleting pod pod2 in namespace services-7829 @ 01/15/25 02:01:18.658
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7829 to expose endpoints map[] @ 01/15/25 02:01:18.736
  I0115 02:01:18.804541 24 service.go:4460] successfully validated that service multi-endpoint-test in namespace services-7829 exposes endpoints map[]
  I0115 02:01:18.890755 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-7829" for this suite. @ 01/15/25 02:01:18.907
• [9.515 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:108
  STEP: Creating a kubernetes client @ 01/15/25 02:01:18.949
  I0115 02:01:18.949717 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename pod-network-test @ 01/15/25 02:01:18.954
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:01:19.042
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:01:19.093
  STEP: Performing setup for networking test in namespace pod-network-test-3729 @ 01/15/25 02:01:19.147
  STEP: creating a selector @ 01/15/25 02:01:19.147
  STEP: Creating the service pods in kubernetes @ 01/15/25 02:01:19.147
  I0115 02:01:19.147977 24 helper.go:51] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0115 02:01:19.194761      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:01:20.196037      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:01:21.197413      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:01:22.198580      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:01:23.198949      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:01:24.200047      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:01:25.200863      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:01:26.205723      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:01:27.206254      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:01:28.208652      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:01:29.209607      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:01:30.209710      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:01:31.210293      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:01:32.211085      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:01:33.212794      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:01:34.214157      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:01:35.215474      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 01/15/25 02:01:35.489
  E0115 02:01:36.215588      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:01:37.217845      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:01:37.537545 24 utils.go:803] Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
  I0115 02:01:37.537663 24 utils.go:496] Going to poll 10.1.213.115 on port 8083 at least 0 times, with a maximum of 34 tries before failing
  I0115 02:01:37.545849 24 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.1.213.115:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3729 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0115 02:01:37.546031 24 exec_util.go:64] ExecWithOptions: Clientset creation
  I0115 02:01:37.546274 24 exec_util.go:80] ExecWithOptions: execute(POST https://169.169.0.1:443/api/v1/namespaces/pod-network-test-3729/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.1.213.115%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&stderr=true&stdout=true)
  I0115 02:01:37.733791 24 utils.go:513] Found all 1 expected endpoints: [netserver-0]
  I0115 02:01:37.733848 24 utils.go:496] Going to poll 10.1.155.46 on port 8083 at least 0 times, with a maximum of 34 tries before failing
  I0115 02:01:37.741777 24 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.1.155.46:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3729 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0115 02:01:37.743181 24 exec_util.go:64] ExecWithOptions: Clientset creation
  I0115 02:01:37.743391 24 exec_util.go:80] ExecWithOptions: execute(POST https://169.169.0.1:443/api/v1/namespaces/pod-network-test-3729/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F10.1.155.46%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&stderr=true&stdout=true)
  I0115 02:01:37.819015 24 utils.go:513] Found all 1 expected endpoints: [netserver-1]
  I0115 02:01:37.819144 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-3729" for this suite. @ 01/15/25 02:01:37.823
• [18.880 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:154
  STEP: Creating a kubernetes client @ 01/15/25 02:01:37.83
  I0115 02:01:37.830201 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename crd-publish-openapi @ 01/15/25 02:01:37.831
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:01:37.846
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:01:37.853
  I0115 02:01:37.858650 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  E0115 02:01:38.217948      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 01/15/25 02:01:39.168
  I0115 02:01:39.169411 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=crd-publish-openapi-409 --namespace=crd-publish-openapi-409 create -f -'
  E0115 02:01:39.218625      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:01:39.275119 24 builder.go:146] stderr: ""
  I0115 02:01:39.275202 24 builder.go:147] stdout: "e2e-test-crd-publish-openapi-6196-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  I0115 02:01:39.275262 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=crd-publish-openapi-409 --namespace=crd-publish-openapi-409 delete e2e-test-crd-publish-openapi-6196-crds test-cr'
  I0115 02:01:39.391587 24 builder.go:146] stderr: ""
  I0115 02:01:39.391661 24 builder.go:147] stdout: "e2e-test-crd-publish-openapi-6196-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
  I0115 02:01:39.391717 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=crd-publish-openapi-409 --namespace=crd-publish-openapi-409 apply -f -'
  I0115 02:01:39.564824 24 builder.go:146] stderr: ""
  I0115 02:01:39.564896 24 builder.go:147] stdout: "e2e-test-crd-publish-openapi-6196-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  I0115 02:01:39.564955 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=crd-publish-openapi-409 --namespace=crd-publish-openapi-409 delete e2e-test-crd-publish-openapi-6196-crds test-cr'
  I0115 02:01:39.651937 24 builder.go:146] stderr: ""
  I0115 02:01:39.652007 24 builder.go:147] stdout: "e2e-test-crd-publish-openapi-6196-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR without validation schema @ 01/15/25 02:01:39.652
  I0115 02:01:39.652146 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=crd-publish-openapi-409 explain e2e-test-crd-publish-openapi-6196-crds'
  I0115 02:01:39.728655 24 builder.go:146] stderr: ""
  I0115 02:01:39.728745 24 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-empty.example.com\nKIND:       e2e-test-crd-publish-openapi-6196-crd\nVERSION:    v1\n\nDESCRIPTION:\n    <empty>\nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n\n"
  E0115 02:01:40.219391      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:01:41.085686 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-409" for this suite. @ 01/15/25 02:01:41.096
• [3.273 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:176
  STEP: Creating a kubernetes client @ 01/15/25 02:01:41.103
  I0115 02:01:41.103806 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename configmap @ 01/15/25 02:01:41.104
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:01:41.12
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:01:41.127
  STEP: Creating configMap with name configmap-test-upd-78a056dc-3393-4d16-ae84-8e951bdf216c @ 01/15/25 02:01:41.196
  STEP: Creating the pod @ 01/15/25 02:01:41.202
  E0115 02:01:41.224726      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:01:42.225527      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:01:43.225655      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Waiting for pod with text data @ 01/15/25 02:01:43.264
  STEP: Waiting for pod with binary data @ 01/15/25 02:01:43.284
  I0115 02:01:43.311750 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-6356" for this suite. @ 01/15/25 02:01:43.324
• [2.243 seconds]
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:214
  STEP: Creating a kubernetes client @ 01/15/25 02:01:43.347
  I0115 02:01:43.347425 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename sched-preemption @ 01/15/25 02:01:43.348
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:01:43.392
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:01:43.4
  I0115 02:01:43.437554 24 wait.go:51] Waiting up to 1m0s for all nodes to be ready
  E0115 02:01:44.226969      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:01:45.227434      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:01:46.227582      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:01:47.228321      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:01:48.230238      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:01:49.231019      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:01:50.231726      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:01:51.233548      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:01:52.234317      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:01:53.235450      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:01:54.236544      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:01:55.236778      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:01:56.238171      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:01:57.238789      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:01:58.239510      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:01:59.243398      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:02:00.247720      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:02:01.248764      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:02:02.249187      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:02:03.250026      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:02:04.251377      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:02:05.251873      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:02:06.252480      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:02:07.252596      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:02:08.254757      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:02:09.256714      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:02:10.257053      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:02:11.257822      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:02:12.258719      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:02:13.259843      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:02:14.260956      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:02:15.262426      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:02:16.263276      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:02:17.264441      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:02:18.264697      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:02:19.265601      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:02:20.266010      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:02:21.267161      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:02:22.268197      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:02:23.270121      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:02:24.270751      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:02:25.271742      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:02:26.271951      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:02:27.272756      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:02:28.273239      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:02:29.274287      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:02:30.274464      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:02:31.275795      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:02:32.276963      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:02:33.278050      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:02:34.278448      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:02:35.280454      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:02:36.280842      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:02:37.283049      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:02:38.283820      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:02:39.284809      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:02:40.286318      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:02:41.288326      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:02:42.289884      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:02:43.291042      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:02:43.454273 24 util.go:396] Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 01/15/25 02:02:43.466
  STEP: Adding a custom resource @ 01/15/25 02:02:43.467
  I0115 02:02:43.544272 24 preemption.go:255] Created pod: pod0-0-sched-preemption-low-priority
  I0115 02:02:43.552712 24 preemption.go:255] Created pod: pod0-1-sched-preemption-medium-priority
  STEP: Adding a custom resource @ 01/15/25 02:02:43.552
  I0115 02:02:43.622614 24 preemption.go:255] Created pod: pod1-0-sched-preemption-medium-priority
  I0115 02:02:43.638453 24 preemption.go:255] Created pod: pod1-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 01/15/25 02:02:43.638
  E0115 02:02:44.291403      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:02:45.292170      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Run a critical pod that use same resources as that of a lower priority pod @ 01/15/25 02:02:45.673
  E0115 02:02:46.293166      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:02:47.294422      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:02:48.295567      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:02:49.296600      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Removing a custom resource @ 01/15/25 02:02:49.778
  STEP: Removing a custom resource @ 01/15/25 02:02:49.793
  I0115 02:02:49.810980 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-5757" for this suite. @ 01/15/25 02:02:49.817
• [66.480 seconds]
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:443
  STEP: Creating a kubernetes client @ 01/15/25 02:02:49.827
  I0115 02:02:49.827653 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename daemonsets @ 01/15/25 02:02:49.829
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:02:49.846
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:02:49.852
  I0115 02:02:49.885433 24 daemon_set.go:447] Create a RollingUpdate DaemonSet
  I0115 02:02:49.892387 24 daemon_set.go:454] Check that daemon pods launch on every node of the cluster
  I0115 02:02:49.976413 24 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0115 02:02:49.976583 24 fixtures.go:131] Node 192.168.18.91 is running 0 daemon pod, expected 1
  E0115 02:02:50.297879      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:02:50.936160 24 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0115 02:02:50.936384 24 fixtures.go:131] Node 192.168.18.91 is running 0 daemon pod, expected 1
  E0115 02:02:51.298032      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:02:51.901258 24 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0115 02:02:51.901347 24 fixtures.go:136] Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  I0115 02:02:51.901371 24 daemon_set.go:458] Update the DaemonSet to trigger a rollout
  I0115 02:02:51.910214 24 daemon_set.go:102] Updating DaemonSet daemon-set
  E0115 02:02:52.300113      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:02:53.300513      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:02:54.301879      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:02:54.936485 24 daemon_set.go:493] Roll back the DaemonSet before rollout is complete
  I0115 02:02:54.952890 24 daemon_set.go:102] Updating DaemonSet daemon-set
  I0115 02:02:54.952965 24 daemon_set.go:499] Make sure DaemonSet rollback is complete
  I0115 02:02:54.962101 24 daemon_set.go:1193] Wrong image for pod: daemon-set-m28cx. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-4, got: foo:non-existent.
  I0115 02:02:54.962161 24 daemon_set.go:1198] Pod daemon-set-m28cx is not available
  E0115 02:02:55.301656      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:02:56.301929      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:02:57.302889      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:02:58.303497      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:02:59.303987      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:03:00.305189      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:03:00.965781 24 daemon_set.go:1198] Pod daemon-set-csfd7 is not available
  STEP: Deleting DaemonSet "daemon-set" @ 01/15/25 02:03:00.987
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5568, will wait for the garbage collector to delete the pods @ 01/15/25 02:03:00.987
  I0115 02:03:01.049001 24 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 4.751845ms
  I0115 02:03:01.149213 24 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 100.209226ms
  E0115 02:03:01.305591      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:03:02.306980      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:03:02.753117 24 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0115 02:03:02.753202 24 fixtures.go:136] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0115 02:03:02.757413 24 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"168476"},"items":null}

  I0115 02:03:02.761248 24 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"168476"},"items":null}

  I0115 02:03:02.776842 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-5568" for this suite. @ 01/15/25 02:03:02.782
• [12.964 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:209
  STEP: Creating a kubernetes client @ 01/15/25 02:03:02.792
  I0115 02:03:02.792362 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename projected @ 01/15/25 02:03:02.793
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:03:02.812
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:03:02.817
  STEP: Creating a pod to test downward API volume plugin @ 01/15/25 02:03:02.824
  E0115 02:03:03.307042      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:03:04.307867      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:03:05.309146      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:03:06.309783      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 02:03:06.853
  I0115 02:03:06.858291 24 output.go:207] Trying to get logs from node 192.168.18.92 pod downwardapi-volume-efc16895-f161-4cb2-bd93-3809985dbce0 container client-container: <nil>
  STEP: delete the pod @ 01/15/25 02:03:06.868
  I0115 02:03:06.885935 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6471" for this suite. @ 01/15/25 02:03:06.891
• [4.107 seconds]
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:100
  STEP: Creating a kubernetes client @ 01/15/25 02:03:06.899
  I0115 02:03:06.899440 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename configmap @ 01/15/25 02:03:06.9
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:03:06.914
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:03:06.919
  STEP: Creating configMap with name configmap-test-volume-map-606e5d42-b373-43c9-bebb-04d012af16f3 @ 01/15/25 02:03:06.924
  STEP: Creating a pod to test consume configMaps @ 01/15/25 02:03:06.931
  E0115 02:03:07.312452      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:03:08.313686      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:03:09.315316      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:03:10.315540      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 02:03:10.974
  I0115 02:03:10.987490 24 output.go:207] Trying to get logs from node 192.168.18.92 pod pod-configmaps-81c5d79a-ae4f-4809-b3d2-a5f6721d14b3 container agnhost-container: <nil>
  STEP: delete the pod @ 01/15/25 02:03:11.016
  I0115 02:03:11.046876 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-3139" for this suite. @ 01/15/25 02:03:11.054
• [4.168 seconds]
------------------------------
[sig-api-machinery] FieldValidation should detect unknown and duplicate fields of a typed object [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:62
  STEP: Creating a kubernetes client @ 01/15/25 02:03:11.067
  I0115 02:03:11.067865 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename field-validation @ 01/15/25 02:03:11.069
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:03:11.112
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:03:11.118
  STEP: apply creating a deployment @ 01/15/25 02:03:11.125
  I0115 02:03:11.148384 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-7763" for this suite. @ 01/15/25 02:03:11.154
• [0.094 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should patch a pod status [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:1084
  STEP: Creating a kubernetes client @ 01/15/25 02:03:11.166
  I0115 02:03:11.166874 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename pods @ 01/15/25 02:03:11.171
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:03:11.2
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:03:11.206
  STEP: Create a pod @ 01/15/25 02:03:11.213
  E0115 02:03:11.316101      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:03:12.321743      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:03:13.324536      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:03:14.325912      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: patching /status @ 01/15/25 02:03:15.261
  I0115 02:03:15.306850 24 pods.go:1124] Status Message: "Patched by e2e test" and Reason: "E2E"
  I0115 02:03:15.308298 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  E0115 02:03:15.327412      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Destroying namespace "pods-8111" for this suite. @ 01/15/25 02:03:15.327
• [4.177 seconds]
------------------------------
SSS
------------------------------
[sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:167
  STEP: Creating a kubernetes client @ 01/15/25 02:03:15.343
  I0115 02:03:15.343996 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename disruption @ 01/15/25 02:03:15.345
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:03:15.4
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:03:15.42
  STEP: Waiting for the pdb to be processed @ 01/15/25 02:03:15.435
  STEP: Updating PodDisruptionBudget status @ 01/15/25 02:03:15.44
  STEP: Waiting for all pods to be running @ 01/15/25 02:03:15.452
  I0115 02:03:15.462683 24 disruption.go:691] running pods: 0 < 1
  E0115 02:03:16.327501      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:03:17.328810      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: locating a running pod @ 01/15/25 02:03:17.464
  STEP: Waiting for the pdb to be processed @ 01/15/25 02:03:17.514
  STEP: Patching PodDisruptionBudget status @ 01/15/25 02:03:17.548
  STEP: Waiting for the pdb to be processed @ 01/15/25 02:03:17.602
  I0115 02:03:17.610770 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-1347" for this suite. @ 01/15/25 02:03:17.625
• [2.295 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:277
  STEP: Creating a kubernetes client @ 01/15/25 02:03:17.639
  I0115 02:03:17.640349 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename crd-publish-openapi @ 01/15/25 02:03:17.645
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:03:17.667
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:03:17.672
  STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation @ 01/15/25 02:03:17.679
  I0115 02:03:17.680025 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  E0115 02:03:18.341955      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:03:19.217427 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  E0115 02:03:19.342135      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:03:20.342482      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:03:21.348175      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:03:22.349148      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:03:23.349453      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:03:24.351419      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:03:25.352749      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:03:26.353958      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:03:27.354033      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:03:27.492193 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-7177" for this suite. @ 01/15/25 02:03:27.518
• [9.891 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance] [sig-architecture, Conformance]
k8s.io/kubernetes/test/e2e/architecture/conformance.go:39
  STEP: Creating a kubernetes client @ 01/15/25 02:03:27.531
  I0115 02:03:27.531981 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename conformance-tests @ 01/15/25 02:03:27.533
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:03:27.564
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:03:27.572
  STEP: Getting node addresses @ 01/15/25 02:03:27.581
  I0115 02:03:27.582034 24 helper.go:51] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  I0115 02:03:27.620705 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "conformance-tests-4001" for this suite. @ 01/15/25 02:03:27.63
• [0.116 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/podtemplates.go:54
  STEP: Creating a kubernetes client @ 01/15/25 02:03:27.648
  I0115 02:03:27.648324 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename podtemplate @ 01/15/25 02:03:27.65
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:03:27.686
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:03:27.695
  I0115 02:03:27.767135 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-7036" for this suite. @ 01/15/25 02:03:27.778
• [0.144 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:113
  STEP: Creating a kubernetes client @ 01/15/25 02:03:27.793
  I0115 02:03:27.793230 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename deployment @ 01/15/25 02:03:27.796
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:03:27.846
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:03:27.862
  I0115 02:03:27.874747 24 deployment.go:792] Creating deployment "test-recreate-deployment"
  I0115 02:03:27.893168 24 deployment.go:798] Waiting deployment "test-recreate-deployment" to be updated to revision 1
  I0115 02:03:27.908317 24 deployment.go:223] deployment "test-recreate-deployment" doesn't have the required revision set
  E0115 02:03:28.354245      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:03:29.354987      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:03:29.935431 24 deployment.go:802] Waiting deployment "test-recreate-deployment" to complete
  I0115 02:03:29.950390 24 deployment.go:807] Triggering a new rollout for deployment "test-recreate-deployment"
  I0115 02:03:29.999097 24 deployment.go:314] Updating deployment test-recreate-deployment
  I0115 02:03:29.999439 24 deployment.go:814] Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
  I0115 02:03:30.118883 24 deployment.go:633] Deployment "test-recreate-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-recreate-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4796",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "73c20797-ad9e-48ff-85d5-fe439aeac563",
      ResourceVersion: (string) (len=6) "168771",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872503407,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872503409,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=570) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |":{"f:type":{}},|
              000000b0  22 66 3a 74 65 6d 70 6c  61 74 65 22 3a 7b 22 66  |"f:template":{"f|
              000000c0  3a 6d 65 74 61 64 61 74  61 22 3a 7b 22 66 3a 6c  |:metadata":{"f:l|
              000000d0  61 62 65 6c 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |abels":{".":{},"|
              000000e0  66 3a 6e 61 6d 65 22 3a  7b 7d 7d 7d 2c 22 66 3a  |f:name":{}}},"f:|
              000000f0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              00000100  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              00000110  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              00000120  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              00000130  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000140  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000150  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000160  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 73 65 63 75  |rces":{},"f:secu|
              00000170  72 69 74 79 43 6f 6e 74  65 78 74 22 3a 7b 7d 2c  |rityContext":{},|
              00000180  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000190  73 73 61 67 65 50 61 74  68 22 3a 7b 7d 2c 22 66  |ssagePath":{},"f|
              000001a0  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 4d 65 73 73  |:terminationMess|
              000001b0  61 67 65 50 6f 6c 69 63  79 22 3a 7b 7d 7d 7d 2c  |agePolicy":{}}},|
              000001c0  22 66 3a 64 6e 73 50 6f  6c 69 63 79 22 3a 7b 7d  |"f:dnsPolicy":{}|
              000001d0  2c 22 66 3a 72 65 73 74  61 72 74 50 6f 6c 69 63  |,"f:restartPolic|
              000001e0  79 22 3a 7b 7d 2c 22 66  3a 73 63 68 65 64 75 6c  |y":{},"f:schedul|
              000001f0  65 72 4e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 73 65  |erName":{},"f:se|
              00000200  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000210  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000220  47 72 61 63 65 50 65 72  69 6f 64 53 65 63 6f 6e  |GracePeriodSecon|
              00000230  64 73 22 3a 7b 7d 7d 7d  7d 7d                    |ds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872503410,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=495) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 63 6f 6e 64 69 74 69  6f 6e 73 22 3a 7b 22 2e  |:conditions":{".|
              00000070  22 3a 7b 7d 2c 22 6b 3a  7b 5c 22 74 79 70 65 5c  |":{},"k:{\"type\|
              00000080  22 3a 5c 22 41 76 61 69  6c 61 62 6c 65 5c 22 7d  |":\"Available\"}|
              00000090  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |":{".":{},"f:las|
              000000a0  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              000000b0  3a 7b 7d 2c 22 66 3a 6c  61 73 74 55 70 64 61 74  |:{},"f:lastUpdat|
              000000c0  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6d 65 73  |eTime":{},"f:mes|
              000000d0  73 61 67 65 22 3a 7b 7d  2c 22 66 3a 72 65 61 73  |sage":{},"f:reas|
              000000e0  6f 6e 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |on":{},"f:status|
              000000f0  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000100  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000110  22 50 72 6f 67 72 65 73  73 69 6e 67 5c 22 7d 22  |"Progressing\"}"|
              00000120  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              00000130  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000140  7b 7d 2c 22 66 3a 6c 61  73 74 55 70 64 61 74 65  |{},"f:lastUpdate|
              00000150  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6d 65 73 73  |Time":{},"f:mess|
              00000160  61 67 65 22 3a 7b 7d 2c  22 66 3a 72 65 61 73 6f  |age":{},"f:reaso|
              00000170  6e 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |n":{},"f:status"|
              00000180  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000190  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              000001a0  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              000001b0  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 75  |eplicas":{},"f:u|
              000001c0  6e 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |navailableReplic|
              000001d0  61 73 22 3a 7b 7d 2c 22  66 3a 75 70 64 61 74 65  |as":{},"f:update|
              000001e0  64 52 65 70 6c 69 63 61  73 22 3a 7b 7d 7d 7d     |dReplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=8) "Recreate",
        RollingUpdate: (*v1.RollingUpdateDeployment)(<nil>)
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      UnavailableReplicas: (int32) 1,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872503410,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872503410,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=26) "MinimumReplicasUnavailable",
          Message: (string) (len=46) "Deployment does not have minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872503410,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872503407,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=17) "ReplicaSetUpdated",
          Message: (string) (len=64) "ReplicaSet \"test-recreate-deployment-59cddbdd4b\" is progressing."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0115 02:03:30.146361 24 deployment.go:40] New ReplicaSet "test-recreate-deployment-59cddbdd4b" of Deployment "test-recreate-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-recreate-deployment-59cddbdd4b",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4796",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "419a4628-a26e-44d5-ae69-e9b37e056ad2",
      ResourceVersion: (string) (len=6) "168768",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872503410,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=10) "59cddbdd4b"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "1",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-recreate-deployment",
          UID: (types.UID) (len=36) "73c20797-ad9e-48ff-85d5-fe439aeac563",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872503410,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 37 33 63 32 30 37  39 37 2d 61 64 39 65 2d  |\"73c20797-ad9e-|
              00000120  34 38 66 66 2d 38 35 64  35 2d 66 65 34 33 39 61  |48ff-85d5-fe439a|
              00000130  65 61 63 35 36 33 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |eac563\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872503410,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=84) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  66 75 6c 6c 79 4c 61 62  65 6c 65 64 52 65 70 6c  |fullyLabeledRepl|
              00000020  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 6f 62 73 65  |icas":{},"f:obse|
              00000030  72 76 65 64 47 65 6e 65  72 61 74 69 6f 6e 22 3a  |rvedGeneration":|
              00000040  7b 7d 2c 22 66 3a 72 65  70 6c 69 63 61 73 22 3a  |{},"f:replicas":|
              00000050  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3",
          (string) (len=17) "pod-template-hash": (string) (len=10) "59cddbdd4b"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3",
            (string) (len=17) "pod-template-hash": (string) (len=10) "59cddbdd4b"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0115 02:03:30.148488 24 deployment.go:45] All old ReplicaSets of Deployment "test-recreate-deployment":
  I0115 02:03:30.150189 24 deployment.go:48] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=34) "test-recreate-deployment-db85869db",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4796",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "891d23cb-e5ac-4af2-87cb-0c97ff9ce095",
      ResourceVersion: (string) (len=6) "168758",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872503407,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=9) "db85869db"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "1",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-recreate-deployment",
          UID: (types.UID) (len=36) "73c20797-ad9e-48ff-85d5-fe439aeac563",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872503409,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 37 33 63 32 30 37  39 37 2d 61 64 39 65 2d  |\"73c20797-ad9e-|
              00000120  34 38 66 66 2d 38 35 64  35 2d 66 65 34 33 39 61  |48ff-85d5-fe439a|
              00000130  65 61 63 35 36 33 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |eac563\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872503410,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3",
          (string) (len=17) "pod-template-hash": (string) (len=9) "db85869db"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3",
            (string) (len=17) "pod-template-hash": (string) (len=9) "db85869db"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.53",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0115 02:03:30.162674 24 deployment.go:68] Pod "test-recreate-deployment-59cddbdd4b-k7pgd" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=41) "test-recreate-deployment-59cddbdd4b-k7pgd",
      GenerateName: (string) (len=36) "test-recreate-deployment-59cddbdd4b-",
      Namespace: (string) (len=15) "deployment-4796",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "24ba6e74-00e0-43a9-8846-9f34584bee59",
      ResourceVersion: (string) (len=6) "168770",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872503410,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=10) "59cddbdd4b"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=35) "test-recreate-deployment-59cddbdd4b",
          UID: (types.UID) (len=36) "419a4628-a26e-44d5-ae69-e9b37e056ad2",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872503410,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 31  39 61 34 36 32 38 2d 61  |d\":\"419a4628-a|
              00000090  32 36 65 2d 34 34 64 35  2d 61 65 36 39 2d 65 39  |26e-44d5-ae69-e9|
              000000a0  62 33 37 65 30 35 36 61  64 32 5c 22 7d 22 3a 7b  |b37e056ad2\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872503410,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-vzpq2",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-vzpq2",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=13) "192.168.18.92",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872503410,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872503410,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872503410,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872503410,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872503410,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "192.168.18.92",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "192.168.18.92"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872503410,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-vzpq2",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0115 02:03:30.168008 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-4796" for this suite. @ 01/15/25 02:03:30.181
• [2.408 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:91
  STEP: Creating a kubernetes client @ 01/15/25 02:03:30.201
  I0115 02:03:30.201952 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename subpath @ 01/15/25 02:03:30.205
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:03:30.243
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:03:30.296
  STEP: Setting up data @ 01/15/25 02:03:30.324
  E0115 02:03:30.355085      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Creating pod pod-subpath-test-downwardapi-6hzh @ 01/15/25 02:03:30.38
  STEP: Creating a pod to test atomic-volume-subpath @ 01/15/25 02:03:30.38
  E0115 02:03:31.356111      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:03:32.356877      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:03:33.357205      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:03:34.357890      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:03:35.358713      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:03:36.360011      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:03:37.360747      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:03:38.361320      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:03:39.362908      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:03:40.363141      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:03:41.363867      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:03:42.364507      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:03:43.365135      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:03:44.366356      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:03:45.367378      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:03:46.368999      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:03:47.370599      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:03:48.371871      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:03:49.372889      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:03:50.373762      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:03:51.374599      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:03:52.375763      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:03:53.376598      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:03:54.377004      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 02:03:54.552
  I0115 02:03:54.560359 24 output.go:207] Trying to get logs from node 192.168.18.92 pod pod-subpath-test-downwardapi-6hzh container test-container-subpath-downwardapi-6hzh: <nil>
  STEP: delete the pod @ 01/15/25 02:03:54.572
  STEP: Deleting pod pod-subpath-test-downwardapi-6hzh @ 01/15/25 02:03:54.584
  I0115 02:03:54.584649 24 delete.go:62] Deleting pod "pod-subpath-test-downwardapi-6hzh" in namespace "subpath-9609"
  I0115 02:03:54.588150 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-9609" for this suite. @ 01/15/25 02:03:54.592
• [24.398 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:215
  STEP: Creating a kubernetes client @ 01/15/25 02:03:54.599
  I0115 02:03:54.599944 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename projected @ 01/15/25 02:03:54.6
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:03:54.615
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:03:54.62
  STEP: Creating secret with name s-test-opt-del-fe14deb2-3ef2-4fd9-9972-e9f3f36e374c @ 01/15/25 02:03:54.699
  STEP: Creating secret with name s-test-opt-upd-469df28a-4b71-49a3-b96d-fe53cf9ac515 @ 01/15/25 02:03:54.719
  STEP: Creating the pod @ 01/15/25 02:03:54.743
  E0115 02:03:55.378527      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:03:56.378832      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:03:57.381404      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:03:58.382588      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Deleting secret s-test-opt-del-fe14deb2-3ef2-4fd9-9972-e9f3f36e374c @ 01/15/25 02:03:58.822
  STEP: Updating secret s-test-opt-upd-469df28a-4b71-49a3-b96d-fe53cf9ac515 @ 01/15/25 02:03:58.826
  STEP: Creating secret with name s-test-opt-create-a8ed35a1-c868-4fcd-9721-bc4c33a26220 @ 01/15/25 02:03:58.83
  STEP: waiting to observe update in volume @ 01/15/25 02:03:58.834
  E0115 02:03:59.384669      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:00.385058      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:01.385876      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:02.387590      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:03.386212      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:04.387255      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:05.387884      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:06.388888      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:07.388909      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:08.390618      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:09.391029      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:10.391748      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:11.393774      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:12.394540      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:13.396197      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:14.396844      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:15.400047      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:16.399170      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:17.399203      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:18.401184      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:19.401909      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:20.402864      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:21.403041      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:22.405112      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:23.405353      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:24.406560      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:25.406781      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:26.407000      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:27.407305      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:28.409867      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:29.410328      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:30.411979      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:31.412233      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:32.413303      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:33.413363      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:34.415357      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:35.415389      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:36.415954      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:37.417367      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:38.418256      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:39.420202      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:40.420445      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:41.420643      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:42.421086      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:43.422442      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:44.423804      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:45.425515      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:46.426276      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:47.427456      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:48.429165      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:49.430039      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:50.430742      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:51.431525      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:52.432813      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:53.433281      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:54.434051      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:55.436129      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:56.436446      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:57.437546      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:58.437992      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:04:59.438200      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:05:00.440577      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:05:01.441189      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:05:02.444751      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:05:03.444286      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:05:03.467579 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9661" for this suite. @ 01/15/25 02:05:03.473
• [68.880 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:619
  STEP: Creating a kubernetes client @ 01/15/25 02:05:03.48
  I0115 02:05:03.480073 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename pods @ 01/15/25 02:05:03.48
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:05:03.494
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:05:03.499
  I0115 02:05:03.504147 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: creating the pod @ 01/15/25 02:05:03.504
  STEP: submitting the pod to kubernetes @ 01/15/25 02:05:03.504
  E0115 02:05:04.444626      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:05:05.445744      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:05:05.539239 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-6367" for this suite. @ 01/15/25 02:05:05.546
• [2.073 seconds]
------------------------------
SS
------------------------------
[sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1513
  STEP: Creating a kubernetes client @ 01/15/25 02:05:05.553
  I0115 02:05:05.553326 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename services @ 01/15/25 02:05:05.554
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:05:05.568
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:05:05.572
  STEP: creating a service nodeport-service with the type=NodePort in namespace services-5558 @ 01/15/25 02:05:05.578
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 01/15/25 02:05:05.59
  STEP: creating service externalsvc in namespace services-5558 @ 01/15/25 02:05:05.591
  STEP: creating replication controller externalsvc in namespace services-5558 @ 01/15/25 02:05:05.61
  I0115 02:05:05.620034      24 runners.go:193] Created replication controller with name: externalsvc, namespace: services-5558, replica count: 2
  E0115 02:05:06.445960      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:05:07.448277      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:05:08.448924      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:05:08.672177      24 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  STEP: changing the NodePort service to type=ExternalName @ 01/15/25 02:05:08.679
  I0115 02:05:08.721800 24 resource.go:361] Creating new exec pod
  E0115 02:05:09.448850      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:05:10.449111      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:05:10.766262 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-5558 exec execpodbmch9 -- /bin/sh -x -c nslookup nodeport-service.services-5558.svc.cluster.local'
  I0115 02:05:11.043151 24 builder.go:146] stderr: "+ nslookup nodeport-service.services-5558.svc.cluster.local\n"
  I0115 02:05:11.043276 24 builder.go:147] stdout: "Server:\t\t169.169.0.10\nAddress:\t169.169.0.10#53\n\nnodeport-service.services-5558.svc.cluster.local\tcanonical name = externalsvc.services-5558.svc.cluster.local.\nName:\texternalsvc.services-5558.svc.cluster.local\nAddress: 169.169.130.215\n\n"
  STEP: deleting ReplicationController externalsvc in namespace services-5558, will wait for the garbage collector to delete the pods @ 01/15/25 02:05:11.043
  I0115 02:05:11.126054 24 resources.go:139] Deleting ReplicationController externalsvc took: 27.802263ms
  I0115 02:05:11.226616 24 resources.go:163] Terminating ReplicationController externalsvc pods took: 100.572649ms
  E0115 02:05:11.449388      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:05:12.450760      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:05:13.452297      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:05:14.454177      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:05:14.542681 24 service.go:1524] Cleaning up the NodePort to ExternalName test service
  I0115 02:05:14.557462 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-5558" for this suite. @ 01/15/25 02:05:14.563
• [9.017 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:940
  STEP: Creating a kubernetes client @ 01/15/25 02:05:14.57
  I0115 02:05:14.570756 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename resourcequota @ 01/15/25 02:05:14.571
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:05:14.587
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:05:14.594
  STEP: Creating a ResourceQuota @ 01/15/25 02:05:14.599
  STEP: Getting a ResourceQuota @ 01/15/25 02:05:14.605
  STEP: Updating a ResourceQuota @ 01/15/25 02:05:14.609
  STEP: Verifying a ResourceQuota was modified @ 01/15/25 02:05:14.616
  STEP: Deleting a ResourceQuota @ 01/15/25 02:05:14.621
  STEP: Verifying the deleted ResourceQuota @ 01/15/25 02:05:14.629
  I0115 02:05:14.633391 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-1249" for this suite. @ 01/15/25 02:05:14.67
• [0.119 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:258
  STEP: Creating a kubernetes client @ 01/15/25 02:05:14.69
  I0115 02:05:14.690125 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename webhook @ 01/15/25 02:05:14.69
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:05:14.714
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:05:14.72
  STEP: Setting up server cert @ 01/15/25 02:05:14.808
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 01/15/25 02:05:15.364
  STEP: Deploying the webhook pod @ 01/15/25 02:05:15.372
  STEP: Wait for the deployment to be ready @ 01/15/25 02:05:15.384
  I0115 02:05:15.390601 24 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0115 02:05:15.455881      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:05:16.456528      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 01/15/25 02:05:17.401
  STEP: Verifying the service has paired with the endpoint @ 01/15/25 02:05:17.41
  E0115 02:05:17.457340      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:05:18.412734 24 util.go:423] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the mutating pod webhook via the AdmissionRegistration API @ 01/15/25 02:05:18.437
  E0115 02:05:18.458950      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: create a pod that should be updated by the webhook @ 01/15/25 02:05:18.505
  I0115 02:05:18.638340 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-1128" for this suite. @ 01/15/25 02:05:18.65
  STEP: Destroying namespace "webhook-markers-5657" for this suite. @ 01/15/25 02:05:18.657
• [3.974 seconds]
------------------------------
SSS
------------------------------
[sig-apps] ReplicaSet should serve a basic image on each replica with a public image [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:112
  STEP: Creating a kubernetes client @ 01/15/25 02:05:18.663
  I0115 02:05:18.664026 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename replicaset @ 01/15/25 02:05:18.665
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:05:18.691
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:05:18.696
  I0115 02:05:18.703909 24 replica_set.go:191] Creating ReplicaSet my-hostname-basic-7c47da01-6576-4bca-8b32-a1c28e3eff75
  I0115 02:05:18.712953 24 resource.go:87] Pod name my-hostname-basic-7c47da01-6576-4bca-8b32-a1c28e3eff75: Found 0 pods out of 1
  E0115 02:05:19.459668      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:05:20.463693      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:05:21.464938      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:05:22.465249      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:05:23.466802      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:05:23.717336 24 resource.go:87] Pod name my-hostname-basic-7c47da01-6576-4bca-8b32-a1c28e3eff75: Found 1 pods out of 1
  I0115 02:05:23.717422 24 replica_set.go:204] Ensuring a pod for ReplicaSet "my-hostname-basic-7c47da01-6576-4bca-8b32-a1c28e3eff75" is running
  I0115 02:05:23.721140 24 replica_set.go:220] Pod "my-hostname-basic-7c47da01-6576-4bca-8b32-a1c28e3eff75-7p5dl" is running (conditions: [{Type:PodReadyToStartContainers Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2025-01-15 02:05:20 +0000 UTC Reason: Message:} {Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2025-01-15 02:05:18 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2025-01-15 02:05:20 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2025-01-15 02:05:20 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2025-01-15 02:05:18 +0000 UTC Reason: Message:}])
  I0115 02:05:23.721200 24 replica_set.go:228] Trying to dial the pod
  STEP: trying to dial each unique pod @ 01/15/25 02:05:23.721
  I0115 02:05:23.824958 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-3871" for this suite. @ 01/15/25 02:05:23.829
• [5.173 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:69
  STEP: Creating a kubernetes client @ 01/15/25 02:05:23.837
  I0115 02:05:23.837365 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename endpointslice @ 01/15/25 02:05:23.838
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:05:23.926
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:05:23.94
  I0115 02:05:23.979262 24 endpointslice.go:1045] Endpoints addresses: [192.168.18.91] , ports: [6443]
  I0115 02:05:23.979391 24 endpointslice.go:1075] EndpointSlices addresses: [192.168.18.91] , ports: [6443]
  I0115 02:05:23.979590 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-333" for this suite. @ 01/15/25 02:05:23.985
• [0.154 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should allow to use a pod failure policy to ignore failure matching on DisruptionTarget condition [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:199
  STEP: Creating a kubernetes client @ 01/15/25 02:05:23.992
  I0115 02:05:23.992243 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename job @ 01/15/25 02:05:23.993
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:05:24.01
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:05:24.015
  STEP: Looking for a node to schedule job pods @ 01/15/25 02:05:24.02
  STEP: Creating a job @ 01/15/25 02:05:24.095
  STEP: Waiting for all the pods to be ready @ 01/15/25 02:05:24.118
  E0115 02:05:24.467650      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:05:25.468274      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:05:26.469626      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:05:27.470765      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Fetch all running pods @ 01/15/25 02:05:28.152
  STEP: Evict all the Pods @ 01/15/25 02:05:28.16
  STEP: Evicting the running pod: evicted-pod-ignore-on-disruption-condition-0-ltt2l/job-995 @ 01/15/25 02:05:28.16
  STEP: Evicting the running pod: evicted-pod-ignore-on-disruption-condition-1-djfb6/job-995 @ 01/15/25 02:05:28.16
  STEP: Evicting the running pod: evicted-pod-ignore-on-disruption-condition-2-z7hh4/job-995 @ 01/15/25 02:05:28.16
  STEP: Awaiting for the pod: evicted-pod-ignore-on-disruption-condition-1-djfb6/job-995 to be deleted @ 01/15/25 02:05:28.184
  STEP: Awaiting for the pod: evicted-pod-ignore-on-disruption-condition-0-ltt2l/job-995 to be deleted @ 01/15/25 02:05:28.193
  STEP: Awaiting for the pod: evicted-pod-ignore-on-disruption-condition-2-z7hh4/job-995 to be deleted @ 01/15/25 02:05:28.199
  E0115 02:05:28.471184      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:05:29.471843      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:05:30.476823      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:05:31.472621      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Ensuring job reaches completions @ 01/15/25 02:05:32.223
  E0115 02:05:32.474185      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:05:33.475421      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:05:34.477298      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:05:35.478001      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:05:36.479222      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:05:37.480203      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:05:38.480563      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:05:39.481837      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:05:40.482727      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:05:41.483573      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:05:42.485274      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:05:43.486200      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:05:44.486893      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:05:45.488730      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:05:46.489665      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:05:47.490916      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:05:48.491762      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:05:49.491974      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:05:50.492363      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:05:51.493200      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:05:52.493284      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:05:53.493958      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:05:54.494449      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:05:55.494665      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:05:56.495829      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:05:57.496858      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:05:58.497058      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:05:59.498744      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:06:00.499915      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:06:01.501091      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:06:02.502876      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:06:03.504797      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:06:04.505920      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:06:05.505988      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:06:06.506672      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:06:07.507414      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:06:08.509181      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:06:09.510387      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:06:10.511049      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:06:11.511741      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:06:12.512905      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:06:13.513651      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:06:14.392864 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-995" for this suite. @ 01/15/25 02:06:14.399
• [50.414 seconds]
------------------------------
S
------------------------------
[sig-cli] Kubectl client Proxy server should support --unix-socket=/path [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1855
  STEP: Creating a kubernetes client @ 01/15/25 02:06:14.406
  I0115 02:06:14.406063 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename kubectl @ 01/15/25 02:06:14.407
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:06:14.425
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:06:14.429
  STEP: Starting the proxy @ 01/15/25 02:06:14.435
  I0115 02:06:14.435385 24 util.go:590] Asynchronously running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-2859 proxy --unix-socket=/tmp/kubectl-proxy-unix3915428334/test'
  STEP: retrieving proxy /api/ output @ 01/15/25 02:06:14.491
  I0115 02:06:14.492547 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-2859" for this suite. @ 01/15/25 02:06:14.499
• [0.099 seconds]
------------------------------
[sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:897
  STEP: Creating a kubernetes client @ 01/15/25 02:06:14.505
  I0115 02:06:14.505344 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename pods @ 01/15/25 02:06:14.506
  E0115 02:06:14.514795      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:06:14.53
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:06:14.536
  STEP: creating a Pod with a static label @ 01/15/25 02:06:14.545
  STEP: watching for Pod to be ready @ 01/15/25 02:06:14.553
  I0115 02:06:14.556472 24 pods.go:945] observed Pod pod-test in namespace pods-1112 in phase Pending with labels: map[test-pod-static:true] & conditions []
  I0115 02:06:14.561167 24 pods.go:945] observed Pod pod-test in namespace pods-1112 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2025-01-15 02:06:14 +0000 UTC  }]
  I0115 02:06:14.576141 24 pods.go:945] observed Pod pod-test in namespace pods-1112 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodReadyToStartContainers False 0001-01-01 00:00:00 +0000 UTC 2025-01-15 02:06:14 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2025-01-15 02:06:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2025-01-15 02:06:14 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2025-01-15 02:06:14 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2025-01-15 02:06:14 +0000 UTC  }]
  I0115 02:06:15.082847 24 pods.go:945] observed Pod pod-test in namespace pods-1112 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodReadyToStartContainers False 0001-01-01 00:00:00 +0000 UTC 2025-01-15 02:06:14 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2025-01-15 02:06:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2025-01-15 02:06:14 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2025-01-15 02:06:14 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2025-01-15 02:06:14 +0000 UTC  }]
  E0115 02:06:15.515091      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:06:15.675991 24 pods.go:948] Found Pod pod-test in namespace pods-1112 in phase Running with labels: map[test-pod-static:true] & conditions [{PodReadyToStartContainers True 0001-01-01 00:00:00 +0000 UTC 2025-01-15 02:06:15 +0000 UTC  } {Initialized True 0001-01-01 00:00:00 +0000 UTC 2025-01-15 02:06:14 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2025-01-15 02:06:15 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2025-01-15 02:06:15 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2025-01-15 02:06:14 +0000 UTC  }]
  STEP: patching the Pod with a new Label and updated data @ 01/15/25 02:06:15.688
  STEP: getting the Pod and ensuring that it's patched @ 01/15/25 02:06:15.706
  STEP: replacing the Pod's status Ready condition to False @ 01/15/25 02:06:15.71
  STEP: check the Pod again to ensure its Ready conditions are False @ 01/15/25 02:06:15.725
  STEP: deleting the Pod via a Collection with a LabelSelector @ 01/15/25 02:06:15.725
  STEP: watching for the Pod to be deleted @ 01/15/25 02:06:15.737
  I0115 02:06:15.740710 24 pods.go:1058] observed event type MODIFIED
  E0115 02:06:16.515333      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:06:17.515703      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:06:17.680931 24 pods.go:1058] observed event type MODIFIED
  I0115 02:06:17.841768 24 pods.go:1058] observed event type MODIFIED
  I0115 02:06:17.958149 24 pods.go:1058] observed event type MODIFIED
  E0115 02:06:18.516385      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:06:18.719388 24 pods.go:1058] observed event type MODIFIED
  I0115 02:06:18.726513 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-1112" for this suite. @ 01/15/25 02:06:18.731
• [4.233 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslicemirroring.go:55
  STEP: Creating a kubernetes client @ 01/15/25 02:06:18.738
  I0115 02:06:18.738256 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename endpointslicemirroring @ 01/15/25 02:06:18.739
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:06:18.755
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:06:18.761
  STEP: mirroring a new custom Endpoint @ 01/15/25 02:06:18.776
  I0115 02:06:18.786478 24 endpointslicemirroring.go:96] Waiting for at least 1 EndpointSlice to exist, got 0
  E0115 02:06:19.518618      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:06:20.519786      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: mirroring an update to a custom Endpoint @ 01/15/25 02:06:20.8
  STEP: mirroring deletion of a custom Endpoint @ 01/15/25 02:06:20.835
  I0115 02:06:20.873870 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslicemirroring-3386" for this suite. @ 01/15/25 02:06:20.88
• [2.152 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:177
  STEP: Creating a kubernetes client @ 01/15/25 02:06:20.89
  I0115 02:06:20.890979 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename replicaset @ 01/15/25 02:06:20.892
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:06:20.913
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:06:20.92
  STEP: Create a Replicaset @ 01/15/25 02:06:20.928
  STEP: Verify that the required pods have come up. @ 01/15/25 02:06:20.934
  I0115 02:06:20.941852 24 resource.go:87] Pod name sample-pod: Found 0 pods out of 1
  E0115 02:06:21.519957      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:06:22.520609      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:06:23.521075      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:06:24.522054      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:06:25.523796      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:06:25.957049 24 resource.go:87] Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 01/15/25 02:06:25.957
  STEP: Getting /status @ 01/15/25 02:06:25.957
  I0115 02:06:25.972966 24 replica_set.go:643] Replicaset test-rs has Conditions: []
  STEP: updating the Replicaset Status @ 01/15/25 02:06:25.973
  I0115 02:06:25.991506 24 replica_set.go:663] updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the ReplicaSet status to be updated @ 01/15/25 02:06:25.991
  I0115 02:06:25.995389 24 replica_set.go:689] Observed &ReplicaSet event: ADDED
  I0115 02:06:25.995631 24 replica_set.go:689] Observed &ReplicaSet event: MODIFIED
  I0115 02:06:25.995847 24 replica_set.go:689] Observed &ReplicaSet event: MODIFIED
  I0115 02:06:25.996290 24 replica_set.go:689] Observed &ReplicaSet event: MODIFIED
  I0115 02:06:25.996343 24 replica_set.go:682] Found replicaset test-rs in namespace replicaset-3844 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  I0115 02:06:25.996360 24 replica_set.go:693] Replicaset test-rs has an updated status
  STEP: patching the Replicaset Status @ 01/15/25 02:06:25.996
  I0115 02:06:25.996399 24 replica_set.go:697] Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  I0115 02:06:26.003509 24 replica_set.go:701] Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Replicaset status to be patched @ 01/15/25 02:06:26.003
  I0115 02:06:26.006969 24 replica_set.go:725] Observed &ReplicaSet event: ADDED
  I0115 02:06:26.007207 24 replica_set.go:725] Observed &ReplicaSet event: MODIFIED
  I0115 02:06:26.007336 24 replica_set.go:725] Observed &ReplicaSet event: MODIFIED
  I0115 02:06:26.007966 24 replica_set.go:725] Observed &ReplicaSet event: MODIFIED
  I0115 02:06:26.008022 24 replica_set.go:721] Observed replicaset test-rs in namespace replicaset-3844 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0115 02:06:26.008156 24 replica_set.go:725] Observed &ReplicaSet event: MODIFIED
  I0115 02:06:26.008248 24 replica_set.go:718] Found replicaset test-rs in namespace replicaset-3844 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
  I0115 02:06:26.008280 24 replica_set.go:729] Replicaset test-rs has a patched status
  I0115 02:06:26.008414 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-3844" for this suite. @ 01/15/25 02:06:26.013
• [5.130 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:859
  STEP: Creating a kubernetes client @ 01/15/25 02:06:26.02
  I0115 02:06:26.020953 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename resourcequota @ 01/15/25 02:06:26.022
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:06:26.035
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:06:26.04
  STEP: Creating a ResourceQuota with best effort scope @ 01/15/25 02:06:26.045
  STEP: Ensuring ResourceQuota status is calculated @ 01/15/25 02:06:26.05
  E0115 02:06:26.523896      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:06:27.524715      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota with not best effort scope @ 01/15/25 02:06:28.054
  STEP: Ensuring ResourceQuota status is calculated @ 01/15/25 02:06:28.059
  E0115 02:06:28.525014      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:06:29.525489      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Creating a best-effort pod @ 01/15/25 02:06:30.064
  STEP: Ensuring resource quota with best effort scope captures the pod usage @ 01/15/25 02:06:30.079
  E0115 02:06:30.525749      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:06:31.526662      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with not best effort ignored the pod usage @ 01/15/25 02:06:32.096
  E0115 02:06:32.527506      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:06:33.531490      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 01/15/25 02:06:34.101
  STEP: Ensuring resource quota status released the pod usage @ 01/15/25 02:06:34.11
  E0115 02:06:34.532564      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:06:35.533772      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Creating a not best-effort pod @ 01/15/25 02:06:36.114
  STEP: Ensuring resource quota with not best effort scope captures the pod usage @ 01/15/25 02:06:36.129
  E0115 02:06:36.534069      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:06:37.537640      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with best effort scope ignored the pod usage @ 01/15/25 02:06:38.139
  E0115 02:06:38.539044      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:06:39.539958      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 01/15/25 02:06:40.144
  STEP: Ensuring resource quota status released the pod usage @ 01/15/25 02:06:40.155
  E0115 02:06:40.546081      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:06:41.546493      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:06:42.159471 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-470" for this suite. @ 01/15/25 02:06:42.163
• [16.149 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance] [sig-node, Serial, Disruptive, Conformance]
k8s.io/kubernetes/test/e2e/node/taints.go:444
  STEP: Creating a kubernetes client @ 01/15/25 02:06:42.17
  I0115 02:06:42.170386 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename taint-multiple-pods @ 01/15/25 02:06:42.171
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:06:42.188
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:06:42.193
  I0115 02:06:42.198483 24 wait.go:51] Waiting up to 1m0s for all nodes to be ready
  E0115 02:06:42.548304      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:06:43.549163      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:06:44.549962      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:06:45.551515      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:06:46.553467      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:06:47.554931      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:06:48.555202      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:06:49.556199      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:06:50.557447      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:06:51.559210      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:06:52.559357      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:06:53.559760      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:06:54.560476      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:06:55.560709      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:06:56.561094      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:06:57.561953      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:06:58.563811      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:06:59.566011      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:07:00.566114      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:07:01.566931      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:07:02.568066      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:07:03.570792      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:07:04.571844      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:07:05.572743      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:07:06.573588      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:07:07.573940      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:07:08.576407      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:07:09.576058      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:07:10.576793      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:07:11.577613      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:07:12.577818      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:07:13.578517      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:07:14.578695      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:07:15.579297      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:07:16.579944      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:07:17.581804      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:07:18.582932      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:07:19.583636      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:07:20.584778      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:07:21.585200      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:07:22.586011      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:07:23.586973      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:07:24.587262      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:07:25.588624      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:07:26.590583      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:07:27.591254      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:07:28.591725      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:07:29.592983      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:07:30.593793      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:07:31.594427      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:07:32.595140      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:07:33.596368      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:07:34.596893      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:07:35.598131      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:07:36.598970      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:07:37.599879      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:07:38.600227      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:07:39.601196      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:07:40.602745      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:07:41.603286      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:07:42.199685 24 util.go:396] Waiting for terminating namespaces to be deleted...
  I0115 02:07:42.206869 24 taints.go:144] Starting informer...
  STEP: Starting pods... @ 01/15/25 02:07:42.207
  I0115 02:07:42.429762 24 taints.go:463] Pod1 is running on 192.168.18.92. Tainting Node
  E0115 02:07:42.603650      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:07:43.604734      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:07:44.607748      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:07:44.695892 24 taints.go:471] Pod2 is running on 192.168.18.92. Tainting Node
  STEP: Trying to apply a taint on the Node @ 01/15/25 02:07:44.696
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 01/15/25 02:07:44.73
  STEP: Waiting for Pod1 and Pod2 to be deleted @ 01/15/25 02:07:44.74
  E0115 02:07:45.607897      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:07:46.608333      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:07:47.609186      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:07:48.610563      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:07:49.611418      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:07:50.462126 24 taints.go:492] Noticed Pod "taint-eviction-b1" gets evicted.
  E0115 02:07:50.612287      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:07:51.613059      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:07:52.613523      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:07:53.614508      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:07:54.615083      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:07:55.616412      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:07:56.617345      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:07:57.618207      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:07:58.619423      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:07:59.619950      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:08:00.620021      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:08:01.620442      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:08:02.621263      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:08:03.621915      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:08:04.622395      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:08:05.623309      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:08:06.623773      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:08:07.624057      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:08:08.624768      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:08:09.625804      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:08:10.502321 24 taints.go:492] Noticed Pod "taint-eviction-b2" gets evicted.
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 01/15/25 02:08:10.517
  I0115 02:08:10.522862 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "taint-multiple-pods-6257" for this suite. @ 01/15/25 02:08:10.529
• [88.366 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:263
  STEP: Creating a kubernetes client @ 01/15/25 02:08:10.537
  I0115 02:08:10.537125 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename projected @ 01/15/25 02:08:10.538
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:08:10.557
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:08:10.564
  STEP: Creating a pod to test downward API volume plugin @ 01/15/25 02:08:10.575
  E0115 02:08:10.627637      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:08:11.627688      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:08:12.628433      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:08:13.629915      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:08:14.632072      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 02:08:14.659
  I0115 02:08:14.674138 24 output.go:207] Trying to get logs from node 192.168.18.92 pod downwardapi-volume-ab9eb559-6f16-426d-b1d2-7fd4978a358d container client-container: <nil>
  STEP: delete the pod @ 01/15/25 02:08:14.688
  I0115 02:08:14.738571 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2863" for this suite. @ 01/15/25 02:08:14.746
• [4.215 seconds]
------------------------------
S
------------------------------
[sig-network] DNS should provide DNS for the cluster [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:54
  STEP: Creating a kubernetes client @ 01/15/25 02:08:14.752
  I0115 02:08:14.752529 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename dns @ 01/15/25 02:08:14.753
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:08:14.766
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:08:14.77
  STEP: Running these commands on agnhost: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/agnhost_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/agnhost_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 01/15/25 02:08:14.774
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 01/15/25 02:08:14.774
  STEP: creating a pod to probe DNS @ 01/15/25 02:08:14.774
  STEP: submitting the pod to kubernetes @ 01/15/25 02:08:14.774
  E0115 02:08:15.633684      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:08:16.634454      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 01/15/25 02:08:16.792
  STEP: looking for the results for each expected name from probers @ 01/15/25 02:08:16.797
  I0115 02:08:16.816289 24 dns_common.go:546] DNS probes using dns-100/dns-test-9149ff87-2fa4-4d3a-ba39-3effc2cbfdd3 succeeded

  STEP: deleting the pod @ 01/15/25 02:08:16.816
  I0115 02:08:16.830060 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-100" for this suite. @ 01/15/25 02:08:16.839
• [2.095 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Lease lease API should be available [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lease.go:73
  STEP: Creating a kubernetes client @ 01/15/25 02:08:16.847
  I0115 02:08:16.847922 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename lease-test @ 01/15/25 02:08:16.849
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:08:16.873
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:08:16.882
  I0115 02:08:16.943696 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "lease-test-8347" for this suite. @ 01/15/25 02:08:16.948
• [0.106 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply a CR with unknown fields for CRD with no validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:287
  STEP: Creating a kubernetes client @ 01/15/25 02:08:16.953
  I0115 02:08:16.953915 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename field-validation @ 01/15/25 02:08:16.955
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:08:16.969
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:08:16.973
  I0115 02:08:16.977991 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  E0115 02:08:17.636490      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:08:18.637462      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:08:19.638237      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:08:20.102191 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-3937" for this suite. @ 01/15/25 02:08:20.107
• [3.159 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:76
  STEP: Creating a kubernetes client @ 01/15/25 02:08:20.113
  I0115 02:08:20.113528 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename containers @ 01/15/25 02:08:20.114
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:08:20.128
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:08:20.133
  STEP: Creating a pod to test override command @ 01/15/25 02:08:20.138
  E0115 02:08:20.638778      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:08:21.640055      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:08:22.640740      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:08:23.641610      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 02:08:24.17
  I0115 02:08:24.184347 24 output.go:207] Trying to get logs from node 192.168.18.92 pod client-containers-2033614a-3f34-4c0e-925d-5ae1491ca53e container agnhost-container: <nil>
  STEP: delete the pod @ 01/15/25 02:08:24.211
  I0115 02:08:24.252972 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-6441" for this suite. @ 01/15/25 02:08:24.262
• [4.157 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:132
  STEP: Creating a kubernetes client @ 01/15/25 02:08:24.27
  I0115 02:08:24.270936 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename downward-api @ 01/15/25 02:08:24.273
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:08:24.289
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:08:24.295
  STEP: Creating the pod @ 01/15/25 02:08:24.3
  E0115 02:08:24.642632      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:08:25.642878      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:08:26.644088      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:08:26.845003 24 pod_client.go:173] Successfully updated pod "labelsupdateb88572a0-c023-481d-b597-f37b77bb5460"
  E0115 02:08:27.644811      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:08:28.645594      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:08:29.646124      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:08:30.647761      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:08:30.890380 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-9747" for this suite. @ 01/15/25 02:08:30.911
• [6.654 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:368
  STEP: Creating a kubernetes client @ 01/15/25 02:08:30.925
  I0115 02:08:30.925409 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename webhook @ 01/15/25 02:08:30.927
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:08:30.946
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:08:30.952
  STEP: Setting up server cert @ 01/15/25 02:08:31.082
  E0115 02:08:31.650571      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 01/15/25 02:08:31.724
  STEP: Deploying the webhook pod @ 01/15/25 02:08:31.732
  STEP: Wait for the deployment to be ready @ 01/15/25 02:08:31.741
  I0115 02:08:31.747410 24 deployment.go:223] new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E0115 02:08:32.651651      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:08:33.655555      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 01/15/25 02:08:33.758
  STEP: Verifying the service has paired with the endpoint @ 01/15/25 02:08:33.769
  E0115 02:08:34.656156      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:08:34.769988 24 util.go:423] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Setting timeout (1s) shorter than webhook latency (5s) @ 01/15/25 02:08:34.777
  STEP: Registering slow webhook via the AdmissionRegistration API @ 01/15/25 02:08:34.777
  STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) @ 01/15/25 02:08:34.795
  E0115 02:08:35.656945      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore @ 01/15/25 02:08:35.804
  STEP: Registering slow webhook via the AdmissionRegistration API @ 01/15/25 02:08:35.804
  E0115 02:08:36.657936      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is longer than webhook latency @ 01/15/25 02:08:36.868
  STEP: Registering slow webhook via the AdmissionRegistration API @ 01/15/25 02:08:36.869
  E0115 02:08:37.657775      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:08:38.658509      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:08:39.659148      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:08:40.659682      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:08:41.659566      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is empty (defaulted to 10s in v1) @ 01/15/25 02:08:41.944
  STEP: Registering slow webhook via the AdmissionRegistration API @ 01/15/25 02:08:41.944
  E0115 02:08:42.659658      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:08:43.660431      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:08:44.660849      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:08:45.660822      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:08:46.662071      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:08:47.065021 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-566" for this suite. @ 01/15/25 02:08:47.087
  STEP: Destroying namespace "webhook-markers-1618" for this suite. @ 01/15/25 02:08:47.098
• [16.180 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for API chunking should support continue listing from the last key if the original version has been compacted away, though the list is inconsistent [Slow] [Conformance] [sig-api-machinery, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/chunking.go:144
  STEP: Creating a kubernetes client @ 01/15/25 02:08:47.105
  I0115 02:08:47.105745 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename chunking @ 01/15/25 02:08:47.107
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:08:47.131
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:08:47.137
  STEP: creating a large number of resources @ 01/15/25 02:08:47.145
  E0115 02:08:47.662223      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:08:48.663105      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:08:49.663658      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:08:50.664995      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:08:51.665614      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:08:52.667577      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:08:53.668230      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:08:54.670805      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:08:55.671583      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:08:56.672016      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:08:57.673869      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:08:58.674761      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:08:59.676159      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:09:00.676575      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:09:01.677038      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:09:02.677823      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:09:03.678536      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:09:04.679235      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: retrieving the first page @ 01/15/25 02:09:04.814
  I0115 02:09:04.869197 24 chunking.go:163] Retrieved 40/40 results with rv 170672 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTcwNjcyLCJzdGFydCI6Ii90ZW1wbGF0ZS0wMDM5XHUwMDAwIn0
  STEP: retrieving the second page until the token expires @ 01/15/25 02:09:04.869
  E0115 02:09:05.680686      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:09:06.680941      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:09:07.682489      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:09:08.684202      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:09:09.685521      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:09:10.686657      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:09:11.688831      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:09:12.689367      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:09:13.690583      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:09:14.691242      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:09:15.692225      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:09:16.693131      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:09:17.694078      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:09:18.695011      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:09:19.697850      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:09:20.698138      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:09:21.699156      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:09:22.700287      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:09:23.701862      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:09:24.702513      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:09:24.883219 24 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTcwNjcyLCJzdGFydCI6Ii90ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  E0115 02:09:25.705317      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:09:26.706129      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:09:27.706706      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:09:28.708739      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:09:29.710758      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:09:30.712814      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:09:31.714952      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:09:32.714783      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:09:33.715076      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:09:34.715662      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:09:35.716224      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:09:36.717229      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:09:37.719072      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:09:38.719874      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:09:39.721527      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:09:40.721505      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:09:41.722303      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:09:42.723807      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:09:43.725062      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:09:44.725290      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:09:44.875998 24 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTcwNjcyLCJzdGFydCI6Ii90ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  E0115 02:09:45.727336      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:09:46.728528      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:09:47.731590      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:09:48.733303      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:09:49.734206      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:09:50.736045      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:09:51.737346      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:09:52.738370      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:09:53.739660      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:09:54.742400      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:09:55.742629      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:09:56.743248      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:09:57.744727      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:09:58.745547      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:09:59.747792      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:10:00.749215      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:10:01.750140      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:10:02.750095      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:10:03.751962      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:10:04.753406      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:10:04.882589 24 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTcwNjcyLCJzdGFydCI6Ii90ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  E0115 02:10:05.753948      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:10:06.754832      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:10:07.755879      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:10:08.756914      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:10:09.757949      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:10:10.759258      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:10:11.760110      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:10:12.761326      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:10:13.762313      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:10:14.764813      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:10:15.765705      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:10:16.766759      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:10:17.768000      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:10:18.768399      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:10:19.770063      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:10:20.770485      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:10:21.771501      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:10:22.772458      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:10:23.773363      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:10:24.773604      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:10:24.898884 24 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTcwNjcyLCJzdGFydCI6Ii90ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  E0115 02:10:25.775503      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:10:26.776518      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:10:27.777993      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:10:28.778141      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:10:29.780643      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:10:30.781968      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:10:31.782687      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:10:32.784417      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:10:33.784494      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:10:34.784782      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:10:35.785549      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:10:36.787052      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:10:37.788437      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:10:38.789995      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:10:39.790883      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:10:40.791750      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:10:41.792559      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:10:42.792773      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:10:43.794207      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:10:44.795225      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:10:44.874916 24 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTcwNjcyLCJzdGFydCI6Ii90ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  E0115 02:10:45.795652      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:10:46.796504      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:10:47.796970      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:10:48.797999      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:10:49.798924      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:10:50.800464      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:10:51.801180      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:10:52.802660      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:10:53.803935      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:10:54.805934      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:10:55.807634      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:10:56.808410      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:10:57.808814      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:10:58.809172      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:10:59.809671      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:11:00.810667      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:11:01.811941      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:11:02.813118      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:11:03.814130      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:11:04.816644      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:11:04.877229 24 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTcwNjcyLCJzdGFydCI6Ii90ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  E0115 02:11:05.818460      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:11:06.818835      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:11:07.820527      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:11:08.822245      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:11:09.824289      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:11:10.825045      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:11:11.825812      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:11:12.826968      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:11:13.828526      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:11:14.829916      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:11:15.829762      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:11:16.829937      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:11:17.830522      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:11:18.831808      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:11:19.832008      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:11:20.833937      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:11:21.834919      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:11:22.836156      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:11:23.836617      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:11:24.837710      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:11:24.874699 24 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTcwNjcyLCJzdGFydCI6Ii90ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  E0115 02:11:25.838182      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:11:26.838856      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:11:27.839332      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:11:28.840181      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:11:29.840667      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:11:30.841178      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:11:31.842500      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:11:32.843847      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:11:33.844599      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:11:34.845473      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:11:35.846512      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:11:36.847973      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:11:37.848450      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:11:38.849536      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:11:39.851224      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:11:40.852585      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:11:41.853355      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:11:42.854162      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:11:43.854882      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:11:44.855157      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:11:44.878041 24 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTcwNjcyLCJzdGFydCI6Ii90ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  E0115 02:11:45.855668      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:11:46.856049      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:11:47.856987      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:11:48.857779      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:11:49.858756      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:11:50.859023      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:11:51.859613      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:11:52.860051      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:11:53.860846      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:11:54.861263      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:11:55.861905      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:11:56.862243      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:11:57.862935      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:11:58.863630      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:11:59.865304      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:12:00.866776      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:12:01.868234      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:12:02.870119      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:12:03.870280      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:12:04.870345      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:12:04.891574 24 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTcwNjcyLCJzdGFydCI6Ii90ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  E0115 02:12:05.870960      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:12:06.872450      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:12:07.873494      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:12:08.874671      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:12:09.876785      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:12:10.877402      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:12:11.878048      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:12:12.879229      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:12:13.879879      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:12:14.880745      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:12:15.882447      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:12:16.883480      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:12:17.884672      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:12:18.885236      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:12:19.886042      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:12:20.887888      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:12:21.889017      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:12:22.890523      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:12:23.890698      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:12:24.875921 24 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTcwNjcyLCJzdGFydCI6Ii90ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  E0115 02:12:24.892233      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:12:25.893704      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:12:26.895503      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:12:27.897778      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:12:28.899008      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:12:29.899329      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:12:30.899759      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:12:31.902102      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:12:32.901111      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:12:33.902059      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:12:34.902645      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:12:35.903244      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:12:36.903802      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:12:37.905067      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:12:38.905964      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:12:39.906131      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:12:40.907786      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:12:41.908961      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:12:42.910777      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:12:43.914405      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:12:44.888520 24 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTcwNjcyLCJzdGFydCI6Ii90ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  E0115 02:12:44.915913      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:12:45.918816      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:12:46.918808      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:12:47.920057      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:12:48.922056      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:12:49.924920      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:12:50.926170      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:12:51.927550      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:12:52.928535      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:12:53.931997      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:12:54.932714      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:12:55.935298      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:12:56.936231      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:12:57.936702      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:12:58.938060      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:12:59.939114      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:13:00.939729      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:13:01.940677      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:13:02.942272      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:13:03.942551      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:13:04.892183 24 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTcwNjcyLCJzdGFydCI6Ii90ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  E0115 02:13:04.943973      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:13:05.944760      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:13:06.946061      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:13:07.947272      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:13:08.948291      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:13:09.948967      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:13:10.950825      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:13:11.951424      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:13:12.953928      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:13:13.955030      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:13:14.955905      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:13:15.957749      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:13:16.957944      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:13:17.959847      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:13:18.959929      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:13:19.960617      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:13:20.960987      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:13:21.961495      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:13:22.962529      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:13:23.963741      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:13:24.878488 24 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTcwNjcyLCJzdGFydCI6Ii90ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  E0115 02:13:24.964050      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:13:25.964619      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:13:26.966064      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:13:27.967322      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:13:28.968665      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:13:29.968451      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:13:30.970179      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:13:31.971047      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:13:32.971700      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:13:33.972907      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:13:34.973240      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:13:35.974262      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:13:36.975884      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:13:37.977689      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:13:38.978690      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:13:39.979052      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:13:40.979557      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:13:41.980678      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:13:42.982075      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:13:43.982843      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:13:44.895417 24 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTcwNjcyLCJzdGFydCI6Ii90ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  E0115 02:13:44.983911      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:13:45.984965      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:13:46.988530      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:13:47.988934      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:13:48.990179      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:13:49.990495      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:13:50.991623      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:13:52.004683      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:13:53.005103      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:13:54.005798      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:13:55.007405      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:13:56.008750      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:13:57.010420      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:13:58.011477      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:13:59.016997      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:14:00.017694      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:14:01.018363      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:14:02.019201      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:14:03.021050      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:14:04.023033      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:14:04.888988 24 chunking.go:171] Token eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTcwNjcyLCJzdGFydCI6Ii90ZW1wbGF0ZS0wMDM5XHUwMDAwIn0 has not expired yet
  E0115 02:14:05.024126      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:14:06.024618      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:14:07.025271      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:14:08.026298      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:14:09.027375      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:14:10.027475      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:14:11.027887      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:14:12.028698      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:14:13.029520      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:14:14.030623      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:14:15.031573      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:14:16.033108      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:14:17.034109      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:14:18.035490      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:14:19.039093      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:14:20.039198      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:14:21.040193      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:14:22.041515      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:14:23.042685      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:14:24.043227      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:14:24.873445 24 chunking.go:177] got error The provided continue parameter is too old to display a consistent list result. You can start a new list without the continue parameter, or use the continue token in this response to retrieve the remainder of the results. Continuing with the provided token results in an inconsistent list - objects that were created, modified, or deleted between the time the first chunk was returned and now may show up in the list.
  I0115 02:14:24.873511 24 chunking.go:186] Retrieved inconsistent continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6LTEsInN0YXJ0IjoidGVtcGxhdGUtMDAzOVx1MDAwMCJ9
  STEP: retrieving the second page again with the token received with the error message @ 01/15/25 02:14:24.873
  STEP: retrieving all remaining pages @ 01/15/25 02:14:24.878
  I0115 02:14:24.884062 24 chunking.go:221] Retrieved 40/40 results with rv 171122 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTcxMTIyLCJzdGFydCI6InRlbXBsYXRlLTAxMTlcdTAwMDAifQ
  I0115 02:14:24.888779 24 chunking.go:221] Retrieved 40/40 results with rv 171122 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTcxMTIyLCJzdGFydCI6InRlbXBsYXRlLTAxNTlcdTAwMDAifQ
  I0115 02:14:24.893982 24 chunking.go:221] Retrieved 40/40 results with rv 171122 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTcxMTIyLCJzdGFydCI6InRlbXBsYXRlLTAxOTlcdTAwMDAifQ
  I0115 02:14:24.899412 24 chunking.go:221] Retrieved 40/40 results with rv 171122 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTcxMTIyLCJzdGFydCI6InRlbXBsYXRlLTAyMzlcdTAwMDAifQ
  I0115 02:14:24.908500 24 chunking.go:221] Retrieved 40/40 results with rv 171122 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTcxMTIyLCJzdGFydCI6InRlbXBsYXRlLTAyNzlcdTAwMDAifQ
  I0115 02:14:24.912932 24 chunking.go:221] Retrieved 40/40 results with rv 171122 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTcxMTIyLCJzdGFydCI6InRlbXBsYXRlLTAzMTlcdTAwMDAifQ
  I0115 02:14:24.920953 24 chunking.go:221] Retrieved 40/40 results with rv 171122 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTcxMTIyLCJzdGFydCI6InRlbXBsYXRlLTAzNTlcdTAwMDAifQ
  I0115 02:14:24.926233 24 chunking.go:221] Retrieved 40/40 results with rv 171122 and continue 
  I0115 02:14:24.926537 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "chunking-8763" for this suite. @ 01/15/25 02:14:24.932
• [337.835 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment should validate Deployment Status endpoints [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:489
  STEP: Creating a kubernetes client @ 01/15/25 02:14:24.94
  I0115 02:14:24.940904 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename deployment @ 01/15/25 02:14:24.941
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:14:24.957
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:14:24.964
  STEP: creating a Deployment @ 01/15/25 02:14:24.974
  I0115 02:14:24.974968 24 deployment.go:507] Creating simple deployment test-deployment-ll89r
  I0115 02:14:24.990815 24 deployment.go:223] deployment "test-deployment-ll89r" doesn't have the required revision set
  E0115 02:14:25.044792      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:14:26.046567      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Getting /status @ 01/15/25 02:14:27.044
  E0115 02:14:27.048104      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:14:27.059798 24 deployment.go:532] Deployment test-deployment-ll89r has Conditions: [{Available True 2025-01-15 02:14:26 +0000 UTC 2025-01-15 02:14:26 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2025-01-15 02:14:26 +0000 UTC 2025-01-15 02:14:24 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-ll89r-6fb4c74686" has successfully progressed.}]
  STEP: updating Deployment Status @ 01/15/25 02:14:27.059
  I0115 02:14:27.084734 24 deployment.go:552] updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2025, time.January, 15, 2, 14, 26, 0, time.Local), LastTransitionTime:time.Date(2025, time.January, 15, 2, 14, 26, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.January, 15, 2, 14, 26, 0, time.Local), LastTransitionTime:time.Date(2025, time.January, 15, 2, 14, 24, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-ll89r-6fb4c74686\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Deployment status to be updated @ 01/15/25 02:14:27.084
  I0115 02:14:27.089147 24 deployment.go:579] Observed &Deployment event: ADDED
  I0115 02:14:27.089314 24 deployment.go:575] Observed Deployment test-deployment-ll89r in namespace deployment-2275 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2025-01-15 02:14:24 +0000 UTC 2025-01-15 02:14:24 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-ll89r-6fb4c74686"}
  I0115 02:14:27.089565 24 deployment.go:579] Observed &Deployment event: MODIFIED
  I0115 02:14:27.089686 24 deployment.go:575] Observed Deployment test-deployment-ll89r in namespace deployment-2275 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2025-01-15 02:14:24 +0000 UTC 2025-01-15 02:14:24 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-ll89r-6fb4c74686"}
  I0115 02:14:27.089719 24 deployment.go:575] Observed Deployment test-deployment-ll89r in namespace deployment-2275 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2025-01-15 02:14:24 +0000 UTC 2025-01-15 02:14:24 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  I0115 02:14:27.089950 24 deployment.go:579] Observed &Deployment event: MODIFIED
  I0115 02:14:27.090731 24 deployment.go:575] Observed Deployment test-deployment-ll89r in namespace deployment-2275 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2025-01-15 02:14:24 +0000 UTC 2025-01-15 02:14:24 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  I0115 02:14:27.091107 24 deployment.go:575] Observed Deployment test-deployment-ll89r in namespace deployment-2275 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2025-01-15 02:14:25 +0000 UTC 2025-01-15 02:14:24 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-ll89r-6fb4c74686" is progressing.}
  I0115 02:14:27.091819 24 deployment.go:579] Observed &Deployment event: MODIFIED
  I0115 02:14:27.091889 24 deployment.go:575] Observed Deployment test-deployment-ll89r in namespace deployment-2275 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2025-01-15 02:14:26 +0000 UTC 2025-01-15 02:14:26 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  I0115 02:14:27.091914 24 deployment.go:575] Observed Deployment test-deployment-ll89r in namespace deployment-2275 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2025-01-15 02:14:26 +0000 UTC 2025-01-15 02:14:24 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-ll89r-6fb4c74686" has successfully progressed.}
  I0115 02:14:27.092070 24 deployment.go:579] Observed &Deployment event: MODIFIED
  I0115 02:14:27.092129 24 deployment.go:575] Observed Deployment test-deployment-ll89r in namespace deployment-2275 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2025-01-15 02:14:26 +0000 UTC 2025-01-15 02:14:26 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  I0115 02:14:27.092159 24 deployment.go:575] Observed Deployment test-deployment-ll89r in namespace deployment-2275 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2025-01-15 02:14:26 +0000 UTC 2025-01-15 02:14:24 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-ll89r-6fb4c74686" has successfully progressed.}
  I0115 02:14:27.092181 24 deployment.go:572] Found Deployment test-deployment-ll89r in namespace deployment-2275 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0115 02:14:27.092195 24 deployment.go:583] Deployment test-deployment-ll89r has an updated status
  STEP: patching the Statefulset Status @ 01/15/25 02:14:27.092
  I0115 02:14:27.092235 24 deployment.go:587] Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  I0115 02:14:27.103301 24 deployment.go:591] Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Deployment status to be patched @ 01/15/25 02:14:27.103
  I0115 02:14:27.106439 24 deployment.go:616] Observed &Deployment event: ADDED
  I0115 02:14:27.106659 24 deployment.go:612] Observed deployment test-deployment-ll89r in namespace deployment-2275 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2025-01-15 02:14:24 +0000 UTC 2025-01-15 02:14:24 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-ll89r-6fb4c74686"}
  I0115 02:14:27.106927 24 deployment.go:616] Observed &Deployment event: MODIFIED
  I0115 02:14:27.107548 24 deployment.go:612] Observed deployment test-deployment-ll89r in namespace deployment-2275 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2025-01-15 02:14:24 +0000 UTC 2025-01-15 02:14:24 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-ll89r-6fb4c74686"}
  I0115 02:14:27.107688 24 deployment.go:612] Observed deployment test-deployment-ll89r in namespace deployment-2275 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2025-01-15 02:14:24 +0000 UTC 2025-01-15 02:14:24 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  I0115 02:14:27.108144 24 deployment.go:616] Observed &Deployment event: MODIFIED
  I0115 02:14:27.108229 24 deployment.go:612] Observed deployment test-deployment-ll89r in namespace deployment-2275 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2025-01-15 02:14:24 +0000 UTC 2025-01-15 02:14:24 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  I0115 02:14:27.108260 24 deployment.go:612] Observed deployment test-deployment-ll89r in namespace deployment-2275 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2025-01-15 02:14:25 +0000 UTC 2025-01-15 02:14:24 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-ll89r-6fb4c74686" is progressing.}
  I0115 02:14:27.108630 24 deployment.go:616] Observed &Deployment event: MODIFIED
  I0115 02:14:27.108746 24 deployment.go:612] Observed deployment test-deployment-ll89r in namespace deployment-2275 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2025-01-15 02:14:26 +0000 UTC 2025-01-15 02:14:26 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  I0115 02:14:27.108786 24 deployment.go:612] Observed deployment test-deployment-ll89r in namespace deployment-2275 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2025-01-15 02:14:26 +0000 UTC 2025-01-15 02:14:24 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-ll89r-6fb4c74686" has successfully progressed.}
  I0115 02:14:27.109589 24 deployment.go:616] Observed &Deployment event: MODIFIED
  I0115 02:14:27.109667 24 deployment.go:612] Observed deployment test-deployment-ll89r in namespace deployment-2275 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2025-01-15 02:14:26 +0000 UTC 2025-01-15 02:14:26 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  I0115 02:14:27.109691 24 deployment.go:612] Observed deployment test-deployment-ll89r in namespace deployment-2275 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2025-01-15 02:14:26 +0000 UTC 2025-01-15 02:14:24 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-ll89r-6fb4c74686" has successfully progressed.}
  I0115 02:14:27.109914 24 deployment.go:612] Observed deployment test-deployment-ll89r in namespace deployment-2275 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0115 02:14:27.110226 24 deployment.go:616] Observed &Deployment event: MODIFIED
  I0115 02:14:27.110340 24 deployment.go:609] Found deployment test-deployment-ll89r in namespace deployment-2275 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
  I0115 02:14:27.110377 24 deployment.go:620] Deployment test-deployment-ll89r has a patched status
  I0115 02:14:27.116054 24 deployment.go:633] Deployment "test-deployment-ll89r":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=21) "test-deployment-ll89r",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2275",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "1e0dc88b-39a7-49d4-81b9-959ee880b766",
      ResourceVersion: (string) (len=6) "171153",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872504064,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504064,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=657) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 65 32 65  22 3a 7b 7d 2c 22 66 3a  |},"f:e2e":{},"f:|
              00000030  6e 61 6d 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |name":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  70 72 6f 67 72 65 73 73  |ec":{"f:progress|
              00000050  44 65 61 64 6c 69 6e 65  53 65 63 6f 6e 64 73 22  |DeadlineSeconds"|
              00000060  3a 7b 7d 2c 22 66 3a 72  65 70 6c 69 63 61 73 22  |:{},"f:replicas"|
              00000070  3a 7b 7d 2c 22 66 3a 72  65 76 69 73 69 6f 6e 48  |:{},"f:revisionH|
              00000080  69 73 74 6f 72 79 4c 69  6d 69 74 22 3a 7b 7d 2c  |istoryLimit":{},|
              00000090  22 66 3a 73 65 6c 65 63  74 6f 72 22 3a 7b 7d 2c  |"f:selector":{},|
              000000a0  22 66 3a 73 74 72 61 74  65 67 79 22 3a 7b 22 66  |"f:strategy":{"f|
              000000b0  3a 72 6f 6c 6c 69 6e 67  55 70 64 61 74 65 22 3a  |:rollingUpdate":|
              000000c0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6d 61 78 53 75  |{".":{},"f:maxSu|
              000000d0  72 67 65 22 3a 7b 7d 2c  22 66 3a 6d 61 78 55 6e  |rge":{},"f:maxUn|
              000000e0  61 76 61 69 6c 61 62 6c  65 22 3a 7b 7d 7d 2c 22  |available":{}},"|
              000000f0  66 3a 74 79 70 65 22 3a  7b 7d 7d 2c 22 66 3a 74  |f:type":{}},"f:t|
              00000100  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000110  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              00000120  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 65 32  |s":{".":{},"f:e2|
              00000130  65 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |e":{},"f:name":{|
              00000140  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              00000150  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000160  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              00000170  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              00000180  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000190  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              000001a0  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              000001b0  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              000001c0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000001d0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000001e0  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000210  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000220  69 63 79 22 3a 7b 7d 2c  22 66 3a 72 65 73 74 61  |icy":{},"f:resta|
              00000230  72 74 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |rtPolicy":{},"f:|
              00000240  73 63 68 65 64 75 6c 65  72 4e 61 6d 65 22 3a 7b  |schedulerName":{|
              00000250  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000260  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000270  69 6e 61 74 69 6f 6e 47  72 61 63 65 50 65 72 69  |inationGracePeri|
              00000280  6f 64 53 65 63 6f 6e 64  73 22 3a 7b 7d 7d 7d 7d  |odSeconds":{}}}}|
              00000290  7d                                                |}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504067,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=147) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 53 74 61 74  |{\"type\":\"Stat|
              00000030  75 73 50 61 74 63 68 65  64 5c 22 7d 22 3a 7b 22  |usPatched\"}":{"|
              00000040  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |.":{},"f:lastTra|
              00000050  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000060  22 66 3a 6c 61 73 74 55  70 64 61 74 65 54 69 6d  |"f:lastUpdateTim|
              00000070  65 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |e":{},"f:status"|
              00000080  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000090  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504067,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=373) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 50 72 6f  |:{\"type\":\"Pro|
              000000a0  67 72 65 73 73 69 6e 67  5c 22 7d 22 3a 7b 22 2e  |gressing\"}":{".|
              000000b0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000000c0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000000d0  66 3a 6c 61 73 74 55 70  64 61 74 65 54 69 6d 65  |f:lastUpdateTime|
              000000e0  22 3a 7b 7d 2c 22 66 3a  6d 65 73 73 61 67 65 22  |":{},"f:message"|
              000000f0  3a 7b 7d 2c 22 66 3a 72  65 61 73 6f 6e 22 3a 7b  |:{},"f:reason":{|
              00000100  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              00000110  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              00000120  3a 6f 62 73 65 72 76 65  64 47 65 6e 65 72 61 74  |:observedGenerat|
              00000130  69 6f 6e 22 3a 7b 7d 2c  22 66 3a 72 65 61 64 79  |ion":{},"f:ready|
              00000140  52 65 70 6c 69 63 61 73  22 3a 7b 7d 2c 22 66 3a  |Replicas":{},"f:|
              00000150  72 65 70 6c 69 63 61 73  22 3a 7b 7d 2c 22 66 3a  |replicas":{},"f:|
              00000160  75 70 64 61 74 65 64 52  65 70 6c 69 63 61 73 22  |updatedReplicas"|
              00000170  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=3) "e2e": (string) (len=7) "testing",
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=3) "e2e": (string) (len=7) "testing",
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=13) "StatusPatched",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504067,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504067,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "FoundNewReplicaSet",
          Message: (string) (len=56) "Found new replica set \"test-deployment-ll89r-6fb4c74686\""
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0115 02:14:27.124874 24 deployment.go:40] New ReplicaSet "test-deployment-ll89r-6fb4c74686" of Deployment "test-deployment-ll89r":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=32) "test-deployment-ll89r-6fb4c74686",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2275",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "9df9603b-965a-4de4-a738-ba575dd5c7c6",
      ResourceVersion: (string) (len=6) "171149",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872504064,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=3) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6fb4c74686"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=21) "test-deployment-ll89r",
          UID: (types.UID) (len=36) "1e0dc88b-39a7-49d4-81b9-959ee880b766",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504064,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=803) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 65 32 65  22 3a 7b 7d 2c 22 66 3a  |},"f:e2e":{},"f:|
              000000d0  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 70 6f 64 2d  |name":{},"f:pod-|
              000000e0  74 65 6d 70 6c 61 74 65  2d 68 61 73 68 22 3a 7b  |template-hash":{|
              000000f0  7d 7d 2c 22 66 3a 6f 77  6e 65 72 52 65 66 65 72  |}},"f:ownerRefer|
              00000100  65 6e 63 65 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |ences":{".":{},"|
              00000110  6b 3a 7b 5c 22 75 69 64  5c 22 3a 5c 22 31 65 30  |k:{\"uid\":\"1e0|
              00000120  64 63 38 38 62 2d 33 39  61 37 2d 34 39 64 34 2d  |dc88b-39a7-49d4-|
              00000130  38 31 62 39 2d 39 35 39  65 65 38 38 30 62 37 36  |81b9-959ee880b76|
              00000140  36 5c 22 7d 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |6\"}":{}}},"f:sp|
              00000150  65 63 22 3a 7b 22 66 3a  72 65 70 6c 69 63 61 73  |ec":{"f:replicas|
              00000160  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000180  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000190  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              000001a0  3a 7b 7d 2c 22 66 3a 65  32 65 22 3a 7b 7d 2c 22  |:{},"f:e2e":{},"|
              000001b0  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 70 6f  |f:name":{},"f:po|
              000001c0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001d0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000001e0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000001f0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 68  |"k:{\"name\":\"h|
              00000200  74 74 70 64 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |ttpd\"}":{".":{}|
              00000210  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000220  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000230  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000240  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000250  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000260  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000270  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000280  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000290  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              000002a0  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              000002b0  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              000002c0  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              000002d0  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              000002e0  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000002f0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              00000300  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              00000310  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              00000320  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504066,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=3) {
          (string) (len=17) "pod-template-hash": (string) (len=10) "6fb4c74686",
          (string) (len=3) "e2e": (string) (len=7) "testing",
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=3) {
            (string) (len=3) "e2e": (string) (len=7) "testing",
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "6fb4c74686"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0115 02:14:27.132923 24 deployment.go:68] Pod "test-deployment-ll89r-6fb4c74686-4q7xb" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=38) "test-deployment-ll89r-6fb4c74686-4q7xb",
      GenerateName: (string) (len=33) "test-deployment-ll89r-6fb4c74686-",
      Namespace: (string) (len=15) "deployment-2275",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "90f24b2e-18fb-4cb7-8de5-2d8e6be09568",
      ResourceVersion: (string) (len=6) "171148",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872504064,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=3) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6fb4c74686"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "7d9ac603aec7f47494c08516dfceffe52b79540cd1aca2bf9a69653d364683d9",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=14) "10.1.155.55/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=14) "10.1.155.55/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=32) "test-deployment-ll89r-6fb4c74686",
          UID: (types.UID) (len=36) "9df9603b-965a-4de4-a738-ba575dd5c7c6",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504064,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=548) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 65 32 65 22 3a 7b 7d  |.":{},"f:e2e":{}|
              00000040  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000050  70 6f 64 2d 74 65 6d 70  6c 61 74 65 2d 68 61 73  |pod-template-has|
              00000060  68 22 3a 7b 7d 7d 2c 22  66 3a 6f 77 6e 65 72 52  |h":{}},"f:ownerR|
              00000070  65 66 65 72 65 6e 63 65  73 22 3a 7b 22 2e 22 3a  |eferences":{".":|
              00000080  7b 7d 2c 22 6b 3a 7b 5c  22 75 69 64 5c 22 3a 5c  |{},"k:{\"uid\":\|
              00000090  22 39 64 66 39 36 30 33  62 2d 39 36 35 61 2d 34  |"9df9603b-965a-4|
              000000a0  64 65 34 2d 61 37 33 38  2d 62 61 35 37 35 64 64  |de4-a738-ba575dd|
              000000b0  35 63 37 63 36 5c 22 7d  22 3a 7b 7d 7d 7d 2c 22  |5c7c6\"}":{}}},"|
              000000c0  66 3a 73 70 65 63 22 3a  7b 22 66 3a 63 6f 6e 74  |f:spec":{"f:cont|
              000000d0  61 69 6e 65 72 73 22 3a  7b 22 6b 3a 7b 5c 22 6e  |ainers":{"k:{\"n|
              000000e0  61 6d 65 5c 22 3a 5c 22  68 74 74 70 64 5c 22 7d  |ame\":\"httpd\"}|
              000000f0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |":{".":{},"f:ima|
              00000100  67 65 22 3a 7b 7d 2c 22  66 3a 69 6d 61 67 65 50  |ge":{},"f:imageP|
              00000110  75 6c 6c 50 6f 6c 69 63  79 22 3a 7b 7d 2c 22 66  |ullPolicy":{},"f|
              00000120  3a 6e 61 6d 65 22 3a 7b  7d 2c 22 66 3a 72 65 73  |:name":{},"f:res|
              00000130  6f 75 72 63 65 73 22 3a  7b 7d 2c 22 66 3a 73 65  |ources":{},"f:se|
              00000140  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000150  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000160  4d 65 73 73 61 67 65 50  61 74 68 22 3a 7b 7d 2c  |MessagePath":{},|
              00000170  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000180  73 73 61 67 65 50 6f 6c  69 63 79 22 3a 7b 7d 7d  |ssagePolicy":{}}|
              00000190  7d 2c 22 66 3a 64 6e 73  50 6f 6c 69 63 79 22 3a  |},"f:dnsPolicy":|
              000001a0  7b 7d 2c 22 66 3a 65 6e  61 62 6c 65 53 65 72 76  |{},"f:enableServ|
              000001b0  69 63 65 4c 69 6e 6b 73  22 3a 7b 7d 2c 22 66 3a  |iceLinks":{},"f:|
              000001c0  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000001d0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000001e0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000001f0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              00000200  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              00000210  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              00000220  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504065,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504066,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 31 2e 31 35 35 2e 35  35 5c 22 7d 22 3a 7b 22  |.1.155.55\"}":{"|
              00000270  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000280  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000290  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-6gwgw",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-6gwgw",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=13) "192.168.18.92",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504066,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504065,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504066,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504066,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504064,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "192.168.18.92",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "192.168.18.92"
        }
      },
      PodIP: (string) (len=11) "10.1.155.55",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.1.155.55"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872504065,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63872504066,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://8f2b7d50a39ed9f59580af0f15866de59af9062453a6deb61376ea5d3a86daab",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-6gwgw",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0115 02:14:27.135809 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-2275" for this suite. @ 01/15/25 02:14:27.145
• [2.212 seconds]
------------------------------
S
------------------------------
[sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1396
  STEP: Creating a kubernetes client @ 01/15/25 02:14:27.153
  I0115 02:14:27.153613 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename services @ 01/15/25 02:14:27.155
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:14:27.174
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:14:27.182
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-5247 @ 01/15/25 02:14:27.195
  STEP: changing the ExternalName service to type=ClusterIP @ 01/15/25 02:14:27.204
  STEP: creating replication controller externalname-service in namespace services-5247 @ 01/15/25 02:14:27.226
  I0115 02:14:27.244964      24 runners.go:193] Created replication controller with name: externalname-service, namespace: services-5247, replica count: 2
  E0115 02:14:28.049009      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:14:29.049868      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:14:30.049885      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:14:30.296500      24 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0115 02:14:30.296600 24 resource.go:361] Creating new exec pod
  E0115 02:14:31.051182      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:14:32.052309      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:14:33.051906      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:14:33.335598 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-5247 exec execpodfl8lk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  I0115 02:14:33.735182 24 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service (169.169.229.242) 80 port [tcp/http] succeeded!\n"
  I0115 02:14:33.735276 24 builder.go:147] stdout: "externalname-service-p2m2q"
  I0115 02:14:33.735422 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-5247 exec execpodfl8lk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 169.169.229.242 80'
  I0115 02:14:34.029196 24 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 169.169.229.242 80\nConnection to 169.169.229.242 80 port [tcp/http] succeeded!\n"
  I0115 02:14:34.029287 24 builder.go:147] stdout: ""
  E0115 02:14:34.053260      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:14:34.736580 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-5247 exec execpodfl8lk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 169.169.229.242 80'
  E0115 02:14:35.054557      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:14:35.100573 24 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 169.169.229.242 80\nConnection to 169.169.229.242 80 port [tcp/http] succeeded!\n"
  I0115 02:14:35.100632 24 builder.go:147] stdout: "externalname-service-v9wfp"
  I0115 02:14:35.100784 24 service.go:1405] Cleaning up the ExternalName to ClusterIP test service
  I0115 02:14:35.119249 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-5247" for this suite. @ 01/15/25 02:14:35.127
• [7.980 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:424
  STEP: Creating a kubernetes client @ 01/15/25 02:14:35.134
  I0115 02:14:35.134161 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename configmap @ 01/15/25 02:14:35.135
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:14:35.156
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:14:35.161
  STEP: Creating configMap with name configmap-test-volume-a7272477-1583-4748-9e33-a8cff1d48c26 @ 01/15/25 02:14:35.171
  STEP: Creating a pod to test consume configMaps @ 01/15/25 02:14:35.183
  E0115 02:14:36.054940      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:14:37.056430      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:14:38.057321      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:14:39.058193      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 02:14:39.222
  I0115 02:14:39.229241 24 output.go:207] Trying to get logs from node 192.168.18.92 pod pod-configmaps-a3bf3121-a623-41f2-8700-4a1fb431b668 container configmap-volume-test: <nil>
  STEP: delete the pod @ 01/15/25 02:14:39.241
  I0115 02:14:39.269396 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-5860" for this suite. @ 01/15/25 02:14:39.314
• [4.212 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:216
  STEP: Creating a kubernetes client @ 01/15/25 02:14:39.346
  I0115 02:14:39.346681 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename container-runtime @ 01/15/25 02:14:39.356
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:14:39.409
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:14:39.419
  STEP: create the container @ 01/15/25 02:14:39.428
  W0115 02:14:39.441223      24 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Failed @ 01/15/25 02:14:39.441
  E0115 02:14:40.058479      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:14:41.058668      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:14:42.058957      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:14:43.060029      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: get the container status @ 01/15/25 02:14:43.583
  STEP: the container should be terminated @ 01/15/25 02:14:43.608
  STEP: the termination message should be set @ 01/15/25 02:14:43.608
  I0115 02:14:43.608625 24 runtime.go:167] Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 01/15/25 02:14:43.608
  I0115 02:14:43.698334 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-6911" for this suite. @ 01/15/25 02:14:43.711
• [4.374 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:400
  STEP: Creating a kubernetes client @ 01/15/25 02:14:43.722
  I0115 02:14:43.722441 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename webhook @ 01/15/25 02:14:43.724
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:14:43.775
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:14:43.785
  STEP: Setting up server cert @ 01/15/25 02:14:43.866
  E0115 02:14:44.060796      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:14:45.062292      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 01/15/25 02:14:45.121
  STEP: Deploying the webhook pod @ 01/15/25 02:14:45.134
  STEP: Wait for the deployment to be ready @ 01/15/25 02:14:45.154
  I0115 02:14:45.165486 24 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0115 02:14:46.064070      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:14:47.064717      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:14:47.180740 24 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.January, 15, 2, 14, 45, 0, time.Local), LastTransitionTime:time.Date(2025, time.January, 15, 2, 14, 45, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.January, 15, 2, 14, 45, 0, time.Local), LastTransitionTime:time.Date(2025, time.January, 15, 2, 14, 45, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-bcbfc85d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0115 02:14:48.065889      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:14:49.067246      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 01/15/25 02:14:49.194
  STEP: Verifying the service has paired with the endpoint @ 01/15/25 02:14:49.218
  E0115 02:14:50.067258      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:14:50.220559 24 util.go:423] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Creating a validating webhook configuration @ 01/15/25 02:14:50.229
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 01/15/25 02:14:50.252
  STEP: Updating a validating webhook configuration's rules to not include the create operation @ 01/15/25 02:14:50.263
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 01/15/25 02:14:50.277
  STEP: Patching a validating webhook configuration's rules to include the create operation @ 01/15/25 02:14:50.291
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 01/15/25 02:14:50.3
  I0115 02:14:50.392392 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-5874" for this suite. @ 01/15/25 02:14:50.414
  STEP: Destroying namespace "webhook-markers-9435" for this suite. @ 01/15/25 02:14:50.432
• [6.725 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:139
  STEP: Creating a kubernetes client @ 01/15/25 02:14:50.449
  I0115 02:14:50.449061 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename crd-webhook @ 01/15/25 02:14:50.451
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:14:50.484
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:14:50.531
  STEP: Setting up server cert @ 01/15/25 02:14:50.558
  E0115 02:14:51.068188      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 01/15/25 02:14:51.607
  STEP: Deploying the custom resource conversion webhook pod @ 01/15/25 02:14:51.615
  STEP: Wait for the deployment to be ready @ 01/15/25 02:14:51.634
  I0115 02:14:51.647741 24 deployment.go:223] deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
  E0115 02:14:52.071056      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:14:53.072330      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 01/15/25 02:14:53.667
  STEP: Verifying the service has paired with the endpoint @ 01/15/25 02:14:53.678
  E0115 02:14:54.073800      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:14:54.679682 24 util.go:423] Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  I0115 02:14:54.688903 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  E0115 02:14:55.073970      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:14:56.074251      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:14:57.075532      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Creating a v1 custom resource @ 01/15/25 02:14:57.252
  STEP: v2 custom resource should be converted @ 01/15/25 02:14:57.258
  I0115 02:14:57.899524 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-webhook-204" for this suite. @ 01/15/25 02:14:57.905
• [7.469 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:79
  STEP: Creating a kubernetes client @ 01/15/25 02:14:57.917
  I0115 02:14:57.917357 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename subpath @ 01/15/25 02:14:57.919
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:14:57.944
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:14:57.951
  STEP: Setting up data @ 01/15/25 02:14:57.957
  STEP: Creating pod pod-subpath-test-configmap-2q64 @ 01/15/25 02:14:57.972
  STEP: Creating a pod to test atomic-volume-subpath @ 01/15/25 02:14:57.972
  E0115 02:14:58.076146      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:14:59.077178      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:15:00.077415      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:15:01.079138      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:15:02.080100      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:15:03.080334      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:15:04.080963      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:15:05.080699      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:15:06.082033      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:15:07.082740      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:15:08.082770      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:15:09.083206      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:15:10.084228      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:15:11.084617      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:15:12.084787      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:15:13.085910      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:15:14.087060      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:15:15.087016      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:15:16.087583      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:15:17.089037      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:15:18.089593      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:15:19.090740      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:15:20.093123      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:15:21.097116      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:15:22.098276      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 02:15:22.119
  I0115 02:15:22.123653 24 output.go:207] Trying to get logs from node 192.168.18.92 pod pod-subpath-test-configmap-2q64 container test-container-subpath-configmap-2q64: <nil>
  STEP: delete the pod @ 01/15/25 02:15:22.135
  STEP: Deleting pod pod-subpath-test-configmap-2q64 @ 01/15/25 02:15:22.153
  I0115 02:15:22.154022 24 delete.go:62] Deleting pod "pod-subpath-test-configmap-2q64" in namespace "subpath-3547"
  I0115 02:15:22.158373 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-3547" for this suite. @ 01/15/25 02:15:22.164
• [24.255 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:184
  STEP: Creating a kubernetes client @ 01/15/25 02:15:22.172
  I0115 02:15:22.172781 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename kubelet-test @ 01/15/25 02:15:22.174
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:15:22.193
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:15:22.199
  E0115 02:15:23.099345      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:15:24.100297      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:15:24.276354 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-2644" for this suite. @ 01/15/25 02:15:24.301
• [2.140 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:105
  STEP: Creating a kubernetes client @ 01/15/25 02:15:24.312
  I0115 02:15:24.312876 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename deployment @ 01/15/25 02:15:24.315
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:15:24.336
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:15:24.342
  I0115 02:15:24.347511 24 deployment.go:754] Creating replica set "test-rolling-update-controller" (going to be adopted)
  I0115 02:15:24.359013 24 resource.go:87] Pod name sample-pod: Found 0 pods out of 1
  E0115 02:15:25.100720      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:15:26.101771      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:15:27.102737      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:15:28.103285      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:15:29.103970      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:15:29.363534 24 resource.go:87] Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 01/15/25 02:15:29.363
  I0115 02:15:29.363661 24 deployment.go:763] Creating deployment "test-rolling-update-deployment"
  I0115 02:15:29.370357 24 deployment.go:769] Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
  I0115 02:15:29.379699 24 deployment.go:223] new replicaset for deployment "test-rolling-update-deployment" is yet to be created
  E0115 02:15:30.104164      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:15:31.106093      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:15:31.408157 24 deployment.go:773] Ensuring status for deployment "test-rolling-update-deployment" is the expected
  I0115 02:15:31.419455 24 deployment.go:778] Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
  I0115 02:15:31.458749 24 deployment.go:633] Deployment "test-rolling-update-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-rolling-update-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5034",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "914d8b05-5ef4-4e19-81bc-f2cac6d624d4",
      ResourceVersion: (string) (len=6) "172079",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872504129,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=10) "sample-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305833"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504129,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=637) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 61  67 6e 68 6f 73 74 5c 22  |me\":\"agnhost\"|
              00000160  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000170  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000180  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000190  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              000001a0  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              000001b0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001c0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              000001d0  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              000001e0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001f0  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000200  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              00000210  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              00000220  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              00000230  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000270  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504130,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=10) "sample-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=10) "sample-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.53",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504129,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504129,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504130,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504129,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=83) "ReplicaSet \"test-rolling-update-deployment-6ff565599d\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0115 02:15:31.475773 24 deployment.go:40] New ReplicaSet "test-rolling-update-deployment-6ff565599d" of Deployment "test-rolling-update-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=41) "test-rolling-update-deployment-6ff565599d",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5034",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "f95690a6-1862-420b-91f6-15b3981e50e8",
      ResourceVersion: (string) (len=6) "172069",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872504129,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6ff565599d"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305833"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=30) "test-rolling-update-deployment",
          UID: (types.UID) (len=36) "914d8b05-5ef4-4e19-81bc-f2cac6d624d4",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504129,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 39 31 34 64 38 62  30 35 2d 35 65 66 34 2d  |\"914d8b05-5ef4-|
              00000120  34 65 31 39 2d 38 31 62  63 2d 66 32 63 61 63 36  |4e19-81bc-f2cac6|
              00000130  64 36 32 34 64 34 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |d624d4\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504130,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=10) "sample-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "6ff565599d"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=10) "sample-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "6ff565599d"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.53",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0115 02:15:31.478504 24 deployment.go:45] All old ReplicaSets of Deployment "test-rolling-update-deployment":
  I0115 02:15:31.480153 24 deployment.go:48] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-rolling-update-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5034",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "5f787f23-425f-4cf0-8239-e77ace0cdb64",
      ResourceVersion: (string) (len=6) "172078",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872504124,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305832"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=30) "test-rolling-update-deployment",
          UID: (types.UID) (len=36) "914d8b05-5ef4-4e19-81bc-f2cac6d624d4",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504124,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=533) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  2c 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |,"f:labels":{"."|
              00000060  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              00000070  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              00000080  73 70 65 63 22 3a 7b 22  66 3a 73 65 6c 65 63 74  |spec":{"f:select|
              00000090  6f 72 22 3a 7b 7d 2c 22  66 3a 74 65 6d 70 6c 61  |or":{},"f:templa|
              000000a0  74 65 22 3a 7b 22 66 3a  6d 65 74 61 64 61 74 61  |te":{"f:metadata|
              000000b0  22 3a 7b 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |":{"f:labels":{"|
              000000c0  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              000000d0  7d 2c 22 66 3a 70 6f 64  22 3a 7b 7d 7d 7d 2c 22  |},"f:pod":{}}},"|
              000000e0  66 3a 73 70 65 63 22 3a  7b 22 66 3a 63 6f 6e 74  |f:spec":{"f:cont|
              000000f0  61 69 6e 65 72 73 22 3a  7b 22 6b 3a 7b 5c 22 6e  |ainers":{"k:{\"n|
              00000100  61 6d 65 5c 22 3a 5c 22  68 74 74 70 64 5c 22 7d  |ame\":\"httpd\"}|
              00000110  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |":{".":{},"f:ima|
              00000120  67 65 22 3a 7b 7d 2c 22  66 3a 69 6d 61 67 65 50  |ge":{},"f:imageP|
              00000130  75 6c 6c 50 6f 6c 69 63  79 22 3a 7b 7d 2c 22 66  |ullPolicy":{},"f|
              00000140  3a 6e 61 6d 65 22 3a 7b  7d 2c 22 66 3a 72 65 73  |:name":{},"f:res|
              00000150  6f 75 72 63 65 73 22 3a  7b 7d 2c 22 66 3a 74 65  |ources":{},"f:te|
              00000160  72 6d 69 6e 61 74 69 6f  6e 4d 65 73 73 61 67 65  |rminationMessage|
              00000170  50 61 74 68 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |Path":{},"f:term|
              00000180  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 6f  |inationMessagePo|
              00000190  6c 69 63 79 22 3a 7b 7d  7d 7d 2c 22 66 3a 64 6e  |licy":{}}},"f:dn|
              000001a0  73 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 72  |sPolicy":{},"f:r|
              000001b0  65 73 74 61 72 74 50 6f  6c 69 63 79 22 3a 7b 7d  |estartPolicy":{}|
              000001c0  2c 22 66 3a 73 63 68 65  64 75 6c 65 72 4e 61 6d  |,"f:schedulerNam|
              000001d0  65 22 3a 7b 7d 2c 22 66  3a 73 65 63 75 72 69 74  |e":{},"f:securit|
              000001e0  79 43 6f 6e 74 65 78 74  22 3a 7b 7d 2c 22 66 3a  |yContext":{},"f:|
              000001f0  74 65 72 6d 69 6e 61 74  69 6f 6e 47 72 61 63 65  |terminationGrace|
              00000200  50 65 72 69 6f 64 53 65  63 6f 6e 64 73 22 3a 7b  |PeriodSeconds":{|
              00000210  7d 7d 7d 7d 7d                                    |}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504130,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=242) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 66 3a 64 65 70 6c 6f  79 6d 65 6e 74 2e 6b 75  |"f:deployment.ku|
              00000030  62 65 72 6e 65 74 65 73  2e 69 6f 2f 64 65 73 69  |bernetes.io/desi|
              00000040  72 65 64 2d 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |red-replicas":{}|
              00000050  2c 22 66 3a 64 65 70 6c  6f 79 6d 65 6e 74 2e 6b  |,"f:deployment.k|
              00000060  75 62 65 72 6e 65 74 65  73 2e 69 6f 2f 6d 61 78  |ubernetes.io/max|
              00000070  2d 72 65 70 6c 69 63 61  73 22 3a 7b 7d 7d 2c 22  |-replicas":{}},"|
              00000080  66 3a 6f 77 6e 65 72 52  65 66 65 72 65 6e 63 65  |f:ownerReference|
              00000090  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 6b 3a 7b 5c  |s":{".":{},"k:{\|
              000000a0  22 75 69 64 5c 22 3a 5c  22 39 31 34 64 38 62 30  |"uid\":\"914d8b0|
              000000b0  35 2d 35 65 66 34 2d 34  65 31 39 2d 38 31 62 63  |5-5ef4-4e19-81bc|
              000000c0  2d 66 32 63 61 63 36 64  36 32 34 64 34 5c 22 7d  |-f2cac6d624d4\"}|
              000000d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000000e0  7b 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |{"f:replicas":{}|
              000000f0  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504130,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=10) "sample-pod",
          (string) (len=3) "pod": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=10) "sample-pod",
            (string) (len=3) "pod": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0115 02:15:31.498562 24 deployment.go:68] Pod "test-rolling-update-deployment-6ff565599d-54fjz" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=47) "test-rolling-update-deployment-6ff565599d-54fjz",
      GenerateName: (string) (len=42) "test-rolling-update-deployment-6ff565599d-",
      Namespace: (string) (len=15) "deployment-5034",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "3e15d473-1e67-45af-87fa-215cd382f809",
      ResourceVersion: (string) (len=6) "172068",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872504129,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6ff565599d"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "d66d48bf8150428cb16cbce2c36063a720a9788332ef8b26c41834390110da8a",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=14) "10.1.155.28/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=14) "10.1.155.28/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=41) "test-rolling-update-deployment-6ff565599d",
          UID: (types.UID) (len=36) "f95690a6-1862-420b-91f6-15b3981e50e8",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504129,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504129,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 66 39  35 36 39 30 61 36 2d 31  |d\":\"f95690a6-1|
              00000090  38 36 32 2d 34 32 30 62  2d 39 31 66 36 2d 31 35  |862-420b-91f6-15|
              000000a0  62 33 39 38 31 65 35 30  65 38 5c 22 7d 22 3a 7b  |b3981e50e8\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504130,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 31 2e 31 35 35 2e 32  38 5c 22 7d 22 3a 7b 22  |.1.155.28\"}":{"|
              00000270  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000280  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000290  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-9btzv",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.53",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-9btzv",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=13) "192.168.18.92",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504130,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504129,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504130,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504130,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504129,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "192.168.18.92",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "192.168.18.92"
        }
      },
      PodIP: (string) (len=11) "10.1.155.28",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.1.155.28"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872504129,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63872504130,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.53",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:99c6b4bb4a1e1df3f0b3752168c89358794d02258ebebc26bf21c29399011a85",
          ContainerID: (string) (len=77) "containerd://50881cffe9a67bf74475a498855a3168cfa02461d638fe10ba8a5e379a26d00b",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-9btzv",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0115 02:15:31.505006 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-5034" for this suite. @ 01/15/25 02:15:31.523
• [7.229 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:48
  STEP: Creating a kubernetes client @ 01/15/25 02:15:31.546
  I0115 02:15:31.546443 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename secrets @ 01/15/25 02:15:31.548
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:15:31.569
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:15:31.575
  STEP: Creating secret with name secret-test-863de3db-d85c-4ccb-a995-05f947e954ba @ 01/15/25 02:15:31.579
  STEP: Creating a pod to test consume secrets @ 01/15/25 02:15:31.583
  E0115 02:15:32.107509      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:15:33.108356      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:15:34.109877      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:15:35.109862      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 02:15:35.604
  I0115 02:15:35.607265 24 output.go:207] Trying to get logs from node 192.168.18.92 pod pod-secrets-2a73086e-c227-4840-9af0-9dd7e2124988 container secret-env-test: <nil>
  STEP: delete the pod @ 01/15/25 02:15:35.615
  I0115 02:15:35.628130 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-4359" for this suite. @ 01/15/25 02:15:35.632
• [4.094 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet_etc_hosts.go:65
  STEP: Creating a kubernetes client @ 01/15/25 02:15:35.638
  I0115 02:15:35.638483 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts @ 01/15/25 02:15:35.639
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:15:35.653
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:15:35.658
  STEP: Setting up the test @ 01/15/25 02:15:35.663
  STEP: Creating hostNetwork=false pod @ 01/15/25 02:15:35.663
  E0115 02:15:36.110769      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:15:37.111684      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:15:38.111977      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:15:39.112255      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Creating hostNetwork=true pod @ 01/15/25 02:15:39.768
  E0115 02:15:40.112750      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:15:41.113388      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Running the test @ 01/15/25 02:15:41.807
  STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false @ 01/15/25 02:15:41.807
  I0115 02:15:41.807513 24 exec_util.go:59] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-334 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0115 02:15:41.807541 24 exec_util.go:64] ExecWithOptions: Clientset creation
  I0115 02:15:41.807621 24 exec_util.go:80] ExecWithOptions: execute(POST https://169.169.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-334/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&stderr=true&stdout=true)
  I0115 02:15:41.904531 24 exec_util.go:108] Exec stderr: ""
  I0115 02:15:41.904653 24 exec_util.go:59] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-334 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0115 02:15:41.904723 24 exec_util.go:64] ExecWithOptions: Clientset creation
  I0115 02:15:41.904851 24 exec_util.go:80] ExecWithOptions: execute(POST https://169.169.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-334/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&stderr=true&stdout=true)
  I0115 02:15:42.000841 24 exec_util.go:108] Exec stderr: ""
  I0115 02:15:42.000920 24 exec_util.go:59] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-334 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0115 02:15:42.000942 24 exec_util.go:64] ExecWithOptions: Clientset creation
  I0115 02:15:42.001077 24 exec_util.go:80] ExecWithOptions: execute(POST https://169.169.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-334/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&stderr=true&stdout=true)
  I0115 02:15:42.091050 24 exec_util.go:108] Exec stderr: ""
  I0115 02:15:42.091128 24 exec_util.go:59] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-334 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0115 02:15:42.091151 24 exec_util.go:64] ExecWithOptions: Clientset creation
  I0115 02:15:42.091250 24 exec_util.go:80] ExecWithOptions: execute(POST https://169.169.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-334/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&stderr=true&stdout=true)
  E0115 02:15:42.114246      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:15:42.187956 24 exec_util.go:108] Exec stderr: ""
  STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount @ 01/15/25 02:15:42.188
  I0115 02:15:42.188120 24 exec_util.go:59] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-334 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0115 02:15:42.188142 24 exec_util.go:64] ExecWithOptions: Clientset creation
  I0115 02:15:42.188228 24 exec_util.go:80] ExecWithOptions: execute(POST https://169.169.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-334/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&stderr=true&stdout=true)
  I0115 02:15:42.318748 24 exec_util.go:108] Exec stderr: ""
  I0115 02:15:42.318875 24 exec_util.go:59] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-334 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0115 02:15:42.318905 24 exec_util.go:64] ExecWithOptions: Clientset creation
  I0115 02:15:42.319033 24 exec_util.go:80] ExecWithOptions: execute(POST https://169.169.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-334/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&stderr=true&stdout=true)
  I0115 02:15:42.522843 24 exec_util.go:108] Exec stderr: ""
  STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true @ 01/15/25 02:15:42.523
  I0115 02:15:42.523116 24 exec_util.go:59] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-334 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0115 02:15:42.523161 24 exec_util.go:64] ExecWithOptions: Clientset creation
  I0115 02:15:42.523274 24 exec_util.go:80] ExecWithOptions: execute(POST https://169.169.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-334/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&stderr=true&stdout=true)
  I0115 02:15:42.673247 24 exec_util.go:108] Exec stderr: ""
  I0115 02:15:42.673469 24 exec_util.go:59] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-334 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0115 02:15:42.673507 24 exec_util.go:64] ExecWithOptions: Clientset creation
  I0115 02:15:42.673665 24 exec_util.go:80] ExecWithOptions: execute(POST https://169.169.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-334/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&stderr=true&stdout=true)
  I0115 02:15:42.791019 24 exec_util.go:108] Exec stderr: ""
  I0115 02:15:42.791153 24 exec_util.go:59] ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-334 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0115 02:15:42.791181 24 exec_util.go:64] ExecWithOptions: Clientset creation
  I0115 02:15:42.791313 24 exec_util.go:80] ExecWithOptions: execute(POST https://169.169.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-334/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&stderr=true&stdout=true)
  I0115 02:15:42.950362 24 exec_util.go:108] Exec stderr: ""
  I0115 02:15:42.950541 24 exec_util.go:59] ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-334 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0115 02:15:42.950581 24 exec_util.go:64] ExecWithOptions: Clientset creation
  I0115 02:15:42.950740 24 exec_util.go:80] ExecWithOptions: execute(POST https://169.169.0.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-334/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&stderr=true&stdout=true)
  I0115 02:15:43.079192 24 exec_util.go:108] Exec stderr: ""
  I0115 02:15:43.079659 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "e2e-kubelet-etc-hosts-334" for this suite. @ 01/15/25 02:15:43.089
• [7.461 seconds]
------------------------------
[sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:209
  STEP: Creating a kubernetes client @ 01/15/25 02:15:43.1
  I0115 02:15:43.101038 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  E0115 02:15:43.114792      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Building a namespace api object, basename downward-api @ 01/15/25 02:15:43.117
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:15:43.14
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:15:43.147
  STEP: Creating a pod to test downward API volume plugin @ 01/15/25 02:15:43.153
  E0115 02:15:44.115470      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:15:45.116168      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:15:46.117008      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:15:47.118216      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 02:15:47.193
  I0115 02:15:47.211261 24 output.go:207] Trying to get logs from node 192.168.18.91 pod downwardapi-volume-9f3714b4-d932-4ada-a7f4-632204dc6f02 container client-container: <nil>
  STEP: delete the pod @ 01/15/25 02:15:47.268
  I0115 02:15:47.313674 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-9766" for this suite. @ 01/15/25 02:15:47.325
• [4.255 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment deployment should delete old replica sets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:122
  STEP: Creating a kubernetes client @ 01/15/25 02:15:47.355
  I0115 02:15:47.355638 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename deployment @ 01/15/25 02:15:47.357
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:15:47.379
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:15:47.385
  I0115 02:15:47.403439 24 resource.go:87] Pod name cleanup-pod: Found 0 pods out of 1
  E0115 02:15:48.118524      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:15:49.120396      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:15:50.120579      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:15:51.121475      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:15:52.121576      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:15:52.410965 24 resource.go:87] Pod name cleanup-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 01/15/25 02:15:52.411
  I0115 02:15:52.411126 24 deployment.go:841] Creating deployment test-cleanup-deployment
  STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up @ 01/15/25 02:15:52.423
  E0115 02:15:53.121999      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:15:54.122695      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:15:54.452085 24 deployment.go:633] Deployment "test-cleanup-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=23) "test-cleanup-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-3658",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "c308ec00-2f1f-4fd0-8a1f-8dd4f6729d4e",
      ResourceVersion: (string) (len=6) "172318",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872504152,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504152,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=637) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 61  67 6e 68 6f 73 74 5c 22  |me\":\"agnhost\"|
              00000160  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000170  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000180  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000190  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              000001a0  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              000001b0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001c0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              000001d0  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              000001e0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001f0  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000200  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              00000210  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              00000220  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              00000230  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000270  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504153,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=11) "cleanup-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=11) "cleanup-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.53",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(0),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504152,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504152,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504153,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504152,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=76) "ReplicaSet \"test-cleanup-deployment-69b989f764\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0115 02:15:54.463617 24 deployment.go:40] New ReplicaSet "test-cleanup-deployment-69b989f764" of Deployment "test-cleanup-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=34) "test-cleanup-deployment-69b989f764",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-3658",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "8128527d-9279-4901-9012-ff347f46ddc0",
      ResourceVersion: (string) (len=6) "172307",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872504152,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "69b989f764"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=23) "test-cleanup-deployment",
          UID: (types.UID) (len=36) "c308ec00-2f1f-4fd0-8a1f-8dd4f6729d4e",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504152,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 63 33 30 38 65 63  30 30 2d 32 66 31 66 2d  |\"c308ec00-2f1f-|
              00000120  34 66 64 30 2d 38 61 31  66 2d 38 64 64 34 66 36  |4fd0-8a1f-8dd4f6|
              00000130  37 32 39 64 34 65 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |729d4e\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504153,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=11) "cleanup-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "69b989f764"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=11) "cleanup-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "69b989f764"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.53",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0115 02:15:54.500346 24 deployment.go:68] Pod "test-cleanup-deployment-69b989f764-b9fpc" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=40) "test-cleanup-deployment-69b989f764-b9fpc",
      GenerateName: (string) (len=35) "test-cleanup-deployment-69b989f764-",
      Namespace: (string) (len=15) "deployment-3658",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "1cdd1082-a8f1-4d99-b538-c57003ec499a",
      ResourceVersion: (string) (len=6) "172306",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872504152,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "69b989f764"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "c56265bae3494fdf5a3b65c569a713d5c1504f829cdf42fe391eb2f3ac70ae34",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=14) "10.1.155.23/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=14) "10.1.155.23/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=34) "test-cleanup-deployment-69b989f764",
          UID: (types.UID) (len=36) "8128527d-9279-4901-9012-ff347f46ddc0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504152,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 31  32 38 35 32 37 64 2d 39  |d\":\"8128527d-9|
              00000090  32 37 39 2d 34 39 30 31  2d 39 30 31 32 2d 66 66  |279-4901-9012-ff|
              000000a0  33 34 37 66 34 36 64 64  63 30 5c 22 7d 22 3a 7b  |347f46ddc0\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504153,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504153,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 31 2e 31 35 35 2e 32  33 5c 22 7d 22 3a 7b 22  |.1.155.23\"}":{"|
              00000270  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000280  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000290  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-8ljkw",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.53",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-8ljkw",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=13) "192.168.18.92",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504153,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504152,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504153,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504153,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504152,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "192.168.18.92",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "192.168.18.92"
        }
      },
      PodIP: (string) (len=11) "10.1.155.23",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.1.155.23"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872504152,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63872504153,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.53",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:99c6b4bb4a1e1df3f0b3752168c89358794d02258ebebc26bf21c29399011a85",
          ContainerID: (string) (len=77) "containerd://c08d1cb0d456603f54f4401230c9e1fb477fb93a38856e58990d5551bf20d77c",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-8ljkw",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0115 02:15:54.509788 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-3658" for this suite. @ 01/15/25 02:15:54.549
• [7.219 seconds]
------------------------------
[sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:62
  STEP: Creating a kubernetes client @ 01/15/25 02:15:54.574
  I0115 02:15:54.574804 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename containers @ 01/15/25 02:15:54.576
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:15:54.606
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:15:54.613
  STEP: Creating a pod to test override arguments @ 01/15/25 02:15:54.621
  E0115 02:15:55.125628      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:15:56.127766      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:15:57.127624      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:15:58.128663      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 02:15:58.676
  I0115 02:15:58.686073 24 output.go:207] Trying to get logs from node 192.168.18.92 pod client-containers-35e80bfe-c67f-4aed-8949-0b0f65e4a903 container agnhost-container: <nil>
  STEP: delete the pod @ 01/15/25 02:15:58.701
  I0115 02:15:58.720670 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-8682" for this suite. @ 01/15/25 02:15:58.727
• [4.161 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:51
  STEP: Creating a kubernetes client @ 01/15/25 02:15:58.736
  I0115 02:15:58.736376 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename crd-watch @ 01/15/25 02:15:58.738
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:15:58.756
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:15:58.763
  I0115 02:15:58.770483 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  E0115 02:15:59.129703      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:16:00.130678      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:16:01.131872      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Creating first CR  @ 01/15/25 02:16:01.378
  I0115 02:16:01.393990 24 watch.go:431] Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2025-01-15T02:16:01Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2025-01-15T02:16:01Z]] name:name1 resourceVersion:172399 uid:215f4d06-fca1-4ebe-800d-40bede7784b4] num:map[num1:9223372036854775807 num2:1000000]]}
  E0115 02:16:02.132506      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:16:03.133548      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:16:04.135087      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:16:05.135146      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:16:06.140819      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:16:07.141340      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:16:08.141733      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:16:09.142660      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:16:10.143431      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:16:11.144509      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Creating second CR @ 01/15/25 02:16:11.395
  I0115 02:16:11.414954 24 watch.go:431] Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2025-01-15T02:16:11Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2025-01-15T02:16:11Z]] name:name2 resourceVersion:172424 uid:0cbea0bb-3765-4020-9a66-83f570b606ab] num:map[num1:9223372036854775807 num2:1000000]]}
  E0115 02:16:12.146120      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:16:13.147347      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:16:14.148932      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:16:15.152520      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:16:16.153463      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:16:17.153445      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:16:18.153981      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:16:19.154994      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:16:20.155854      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:16:21.156753      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Modifying first CR @ 01/15/25 02:16:21.417
  I0115 02:16:21.422680 24 watch.go:431] Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2025-01-15T02:16:01Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2025-01-15T02:16:21Z]] name:name1 resourceVersion:172439 uid:215f4d06-fca1-4ebe-800d-40bede7784b4] num:map[num1:9223372036854775807 num2:1000000]]}
  E0115 02:16:22.158310      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:16:23.160024      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:16:24.161210      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:16:25.162311      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:16:26.162603      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:16:27.163170      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:16:28.163885      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:16:29.164707      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:16:30.167617      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:16:31.170415      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Modifying second CR @ 01/15/25 02:16:31.423
  I0115 02:16:31.456287 24 watch.go:431] Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2025-01-15T02:16:11Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2025-01-15T02:16:31Z]] name:name2 resourceVersion:172454 uid:0cbea0bb-3765-4020-9a66-83f570b606ab] num:map[num1:9223372036854775807 num2:1000000]]}
  E0115 02:16:32.171246      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:16:33.172457      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:16:34.173938      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:16:35.174956      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:16:36.176037      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:16:37.177069      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:16:38.177483      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:16:39.178898      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:16:40.178944      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:16:41.179998      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Deleting first CR @ 01/15/25 02:16:41.458
  I0115 02:16:41.466953 24 watch.go:431] Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2025-01-15T02:16:01Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2025-01-15T02:16:21Z]] name:name1 resourceVersion:172469 uid:215f4d06-fca1-4ebe-800d-40bede7784b4] num:map[num1:9223372036854775807 num2:1000000]]}
  E0115 02:16:42.182746      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:16:43.183755      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:16:44.183944      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:16:45.186368      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:16:46.187667      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:16:47.189298      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:16:48.189303      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:16:49.190317      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:16:50.190596      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:16:51.191668      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Deleting second CR @ 01/15/25 02:16:51.467
  I0115 02:16:51.479976 24 watch.go:431] Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2025-01-15T02:16:11Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2025-01-15T02:16:31Z]] name:name2 resourceVersion:172484 uid:0cbea0bb-3765-4020-9a66-83f570b606ab] num:map[num1:9223372036854775807 num2:1000000]]}
  E0115 02:16:52.192589      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:16:53.193709      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:16:54.195139      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:16:55.215380      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:16:56.215926      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:16:57.216853      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:16:58.218000      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:16:59.218568      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:17:00.219589      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:17:01.220264      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:17:01.994769 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-watch-3933" for this suite. @ 01/15/25 02:17:02
• [63.270 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:184
  STEP: Creating a kubernetes client @ 01/15/25 02:17:02.006
  I0115 02:17:02.006551 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename container-probe @ 01/15/25 02:17:02.007
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:17:02.022
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:17:02.026
  STEP: Creating pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020 @ 01/15/25 02:17:02.032
  E0115 02:17:02.220067      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:17:03.222604      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 01/15/25 02:17:04.059
  I0115 02:17:04.066542 24 container_probe.go:1749] Initial restart count of pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 is 0
  I0115 02:17:04.076204 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:17:04.223120      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:17:05.224064      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:17:06.087840 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:17:06.226712      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:17:07.227209      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:17:08.093705 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:17:08.228027      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:17:09.229865      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:17:10.108266 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:17:10.231207      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:17:11.231880      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:17:12.113934 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:17:12.232259      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:17:13.238646      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:17:14.132366 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:17:14.239885      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:17:15.240109      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:17:16.137874 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:17:16.240217      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:17:17.240784      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:17:18.143920 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:17:18.243139      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:17:19.244581      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:17:20.150648 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:17:20.245803      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:17:21.245873      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:17:22.156929 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:17:22.246427      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:17:23.247213      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:17:24.161355 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:17:24.248241      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:17:25.249068      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:17:26.165203 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:17:26.250900      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:17:27.251214      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:17:28.176076 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:17:28.253564      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:17:29.254605      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:17:30.180772 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:17:30.255132      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:17:31.255473      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:17:32.187068 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:17:32.258024      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:17:33.258078      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:17:34.199159 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:17:34.267339      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:17:35.268333      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:17:36.204918 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:17:36.268250      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:17:37.269103      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:17:38.216527 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:17:38.270322      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:17:39.271860      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:17:40.230916 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:17:40.272924      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:17:41.273347      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:17:42.235069 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:17:42.273691      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:17:43.274669      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:17:44.241600 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:17:44.276503      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:17:45.277603      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:17:46.249481 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:17:46.279802      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:17:47.280784      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:17:48.253230 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:17:48.282082      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:17:49.283680      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:17:50.261008 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:17:50.284362      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:17:51.284615      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:17:52.266373 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:17:52.284947      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:17:53.286109      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:17:54.273609 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:17:54.287476      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:17:55.288126      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:17:56.282336 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:17:56.289333      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:17:57.290928      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:17:58.291783      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:17:58.309716 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:17:59.294944      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:18:00.295415      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:18:00.315500 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:18:01.295972      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:18:02.297536      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:18:02.327419 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:18:03.298391      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:18:04.299645      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:18:04.333290 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:18:05.299777      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:18:06.300154      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:18:06.337616 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:18:07.300919      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:18:08.300914      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:18:08.348363 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:18:09.301607      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:18:10.302880      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:18:10.354104 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:18:11.304287      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:18:12.305448      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:18:12.359143 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:18:13.306534      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:18:14.307907      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:18:14.363603 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:18:15.309945      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:18:16.311248      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:18:16.378869 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:18:17.313213      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:18:18.313254      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:18:18.390405 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:18:19.325658      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:18:20.326102      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:18:20.399758 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:18:21.327280      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:18:22.329369      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:18:22.405218 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:18:23.332149      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:18:24.335578      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:18:24.423873 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:18:25.336793      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:18:26.337891      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:18:26.436113 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:18:27.339353      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:18:28.341248      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:18:28.441084 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:18:29.344379      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:18:30.344281      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:18:30.445460 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:18:31.345171      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:18:32.346530      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:18:32.463867 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:18:33.347176      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:18:34.348013      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:18:34.469142 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:18:35.349042      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:18:36.351107      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:18:36.488767 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:18:37.351026      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:18:38.353068      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:18:38.502703 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:18:39.355519      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:18:40.355587      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:18:40.505836 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:18:41.356636      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:18:42.357665      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:18:42.510680 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:18:43.359271      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:18:44.360149      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:18:44.520979 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:18:45.361288      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:18:46.362107      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:18:46.538956 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:18:47.362233      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:18:48.362942      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:18:48.550910 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:18:49.365214      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:18:50.365298      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:18:50.565143 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:18:51.366338      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:18:52.366595      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:18:52.569104 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:18:53.366892      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:18:54.370522      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:18:54.583294 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:18:55.371532      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:18:56.373149      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:18:56.592327 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:18:57.374339      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:18:58.374903      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:18:58.596284 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:18:59.375284      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:19:00.376581      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:19:00.604791 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:19:01.377248      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:19:02.378861      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:19:02.631715 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:19:03.388166      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:19:04.388842      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:19:04.638663 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:19:05.389593      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:19:06.392210      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:19:06.643901 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:19:07.393107      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:19:08.393778      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:19:08.650120 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:19:09.395162      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:19:10.396304      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:19:10.653784 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:19:11.396580      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:19:12.397439      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:19:12.671545 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:19:13.398951      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:19:14.400756      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:19:14.699037 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:19:15.401121      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:19:16.401918      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:19:16.707082 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:19:17.403284      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:19:18.403607      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:19:18.712655 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:19:19.404950      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:19:20.405776      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:19:20.721717 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:19:21.406382      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:19:22.407004      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:19:22.734700 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:19:23.408173      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:19:24.409810      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:19:24.756997 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:19:25.410585      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:19:26.411018      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:19:26.762125 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:19:27.411462      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:19:28.412282      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:19:28.766340 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:19:29.412562      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:19:30.413745      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:19:30.777949 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:19:31.414224      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:19:32.415070      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:19:32.783309 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:19:33.415257      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:19:34.416193      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:19:34.788363 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:19:35.417367      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:19:36.419209      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:19:36.797432 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:19:37.426481      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:19:38.427215      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:19:38.809165 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:19:39.427753      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:19:40.428504      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:19:40.813054 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:19:41.430334      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:19:42.430902      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:19:42.818486 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:19:43.436287      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:19:44.433034      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:19:44.833342 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:19:45.434714      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:19:46.435919      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:19:46.842141 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:19:47.437019      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:19:48.437696      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:19:48.852405 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:19:49.437708      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:19:50.438926      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:19:50.865950 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:19:51.439442      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:19:52.440847      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:19:52.875665 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:19:53.441817      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:19:54.442710      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:19:54.881253 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:19:55.445308      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:19:56.445904      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:19:56.885643 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:19:57.447386      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:19:58.448414      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:19:58.891013 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:19:59.448827      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:20:00.450000      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:20:00.905498 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:20:01.450721      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:20:02.452263      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:20:02.910003 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:20:03.453674      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:20:04.454309      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:20:04.915052 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:20:05.455623      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:20:06.457187      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:20:06.927543 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:20:07.457924      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:20:08.458988      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:20:08.945053 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:20:09.459361      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:20:10.470037      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:20:10.973898 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:20:11.471593      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:20:12.472518      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:20:12.990668 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:20:13.472777      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:20:14.475863      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:20:15.008825 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:20:15.476774      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:20:16.477500      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:20:17.014282 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:20:17.479206      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:20:18.480286      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:20:19.035209 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:20:19.481164      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:20:20.481918      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:20:21.039054 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:20:21.481913      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:20:22.484081      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:20:23.062070 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:20:23.485890      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:20:24.486786      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:20:25.066047 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:20:25.487096      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:20:26.487691      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:20:27.082313 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:20:27.488269      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:20:28.489342      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:20:29.086891 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:20:29.490091      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:20:30.491554      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:20:31.105026 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:20:31.491815      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:20:32.493805      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:20:33.117547 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:20:33.496917      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:20:34.499902      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:20:35.128348 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:20:35.501053      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:20:36.501414      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:20:37.134390 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:20:37.502575      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:20:38.504131      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:20:39.155853 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:20:39.507084      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:20:40.508951      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:20:41.162382 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:20:41.509525      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:20:42.510045      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:20:43.167704 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:20:43.510442      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:20:44.512334      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:20:45.171465 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:20:45.513172      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:20:46.513434      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:20:47.196513 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:20:47.514254      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:20:48.514851      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:20:49.201610 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:20:49.515364      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:20:50.516503      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:20:51.205341 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:20:51.516917      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:20:52.518953      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:20:53.221628 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:20:53.519833      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:20:54.520894      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:20:55.265275 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:20:55.521638      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:20:56.527249      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:20:57.277445 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:20:57.528133      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:20:58.528685      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:20:59.282768 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:20:59.528800      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:21:00.529904      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:21:01.313918 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:21:01.530976      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:21:02.536021      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:21:03.333123 24 container_probe.go:1759] Get pod liveness-40cedcdf-c91b-41ea-9904-88a9fe116169 in namespace container-probe-6020
  E0115 02:21:03.536512      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:21:04.537748      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: deleting the pod @ 01/15/25 02:21:05.334
  I0115 02:21:05.395810 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-6020" for this suite. @ 01/15/25 02:21:05.413
• [243.425 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:861
  STEP: Creating a kubernetes client @ 01/15/25 02:21:05.432
  I0115 02:21:05.432256 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename job @ 01/15/25 02:21:05.433
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:21:05.45
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:21:05.456
  STEP: Creating a job @ 01/15/25 02:21:05.462
  STEP: Ensuring active pods == parallelism @ 01/15/25 02:21:05.47
  E0115 02:21:05.538408      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:21:06.539233      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Orphaning one of the Job's Pods @ 01/15/25 02:21:07.481
  E0115 02:21:07.540650      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:21:08.044655 24 pod_client.go:173] Successfully updated pod "adopt-release-m9t7x"
  STEP: Checking that the Job readopts the Pod @ 01/15/25 02:21:08.056
  E0115 02:21:08.541637      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:21:09.542104      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Removing the labels from the Job's Pod @ 01/15/25 02:21:10.099
  E0115 02:21:10.542780      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:21:10.611378 24 pod_client.go:173] Successfully updated pod "adopt-release-m9t7x"
  STEP: Checking that the Job releases the Pod @ 01/15/25 02:21:10.611
  E0115 02:21:11.543425      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:21:12.544380      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:21:12.620226 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-465" for this suite. @ 01/15/25 02:21:12.625
• [7.202 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a GRPC liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:551
  STEP: Creating a kubernetes client @ 01/15/25 02:21:12.634
  I0115 02:21:12.634338 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename container-probe @ 01/15/25 02:21:12.635
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:21:12.648
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:21:12.652
  STEP: Creating pod test-grpc-a546b771-4c07-47ae-9f45-3581f49edab5 in namespace container-probe-7920 @ 01/15/25 02:21:12.656
  E0115 02:21:13.547907      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:21:14.546962      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 01/15/25 02:21:14.673
  I0115 02:21:14.676796 24 container_probe.go:1749] Initial restart count of pod test-grpc-a546b771-4c07-47ae-9f45-3581f49edab5 is 0
  I0115 02:21:14.680034 24 container_probe.go:1759] Get pod test-grpc-a546b771-4c07-47ae-9f45-3581f49edab5 in namespace container-probe-7920
  E0115 02:21:15.547817      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:21:16.548572      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:21:16.686332 24 container_probe.go:1759] Get pod test-grpc-a546b771-4c07-47ae-9f45-3581f49edab5 in namespace container-probe-7920
  E0115 02:21:17.548923      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:21:18.550120      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:21:18.690124 24 container_probe.go:1759] Get pod test-grpc-a546b771-4c07-47ae-9f45-3581f49edab5 in namespace container-probe-7920
  E0115 02:21:19.551234      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:21:20.551785      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:21:20.693704 24 container_probe.go:1759] Get pod test-grpc-a546b771-4c07-47ae-9f45-3581f49edab5 in namespace container-probe-7920
  E0115 02:21:21.552883      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:21:22.553416      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:21:22.709375 24 container_probe.go:1759] Get pod test-grpc-a546b771-4c07-47ae-9f45-3581f49edab5 in namespace container-probe-7920
  E0115 02:21:23.553759      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:21:24.555220      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:21:24.725966 24 container_probe.go:1759] Get pod test-grpc-a546b771-4c07-47ae-9f45-3581f49edab5 in namespace container-probe-7920
  E0115 02:21:25.556032      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:21:26.557122      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:21:26.732066 24 container_probe.go:1759] Get pod test-grpc-a546b771-4c07-47ae-9f45-3581f49edab5 in namespace container-probe-7920
  E0115 02:21:27.557624      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:21:28.558865      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:21:28.736941 24 container_probe.go:1759] Get pod test-grpc-a546b771-4c07-47ae-9f45-3581f49edab5 in namespace container-probe-7920
  E0115 02:21:29.559160      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:21:30.561030      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:21:30.742594 24 container_probe.go:1759] Get pod test-grpc-a546b771-4c07-47ae-9f45-3581f49edab5 in namespace container-probe-7920
  E0115 02:21:31.561730      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:21:32.562504      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:21:32.749192 24 container_probe.go:1759] Get pod test-grpc-a546b771-4c07-47ae-9f45-3581f49edab5 in namespace container-probe-7920
  E0115 02:21:33.563896      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:21:34.564242      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:21:34.764850 24 container_probe.go:1759] Get pod test-grpc-a546b771-4c07-47ae-9f45-3581f49edab5 in namespace container-probe-7920
  E0115 02:21:35.566153      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:21:36.568074      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:21:36.778400 24 container_probe.go:1759] Get pod test-grpc-a546b771-4c07-47ae-9f45-3581f49edab5 in namespace container-probe-7920
  E0115 02:21:37.569446      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:21:38.571264      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:21:38.791819 24 container_probe.go:1759] Get pod test-grpc-a546b771-4c07-47ae-9f45-3581f49edab5 in namespace container-probe-7920
  E0115 02:21:39.573437      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:21:40.575859      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:21:40.805714 24 container_probe.go:1759] Get pod test-grpc-a546b771-4c07-47ae-9f45-3581f49edab5 in namespace container-probe-7920
  E0115 02:21:41.576154      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:21:42.578759      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:21:42.826525 24 container_probe.go:1759] Get pod test-grpc-a546b771-4c07-47ae-9f45-3581f49edab5 in namespace container-probe-7920
  E0115 02:21:43.588092      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:21:44.582922      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:21:44.830146 24 container_probe.go:1759] Get pod test-grpc-a546b771-4c07-47ae-9f45-3581f49edab5 in namespace container-probe-7920
  E0115 02:21:45.583731      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:21:46.585068      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:21:46.843276 24 container_probe.go:1759] Get pod test-grpc-a546b771-4c07-47ae-9f45-3581f49edab5 in namespace container-probe-7920
  E0115 02:21:47.585913      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:21:48.587334      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:21:48.854231 24 container_probe.go:1759] Get pod test-grpc-a546b771-4c07-47ae-9f45-3581f49edab5 in namespace container-probe-7920
  E0115 02:21:49.587839      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:21:50.589987      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:21:50.858437 24 container_probe.go:1759] Get pod test-grpc-a546b771-4c07-47ae-9f45-3581f49edab5 in namespace container-probe-7920
  E0115 02:21:51.590688      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:21:52.591688      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:21:52.864884 24 container_probe.go:1759] Get pod test-grpc-a546b771-4c07-47ae-9f45-3581f49edab5 in namespace container-probe-7920
  E0115 02:21:53.593713      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:21:54.594728      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:21:54.870092 24 container_probe.go:1759] Get pod test-grpc-a546b771-4c07-47ae-9f45-3581f49edab5 in namespace container-probe-7920
  E0115 02:21:55.596129      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:21:56.597185      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:21:56.874505 24 container_probe.go:1759] Get pod test-grpc-a546b771-4c07-47ae-9f45-3581f49edab5 in namespace container-probe-7920
  E0115 02:21:57.597469      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:21:58.598676      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:21:58.891174 24 container_probe.go:1759] Get pod test-grpc-a546b771-4c07-47ae-9f45-3581f49edab5 in namespace container-probe-7920
  E0115 02:21:59.599465      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:22:00.600675      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:22:00.897754 24 container_probe.go:1759] Get pod test-grpc-a546b771-4c07-47ae-9f45-3581f49edab5 in namespace container-probe-7920
  E0115 02:22:01.602574      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:22:02.604652      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:22:02.906052 24 container_probe.go:1759] Get pod test-grpc-a546b771-4c07-47ae-9f45-3581f49edab5 in namespace container-probe-7920
  E0115 02:22:03.605650      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:22:04.606605      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:22:04.922226 24 container_probe.go:1759] Get pod test-grpc-a546b771-4c07-47ae-9f45-3581f49edab5 in namespace container-probe-7920
  E0115 02:22:05.612974      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:22:06.613879      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:22:06.932458 24 container_probe.go:1759] Get pod test-grpc-a546b771-4c07-47ae-9f45-3581f49edab5 in namespace container-probe-7920
  E0115 02:22:07.616040      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:22:08.616347      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:22:08.955389 24 container_probe.go:1759] Get pod test-grpc-a546b771-4c07-47ae-9f45-3581f49edab5 in namespace container-probe-7920
  E0115 02:22:09.618524      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:22:10.619639      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:22:10.968290 24 container_probe.go:1759] Get pod test-grpc-a546b771-4c07-47ae-9f45-3581f49edab5 in namespace container-probe-7920
  E0115 02:22:11.619960      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:22:12.620146      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:22:12.972085 24 container_probe.go:1759] Get pod test-grpc-a546b771-4c07-47ae-9f45-3581f49edab5 in namespace container-probe-7920
  E0115 02:22:13.621112      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:22:14.623648      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:22:14.976846 24 container_probe.go:1759] Get pod test-grpc-a546b771-4c07-47ae-9f45-3581f49edab5 in namespace container-probe-7920
  E0115 02:22:15.625889      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:22:16.626968      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:22:16.988861 24 container_probe.go:1759] Get pod test-grpc-a546b771-4c07-47ae-9f45-3581f49edab5 in namespace container-probe-7920
  E0115 02:22:17.627974      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:22:18.628498      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:22:18.993267 24 container_probe.go:1759] Get pod test-grpc-a546b771-4c07-47ae-9f45-3581f49edab5 in namespace container-probe-7920
  E0115 02:22:19.629186      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:22:20.630774      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:22:21.008858 24 container_probe.go:1759] Get pod test-grpc-a546b771-4c07-47ae-9f45-3581f49edab5 in namespace container-probe-7920
  E0115 02:22:21.632279      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:22:22.634205      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:22:23.035775 24 container_probe.go:1759] Get pod test-grpc-a546b771-4c07-47ae-9f45-3581f49edab5 in namespace container-probe-7920
  E0115 02:22:23.635393      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:22:24.636688      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:22:25.051092 24 container_probe.go:1759] Get pod test-grpc-a546b771-4c07-47ae-9f45-3581f49edab5 in namespace container-probe-7920
  E0115 02:22:25.637467      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:22:26.639975      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:22:27.063212 24 container_probe.go:1759] Get pod test-grpc-a546b771-4c07-47ae-9f45-3581f49edab5 in namespace container-probe-7920
  E0115 02:22:27.640261      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:22:28.642777      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:22:29.079190 24 container_probe.go:1759] Get pod test-grpc-a546b771-4c07-47ae-9f45-3581f49edab5 in namespace container-probe-7920
  I0115 02:22:29.079671 24 container_probe.go:1763] Restart count of pod container-probe-7920/test-grpc-a546b771-4c07-47ae-9f45-3581f49edab5 is now 1 (1m14.402810127s elapsed)
  STEP: deleting the pod @ 01/15/25 02:22:29.08
  I0115 02:22:29.121090 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-7920" for this suite. @ 01/15/25 02:22:29.135
• [76.519 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should support RuntimeClasses API operations [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:191
  STEP: Creating a kubernetes client @ 01/15/25 02:22:29.153
  I0115 02:22:29.153671 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename runtimeclass @ 01/15/25 02:22:29.154
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:22:29.217
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:22:29.237
  STEP: getting /apis @ 01/15/25 02:22:29.243
  STEP: getting /apis/node.k8s.io @ 01/15/25 02:22:29.251
  STEP: getting /apis/node.k8s.io/v1 @ 01/15/25 02:22:29.254
  STEP: creating @ 01/15/25 02:22:29.256
  STEP: watching @ 01/15/25 02:22:29.277
  I0115 02:22:29.277165 24 runtimeclass.go:275] starting watch
  STEP: getting @ 01/15/25 02:22:29.285
  STEP: listing @ 01/15/25 02:22:29.288
  STEP: patching @ 01/15/25 02:22:29.291
  STEP: updating @ 01/15/25 02:22:29.296
  I0115 02:22:29.300152 24 runtimeclass.go:305] waiting for watch events with expected annotations
  STEP: deleting @ 01/15/25 02:22:29.3
  STEP: deleting a collection @ 01/15/25 02:22:29.309
  I0115 02:22:29.319594 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-5680" for this suite. @ 01/15/25 02:22:29.323
• [0.175 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:105
  STEP: Creating a kubernetes client @ 01/15/25 02:22:29.329
  I0115 02:22:29.329230 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename subpath @ 01/15/25 02:22:29.329
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:22:29.342
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:22:29.346
  STEP: Setting up data @ 01/15/25 02:22:29.349
  STEP: Creating pod pod-subpath-test-projected-48pf @ 01/15/25 02:22:29.357
  STEP: Creating a pod to test atomic-volume-subpath @ 01/15/25 02:22:29.357
  E0115 02:22:29.643726      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:22:30.645798      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:22:31.646250      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:22:32.646984      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:22:33.647449      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:22:34.650181      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:22:35.650453      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:22:36.651561      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:22:37.652895      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:22:38.653682      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:22:39.654174      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:22:40.655198      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:22:41.658093      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:22:42.660494      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:22:43.660399      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:22:44.661285      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:22:45.662945      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:22:46.664259      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:22:47.665351      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:22:48.666153      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:22:49.668151      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:22:50.669485      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:22:51.670839      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:22:52.670659      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 02:22:53.482
  I0115 02:22:53.499090 24 output.go:207] Trying to get logs from node 192.168.18.92 pod pod-subpath-test-projected-48pf container test-container-subpath-projected-48pf: <nil>
  STEP: delete the pod @ 01/15/25 02:22:53.548
  STEP: Deleting pod pod-subpath-test-projected-48pf @ 01/15/25 02:22:53.561
  I0115 02:22:53.561140 24 delete.go:62] Deleting pod "pod-subpath-test-projected-48pf" in namespace "subpath-4239"
  I0115 02:22:53.564165 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-4239" for this suite. @ 01/15/25 02:22:53.57
• [24.246 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:771
  STEP: Creating a kubernetes client @ 01/15/25 02:22:53.576
  I0115 02:22:53.576051 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename svcaccounts @ 01/15/25 02:22:53.577
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:22:53.591
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:22:53.596
  I0115 02:22:53.606902 24 service_accounts.go:783] Got root ca configmap in namespace "svcaccounts-577"
  I0115 02:22:53.612522 24 service_accounts.go:786] Deleted root ca configmap in namespace "svcaccounts-577"
  E0115 02:22:53.671272      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: waiting for a new root ca configmap created @ 01/15/25 02:22:54.112
  I0115 02:22:54.125695 24 service_accounts.go:800] Recreated root ca configmap in namespace "svcaccounts-577"
  I0115 02:22:54.146604 24 service_accounts.go:811] Updated root ca configmap in namespace "svcaccounts-577"
  STEP: waiting for the root ca configmap reconciled @ 01/15/25 02:22:54.647
  I0115 02:22:54.658131 24 service_accounts.go:829] Reconciled root ca configmap in namespace "svcaccounts-577"
  I0115 02:22:54.658868 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  E0115 02:22:54.671781      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Destroying namespace "svcaccounts-577" for this suite. @ 01/15/25 02:22:54.675
• [1.117 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:67
  STEP: Creating a kubernetes client @ 01/15/25 02:22:54.696
  I0115 02:22:54.696450 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename projected @ 01/15/25 02:22:54.699
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:22:54.739
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:22:54.752
  STEP: Creating projection with secret that has name projected-secret-test-fb5243e3-6833-4422-9e6d-7a496e64148b @ 01/15/25 02:22:54.759
  STEP: Creating a pod to test consume secrets @ 01/15/25 02:22:54.766
  E0115 02:22:55.673265      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:22:56.674811      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:22:57.680238      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:22:58.680680      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 02:22:58.802
  I0115 02:22:58.806048 24 output.go:207] Trying to get logs from node 192.168.18.92 pod pod-projected-secrets-7b2894fd-bcc5-4263-a1da-37e49f687d48 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 01/15/25 02:22:58.814
  I0115 02:22:58.828672 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3850" for this suite. @ 01/15/25 02:22:58.832
• [4.144 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance] [sig-apps, Slow, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:97
  STEP: Creating a kubernetes client @ 01/15/25 02:22:58.839
  I0115 02:22:58.839545 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename cronjob @ 01/15/25 02:22:58.841
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:22:58.858
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:22:58.862
  STEP: Creating a suspended cronjob @ 01/15/25 02:22:58.866
  STEP: Ensuring no jobs are scheduled @ 01/15/25 02:22:58.872
  E0115 02:22:59.681171      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:00.682236      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:01.685863      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:02.686377      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:03.687328      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:04.688351      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:05.689042      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:06.689554      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:07.693122      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:08.694417      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:09.694861      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:10.696313      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:11.697232      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:12.697880      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:13.698437      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:14.699263      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:15.700360      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:16.701808      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:17.702444      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:18.703297      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:19.703812      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:20.705773      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:21.706837      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:22.707486      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:23.707794      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:24.708548      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:25.709918      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:26.711464      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:27.712336      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:28.713863      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:29.714607      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:30.716326      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:31.716812      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:32.718058      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:33.719493      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:34.722091      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:35.723436      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:36.724292      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:37.725243      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:38.726384      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:39.726912      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:40.727695      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:41.728787      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:42.730355      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:43.731541      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:44.731386      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:45.732557      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:46.733430      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:47.734615      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:48.737308      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:49.737072      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:50.738919      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:51.739625      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:52.741121      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:53.741557      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:54.743008      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:55.743833      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:56.745307      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:57.747125      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:58.748157      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:23:59.748256      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:00.750070      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:01.750273      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:02.751212      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:03.751928      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:04.753726      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:05.753626      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:06.754505      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:07.755464      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:08.755591      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:09.756768      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:10.758360      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:11.759769      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:12.761189      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:13.761410      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:14.762328      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:15.763401      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:16.763975      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:17.765252      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:18.766379      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:19.766900      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:20.767780      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:21.768046      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:22.768563      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:23.769836      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:24.771425      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:25.773566      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:26.775166      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:27.777313      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:28.778549      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:29.779199      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:30.780351      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:31.780636      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:32.781392      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:33.782167      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:34.782462      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:35.783301      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:36.784598      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:37.785635      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:38.785984      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:39.786469      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:40.787380      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:41.788675      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:42.790086      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:43.791535      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:44.792817      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:45.793449      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:46.795321      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:47.795656      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:48.797679      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:49.798717      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:50.800545      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:51.800852      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:52.802501      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:53.804791      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:54.805741      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:55.806058      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:56.807008      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:57.807962      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:58.808434      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:24:59.813834      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:00.815772      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:01.818959      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:02.819422      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:03.819981      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:04.823265      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:05.824796      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:06.826038      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:07.826528      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:08.827023      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:09.827158      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:10.829234      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:11.828794      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:12.830218      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:13.830658      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:14.831523      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:15.833291      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:16.834386      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:17.834946      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:18.836675      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:19.836977      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:20.838749      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:21.839030      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:22.839977      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:23.840329      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:24.841877      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:25.842722      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:26.844856      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:27.847528      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:28.851162      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:29.851686      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:30.853069      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:31.853778      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:32.855104      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:33.856718      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:34.857153      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:35.859338      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:36.861385      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:37.863470      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:38.864923      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:39.866445      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:40.867138      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:41.867958      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:42.868423      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:43.870696      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:44.871371      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:45.872797      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:46.874356      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:47.875577      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:48.876934      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:49.877719      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:50.880466      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:51.883307      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:52.884758      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:53.884903      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:54.886883      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:55.888262      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:56.890179      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:57.891404      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:58.892484      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:25:59.893730      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:00.893871      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:01.894584      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:02.895448      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:03.895890      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:04.896946      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:05.897845      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:06.898994      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:07.900462      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:08.900816      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:09.901622      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:10.902513      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:11.906170      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:12.907273      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:13.908935      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:14.910277      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:15.911009      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:16.913390      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:17.914210      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:18.915262      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:19.915887      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:20.915819      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:21.917841      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:22.918268      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:23.920661      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:24.920464      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:25.921089      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:26.921176      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:27.922818      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:28.923746      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:29.925913      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:30.926783      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:31.927580      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:32.929572      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:33.933122      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:34.933838      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:35.934600      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:36.935532      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:37.936418      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:38.937751      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:39.939139      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:40.940366      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:41.941131      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:42.941189      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:43.942299      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:44.943278      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:45.944080      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:46.944832      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:47.946084      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:48.948245      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:49.949229      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:50.950368      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:51.951232      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:52.951970      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:53.953359      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:54.953828      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:55.955524      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:56.956222      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:57.958093      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:58.959076      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:26:59.959879      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:27:00.961130      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:27:01.961536      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:27:02.961821      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:27:03.962880      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:27:04.963728      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:27:05.965260      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:27:06.971176      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:27:07.972754      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:27:08.975163      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:27:09.976214      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:27:10.977292      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:27:11.978229      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:27:12.979075      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:27:13.981054      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:27:14.981198      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:27:15.983995      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:27:16.985379      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:27:17.986095      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:27:18.987323      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:27:19.988094      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:27:20.990066      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:27:21.991357      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:27:22.991680      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:27:23.993218      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:27:24.993970      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:27:25.995153      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:27:26.995322      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:27:27.996541      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:27:28.999035      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:27:30.000750      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:27:31.001748      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:27:32.002407      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:27:33.003487      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:27:34.007465      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:27:35.008783      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:27:36.010278      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:27:37.010012      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:27:38.011187      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:27:39.015105      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:27:40.015176      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:27:41.015449      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:27:42.015760      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:27:43.018563      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:27:44.019190      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:27:45.020479      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:27:46.020629      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:27:47.021026      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:27:48.021030      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:27:49.022541      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:27:50.023016      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:27:51.023021      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:27:52.024946      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:27:53.026202      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:27:54.027209      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:27:55.029068      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:27:56.029423      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:27:57.030518      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:27:58.032984      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Ensuring no job exists by listing jobs explicitly @ 01/15/25 02:27:58.874
  STEP: Removing cronjob @ 01/15/25 02:27:58.882
  I0115 02:27:58.893241 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-6152" for this suite. @ 01/15/25 02:27:58.903
• [300.075 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should adopt matching pods on creation [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:95
  STEP: Creating a kubernetes client @ 01/15/25 02:27:58.915
  I0115 02:27:58.915748 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename replication-controller @ 01/15/25 02:27:58.917
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:27:58.953
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:27:58.961
  STEP: Given a Pod with a 'name' label pod-adoption is created @ 01/15/25 02:27:58.966
  E0115 02:27:59.033864      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:28:00.034443      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: When a replication controller with a matching selector is created @ 01/15/25 02:28:00.993
  STEP: Then the orphan pod is adopted @ 01/15/25 02:28:01.001
  E0115 02:28:01.034609      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:28:02.015632 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-620" for this suite. @ 01/15/25 02:28:02.026
  E0115 02:28:02.035362      24 retrywatcher.go:160] "Watch failed" err="context canceled"
• [3.139 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:58
  STEP: Creating a kubernetes client @ 01/15/25 02:28:02.056
  I0115 02:28:02.056973 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename projected @ 01/15/25 02:28:02.06
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:28:02.121
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:28:02.137
  STEP: Creating configMap with name projected-configmap-test-volume-a40d4859-d5e6-4f28-81ae-b95788c61371 @ 01/15/25 02:28:02.168
  STEP: Creating a pod to test consume configMaps @ 01/15/25 02:28:02.181
  E0115 02:28:03.035275      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:28:04.036183      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:28:05.036977      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:28:06.037617      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 02:28:06.274
  I0115 02:28:06.284841 24 output.go:207] Trying to get logs from node 192.168.18.92 pod pod-projected-configmaps-6f0a1294-f869-493d-88d9-5fb68f675227 container agnhost-container: <nil>
  STEP: delete the pod @ 01/15/25 02:28:06.344
  I0115 02:28:06.383215 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9690" for this suite. @ 01/15/25 02:28:06.396
• [4.362 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be immutable if `immutable` field is set [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:386
  STEP: Creating a kubernetes client @ 01/15/25 02:28:06.425
  I0115 02:28:06.425515 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename secrets @ 01/15/25 02:28:06.427
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:28:06.451
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:28:06.456
  I0115 02:28:06.517874 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-9634" for this suite. @ 01/15/25 02:28:06.522
• [0.106 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-network] Ingress API should support creating Ingress API operations [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/ingress.go:55
  STEP: Creating a kubernetes client @ 01/15/25 02:28:06.531
  I0115 02:28:06.531604 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename ingress @ 01/15/25 02:28:06.532
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:28:06.547
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:28:06.552
  STEP: getting /apis @ 01/15/25 02:28:06.558
  STEP: getting /apis/networking.k8s.io @ 01/15/25 02:28:06.565
  STEP: getting /apis/networking.k8s.iov1 @ 01/15/25 02:28:06.567
  STEP: creating @ 01/15/25 02:28:06.569
  STEP: getting @ 01/15/25 02:28:06.586
  STEP: listing @ 01/15/25 02:28:06.59
  STEP: watching @ 01/15/25 02:28:06.593
  I0115 02:28:06.593500 24 ingress.go:186] starting watch
  STEP: cluster-wide listing @ 01/15/25 02:28:06.595
  STEP: cluster-wide watching @ 01/15/25 02:28:06.6
  I0115 02:28:06.600158 24 ingress.go:198] starting watch
  STEP: patching @ 01/15/25 02:28:06.602
  STEP: updating @ 01/15/25 02:28:06.608
  I0115 02:28:06.618270 24 ingress.go:221] waiting for watch events with expected annotations
  I0115 02:28:06.618454 24 ingress.go:234] saw patched and updated annotations
  STEP: patching /status @ 01/15/25 02:28:06.618
  STEP: updating /status @ 01/15/25 02:28:06.624
  STEP: get /status @ 01/15/25 02:28:06.635
  STEP: deleting @ 01/15/25 02:28:06.639
  STEP: deleting a collection @ 01/15/25 02:28:06.653
  I0115 02:28:06.668407 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingress-1077" for this suite. @ 01/15/25 02:28:06.673
• [0.157 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:205
  STEP: Creating a kubernetes client @ 01/15/25 02:28:06.688
  I0115 02:28:06.688879 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename daemonsets @ 01/15/25 02:28:06.689
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:28:06.706
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:28:06.713
  I0115 02:28:06.791451 24 daemon_set.go:208] Creating daemon "daemon-set" with a node selector
  STEP: Initially, daemon pods should not be running on any nodes. @ 01/15/25 02:28:06.798
  I0115 02:28:06.803149 24 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0115 02:28:06.803193 24 fixtures.go:136] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Change node label to blue, check that daemon pod is launched. @ 01/15/25 02:28:06.803
  I0115 02:28:06.965948 24 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0115 02:28:06.966099 24 fixtures.go:131] Node 192.168.18.92 is running 0 daemon pod, expected 1
  E0115 02:28:07.038303      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:28:07.969102 24 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0115 02:28:07.969183 24 fixtures.go:131] Node 192.168.18.92 is running 0 daemon pod, expected 1
  E0115 02:28:08.038910      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:28:08.943425 24 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0115 02:28:08.943484 24 fixtures.go:131] Node 192.168.18.92 is running 0 daemon pod, expected 1
  E0115 02:28:09.039540      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:28:09.944961 24 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0115 02:28:09.945047 24 fixtures.go:136] Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Update the node label to green, and wait for daemons to be unscheduled @ 01/15/25 02:28:09.953
  I0115 02:28:09.987376 24 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0115 02:28:09.987786 24 fixtures.go:136] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate @ 01/15/25 02:28:09.987
  E0115 02:28:10.040726      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:28:10.045305 24 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0115 02:28:10.045464 24 fixtures.go:131] Node 192.168.18.92 is running 0 daemon pod, expected 1
  I0115 02:28:11.009601 24 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0115 02:28:11.009667 24 fixtures.go:131] Node 192.168.18.92 is running 0 daemon pod, expected 1
  E0115 02:28:11.041092      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:28:12.010365 24 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0115 02:28:12.010453 24 fixtures.go:131] Node 192.168.18.92 is running 0 daemon pod, expected 1
  E0115 02:28:12.041799      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:28:13.012290 24 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0115 02:28:13.012399 24 fixtures.go:131] Node 192.168.18.92 is running 0 daemon pod, expected 1
  E0115 02:28:13.042132      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:28:14.017632 24 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0115 02:28:14.017767 24 fixtures.go:136] Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 01/15/25 02:28:14.042
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7325, will wait for the garbage collector to delete the pods @ 01/15/25 02:28:14.043
  E0115 02:28:14.043673      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:28:14.126458 24 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 20.847437ms
  I0115 02:28:14.227663 24 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 101.211844ms
  E0115 02:28:15.044049      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:28:16.044159      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:28:16.649206 24 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0115 02:28:16.649387 24 fixtures.go:136] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0115 02:28:16.670201 24 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"173884"},"items":null}

  I0115 02:28:16.688932 24 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"173884"},"items":null}

  I0115 02:28:16.991256 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  E0115 02:28:17.048882      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Destroying namespace "daemonsets-7325" for this suite. @ 01/15/25 02:28:17.066
• [10.477 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:70
  STEP: Creating a kubernetes client @ 01/15/25 02:28:17.168
  I0115 02:28:17.168936 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename downward-api @ 01/15/25 02:28:17.175
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:28:17.336
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:28:17.395
  STEP: Creating a pod to test downward API volume plugin @ 01/15/25 02:28:17.449
  E0115 02:28:18.045755      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:28:19.045832      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:28:20.046171      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:28:21.046760      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 02:28:21.818
  I0115 02:28:21.824870 24 output.go:207] Trying to get logs from node 192.168.18.92 pod downwardapi-volume-8892c169-d98d-4089-b96b-1caf5514d053 container client-container: <nil>
  STEP: delete the pod @ 01/15/25 02:28:21.834
  I0115 02:28:21.853063 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-913" for this suite. @ 01/15/25 02:28:21.861
• [4.703 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:195
  STEP: Creating a kubernetes client @ 01/15/25 02:28:21.869
  I0115 02:28:21.869772 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename container-runtime @ 01/15/25 02:28:21.871
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:28:21.894
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:28:21.901
  STEP: create the container @ 01/15/25 02:28:21.908
  W0115 02:28:21.922436      24 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 01/15/25 02:28:21.922
  E0115 02:28:22.048285      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:28:23.048734      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:28:24.050493      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:28:25.050724      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: get the container status @ 01/15/25 02:28:25.977
  STEP: the container should be terminated @ 01/15/25 02:28:25.981
  STEP: the termination message should be set @ 01/15/25 02:28:25.981
  I0115 02:28:25.981916 24 runtime.go:167] Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 01/15/25 02:28:25.981
  I0115 02:28:26.003282 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-8346" for this suite. @ 01/15/25 02:28:26.009
• [4.147 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update mutating webhook configurations with match conditions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:763
  STEP: Creating a kubernetes client @ 01/15/25 02:28:26.017
  I0115 02:28:26.017249 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename webhook @ 01/15/25 02:28:26.018
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:28:26.038
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:28:26.044
  E0115 02:28:26.051557      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Setting up server cert @ 01/15/25 02:28:26.138
  E0115 02:28:27.052068      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 01/15/25 02:28:27.875
  STEP: Deploying the webhook pod @ 01/15/25 02:28:27.919
  STEP: Wait for the deployment to be ready @ 01/15/25 02:28:27.969
  I0115 02:28:27.997987 24 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0115 02:28:28.053337      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:28:29.075422      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:28:30.021651 24 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.January, 15, 2, 28, 27, 0, time.Local), LastTransitionTime:time.Date(2025, time.January, 15, 2, 28, 27, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.January, 15, 2, 28, 28, 0, time.Local), LastTransitionTime:time.Date(2025, time.January, 15, 2, 28, 27, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-bcbfc85d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0115 02:28:30.075900      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:28:31.076912      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 01/15/25 02:28:32.031
  STEP: Verifying the service has paired with the endpoint @ 01/15/25 02:28:32.049
  E0115 02:28:32.078001      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:28:33.050416 24 util.go:423] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: creating a mutating webhook with match conditions @ 01/15/25 02:28:33.061
  STEP: verifying the mutating webhook match conditions @ 01/15/25 02:28:33.07
  STEP: updating the mutating webhook match conditions @ 01/15/25 02:28:33.074
  E0115 02:28:33.078817      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: verifying the mutating webhook match conditions @ 01/15/25 02:28:33.083
  I0115 02:28:33.146172 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8426" for this suite. @ 01/15/25 02:28:33.152
  STEP: Destroying namespace "webhook-markers-2606" for this suite. @ 01/15/25 02:28:33.165
• [7.159 seconds]
------------------------------
S
------------------------------
[sig-storage] EmptyDir wrapper volumes should not conflict [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/empty_dir_wrapper.go:67
  STEP: Creating a kubernetes client @ 01/15/25 02:28:33.176
  I0115 02:28:33.176211 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename emptydir-wrapper @ 01/15/25 02:28:33.179
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:28:33.203
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:28:33.216
  E0115 02:28:34.081260      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:28:35.081694      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:28:36.083028      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:28:37.083856      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Cleaning up the secret @ 01/15/25 02:28:37.371
  STEP: Cleaning up the configmap @ 01/15/25 02:28:37.378
  STEP: Cleaning up the pod @ 01/15/25 02:28:37.385
  I0115 02:28:37.400242 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-wrapper-8649" for this suite. @ 01/15/25 02:28:37.406
• [4.237 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:170
  STEP: Creating a kubernetes client @ 01/15/25 02:28:37.413
  I0115 02:28:37.413400 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 01/15/25 02:28:37.415
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:28:37.494
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:28:37.504
  STEP: create the container to handle the HTTPGet hook request. @ 01/15/25 02:28:37.522
  E0115 02:28:38.084612      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:28:39.085689      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:28:40.086104      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:28:41.086832      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 01/15/25 02:28:41.593
  E0115 02:28:42.090902      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:28:43.121226      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:28:44.122735      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:28:45.122760      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:28:46.123552      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:28:47.123884      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: check poststart hook @ 01/15/25 02:28:47.858
  STEP: delete the pod with lifecycle hook @ 01/15/25 02:28:47.885
  E0115 02:28:48.124881      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:28:49.125827      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:28:50.125946      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:28:51.126482      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:28:51.943011 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-4540" for this suite. @ 01/15/25 02:28:51.957
• [14.566 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/replica_set.go:132
  STEP: Creating a kubernetes client @ 01/15/25 02:28:51.981
  I0115 02:28:51.981342 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename replicaset @ 01/15/25 02:28:51.984
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:28:52.048
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:28:52.057
  STEP: Given a Pod with a 'name' label pod-adoption-release is created @ 01/15/25 02:28:52.065
  E0115 02:28:52.126579      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:28:53.127586      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:28:54.127598      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:28:55.127737      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: When a replicaset with a matching selector is created @ 01/15/25 02:28:56.12
  E0115 02:28:56.143507      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Then the orphan pod is adopted @ 01/15/25 02:28:56.158
  E0115 02:28:57.144110      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: When the matched label of one of its pods change @ 01/15/25 02:28:57.207
  I0115 02:28:57.223880 24 resource.go:87] Pod name pod-adoption-release: Found 1 pods out of 1
  STEP: Then the pod is released @ 01/15/25 02:28:57.268
  E0115 02:28:58.144709      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:28:58.295870 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-9669" for this suite. @ 01/15/25 02:28:58.339
• [6.388 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:158
  STEP: Creating a kubernetes client @ 01/15/25 02:28:58.371
  I0115 02:28:58.371250 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename runtimeclass @ 01/15/25 02:28:58.443
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:28:58.591
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:28:58.61
  STEP: Deleting RuntimeClass runtimeclass-296-delete-me @ 01/15/25 02:28:58.691
  STEP: Waiting for the RuntimeClass to disappear @ 01/15/25 02:28:58.759
  I0115 02:28:58.990025 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-296" for this suite. @ 01/15/25 02:28:59.03
• [0.708 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:237
  STEP: Creating a kubernetes client @ 01/15/25 02:28:59.079
  I0115 02:28:59.079330 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename downward-api @ 01/15/25 02:28:59.091
  E0115 02:28:59.145938      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:28:59.197
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:28:59.227
  STEP: Creating a pod to test downward API volume plugin @ 01/15/25 02:28:59.252
  E0115 02:29:00.147233      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:29:01.148232      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:29:02.149174      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:29:03.149820      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:29:04.157525      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:29:05.159344      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 02:29:05.492
  I0115 02:29:05.509721 24 output.go:207] Trying to get logs from node 192.168.18.92 pod downwardapi-volume-342f9055-f047-4d03-948a-388a1d8caa92 container client-container: <nil>
  STEP: delete the pod @ 01/15/25 02:29:05.542
  I0115 02:29:05.812661 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-7827" for this suite. @ 01/15/25 02:29:06.084
  E0115 02:29:06.159733      24 retrywatcher.go:160] "Watch failed" err="context canceled"
• [7.085 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:190
  STEP: Creating a kubernetes client @ 01/15/25 02:29:06.164
  I0115 02:29:06.165527 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename emptydir @ 01/15/25 02:29:06.171
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:29:06.262
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:29:06.317
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 01/15/25 02:29:06.335
  E0115 02:29:07.161843      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:29:08.163029      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:29:09.163295      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:29:10.164213      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 02:29:10.467
  I0115 02:29:10.470914 24 output.go:207] Trying to get logs from node 192.168.18.92 pod pod-fdcdf039-19c3-477d-9dcd-239ecde001ee container test-container: <nil>
  STEP: delete the pod @ 01/15/25 02:29:10.477
  I0115 02:29:10.492659 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-6971" for this suite. @ 01/15/25 02:29:10.497
• [4.340 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Deployment deployment should support proportional scaling [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:160
  STEP: Creating a kubernetes client @ 01/15/25 02:29:10.504
  I0115 02:29:10.504762 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename deployment @ 01/15/25 02:29:10.506
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:29:10.523
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:29:10.527
  I0115 02:29:10.533497 24 deployment.go:1196] Creating deployment "webserver-deployment"
  I0115 02:29:10.538773 24 deployment.go:1200] Waiting for observed generation 1
  E0115 02:29:11.167537      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:29:12.170372      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:29:12.573099 24 deployment.go:1205] Waiting for all required pods to come up
  I0115 02:29:12.708202 24 resource.go:87] Pod name httpd: Found 10 pods out of 10
  STEP: ensuring each pod is running @ 01/15/25 02:29:12.708
  E0115 02:29:13.175471      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:29:14.179706      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:29:15.185054      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:29:16.186700      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:29:16.958701 24 deployment.go:1209] Waiting for deployment "webserver-deployment" to complete
  I0115 02:29:16.975394 24 deployment.go:1218] Updating deployment "webserver-deployment" with a non-existent image
  I0115 02:29:16.992753 24 deployment.go:314] Updating deployment webserver-deployment
  I0115 02:29:16.992834 24 deployment.go:1224] Waiting for observed generation 2
  E0115 02:29:17.187697      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:29:18.189215      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:29:19.009900 24 deployment.go:1234] Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
  I0115 02:29:19.018137 24 deployment.go:1239] Waiting for the first rollout's replicaset to have .spec.replicas = 8
  I0115 02:29:19.028894 24 deployment.go:1244] Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  I0115 02:29:19.073979 24 deployment.go:1258] Verifying that the second rollout's replicaset has .status.availableReplicas = 0
  I0115 02:29:19.074070 24 deployment.go:1263] Waiting for the second rollout's replicaset to have .spec.replicas = 5
  I0115 02:29:19.081658 24 deployment.go:1268] Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  I0115 02:29:19.109113 24 deployment.go:1275] Verifying that deployment "webserver-deployment" has minimum required number of available replicas
  I0115 02:29:19.109185 24 deployment.go:1283] Scaling up the deployment "webserver-deployment" from 10 to 30
  I0115 02:29:19.135579 24 deployment.go:314] Updating deployment webserver-deployment
  I0115 02:29:19.135834 24 deployment.go:1289] Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
  I0115 02:29:19.162895 24 deployment.go:1297] Verifying that first rollout's replicaset has .spec.replicas = 20
  I0115 02:29:19.173488 24 deployment.go:1303] Verifying that second rollout's replicaset has .spec.replicas = 13
  E0115 02:29:19.191936      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:29:19.280509 24 deployment.go:633] Deployment "webserver-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=20) "webserver-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=13) "deployment-36",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "c313348b-12c8-421f-af7b-475e7d6ed2cc",
      ResourceVersion: (string) (len=6) "174575",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872504950,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504959,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=635) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 68  74 74 70 64 5c 22 7d 22  |me\":\"httpd\"}"|
              00000160  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000170  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000180  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000190  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              000001a0  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              000001b0  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              000001c0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001d0  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000001e0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000001f0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              00000200  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              00000210  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              00000220  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              00000230  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000270  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504959,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=541) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 6e 61  |licas":{},"f:una|
              000001f0  76 61 69 6c 61 62 6c 65  52 65 70 6c 69 63 61 73  |vailableReplicas|
              00000200  22 3a 7b 7d 2c 22 66 3a  75 70 64 61 74 65 64 52  |":{},"f:updatedR|
              00000210  65 70 6c 69 63 61 73 22  3a 7b 7d 7d 7d           |eplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(30),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=13) "webserver:404",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 2,
            StrVal: (string) ""
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 3,
            StrVal: (string) ""
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 3,
      Replicas: (int32) 13,
      UpdatedReplicas: (int32) 5,
      ReadyReplicas: (int32) 8,
      AvailableReplicas: (int32) 8,
      UnavailableReplicas: (int32) 5,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504957,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504950,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=17) "ReplicaSetUpdated",
          Message: (string) (len=60) "ReplicaSet \"webserver-deployment-6fc69b9478\" is progressing."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504959,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504959,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=26) "MinimumReplicasUnavailable",
          Message: (string) (len=46) "Deployment does not have minimum availability."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0115 02:29:19.350573 24 deployment.go:40] New ReplicaSet "webserver-deployment-6fc69b9478" of Deployment "webserver-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=31) "webserver-deployment-6fc69b9478",
      GenerateName: (string) "",
      Namespace: (string) (len=13) "deployment-36",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "ee3a067c-7a61-462b-bb1a-b56d261eeca1",
      ResourceVersion: (string) (len=6) "174565",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872504956,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6fc69b9478"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=2) "30",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=2) "33",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=20) "webserver-deployment",
          UID: (types.UID) (len=36) "c313348b-12c8-421f-af7b-475e7d6ed2cc",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504957,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=84) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  66 75 6c 6c 79 4c 61 62  65 6c 65 64 52 65 70 6c  |fullyLabeledRepl|
              00000020  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 6f 62 73 65  |icas":{},"f:obse|
              00000030  72 76 65 64 47 65 6e 65  72 61 74 69 6f 6e 22 3a  |rvedGeneration":|
              00000040  7b 7d 2c 22 66 3a 72 65  70 6c 69 63 61 73 22 3a  |{},"f:replicas":|
              00000050  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504959,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 63 33 31 33 33 34  38 62 2d 31 32 63 38 2d  |\"c313348b-12c8-|
              00000120  34 32 31 66 2d 61 66 37  62 2d 34 37 35 65 37 64  |421f-af7b-475e7d|
              00000130  36 65 64 32 63 63 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |6ed2cc\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(13),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "6fc69b9478"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "6fc69b9478"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=13) "webserver:404",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 5,
      FullyLabeledReplicas: (int32) 5,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0115 02:29:19.353284 24 deployment.go:45] All old ReplicaSets of Deployment "webserver-deployment":
  I0115 02:29:19.355167 24 deployment.go:48] (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=31) "webserver-deployment-685b768f58",
      GenerateName: (string) "",
      Namespace: (string) (len=13) "deployment-36",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "10150bad-f70b-4c4e-b08b-f5a1b3b74a5e",
      ResourceVersion: (string) (len=6) "174562",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872504950,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "685b768f58"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=2) "30",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=2) "33",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=20) "webserver-deployment",
          UID: (types.UID) (len=36) "c313348b-12c8-421f-af7b-475e7d6ed2cc",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504957,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504959,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 63 33 31 33 33 34  38 62 2d 31 32 63 38 2d  |\"c313348b-12c8-|
              00000120  34 32 31 66 2d 61 66 37  62 2d 34 37 35 65 37 64  |421f-af7b-475e7d|
              00000130  36 65 64 32 63 63 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |6ed2cc\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(20),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "685b768f58"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "685b768f58"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 8,
      FullyLabeledReplicas: (int32) 8,
      ReadyReplicas: (int32) 8,
      AvailableReplicas: (int32) 8,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0115 02:29:19.547050 24 deployment.go:68] Pod "webserver-deployment-685b768f58-5mx2d" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-685b768f58-5mx2d",
      GenerateName: (string) (len=32) "webserver-deployment-685b768f58-",
      Namespace: (string) (len=13) "deployment-36",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "2211e9d6-aee3-495d-9203-0cf646e818d5",
      ResourceVersion: (string) (len=6) "174601",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872504959,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "685b768f58"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-685b768f58",
          UID: (types.UID) (len=36) "10150bad-f70b-4c4e-b08b-f5a1b3b74a5e",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504959,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 30  31 35 30 62 61 64 2d 66  |d\":\"10150bad-f|
              00000090  37 30 62 2d 34 63 34 65  2d 62 30 38 62 2d 66 35  |70b-4c4e-b08b-f5|
              000000a0  61 31 62 33 62 37 34 61  35 65 5c 22 7d 22 3a 7b  |a1b3b74a5e\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-r4dzs",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-r4dzs",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=13) "192.168.18.92",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504959,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0115 02:29:19.551480 24 deployment.go:68] Pod "webserver-deployment-685b768f58-67k6j" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-685b768f58-67k6j",
      GenerateName: (string) (len=32) "webserver-deployment-685b768f58-",
      Namespace: (string) (len=13) "deployment-36",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "b734ec7e-c26f-4247-81ed-d0b96e666729",
      ResourceVersion: (string) (len=6) "174602",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872504959,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "685b768f58"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-685b768f58",
          UID: (types.UID) (len=36) "10150bad-f70b-4c4e-b08b-f5a1b3b74a5e",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504959,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 30  31 35 30 62 61 64 2d 66  |d\":\"10150bad-f|
              00000090  37 30 62 2d 34 63 34 65  2d 62 30 38 62 2d 66 35  |70b-4c4e-b08b-f5|
              000000a0  61 31 62 33 62 37 34 61  35 65 5c 22 7d 22 3a 7b  |a1b3b74a5e\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-xjhm9",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-xjhm9",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=13) "192.168.18.91",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504959,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0115 02:29:19.577950 24 deployment.go:68] Pod "webserver-deployment-685b768f58-6w6tw" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-685b768f58-6w6tw",
      GenerateName: (string) (len=32) "webserver-deployment-685b768f58-",
      Namespace: (string) (len=13) "deployment-36",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "fcb547e2-3fa2-4712-84d4-cb285a4bacbd",
      ResourceVersion: (string) (len=6) "174587",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872504959,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "685b768f58"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-685b768f58",
          UID: (types.UID) (len=36) "10150bad-f70b-4c4e-b08b-f5a1b3b74a5e",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504959,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 30  31 35 30 62 61 64 2d 66  |d\":\"10150bad-f|
              00000090  37 30 62 2d 34 63 34 65  2d 62 30 38 62 2d 66 35  |70b-4c4e-b08b-f5|
              000000a0  61 31 62 33 62 37 34 61  35 65 5c 22 7d 22 3a 7b  |a1b3b74a5e\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504959,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-lbn9x",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-lbn9x",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=13) "192.168.18.92",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504959,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504959,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504959,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504959,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504959,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "192.168.18.92",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "192.168.18.92"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872504959,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-lbn9x",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0115 02:29:19.582400 24 deployment.go:68] Pod "webserver-deployment-685b768f58-7q88s" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-685b768f58-7q88s",
      GenerateName: (string) (len=32) "webserver-deployment-685b768f58-",
      Namespace: (string) (len=13) "deployment-36",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "e149196c-a367-4e3c-b02d-09a3ab2c5d7b",
      ResourceVersion: (string) (len=6) "174592",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872504959,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "685b768f58"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-685b768f58",
          UID: (types.UID) (len=36) "10150bad-f70b-4c4e-b08b-f5a1b3b74a5e",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504959,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 30  31 35 30 62 61 64 2d 66  |d\":\"10150bad-f|
              00000090  37 30 62 2d 34 63 34 65  2d 62 30 38 62 2d 66 35  |70b-4c4e-b08b-f5|
              000000a0  61 31 62 33 62 37 34 61  35 65 5c 22 7d 22 3a 7b  |a1b3b74a5e\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-h2hpq",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-h2hpq",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0115 02:29:19.600677 24 deployment.go:68] Pod "webserver-deployment-685b768f58-89hqq" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-685b768f58-89hqq",
      GenerateName: (string) (len=32) "webserver-deployment-685b768f58-",
      Namespace: (string) (len=13) "deployment-36",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "a4f23fd6-2f31-444a-b028-2de245b967be",
      ResourceVersion: (string) (len=6) "174453",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872504950,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "685b768f58"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=15) "10.1.213.100/32",
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "a1c1e7c1ed412d55b472be0d12f84229d78d700b1aa2029b1d70ffae1cac76dd",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=15) "10.1.213.100/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-685b768f58",
          UID: (types.UID) (len=36) "10150bad-f70b-4c4e-b08b-f5a1b3b74a5e",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504950,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 30  31 35 30 62 61 64 2d 66  |d\":\"10150bad-f|
              00000090  37 30 62 2d 34 63 34 65  2d 62 30 38 62 2d 66 35  |70b-4c4e-b08b-f5|
              000000a0  61 31 62 33 62 37 34 61  35 65 5c 22 7d 22 3a 7b  |a1b3b74a5e\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504952,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504955,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=661) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 31 2e 32 31 33 2e 31  30 30 5c 22 7d 22 3a 7b  |.1.213.100\"}":{|
              00000270  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              00000280  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              00000290  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-gm8ht",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-gm8ht",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=13) "192.168.18.91",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504955,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504950,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504955,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504955,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504950,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "192.168.18.91",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "192.168.18.91"
        }
      },
      PodIP: (string) (len=12) "10.1.213.100",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "10.1.213.100"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872504950,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63872504955,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://1c7ce46be63af60a76144be562fb8e9df516e22ba06c095e428dbf69ed4c44d5",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-gm8ht",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0115 02:29:19.606084 24 deployment.go:68] Pod "webserver-deployment-685b768f58-b9pqz" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-685b768f58-b9pqz",
      GenerateName: (string) (len=32) "webserver-deployment-685b768f58-",
      Namespace: (string) (len=13) "deployment-36",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "90b30911-1677-4ab7-a9b3-adfe8720b837",
      ResourceVersion: (string) (len=6) "174598",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872504959,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "685b768f58"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-685b768f58",
          UID: (types.UID) (len=36) "10150bad-f70b-4c4e-b08b-f5a1b3b74a5e",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504959,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 30  31 35 30 62 61 64 2d 66  |d\":\"10150bad-f|
              00000090  37 30 62 2d 34 63 34 65  2d 62 30 38 62 2d 66 35  |70b-4c4e-b08b-f5|
              000000a0  61 31 62 33 62 37 34 61  35 65 5c 22 7d 22 3a 7b  |a1b3b74a5e\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-rwv7h",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-rwv7h",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=13) "192.168.18.91",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504959,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0115 02:29:19.621106 24 deployment.go:68] Pod "webserver-deployment-685b768f58-dcxwc" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-685b768f58-dcxwc",
      GenerateName: (string) (len=32) "webserver-deployment-685b768f58-",
      Namespace: (string) (len=13) "deployment-36",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "5d9acb83-dc9e-4338-a004-78e04857a5c7",
      ResourceVersion: (string) (len=6) "174476",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872504950,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "685b768f58"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "a368166a797d71415a6148b671f0514db4e95832da0c975115e490a0d71230c7",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=14) "10.1.213.86/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=14) "10.1.213.86/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-685b768f58",
          UID: (types.UID) (len=36) "10150bad-f70b-4c4e-b08b-f5a1b3b74a5e",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504950,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 30  31 35 30 62 61 64 2d 66  |d\":\"10150bad-f|
              00000090  37 30 62 2d 34 63 34 65  2d 62 30 38 62 2d 66 35  |70b-4c4e-b08b-f5|
              000000a0  61 31 62 33 62 37 34 61  35 65 5c 22 7d 22 3a 7b  |a1b3b74a5e\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504954,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504956,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 31 2e 32 31 33 2e 38  36 5c 22 7d 22 3a 7b 22  |.1.213.86\"}":{"|
              00000270  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000280  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000290  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-zkxwv",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-zkxwv",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=13) "192.168.18.91",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504956,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504950,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504956,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504956,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504950,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "192.168.18.91",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "192.168.18.91"
        }
      },
      PodIP: (string) (len=11) "10.1.213.86",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.1.213.86"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872504950,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63872504956,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://f0b7b02d92fe7a5f2446cc1d504e9ea9753554a1b2df0379482aa466343e5560",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-zkxwv",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0115 02:29:19.637370 24 deployment.go:68] Pod "webserver-deployment-685b768f58-fqcpx" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-685b768f58-fqcpx",
      GenerateName: (string) (len=32) "webserver-deployment-685b768f58-",
      Namespace: (string) (len=13) "deployment-36",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "b1465803-9e87-40d9-b2b5-f6fa5d563ba0",
      ResourceVersion: (string) (len=6) "174436",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872504950,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "685b768f58"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "35fb8d8f90e3891a8c99273adba91c6c56a3a8ced68a5b5798d43d11993f869c",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=14) "10.1.155.46/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=14) "10.1.155.46/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-685b768f58",
          UID: (types.UID) (len=36) "10150bad-f70b-4c4e-b08b-f5a1b3b74a5e",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504950,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 30  31 35 30 62 61 64 2d 66  |d\":\"10150bad-f|
              00000090  37 30 62 2d 34 63 34 65  2d 62 30 38 62 2d 66 35  |70b-4c4e-b08b-f5|
              000000a0  61 31 62 33 62 37 34 61  35 65 5c 22 7d 22 3a 7b  |a1b3b74a5e\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504951,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504954,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 31 2e 31 35 35 2e 34  36 5c 22 7d 22 3a 7b 22  |.1.155.46\"}":{"|
              00000270  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000280  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000290  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-668bv",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-668bv",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=13) "192.168.18.92",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504954,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504950,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504954,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504954,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504950,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "192.168.18.92",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "192.168.18.92"
        }
      },
      PodIP: (string) (len=11) "10.1.155.46",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.1.155.46"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872504950,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63872504953,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://4fcf7b7d55064e4aa96a348813e5ea066b218547f40d07bb8abeaab28c40414a",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-668bv",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0115 02:29:19.643687 24 deployment.go:68] Pod "webserver-deployment-685b768f58-gnjw5" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-685b768f58-gnjw5",
      GenerateName: (string) (len=32) "webserver-deployment-685b768f58-",
      Namespace: (string) (len=13) "deployment-36",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "4cc52e43-2c54-4837-a63e-55e5bdace2d2",
      ResourceVersion: (string) (len=6) "174474",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872504950,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "685b768f58"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=14) "10.1.213.83/32",
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "a072d33ef3000169532c72eaedb47c9fd32655ec382560be262d2457e7f1f0ca",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=14) "10.1.213.83/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-685b768f58",
          UID: (types.UID) (len=36) "10150bad-f70b-4c4e-b08b-f5a1b3b74a5e",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504950,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 30  31 35 30 62 61 64 2d 66  |d\":\"10150bad-f|
              00000090  37 30 62 2d 34 63 34 65  2d 62 30 38 62 2d 66 35  |70b-4c4e-b08b-f5|
              000000a0  61 31 62 33 62 37 34 61  35 65 5c 22 7d 22 3a 7b  |a1b3b74a5e\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504953,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504956,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 31 2e 32 31 33 2e 38  33 5c 22 7d 22 3a 7b 22  |.1.213.83\"}":{"|
              00000270  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000280  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000290  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-bbjnt",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-bbjnt",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=13) "192.168.18.91",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504956,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504950,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504956,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504956,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504950,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "192.168.18.91",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "192.168.18.91"
        }
      },
      PodIP: (string) (len=11) "10.1.213.83",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.1.213.83"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872504950,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63872504955,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://a910f408fbbecaca4203d29ab2dce20a7195aa5deac554e4fb01349678fbfb23",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-bbjnt",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0115 02:29:19.663662 24 deployment.go:68] Pod "webserver-deployment-685b768f58-jfzxz" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-685b768f58-jfzxz",
      GenerateName: (string) (len=32) "webserver-deployment-685b768f58-",
      Namespace: (string) (len=13) "deployment-36",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "ac285804-13b9-4e56-9e52-1d5445b8269e",
      ResourceVersion: (string) (len=6) "174600",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872504959,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "685b768f58"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-685b768f58",
          UID: (types.UID) (len=36) "10150bad-f70b-4c4e-b08b-f5a1b3b74a5e",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504959,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 30  31 35 30 62 61 64 2d 66  |d\":\"10150bad-f|
              00000090  37 30 62 2d 34 63 34 65  2d 62 30 38 62 2d 66 35  |70b-4c4e-b08b-f5|
              000000a0  61 31 62 33 62 37 34 61  35 65 5c 22 7d 22 3a 7b  |a1b3b74a5e\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-rk97z",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-rk97z",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=13) "192.168.18.91",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504959,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0115 02:29:19.666815 24 deployment.go:68] Pod "webserver-deployment-685b768f58-k5ftd" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-685b768f58-k5ftd",
      GenerateName: (string) (len=32) "webserver-deployment-685b768f58-",
      Namespace: (string) (len=13) "deployment-36",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "db42ef5a-72e8-4728-96b4-0779a9b0e5b7",
      ResourceVersion: (string) (len=6) "174576",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872504959,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "685b768f58"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-685b768f58",
          UID: (types.UID) (len=36) "10150bad-f70b-4c4e-b08b-f5a1b3b74a5e",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504959,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 30  31 35 30 62 61 64 2d 66  |d\":\"10150bad-f|
              00000090  37 30 62 2d 34 63 34 65  2d 62 30 38 62 2d 66 35  |70b-4c4e-b08b-f5|
              000000a0  61 31 62 33 62 37 34 61  35 65 5c 22 7d 22 3a 7b  |a1b3b74a5e\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-8rj6k",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-8rj6k",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=13) "192.168.18.92",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504959,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0115 02:29:19.672065 24 deployment.go:68] Pod "webserver-deployment-685b768f58-kgt6s" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-685b768f58-kgt6s",
      GenerateName: (string) (len=32) "webserver-deployment-685b768f58-",
      Namespace: (string) (len=13) "deployment-36",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "1963376a-d647-42f7-b64e-c739d0b62960",
      ResourceVersion: (string) (len=6) "174599",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872504959,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "685b768f58"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-685b768f58",
          UID: (types.UID) (len=36) "10150bad-f70b-4c4e-b08b-f5a1b3b74a5e",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504959,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 30  31 35 30 62 61 64 2d 66  |d\":\"10150bad-f|
              00000090  37 30 62 2d 34 63 34 65  2d 62 30 38 62 2d 66 35  |70b-4c4e-b08b-f5|
              000000a0  61 31 62 33 62 37 34 61  35 65 5c 22 7d 22 3a 7b  |a1b3b74a5e\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-29zgz",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-29zgz",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=13) "192.168.18.92",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504959,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0115 02:29:19.679955 24 deployment.go:68] Pod "webserver-deployment-685b768f58-lkg8g" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-685b768f58-lkg8g",
      GenerateName: (string) (len=32) "webserver-deployment-685b768f58-",
      Namespace: (string) (len=13) "deployment-36",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "f23bd78d-0365-4dbe-b1e0-4d7770e61d53",
      ResourceVersion: (string) (len=6) "174593",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872504959,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "685b768f58"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-685b768f58",
          UID: (types.UID) (len=36) "10150bad-f70b-4c4e-b08b-f5a1b3b74a5e",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504959,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 30  31 35 30 62 61 64 2d 66  |d\":\"10150bad-f|
              00000090  37 30 62 2d 34 63 34 65  2d 62 30 38 62 2d 66 35  |70b-4c4e-b08b-f5|
              000000a0  61 31 62 33 62 37 34 61  35 65 5c 22 7d 22 3a 7b  |a1b3b74a5e\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-tpl2d",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-tpl2d",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0115 02:29:19.684801 24 deployment.go:68] Pod "webserver-deployment-685b768f58-nfh9x" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-685b768f58-nfh9x",
      GenerateName: (string) (len=32) "webserver-deployment-685b768f58-",
      Namespace: (string) (len=13) "deployment-36",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "5b8351a9-6b6d-460f-88a2-69721dfda0f6",
      ResourceVersion: (string) (len=6) "174480",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872504950,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "685b768f58"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "607f7a7a1af8becacec5b5f28d46c45fe5aa8ec7c36caa0fa8b799c9c4cb365c",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=14) "10.1.213.87/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=14) "10.1.213.87/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-685b768f58",
          UID: (types.UID) (len=36) "10150bad-f70b-4c4e-b08b-f5a1b3b74a5e",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504950,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 30  31 35 30 62 61 64 2d 66  |d\":\"10150bad-f|
              00000090  37 30 62 2d 34 63 34 65  2d 62 30 38 62 2d 66 35  |70b-4c4e-b08b-f5|
              000000a0  61 31 62 33 62 37 34 61  35 65 5c 22 7d 22 3a 7b  |a1b3b74a5e\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504953,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504956,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 31 2e 32 31 33 2e 38  37 5c 22 7d 22 3a 7b 22  |.1.213.87\"}":{"|
              00000270  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000280  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000290  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-dkvpq",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-dkvpq",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=13) "192.168.18.91",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504956,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504950,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504956,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504956,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504950,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "192.168.18.91",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "192.168.18.91"
        }
      },
      PodIP: (string) (len=11) "10.1.213.87",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.1.213.87"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872504950,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63872504955,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://8aa2d3c183f5acdc03ecc822e971dffec8edde560c16b1b12156603d2770e48f",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-dkvpq",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0115 02:29:19.693249 24 deployment.go:68] Pod "webserver-deployment-685b768f58-prxdb" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-685b768f58-prxdb",
      GenerateName: (string) (len=32) "webserver-deployment-685b768f58-",
      Namespace: (string) (len=13) "deployment-36",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "4e014ded-dde8-4aa6-ab9d-08a14105db84",
      ResourceVersion: (string) (len=6) "174594",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872504959,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "685b768f58"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-685b768f58",
          UID: (types.UID) (len=36) "10150bad-f70b-4c4e-b08b-f5a1b3b74a5e",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504959,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 30  31 35 30 62 61 64 2d 66  |d\":\"10150bad-f|
              00000090  37 30 62 2d 34 63 34 65  2d 62 30 38 62 2d 66 35  |70b-4c4e-b08b-f5|
              000000a0  61 31 62 33 62 37 34 61  35 65 5c 22 7d 22 3a 7b  |a1b3b74a5e\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-v55sq",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-v55sq",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0115 02:29:19.696811 24 deployment.go:68] Pod "webserver-deployment-685b768f58-qwtx5" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-685b768f58-qwtx5",
      GenerateName: (string) (len=32) "webserver-deployment-685b768f58-",
      Namespace: (string) (len=13) "deployment-36",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "e5571d92-4f28-4ca2-ad3a-473cbed33d68",
      ResourceVersion: (string) (len=6) "174443",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872504950,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "685b768f58"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "654e1a31653f4f5c199b1163da2aff48d13f6eac4a25cc479542fd71d379b558",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=14) "10.1.155.35/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=14) "10.1.155.35/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-685b768f58",
          UID: (types.UID) (len=36) "10150bad-f70b-4c4e-b08b-f5a1b3b74a5e",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504950,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 30  31 35 30 62 61 64 2d 66  |d\":\"10150bad-f|
              00000090  37 30 62 2d 34 63 34 65  2d 62 30 38 62 2d 66 35  |70b-4c4e-b08b-f5|
              000000a0  61 31 62 33 62 37 34 61  35 65 5c 22 7d 22 3a 7b  |a1b3b74a5e\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504952,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504954,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 31 2e 31 35 35 2e 33  35 5c 22 7d 22 3a 7b 22  |.1.155.35\"}":{"|
              00000270  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000280  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000290  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-chtd6",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-chtd6",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=13) "192.168.18.92",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504954,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504950,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504954,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504954,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504950,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "192.168.18.92",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "192.168.18.92"
        }
      },
      PodIP: (string) (len=11) "10.1.155.35",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.1.155.35"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872504950,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63872504953,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://2bd1fd5b4922191c2313024148bf1e22db2988397d74437ec398ef3d5f8e2366",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-chtd6",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0115 02:29:19.706660 24 deployment.go:68] Pod "webserver-deployment-685b768f58-r9x9t" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-685b768f58-r9x9t",
      GenerateName: (string) (len=32) "webserver-deployment-685b768f58-",
      Namespace: (string) (len=13) "deployment-36",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "79ae8642-8fd9-4d62-9069-5beafda6c4c2",
      ResourceVersion: (string) (len=6) "174458",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872504950,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "685b768f58"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=14) "10.1.213.97/32",
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "9f127c15ca4589181218a18c1fa5fd9007908bde12cba40bbfaf1a23f606821d",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=14) "10.1.213.97/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-685b768f58",
          UID: (types.UID) (len=36) "10150bad-f70b-4c4e-b08b-f5a1b3b74a5e",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504950,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 30  31 35 30 62 61 64 2d 66  |d\":\"10150bad-f|
              00000090  37 30 62 2d 34 63 34 65  2d 62 30 38 62 2d 66 35  |70b-4c4e-b08b-f5|
              000000a0  61 31 62 33 62 37 34 61  35 65 5c 22 7d 22 3a 7b  |a1b3b74a5e\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504952,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504955,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 31 2e 32 31 33 2e 39  37 5c 22 7d 22 3a 7b 22  |.1.213.97\"}":{"|
              00000270  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000280  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000290  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-f57mk",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-f57mk",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=13) "192.168.18.91",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504955,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504950,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504955,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504955,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504950,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "192.168.18.91",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "192.168.18.91"
        }
      },
      PodIP: (string) (len=11) "10.1.213.97",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.1.213.97"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872504950,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63872504955,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://bb9f0b0b0c0a86096280d60f404291ee217f3e53f9d7a79e6efb168583e14fca",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-f57mk",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0115 02:29:19.722414 24 deployment.go:68] Pod "webserver-deployment-685b768f58-trf54" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-685b768f58-trf54",
      GenerateName: (string) (len=32) "webserver-deployment-685b768f58-",
      Namespace: (string) (len=13) "deployment-36",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "782572a6-8971-4c89-9767-64064b5ad059",
      ResourceVersion: (string) (len=6) "174580",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872504959,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "685b768f58"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-685b768f58",
          UID: (types.UID) (len=36) "10150bad-f70b-4c4e-b08b-f5a1b3b74a5e",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504959,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 30  31 35 30 62 61 64 2d 66  |d\":\"10150bad-f|
              00000090  37 30 62 2d 34 63 34 65  2d 62 30 38 62 2d 66 35  |70b-4c4e-b08b-f5|
              000000a0  61 31 62 33 62 37 34 61  35 65 5c 22 7d 22 3a 7b  |a1b3b74a5e\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-f7m4b",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-f7m4b",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=13) "192.168.18.92",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504959,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0115 02:29:19.736983 24 deployment.go:68] Pod "webserver-deployment-685b768f58-x8pbh" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-685b768f58-x8pbh",
      GenerateName: (string) (len=32) "webserver-deployment-685b768f58-",
      Namespace: (string) (len=13) "deployment-36",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "bd42fc00-e959-4d9e-9244-d4b7506d8886",
      ResourceVersion: (string) (len=6) "174433",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872504950,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "685b768f58"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=14) "10.1.155.38/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=14) "10.1.155.38/32",
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "511250dd7ad4ade3dbfdda040a7e0e3046b74b9a51d419b8dd1cd7b9c15d0feb"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-685b768f58",
          UID: (types.UID) (len=36) "10150bad-f70b-4c4e-b08b-f5a1b3b74a5e",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504950,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 30  31 35 30 62 61 64 2d 66  |d\":\"10150bad-f|
              00000090  37 30 62 2d 34 63 34 65  2d 62 30 38 62 2d 66 35  |70b-4c4e-b08b-f5|
              000000a0  61 31 62 33 62 37 34 61  35 65 5c 22 7d 22 3a 7b  |a1b3b74a5e\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504952,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504954,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 31 2e 31 35 35 2e 33  38 5c 22 7d 22 3a 7b 22  |.1.155.38\"}":{"|
              00000270  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000280  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000290  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-glgtj",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-glgtj",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=13) "192.168.18.92",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504954,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504950,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504954,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504954,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504950,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "192.168.18.92",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "192.168.18.92"
        }
      },
      PodIP: (string) (len=11) "10.1.155.38",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.1.155.38"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872504950,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63872504954,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://4e0963e0a9c97ae58259d697276ca3efd22a466e2b7f853d25e7860e8e8acaf3",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-glgtj",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0115 02:29:19.741623 24 deployment.go:68] Pod "webserver-deployment-685b768f58-xbdkh" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-685b768f58-xbdkh",
      GenerateName: (string) (len=32) "webserver-deployment-685b768f58-",
      Namespace: (string) (len=13) "deployment-36",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "ae278e78-2f15-4128-b1e4-3d40b8a9f73e",
      ResourceVersion: (string) (len=6) "174591",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872504959,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "685b768f58"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-685b768f58",
          UID: (types.UID) (len=36) "10150bad-f70b-4c4e-b08b-f5a1b3b74a5e",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504959,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 30  31 35 30 62 61 64 2d 66  |d\":\"10150bad-f|
              00000090  37 30 62 2d 34 63 34 65  2d 62 30 38 62 2d 66 35  |70b-4c4e-b08b-f5|
              000000a0  61 31 62 33 62 37 34 61  35 65 5c 22 7d 22 3a 7b  |a1b3b74a5e\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-92sdl",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-92sdl",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0115 02:29:19.744402 24 deployment.go:68] Pod "webserver-deployment-6fc69b9478-5fxz4" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-6fc69b9478-5fxz4",
      GenerateName: (string) (len=32) "webserver-deployment-6fc69b9478-",
      Namespace: (string) (len=13) "deployment-36",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "3756c6c8-cce1-44f1-adbc-7a128875c767",
      ResourceVersion: (string) (len=6) "174550",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872504957,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6fc69b9478"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=14) "10.1.213.98/32",
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "4f3fed8eec9afdd371ad2bf3bdf03d7448f6f42bcd838b175e9ff27ccb152bfd",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=14) "10.1.213.98/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-6fc69b9478",
          UID: (types.UID) (len=36) "ee3a067c-7a61-462b-bb1a-b56d261eeca1",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504957,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 65 65  33 61 30 36 37 63 2d 37  |d\":\"ee3a067c-7|
              00000090  61 36 31 2d 34 36 32 62  2d 62 62 31 61 2d 62 35  |a61-462b-bb1a-b5|
              000000a0  36 64 32 36 31 65 65 63  61 31 5c 22 7d 22 3a 7b  |6d261eeca1\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504957,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504958,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-7hnxr",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-7hnxr",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=13) "192.168.18.91",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504957,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504957,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504957,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504957,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504957,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "192.168.18.91",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "192.168.18.91"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872504957,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-7hnxr",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0115 02:29:19.751773 24 deployment.go:68] Pod "webserver-deployment-6fc69b9478-7j2kg" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-6fc69b9478-7j2kg",
      GenerateName: (string) (len=32) "webserver-deployment-6fc69b9478-",
      Namespace: (string) (len=13) "deployment-36",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "334bb5cb-eb3c-438b-87a7-952d143c1d0a",
      ResourceVersion: (string) (len=6) "174557",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872504957,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6fc69b9478"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "afcd9ea84f3a39193ebddb0d09dcedcffccd059249543ca78e2a805930608c82",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=13) "10.1.155.9/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=13) "10.1.155.9/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-6fc69b9478",
          UID: (types.UID) (len=36) "ee3a067c-7a61-462b-bb1a-b56d261eeca1",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504957,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 65 65  33 61 30 36 37 63 2d 37  |d\":\"ee3a067c-7|
              00000090  61 36 31 2d 34 36 32 62  2d 62 62 31 61 2d 62 35  |a61-462b-bb1a-b5|
              000000a0  36 64 32 36 31 65 65 63  61 31 5c 22 7d 22 3a 7b  |6d261eeca1\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504957,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504959,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-rhf2b",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-rhf2b",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=13) "192.168.18.92",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504957,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504957,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504957,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504957,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504957,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "192.168.18.92",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "192.168.18.92"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872504957,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-rhf2b",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0115 02:29:19.767574 24 deployment.go:68] Pod "webserver-deployment-6fc69b9478-8psqt" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-6fc69b9478-8psqt",
      GenerateName: (string) (len=32) "webserver-deployment-6fc69b9478-",
      Namespace: (string) (len=13) "deployment-36",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "11924610-e6e7-4240-b1b8-0b815ef6933b",
      ResourceVersion: (string) (len=6) "174544",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872504956,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6fc69b9478"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=14) "10.1.213.89/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=14) "10.1.213.89/32",
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "8a732013be6f03a2d19d818183a5a1d473f3a321c9a89d9470032d53f4cb6cfc"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-6fc69b9478",
          UID: (types.UID) (len=36) "ee3a067c-7a61-462b-bb1a-b56d261eeca1",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504956,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 65 65  33 61 30 36 37 63 2d 37  |d\":\"ee3a067c-7|
              00000090  61 36 31 2d 34 36 32 62  2d 62 62 31 61 2d 62 35  |a61-462b-bb1a-b5|
              000000a0  36 64 32 36 31 65 65 63  61 31 5c 22 7d 22 3a 7b  |6d261eeca1\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504957,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504958,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-gt767",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-gt767",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=13) "192.168.18.91",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504957,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504957,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504957,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504957,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504957,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "192.168.18.91",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "192.168.18.91"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872504957,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-gt767",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0115 02:29:19.771668 24 deployment.go:68] Pod "webserver-deployment-6fc69b9478-8wgrt" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-6fc69b9478-8wgrt",
      GenerateName: (string) (len=32) "webserver-deployment-6fc69b9478-",
      Namespace: (string) (len=13) "deployment-36",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "65728e0d-5eb6-4a0f-9ab6-3d043b78829e",
      ResourceVersion: (string) (len=6) "174585",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872504959,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6fc69b9478"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-6fc69b9478",
          UID: (types.UID) (len=36) "ee3a067c-7a61-462b-bb1a-b56d261eeca1",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504959,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 65 65  33 61 30 36 37 63 2d 37  |d\":\"ee3a067c-7|
              00000090  61 36 31 2d 34 36 32 62  2d 62 62 31 61 2d 62 35  |a61-462b-bb1a-b5|
              000000a0  36 64 32 36 31 65 65 63  61 31 5c 22 7d 22 3a 7b  |6d261eeca1\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-mp4f5",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-mp4f5",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=13) "192.168.18.91",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504959,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0115 02:29:19.783189 24 deployment.go:68] Pod "webserver-deployment-6fc69b9478-fhw2j" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-6fc69b9478-fhw2j",
      GenerateName: (string) (len=32) "webserver-deployment-6fc69b9478-",
      Namespace: (string) (len=13) "deployment-36",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "8edb4ac5-e9cb-4c8a-860a-668e74c745a2",
      ResourceVersion: (string) (len=6) "174549",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872504956,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6fc69b9478"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "4e67c3fb47fa6420f0e177e8374799ab4ef729aa200a2be94ee39d5f06e82a8b",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=14) "10.1.155.47/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=14) "10.1.155.47/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-6fc69b9478",
          UID: (types.UID) (len=36) "ee3a067c-7a61-462b-bb1a-b56d261eeca1",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504956,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 65 65  33 61 30 36 37 63 2d 37  |d\":\"ee3a067c-7|
              00000090  61 36 31 2d 34 36 32 62  2d 62 62 31 61 2d 62 35  |a61-462b-bb1a-b5|
              000000a0  36 64 32 36 31 65 65 63  61 31 5c 22 7d 22 3a 7b  |6d261eeca1\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504957,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504958,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-gqqp7",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-gqqp7",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=13) "192.168.18.92",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504957,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504957,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504957,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504957,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504957,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "192.168.18.92",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "192.168.18.92"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872504957,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-gqqp7",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0115 02:29:19.821165 24 deployment.go:68] Pod "webserver-deployment-6fc69b9478-s4hbv" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-6fc69b9478-s4hbv",
      GenerateName: (string) (len=32) "webserver-deployment-6fc69b9478-",
      Namespace: (string) (len=13) "deployment-36",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "350bcbb6-82ce-4629-8be4-594b6a990fee",
      ResourceVersion: (string) (len=6) "174590",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872504959,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6fc69b9478"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-6fc69b9478",
          UID: (types.UID) (len=36) "ee3a067c-7a61-462b-bb1a-b56d261eeca1",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504959,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 65 65  33 61 30 36 37 63 2d 37  |d\":\"ee3a067c-7|
              00000090  61 36 31 2d 34 36 32 62  2d 62 62 31 61 2d 62 35  |a61-462b-bb1a-b5|
              000000a0  36 64 32 36 31 65 65 63  61 31 5c 22 7d 22 3a 7b  |6d261eeca1\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-nvxb9",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-nvxb9",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0115 02:29:19.827689 24 deployment.go:68] Pod "webserver-deployment-6fc69b9478-tfpxd" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-6fc69b9478-tfpxd",
      GenerateName: (string) (len=32) "webserver-deployment-6fc69b9478-",
      Namespace: (string) (len=13) "deployment-36",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "018261fb-d805-4d3a-baef-aee2625a2e97",
      ResourceVersion: (string) (len=6) "174553",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872504956,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6fc69b9478"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "5ac251c2b41d9b65376146fc7d574d844409545e531c2968cf0bab3cb4ebf569",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=14) "10.1.155.56/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=14) "10.1.155.56/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-6fc69b9478",
          UID: (types.UID) (len=36) "ee3a067c-7a61-462b-bb1a-b56d261eeca1",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504956,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 65 65  33 61 30 36 37 63 2d 37  |d\":\"ee3a067c-7|
              00000090  61 36 31 2d 34 36 32 62  2d 62 62 31 61 2d 62 35  |a61-462b-bb1a-b5|
              000000a0  36 64 32 36 31 65 65 63  61 31 5c 22 7d 22 3a 7b  |6d261eeca1\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504957,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504958,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-9wxjz",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-9wxjz",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=13) "192.168.18.92",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504957,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504957,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504957,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504957,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504956,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "192.168.18.92",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "192.168.18.92"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872504957,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-9wxjz",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0115 02:29:19.846923 24 deployment.go:68] Pod "webserver-deployment-6fc69b9478-vh2vk" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-6fc69b9478-vh2vk",
      GenerateName: (string) (len=32) "webserver-deployment-6fc69b9478-",
      Namespace: (string) (len=13) "deployment-36",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "96fa1fd7-5ac9-4a86-aa5d-97b5b7673073",
      ResourceVersion: (string) (len=6) "174603",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872504959,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "6fc69b9478"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-6fc69b9478",
          UID: (types.UID) (len=36) "ee3a067c-7a61-462b-bb1a-b56d261eeca1",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504959,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 65 65  33 61 30 36 37 63 2d 37  |d\":\"ee3a067c-7|
              00000090  61 36 31 2d 34 36 32 62  2d 62 62 31 61 2d 62 35  |a61-462b-bb1a-b5|
              000000a0  36 64 32 36 31 65 65 63  61 31 5c 22 7d 22 3a 7b  |6d261eeca1\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-thk8c",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-thk8c",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=13) "192.168.18.92",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872504959,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0115 02:29:19.849113 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-36" for this suite. @ 01/15/25 02:29:19.906
• [9.443 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:505
  STEP: Creating a kubernetes client @ 01/15/25 02:29:19.949
  I0115 02:29:19.949635 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename configmap @ 01/15/25 02:29:19.954
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:29:20.092
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:29:20.113
  E0115 02:29:20.201150      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:29:20.353252 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-4430" for this suite. @ 01/15/25 02:29:20.403
• [0.485 seconds]
------------------------------
S
------------------------------
[sig-storage] VolumeAttachment Conformance should apply changes to a volumeattachment status [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/volume_attachment.go:180
  STEP: Creating a kubernetes client @ 01/15/25 02:29:20.434
  I0115 02:29:20.434914 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename volumeattachment @ 01/15/25 02:29:20.437
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:29:20.543
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:29:20.583
  STEP: Create VolumeAttachment "va-e2e-wndgv" on node "192.168.18.92" @ 01/15/25 02:29:20.658
  STEP: Patch VolumeAttachment "va-e2e-wndgv" on node "192.168.18.92" @ 01/15/25 02:29:20.805
  STEP: Reading "va-e2e-wndgv" Status @ 01/15/25 02:29:20.858
  STEP: Patching "va-e2e-wndgv" Status @ 01/15/25 02:29:20.882
  I0115 02:29:20.930906 24 volume_attachment.go:224] "va-e2e-wndgv" Status.Attached: true
  STEP: Updating "va-e2e-wndgv" Status @ 01/15/25 02:29:20.931
  I0115 02:29:20.980914 24 volume_attachment.go:240] "va-e2e-wndgv" Status.Attached: false
  STEP: Delete VolumeAttachment "va-e2e-wndgv" on node "192.168.18.92" @ 01/15/25 02:29:20.981
  STEP: Confirm deletion of VolumeAttachment "va-e2e-wndgv" on node "192.168.18.92" @ 01/15/25 02:29:21.004
  I0115 02:29:21.014463 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "volumeattachment-3661" for this suite. @ 01/15/25 02:29:21.034
• [0.640 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:537
  STEP: Creating a kubernetes client @ 01/15/25 02:29:21.075
  I0115 02:29:21.075660 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename pods @ 01/15/25 02:29:21.077
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:29:21.146
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:29:21.186
  E0115 02:29:21.217694      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:29:21.226648 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: creating the pod @ 01/15/25 02:29:21.227
  STEP: submitting the pod to kubernetes @ 01/15/25 02:29:21.228
  E0115 02:29:22.218557      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:29:23.220138      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:29:24.231493      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:29:25.236418      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:29:26.237259      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:29:27.238154      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:29:28.240365      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:29:28.868221 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-5312" for this suite. @ 01/15/25 02:29:28.956
• [7.969 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:150
  STEP: Creating a kubernetes client @ 01/15/25 02:29:29.046
  I0115 02:29:29.046635 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename emptydir @ 01/15/25 02:29:29.049
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:29:29.19
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:29:29.219
  E0115 02:29:29.248780      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 01/15/25 02:29:29.298
  E0115 02:29:30.252969      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:29:31.256305      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:29:32.268197      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:29:33.275241      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:29:34.273614      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:29:35.280005      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:29:36.283768      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:29:37.283928      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 02:29:37.677
  I0115 02:29:37.684748 24 output.go:207] Trying to get logs from node 192.168.18.92 pod pod-d7678666-0fe1-42cd-b7d9-5add774b20a6 container test-container: <nil>
  STEP: delete the pod @ 01/15/25 02:29:37.7
  I0115 02:29:37.724075 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-610" for this suite. @ 01/15/25 02:29:37.732
• [8.699 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:78
  STEP: Creating a kubernetes client @ 01/15/25 02:29:37.745
  I0115 02:29:37.745535 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename projected @ 01/15/25 02:29:37.747
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:29:37.815
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:29:37.861
  STEP: Creating projection with secret that has name projected-secret-test-map-fc933861-7ae0-4efb-a46c-f1c9f1aded73 @ 01/15/25 02:29:37.881
  STEP: Creating a pod to test consume secrets @ 01/15/25 02:29:37.892
  E0115 02:29:38.284035      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:29:39.284703      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:29:40.284841      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:29:41.287566      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 02:29:41.959
  I0115 02:29:41.980993 24 output.go:207] Trying to get logs from node 192.168.18.92 pod pod-projected-secrets-a44b4f8d-5b13-44b8-a6d1-3eead2ad60ca container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 01/15/25 02:29:42.039
  I0115 02:29:42.064116 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8484" for this suite. @ 01/15/25 02:29:42.069
• [4.330 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:237
  STEP: Creating a kubernetes client @ 01/15/25 02:29:42.075
  I0115 02:29:42.075777 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename crd-publish-openapi @ 01/15/25 02:29:42.077
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:29:42.092
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:29:42.097
  I0115 02:29:42.102512 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  E0115 02:29:42.288724      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:29:43.289955      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:29:44.290758      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 01/15/25 02:29:44.382
  I0115 02:29:44.382228 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=crd-publish-openapi-6685 --namespace=crd-publish-openapi-6685 create -f -'
  I0115 02:29:44.683696 24 builder.go:146] stderr: ""
  I0115 02:29:44.683860 24 builder.go:147] stdout: "e2e-test-crd-publish-openapi-9688-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  I0115 02:29:44.684057 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=crd-publish-openapi-6685 --namespace=crd-publish-openapi-6685 delete e2e-test-crd-publish-openapi-9688-crds test-cr'
  I0115 02:29:44.884713 24 builder.go:146] stderr: ""
  I0115 02:29:44.884830 24 builder.go:147] stdout: "e2e-test-crd-publish-openapi-9688-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
  I0115 02:29:44.884915 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=crd-publish-openapi-6685 --namespace=crd-publish-openapi-6685 apply -f -'
  I0115 02:29:45.157530 24 builder.go:146] stderr: ""
  I0115 02:29:45.158159 24 builder.go:147] stdout: "e2e-test-crd-publish-openapi-9688-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  I0115 02:29:45.158260 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=crd-publish-openapi-6685 --namespace=crd-publish-openapi-6685 delete e2e-test-crd-publish-openapi-9688-crds test-cr'
  E0115 02:29:45.292170      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:29:45.376886 24 builder.go:146] stderr: ""
  I0115 02:29:45.377077 24 builder.go:147] stdout: "e2e-test-crd-publish-openapi-9688-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR @ 01/15/25 02:29:45.377
  I0115 02:29:45.378957 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=crd-publish-openapi-6685 explain e2e-test-crd-publish-openapi-9688-crds'
  I0115 02:29:46.070270 24 builder.go:146] stderr: ""
  I0115 02:29:46.071348 24 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-unknown-in-nested.example.com\nKIND:       e2e-test-crd-publish-openapi-9688-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties in nested field for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  E0115 02:29:46.335861      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:29:47.336348      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:29:47.877538 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-6685" for this suite. @ 01/15/25 02:29:47.895
• [5.831 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:934
  STEP: Creating a kubernetes client @ 01/15/25 02:29:47.907
  I0115 02:29:47.907645 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename sched-preemption @ 01/15/25 02:29:47.909
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:29:47.93
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:29:47.938
  I0115 02:29:47.971790 24 wait.go:51] Waiting up to 1m0s for all nodes to be ready
  E0115 02:29:48.337396      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:29:49.340063      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:29:50.340403      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:29:51.340942      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:29:52.357473      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:29:53.358347      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:29:54.359410      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:29:55.359466      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:29:56.360176      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:29:57.360644      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:29:58.361812      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:29:59.362993      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:30:00.363236      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:30:01.366746      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:30:02.367105      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:30:03.368787      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:30:04.369966      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:30:05.370666      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:30:06.371442      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:30:07.372309      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:30:08.372599      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:30:09.372897      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:30:10.373139      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:30:11.373605      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:30:12.373984      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:30:13.377055      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:30:14.377228      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:30:15.378113      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:30:16.378509      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:30:17.379576      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:30:18.381722      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:30:19.381447      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:30:20.382263      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:30:21.383603      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:30:22.385137      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:30:23.388204      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:30:24.388194      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:30:25.389629      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:30:26.390362      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:30:27.391329      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:30:28.391479      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:30:29.392589      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:30:30.393440      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:30:31.394492      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:30:32.396315      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:30:33.398692      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:30:34.400824      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:30:35.401478      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:30:36.403100      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:30:37.403739      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:30:38.404723      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:30:39.405945      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:30:40.407619      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:30:41.407484      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:30:42.409050      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:30:43.410257      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:30:44.411399      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:30:45.412471      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:30:46.413157      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:30:47.414371      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:30:47.997831 24 util.go:396] Waiting for terminating namespaces to be deleted...
  STEP: Creating a kubernetes client @ 01/15/25 02:30:48.016
  I0115 02:30:48.016978 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename sched-preemption-path @ 01/15/25 02:30:48.021
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:30:48.082
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:30:48.089
  I0115 02:30:48.119010 24 preemption.go:940] PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
  I0115 02:30:48.123539 24 preemption.go:946] PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
  STEP: Removing a custom resource @ 01/15/25 02:30:48.173
  STEP: Removing a custom resource @ 01/15/25 02:30:48.184
  I0115 02:30:48.195861 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-path-4320" for this suite. @ 01/15/25 02:30:48.2
  I0115 02:30:48.206007 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-7369" for this suite. @ 01/15/25 02:30:48.305
• [60.419 seconds]
------------------------------
SSSSSS
------------------------------
[sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:208
  STEP: Creating a kubernetes client @ 01/15/25 02:30:48.328
  I0115 02:30:48.328410 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename endpointslice @ 01/15/25 02:30:48.332
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:30:48.388
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:30:48.407
  E0115 02:30:48.415149      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:30:49.415872      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:30:50.416999      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: referencing a single matching pod @ 01/15/25 02:30:50.543
  STEP: referencing matching pods with named port @ 01/15/25 02:30:50.551
  STEP: creating empty Endpoints and EndpointSlices for no matching Pods @ 01/15/25 02:30:50.557
  STEP: recreating EndpointSlices after they've been deleted @ 01/15/25 02:30:50.565
  I0115 02:30:50.581824 24 endpointslice.go:938] EndpointSlice for Service endpointslice-842/example-named-port not found
  E0115 02:30:51.418144      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:30:52.419331      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:30:52.587552 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-842" for this suite. @ 01/15/25 02:30:52.592
• [4.270 seconds]
------------------------------
S
------------------------------
[sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:86
  STEP: Creating a kubernetes client @ 01/15/25 02:30:52.597
  I0115 02:30:52.597626 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename downward-api @ 01/15/25 02:30:52.598
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:30:52.615
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:30:52.62
  STEP: Creating a pod to test downward API volume plugin @ 01/15/25 02:30:52.625
  E0115 02:30:53.419570      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:30:54.420081      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:30:55.419948      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:30:56.420556      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 02:30:56.659
  I0115 02:30:56.665263 24 output.go:207] Trying to get logs from node 192.168.18.92 pod downwardapi-volume-20bbc2a5-3f65-4566-bb8d-d055a05c3742 container client-container: <nil>
  STEP: delete the pod @ 01/15/25 02:30:56.675
  I0115 02:30:56.690726 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-3138" for this suite. @ 01/15/25 02:30:56.696
• [4.104 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for ExternalName services [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:352
  STEP: Creating a kubernetes client @ 01/15/25 02:30:56.702
  I0115 02:30:56.702500 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename dns @ 01/15/25 02:30:56.704
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:30:56.722
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:30:56.728
  STEP: Creating a test externalName service @ 01/15/25 02:30:56.733
  STEP: Running these commands on agnhost: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6575.svc.cluster.local CNAME > /results/agnhost_udp@dns-test-service-3.dns-6575.svc.cluster.local; sleep 1; done
   @ 01/15/25 02:30:56.739
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6575.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-6575.svc.cluster.local; sleep 1; done
   @ 01/15/25 02:30:56.739
  STEP: creating a pod to probe DNS @ 01/15/25 02:30:56.739
  STEP: submitting the pod to kubernetes @ 01/15/25 02:30:56.739
  E0115 02:30:57.428742      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:30:58.429005      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 01/15/25 02:30:58.768
  STEP: looking for the results for each expected name from probers @ 01/15/25 02:30:58.786
  I0115 02:30:58.816578 24 dns_common.go:499] File agnhost_udp@dns-test-service-3.dns-6575.svc.cluster.local from pod  dns-6575/dns-test-810c4d5d-0040-406e-8bfb-46fcc61dd079 contains '' instead of 'foo.example.com.'
  I0115 02:30:58.839013 24 dns_common.go:506] Lookups using dns-6575/dns-test-810c4d5d-0040-406e-8bfb-46fcc61dd079 failed for: [agnhost_udp@dns-test-service-3.dns-6575.svc.cluster.local]

  I0115 02:30:58.855932 24 dns_common.go:514] Pod client logs for webserver: 
  I0115 02:30:58.865497 24 dns_common.go:514] Pod client logs for agnhost-querier: 
  I0115 02:30:58.874546 24 dns_common.go:514] Pod client logs for jessie-querier: 
  E0115 02:30:59.429540      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:31:00.430066      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:31:01.431821      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:31:02.433174      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:31:03.433693      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:31:03.816296 24 dns_common.go:571] DNS probes using dns-test-810c4d5d-0040-406e-8bfb-46fcc61dd079 succeeded

  STEP: changing the externalName to bar.example.com @ 01/15/25 02:31:03.816
  STEP: Running these commands on agnhost: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6575.svc.cluster.local CNAME > /results/agnhost_udp@dns-test-service-3.dns-6575.svc.cluster.local; sleep 1; done
   @ 01/15/25 02:31:03.835
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6575.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-6575.svc.cluster.local; sleep 1; done
   @ 01/15/25 02:31:03.835
  STEP: creating a second pod to probe DNS @ 01/15/25 02:31:03.835
  STEP: submitting the pod to kubernetes @ 01/15/25 02:31:03.835
  E0115 02:31:04.434120      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:31:05.434926      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:31:06.435764      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:31:07.436706      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 01/15/25 02:31:07.899
  STEP: looking for the results for each expected name from probers @ 01/15/25 02:31:07.904
  I0115 02:31:07.924344 24 dns_common.go:571] DNS probes using dns-test-5494fc22-274a-463d-8972-14be58a1cd70 succeeded

  STEP: changing the service to type=ClusterIP @ 01/15/25 02:31:07.924
  W0115 02:31:07.950189      24 warnings.go:70] spec.externalName is ignored when spec.type is not "ExternalName"
  STEP: Running these commands on agnhost: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6575.svc.cluster.local A > /results/agnhost_udp@dns-test-service-3.dns-6575.svc.cluster.local; sleep 1; done
   @ 01/15/25 02:31:07.95
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6575.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-6575.svc.cluster.local; sleep 1; done
   @ 01/15/25 02:31:07.95
  STEP: creating a third pod to probe DNS @ 01/15/25 02:31:07.95
  STEP: submitting the pod to kubernetes @ 01/15/25 02:31:07.963
  E0115 02:31:08.437551      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:31:09.438450      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:31:10.441503      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:31:11.458818      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 01/15/25 02:31:12.028
  STEP: looking for the results for each expected name from probers @ 01/15/25 02:31:12.037
  I0115 02:31:12.059971 24 dns_common.go:571] DNS probes using dns-test-b34a5063-8511-4ae2-bc5a-e392e31343c6 succeeded

  STEP: deleting the pod @ 01/15/25 02:31:12.06
  STEP: deleting the pod @ 01/15/25 02:31:12.102
  STEP: deleting the pod @ 01/15/25 02:31:12.153
  STEP: deleting the test externalName service @ 01/15/25 02:31:12.23
  E0115 02:31:12.459443      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:31:12.526891 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-6575" for this suite. @ 01/15/25 02:31:12.561
• [15.953 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:100
  STEP: Creating a kubernetes client @ 01/15/25 02:31:12.656
  I0115 02:31:12.656693 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename projected @ 01/15/25 02:31:12.663
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:31:12.768
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:31:12.804
  STEP: Creating configMap with name projected-configmap-test-volume-map-8470d5be-9be1-4b90-ab1d-c2f49f811214 @ 01/15/25 02:31:12.833
  STEP: Creating a pod to test consume configMaps @ 01/15/25 02:31:12.867
  E0115 02:31:13.461236      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:31:14.470261      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:31:15.464721      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:31:16.465034      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 02:31:16.924
  I0115 02:31:16.931072 24 output.go:207] Trying to get logs from node 192.168.18.92 pod pod-projected-configmaps-a8558d0c-4480-4b26-bb4b-a20b1c050bbf container agnhost-container: <nil>
  STEP: delete the pod @ 01/15/25 02:31:16.942
  I0115 02:31:16.968641 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5667" for this suite. @ 01/15/25 02:31:16.977
• [4.336 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:88
  STEP: Creating a kubernetes client @ 01/15/25 02:31:16.993
  I0115 02:31:16.993652 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename projected @ 01/15/25 02:31:16.995
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:31:17.021
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:31:17.029
  STEP: Creating projection with secret that has name projected-secret-test-map-46c490d9-4a08-415c-9a68-50eea27bf3d6 @ 01/15/25 02:31:17.041
  STEP: Creating a pod to test consume secrets @ 01/15/25 02:31:17.05
  E0115 02:31:17.465570      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:31:18.467643      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:31:19.468764      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:31:20.470994      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 02:31:21.091
  I0115 02:31:21.099268 24 output.go:207] Trying to get logs from node 192.168.18.92 pod pod-projected-secrets-592470fc-a5f6-41bc-85fd-11eb5a0a5734 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 01/15/25 02:31:21.107
  I0115 02:31:21.122820 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8467" for this suite. @ 01/15/25 02:31:21.127
• [4.140 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] IngressClass API should support creating IngressClass API operations [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/ingressclass.go:268
  STEP: Creating a kubernetes client @ 01/15/25 02:31:21.133
  I0115 02:31:21.133290 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename ingressclass @ 01/15/25 02:31:21.134
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:31:21.15
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:31:21.155
  STEP: getting /apis @ 01/15/25 02:31:21.16
  STEP: getting /apis/networking.k8s.io @ 01/15/25 02:31:21.167
  STEP: getting /apis/networking.k8s.iov1 @ 01/15/25 02:31:21.169
  STEP: creating @ 01/15/25 02:31:21.17
  STEP: getting @ 01/15/25 02:31:21.185
  STEP: listing @ 01/15/25 02:31:21.188
  STEP: watching @ 01/15/25 02:31:21.191
  I0115 02:31:21.192017 24 ingressclass.go:348] starting watch
  STEP: patching @ 01/15/25 02:31:21.194
  STEP: updating @ 01/15/25 02:31:21.2
  I0115 02:31:21.204717 24 ingressclass.go:364] waiting for watch events with expected annotations
  I0115 02:31:21.204790 24 ingressclass.go:377] saw patched and updated annotations
  STEP: deleting @ 01/15/25 02:31:21.204
  STEP: deleting a collection @ 01/15/25 02:31:21.216
  I0115 02:31:21.230492 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingressclass-8081" for this suite. @ 01/15/25 02:31:21.235
• [0.107 seconds]
------------------------------
S
------------------------------
[sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:205
  STEP: Creating a kubernetes client @ 01/15/25 02:31:21.24
  I0115 02:31:21.240912 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename secrets @ 01/15/25 02:31:21.243
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:31:21.262
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:31:21.267
  STEP: Creating secret with name s-test-opt-del-035ade9c-562e-4f94-8c75-fdf6d54dce8b @ 01/15/25 02:31:21.34
  STEP: Creating secret with name s-test-opt-upd-0136ed2d-c585-4944-af07-cd704c98f79a @ 01/15/25 02:31:21.359
  STEP: Creating the pod @ 01/15/25 02:31:21.38
  E0115 02:31:21.472046      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:31:22.472713      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:31:23.473364      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Deleting secret s-test-opt-del-035ade9c-562e-4f94-8c75-fdf6d54dce8b @ 01/15/25 02:31:23.524
  STEP: Updating secret s-test-opt-upd-0136ed2d-c585-4944-af07-cd704c98f79a @ 01/15/25 02:31:23.532
  STEP: Creating secret with name s-test-opt-create-3f358598-2306-4451-8bc1-e3606b1b51a1 @ 01/15/25 02:31:23.539
  STEP: waiting to observe update in volume @ 01/15/25 02:31:23.545
  E0115 02:31:24.474506      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:31:25.476009      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:31:25.601375 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-8285" for this suite. @ 01/15/25 02:31:25.609
• [4.379 seconds]
------------------------------
[sig-cli] Kubectl client Kubectl label should update the label on a resource [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1621
  STEP: Creating a kubernetes client @ 01/15/25 02:31:25.619
  I0115 02:31:25.620056 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename kubectl @ 01/15/25 02:31:25.621
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:31:25.646
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:31:25.657
  STEP: creating the pod @ 01/15/25 02:31:25.666
  I0115 02:31:25.666349 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-5103 create -f -'
  I0115 02:31:26.096457 24 builder.go:146] stderr: ""
  I0115 02:31:26.096561 24 builder.go:147] stdout: "pod/pause created\n"
  E0115 02:31:26.485726      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:31:27.489202      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:31:28.491171      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:31:29.491213      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: adding the label testing-label with value testing-label-value to a pod @ 01/15/25 02:31:30.164
  I0115 02:31:30.164779 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-5103 label pods pause testing-label=testing-label-value'
  I0115 02:31:30.404236 24 builder.go:146] stderr: ""
  I0115 02:31:30.404291 24 builder.go:147] stdout: "pod/pause labeled\n"
  STEP: verifying the pod has the label testing-label with the value testing-label-value @ 01/15/25 02:31:30.404
  I0115 02:31:30.404415 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-5103 get pod pause -L testing-label'
  E0115 02:31:30.491732      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:31:30.576787 24 builder.go:146] stderr: ""
  I0115 02:31:30.576876 24 builder.go:147] stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
  STEP: removing the label testing-label of a pod @ 01/15/25 02:31:30.576
  I0115 02:31:30.577013 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-5103 label pods pause testing-label-'
  I0115 02:31:30.797941 24 builder.go:146] stderr: ""
  I0115 02:31:30.798000 24 builder.go:147] stdout: "pod/pause unlabeled\n"
  STEP: verifying the pod doesn't have the label testing-label @ 01/15/25 02:31:30.798
  I0115 02:31:30.798093 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-5103 get pod pause -L testing-label'
  I0115 02:31:30.985564 24 builder.go:146] stderr: ""
  I0115 02:31:30.985631 24 builder.go:147] stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    \n"
  STEP: using delete to clean up resources @ 01/15/25 02:31:30.986
  I0115 02:31:30.986261 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-5103 delete --grace-period=0 --force -f -'
  I0115 02:31:31.138975 24 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0115 02:31:31.139084 24 builder.go:147] stdout: "pod \"pause\" force deleted\n"
  I0115 02:31:31.139164 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-5103 get rc,svc -l name=pause --no-headers'
  I0115 02:31:31.388700 24 builder.go:146] stderr: "No resources found in kubectl-5103 namespace.\n"
  I0115 02:31:31.388776 24 builder.go:147] stdout: ""
  I0115 02:31:31.388848 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-5103 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  E0115 02:31:31.494378      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:31:31.599647 24 builder.go:146] stderr: ""
  I0115 02:31:31.599774 24 builder.go:147] stdout: ""
  I0115 02:31:31.605349 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-5103" for this suite. @ 01/15/25 02:31:31.619
• [6.020 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:90
  STEP: Creating a kubernetes client @ 01/15/25 02:31:31.643
  I0115 02:31:31.643200 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename configmap @ 01/15/25 02:31:31.646
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:31:31.682
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:31:31.711
  STEP: Creating configMap with name configmap-test-volume-map-49b44f71-2faf-4a28-85b9-66a5f9e847d7 @ 01/15/25 02:31:31.729
  STEP: Creating a pod to test consume configMaps @ 01/15/25 02:31:31.737
  E0115 02:31:32.503252      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:31:33.509122      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:31:34.525759      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:31:35.525890      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:31:36.528977      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:31:37.530045      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 02:31:37.858
  I0115 02:31:37.875065 24 output.go:207] Trying to get logs from node 192.168.18.92 pod pod-configmaps-50d3fc90-7448-404d-9592-47cb481ca92a container agnhost-container: <nil>
  STEP: delete the pod @ 01/15/25 02:31:37.917
  I0115 02:31:37.950430 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-5131" for this suite. @ 01/15/25 02:31:37.975
• [6.347 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:247
  STEP: Creating a kubernetes client @ 01/15/25 02:31:37.993
  I0115 02:31:37.993528 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename webhook @ 01/15/25 02:31:37.995
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:31:38.024
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:31:38.034
  STEP: Setting up server cert @ 01/15/25 02:31:38.125
  E0115 02:31:38.530478      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 01/15/25 02:31:38.95
  STEP: Deploying the webhook pod @ 01/15/25 02:31:38.965
  STEP: Wait for the deployment to be ready @ 01/15/25 02:31:38.987
  I0115 02:31:39.003292 24 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0115 02:31:39.531411      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:31:40.531869      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 01/15/25 02:31:41.046
  STEP: Verifying the service has paired with the endpoint @ 01/15/25 02:31:41.093
  E0115 02:31:41.532651      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:31:42.095534 24 util.go:423] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the mutating configmap webhook via the AdmissionRegistration API @ 01/15/25 02:31:42.127
  STEP: create a configmap that should be updated by the webhook @ 01/15/25 02:31:42.162
  I0115 02:31:42.224880 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6536" for this suite. @ 01/15/25 02:31:42.234
  STEP: Destroying namespace "webhook-markers-4775" for this suite. @ 01/15/25 02:31:42.24
• [4.255 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:171
  STEP: Creating a kubernetes client @ 01/15/25 02:31:42.247
  I0115 02:31:42.247965 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename configmap @ 01/15/25 02:31:42.248
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:31:42.264
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:31:42.27
  STEP: creating a ConfigMap @ 01/15/25 02:31:42.277
  STEP: fetching the ConfigMap @ 01/15/25 02:31:42.282
  STEP: patching the ConfigMap @ 01/15/25 02:31:42.286
  STEP: listing all ConfigMaps in all namespaces with a label selector @ 01/15/25 02:31:42.29
  STEP: deleting the ConfigMap by collection with a label selector @ 01/15/25 02:31:42.292
  STEP: listing all ConfigMaps in test namespace @ 01/15/25 02:31:42.298
  I0115 02:31:42.301379 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-53" for this suite. @ 01/15/25 02:31:42.339
• [0.117 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:908
  STEP: Creating a kubernetes client @ 01/15/25 02:31:42.367
  I0115 02:31:42.367842 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename statefulset @ 01/15/25 02:31:42.371
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:31:42.419
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:31:42.437
  STEP: Creating service test in namespace statefulset-1338 @ 01/15/25 02:31:42.448
  STEP: Creating statefulset ss in namespace statefulset-1338 @ 01/15/25 02:31:42.456
  I0115 02:31:42.470690 24 wait.go:40] Found 0 stateful pods, waiting for 1
  E0115 02:31:42.534832      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:31:43.538632      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:31:44.538920      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:31:45.539055      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:31:46.540306      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:31:47.540670      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:31:48.542479      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:31:49.542983      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:31:50.543723      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:31:51.544413      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:31:52.477910 24 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: getting scale subresource @ 01/15/25 02:31:52.493
  STEP: updating a scale subresource @ 01/15/25 02:31:52.497
  STEP: verifying the statefulset Spec.Replicas was modified @ 01/15/25 02:31:52.502
  STEP: Patch a scale subresource @ 01/15/25 02:31:52.507
  STEP: verifying the statefulset Spec.Replicas was modified @ 01/15/25 02:31:52.513
  I0115 02:31:52.523100 24 statefulset.go:138] Deleting all statefulset in ns statefulset-1338
  I0115 02:31:52.529714 24 rest.go:152] Scaling statefulset ss to 0
  E0115 02:31:52.544714      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:31:53.545131      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:31:54.546224      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:31:55.547131      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:31:56.548071      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:31:57.548625      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:31:58.549087      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:31:59.549470      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:32:00.550707      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:32:01.550467      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:32:02.551782      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:32:02.642725 24 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I0115 02:32:02.657162 24 rest.go:90] Deleting statefulset ss
  I0115 02:32:02.690853 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-1338" for this suite. @ 01/15/25 02:32:02.702
• [20.342 seconds]
------------------------------
[sig-scheduling] LimitRange should list, patch and delete a LimitRange by collection [Conformance] [sig-scheduling, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/limit_range.go:253
  STEP: Creating a kubernetes client @ 01/15/25 02:32:02.708
  I0115 02:32:02.708877 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename limitrange @ 01/15/25 02:32:02.71
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:32:02.74
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:32:02.747
  STEP: Creating LimitRange "e2e-limitrange-zbw9l" in namespace "limitrange-7756" @ 01/15/25 02:32:02.756
  STEP: Creating another limitRange in another namespace @ 01/15/25 02:32:02.77
  I0115 02:32:02.845619 24 limit_range.go:299] Namespace "e2e-limitrange-zbw9l-5404" created
  I0115 02:32:02.845731 24 limit_range.go:300] Creating LimitRange "e2e-limitrange-zbw9l" in namespace "e2e-limitrange-zbw9l-5404"
  STEP: Listing all LimitRanges with label "e2e-test=e2e-limitrange-zbw9l" @ 01/15/25 02:32:02.861
  I0115 02:32:02.872680 24 limit_range.go:309] Found 2 limitRanges
  STEP: Patching LimitRange "e2e-limitrange-zbw9l" in "limitrange-7756" namespace @ 01/15/25 02:32:02.872
  I0115 02:32:02.885838 24 limit_range.go:335] LimitRange "e2e-limitrange-zbw9l" has been patched
  STEP: Delete LimitRange "e2e-limitrange-zbw9l" by Collection with labelSelector: "e2e-limitrange-zbw9l=patched" @ 01/15/25 02:32:02.885
  STEP: Confirm that the limitRange "e2e-limitrange-zbw9l" has been deleted @ 01/15/25 02:32:02.898
  I0115 02:32:02.898690 24 limit_range.go:443] Requesting list of LimitRange to confirm quantity
  I0115 02:32:02.904033 24 limit_range.go:453] Found 0 LimitRange with label "e2e-limitrange-zbw9l=patched"
  I0115 02:32:02.904157 24 limit_range.go:344] LimitRange "e2e-limitrange-zbw9l" has been deleted.
  STEP: Confirm that a single LimitRange still exists with label "e2e-test=e2e-limitrange-zbw9l" @ 01/15/25 02:32:02.904
  I0115 02:32:02.909989 24 limit_range.go:350] Found 1 limitRange
  I0115 02:32:02.910346 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-7756" for this suite. @ 01/15/25 02:32:02.919
  STEP: Destroying namespace "e2e-limitrange-zbw9l-5404" for this suite. @ 01/15/25 02:32:02.93
• [0.231 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:116
  STEP: Creating a kubernetes client @ 01/15/25 02:32:02.94
  I0115 02:32:02.940797 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename var-expansion @ 01/15/25 02:32:02.942
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:32:02.966
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:32:02.975
  STEP: Creating a pod to test substitution in volume subpath @ 01/15/25 02:32:02.998
  E0115 02:32:03.551907      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:32:04.553265      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:32:05.554272      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:32:06.554910      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 02:32:07.036
  I0115 02:32:07.049144 24 output.go:207] Trying to get logs from node 192.168.18.92 pod var-expansion-9dfcc6fc-b139-4f40-89e3-a0b63b98ab8c container dapi-container: <nil>
  STEP: delete the pod @ 01/15/25 02:32:07.077
  I0115 02:32:07.099698 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-2356" for this suite. @ 01/15/25 02:32:07.107
• [4.173 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo should create and stop a replication controller [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:337
  STEP: Creating a kubernetes client @ 01/15/25 02:32:07.113
  I0115 02:32:07.113910 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename kubectl @ 01/15/25 02:32:07.114
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:32:07.134
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:32:07.14
  STEP: creating a replication controller @ 01/15/25 02:32:07.146
  I0115 02:32:07.146286 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-5301 create -f -'
  I0115 02:32:07.365803 24 builder.go:146] stderr: ""
  I0115 02:32:07.365850 24 builder.go:147] stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 01/15/25 02:32:07.365
  I0115 02:32:07.366252 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-5301 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0115 02:32:07.467747 24 builder.go:146] stderr: ""
  I0115 02:32:07.467815 24 builder.go:147] stdout: "update-demo-nautilus-m4qll update-demo-nautilus-wn7l4 "
  I0115 02:32:07.467875 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-5301 get pods update-demo-nautilus-m4qll -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0115 02:32:07.544406 24 builder.go:146] stderr: ""
  I0115 02:32:07.544472 24 builder.go:147] stdout: ""
  I0115 02:32:07.544493 24 kubectl.go:2499] update-demo-nautilus-m4qll is created but not running
  E0115 02:32:07.557056      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:32:08.557774      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:32:09.559017      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:32:10.560232      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:32:11.561309      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:32:12.545020 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-5301 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  E0115 02:32:12.561253      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:32:12.645803 24 builder.go:146] stderr: ""
  I0115 02:32:12.645884 24 builder.go:147] stdout: "update-demo-nautilus-m4qll update-demo-nautilus-wn7l4 "
  I0115 02:32:12.645951 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-5301 get pods update-demo-nautilus-m4qll -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0115 02:32:12.738909 24 builder.go:146] stderr: ""
  I0115 02:32:12.738981 24 builder.go:147] stdout: "true"
  I0115 02:32:12.739037 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-5301 get pods update-demo-nautilus-m4qll -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0115 02:32:12.818958 24 builder.go:146] stderr: ""
  I0115 02:32:12.819038 24 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0115 02:32:12.819061 24 kubectl.go:2390] validating pod update-demo-nautilus-m4qll
  I0115 02:32:12.824599 24 kubectl.go:2410] got data: {
    "image": "nautilus.jpg"
  }

  I0115 02:32:12.824685 24 kubectl.go:2415] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0115 02:32:12.824702 24 kubectl.go:2517] update-demo-nautilus-m4qll is verified up and running
  I0115 02:32:12.824743 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-5301 get pods update-demo-nautilus-wn7l4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0115 02:32:12.895456 24 builder.go:146] stderr: ""
  I0115 02:32:12.895526 24 builder.go:147] stdout: "true"
  I0115 02:32:12.895589 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-5301 get pods update-demo-nautilus-wn7l4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0115 02:32:12.957352 24 builder.go:146] stderr: ""
  I0115 02:32:12.957423 24 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0115 02:32:12.957441 24 kubectl.go:2390] validating pod update-demo-nautilus-wn7l4
  I0115 02:32:12.962652 24 kubectl.go:2410] got data: {
    "image": "nautilus.jpg"
  }

  I0115 02:32:12.962758 24 kubectl.go:2415] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0115 02:32:12.962776 24 kubectl.go:2517] update-demo-nautilus-wn7l4 is verified up and running
  STEP: using delete to clean up resources @ 01/15/25 02:32:12.962
  I0115 02:32:12.962842 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-5301 delete --grace-period=0 --force -f -'
  I0115 02:32:13.039115 24 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0115 02:32:13.039213 24 builder.go:147] stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
  I0115 02:32:13.039282 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-5301 get rc,svc -l name=update-demo --no-headers'
  I0115 02:32:13.175672 24 builder.go:146] stderr: "No resources found in kubectl-5301 namespace.\n"
  I0115 02:32:13.175763 24 builder.go:147] stdout: ""
  I0115 02:32:13.175829 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-5301 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  I0115 02:32:13.284161 24 builder.go:146] stderr: ""
  I0115 02:32:13.284240 24 builder.go:147] stdout: ""
  I0115 02:32:13.284417 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-5301" for this suite. @ 01/15/25 02:32:13.292
• [6.190 seconds]
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl version should check is all data is printed [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1720
  STEP: Creating a kubernetes client @ 01/15/25 02:32:13.304
  I0115 02:32:13.304690 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename kubectl @ 01/15/25 02:32:13.305
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:32:13.337
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:32:13.344
  I0115 02:32:13.350272 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-9795 version'
  I0115 02:32:13.445511 24 builder.go:146] stderr: ""
  I0115 02:32:13.445585 24 builder.go:147] stdout: "Client Version: v1.32.0\nKustomize Version: v5.5.0\nServer Version: v1.32.0\n"
  I0115 02:32:13.445886 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-9795" for this suite. @ 01/15/25 02:32:13.45
• [0.154 seconds]
------------------------------
S
------------------------------
[sig-apps] CronJob should support CronJob API operations [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:366
  STEP: Creating a kubernetes client @ 01/15/25 02:32:13.459
  I0115 02:32:13.459099 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename cronjob @ 01/15/25 02:32:13.46
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:32:13.478
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:32:13.486
  STEP: Creating a cronjob @ 01/15/25 02:32:13.491
  STEP: creating @ 01/15/25 02:32:13.491
  STEP: getting @ 01/15/25 02:32:13.499
  STEP: listing @ 01/15/25 02:32:13.502
  STEP: watching @ 01/15/25 02:32:13.51
  I0115 02:32:13.510612 24 cronjob.go:395] starting watch
  STEP: cluster-wide listing @ 01/15/25 02:32:13.512
  STEP: cluster-wide watching @ 01/15/25 02:32:13.516
  I0115 02:32:13.516753 24 cronjob.go:407] starting watch
  STEP: patching @ 01/15/25 02:32:13.518
  STEP: updating @ 01/15/25 02:32:13.525
  I0115 02:32:13.533803 24 cronjob.go:431] waiting for watch events with expected annotations
  I0115 02:32:13.533897 24 cronjob.go:445] saw patched and updated annotations
  STEP: patching /status @ 01/15/25 02:32:13.534
  STEP: updating /status @ 01/15/25 02:32:13.539
  STEP: get /status @ 01/15/25 02:32:13.547
  STEP: deleting @ 01/15/25 02:32:13.55
  E0115 02:32:13.562255      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: deleting a collection @ 01/15/25 02:32:13.563
  I0115 02:32:13.574129 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-1990" for this suite. @ 01/15/25 02:32:13.577
• [0.129 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:144
  STEP: Creating a kubernetes client @ 01/15/25 02:32:13.588
  I0115 02:32:13.588849 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename disruption @ 01/15/25 02:32:13.589
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:32:13.614
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:32:13.644
  STEP: Waiting for the pdb to be processed @ 01/15/25 02:32:13.658
  E0115 02:32:14.563449      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:32:15.564024      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Waiting for all pods to be running @ 01/15/25 02:32:15.743
  I0115 02:32:15.754148 24 disruption.go:691] running pods: 0 < 3
  E0115 02:32:16.564997      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:32:17.565867      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:32:17.759910 24 disruption.go:691] running pods: 1 < 3
  E0115 02:32:18.567139      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:32:19.567897      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:32:19.749954 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-9421" for this suite. @ 01/15/25 02:32:19.755
• [6.173 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Services should serve a basic endpoint from pods [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:760
  STEP: Creating a kubernetes client @ 01/15/25 02:32:19.761
  I0115 02:32:19.761823 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename services @ 01/15/25 02:32:19.762
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:32:19.779
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:32:19.784
  STEP: creating service endpoint-test2 in namespace services-2682 @ 01/15/25 02:32:19.789
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2682 to expose endpoints map[] @ 01/15/25 02:32:19.797
  I0115 02:32:19.803174 24 service.go:4428] Failed go get Endpoints object: endpoints "endpoint-test2" not found
  E0115 02:32:20.568697      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:32:20.811873 24 service.go:4460] successfully validated that service endpoint-test2 in namespace services-2682 exposes endpoints map[]
  STEP: Creating pod pod1 in namespace services-2682 @ 01/15/25 02:32:20.811
  E0115 02:32:21.569611      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:32:22.570524      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2682 to expose endpoints map[pod1:[80]] @ 01/15/25 02:32:22.856
  I0115 02:32:22.886481 24 service.go:4460] successfully validated that service endpoint-test2 in namespace services-2682 exposes endpoints map[pod1:[80]]
  STEP: Checking if the Service forwards traffic to pod1 @ 01/15/25 02:32:22.886
  I0115 02:32:22.886703 24 resource.go:361] Creating new exec pod
  E0115 02:32:23.572408      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:32:24.573112      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:32:25.573901      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:32:25.904702 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-2682 exec execpodgrs96 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  I0115 02:32:26.201539 24 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 (169.169.144.158) 80 port [tcp/http] succeeded!\n"
  I0115 02:32:26.201617 24 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0115 02:32:26.201743 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-2682 exec execpodgrs96 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 169.169.144.158 80'
  E0115 02:32:26.575698      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:32:26.668448 24 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 169.169.144.158 80\nConnection to 169.169.144.158 80 port [tcp/http] succeeded!\n"
  I0115 02:32:26.668541 24 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Creating pod pod2 in namespace services-2682 @ 01/15/25 02:32:26.668
  E0115 02:32:27.576830      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:32:28.577442      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:32:29.578087      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:32:30.579395      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2682 to expose endpoints map[pod1:[80] pod2:[80]] @ 01/15/25 02:32:30.71
  I0115 02:32:30.736799 24 service.go:4460] successfully validated that service endpoint-test2 in namespace services-2682 exposes endpoints map[pod1:[80] pod2:[80]]
  STEP: Checking if the Service forwards traffic to pod1 and pod2 @ 01/15/25 02:32:30.736
  E0115 02:32:31.584240      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:32:31.737554 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-2682 exec execpodgrs96 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  I0115 02:32:32.190305 24 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 (169.169.144.158) 80 port [tcp/http] succeeded!\n"
  I0115 02:32:32.190397 24 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0115 02:32:32.190545 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-2682 exec execpodgrs96 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 169.169.144.158 80'
  I0115 02:32:32.532164 24 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 169.169.144.158 80\nConnection to 169.169.144.158 80 port [tcp/http] succeeded!\n"
  I0115 02:32:32.532289 24 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod1 in namespace services-2682 @ 01/15/25 02:32:32.532
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2682 to expose endpoints map[pod2:[80]] @ 01/15/25 02:32:32.559
  E0115 02:32:32.585414      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:32:32.620255 24 service.go:4460] successfully validated that service endpoint-test2 in namespace services-2682 exposes endpoints map[pod2:[80]]
  STEP: Checking if the Service forwards traffic to pod2 @ 01/15/25 02:32:32.62
  E0115 02:32:33.586454      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:32:33.621073 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-2682 exec execpodgrs96 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  I0115 02:32:34.038952 24 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 (169.169.144.158) 80 port [tcp/http] succeeded!\n"
  I0115 02:32:34.039034 24 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0115 02:32:34.039181 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-2682 exec execpodgrs96 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 169.169.144.158 80'
  I0115 02:32:34.449384 24 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 169.169.144.158 80\nConnection to 169.169.144.158 80 port [tcp/http] succeeded!\n"
  I0115 02:32:34.449471 24 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod2 in namespace services-2682 @ 01/15/25 02:32:34.449
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2682 to expose endpoints map[] @ 01/15/25 02:32:34.511
  E0115 02:32:34.586599      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:32:34.627846 24 service.go:4460] successfully validated that service endpoint-test2 in namespace services-2682 exposes endpoints map[]
  I0115 02:32:34.744594 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-2682" for this suite. @ 01/15/25 02:32:34.792
• [15.049 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:110
  STEP: Creating a kubernetes client @ 01/15/25 02:32:34.813
  I0115 02:32:34.813622 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename emptydir @ 01/15/25 02:32:34.816
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:32:34.876
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:32:34.887
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 01/15/25 02:32:34.898
  E0115 02:32:35.586844      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:32:36.589141      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:32:37.588613      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:32:38.589636      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:32:39.591358      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:32:40.595913      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 02:32:40.952
  I0115 02:32:40.960991 24 output.go:207] Trying to get logs from node 192.168.18.92 pod pod-07ea0e81-577d-45ab-9603-cb09e9e916cf container test-container: <nil>
  STEP: delete the pod @ 01/15/25 02:32:40.99
  I0115 02:32:41.199509 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-6671" for this suite. @ 01/15/25 02:32:41.269
• [6.491 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:223
  STEP: Creating a kubernetes client @ 01/15/25 02:32:41.313
  I0115 02:32:41.313357 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename projected @ 01/15/25 02:32:41.316
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:32:41.497
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:32:41.517
  STEP: Creating a pod to test downward API volume plugin @ 01/15/25 02:32:41.553
  E0115 02:32:41.596090      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:32:42.596199      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:32:43.597165      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:32:44.598580      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:32:45.599551      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:32:46.599994      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:32:47.600626      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 02:32:47.706
  I0115 02:32:47.738891 24 output.go:207] Trying to get logs from node 192.168.18.92 pod downwardapi-volume-68d2626b-5fb3-4030-9401-e60074da2c6d container client-container: <nil>
  STEP: delete the pod @ 01/15/25 02:32:47.805
  I0115 02:32:47.877884 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4974" for this suite. @ 01/15/25 02:32:47.902
• [6.603 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should delete a collection of services [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3599
  STEP: Creating a kubernetes client @ 01/15/25 02:32:47.916
  I0115 02:32:47.916877 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename services @ 01/15/25 02:32:47.919
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:32:47.986
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:32:48.009
  STEP: creating a collection of services @ 01/15/25 02:32:48.033
  I0115 02:32:48.035423 24 service.go:3635] Creating e2e-svc-a-p258q
  I0115 02:32:48.077782 24 service.go:3635] Creating e2e-svc-b-p7lbp
  I0115 02:32:48.203289 24 service.go:3635] Creating e2e-svc-c-5rlzv
  STEP: deleting service collection @ 01/15/25 02:32:48.276
  I0115 02:32:48.536030 24 service.go:3670] Collection of services has been deleted
  I0115 02:32:48.543892 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-6363" for this suite. @ 01/15/25 02:32:48.568
• [0.680 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:154
  STEP: Creating a kubernetes client @ 01/15/25 02:32:48.597
  I0115 02:32:48.597585 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  E0115 02:32:48.601042      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 01/15/25 02:32:48.601
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:32:48.659
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:32:48.673
  STEP: create the container to handle the HTTPGet hook request. @ 01/15/25 02:32:48.705
  E0115 02:32:49.602242      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:32:50.603717      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:32:51.608206      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:32:52.608373      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 01/15/25 02:32:52.907
  E0115 02:32:53.611053      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:32:54.612514      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:32:55.612769      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:32:56.614344      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: delete the pod with lifecycle hook @ 01/15/25 02:32:57.009
  E0115 02:32:57.615505      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:32:58.618337      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:32:59.621519      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:33:00.622484      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: check prestop hook @ 01/15/25 02:33:01.046
  I0115 02:33:01.060390 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-4913" for this suite. @ 01/15/25 02:33:01.067
• [12.490 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:90
  STEP: Creating a kubernetes client @ 01/15/25 02:33:01.089
  I0115 02:33:01.089419 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename containers @ 01/15/25 02:33:01.091
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:33:01.116
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:33:01.125
  STEP: Creating a pod to test override all @ 01/15/25 02:33:01.132
  E0115 02:33:01.622899      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:33:02.623403      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:33:03.623715      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:33:04.624918      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 02:33:05.17
  I0115 02:33:05.177070 24 output.go:207] Trying to get logs from node 192.168.18.92 pod client-containers-e68b90c2-80f3-4af3-a355-0eb326fff5f9 container agnhost-container: <nil>
  STEP: delete the pod @ 01/15/25 02:33:05.194
  I0115 02:33:05.216324 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-4542" for this suite. @ 01/15/25 02:33:05.228
• [4.154 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:160
  STEP: Creating a kubernetes client @ 01/15/25 02:33:05.243
  I0115 02:33:05.243647 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename emptydir @ 01/15/25 02:33:05.245
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:33:05.278
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:33:05.287
  STEP: Creating a pod to test emptydir volume type on node default medium @ 01/15/25 02:33:05.295
  E0115 02:33:05.625680      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:33:06.631928      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:33:07.632111      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:33:08.633661      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 02:33:09.342
  I0115 02:33:09.348147 24 output.go:207] Trying to get logs from node 192.168.18.92 pod pod-41388c81-c5c2-41a7-90f2-5b253cf10524 container test-container: <nil>
  STEP: delete the pod @ 01/15/25 02:33:09.367
  I0115 02:33:09.394797 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-564" for this suite. @ 01/15/25 02:33:09.406
• [4.172 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:104
  STEP: Creating a kubernetes client @ 01/15/25 02:33:09.415
  I0115 02:33:09.416018 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename resourcequota @ 01/15/25 02:33:09.418
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:33:09.445
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:33:09.46
  STEP: Counting existing ResourceQuota @ 01/15/25 02:33:09.471
  E0115 02:33:09.688031      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:33:10.688111      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:33:11.689223      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:33:12.690885      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:33:13.692577      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 01/15/25 02:33:14.476
  STEP: Ensuring resource quota status is calculated @ 01/15/25 02:33:14.484
  E0115 02:33:14.693331      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:33:15.693749      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Creating a Service @ 01/15/25 02:33:16.528
  STEP: Creating a NodePort Service @ 01/15/25 02:33:16.61
  STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota @ 01/15/25 02:33:16.672
  E0115 02:33:16.695192      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota status captures service creation @ 01/15/25 02:33:16.699
  E0115 02:33:17.697901      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:33:18.699034      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Deleting Services @ 01/15/25 02:33:18.715
  STEP: Ensuring resource quota status released usage @ 01/15/25 02:33:18.805
  E0115 02:33:19.701851      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:33:20.703256      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:33:20.818674 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-3972" for this suite. @ 01/15/25 02:33:20.833
• [11.444 seconds]
------------------------------
S
------------------------------
[sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/ephemeral_containers.go:51
  STEP: Creating a kubernetes client @ 01/15/25 02:33:20.861
  I0115 02:33:20.861570 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename ephemeral-containers-test @ 01/15/25 02:33:20.865
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:33:20.906
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:33:20.925
  STEP: creating a target pod @ 01/15/25 02:33:20.933
  E0115 02:33:21.704587      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:33:22.705344      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: adding an ephemeral container @ 01/15/25 02:33:22.978
  E0115 02:33:23.706832      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:33:24.707583      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:33:25.708837      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:33:26.717027      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: checking pod container endpoints @ 01/15/25 02:33:27.028
  I0115 02:33:27.028943 24 exec_util.go:59] ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-974 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0115 02:33:27.028996 24 exec_util.go:64] ExecWithOptions: Clientset creation
  I0115 02:33:27.029117 24 exec_util.go:80] ExecWithOptions: execute(POST https://169.169.0.1:443/api/v1/namespaces/ephemeral-containers-test-974/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&stderr=true&stdout=true)
  I0115 02:33:27.115092 24 exec_util.go:108] Exec stderr: ""
  I0115 02:33:27.124542 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ephemeral-containers-test-974" for this suite. @ 01/15/25 02:33:27.13
• [6.277 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:305
  STEP: Creating a kubernetes client @ 01/15/25 02:33:27.137
  I0115 02:33:27.137913 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename namespaces @ 01/15/25 02:33:27.139
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:33:27.151
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:33:27.157
  STEP: Read namespace status @ 01/15/25 02:33:27.161
  I0115 02:33:27.164374 24 namespace.go:318] Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
  STEP: Patch namespace status @ 01/15/25 02:33:27.164
  I0115 02:33:27.170784 24 namespace.go:338] Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
  STEP: Update namespace status @ 01/15/25 02:33:27.17
  I0115 02:33:27.178691 24 namespace.go:363] Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
  I0115 02:33:27.178882 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-2428" for this suite. @ 01/15/25 02:33:27.234
• [0.122 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:220
  STEP: Creating a kubernetes client @ 01/15/25 02:33:27.26
  I0115 02:33:27.260966 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename emptydir @ 01/15/25 02:33:27.264
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:33:27.313
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:33:27.322
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 01/15/25 02:33:27.328
  E0115 02:33:27.720327      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:33:28.720830      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:33:29.722240      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:33:30.723673      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 02:33:31.378
  I0115 02:33:31.384557 24 output.go:207] Trying to get logs from node 192.168.18.92 pod pod-1f06297d-540e-46ce-b996-d358a0a9b760 container test-container: <nil>
  STEP: delete the pod @ 01/15/25 02:33:31.404
  I0115 02:33:31.499519 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-4898" for this suite. @ 01/15/25 02:33:31.505
• [4.255 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/security_context.go:337
  STEP: Creating a kubernetes client @ 01/15/25 02:33:31.516
  I0115 02:33:31.516029 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename security-context @ 01/15/25 02:33:31.517
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:33:31.533
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:33:31.539
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 01/15/25 02:33:31.544
  E0115 02:33:31.727205      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:33:32.727667      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:33:33.729774      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:33:34.730253      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 02:33:35.601
  I0115 02:33:35.604811 24 output.go:207] Trying to get logs from node 192.168.18.92 pod security-context-a5948b68-e51b-4ff7-a8fd-2a49b16aed65 container test-container: <nil>
  STEP: delete the pod @ 01/15/25 02:33:35.61
  I0115 02:33:35.622080 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-8842" for this suite. @ 01/15/25 02:33:35.625
• [4.115 seconds]
------------------------------
SSS
------------------------------
[sig-instrumentation] Events should manage the lifecycle of an event [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/core_events.go:58
  STEP: Creating a kubernetes client @ 01/15/25 02:33:35.63
  I0115 02:33:35.630800 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename events @ 01/15/25 02:33:35.631
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:33:35.644
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:33:35.648
  STEP: creating a test event @ 01/15/25 02:33:35.653
  STEP: listing all events in all namespaces @ 01/15/25 02:33:35.658
  STEP: patching the test event @ 01/15/25 02:33:35.662
  STEP: fetching the test event @ 01/15/25 02:33:35.667
  STEP: updating the test event @ 01/15/25 02:33:35.67
  STEP: getting the test event @ 01/15/25 02:33:35.678
  STEP: deleting the test event @ 01/15/25 02:33:35.68
  STEP: listing all events in all namespaces @ 01/15/25 02:33:35.686
  I0115 02:33:35.689135 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-5222" for this suite. @ 01/15/25 02:33:35.727
  E0115 02:33:35.731350      24 retrywatcher.go:160] "Watch failed" err="context canceled"
• [0.102 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Services should find a service from listing all namespaces [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3164
  STEP: Creating a kubernetes client @ 01/15/25 02:33:35.733
  I0115 02:33:35.733232 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename services @ 01/15/25 02:33:35.734
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:33:35.745
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:33:35.749
  STEP: fetching services @ 01/15/25 02:33:35.753
  I0115 02:33:35.756723 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-359" for this suite. @ 01/15/25 02:33:35.828
• [0.100 seconds]
------------------------------
SSS
------------------------------
[sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2157
  STEP: Creating a kubernetes client @ 01/15/25 02:33:35.832
  I0115 02:33:35.832993 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename services @ 01/15/25 02:33:35.833
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:33:35.848
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:33:35.852
  STEP: creating service in namespace services-954 @ 01/15/25 02:33:35.857
  STEP: creating service affinity-clusterip in namespace services-954 @ 01/15/25 02:33:35.857
  STEP: creating replication controller affinity-clusterip in namespace services-954 @ 01/15/25 02:33:35.867
  I0115 02:33:35.875140      24 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-954, replica count: 3
  E0115 02:33:36.731388      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:33:37.732330      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:33:38.733452      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:33:38.927234      24 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0115 02:33:38.944255 24 resource.go:361] Creating new exec pod
  E0115 02:33:39.733683      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:33:40.734340      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:33:41.735041      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:33:41.967288 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-954 exec execpod-affinitylfksb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
  I0115 02:33:42.216686 24 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip (169.169.24.58) 80 port [tcp/http] succeeded!\n"
  I0115 02:33:42.216799 24 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0115 02:33:42.216892 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-954 exec execpod-affinitylfksb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 169.169.24.58 80'
  I0115 02:33:42.453978 24 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 169.169.24.58 80\nConnection to 169.169.24.58 80 port [tcp/http] succeeded!\n"
  I0115 02:33:42.454088 24 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0115 02:33:42.454653 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-954 exec execpod-affinitylfksb -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://169.169.24.58:80/ ; done'
  E0115 02:33:42.736067      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:33:42.967685 24 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://169.169.24.58:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://169.169.24.58:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://169.169.24.58:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://169.169.24.58:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://169.169.24.58:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://169.169.24.58:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://169.169.24.58:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://169.169.24.58:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://169.169.24.58:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://169.169.24.58:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://169.169.24.58:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://169.169.24.58:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://169.169.24.58:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://169.169.24.58:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://169.169.24.58:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://169.169.24.58:80/\n"
  I0115 02:33:42.967815 24 builder.go:147] stdout: "\naffinity-clusterip-wl25r\naffinity-clusterip-wl25r\naffinity-clusterip-wl25r\naffinity-clusterip-wl25r\naffinity-clusterip-wl25r\naffinity-clusterip-wl25r\naffinity-clusterip-wl25r\naffinity-clusterip-wl25r\naffinity-clusterip-wl25r\naffinity-clusterip-wl25r\naffinity-clusterip-wl25r\naffinity-clusterip-wl25r\naffinity-clusterip-wl25r\naffinity-clusterip-wl25r\naffinity-clusterip-wl25r\naffinity-clusterip-wl25r"
  I0115 02:33:42.968412 24 service.go:242] Received response from host: affinity-clusterip-wl25r
  I0115 02:33:42.968488 24 service.go:242] Received response from host: affinity-clusterip-wl25r
  I0115 02:33:42.968514 24 service.go:242] Received response from host: affinity-clusterip-wl25r
  I0115 02:33:42.968531 24 service.go:242] Received response from host: affinity-clusterip-wl25r
  I0115 02:33:42.968550 24 service.go:242] Received response from host: affinity-clusterip-wl25r
  I0115 02:33:42.968561 24 service.go:242] Received response from host: affinity-clusterip-wl25r
  I0115 02:33:42.968571 24 service.go:242] Received response from host: affinity-clusterip-wl25r
  I0115 02:33:42.968582 24 service.go:242] Received response from host: affinity-clusterip-wl25r
  I0115 02:33:42.968592 24 service.go:242] Received response from host: affinity-clusterip-wl25r
  I0115 02:33:42.968605 24 service.go:242] Received response from host: affinity-clusterip-wl25r
  I0115 02:33:42.968615 24 service.go:242] Received response from host: affinity-clusterip-wl25r
  I0115 02:33:42.968625 24 service.go:242] Received response from host: affinity-clusterip-wl25r
  I0115 02:33:42.968652 24 service.go:242] Received response from host: affinity-clusterip-wl25r
  I0115 02:33:42.968673 24 service.go:242] Received response from host: affinity-clusterip-wl25r
  I0115 02:33:42.968684 24 service.go:242] Received response from host: affinity-clusterip-wl25r
  I0115 02:33:42.968697 24 service.go:242] Received response from host: affinity-clusterip-wl25r
  I0115 02:33:42.968987 24 service.go:4203] Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-clusterip in namespace services-954, will wait for the garbage collector to delete the pods @ 01/15/25 02:33:42.996
  I0115 02:33:43.067109 24 resources.go:139] Deleting ReplicationController affinity-clusterip took: 12.726549ms
  I0115 02:33:43.167490 24 resources.go:163] Terminating ReplicationController affinity-clusterip pods took: 100.375903ms
  E0115 02:33:43.737107      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:33:44.737490      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:33:45.737659      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:33:46.739009      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:33:47.096421 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-954" for this suite. @ 01/15/25 02:33:47.11
• [11.292 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:643
  STEP: Creating a kubernetes client @ 01/15/25 02:33:47.127
  I0115 02:33:47.127633 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename webhook @ 01/15/25 02:33:47.13
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:33:47.154
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:33:47.17
  STEP: Setting up server cert @ 01/15/25 02:33:47.258
  E0115 02:33:47.740105      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 01/15/25 02:33:48.284
  STEP: Deploying the webhook pod @ 01/15/25 02:33:48.298
  STEP: Wait for the deployment to be ready @ 01/15/25 02:33:48.321
  I0115 02:33:48.333709 24 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0115 02:33:48.740206      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:33:49.745382      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 01/15/25 02:33:50.353
  STEP: Verifying the service has paired with the endpoint @ 01/15/25 02:33:50.38
  E0115 02:33:50.742172      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:33:51.380868 24 util.go:423] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Listing all of the created validation webhooks @ 01/15/25 02:33:51.464
  STEP: Creating a configMap that should be mutated @ 01/15/25 02:33:51.487
  STEP: Deleting the collection of validation webhooks @ 01/15/25 02:33:51.543
  STEP: Creating a configMap that should not be mutated @ 01/15/25 02:33:51.674
  E0115 02:33:51.742101      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:33:51.744402 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-3810" for this suite. @ 01/15/25 02:33:51.751
  STEP: Destroying namespace "webhook-markers-4348" for this suite. @ 01/15/25 02:33:51.762
• [4.647 seconds]
------------------------------
SSSS
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/certificates.go:200
  STEP: Creating a kubernetes client @ 01/15/25 02:33:51.774
  I0115 02:33:51.774795 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename certificates @ 01/15/25 02:33:51.778
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:33:51.8
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:33:51.812
  E0115 02:33:52.746626      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:33:53.746702      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: getting /apis @ 01/15/25 02:33:53.942
  STEP: getting /apis/certificates.k8s.io @ 01/15/25 02:33:53.954
  STEP: getting /apis/certificates.k8s.io/v1 @ 01/15/25 02:33:53.958
  STEP: creating @ 01/15/25 02:33:53.961
  STEP: getting @ 01/15/25 02:33:53.988
  STEP: listing @ 01/15/25 02:33:53.993
  STEP: watching @ 01/15/25 02:33:54
  I0115 02:33:54.000783 24 certificates.go:316] starting watch
  STEP: patching @ 01/15/25 02:33:54.004
  STEP: updating @ 01/15/25 02:33:54.014
  I0115 02:33:54.028662 24 certificates.go:332] waiting for watch events with expected annotations
  I0115 02:33:54.028928 24 certificates.go:345] saw patched and updated annotations
  STEP: getting /approval @ 01/15/25 02:33:54.029
  STEP: patching /approval @ 01/15/25 02:33:54.035
  STEP: updating /approval @ 01/15/25 02:33:54.047
  STEP: getting /status @ 01/15/25 02:33:54.057
  STEP: patching /status @ 01/15/25 02:33:54.063
  STEP: updating /status @ 01/15/25 02:33:54.075
  STEP: deleting @ 01/15/25 02:33:54.086
  STEP: deleting a collection @ 01/15/25 02:33:54.105
  I0115 02:33:54.126826 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "certificates-5030" for this suite. @ 01/15/25 02:33:54.135
• [2.371 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:156
  STEP: Creating a kubernetes client @ 01/15/25 02:33:54.146
  I0115 02:33:54.146384 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename var-expansion @ 01/15/25 02:33:54.149
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:33:54.175
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:33:54.183
  E0115 02:33:54.748018      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:33:55.750951      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:33:56.226183 24 delete.go:62] Deleting pod "var-expansion-d030bd6c-b0a2-42be-ba65-04fab2f564a1" in namespace "var-expansion-4890"
  I0115 02:33:56.246169 24 delete.go:70] Wait up to 5m0s for pod "var-expansion-d030bd6c-b0a2-42be-ba65-04fab2f564a1" to be fully deleted
  E0115 02:33:56.750708      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:33:57.752412      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:33:58.753481      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:33:59.753988      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:34:00.291128 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-4890" for this suite. @ 01/15/25 02:34:00.3
• [6.165 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should mount projected service account token [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:306
  STEP: Creating a kubernetes client @ 01/15/25 02:34:00.312
  I0115 02:34:00.312574 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename svcaccounts @ 01/15/25 02:34:00.313
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:34:00.341
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:34:00.348
  STEP: Creating a pod to test service account token:  @ 01/15/25 02:34:00.36
  E0115 02:34:00.754852      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:34:01.755605      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:34:02.756254      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:34:03.757713      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 02:34:04.41
  I0115 02:34:04.428758 24 output.go:207] Trying to get logs from node 192.168.18.92 pod test-pod-df593a6f-bbf8-4121-8d59-9a3394ae8a5f container agnhost-container: <nil>
  STEP: delete the pod @ 01/15/25 02:34:04.457
  I0115 02:34:04.550627 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-1328" for this suite. @ 01/15/25 02:34:04.563
• [4.258 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:77
  STEP: Creating a kubernetes client @ 01/15/25 02:34:04.57
  I0115 02:34:04.570410 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename var-expansion @ 01/15/25 02:34:04.571
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:34:04.586
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:34:04.591
  STEP: Creating a pod to test substitution in container's command @ 01/15/25 02:34:04.597
  E0115 02:34:04.759171      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:34:05.759811      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:34:06.760234      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:34:07.762991      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 02:34:08.632
  I0115 02:34:08.645238 24 output.go:207] Trying to get logs from node 192.168.18.92 pod var-expansion-55e75b3c-4d6d-4745-9686-2fdd234bdc30 container dapi-container: <nil>
  STEP: delete the pod @ 01/15/25 02:34:08.662
  I0115 02:34:08.681110 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-1066" for this suite. @ 01/15/25 02:34:08.685
• [4.124 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/watch.go:191
  STEP: Creating a kubernetes client @ 01/15/25 02:34:08.694
  I0115 02:34:08.694830 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename watch @ 01/15/25 02:34:08.695
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:34:08.709
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:34:08.714
  STEP: creating a watch on configmaps @ 01/15/25 02:34:08.719
  STEP: creating a new configmap @ 01/15/25 02:34:08.722
  STEP: modifying the configmap once @ 01/15/25 02:34:08.725
  STEP: closing the watch once it receives two notifications @ 01/15/25 02:34:08.733
  I0115 02:34:08.733344 24 watch.go:431] Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1403  3babffbf-e61c-4564-87f7-abd2a2b8e97f 177230 0 2025-01-15 02:34:08 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2025-01-15 02:34:08 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  I0115 02:34:08.733565 24 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1403  3babffbf-e61c-4564-87f7-abd2a2b8e97f 177231 0 2025-01-15 02:34:08 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2025-01-15 02:34:08 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time, while the watch is closed @ 01/15/25 02:34:08.733
  STEP: creating a new watch on configmaps from the last resource version observed by the first watch @ 01/15/25 02:34:08.74
  STEP: deleting the configmap @ 01/15/25 02:34:08.742
  STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed @ 01/15/25 02:34:08.746
  I0115 02:34:08.747104 24 watch.go:431] Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1403  3babffbf-e61c-4564-87f7-abd2a2b8e97f 177232 0 2025-01-15 02:34:08 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2025-01-15 02:34:08 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0115 02:34:08.747248 24 watch.go:431] Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1403  3babffbf-e61c-4564-87f7-abd2a2b8e97f 177233 0 2025-01-15 02:34:08 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2025-01-15 02:34:08 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  I0115 02:34:08.747359 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  E0115 02:34:08.763368      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Destroying namespace "watch-1403" for this suite. @ 01/15/25 02:34:08.785
• [0.096 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:322
  STEP: Creating a kubernetes client @ 01/15/25 02:34:08.791
  I0115 02:34:08.791020 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename gc @ 01/15/25 02:34:08.791
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:34:08.808
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:34:08.813
  STEP: create the rc @ 01/15/25 02:34:08.817
  W0115 02:34:08.822498      24 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E0115 02:34:09.764269      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:34:10.765000      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:34:11.766101      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:34:12.766608      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:34:13.767229      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: delete the rc @ 01/15/25 02:34:13.875
  STEP: wait for all pods to be garbage collected @ 01/15/25 02:34:13.906
  E0115 02:34:14.768524      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:34:15.770957      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:34:16.771079      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:34:17.771364      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:34:18.772059      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 01/15/25 02:34:18.926
  I0115 02:34:19.249899 24 garbage_collector.go:265] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0115 02:34:19.250382 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-3653" for this suite. @ 01/15/25 02:34:19.262
• [10.487 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:358
  STEP: Creating a kubernetes client @ 01/15/25 02:34:19.279
  I0115 02:34:19.279059 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename crd-publish-openapi @ 01/15/25 02:34:19.281
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:34:19.372
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:34:19.392
  STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation @ 01/15/25 02:34:19.42
  I0115 02:34:19.422134 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  E0115 02:34:19.772860      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:34:20.775144      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:34:21.531172 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  E0115 02:34:21.776419      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:34:22.777009      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:34:23.777842      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:34:24.779323      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:34:25.781281      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:34:26.782015      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:34:27.782601      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:34:28.375762 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-1888" for this suite. @ 01/15/25 02:34:28.39
• [9.121 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtimeclass.go:131
  STEP: Creating a kubernetes client @ 01/15/25 02:34:28.401
  I0115 02:34:28.401098 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename runtimeclass @ 01/15/25 02:34:28.402
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:34:28.42
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:34:28.427
  E0115 02:34:28.783704      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:34:29.783845      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:34:30.485382 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-5616" for this suite. @ 01/15/25 02:34:30.496
• [2.110 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1362
  STEP: Creating a kubernetes client @ 01/15/25 02:34:30.511
  I0115 02:34:30.511991 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename kubectl @ 01/15/25 02:34:30.514
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:34:30.554
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:34:30.564
  STEP: validating cluster-info @ 01/15/25 02:34:30.578
  I0115 02:34:30.578676 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-5542 cluster-info'
  I0115 02:34:30.722838 24 builder.go:146] stderr: ""
  I0115 02:34:30.722949 24 builder.go:147] stdout: "Kubernetes control plane is running at https://169.169.0.1:443\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
  I0115 02:34:30.723788 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-5542" for this suite. @ 01/15/25 02:34:30.731
• [0.230 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:799
  STEP: Creating a kubernetes client @ 01/15/25 02:34:30.755
  I0115 02:34:30.755475 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename statefulset @ 01/15/25 02:34:30.757
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:34:30.779
  E0115 02:34:30.783896      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:34:30.786
  STEP: Creating service test in namespace statefulset-3166 @ 01/15/25 02:34:30.792
  STEP: Looking for a node to schedule stateful set and pod @ 01/15/25 02:34:30.8
  STEP: Creating pod with conflicting port in namespace statefulset-3166 @ 01/15/25 02:34:30.83
  STEP: Waiting until pod test-pod will start running in namespace statefulset-3166 @ 01/15/25 02:34:30.841
  E0115 02:34:31.785034      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:34:32.786272      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Creating statefulset with conflicting port in namespace statefulset-3166 @ 01/15/25 02:34:32.854
  STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-3166 @ 01/15/25 02:34:32.864
  I0115 02:34:32.882627 24 statefulset.go:872] Observed stateful pod in namespace: statefulset-3166, name: ss-0, uid: d86aeddd-118b-4ede-b010-086a2c1458ff, status phase: Pending. Waiting for statefulset controller to delete.
  I0115 02:34:32.898133 24 statefulset.go:872] Observed stateful pod in namespace: statefulset-3166, name: ss-0, uid: d86aeddd-118b-4ede-b010-086a2c1458ff, status phase: Failed. Waiting for statefulset controller to delete.
  I0115 02:34:32.910883 24 statefulset.go:872] Observed stateful pod in namespace: statefulset-3166, name: ss-0, uid: d86aeddd-118b-4ede-b010-086a2c1458ff, status phase: Failed. Waiting for statefulset controller to delete.
  I0115 02:34:32.914766 24 statefulset.go:866] Observed delete event for stateful pod ss-0 in namespace statefulset-3166
  STEP: Removing pod with conflicting port in namespace statefulset-3166 @ 01/15/25 02:34:32.914
  STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-3166 and will be in running state @ 01/15/25 02:34:32.931
  E0115 02:34:33.787035      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:34:34.787117      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:34:35.787665      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:34:36.788313      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:34:36.965351 24 statefulset.go:138] Deleting all statefulset in ns statefulset-3166
  I0115 02:34:36.985080 24 rest.go:152] Scaling statefulset ss to 0
  E0115 02:34:37.788470      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:34:38.789325      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:34:39.790993      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:34:40.792875      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:34:41.799080      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:34:42.800133      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:34:43.801750      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:34:44.802564      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:34:45.804181      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:34:46.806460      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:34:47.052453 24 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I0115 02:34:47.062955 24 rest.go:90] Deleting statefulset ss
  I0115 02:34:47.121879 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-3166" for this suite. @ 01/15/25 02:34:47.13
• [16.385 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace should update a single-container pod's image [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1788
  STEP: Creating a kubernetes client @ 01/15/25 02:34:47.14
  I0115 02:34:47.140645 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename kubectl @ 01/15/25 02:34:47.141
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:34:47.158
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:34:47.163
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 01/15/25 02:34:47.169
  I0115 02:34:47.169268 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-5907 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
  I0115 02:34:47.269041 24 builder.go:146] stderr: ""
  I0115 02:34:47.269100 24 builder.go:147] stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: verifying the pod e2e-test-httpd-pod is running @ 01/15/25 02:34:47.269
  E0115 02:34:47.808124      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:34:48.808899      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:34:49.809965      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:34:50.810087      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:34:51.810433      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: verifying the pod e2e-test-httpd-pod was created @ 01/15/25 02:34:52.321
  I0115 02:34:52.321927 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-5907 get pod e2e-test-httpd-pod -o json'
  I0115 02:34:52.464476 24 builder.go:146] stderr: ""
  I0115 02:34:52.464706 24 builder.go:147] stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/containerID\": \"9d2a014dd52506fd2f84abf0fdc5ffdd2df7c54861b8fcd6f1e9d4cb7615640f\",\n            \"cni.projectcalico.org/podIP\": \"10.1.155.1/32\",\n            \"cni.projectcalico.org/podIPs\": \"10.1.155.1/32\"\n        },\n        \"creationTimestamp\": \"2025-01-15T02:34:47Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-5907\",\n        \"resourceVersion\": \"177518\",\n        \"uid\": \"d7e55668-0983-40dc-874b-69823f89825e\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-mdr42\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"192.168.18.92\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-mdr42\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2025-01-15T02:34:49Z\",\n                \"status\": \"True\",\n                \"type\": \"PodReadyToStartContainers\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2025-01-15T02:34:47Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2025-01-15T02:34:49Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2025-01-15T02:34:49Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2025-01-15T02:34:47Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://f84cbe6aa1dc02d841bef1d773f01ce064af59c0fb64f3a9fedd29c2dbc8d560\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2025-01-15T02:34:48Z\"\n                    }\n                },\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-mdr42\",\n                        \"readOnly\": true,\n                        \"recursiveReadOnly\": \"Disabled\"\n                    }\n                ]\n            }\n        ],\n        \"hostIP\": \"192.168.18.92\",\n        \"hostIPs\": [\n            {\n                \"ip\": \"192.168.18.92\"\n            }\n        ],\n        \"phase\": \"Running\",\n        \"podIP\": \"10.1.155.1\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.1.155.1\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2025-01-15T02:34:47Z\"\n    }\n}\n"
  STEP: replace the image in the pod @ 01/15/25 02:34:52.464
  I0115 02:34:52.464867 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-5907 replace -f -'
  E0115 02:34:52.810969      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:34:52.847260 24 builder.go:146] stderr: ""
  I0115 02:34:52.847449 24 builder.go:147] stdout: "pod/e2e-test-httpd-pod replaced\n"
  STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.36.1-1 @ 01/15/25 02:34:52.847
  I0115 02:34:52.853356 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-5907 delete pods e2e-test-httpd-pod'
  E0115 02:34:53.811260      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:34:54.560510 24 builder.go:146] stderr: ""
  I0115 02:34:54.560617 24 builder.go:147] stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  I0115 02:34:54.560915 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-5907" for this suite. @ 01/15/25 02:34:54.568
• [7.437 seconds]
------------------------------
[sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:86
  STEP: Creating a kubernetes client @ 01/15/25 02:34:54.577
  I0115 02:34:54.577570 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename replication-controller @ 01/15/25 02:34:54.578
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:34:54.603
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:34:54.612
  I0115 02:34:54.620948 24 rc.go:544] Creating quota "condition-test" that allows only two pods to run in the current namespace
  E0115 02:34:54.813175      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Creating rc "condition-test" that asks for more than the allowed pod quota @ 01/15/25 02:34:55.643
  STEP: Checking rc "condition-test" has the desired failure condition set @ 01/15/25 02:34:55.652
  E0115 02:34:55.813445      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Scaling down rc "condition-test" to satisfy pod quota @ 01/15/25 02:34:56.671
  I0115 02:34:56.714168 24 rc.go:730] Updating replication controller "condition-test"
  STEP: Checking rc "condition-test" has no failure condition set @ 01/15/25 02:34:56.714
  E0115 02:34:56.815703      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:34:57.750989 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-2768" for this suite. @ 01/15/25 02:34:57.766
• [3.207 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply a finalizer to a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:400
  STEP: Creating a kubernetes client @ 01/15/25 02:34:57.789
  I0115 02:34:57.789673 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename namespaces @ 01/15/25 02:34:57.794
  E0115 02:34:57.820212      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:34:57.839
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:34:57.853
  STEP: Creating namespace "e2e-ns-npm9t" @ 01/15/25 02:34:57.865
  I0115 02:34:57.928795 24 namespace.go:411] Namespace "e2e-ns-npm9t-4081" has []v1.FinalizerName{"kubernetes"}
  STEP: Adding e2e finalizer to namespace "e2e-ns-npm9t-4081" @ 01/15/25 02:34:57.929
  I0115 02:34:57.948299 24 namespace.go:434] Namespace "e2e-ns-npm9t-4081" has []v1.FinalizerName{"kubernetes", "e2e.example.com/fakeFinalizer"}
  STEP: Removing e2e finalizer from namespace "e2e-ns-npm9t-4081" @ 01/15/25 02:34:57.948
  I0115 02:34:57.964155 24 namespace.go:463] Namespace "e2e-ns-npm9t-4081" has []v1.FinalizerName{"kubernetes"}
  I0115 02:34:57.964468 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-7323" for this suite. @ 01/15/25 02:34:57.973
  STEP: Destroying namespace "e2e-ns-npm9t-4081" for this suite. @ 01/15/25 02:34:57.983
• [0.207 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:327
  STEP: Creating a kubernetes client @ 01/15/25 02:34:57.996
  I0115 02:34:57.996706 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename statefulset @ 01/15/25 02:34:57.998
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:34:58.026
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:34:58.035
  STEP: Creating service test in namespace statefulset-8133 @ 01/15/25 02:34:58.046
  STEP: Creating a new StatefulSet @ 01/15/25 02:34:58.059
  I0115 02:34:58.078812 24 wait.go:40] Found 0 stateful pods, waiting for 3
  E0115 02:34:58.820368      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:34:59.823717      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:35:00.827138      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:35:01.827896      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:35:02.829542      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:35:03.837153      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:35:04.839635      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:35:05.840008      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:35:06.840933      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:35:07.840969      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:35:08.079742 24 wait.go:50] Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  I0115 02:35:08.079841 24 wait.go:50] Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  I0115 02:35:08.079875 24 wait.go:50] Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  I0115 02:35:08.097978 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=statefulset-8133 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  I0115 02:35:08.373812 24 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0115 02:35:08.373871 24 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0115 02:35:08.373897 24 statefulset.go:2453] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  E0115 02:35:08.842136      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:35:09.843434      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:35:10.846161      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:35:11.847303      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:35:12.848199      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:35:13.849023      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:35:14.849614      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:35:15.850236      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:35:16.851546      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:35:17.852022      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 @ 01/15/25 02:35:18.404
  I0115 02:35:18.435089 24 statefulset.go:2510] Updating stateful set ss2
  STEP: Creating a new revision @ 01/15/25 02:35:18.435
  E0115 02:35:18.852498      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:35:19.852892      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:35:20.854213      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:35:21.856666      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:35:22.857087      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:35:23.857466      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:35:24.857802      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:35:25.858214      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:35:26.859819      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:35:27.859888      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Updating Pods in reverse ordinal order @ 01/15/25 02:35:28.481
  I0115 02:35:28.492632 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=statefulset-8133 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0115 02:35:28.785084 24 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0115 02:35:28.785194 24 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0115 02:35:28.785221 24 statefulset.go:2477] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  E0115 02:35:28.860850      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:35:29.863766      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:35:30.865172      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:35:31.866079      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:35:32.866678      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:35:33.867393      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:35:34.867943      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:35:35.868574      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:35:36.869461      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:35:37.871001      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:35:38.836642 24 wait.go:158] Waiting for StatefulSet statefulset-8133/ss2 to complete update
  E0115 02:35:38.872181      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:35:39.872290      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:35:40.873462      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:35:41.874206      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:35:42.874905      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:35:43.875787      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:35:44.877577      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:35:45.884047      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:35:46.886166      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:35:47.885587      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:35:48.900399      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Rolling back to a previous revision @ 01/15/25 02:35:48.902
  I0115 02:35:48.902334 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=statefulset-8133 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  E0115 02:35:49.906821      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:35:50.281965 24 builder.go:146] stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  I0115 02:35:50.282066 24 builder.go:147] stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  I0115 02:35:50.282105 24 statefulset.go:2453] stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  E0115 02:35:50.908559      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:35:51.909920      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:35:52.911018      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:35:53.911870      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:35:54.912173      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:35:55.913286      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:35:56.919661      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:35:57.921599      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:35:58.921753      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:35:59.921908      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:36:00.341611 24 statefulset.go:2510] Updating stateful set ss2
  E0115 02:36:00.922576      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:36:01.924419      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:36:02.927129      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:36:03.927991      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:36:04.929822      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:36:05.930334      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:36:06.932115      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:36:07.934697      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:36:08.936180      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:36:09.953732      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Rolling back update in reverse ordinal order @ 01/15/25 02:36:10.358
  I0115 02:36:10.364769 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=statefulset-8133 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  I0115 02:36:10.920303 24 builder.go:146] stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  I0115 02:36:10.920512 24 builder.go:147] stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  I0115 02:36:10.920570 24 statefulset.go:2477] stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  E0115 02:36:10.954502      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:36:11.954904      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:36:12.959014      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:36:13.989775      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:36:15.002690      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:36:16.003082      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:36:17.004110      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:36:18.004738      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:36:19.005596      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:36:20.005682      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:36:21.007044      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:36:22.007912      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:36:23.009321      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:36:24.010500      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:36:25.011871      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:36:26.012434      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:36:27.012523      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:36:28.013553      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:36:29.014075      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:36:30.014389      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:36:30.990795 24 statefulset.go:138] Deleting all statefulset in ns statefulset-8133
  I0115 02:36:30.999578 24 rest.go:152] Scaling statefulset ss2 to 0
  E0115 02:36:31.015100      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:36:32.016306      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:36:33.018143      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:36:34.020082      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:36:35.020812      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:36:36.022837      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:36:37.024308      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:36:38.024990      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:36:39.026543      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:36:40.028221      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:36:41.021700 24 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I0115 02:36:41.025484 24 rest.go:90] Deleting statefulset ss2
  E0115 02:36:41.029215      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:36:41.040724 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-8133" for this suite. @ 01/15/25 02:36:41.046
• [103.057 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Secrets should patch a secret [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:156
  STEP: Creating a kubernetes client @ 01/15/25 02:36:41.053
  I0115 02:36:41.053883 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename secrets @ 01/15/25 02:36:41.054
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:36:41.072
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:36:41.078
  STEP: creating a secret @ 01/15/25 02:36:41.091
  STEP: listing secrets in all namespaces to ensure that there are more than zero @ 01/15/25 02:36:41.097
  STEP: patching the secret @ 01/15/25 02:36:41.102
  STEP: deleting the secret using a LabelSelector @ 01/15/25 02:36:41.112
  STEP: listing secrets in all namespaces, searching for label name and value in patch @ 01/15/25 02:36:41.119
  I0115 02:36:41.123453 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-6737" for this suite. @ 01/15/25 02:36:41.148
• [0.104 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-apps] CronJob should schedule multiple jobs concurrently [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:70
  STEP: Creating a kubernetes client @ 01/15/25 02:36:41.158
  I0115 02:36:41.158456 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename cronjob @ 01/15/25 02:36:41.159
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:36:41.203
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:36:41.209
  STEP: Creating a cronjob @ 01/15/25 02:36:41.214
  STEP: Ensuring more than one job is running at a time @ 01/15/25 02:36:41.22
  E0115 02:36:42.030655      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:36:43.032908      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:36:44.033772      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:36:45.034423      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:36:46.035158      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:36:47.035840      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:36:48.036427      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:36:49.037013      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:36:50.038612      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:36:51.039284      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:36:52.039786      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:36:53.043330      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:36:54.043904      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:36:55.044295      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:36:56.045071      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:36:57.045532      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:36:58.046129      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:36:59.046729      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:00.047190      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:01.047987      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:02.049248      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:03.050243      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:04.051274      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:05.052128      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:06.053160      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:07.054493      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:08.056672      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:09.058178      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:10.059617      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:11.060358      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:12.061833      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:13.064120      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:14.065111      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:15.066600      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:16.067839      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:17.069206      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:18.069628      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:19.071097      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:20.071692      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:21.072623      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:22.074659      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:23.076717      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:24.077328      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:25.078239      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:26.079270      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:27.079844      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:28.083052      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:29.083738      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:30.084083      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:31.084949      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:32.085351      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:33.087827      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:34.089030      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:35.090127      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:36.091826      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:37.092186      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:38.093461      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:39.094807      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:40.095601      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:41.097198      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:42.097901      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:43.098985      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:44.100310      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:45.101891      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:46.104016      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:47.105724      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:48.106914      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:49.106855      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:50.110802      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:51.110805      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:52.111644      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:53.113117      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:54.113907      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:55.114748      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:56.115081      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:57.117656      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:58.117566      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:37:59.117973      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:38:00.118530      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:38:01.120379      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Ensuring at least two running jobs exists by listing jobs explicitly @ 01/15/25 02:38:01.23
  STEP: Removing cronjob @ 01/15/25 02:38:01.237
  I0115 02:38:01.245018 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-2676" for this suite. @ 01/15/25 02:38:01.249
• [80.099 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1753
  STEP: Creating a kubernetes client @ 01/15/25 02:38:01.257
  I0115 02:38:01.257641 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename kubectl @ 01/15/25 02:38:01.258
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:38:01.287
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:38:01.321
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 01/15/25 02:38:01.363
  I0115 02:38:01.363913 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-5800 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4'
  I0115 02:38:01.466010 24 builder.go:146] stderr: ""
  I0115 02:38:01.466086 24 builder.go:147] stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: verifying the pod e2e-test-httpd-pod was created @ 01/15/25 02:38:01.466
  I0115 02:38:01.469955 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-5800 delete pods e2e-test-httpd-pod'
  E0115 02:38:02.122457      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:38:03.122763      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:38:03.491355 24 builder.go:146] stderr: ""
  I0115 02:38:03.491444 24 builder.go:147] stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  I0115 02:38:03.491604 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-5800" for this suite. @ 01/15/25 02:38:03.496
• [2.245 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide hostIPs as an env var [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:118
  STEP: Creating a kubernetes client @ 01/15/25 02:38:03.502
  I0115 02:38:03.502792 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename downward-api @ 01/15/25 02:38:03.503
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:38:03.518
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:38:03.522
  STEP: Creating a pod to test downward api env vars @ 01/15/25 02:38:03.527
  E0115 02:38:04.122875      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:38:05.123751      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:38:06.124192      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:38:07.125654      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 02:38:07.572
  I0115 02:38:07.584195 24 output.go:207] Trying to get logs from node 192.168.18.92 pod downward-api-a3d4b4c1-a1e9-4cef-be74-0bfa815e1e07 container dapi-container: <nil>
  STEP: delete the pod @ 01/15/25 02:38:07.611
  I0115 02:38:07.633384 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-9037" for this suite. @ 01/15/25 02:38:07.64
• [4.145 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment Deployment should have a working scale subresource [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:150
  STEP: Creating a kubernetes client @ 01/15/25 02:38:07.647
  I0115 02:38:07.647965 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename deployment @ 01/15/25 02:38:07.649
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:38:07.673
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:38:07.68
  I0115 02:38:07.686317 24 deployment.go:1645] Creating simple deployment test-new-deployment
  I0115 02:38:07.700835 24 deployment.go:223] deployment "test-new-deployment" doesn't have the required revision set
  E0115 02:38:08.126315      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:38:09.127673      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: getting scale subresource @ 01/15/25 02:38:09.722
  STEP: updating a scale subresource @ 01/15/25 02:38:09.726
  STEP: verifying the deployment Spec.Replicas was modified @ 01/15/25 02:38:09.734
  STEP: Patch a scale subresource @ 01/15/25 02:38:09.739
  I0115 02:38:09.776564 24 deployment.go:633] Deployment "test-new-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=19) "test-new-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-1821",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "0f9b0d38-8150-415d-b487-f0e6be061529",
      ResourceVersion: (string) (len=6) "178554",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872505487,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)(<nil>),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=28) {
              00000000  7b 22 66 3a 73 70 65 63  22 3a 7b 22 66 3a 72 65  |{"f:spec":{"f:re|
              00000010  70 6c 69 63 61 73 22 3a  7b 7d 7d 7d              |plicas":{}}}|
            }
          }),
          Subresource: (string) (len=5) "scale"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872505487,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=619) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |onds":{},"f:revi|
              00000060  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000070  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              00000090  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000a0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000b0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000c0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000d0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000e0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              000000f0  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000100  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000110  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000120  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000130  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000140  6d 65 5c 22 3a 5c 22 68  74 74 70 64 5c 22 7d 22  |me\":\"httpd\"}"|
              00000150  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000160  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000170  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000180  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              00000190  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              000001a0  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              000001b0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001c0  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000001d0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000001e0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              000001f0  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              00000200  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              00000210  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              00000220  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000230  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000240  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000250  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000260  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872505489,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(4),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872505489,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872505489,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872505489,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872505487,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=72) "ReplicaSet \"test-new-deployment-685b768f58\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  I0115 02:38:09.797776 24 deployment.go:40] New ReplicaSet "test-new-deployment-685b768f58" of Deployment "test-new-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-new-deployment-685b768f58",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-1821",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "16439e4f-f186-4382-9d51-bacc13a32909",
      ResourceVersion: (string) (len=6) "178561",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872505487,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "685b768f58"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "4",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "5",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=19) "test-new-deployment",
          UID: (types.UID) (len=36) "0f9b0d38-8150-415d-b487-f0e6be061529",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872505489,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 30 66 39 62 30 64  33 38 2d 38 31 35 30 2d  |\"0f9b0d38-8150-|
              00000120  34 31 35 64 2d 62 34 38  37 2d 66 30 65 36 62 65  |415d-b487-f0e6be|
              00000130  30 36 31 35 32 39 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |061529\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872505489,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(4),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "685b768f58"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "685b768f58"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  I0115 02:38:09.811678 24 deployment.go:68] Pod "test-new-deployment-685b768f58-d84fg" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "test-new-deployment-685b768f58-d84fg",
      GenerateName: (string) (len=31) "test-new-deployment-685b768f58-",
      Namespace: (string) (len=15) "deployment-1821",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "cf754577-dfbc-4913-862c-0fe785cbfb96",
      ResourceVersion: (string) (len=6) "178562",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872505489,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "685b768f58"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "test-new-deployment-685b768f58",
          UID: (types.UID) (len=36) "16439e4f-f186-4382-9d51-bacc13a32909",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872505489,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 36  34 33 39 65 34 66 2d 66  |d\":\"16439e4f-f|
              00000090  31 38 36 2d 34 33 38 32  2d 39 64 35 31 2d 62 61  |186-4382-9d51-ba|
              000000a0  63 63 31 33 61 33 32 39  30 39 5c 22 7d 22 3a 7b  |cc13a32909\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872505489,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=624) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 50  |"k:{\"type\":\"P|
              00000130  6f 64 52 65 61 64 79 54  6f 53 74 61 72 74 43 6f  |odReadyToStartCo|
              00000140  6e 74 61 69 6e 65 72 73  5c 22 7d 22 3a 7b 22 2e  |ntainers\"}":{".|
              00000150  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 50 72 6f 62  |":{},"f:lastProb|
              00000160  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |eTime":{},"f:las|
              00000170  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              00000180  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              00000190  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000001a0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 52 65  |k:{\"type\":\"Re|
              000001b0  61 64 79 5c 22 7d 22 3a  7b 22 2e 22 3a 7b 7d 2c  |ady\"}":{".":{},|
              000001c0  22 66 3a 6c 61 73 74 50  72 6f 62 65 54 69 6d 65  |"f:lastProbeTime|
              000001d0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000001e0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000001f0  66 3a 6d 65 73 73 61 67  65 22 3a 7b 7d 2c 22 66  |f:message":{},"f|
              00000200  3a 72 65 61 73 6f 6e 22  3a 7b 7d 2c 22 66 3a 73  |:reason":{},"f:s|
              00000210  74 61 74 75 73 22 3a 7b  7d 2c 22 66 3a 74 79 70  |tatus":{},"f:typ|
              00000220  65 22 3a 7b 7d 7d 7d 2c  22 66 3a 63 6f 6e 74 61  |e":{}}},"f:conta|
              00000230  69 6e 65 72 53 74 61 74  75 73 65 73 22 3a 7b 7d  |inerStatuses":{}|
              00000240  2c 22 66 3a 68 6f 73 74  49 50 22 3a 7b 7d 2c 22  |,"f:hostIP":{},"|
              00000250  66 3a 68 6f 73 74 49 50  73 22 3a 7b 7d 2c 22 66  |f:hostIPs":{},"f|
              00000260  3a 73 74 61 72 74 54 69  6d 65 22 3a 7b 7d 7d 7d  |:startTime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-4d6wp",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-4d6wp",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=13) "192.168.18.91",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872505489,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872505489,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872505489,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872505489,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872505489,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "192.168.18.91",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "192.168.18.91"
        }
      },
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872505489,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-4d6wp",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0115 02:38:09.816028 24 deployment.go:68] Pod "test-new-deployment-685b768f58-wcnbs" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "test-new-deployment-685b768f58-wcnbs",
      GenerateName: (string) (len=31) "test-new-deployment-685b768f58-",
      Namespace: (string) (len=15) "deployment-1821",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "a6d6746d-e09d-4d7e-ab59-44b92f06259e",
      ResourceVersion: (string) (len=6) "178549",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872505487,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "685b768f58"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "edf7b002949b91a0aa972c0e0fef8c81c3d00bd7c228a73cae8d6cb25ba64d0f",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=14) "10.1.155.58/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=14) "10.1.155.58/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "test-new-deployment-685b768f58",
          UID: (types.UID) (len=36) "16439e4f-f186-4382-9d51-bacc13a32909",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872505487,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 31 36  34 33 39 65 34 66 2d 66  |d\":\"16439e4f-f|
              00000090  31 38 36 2d 34 33 38 32  2d 39 64 35 31 2d 62 61  |186-4382-9d51-ba|
              000000a0  63 63 31 33 61 33 32 39  30 39 5c 22 7d 22 3a 7b  |cc13a32909\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872505488,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872505489,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 31 2e 31 35 35 2e 35  38 5c 22 7d 22 3a 7b 22  |.1.155.58\"}":{"|
              00000270  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000280  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000290  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-jtr46",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-jtr46",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=13) "192.168.18.92",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872505489,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872505487,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872505489,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872505489,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872505487,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "192.168.18.92",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "192.168.18.92"
        }
      },
      PodIP: (string) (len=11) "10.1.155.58",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.1.155.58"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872505487,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63872505488,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://306686a7fb36f090df4fe71d559e87688778031cdb3c1afa87d4649052187919",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-jtr46",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  I0115 02:38:09.819374 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-1821" for this suite. @ 01/15/25 02:38:09.827
• [2.216 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:52
  STEP: Creating a kubernetes client @ 01/15/25 02:38:09.865
  I0115 02:38:09.865084 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename kubelet-test @ 01/15/25 02:38:09.866
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:38:09.895
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:38:09.901
  E0115 02:38:10.127689      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:38:11.129007      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:38:11.943008 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-7175" for this suite. @ 01/15/25 02:38:11.949
• [2.094 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/node/pods.go:163
  STEP: Creating a kubernetes client @ 01/15/25 02:38:11.96
  I0115 02:38:11.960869 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename pods @ 01/15/25 02:38:11.962
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:38:11.981
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:38:11.991
  STEP: creating the pod @ 01/15/25 02:38:11.997
  STEP: submitting the pod to kubernetes @ 01/15/25 02:38:11.998
  STEP: verifying QOS class is set on the pod @ 01/15/25 02:38:12.017
  I0115 02:38:12.033062 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-5982" for this suite. @ 01/15/25 02:38:12.049
• [0.101 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should release no longer matching pods [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:104
  STEP: Creating a kubernetes client @ 01/15/25 02:38:12.062
  I0115 02:38:12.062528 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename replication-controller @ 01/15/25 02:38:12.064
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:38:12.083
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:38:12.089
  STEP: Given a ReplicationController is created @ 01/15/25 02:38:12.094
  STEP: When the matched label of one of its pods change @ 01/15/25 02:38:12.1
  I0115 02:38:12.104946 24 resource.go:87] Pod name pod-release: Found 0 pods out of 1
  E0115 02:38:12.129723      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:38:13.129788      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:38:14.130668      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:38:15.131904      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:38:16.133118      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:38:17.130161 24 resource.go:87] Pod name pod-release: Found 1 pods out of 1
  E0115 02:38:17.134094      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Then the pod is released @ 01/15/25 02:38:17.172
  E0115 02:38:18.135387      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:38:18.208778 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-9311" for this suite. @ 01/15/25 02:38:18.223
• [6.176 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:350
  STEP: Creating a kubernetes client @ 01/15/25 02:38:18.239
  I0115 02:38:18.239249 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename security-context-test @ 01/15/25 02:38:18.242
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:38:18.271
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:38:18.278
  E0115 02:38:19.136059      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:38:20.229155      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:38:21.230023      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:38:22.231238      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:38:23.231935      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:38:24.233092      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:38:24.340100 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-4460" for this suite. @ 01/15/25 02:38:24.351
• [6.125 seconds]
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance] [sig-network, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/network/networking.go:85
  STEP: Creating a kubernetes client @ 01/15/25 02:38:24.364
  I0115 02:38:24.364202 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename pod-network-test @ 01/15/25 02:38:24.367
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:38:24.402
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:38:24.411
  STEP: Performing setup for networking test in namespace pod-network-test-4621 @ 01/15/25 02:38:24.421
  STEP: creating a selector @ 01/15/25 02:38:24.421
  STEP: Creating the service pods in kubernetes @ 01/15/25 02:38:24.421
  I0115 02:38:24.421264 24 helper.go:51] Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E0115 02:38:25.234397      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:38:26.239251      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:38:27.244526      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:38:28.245640      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:38:29.252866      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:38:30.253615      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:38:31.254811      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:38:32.257977      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:38:33.257969      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:38:34.258856      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:38:35.262195      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:38:36.260587      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:38:37.261834      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:38:38.262633      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:38:39.263458      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:38:40.263847      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 01/15/25 02:38:41.076
  E0115 02:38:41.264150      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:38:42.264872      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:38:43.125825 24 utils.go:803] Setting MaxTries for pod polling to 34 for networking test based on endpoint count 2
  I0115 02:38:43.126120 24 networking.go:42] Breadth first check of 10.1.213.76 on host 192.168.18.91...
  I0115 02:38:43.138786 24 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.1.155.56:9080/dial?request=hostname&protocol=http&host=10.1.213.76&port=8083&tries=1'] Namespace:pod-network-test-4621 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0115 02:38:43.139066 24 exec_util.go:64] ExecWithOptions: Clientset creation
  I0115 02:38:43.139337 24 exec_util.go:80] ExecWithOptions: execute(POST https://169.169.0.1:443/api/v1/namespaces/pod-network-test-4621/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.1.155.56%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.1.213.76%26port%3D8083%26tries%3D1%27&container=webserver&stderr=true&stdout=true)
  E0115 02:38:43.265750      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:38:43.400151 24 utils.go:356] Waiting for responses: map[]
  I0115 02:38:43.400467 24 utils.go:360] reached 10.1.213.76 after 0/1 tries
  I0115 02:38:43.400559 24 networking.go:42] Breadth first check of 10.1.155.60 on host 192.168.18.92...
  I0115 02:38:43.414474 24 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.1.155.56:9080/dial?request=hostname&protocol=http&host=10.1.155.60&port=8083&tries=1'] Namespace:pod-network-test-4621 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0115 02:38:43.414693 24 exec_util.go:64] ExecWithOptions: Clientset creation
  I0115 02:38:43.414850 24 exec_util.go:80] ExecWithOptions: execute(POST https://169.169.0.1:443/api/v1/namespaces/pod-network-test-4621/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F10.1.155.56%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D10.1.155.60%26port%3D8083%26tries%3D1%27&container=webserver&stderr=true&stdout=true)
  I0115 02:38:43.600896 24 utils.go:356] Waiting for responses: map[]
  I0115 02:38:43.600958 24 utils.go:360] reached 10.1.155.60 after 0/1 tries
  I0115 02:38:43.600980 24 networking.go:53] Going to retry 0 out of 2 pods....
  I0115 02:38:43.602722 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-4621" for this suite. @ 01/15/25 02:38:43.614
• [19.269 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance] [sig-storage, Serial, Conformance]
k8s.io/kubernetes/test/e2e/storage/empty_dir_wrapper.go:188
  STEP: Creating a kubernetes client @ 01/15/25 02:38:43.632
  I0115 02:38:43.632978 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename emptydir-wrapper @ 01/15/25 02:38:43.638
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:38:43.662
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:38:43.67
  STEP: Creating 50 configmaps @ 01/15/25 02:38:43.678
  STEP: Creating RC which spawns configmap-volume pods @ 01/15/25 02:38:44.032
  I0115 02:38:44.053298 24 resource.go:87] Pod name wrapped-volume-race-9fddccb5-1760-43f9-acc4-de5adba603e0: Found 0 pods out of 5
  E0115 02:38:44.266054      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:38:45.267144      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:38:46.268101      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:38:47.276850      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:38:48.279451      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:38:49.261176 24 resource.go:87] Pod name wrapped-volume-race-9fddccb5-1760-43f9-acc4-de5adba603e0: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 01/15/25 02:38:49.261
  E0115 02:38:49.278219      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:38:50.282401      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:38:51.284649      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:38:52.285088      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:38:53.287012      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Creating RC which spawns configmap-volume pods @ 01/15/25 02:38:53.63
  I0115 02:38:53.668973 24 resource.go:87] Pod name wrapped-volume-race-10a3f26e-3048-4a5f-bff9-8b428380623e: Found 0 pods out of 5
  E0115 02:38:54.288671      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:38:55.292905      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:38:56.293108      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:38:57.294237      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:38:58.296390      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:38:58.841352 24 resource.go:87] Pod name wrapped-volume-race-10a3f26e-3048-4a5f-bff9-8b428380623e: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 01/15/25 02:38:58.841
  E0115 02:38:59.308403      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:39:00.334168      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:39:01.338895      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:39:02.341238      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:39:03.347681      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:39:04.348457      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:39:05.351895      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Creating RC which spawns configmap-volume pods @ 01/15/25 02:39:05.573
  I0115 02:39:05.812101 24 resource.go:87] Pod name wrapped-volume-race-7586843b-b3e9-4eb7-b160-b6e496af6abc: Found 1 pods out of 5
  E0115 02:39:06.352022      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:39:07.353116      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:39:08.451093      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:39:09.548988      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:39:10.544575      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:39:10.838224 24 resource.go:87] Pod name wrapped-volume-race-7586843b-b3e9-4eb7-b160-b6e496af6abc: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 01/15/25 02:39:10.838
  E0115 02:39:11.545533      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:39:12.547058      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:39:13.548048      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:39:14.561736      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:39:15.551688      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:39:16.554212      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:39:17.555746      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:39:18.556036      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: deleting ReplicationController wrapped-volume-race-7586843b-b3e9-4eb7-b160-b6e496af6abc in namespace emptydir-wrapper-6866, will wait for the garbage collector to delete the pods @ 01/15/25 02:39:19.084
  I0115 02:39:19.165787 24 resources.go:139] Deleting ReplicationController wrapped-volume-race-7586843b-b3e9-4eb7-b160-b6e496af6abc took: 13.568598ms
  I0115 02:39:19.366064 24 resources.go:163] Terminating ReplicationController wrapped-volume-race-7586843b-b3e9-4eb7-b160-b6e496af6abc pods took: 200.273503ms
  E0115 02:39:19.557299      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:39:20.563110      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:39:21.564228      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:39:22.574867      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:39:23.575768      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: deleting ReplicationController wrapped-volume-race-10a3f26e-3048-4a5f-bff9-8b428380623e in namespace emptydir-wrapper-6866, will wait for the garbage collector to delete the pods @ 01/15/25 02:39:23.967
  I0115 02:39:24.031230 24 resources.go:139] Deleting ReplicationController wrapped-volume-race-10a3f26e-3048-4a5f-bff9-8b428380623e took: 8.105375ms
  I0115 02:39:24.233291 24 resources.go:163] Terminating ReplicationController wrapped-volume-race-10a3f26e-3048-4a5f-bff9-8b428380623e pods took: 202.05721ms
  E0115 02:39:24.577445      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:39:25.592410      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:39:26.592509      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:39:27.599804      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: deleting ReplicationController wrapped-volume-race-9fddccb5-1760-43f9-acc4-de5adba603e0 in namespace emptydir-wrapper-6866, will wait for the garbage collector to delete the pods @ 01/15/25 02:39:27.935
  I0115 02:39:28.279755 24 resources.go:139] Deleting ReplicationController wrapped-volume-race-9fddccb5-1760-43f9-acc4-de5adba603e0 took: 19.648922ms
  I0115 02:39:28.580177 24 resources.go:163] Terminating ReplicationController wrapped-volume-race-9fddccb5-1760-43f9-acc4-de5adba603e0 pods took: 300.419006ms
  E0115 02:39:28.602393      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:39:29.602570      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:39:30.602818      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:39:31.604265      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:39:32.605657      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:39:33.606739      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:39:34.622435      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Cleaning up the configMaps @ 01/15/25 02:39:35.181
  E0115 02:39:35.620880      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:39:36.111741 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-wrapper-6866" for this suite. @ 01/15/25 02:39:36.126
• [52.518 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:48
  STEP: Creating a kubernetes client @ 01/15/25 02:39:36.152
  I0115 02:39:36.152142 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename configmap @ 01/15/25 02:39:36.158
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:39:36.222
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:39:36.26
  STEP: Creating configMap with name configmap-test-volume-7629804c-a182-40e3-ae12-e4b9379f887e @ 01/15/25 02:39:36.309
  STEP: Creating a pod to test consume configMaps @ 01/15/25 02:39:36.35
  E0115 02:39:36.622088      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:39:37.623634      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:39:38.628187      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:39:39.629931      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:39:40.638684      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:39:41.639956      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 02:39:42.52
  I0115 02:39:42.555190 24 output.go:207] Trying to get logs from node 192.168.18.92 pod pod-configmaps-7d7de9ba-6960-42ab-9054-6dc281bab87c container agnhost-container: <nil>
  E0115 02:39:42.640236      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: delete the pod @ 01/15/25 02:39:42.643
  I0115 02:39:42.683707 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-3286" for this suite. @ 01/15/25 02:39:42.693
• [6.554 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance] should update the ephemeral containers in an existing pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/ephemeral_containers.go:98
  STEP: Creating a kubernetes client @ 01/15/25 02:39:42.706
  I0115 02:39:42.706518 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename ephemeral-containers-test @ 01/15/25 02:39:42.709
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:39:42.747
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:39:42.756
  STEP: creating a target pod @ 01/15/25 02:39:42.765
  E0115 02:39:43.640318      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:39:44.641180      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:39:45.641982      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:39:46.642942      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: adding an ephemeral container @ 01/15/25 02:39:47.116
  E0115 02:39:47.643745      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:39:48.646484      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: checking pod container endpoints @ 01/15/25 02:39:49.247
  I0115 02:39:49.249552 24 exec_util.go:59] ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-8439 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0115 02:39:49.254690 24 exec_util.go:64] ExecWithOptions: Clientset creation
  I0115 02:39:49.254930 24 exec_util.go:80] ExecWithOptions: execute(POST https://169.169.0.1:443/api/v1/namespaces/ephemeral-containers-test-8439/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&stderr=true&stdout=true)
  E0115 02:39:49.660442      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:39:49.742446 24 exec_util.go:108] Exec stderr: ""
  STEP: checking pod "ephemeral-containers-target-pod" has only one ephemeralcontainer @ 01/15/25 02:39:49.825
  STEP: adding another ephemeralcontainer to pod "ephemeral-containers-target-pod" @ 01/15/25 02:39:49.966
  STEP: checking pod "ephemeral-containers-target-pod" has only two ephemeralcontainers @ 01/15/25 02:39:50.114
  I0115 02:39:50.288306 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ephemeral-containers-test-8439" for this suite. @ 01/15/25 02:39:50.364
• [7.736 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:263
  STEP: Creating a kubernetes client @ 01/15/25 02:39:50.443
  I0115 02:39:50.443050 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename downward-api @ 01/15/25 02:39:50.519
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:39:50.635
  E0115 02:39:50.661473      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:39:50.666
  STEP: Creating a pod to test downward API volume plugin @ 01/15/25 02:39:50.698
  E0115 02:39:51.661970      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:39:52.664512      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:39:53.670851      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:39:54.671773      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:39:55.675957      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:39:56.682798      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:39:57.683914      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:39:58.685462      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 02:39:58.898
  I0115 02:39:58.921874 24 output.go:207] Trying to get logs from node 192.168.18.92 pod downwardapi-volume-26843779-bc7b-4976-bd90-44e9d1002fca container client-container: <nil>
  STEP: delete the pod @ 01/15/25 02:39:58.94
  I0115 02:39:58.963890 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-6090" for this suite. @ 01/15/25 02:39:58.971
• [8.540 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates should delete a collection of pod templates [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/podtemplates.go:123
  STEP: Creating a kubernetes client @ 01/15/25 02:39:58.983
  I0115 02:39:58.983754 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename podtemplate @ 01/15/25 02:39:58.986
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:39:59.025
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:39:59.04
  STEP: Create set of pod templates @ 01/15/25 02:39:59.051
  I0115 02:39:59.068284 24 podtemplates.go:143] created test-podtemplate-1
  I0115 02:39:59.084480 24 podtemplates.go:143] created test-podtemplate-2
  I0115 02:39:59.098850 24 podtemplates.go:143] created test-podtemplate-3
  STEP: get a list of pod templates with a label in the current namespace @ 01/15/25 02:39:59.098
  STEP: delete collection of pod templates @ 01/15/25 02:39:59.108
  I0115 02:39:59.109053 24 podtemplates.go:158] requesting DeleteCollection of pod templates
  STEP: check that the list of pod templates matches the requested quantity @ 01/15/25 02:39:59.128
  I0115 02:39:59.129018 24 podtemplates.go:219] requesting list of pod templates to confirm quantity
  I0115 02:39:59.134859 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-2519" for this suite. @ 01/15/25 02:39:59.143
• [0.172 seconds]
------------------------------
[sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:72
  STEP: Creating a kubernetes client @ 01/15/25 02:39:59.156
  I0115 02:39:59.156226 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename container-probe @ 01/15/25 02:39:59.157
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:39:59.182
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:39:59.19
  E0115 02:39:59.685670      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:40:00.686703      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:40:01.687510      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:40:02.689662      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:40:03.689324      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:40:04.690002      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:40:05.692244      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:40:06.693690      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:40:07.694688      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:40:08.696082      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:40:09.696122      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:40:10.700112      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:40:11.700801      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:40:12.720097      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:40:13.721318      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:40:14.726145      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:40:15.730037      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:40:16.730370      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:40:17.741083      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:40:18.742182      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:40:19.742806      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:40:20.753694      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:40:21.753847      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:40:22.755791      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:40:23.508801 24 container_probe.go:92] Container started at 2025-01-15 02:40:00 +0000 UTC, pod became ready at 2025-01-15 02:40:22 +0000 UTC
  I0115 02:40:23.509177 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-5873" for this suite. @ 01/15/25 02:40:23.521
• [24.377 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:398
  STEP: Creating a kubernetes client @ 01/15/25 02:40:23.533
  I0115 02:40:23.533468 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename resourcequota @ 01/15/25 02:40:23.536
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:40:23.644
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:40:23.682
  E0115 02:40:23.767550      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Counting existing ResourceQuota @ 01/15/25 02:40:23.77
  E0115 02:40:24.763342      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:40:25.766226      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:40:26.766620      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:40:27.794253      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 01/15/25 02:40:28.784
  E0115 02:40:28.798305      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota status is calculated @ 01/15/25 02:40:28.813
  E0115 02:40:29.796675      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:40:30.798743      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Creating a ReplicationController @ 01/15/25 02:40:30.858
  STEP: Ensuring resource quota status captures replication controller creation @ 01/15/25 02:40:30.926
  E0115 02:40:31.799699      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:40:32.799943      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Deleting a ReplicationController @ 01/15/25 02:40:32.932
  STEP: Ensuring resource quota status released usage @ 01/15/25 02:40:32.94
  E0115 02:40:33.800170      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:40:34.802967      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:40:34.978077 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-423" for this suite. @ 01/15/25 02:40:34.998
• [11.474 seconds]
------------------------------
SSS
------------------------------
[sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/downwardapi.go:245
  STEP: Creating a kubernetes client @ 01/15/25 02:40:35.007
  I0115 02:40:35.008001 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename downward-api @ 01/15/25 02:40:35.009
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:40:35.031
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:40:35.038
  STEP: Creating a pod to test downward api env vars @ 01/15/25 02:40:35.042
  E0115 02:40:35.804349      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:40:36.805326      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:40:37.806022      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:40:38.807584      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 02:40:39.068
  I0115 02:40:39.077932 24 output.go:207] Trying to get logs from node 192.168.18.92 pod downward-api-0906f8e3-eb5b-415f-9991-8d09b9e06e1e container dapi-container: <nil>
  STEP: delete the pod @ 01/15/25 02:40:39.088
  I0115 02:40:39.113950 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-6511" for this suite. @ 01/15/25 02:40:39.124
• [4.129 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:98
  STEP: Creating a kubernetes client @ 01/15/25 02:40:39.138
  I0115 02:40:39.138699 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename aggregator @ 01/15/25 02:40:39.139
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:40:39.161
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:40:39.167
  I0115 02:40:39.177235 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Registering the sample API server. @ 01/15/25 02:40:39.178
  E0115 02:40:39.809059      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:40:40.024686 24 helpers.go:161] Found ClusterRoles; assuming RBAC is enabled.
  I0115 02:40:40.100011 24 deployment.go:223] deployment "sample-apiserver-deployment" doesn't have the required revision set
  E0115 02:40:40.810606      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:40:41.811281      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:40:42.298969 24 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.January, 15, 2, 40, 40, 0, time.Local), LastTransitionTime:time.Date(2025, time.January, 15, 2, 40, 40, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.January, 15, 2, 40, 40, 0, time.Local), LastTransitionTime:time.Date(2025, time.January, 15, 2, 40, 40, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6bbcf6575d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0115 02:40:42.812125      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:40:43.812727      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:40:44.310615 24 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.January, 15, 2, 40, 40, 0, time.Local), LastTransitionTime:time.Date(2025, time.January, 15, 2, 40, 40, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.January, 15, 2, 40, 40, 0, time.Local), LastTransitionTime:time.Date(2025, time.January, 15, 2, 40, 40, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6bbcf6575d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0115 02:40:44.814548      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:40:45.815482      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:40:46.308029 24 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.January, 15, 2, 40, 40, 0, time.Local), LastTransitionTime:time.Date(2025, time.January, 15, 2, 40, 40, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.January, 15, 2, 40, 40, 0, time.Local), LastTransitionTime:time.Date(2025, time.January, 15, 2, 40, 40, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6bbcf6575d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0115 02:40:46.815783      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:40:47.816903      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:40:48.308283 24 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.January, 15, 2, 40, 40, 0, time.Local), LastTransitionTime:time.Date(2025, time.January, 15, 2, 40, 40, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.January, 15, 2, 40, 40, 0, time.Local), LastTransitionTime:time.Date(2025, time.January, 15, 2, 40, 40, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6bbcf6575d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0115 02:40:48.817824      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:40:49.818852      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:40:50.332423 24 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.January, 15, 2, 40, 40, 0, time.Local), LastTransitionTime:time.Date(2025, time.January, 15, 2, 40, 40, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.January, 15, 2, 40, 40, 0, time.Local), LastTransitionTime:time.Date(2025, time.January, 15, 2, 40, 40, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6bbcf6575d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0115 02:40:50.820382      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:40:51.821833      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:40:52.306106 24 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.January, 15, 2, 40, 40, 0, time.Local), LastTransitionTime:time.Date(2025, time.January, 15, 2, 40, 40, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.January, 15, 2, 40, 40, 0, time.Local), LastTransitionTime:time.Date(2025, time.January, 15, 2, 40, 40, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6bbcf6575d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0115 02:40:52.823612      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:40:53.824536      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:40:54.332052 24 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.January, 15, 2, 40, 40, 0, time.Local), LastTransitionTime:time.Date(2025, time.January, 15, 2, 40, 40, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.January, 15, 2, 40, 40, 0, time.Local), LastTransitionTime:time.Date(2025, time.January, 15, 2, 40, 40, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6bbcf6575d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0115 02:40:54.825243      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:40:55.832208      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:40:56.364158 24 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.January, 15, 2, 40, 40, 0, time.Local), LastTransitionTime:time.Date(2025, time.January, 15, 2, 40, 40, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.January, 15, 2, 40, 40, 0, time.Local), LastTransitionTime:time.Date(2025, time.January, 15, 2, 40, 40, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6bbcf6575d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0115 02:40:56.826904      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:40:57.827019      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:40:58.308398 24 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.January, 15, 2, 40, 40, 0, time.Local), LastTransitionTime:time.Date(2025, time.January, 15, 2, 40, 40, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.January, 15, 2, 40, 40, 0, time.Local), LastTransitionTime:time.Date(2025, time.January, 15, 2, 40, 40, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6bbcf6575d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0115 02:40:58.827752      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:40:59.828644      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:41:00.326308 24 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.January, 15, 2, 40, 40, 0, time.Local), LastTransitionTime:time.Date(2025, time.January, 15, 2, 40, 40, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.January, 15, 2, 40, 40, 0, time.Local), LastTransitionTime:time.Date(2025, time.January, 15, 2, 40, 40, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-6bbcf6575d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0115 02:41:00.829320      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:41:01.829427      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:41:02.507888 24 aggregator.go:755] Waited 174.400932ms for the sample-apiserver to be ready to handle requests.
  STEP: Read Status for v1alpha1.wardle.example.com @ 01/15/25 02:41:02.591
  STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' @ 01/15/25 02:41:02.598
  STEP: List APIServices @ 01/15/25 02:41:02.609
  I0115 02:41:02.617904 24 aggregator.go:556] Found v1alpha1.wardle.example.com in APIServiceList
  STEP: Adding a label to the APIService @ 01/15/25 02:41:02.618
  I0115 02:41:02.632220 24 aggregator.go:581] APIService labels: map[e2e-apiservice:patched]
  STEP: Updating APIService Status @ 01/15/25 02:41:02.632
  I0115 02:41:02.644742 24 aggregator.go:607] updatedStatus.Conditions: []v1.APIServiceCondition{v1.APIServiceCondition{Type:"Available", Status:"True", LastTransitionTime:time.Date(2025, time.January, 15, 2, 41, 2, 0, time.Local), Reason:"Passed", Message:"all checks passed"}, v1.APIServiceCondition{Type:"StatusUpdated", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: Confirm that v1alpha1.wardle.example.com /status was updated @ 01/15/25 02:41:02.644
  I0115 02:41:02.649814 24 aggregator.go:625] Observed APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {Available True 2025-01-15 02:41:02 +0000 UTC Passed all checks passed}
  I0115 02:41:02.649919 24 aggregator.go:621] Found APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0115 02:41:02.649957 24 aggregator.go:631] Found updated status condition for v1alpha1.wardle.example.com
  STEP: Replace APIService v1alpha1.wardle.example.com @ 01/15/25 02:41:02.649
  I0115 02:41:02.664644 24 aggregator.go:647] Found updated apiService label for "v1alpha1.wardle.example.com"
  STEP: Delete flunders resource "dynamic-flunder-1457339420" @ 01/15/25 02:41:02.664
  STEP: Recreating test-flunder before removing endpoint via deleteCollection @ 01/15/25 02:41:02.69
  STEP: Read v1alpha1.wardle.example.com /status before patching it @ 01/15/25 02:41:02.705
  STEP: Patch APIService Status @ 01/15/25 02:41:02.709
  STEP: Confirm that v1alpha1.wardle.example.com /status was patched @ 01/15/25 02:41:02.717
  I0115 02:41:02.726280 24 aggregator.go:725] Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {Available True 2025-01-15 02:41:02 +0000 UTC Passed all checks passed}
  I0115 02:41:02.726467 24 aggregator.go:725] Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0115 02:41:02.726518 24 aggregator.go:721] Found APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC E2E Set by e2e test}
  I0115 02:41:02.726548 24 aggregator.go:731] Found patched status condition for v1alpha1.wardle.example.com
  STEP: APIService deleteCollection with labelSelector: "v1alpha1.wardle.example.com=updated" @ 01/15/25 02:41:02.726
  STEP: Confirm that the generated APIService has been deleted @ 01/15/25 02:41:02.735
  I0115 02:41:02.735174 24 aggregator.go:792] Requesting list of APIServices to confirm quantity
  I0115 02:41:02.739331 24 aggregator.go:802] Found 0 APIService with label "v1alpha1.wardle.example.com=updated"
  I0115 02:41:02.739447 24 aggregator.go:744] APIService v1alpha1.wardle.example.com has been deleted.
  E0115 02:41:02.830970      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:41:02.915393 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregator-2182" for this suite. @ 01/15/25 02:41:02.929
• [23.802 seconds]
------------------------------
SSSSS
------------------------------
[sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2216
  STEP: Creating a kubernetes client @ 01/15/25 02:41:02.941
  I0115 02:41:02.941230 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename services @ 01/15/25 02:41:02.945
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:41:02.97
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:41:02.977
  STEP: creating service in namespace services-3259 @ 01/15/25 02:41:02.984
  STEP: creating service affinity-nodeport-transition in namespace services-3259 @ 01/15/25 02:41:02.984
  STEP: creating replication controller affinity-nodeport-transition in namespace services-3259 @ 01/15/25 02:41:02.999
  I0115 02:41:03.008588      24 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-3259, replica count: 3
  E0115 02:41:03.831917      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:41:04.832839      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:41:05.833134      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:41:06.060200      24 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  E0115 02:41:06.834588      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:41:07.836936      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:41:08.838201      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:41:09.062022      24 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0115 02:41:09.085613 24 resource.go:361] Creating new exec pod
  E0115 02:41:09.837968      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:41:10.838813      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:41:11.839452      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:41:12.147479 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-3259 exec execpod-affinityg57h4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
  I0115 02:41:12.340241 24 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition (169.169.3.189) 80 port [tcp/http] succeeded!\n"
  I0115 02:41:12.340359 24 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0115 02:41:12.340466 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-3259 exec execpod-affinityg57h4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 169.169.3.189 80'
  I0115 02:41:12.663802 24 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 169.169.3.189 80\nConnection to 169.169.3.189 80 port [tcp/http] succeeded!\n"
  I0115 02:41:12.663894 24 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0115 02:41:12.664012 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-3259 exec execpod-affinityg57h4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.18.91 30552'
  E0115 02:41:12.840334      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:41:12.886026 24 builder.go:146] stderr: "+ + echonc hostName -v -t\n -w 2 192.168.18.91 30552\nConnection to 192.168.18.91 30552 port [tcp/*] succeeded!\n"
  I0115 02:41:12.886133 24 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0115 02:41:12.886253 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-3259 exec execpod-affinityg57h4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.18.92 30552'
  I0115 02:41:13.132431 24 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.18.92 30552\nConnection to 192.168.18.92 30552 port [tcp/*] succeeded!\n"
  I0115 02:41:13.132553 24 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0115 02:41:13.146293 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-3259 exec execpod-affinityg57h4 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.18.91:30552/ ; done'
  I0115 02:41:13.663791 24 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.18.91:30552/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.18.91:30552/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.18.91:30552/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.18.91:30552/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.18.91:30552/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.18.91:30552/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.18.91:30552/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.18.91:30552/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.18.91:30552/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.18.91:30552/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.18.91:30552/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.18.91:30552/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.18.91:30552/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.18.91:30552/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.18.91:30552/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.18.91:30552/\n"
  I0115 02:41:13.663928 24 builder.go:147] stdout: "\naffinity-nodeport-transition-wns96\naffinity-nodeport-transition-dpc9k\naffinity-nodeport-transition-dpc9k\naffinity-nodeport-transition-462q4\naffinity-nodeport-transition-dpc9k\naffinity-nodeport-transition-462q4\naffinity-nodeport-transition-462q4\naffinity-nodeport-transition-wns96\naffinity-nodeport-transition-wns96\naffinity-nodeport-transition-dpc9k\naffinity-nodeport-transition-wns96\naffinity-nodeport-transition-wns96\naffinity-nodeport-transition-dpc9k\naffinity-nodeport-transition-dpc9k\naffinity-nodeport-transition-462q4\naffinity-nodeport-transition-wns96"
  I0115 02:41:13.663977 24 service.go:242] Received response from host: affinity-nodeport-transition-wns96
  I0115 02:41:13.664001 24 service.go:242] Received response from host: affinity-nodeport-transition-dpc9k
  I0115 02:41:13.664245 24 service.go:242] Received response from host: affinity-nodeport-transition-dpc9k
  I0115 02:41:13.664287 24 service.go:242] Received response from host: affinity-nodeport-transition-462q4
  I0115 02:41:13.664308 24 service.go:242] Received response from host: affinity-nodeport-transition-dpc9k
  I0115 02:41:13.664326 24 service.go:242] Received response from host: affinity-nodeport-transition-462q4
  I0115 02:41:13.664344 24 service.go:242] Received response from host: affinity-nodeport-transition-462q4
  I0115 02:41:13.664361 24 service.go:242] Received response from host: affinity-nodeport-transition-wns96
  I0115 02:41:13.664379 24 service.go:242] Received response from host: affinity-nodeport-transition-wns96
  I0115 02:41:13.664398 24 service.go:242] Received response from host: affinity-nodeport-transition-dpc9k
  I0115 02:41:13.664574 24 service.go:242] Received response from host: affinity-nodeport-transition-wns96
  I0115 02:41:13.664599 24 service.go:242] Received response from host: affinity-nodeport-transition-wns96
  I0115 02:41:13.664618 24 service.go:242] Received response from host: affinity-nodeport-transition-dpc9k
  I0115 02:41:13.664644 24 service.go:242] Received response from host: affinity-nodeport-transition-dpc9k
  I0115 02:41:13.664662 24 service.go:242] Received response from host: affinity-nodeport-transition-462q4
  I0115 02:41:13.664679 24 service.go:242] Received response from host: affinity-nodeport-transition-wns96
  I0115 02:41:13.688838 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-3259 exec execpod-affinityg57h4 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.18.91:30552/ ; done'
  E0115 02:41:13.844844      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:41:14.579908 24 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.18.91:30552/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.18.91:30552/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.18.91:30552/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.18.91:30552/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.18.91:30552/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.18.91:30552/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.18.91:30552/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.18.91:30552/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.18.91:30552/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.18.91:30552/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.18.91:30552/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.18.91:30552/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.18.91:30552/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.18.91:30552/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.18.91:30552/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.18.91:30552/\n"
  I0115 02:41:14.580070 24 builder.go:147] stdout: "\naffinity-nodeport-transition-dpc9k\naffinity-nodeport-transition-dpc9k\naffinity-nodeport-transition-dpc9k\naffinity-nodeport-transition-dpc9k\naffinity-nodeport-transition-dpc9k\naffinity-nodeport-transition-dpc9k\naffinity-nodeport-transition-dpc9k\naffinity-nodeport-transition-dpc9k\naffinity-nodeport-transition-dpc9k\naffinity-nodeport-transition-dpc9k\naffinity-nodeport-transition-dpc9k\naffinity-nodeport-transition-dpc9k\naffinity-nodeport-transition-dpc9k\naffinity-nodeport-transition-dpc9k\naffinity-nodeport-transition-dpc9k\naffinity-nodeport-transition-dpc9k"
  I0115 02:41:14.580209 24 service.go:242] Received response from host: affinity-nodeport-transition-dpc9k
  I0115 02:41:14.580249 24 service.go:242] Received response from host: affinity-nodeport-transition-dpc9k
  I0115 02:41:14.580271 24 service.go:242] Received response from host: affinity-nodeport-transition-dpc9k
  I0115 02:41:14.580291 24 service.go:242] Received response from host: affinity-nodeport-transition-dpc9k
  I0115 02:41:14.580310 24 service.go:242] Received response from host: affinity-nodeport-transition-dpc9k
  I0115 02:41:14.580329 24 service.go:242] Received response from host: affinity-nodeport-transition-dpc9k
  I0115 02:41:14.580348 24 service.go:242] Received response from host: affinity-nodeport-transition-dpc9k
  I0115 02:41:14.580366 24 service.go:242] Received response from host: affinity-nodeport-transition-dpc9k
  I0115 02:41:14.580387 24 service.go:242] Received response from host: affinity-nodeport-transition-dpc9k
  I0115 02:41:14.580405 24 service.go:242] Received response from host: affinity-nodeport-transition-dpc9k
  I0115 02:41:14.580423 24 service.go:242] Received response from host: affinity-nodeport-transition-dpc9k
  I0115 02:41:14.580439 24 service.go:242] Received response from host: affinity-nodeport-transition-dpc9k
  I0115 02:41:14.580459 24 service.go:242] Received response from host: affinity-nodeport-transition-dpc9k
  I0115 02:41:14.580476 24 service.go:242] Received response from host: affinity-nodeport-transition-dpc9k
  I0115 02:41:14.580494 24 service.go:242] Received response from host: affinity-nodeport-transition-dpc9k
  I0115 02:41:14.580512 24 service.go:242] Received response from host: affinity-nodeport-transition-dpc9k
  I0115 02:41:14.580683 24 service.go:4203] Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-3259, will wait for the garbage collector to delete the pods @ 01/15/25 02:41:14.611
  I0115 02:41:14.684929 24 resources.go:139] Deleting ReplicationController affinity-nodeport-transition took: 10.70315ms
  I0115 02:41:14.785838 24 resources.go:163] Terminating ReplicationController affinity-nodeport-transition pods took: 100.898694ms
  E0115 02:41:14.846006      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:41:15.846839      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:41:16.849813      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:41:17.848940      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:41:18.850593      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:41:19.005158 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-3259" for this suite. @ 01/15/25 02:41:19.018
• [16.090 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should mount an API token into pods [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:80
  STEP: Creating a kubernetes client @ 01/15/25 02:41:19.031
  I0115 02:41:19.031383 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename svcaccounts @ 01/15/25 02:41:19.034
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:41:19.064
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:41:19.073
  E0115 02:41:19.850673      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:41:20.852177      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:41:21.853253      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:41:22.854114      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: reading a file in the container @ 01/15/25 02:41:23.185
  I0115 02:41:23.185636 24 kubectl_utils.go:203] Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6622 pod-service-account-7923176a-1164-43bd-a2d0-315e27af9158 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
  STEP: reading a file in the container @ 01/15/25 02:41:23.441
  I0115 02:41:23.441907 24 kubectl_utils.go:203] Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6622 pod-service-account-7923176a-1164-43bd-a2d0-315e27af9158 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
  STEP: reading a file in the container @ 01/15/25 02:41:23.589
  I0115 02:41:23.589834 24 kubectl_utils.go:203] Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6622 pod-service-account-7923176a-1164-43bd-a2d0-315e27af9158 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
  I0115 02:41:23.785535 24 service_accounts.go:120] Got root ca configmap in namespace "svcaccounts-6622"
  I0115 02:41:23.789016 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-6622" for this suite. @ 01/15/25 02:41:23.794
• [4.770 seconds]
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:170
  STEP: Creating a kubernetes client @ 01/15/25 02:41:23.801
  I0115 02:41:23.801956 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename emptydir @ 01/15/25 02:41:23.803
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:41:23.82
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:41:23.825
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 01/15/25 02:41:23.829
  E0115 02:41:23.855187      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:41:24.855476      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:41:25.855975      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:41:26.856620      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:41:27.857336      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 02:41:27.859
  I0115 02:41:27.866665 24 output.go:207] Trying to get logs from node 192.168.18.92 pod pod-f3d9fb1a-3dc9-4722-a388-7a1c23cd0f57 container test-container: <nil>
  STEP: delete the pod @ 01/15/25 02:41:27.882
  I0115 02:41:27.916459 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-8980" for this suite. @ 01/15/25 02:41:27.932
• [4.144 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicyBinding API operations [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/validatingadmissionpolicy.go:678
  STEP: Creating a kubernetes client @ 01/15/25 02:41:27.947
  I0115 02:41:27.948089 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename validating-admission-policy @ 01/15/25 02:41:27.951
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:41:27.972
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:41:27.978
  STEP: getting /apis @ 01/15/25 02:41:27.992
  STEP: getting /apis/admissionregistration.k8s.io @ 01/15/25 02:41:28.001
  STEP: getting /apis/admissionregistration.k8s.io/v1 @ 01/15/25 02:41:28.004
  STEP: creating @ 01/15/25 02:41:28.006
  STEP: getting @ 01/15/25 02:41:28.023
  STEP: listing @ 01/15/25 02:41:28.026
  STEP: watching @ 01/15/25 02:41:28.03
  I0115 02:41:28.030322 24 validatingadmissionpolicy.go:773] starting watch
  STEP: patching @ 01/15/25 02:41:28.032
  STEP: updating @ 01/15/25 02:41:28.038
  I0115 02:41:28.048271 24 validatingadmissionpolicy.go:801] waiting for watch events with expected annotations
  STEP: deleting @ 01/15/25 02:41:28.048
  STEP: deleting a collection @ 01/15/25 02:41:28.062
  I0115 02:41:28.083250 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "validating-admission-policy-2445" for this suite. @ 01/15/25 02:41:28.088
• [0.149 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:230
  STEP: Creating a kubernetes client @ 01/15/25 02:41:28.096
  I0115 02:41:28.096164 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename emptydir @ 01/15/25 02:41:28.097
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:41:28.115
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:41:28.122
  STEP: Creating Pod @ 01/15/25 02:41:28.127
  E0115 02:41:28.857554      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:41:29.858583      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:41:30.860888      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:41:31.860573      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Reading file content from the nginx-container @ 01/15/25 02:41:32.163
  I0115 02:41:32.163144 24 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-8060 PodName:pod-sharedvolume-af8e9703-78ea-4dde-b2cf-c65b395ee5bb ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0115 02:41:32.163182 24 exec_util.go:64] ExecWithOptions: Clientset creation
  I0115 02:41:32.163279 24 exec_util.go:80] ExecWithOptions: execute(POST https://169.169.0.1:443/api/v1/namespaces/emptydir-8060/pods/pod-sharedvolume-af8e9703-78ea-4dde-b2cf-c65b395ee5bb/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&stderr=true&stdout=true)
  I0115 02:41:32.352516 24 exec_util.go:108] Exec stderr: ""
  I0115 02:41:32.356864 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-8060" for this suite. @ 01/15/25 02:41:32.376
• [4.313 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency should not be very high [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service_latency.go:59
  STEP: Creating a kubernetes client @ 01/15/25 02:41:32.409
  I0115 02:41:32.409377 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename svc-latency @ 01/15/25 02:41:32.411
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:41:32.44
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:41:32.448
  I0115 02:41:32.454770 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: creating replication controller svc-latency-rc in namespace svc-latency-5706 @ 01/15/25 02:41:32.456
  I0115 02:41:32.465220      24 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-5706, replica count: 1
  E0115 02:41:32.861942      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:41:33.518605      24 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  E0115 02:41:33.862506      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:41:34.519319      24 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  E0115 02:41:34.863742      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:41:35.519747      24 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0115 02:41:35.656610 24 service_latency.go:356] Created: latency-svc-5dhv4
  I0115 02:41:35.670539 24 service_latency.go:363] Got endpoints: latency-svc-5dhv4 [49.976674ms]
  I0115 02:41:35.693332 24 service_latency.go:356] Created: latency-svc-lcq8t
  I0115 02:41:35.701504 24 service_latency.go:356] Created: latency-svc-49pdp
  I0115 02:41:35.701503 24 service_latency.go:363] Got endpoints: latency-svc-lcq8t [30.775661ms]
  I0115 02:41:35.728585 24 service_latency.go:363] Got endpoints: latency-svc-49pdp [57.776464ms]
  I0115 02:41:35.735440 24 service_latency.go:356] Created: latency-svc-x4z2c
  I0115 02:41:35.745577 24 service_latency.go:363] Got endpoints: latency-svc-x4z2c [74.55682ms]
  I0115 02:41:35.745651 24 service_latency.go:356] Created: latency-svc-x8dvf
  I0115 02:41:35.753012 24 service_latency.go:363] Got endpoints: latency-svc-x8dvf [82.13917ms]
  I0115 02:41:35.761084 24 service_latency.go:356] Created: latency-svc-v4bch
  I0115 02:41:35.767947 24 service_latency.go:363] Got endpoints: latency-svc-v4bch [96.668594ms]
  I0115 02:41:35.769372 24 service_latency.go:356] Created: latency-svc-lvr2t
  I0115 02:41:35.781994 24 service_latency.go:363] Got endpoints: latency-svc-lvr2t [111.071534ms]
  I0115 02:41:35.783572 24 service_latency.go:356] Created: latency-svc-mrvnk
  I0115 02:41:35.794995 24 service_latency.go:363] Got endpoints: latency-svc-mrvnk [123.889326ms]
  I0115 02:41:35.801047 24 service_latency.go:356] Created: latency-svc-k2v8s
  I0115 02:41:35.813122 24 service_latency.go:363] Got endpoints: latency-svc-k2v8s [141.664607ms]
  I0115 02:41:35.815450 24 service_latency.go:356] Created: latency-svc-xg5nk
  I0115 02:41:35.821876 24 service_latency.go:363] Got endpoints: latency-svc-xg5nk [150.545536ms]
  I0115 02:41:35.828411 24 service_latency.go:356] Created: latency-svc-vrmk2
  I0115 02:41:35.833312 24 service_latency.go:363] Got endpoints: latency-svc-vrmk2 [161.781637ms]
  E0115 02:41:35.863882      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:41:35.890753 24 service_latency.go:356] Created: latency-svc-72574
  I0115 02:41:35.899142 24 service_latency.go:356] Created: latency-svc-628xk
  I0115 02:41:35.900183 24 service_latency.go:356] Created: latency-svc-w4qsf
  I0115 02:41:35.900279 24 service_latency.go:356] Created: latency-svc-22j8v
  I0115 02:41:35.900339 24 service_latency.go:356] Created: latency-svc-vsb4p
  I0115 02:41:35.900365 24 service_latency.go:356] Created: latency-svc-d6hpw
  I0115 02:41:35.900393 24 service_latency.go:356] Created: latency-svc-bxgck
  I0115 02:41:35.900472 24 service_latency.go:356] Created: latency-svc-88hkk
  I0115 02:41:35.903988 24 service_latency.go:356] Created: latency-svc-cxkhq
  I0115 02:41:35.904142 24 service_latency.go:356] Created: latency-svc-2xgw6
  I0115 02:41:35.904253 24 service_latency.go:356] Created: latency-svc-78q6r
  I0115 02:41:35.916260 24 service_latency.go:356] Created: latency-svc-g8m5p
  I0115 02:41:35.916260 24 service_latency.go:356] Created: latency-svc-2579m
  I0115 02:41:35.916329 24 service_latency.go:356] Created: latency-svc-khsfq
  I0115 02:41:35.917708 24 service_latency.go:356] Created: latency-svc-5bjsc
  I0115 02:41:35.934117 24 service_latency.go:363] Got endpoints: latency-svc-72574 [232.523161ms]
  I0115 02:41:35.934872 24 service_latency.go:363] Got endpoints: latency-svc-88hkk [121.610548ms]
  I0115 02:41:35.937182 24 service_latency.go:363] Got endpoints: latency-svc-vsb4p [208.495506ms]
  I0115 02:41:35.938513 24 service_latency.go:363] Got endpoints: latency-svc-cxkhq [192.865483ms]
  I0115 02:41:35.946960 24 service_latency.go:363] Got endpoints: latency-svc-628xk [113.48173ms]
  I0115 02:41:35.954670 24 service_latency.go:363] Got endpoints: latency-svc-w4qsf [283.239133ms]
  I0115 02:41:35.958976 24 service_latency.go:356] Created: latency-svc-z87k7
  I0115 02:41:35.959148 24 service_latency.go:363] Got endpoints: latency-svc-22j8v [287.530557ms]
  I0115 02:41:35.959559 24 service_latency.go:363] Got endpoints: latency-svc-d6hpw [288.174829ms]
  I0115 02:41:35.959731 24 service_latency.go:363] Got endpoints: latency-svc-5bjsc [206.657291ms]
  I0115 02:41:35.959800 24 service_latency.go:363] Got endpoints: latency-svc-78q6r [164.701294ms]
  I0115 02:41:35.978021 24 service_latency.go:356] Created: latency-svc-k9sx7
  I0115 02:41:35.987689 24 service_latency.go:363] Got endpoints: latency-svc-2xgw6 [205.611575ms]
  I0115 02:41:35.994345 24 service_latency.go:363] Got endpoints: latency-svc-2579m [322.635117ms]
  I0115 02:41:35.994577 24 service_latency.go:363] Got endpoints: latency-svc-bxgck [172.569757ms]
  I0115 02:41:35.994852 24 service_latency.go:363] Got endpoints: latency-svc-khsfq [226.831175ms]
  I0115 02:41:35.994901 24 service_latency.go:363] Got endpoints: latency-svc-g8m5p [323.209372ms]
  I0115 02:41:36.002577 24 service_latency.go:356] Created: latency-svc-zs4lf
  I0115 02:41:36.016392 24 service_latency.go:363] Got endpoints: latency-svc-k9sx7 [81.450675ms]
  I0115 02:41:36.017549 24 service_latency.go:363] Got endpoints: latency-svc-z87k7 [83.271472ms]
  I0115 02:41:36.018922 24 service_latency.go:363] Got endpoints: latency-svc-zs4lf [80.990058ms]
  I0115 02:41:36.023682 24 service_latency.go:356] Created: latency-svc-8ng7j
  I0115 02:41:36.036385 24 service_latency.go:363] Got endpoints: latency-svc-8ng7j [97.695015ms]
  I0115 02:41:36.038357 24 service_latency.go:356] Created: latency-svc-hgmmp
  I0115 02:41:36.044160 24 service_latency.go:356] Created: latency-svc-dgfpz
  I0115 02:41:36.053689 24 service_latency.go:363] Got endpoints: latency-svc-hgmmp [106.585839ms]
  I0115 02:41:36.053844 24 service_latency.go:363] Got endpoints: latency-svc-dgfpz [99.047132ms]
  I0115 02:41:36.054633 24 service_latency.go:356] Created: latency-svc-74l2d
  I0115 02:41:36.068379 24 service_latency.go:363] Got endpoints: latency-svc-74l2d [109.185573ms]
  I0115 02:41:36.069280 24 service_latency.go:356] Created: latency-svc-xpdmh
  I0115 02:41:36.081404 24 service_latency.go:363] Got endpoints: latency-svc-xpdmh [121.502684ms]
  I0115 02:41:36.087235 24 service_latency.go:356] Created: latency-svc-bhd7g
  I0115 02:41:36.094975 24 service_latency.go:356] Created: latency-svc-5xnqh
  I0115 02:41:36.097883 24 service_latency.go:363] Got endpoints: latency-svc-bhd7g [138.239093ms]
  I0115 02:41:36.103694 24 service_latency.go:363] Got endpoints: latency-svc-5xnqh [143.907875ms]
  I0115 02:41:36.111404 24 service_latency.go:356] Created: latency-svc-bvcs8
  I0115 02:41:36.125626 24 service_latency.go:363] Got endpoints: latency-svc-bvcs8 [137.829432ms]
  I0115 02:41:36.139688 24 service_latency.go:356] Created: latency-svc-prq5n
  I0115 02:41:36.150905 24 service_latency.go:363] Got endpoints: latency-svc-prq5n [156.464165ms]
  I0115 02:41:36.153867 24 service_latency.go:356] Created: latency-svc-bgcbc
  I0115 02:41:36.165868 24 service_latency.go:363] Got endpoints: latency-svc-bgcbc [171.240596ms]
  I0115 02:41:36.173180 24 service_latency.go:356] Created: latency-svc-5zpn4
  I0115 02:41:36.187797 24 service_latency.go:363] Got endpoints: latency-svc-5zpn4 [192.895988ms]
  I0115 02:41:36.197171 24 service_latency.go:356] Created: latency-svc-bg8cz
  I0115 02:41:36.217576 24 service_latency.go:363] Got endpoints: latency-svc-bg8cz [222.563443ms]
  I0115 02:41:36.224992 24 service_latency.go:356] Created: latency-svc-pkq8k
  I0115 02:41:36.234384 24 service_latency.go:356] Created: latency-svc-7mr4c
  I0115 02:41:36.249295 24 service_latency.go:356] Created: latency-svc-h9rxj
  I0115 02:41:36.260971 24 service_latency.go:356] Created: latency-svc-xcf2n
  I0115 02:41:36.271154 24 service_latency.go:356] Created: latency-svc-p5rwm
  I0115 02:41:36.282287 24 service_latency.go:363] Got endpoints: latency-svc-pkq8k [265.728882ms]
  I0115 02:41:36.292140 24 service_latency.go:356] Created: latency-svc-j4r5n
  I0115 02:41:36.309799 24 service_latency.go:356] Created: latency-svc-6bfxn
  I0115 02:41:36.326879 24 service_latency.go:363] Got endpoints: latency-svc-7mr4c [309.253521ms]
  I0115 02:41:36.332106 24 service_latency.go:356] Created: latency-svc-c9lxk
  I0115 02:41:36.347228 24 service_latency.go:356] Created: latency-svc-gchmp
  I0115 02:41:36.356823 24 service_latency.go:356] Created: latency-svc-tjqvx
  I0115 02:41:36.415910 24 service_latency.go:356] Created: latency-svc-6mqj8
  I0115 02:41:36.416142 24 service_latency.go:363] Got endpoints: latency-svc-h9rxj [397.084786ms]
  I0115 02:41:36.464037 24 service_latency.go:363] Got endpoints: latency-svc-xcf2n [427.500952ms]
  I0115 02:41:36.488772 24 service_latency.go:356] Created: latency-svc-sf5rh
  I0115 02:41:36.494426 24 service_latency.go:363] Got endpoints: latency-svc-p5rwm [440.484333ms]
  I0115 02:41:36.533729 24 service_latency.go:363] Got endpoints: latency-svc-j4r5n [479.884456ms]
  I0115 02:41:36.540776 24 service_latency.go:356] Created: latency-svc-hmgrm
  I0115 02:41:36.557914 24 service_latency.go:356] Created: latency-svc-rddps
  I0115 02:41:36.581009 24 service_latency.go:363] Got endpoints: latency-svc-6bfxn [512.449587ms]
  I0115 02:41:36.582367 24 service_latency.go:356] Created: latency-svc-lz6vk
  I0115 02:41:36.598839 24 service_latency.go:356] Created: latency-svc-wzz5q
  I0115 02:41:36.611079 24 service_latency.go:356] Created: latency-svc-rl7k6
  I0115 02:41:36.617731 24 service_latency.go:356] Created: latency-svc-cm7l6
  I0115 02:41:36.622779 24 service_latency.go:363] Got endpoints: latency-svc-c9lxk [541.239859ms]
  I0115 02:41:36.630163 24 service_latency.go:356] Created: latency-svc-cb7cs
  I0115 02:41:36.640082 24 service_latency.go:356] Created: latency-svc-mxnzw
  I0115 02:41:36.644752 24 service_latency.go:356] Created: latency-svc-9ctwd
  I0115 02:41:36.651538 24 service_latency.go:356] Created: latency-svc-7spzd
  I0115 02:41:36.669600 24 service_latency.go:363] Got endpoints: latency-svc-gchmp [571.556315ms]
  I0115 02:41:36.671321 24 service_latency.go:356] Created: latency-svc-l5ttz
  I0115 02:41:36.694692 24 service_latency.go:356] Created: latency-svc-ps6hw
  I0115 02:41:36.719175 24 service_latency.go:363] Got endpoints: latency-svc-tjqvx [615.347998ms]
  I0115 02:41:36.734456 24 service_latency.go:356] Created: latency-svc-prvqv
  I0115 02:41:36.766860 24 service_latency.go:363] Got endpoints: latency-svc-6mqj8 [640.885642ms]
  I0115 02:41:36.781436 24 service_latency.go:356] Created: latency-svc-5cm4j
  I0115 02:41:36.816981 24 service_latency.go:363] Got endpoints: latency-svc-sf5rh [665.972591ms]
  I0115 02:41:36.830721 24 service_latency.go:356] Created: latency-svc-pr8bt
  E0115 02:41:36.864845      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:41:36.866480 24 service_latency.go:363] Got endpoints: latency-svc-hmgrm [700.516698ms]
  I0115 02:41:36.883113 24 service_latency.go:356] Created: latency-svc-7qlrc
  I0115 02:41:36.922263 24 service_latency.go:363] Got endpoints: latency-svc-rddps [734.33614ms]
  I0115 02:41:36.938784 24 service_latency.go:356] Created: latency-svc-4v68l
  I0115 02:41:36.970094 24 service_latency.go:363] Got endpoints: latency-svc-lz6vk [752.401877ms]
  I0115 02:41:36.985888 24 service_latency.go:356] Created: latency-svc-xm7vt
  I0115 02:41:37.016943 24 service_latency.go:363] Got endpoints: latency-svc-wzz5q [734.55853ms]
  I0115 02:41:37.030942 24 service_latency.go:356] Created: latency-svc-zz8nm
  I0115 02:41:37.082281 24 service_latency.go:363] Got endpoints: latency-svc-rl7k6 [753.993473ms]
  I0115 02:41:37.122601 24 service_latency.go:356] Created: latency-svc-dhtkg
  I0115 02:41:37.128514 24 service_latency.go:363] Got endpoints: latency-svc-cm7l6 [712.009225ms]
  I0115 02:41:37.141554 24 service_latency.go:356] Created: latency-svc-fv95j
  I0115 02:41:37.164969 24 service_latency.go:363] Got endpoints: latency-svc-cb7cs [700.854867ms]
  I0115 02:41:37.183389 24 service_latency.go:356] Created: latency-svc-ctm5c
  I0115 02:41:37.216212 24 service_latency.go:363] Got endpoints: latency-svc-mxnzw [719.735184ms]
  I0115 02:41:37.231504 24 service_latency.go:356] Created: latency-svc-s7sqf
  I0115 02:41:37.263862 24 service_latency.go:363] Got endpoints: latency-svc-9ctwd [729.970292ms]
  I0115 02:41:37.277898 24 service_latency.go:356] Created: latency-svc-4lhv7
  I0115 02:41:37.317951 24 service_latency.go:363] Got endpoints: latency-svc-7spzd [736.797025ms]
  I0115 02:41:37.330602 24 service_latency.go:356] Created: latency-svc-xft2z
  I0115 02:41:37.368388 24 service_latency.go:363] Got endpoints: latency-svc-l5ttz [745.500305ms]
  I0115 02:41:37.382810 24 service_latency.go:356] Created: latency-svc-27tcr
  I0115 02:41:37.416637 24 service_latency.go:363] Got endpoints: latency-svc-ps6hw [746.91161ms]
  I0115 02:41:37.449100 24 service_latency.go:356] Created: latency-svc-gxxmp
  I0115 02:41:37.467295 24 service_latency.go:363] Got endpoints: latency-svc-prvqv [747.992269ms]
  I0115 02:41:37.479067 24 service_latency.go:356] Created: latency-svc-99gqk
  I0115 02:41:37.518428 24 service_latency.go:363] Got endpoints: latency-svc-5cm4j [751.403128ms]
  I0115 02:41:37.531109 24 service_latency.go:356] Created: latency-svc-7flb5
  I0115 02:41:37.611243 24 service_latency.go:363] Got endpoints: latency-svc-pr8bt [794.120832ms]
  I0115 02:41:37.642173 24 service_latency.go:363] Got endpoints: latency-svc-7qlrc [775.605166ms]
  I0115 02:41:37.672388 24 service_latency.go:356] Created: latency-svc-hrfzn
  I0115 02:41:37.681332 24 service_latency.go:363] Got endpoints: latency-svc-4v68l [758.793296ms]
  I0115 02:41:37.708838 24 service_latency.go:356] Created: latency-svc-6htkg
  I0115 02:41:37.750027 24 service_latency.go:356] Created: latency-svc-fm6hj
  I0115 02:41:37.757313 24 service_latency.go:363] Got endpoints: latency-svc-xm7vt [787.077189ms]
  I0115 02:41:37.821282 24 service_latency.go:363] Got endpoints: latency-svc-zz8nm [804.16288ms]
  I0115 02:41:37.826675 24 service_latency.go:356] Created: latency-svc-4c9hz
  I0115 02:41:37.862580 24 service_latency.go:363] Got endpoints: latency-svc-dhtkg [780.133501ms]
  E0115 02:41:37.864991      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:41:37.886948 24 service_latency.go:363] Got endpoints: latency-svc-fv95j [758.311889ms]
  I0115 02:41:37.897610 24 service_latency.go:356] Created: latency-svc-qkgvx
  I0115 02:41:37.915865 24 service_latency.go:356] Created: latency-svc-gb5hq
  I0115 02:41:37.923384 24 service_latency.go:363] Got endpoints: latency-svc-ctm5c [758.308038ms]
  I0115 02:41:37.930113 24 service_latency.go:356] Created: latency-svc-qzvdq
  I0115 02:41:37.941205 24 service_latency.go:356] Created: latency-svc-rdjpg
  I0115 02:41:37.971805 24 service_latency.go:363] Got endpoints: latency-svc-s7sqf [755.506947ms]
  I0115 02:41:37.985983 24 service_latency.go:356] Created: latency-svc-6ff4q
  I0115 02:41:38.016441 24 service_latency.go:363] Got endpoints: latency-svc-4lhv7 [752.485355ms]
  I0115 02:41:38.034114 24 service_latency.go:356] Created: latency-svc-9kcbq
  I0115 02:41:38.069226 24 service_latency.go:363] Got endpoints: latency-svc-xft2z [751.131855ms]
  I0115 02:41:38.093565 24 service_latency.go:356] Created: latency-svc-4g2nd
  I0115 02:41:38.115259 24 service_latency.go:363] Got endpoints: latency-svc-27tcr [746.177956ms]
  I0115 02:41:38.134433 24 service_latency.go:356] Created: latency-svc-pjgzk
  I0115 02:41:38.168757 24 service_latency.go:363] Got endpoints: latency-svc-gxxmp [752.025108ms]
  I0115 02:41:38.183488 24 service_latency.go:356] Created: latency-svc-nfg5g
  I0115 02:41:38.224880 24 service_latency.go:363] Got endpoints: latency-svc-99gqk [757.16489ms]
  I0115 02:41:38.250601 24 service_latency.go:356] Created: latency-svc-5dmbl
  I0115 02:41:38.266754 24 service_latency.go:363] Got endpoints: latency-svc-7flb5 [748.248602ms]
  I0115 02:41:38.281218 24 service_latency.go:356] Created: latency-svc-njc99
  I0115 02:41:38.317285 24 service_latency.go:363] Got endpoints: latency-svc-hrfzn [705.941913ms]
  I0115 02:41:38.332393 24 service_latency.go:356] Created: latency-svc-wkc4w
  I0115 02:41:38.366309 24 service_latency.go:363] Got endpoints: latency-svc-6htkg [722.242175ms]
  I0115 02:41:38.381772 24 service_latency.go:356] Created: latency-svc-rv9fz
  I0115 02:41:38.414698 24 service_latency.go:363] Got endpoints: latency-svc-fm6hj [733.286416ms]
  I0115 02:41:38.431923 24 service_latency.go:356] Created: latency-svc-sg2db
  I0115 02:41:38.465801 24 service_latency.go:363] Got endpoints: latency-svc-4c9hz [708.38656ms]
  I0115 02:41:38.483069 24 service_latency.go:356] Created: latency-svc-trn8z
  I0115 02:41:38.514533 24 service_latency.go:363] Got endpoints: latency-svc-qkgvx [693.156261ms]
  I0115 02:41:38.533809 24 service_latency.go:356] Created: latency-svc-xb6hg
  I0115 02:41:38.572976 24 service_latency.go:363] Got endpoints: latency-svc-gb5hq [710.226182ms]
  I0115 02:41:38.590801 24 service_latency.go:356] Created: latency-svc-n5pfr
  I0115 02:41:38.615639 24 service_latency.go:363] Got endpoints: latency-svc-qzvdq [728.557423ms]
  I0115 02:41:38.629557 24 service_latency.go:356] Created: latency-svc-kwt48
  I0115 02:41:38.670895 24 service_latency.go:363] Got endpoints: latency-svc-rdjpg [747.371558ms]
  I0115 02:41:38.693167 24 service_latency.go:356] Created: latency-svc-64t98
  I0115 02:41:38.727109 24 service_latency.go:363] Got endpoints: latency-svc-6ff4q [755.136244ms]
  I0115 02:41:38.781342 24 service_latency.go:356] Created: latency-svc-b96w4
  I0115 02:41:38.784663 24 service_latency.go:363] Got endpoints: latency-svc-9kcbq [768.124317ms]
  I0115 02:41:38.853814 24 service_latency.go:363] Got endpoints: latency-svc-4g2nd [784.246807ms]
  E0115 02:41:38.865621      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:41:38.884966 24 service_latency.go:356] Created: latency-svc-pdwk8
  I0115 02:41:38.890609 24 service_latency.go:363] Got endpoints: latency-svc-pjgzk [775.226788ms]
  I0115 02:41:38.941827 24 service_latency.go:356] Created: latency-svc-fzpdj
  I0115 02:41:38.955078 24 service_latency.go:363] Got endpoints: latency-svc-nfg5g [786.22651ms]
  I0115 02:41:38.972921 24 service_latency.go:356] Created: latency-svc-z9fkt
  I0115 02:41:38.984806 24 service_latency.go:363] Got endpoints: latency-svc-5dmbl [759.80024ms]
  I0115 02:41:38.993029 24 service_latency.go:356] Created: latency-svc-tsrx2
  I0115 02:41:39.017555 24 service_latency.go:356] Created: latency-svc-wr2bc
  I0115 02:41:39.032829 24 service_latency.go:363] Got endpoints: latency-svc-njc99 [765.885819ms]
  I0115 02:41:39.065453 24 service_latency.go:356] Created: latency-svc-92h4w
  I0115 02:41:39.070057 24 service_latency.go:363] Got endpoints: latency-svc-wkc4w [752.67933ms]
  I0115 02:41:39.087547 24 service_latency.go:356] Created: latency-svc-trg5v
  I0115 02:41:39.132664 24 service_latency.go:363] Got endpoints: latency-svc-rv9fz [766.265924ms]
  I0115 02:41:39.159183 24 service_latency.go:356] Created: latency-svc-9spkh
  I0115 02:41:39.180672 24 service_latency.go:363] Got endpoints: latency-svc-sg2db [765.776841ms]
  I0115 02:41:39.225753 24 service_latency.go:356] Created: latency-svc-qt4fp
  I0115 02:41:39.226267 24 service_latency.go:363] Got endpoints: latency-svc-trn8z [760.307533ms]
  I0115 02:41:39.243445 24 service_latency.go:356] Created: latency-svc-6sj67
  I0115 02:41:39.267376 24 service_latency.go:363] Got endpoints: latency-svc-xb6hg [752.710192ms]
  I0115 02:41:39.292232 24 service_latency.go:356] Created: latency-svc-ht76k
  I0115 02:41:39.320151 24 service_latency.go:363] Got endpoints: latency-svc-n5pfr [747.044531ms]
  I0115 02:41:39.350905 24 service_latency.go:356] Created: latency-svc-f969q
  I0115 02:41:39.408904 24 service_latency.go:363] Got endpoints: latency-svc-kwt48 [793.117016ms]
  I0115 02:41:39.456179 24 service_latency.go:363] Got endpoints: latency-svc-64t98 [785.19199ms]
  I0115 02:41:39.495003 24 service_latency.go:363] Got endpoints: latency-svc-b96w4 [767.726845ms]
  I0115 02:41:39.519484 24 service_latency.go:356] Created: latency-svc-fj5sp
  I0115 02:41:39.545715 24 service_latency.go:363] Got endpoints: latency-svc-pdwk8 [757.844681ms]
  I0115 02:41:39.565876 24 service_latency.go:356] Created: latency-svc-9h78b
  I0115 02:41:39.580250 24 service_latency.go:363] Got endpoints: latency-svc-fzpdj [726.349492ms]
  I0115 02:41:39.597470 24 service_latency.go:356] Created: latency-svc-4v2wv
  I0115 02:41:39.635299 24 service_latency.go:356] Created: latency-svc-nbljn
  I0115 02:41:39.676757 24 service_latency.go:363] Got endpoints: latency-svc-z9fkt [785.97852ms]
  I0115 02:41:39.692044 24 service_latency.go:363] Got endpoints: latency-svc-tsrx2 [736.840928ms]
  I0115 02:41:39.726432 24 service_latency.go:356] Created: latency-svc-gkc4p
  I0115 02:41:39.744871 24 service_latency.go:363] Got endpoints: latency-svc-wr2bc [759.951486ms]
  I0115 02:41:39.768357 24 service_latency.go:356] Created: latency-svc-55b7n
  I0115 02:41:39.790347 24 service_latency.go:363] Got endpoints: latency-svc-92h4w [757.383872ms]
  I0115 02:41:39.803949 24 service_latency.go:356] Created: latency-svc-j972r
  I0115 02:41:39.823015 24 service_latency.go:363] Got endpoints: latency-svc-trg5v [752.814542ms]
  I0115 02:41:39.831186 24 service_latency.go:356] Created: latency-svc-99lq4
  I0115 02:41:39.844804 24 service_latency.go:356] Created: latency-svc-rnd2l
  I0115 02:41:39.863652 24 service_latency.go:356] Created: latency-svc-rkmvs
  E0115 02:41:39.866949      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:41:39.878743 24 service_latency.go:363] Got endpoints: latency-svc-9spkh [745.983851ms]
  I0115 02:41:39.899997 24 service_latency.go:356] Created: latency-svc-wcrkm
  I0115 02:41:39.924615 24 service_latency.go:363] Got endpoints: latency-svc-qt4fp [734.990128ms]
  I0115 02:41:39.944483 24 service_latency.go:356] Created: latency-svc-29z9p
  I0115 02:41:39.975526 24 service_latency.go:363] Got endpoints: latency-svc-6sj67 [749.160727ms]
  I0115 02:41:39.997236 24 service_latency.go:356] Created: latency-svc-jfq7d
  I0115 02:41:40.017051 24 service_latency.go:363] Got endpoints: latency-svc-ht76k [749.589698ms]
  I0115 02:41:40.053013 24 service_latency.go:356] Created: latency-svc-w74qg
  I0115 02:41:40.067590 24 service_latency.go:363] Got endpoints: latency-svc-f969q [747.298381ms]
  I0115 02:41:40.093897 24 service_latency.go:356] Created: latency-svc-jcw4w
  I0115 02:41:40.117096 24 service_latency.go:363] Got endpoints: latency-svc-fj5sp [708.103803ms]
  I0115 02:41:40.141668 24 service_latency.go:356] Created: latency-svc-w5qpd
  I0115 02:41:40.168712 24 service_latency.go:363] Got endpoints: latency-svc-9h78b [712.252664ms]
  I0115 02:41:40.186618 24 service_latency.go:356] Created: latency-svc-kd7pn
  I0115 02:41:40.214803 24 service_latency.go:363] Got endpoints: latency-svc-4v2wv [719.650036ms]
  I0115 02:41:40.227780 24 service_latency.go:356] Created: latency-svc-fbvcn
  I0115 02:41:40.267747 24 service_latency.go:363] Got endpoints: latency-svc-nbljn [721.929751ms]
  I0115 02:41:40.285438 24 service_latency.go:356] Created: latency-svc-5g674
  I0115 02:41:40.315043 24 service_latency.go:363] Got endpoints: latency-svc-gkc4p [734.450326ms]
  I0115 02:41:40.333156 24 service_latency.go:356] Created: latency-svc-zvwws
  I0115 02:41:40.368577 24 service_latency.go:363] Got endpoints: latency-svc-55b7n [691.62156ms]
  I0115 02:41:40.383539 24 service_latency.go:356] Created: latency-svc-fvxs2
  I0115 02:41:40.417643 24 service_latency.go:363] Got endpoints: latency-svc-j972r [725.492428ms]
  I0115 02:41:40.432952 24 service_latency.go:356] Created: latency-svc-r9sjb
  I0115 02:41:40.465914 24 service_latency.go:363] Got endpoints: latency-svc-99lq4 [720.931307ms]
  I0115 02:41:40.485160 24 service_latency.go:356] Created: latency-svc-8hm7p
  I0115 02:41:40.518998 24 service_latency.go:363] Got endpoints: latency-svc-rnd2l [727.74949ms]
  I0115 02:41:40.534996 24 service_latency.go:356] Created: latency-svc-xhxf5
  I0115 02:41:40.581865 24 service_latency.go:363] Got endpoints: latency-svc-rkmvs [758.669187ms]
  I0115 02:41:40.641172 24 service_latency.go:356] Created: latency-svc-sdkjf
  I0115 02:41:40.653938 24 service_latency.go:363] Got endpoints: latency-svc-wcrkm [775.088275ms]
  I0115 02:41:40.691830 24 service_latency.go:363] Got endpoints: latency-svc-29z9p [767.112184ms]
  I0115 02:41:40.723945 24 service_latency.go:356] Created: latency-svc-tl6gx
  I0115 02:41:40.737348 24 service_latency.go:363] Got endpoints: latency-svc-jfq7d [761.610867ms]
  I0115 02:41:40.758412 24 service_latency.go:356] Created: latency-svc-sk6nc
  I0115 02:41:40.767837 24 service_latency.go:356] Created: latency-svc-hbr5f
  I0115 02:41:40.777521 24 service_latency.go:363] Got endpoints: latency-svc-w74qg [760.320312ms]
  I0115 02:41:40.796943 24 service_latency.go:356] Created: latency-svc-gth5l
  I0115 02:41:40.815242 24 service_latency.go:363] Got endpoints: latency-svc-jcw4w [747.175574ms]
  I0115 02:41:40.829537 24 service_latency.go:356] Created: latency-svc-zvlp2
  E0115 02:41:40.868800      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:41:40.871017 24 service_latency.go:363] Got endpoints: latency-svc-w5qpd [753.707857ms]
  I0115 02:41:40.887811 24 service_latency.go:356] Created: latency-svc-w26fc
  I0115 02:41:40.918365 24 service_latency.go:363] Got endpoints: latency-svc-kd7pn [749.507264ms]
  I0115 02:41:40.931867 24 service_latency.go:356] Created: latency-svc-h9c9x
  I0115 02:41:40.967788 24 service_latency.go:363] Got endpoints: latency-svc-fbvcn [752.89696ms]
  I0115 02:41:40.979240 24 service_latency.go:356] Created: latency-svc-lhfzq
  I0115 02:41:41.019963 24 service_latency.go:363] Got endpoints: latency-svc-5g674 [751.996801ms]
  I0115 02:41:41.036425 24 service_latency.go:356] Created: latency-svc-r7pvm
  I0115 02:41:41.071383 24 service_latency.go:363] Got endpoints: latency-svc-zvwws [755.953022ms]
  I0115 02:41:41.143224 24 service_latency.go:363] Got endpoints: latency-svc-fvxs2 [774.55075ms]
  I0115 02:41:41.144893 24 service_latency.go:356] Created: latency-svc-vvszb
  I0115 02:41:41.159922 24 service_latency.go:356] Created: latency-svc-qmp7z
  I0115 02:41:41.173273 24 service_latency.go:363] Got endpoints: latency-svc-r9sjb [755.483548ms]
  I0115 02:41:41.201833 24 service_latency.go:356] Created: latency-svc-45tld
  I0115 02:41:41.218600 24 service_latency.go:363] Got endpoints: latency-svc-8hm7p [752.605831ms]
  I0115 02:41:41.291316 24 service_latency.go:363] Got endpoints: latency-svc-xhxf5 [772.03252ms]
  I0115 02:41:41.312520 24 service_latency.go:356] Created: latency-svc-rjtwk
  I0115 02:41:41.335535 24 service_latency.go:363] Got endpoints: latency-svc-sdkjf [753.53966ms]
  I0115 02:41:41.364011 24 service_latency.go:356] Created: latency-svc-sd2bb
  I0115 02:41:41.381256 24 service_latency.go:356] Created: latency-svc-cprpm
  I0115 02:41:41.382384 24 service_latency.go:363] Got endpoints: latency-svc-tl6gx [723.34519ms]
  I0115 02:41:41.403225 24 service_latency.go:356] Created: latency-svc-zzgpf
  I0115 02:41:41.418943 24 service_latency.go:363] Got endpoints: latency-svc-sk6nc [726.992292ms]
  I0115 02:41:41.432942 24 service_latency.go:356] Created: latency-svc-5jt9j
  I0115 02:41:41.466670 24 service_latency.go:363] Got endpoints: latency-svc-hbr5f [729.114421ms]
  I0115 02:41:41.481625 24 service_latency.go:356] Created: latency-svc-kbfz8
  I0115 02:41:41.516437 24 service_latency.go:363] Got endpoints: latency-svc-gth5l [738.800802ms]
  I0115 02:41:41.529819 24 service_latency.go:356] Created: latency-svc-jvlts
  I0115 02:41:41.565169 24 service_latency.go:363] Got endpoints: latency-svc-zvlp2 [749.158164ms]
  I0115 02:41:41.584201 24 service_latency.go:356] Created: latency-svc-lffgs
  I0115 02:41:41.615827 24 service_latency.go:363] Got endpoints: latency-svc-w26fc [744.711324ms]
  I0115 02:41:41.629416 24 service_latency.go:356] Created: latency-svc-fhzjs
  I0115 02:41:41.692819 24 service_latency.go:363] Got endpoints: latency-svc-h9c9x [774.292986ms]
  I0115 02:41:41.719455 24 service_latency.go:356] Created: latency-svc-t9hrx
  I0115 02:41:41.725703 24 service_latency.go:363] Got endpoints: latency-svc-lhfzq [757.787806ms]
  I0115 02:41:41.740840 24 service_latency.go:356] Created: latency-svc-6dm7b
  I0115 02:41:41.785039 24 service_latency.go:363] Got endpoints: latency-svc-r7pvm [764.924722ms]
  I0115 02:41:41.802264 24 service_latency.go:356] Created: latency-svc-srs47
  I0115 02:41:41.812931 24 service_latency.go:363] Got endpoints: latency-svc-vvszb [741.037058ms]
  I0115 02:41:41.828775 24 service_latency.go:356] Created: latency-svc-qbn7x
  I0115 02:41:41.866636 24 service_latency.go:363] Got endpoints: latency-svc-qmp7z [723.318462ms]
  E0115 02:41:41.869691      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:41:41.878871 24 service_latency.go:356] Created: latency-svc-f2h6k
  I0115 02:41:41.914058 24 service_latency.go:363] Got endpoints: latency-svc-45tld [740.684689ms]
  I0115 02:41:41.927465 24 service_latency.go:356] Created: latency-svc-wcknr
  I0115 02:41:41.963170 24 service_latency.go:363] Got endpoints: latency-svc-rjtwk [744.446345ms]
  I0115 02:41:41.976343 24 service_latency.go:356] Created: latency-svc-hrqd5
  I0115 02:41:42.015407 24 service_latency.go:363] Got endpoints: latency-svc-sd2bb [724.001115ms]
  I0115 02:41:42.030940 24 service_latency.go:356] Created: latency-svc-8nmpf
  I0115 02:41:42.063957 24 service_latency.go:363] Got endpoints: latency-svc-cprpm [728.329984ms]
  I0115 02:41:42.076849 24 service_latency.go:356] Created: latency-svc-t4pjs
  I0115 02:41:42.138042 24 service_latency.go:363] Got endpoints: latency-svc-zzgpf [755.470942ms]
  I0115 02:41:42.182551 24 service_latency.go:363] Got endpoints: latency-svc-5jt9j [763.434822ms]
  I0115 02:41:42.188276 24 service_latency.go:356] Created: latency-svc-w7565
  I0115 02:41:42.199724 24 service_latency.go:356] Created: latency-svc-fdlbn
  I0115 02:41:42.216754 24 service_latency.go:363] Got endpoints: latency-svc-kbfz8 [749.987656ms]
  I0115 02:41:42.229541 24 service_latency.go:356] Created: latency-svc-bchx5
  I0115 02:41:42.265912 24 service_latency.go:363] Got endpoints: latency-svc-jvlts [749.300964ms]
  I0115 02:41:42.279393 24 service_latency.go:356] Created: latency-svc-vjgtw
  I0115 02:41:42.377251 24 service_latency.go:363] Got endpoints: latency-svc-lffgs [811.968877ms]
  I0115 02:41:42.384894 24 service_latency.go:363] Got endpoints: latency-svc-fhzjs [768.939829ms]
  I0115 02:41:42.395422 24 service_latency.go:356] Created: latency-svc-9cxmg
  I0115 02:41:42.406581 24 service_latency.go:356] Created: latency-svc-zd8cr
  I0115 02:41:42.417287 24 service_latency.go:363] Got endpoints: latency-svc-t9hrx [724.240991ms]
  I0115 02:41:42.434183 24 service_latency.go:356] Created: latency-svc-xrzv5
  I0115 02:41:42.479905 24 service_latency.go:363] Got endpoints: latency-svc-6dm7b [754.086164ms]
  I0115 02:41:42.529441 24 service_latency.go:356] Created: latency-svc-t9jzx
  I0115 02:41:42.540671 24 service_latency.go:363] Got endpoints: latency-svc-srs47 [755.085349ms]
  I0115 02:41:42.571727 24 service_latency.go:363] Got endpoints: latency-svc-qbn7x [758.653367ms]
  I0115 02:41:42.581079 24 service_latency.go:356] Created: latency-svc-727gq
  I0115 02:41:42.594988 24 service_latency.go:356] Created: latency-svc-7vbqh
  I0115 02:41:42.616562 24 service_latency.go:363] Got endpoints: latency-svc-f2h6k [749.430229ms]
  I0115 02:41:42.629779 24 service_latency.go:356] Created: latency-svc-8k9nx
  I0115 02:41:42.667970 24 service_latency.go:363] Got endpoints: latency-svc-wcknr [753.781228ms]
  I0115 02:41:42.691387 24 service_latency.go:356] Created: latency-svc-7n8xw
  I0115 02:41:42.720099 24 service_latency.go:363] Got endpoints: latency-svc-hrqd5 [756.817274ms]
  I0115 02:41:42.732883 24 service_latency.go:356] Created: latency-svc-46xh8
  I0115 02:41:42.764650 24 service_latency.go:363] Got endpoints: latency-svc-8nmpf [749.064363ms]
  I0115 02:41:42.777022 24 service_latency.go:356] Created: latency-svc-t87q8
  I0115 02:41:42.813746 24 service_latency.go:363] Got endpoints: latency-svc-t4pjs [749.715273ms]
  I0115 02:41:42.826292 24 service_latency.go:356] Created: latency-svc-kp9t7
  I0115 02:41:42.864314 24 service_latency.go:363] Got endpoints: latency-svc-w7565 [726.052963ms]
  E0115 02:41:42.870730      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:41:42.882540 24 service_latency.go:356] Created: latency-svc-phknm
  I0115 02:41:42.914034 24 service_latency.go:363] Got endpoints: latency-svc-fdlbn [730.767181ms]
  I0115 02:41:42.927943 24 service_latency.go:356] Created: latency-svc-7t48d
  I0115 02:41:42.966992 24 service_latency.go:363] Got endpoints: latency-svc-bchx5 [750.126669ms]
  I0115 02:41:42.980080 24 service_latency.go:356] Created: latency-svc-f4zj2
  I0115 02:41:43.014458 24 service_latency.go:363] Got endpoints: latency-svc-vjgtw [748.348547ms]
  I0115 02:41:43.026306 24 service_latency.go:356] Created: latency-svc-jh8nl
  I0115 02:41:43.069916 24 service_latency.go:363] Got endpoints: latency-svc-9cxmg [692.574701ms]
  I0115 02:41:43.124875 24 service_latency.go:356] Created: latency-svc-8zssp
  I0115 02:41:43.136215 24 service_latency.go:363] Got endpoints: latency-svc-zd8cr [751.199984ms]
  I0115 02:41:43.148276 24 service_latency.go:356] Created: latency-svc-tz6zz
  I0115 02:41:43.165792 24 service_latency.go:363] Got endpoints: latency-svc-xrzv5 [748.309412ms]
  I0115 02:41:43.181596 24 service_latency.go:356] Created: latency-svc-wvzbn
  I0115 02:41:43.215406 24 service_latency.go:363] Got endpoints: latency-svc-t9jzx [734.432623ms]
  I0115 02:41:43.225783 24 service_latency.go:356] Created: latency-svc-8tqvl
  I0115 02:41:43.281947 24 service_latency.go:363] Got endpoints: latency-svc-727gq [741.184966ms]
  I0115 02:41:43.322925 24 service_latency.go:356] Created: latency-svc-sktcd
  I0115 02:41:43.333202 24 service_latency.go:363] Got endpoints: latency-svc-7vbqh [761.386492ms]
  I0115 02:41:43.353692 24 service_latency.go:356] Created: latency-svc-phhsx
  I0115 02:41:43.364606 24 service_latency.go:363] Got endpoints: latency-svc-8k9nx [747.954911ms]
  I0115 02:41:43.381449 24 service_latency.go:356] Created: latency-svc-lgk8g
  I0115 02:41:43.414541 24 service_latency.go:363] Got endpoints: latency-svc-7n8xw [746.485988ms]
  I0115 02:41:43.428578 24 service_latency.go:356] Created: latency-svc-7hhqg
  I0115 02:41:43.465646 24 service_latency.go:363] Got endpoints: latency-svc-46xh8 [745.46176ms]
  I0115 02:41:43.476374 24 service_latency.go:356] Created: latency-svc-kkq96
  I0115 02:41:43.513152 24 service_latency.go:363] Got endpoints: latency-svc-t87q8 [748.328806ms]
  I0115 02:41:43.565321 24 service_latency.go:363] Got endpoints: latency-svc-kp9t7 [751.453866ms]
  I0115 02:41:43.641605 24 service_latency.go:363] Got endpoints: latency-svc-phknm [777.210812ms]
  I0115 02:41:43.682943 24 service_latency.go:363] Got endpoints: latency-svc-7t48d [768.770761ms]
  I0115 02:41:43.737733 24 service_latency.go:363] Got endpoints: latency-svc-f4zj2 [770.644528ms]
  I0115 02:41:43.767543 24 service_latency.go:363] Got endpoints: latency-svc-jh8nl [752.960519ms]
  I0115 02:41:43.819695 24 service_latency.go:363] Got endpoints: latency-svc-8zssp [749.484032ms]
  E0115 02:41:43.871359      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:41:43.871481 24 service_latency.go:363] Got endpoints: latency-svc-tz6zz [735.096755ms]
  I0115 02:41:43.921883 24 service_latency.go:363] Got endpoints: latency-svc-wvzbn [756.010541ms]
  I0115 02:41:43.965662 24 service_latency.go:363] Got endpoints: latency-svc-8tqvl [750.069123ms]
  I0115 02:41:44.014898 24 service_latency.go:363] Got endpoints: latency-svc-sktcd [732.589427ms]
  I0115 02:41:44.070191 24 service_latency.go:363] Got endpoints: latency-svc-phhsx [736.715705ms]
  I0115 02:41:44.113811 24 service_latency.go:363] Got endpoints: latency-svc-lgk8g [749.038311ms]
  I0115 02:41:44.165075 24 service_latency.go:363] Got endpoints: latency-svc-7hhqg [750.437079ms]
  I0115 02:41:44.236213 24 service_latency.go:363] Got endpoints: latency-svc-kkq96 [770.401424ms]
  I0115 02:41:44.236456 24 service_latency.go:114] Latencies: [30.775661ms 57.776464ms 74.55682ms 80.990058ms 81.450675ms 82.13917ms 83.271472ms 96.668594ms 97.695015ms 99.047132ms 106.585839ms 109.185573ms 111.071534ms 113.48173ms 121.502684ms 121.610548ms 123.889326ms 137.829432ms 138.239093ms 141.664607ms 143.907875ms 150.545536ms 156.464165ms 161.781637ms 164.701294ms 171.240596ms 172.569757ms 192.865483ms 192.895988ms 205.611575ms 206.657291ms 208.495506ms 222.563443ms 226.831175ms 232.523161ms 265.728882ms 283.239133ms 287.530557ms 288.174829ms 309.253521ms 322.635117ms 323.209372ms 397.084786ms 427.500952ms 440.484333ms 479.884456ms 512.449587ms 541.239859ms 571.556315ms 615.347998ms 640.885642ms 665.972591ms 691.62156ms 692.574701ms 693.156261ms 700.516698ms 700.854867ms 705.941913ms 708.103803ms 708.38656ms 710.226182ms 712.009225ms 712.252664ms 719.650036ms 719.735184ms 720.931307ms 721.929751ms 722.242175ms 723.318462ms 723.34519ms 724.001115ms 724.240991ms 725.492428ms 726.052963ms 726.349492ms 726.992292ms 727.74949ms 728.329984ms 728.557423ms 729.114421ms 729.970292ms 730.767181ms 732.589427ms 733.286416ms 734.33614ms 734.432623ms 734.450326ms 734.55853ms 734.990128ms 735.096755ms 736.715705ms 736.797025ms 736.840928ms 738.800802ms 740.684689ms 741.037058ms 741.184966ms 744.446345ms 744.711324ms 745.46176ms 745.500305ms 745.983851ms 746.177956ms 746.485988ms 746.91161ms 747.044531ms 747.175574ms 747.298381ms 747.371558ms 747.954911ms 747.992269ms 748.248602ms 748.309412ms 748.328806ms 748.348547ms 749.038311ms 749.064363ms 749.158164ms 749.160727ms 749.300964ms 749.430229ms 749.484032ms 749.507264ms 749.589698ms 749.715273ms 749.987656ms 750.069123ms 750.126669ms 750.437079ms 751.131855ms 751.199984ms 751.403128ms 751.453866ms 751.996801ms 752.025108ms 752.401877ms 752.485355ms 752.605831ms 752.67933ms 752.710192ms 752.814542ms 752.89696ms 752.960519ms 753.53966ms 753.707857ms 753.781228ms 753.993473ms 754.086164ms 755.085349ms 755.136244ms 755.470942ms 755.483548ms 755.506947ms 755.953022ms 756.010541ms 756.817274ms 757.16489ms 757.383872ms 757.787806ms 757.844681ms 758.308038ms 758.311889ms 758.653367ms 758.669187ms 758.793296ms 759.80024ms 759.951486ms 760.307533ms 760.320312ms 761.386492ms 761.610867ms 763.434822ms 764.924722ms 765.776841ms 765.885819ms 766.265924ms 767.112184ms 767.726845ms 768.124317ms 768.770761ms 768.939829ms 770.401424ms 770.644528ms 772.03252ms 774.292986ms 774.55075ms 775.088275ms 775.226788ms 775.605166ms 777.210812ms 780.133501ms 784.246807ms 785.19199ms 785.97852ms 786.22651ms 787.077189ms 793.117016ms 794.120832ms 804.16288ms 811.968877ms]
  I0115 02:41:44.236487 24 service_latency.go:118] 50 %ile: 745.500305ms
  I0115 02:41:44.236507 24 service_latency.go:119] 90 %ile: 768.939829ms
  I0115 02:41:44.236525 24 service_latency.go:120] 99 %ile: 804.16288ms
  I0115 02:41:44.236542 24 service_latency.go:121] Total sample count: 200
  I0115 02:41:44.237000 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svc-latency-5706" for this suite. @ 01/15/25 02:41:44.279
• [11.899 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:125
  STEP: Creating a kubernetes client @ 01/15/25 02:41:44.308
  I0115 02:41:44.308710 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename configmap @ 01/15/25 02:41:44.311
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:41:44.36
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:41:44.368
  STEP: Creating configMap with name configmap-test-upd-1f525199-4e6f-4a15-8807-8226724c77d9 @ 01/15/25 02:41:44.385
  STEP: Creating the pod @ 01/15/25 02:41:44.393
  E0115 02:41:44.872431      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:41:45.872798      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Updating configmap configmap-test-upd-1f525199-4e6f-4a15-8807-8226724c77d9 @ 01/15/25 02:41:46.441
  STEP: waiting to observe update in volume @ 01/15/25 02:41:46.448
  E0115 02:41:46.873896      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:41:47.876062      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:41:48.507062 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-4141" for this suite. @ 01/15/25 02:41:48.541
• [4.263 seconds]
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:70
  STEP: Creating a kubernetes client @ 01/15/25 02:41:48.572
  I0115 02:41:48.572126 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename projected @ 01/15/25 02:41:48.573
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:41:48.604
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:41:48.615
  STEP: Creating a pod to test downward API volume plugin @ 01/15/25 02:41:48.626
  E0115 02:41:48.877302      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:41:49.877695      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:41:50.877710      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:41:51.885925      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:41:52.886337      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:41:53.887823      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 02:41:54.833
  I0115 02:41:54.856262 24 output.go:207] Trying to get logs from node 192.168.18.92 pod downwardapi-volume-0af026b2-c163-455e-b618-7bac749722a6 container client-container: <nil>
  E0115 02:41:54.891531      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: delete the pod @ 01/15/25 02:41:54.9
  I0115 02:41:54.947537 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2745" for this suite. @ 01/15/25 02:41:54.958
• [6.412 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should validate against a Deployment [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/validatingadmissionpolicy.go:77
  STEP: Creating a kubernetes client @ 01/15/25 02:41:54.985
  I0115 02:41:54.985244 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename validating-admission-policy @ 01/15/25 02:41:54.987
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:41:55.032
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:41:55.052
  STEP: creating the policy @ 01/15/25 02:41:55.076
  STEP: waiting until the marker is denied @ 01/15/25 02:41:55.195
  E0115 02:41:55.888326      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: testing a replicated Deployment to be allowed @ 01/15/25 02:41:55.905
  STEP: testing a non-replicated ReplicaSet not to be denied @ 01/15/25 02:41:56.018
  I0115 02:41:56.308703 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "validating-admission-policy-3453" for this suite. @ 01/15/25 02:41:56.359
• [1.427 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:108
  STEP: Creating a kubernetes client @ 01/15/25 02:41:56.412
  I0115 02:41:56.412536 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename container-probe @ 01/15/25 02:41:56.418
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:41:56.512
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:41:56.53
  E0115 02:41:56.888745      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:41:57.889294      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:41:58.890877      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:41:59.891084      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:42:00.894049      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:42:01.895123      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:42:02.895346      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:42:03.896480      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:42:04.897716      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:42:05.897652      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:42:06.898201      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:42:07.898991      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:42:08.900505      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:42:09.900440      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:42:10.901996      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:42:11.902282      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:42:12.903883      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:42:13.904088      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:42:14.905121      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:42:15.907030      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:42:16.907748      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:42:17.908422      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:42:18.909886      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:42:19.910114      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:42:20.910470      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:42:21.911778      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:42:22.913131      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:42:23.914831      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:42:24.914754      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:42:25.916308      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:42:26.917405      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:42:27.918695      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:42:28.920148      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:42:29.920251      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:42:30.921056      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:42:31.921658      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:42:32.922942      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:42:33.926749      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:42:34.926725      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:42:35.928560      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:42:36.930291      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:42:37.931344      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:42:38.932714      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:42:39.933012      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:42:40.934019      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:42:41.935173      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:42:42.935731      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:42:43.936947      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:42:44.937395      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:42:45.940074      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:42:46.940896      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:42:47.941554      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:42:48.942746      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:42:49.942922      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:42:50.944241      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:42:51.944938      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:42:52.945565      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:42:53.946563      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:42:54.947029      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:42:55.947627      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:42:56.574940 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-8053" for this suite. @ 01/15/25 02:42:56.582
• [60.177 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets should fail to create secret due to empty secret key [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/secrets.go:142
  STEP: Creating a kubernetes client @ 01/15/25 02:42:56.59
  I0115 02:42:56.590189 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename secrets @ 01/15/25 02:42:56.597
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:42:56.619
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:42:56.626
  STEP: Creating projection with secret that has name secret-emptykey-test-ec776ecc-ea09-4950-8ab7-f884415439f6 @ 01/15/25 02:42:56.632
  I0115 02:42:56.635912 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-4897" for this suite. @ 01/15/25 02:42:56.73
• [0.155 seconds]
------------------------------
[sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:47
  STEP: Creating a kubernetes client @ 01/15/25 02:42:56.745
  I0115 02:42:56.745389 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename secrets @ 01/15/25 02:42:56.746
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:42:56.77
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:42:56.776
  STEP: Creating secret with name secret-test-5495fe8a-218a-4af0-9e02-b5e81d411602 @ 01/15/25 02:42:56.781
  STEP: Creating a pod to test consume secrets @ 01/15/25 02:42:56.788
  E0115 02:42:56.950092      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:42:57.950568      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:42:58.952795      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:42:59.953259      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 02:43:00.829
  I0115 02:43:00.834083 24 output.go:207] Trying to get logs from node 192.168.18.92 pod pod-secrets-64731b92-36e6-46dd-a36b-5f6a8319448a container secret-volume-test: <nil>
  STEP: delete the pod @ 01/15/25 02:43:00.841
  I0115 02:43:00.855279 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-9505" for this suite. @ 01/15/25 02:43:00.859
• [4.122 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Job should apply changes to a job status [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:1008
  STEP: Creating a kubernetes client @ 01/15/25 02:43:00.868
  I0115 02:43:00.868025 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename job @ 01/15/25 02:43:00.868
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:43:00.889
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:43:00.894
  STEP: Creating a job @ 01/15/25 02:43:00.9
  STEP: Ensure pods equal to parallelism count is attached to the job @ 01/15/25 02:43:00.921
  E0115 02:43:00.953631      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:43:01.954735      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: patching /status @ 01/15/25 02:43:02.94
  STEP: updating /status @ 01/15/25 02:43:02.95
  E0115 02:43:02.955812      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: get /status @ 01/15/25 02:43:02.957
  I0115 02:43:02.962117 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-2009" for this suite. @ 01/15/25 02:43:02.966
• [2.104 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:96
  STEP: Creating a kubernetes client @ 01/15/25 02:43:02.972
  I0115 02:43:02.972403 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename var-expansion @ 01/15/25 02:43:02.973
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:43:02.987
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:43:02.992
  STEP: Creating a pod to test substitution in container's args @ 01/15/25 02:43:02.997
  E0115 02:43:03.956505      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:43:04.958064      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:43:05.959015      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:43:06.960025      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 02:43:07.032
  I0115 02:43:07.040929 24 output.go:207] Trying to get logs from node 192.168.18.92 pod var-expansion-fb921e43-7301-42a1-ad1f-78537db4ea24 container dapi-container: <nil>
  STEP: delete the pod @ 01/15/25 02:43:07.055
  I0115 02:43:07.093448 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-8520" for this suite. @ 01/15/25 02:43:07.106
• [4.149 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] AggregatedDiscovery should support raw aggregated discovery endpoint Accept headers [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregated_discovery.go:151
  STEP: Creating a kubernetes client @ 01/15/25 02:43:07.121
  I0115 02:43:07.121706 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename aggregateddiscovery @ 01/15/25 02:43:07.124
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:43:07.147
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:43:07.154
  I0115 02:43:07.171761 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregateddiscovery-5678" for this suite. @ 01/15/25 02:43:07.202
• [0.094 seconds]
------------------------------
[sig-node] Pods should get a host IP [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:205
  STEP: Creating a kubernetes client @ 01/15/25 02:43:07.215
  I0115 02:43:07.215447 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename pods @ 01/15/25 02:43:07.218
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:43:07.247
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:43:07.254
  STEP: creating pod @ 01/15/25 02:43:07.261
  E0115 02:43:07.960767      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:43:08.963391      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:43:09.964194      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:43:10.968342      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:43:11.392962 24 pods.go:83] Pod pod-hostip-35e583e3-fff2-4083-b676-290787fa929b has hostIP: 192.168.18.92
  I0115 02:43:11.393338 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-8162" for this suite. @ 01/15/25 02:43:11.428
• [4.240 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/container_probe.go:135
  STEP: Creating a kubernetes client @ 01/15/25 02:43:11.455
  I0115 02:43:11.456016 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename container-probe @ 01/15/25 02:43:11.46
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:43:11.553
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:43:11.58
  STEP: Creating pod busybox-bdee6120-5c64-432f-925b-4cbef41c68fd in namespace container-probe-4728 @ 01/15/25 02:43:11.596
  E0115 02:43:11.969153      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:43:12.969720      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:43:13.970989      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:43:14.971746      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 01/15/25 02:43:15.651
  I0115 02:43:15.658576 24 container_probe.go:1749] Initial restart count of pod busybox-bdee6120-5c64-432f-925b-4cbef41c68fd is 0
  I0115 02:43:15.665016 24 container_probe.go:1759] Get pod busybox-bdee6120-5c64-432f-925b-4cbef41c68fd in namespace container-probe-4728
  E0115 02:43:15.971827      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:43:16.972129      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:43:17.671865 24 container_probe.go:1759] Get pod busybox-bdee6120-5c64-432f-925b-4cbef41c68fd in namespace container-probe-4728
  E0115 02:43:17.973539      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:43:18.973866      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:43:19.687519 24 container_probe.go:1759] Get pod busybox-bdee6120-5c64-432f-925b-4cbef41c68fd in namespace container-probe-4728
  E0115 02:43:19.975853      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:43:20.977436      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:43:21.694861 24 container_probe.go:1759] Get pod busybox-bdee6120-5c64-432f-925b-4cbef41c68fd in namespace container-probe-4728
  E0115 02:43:21.978056      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:43:22.979321      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:43:23.715107 24 container_probe.go:1759] Get pod busybox-bdee6120-5c64-432f-925b-4cbef41c68fd in namespace container-probe-4728
  E0115 02:43:23.983252      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:43:24.983936      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:43:25.731524 24 container_probe.go:1759] Get pod busybox-bdee6120-5c64-432f-925b-4cbef41c68fd in namespace container-probe-4728
  E0115 02:43:25.986315      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:43:26.987109      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:43:27.744566 24 container_probe.go:1759] Get pod busybox-bdee6120-5c64-432f-925b-4cbef41c68fd in namespace container-probe-4728
  E0115 02:43:27.986979      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:43:28.987310      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:43:29.754617 24 container_probe.go:1759] Get pod busybox-bdee6120-5c64-432f-925b-4cbef41c68fd in namespace container-probe-4728
  E0115 02:43:29.987686      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:43:30.988612      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:43:31.770430 24 container_probe.go:1759] Get pod busybox-bdee6120-5c64-432f-925b-4cbef41c68fd in namespace container-probe-4728
  E0115 02:43:31.994012      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:43:32.998365      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:43:33.804366 24 container_probe.go:1759] Get pod busybox-bdee6120-5c64-432f-925b-4cbef41c68fd in namespace container-probe-4728
  E0115 02:43:34.003943      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:43:35.003832      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:43:35.820502 24 container_probe.go:1759] Get pod busybox-bdee6120-5c64-432f-925b-4cbef41c68fd in namespace container-probe-4728
  E0115 02:43:36.004229      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:43:37.005482      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:43:37.838158 24 container_probe.go:1759] Get pod busybox-bdee6120-5c64-432f-925b-4cbef41c68fd in namespace container-probe-4728
  E0115 02:43:38.006087      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:43:39.007847      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:43:39.844648 24 container_probe.go:1759] Get pod busybox-bdee6120-5c64-432f-925b-4cbef41c68fd in namespace container-probe-4728
  E0115 02:43:40.008795      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:43:41.009243      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:43:41.849442 24 container_probe.go:1759] Get pod busybox-bdee6120-5c64-432f-925b-4cbef41c68fd in namespace container-probe-4728
  E0115 02:43:42.009367      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:43:43.009983      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:43:43.853978 24 container_probe.go:1759] Get pod busybox-bdee6120-5c64-432f-925b-4cbef41c68fd in namespace container-probe-4728
  E0115 02:43:44.010500      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:43:45.011715      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:43:45.866761 24 container_probe.go:1759] Get pod busybox-bdee6120-5c64-432f-925b-4cbef41c68fd in namespace container-probe-4728
  E0115 02:43:46.012896      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:43:47.012826      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:43:47.883492 24 container_probe.go:1759] Get pod busybox-bdee6120-5c64-432f-925b-4cbef41c68fd in namespace container-probe-4728
  E0115 02:43:48.015245      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:43:49.016739      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:43:49.886948 24 container_probe.go:1759] Get pod busybox-bdee6120-5c64-432f-925b-4cbef41c68fd in namespace container-probe-4728
  E0115 02:43:50.016349      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:43:51.016558      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:43:51.891345 24 container_probe.go:1759] Get pod busybox-bdee6120-5c64-432f-925b-4cbef41c68fd in namespace container-probe-4728
  E0115 02:43:52.016634      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:43:53.017747      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:43:53.902196 24 container_probe.go:1759] Get pod busybox-bdee6120-5c64-432f-925b-4cbef41c68fd in namespace container-probe-4728
  E0115 02:43:54.018008      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:43:55.017775      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:43:55.906331 24 container_probe.go:1759] Get pod busybox-bdee6120-5c64-432f-925b-4cbef41c68fd in namespace container-probe-4728
  E0115 02:43:56.017986      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:43:57.018721      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:43:57.911206 24 container_probe.go:1759] Get pod busybox-bdee6120-5c64-432f-925b-4cbef41c68fd in namespace container-probe-4728
  E0115 02:43:58.018784      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:43:59.019718      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:43:59.927775 24 container_probe.go:1759] Get pod busybox-bdee6120-5c64-432f-925b-4cbef41c68fd in namespace container-probe-4728
  E0115 02:44:00.020993      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:44:01.022603      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:44:01.958569 24 container_probe.go:1759] Get pod busybox-bdee6120-5c64-432f-925b-4cbef41c68fd in namespace container-probe-4728
  E0115 02:44:02.026548      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:44:03.025927      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:44:03.963769 24 container_probe.go:1759] Get pod busybox-bdee6120-5c64-432f-925b-4cbef41c68fd in namespace container-probe-4728
  I0115 02:44:03.963860 24 container_probe.go:1763] Restart count of pod container-probe-4728/busybox-bdee6120-5c64-432f-925b-4cbef41c68fd is now 1 (48.305208825s elapsed)
  STEP: deleting the pod @ 01/15/25 02:44:03.963
  I0115 02:44:03.975226 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-4728" for this suite. @ 01/15/25 02:44:03.981
• [52.533 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should serve endpoints on same port and different protocols [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:3683
  STEP: Creating a kubernetes client @ 01/15/25 02:44:03.989
  I0115 02:44:03.989289 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename services @ 01/15/25 02:44:03.99
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:44:04.009
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:44:04.015
  STEP: creating service multiprotocol-test in namespace services-7130 @ 01/15/25 02:44:04.02
  E0115 02:44:04.027753      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: creating pod pod1 in namespace services-7130 @ 01/15/25 02:44:04.037
  STEP: Creating pod pod1 in namespace services-7130 @ 01/15/25 02:44:04.037
  E0115 02:44:05.028220      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:44:06.028411      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service multiprotocol-test in namespace services-7130 to expose endpoints map[pod1:[{tcp-port 0 80 TCP } {udp-port 0 80 UDP }]] @ 01/15/25 02:44:06.072
  I0115 02:44:06.088604 24 service.go:4553] successfully validated that service multiprotocol-test in namespace services-7130 exposes endpoints map[pod1:[{tcp-port 0 80 TCP } {udp-port 0 80 UDP }]]
  STEP: Checking if the Service forwards traffic to the TCP and UDP port @ 01/15/25 02:44:06.088
  I0115 02:44:06.088769 24 resource.go:361] Creating new exec pod
  E0115 02:44:07.037466      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:44:08.038252      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:44:09.072966      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:44:10.079388      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:44:10.146909 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-7130 exec execpods7ljm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 169.169.238.26 80'
  I0115 02:44:10.963076 24 builder.go:146] stderr: "+ + nc -v -t -w 2 169.169.238.26 80\necho hostName\nConnection to 169.169.238.26 80 port [tcp/http] succeeded!\n"
  I0115 02:44:10.963184 24 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0115 02:44:10.963338 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-7130 exec execpods7ljm -- /bin/sh -x -c echo hostName | nc -v -u -w 2 169.169.238.26 80'
  E0115 02:44:11.079410      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:44:12.080348      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:44:13.082905      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:44:13.340345 24 builder.go:146] stderr: "+ echo+ nc -v -u -w 2 169.169.238.26 80\n hostName\n"
  I0115 02:44:13.340504 24 builder.go:147] stdout: "pod1"
  STEP: Checking if the Service forwards traffic to TCP only @ 01/15/25 02:44:13.34
  I0115 02:44:13.405970 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-7130 exec execpods7ljm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 169.169.238.26 80'
  I0115 02:44:13.647973 24 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 169.169.238.26 80\nConnection to 169.169.238.26 80 port [tcp/http] succeeded!\n"
  I0115 02:44:13.648074 24 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0115 02:44:13.648210 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-7130 exec execpods7ljm -- /bin/sh -x -c echo hostName | nc -v -u -w 2 169.169.238.26 80'
  E0115 02:44:14.082976      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:44:15.082971      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:44:15.884383 24 builder.go:146] stderr: "+ echo hostName\n+ nc -v -u -w 2 169.169.238.26 80\n"
  I0115 02:44:15.884505 24 builder.go:147] stdout: ""
  I0115 02:44:15.884680 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-7130 exec execpods7ljm -- /bin/sh -x -c echo hostName | nc -v -u -w 2 169.169.238.26 80'
  E0115 02:44:16.083589      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:44:17.084926      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:44:18.086346      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:44:18.233832 24 builder.go:146] stderr: "+ nc -v -u -w 2 169.169.238.26 80\n+ echo hostName\n"
  I0115 02:44:18.233968 24 builder.go:147] stdout: ""
  I0115 02:44:18.234090 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-7130 exec execpods7ljm -- /bin/sh -x -c echo hostName | nc -v -u -w 2 169.169.238.26 80'
  E0115 02:44:19.086874      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:44:20.087563      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:44:20.488583 24 builder.go:146] stderr: "+ echo hostName\n+ nc -v -u -w 2 169.169.238.26 80\n"
  I0115 02:44:20.488656 24 builder.go:147] stdout: ""
  STEP: Checking if the Service forwards traffic to UDP only @ 01/15/25 02:44:20.488
  I0115 02:44:20.505736 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-7130 exec execpods7ljm -- /bin/sh -x -c echo hostName | nc -v -u -w 2 169.169.238.26 80'
  E0115 02:44:21.087917      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:44:22.089343      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:44:22.739523 24 builder.go:146] stderr: "+ echo hostName\n+ nc -v -u -w 2 169.169.238.26 80\n"
  I0115 02:44:22.739608 24 builder.go:147] stdout: "pod1"
  I0115 02:44:22.739710 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-7130 exec execpods7ljm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 169.169.238.26 80'
  E0115 02:44:23.091348      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:44:24.092120      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:44:24.949671 24 builder.go:135] rc: 1
  I0115 02:44:24.950041 24 util.go:239] Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-7130 exec execpods7ljm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 169.169.238.26 80:
  Command stdout:

  stderr:
  + nc -v -t -w 2 169.169.238.26 80
  + echo hostName
  nc: connect to 169.169.238.26 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  I0115 02:44:24.950317 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-7130 exec execpods7ljm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 169.169.238.26 80'
  E0115 02:44:25.092173      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:44:26.093073      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:44:27.094263      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:44:27.209086 24 builder.go:135] rc: 1
  I0115 02:44:27.209176 24 util.go:239] Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-7130 exec execpods7ljm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 169.169.238.26 80:
  Command stdout:

  stderr:
  + echo hostName
  + nc -v -t -w 2 169.169.238.26 80
  nc: connect to 169.169.238.26 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  I0115 02:44:27.209278 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-7130 exec execpods7ljm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 169.169.238.26 80'
  E0115 02:44:28.095035      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:44:29.095864      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:44:29.410993 24 builder.go:135] rc: 1
  I0115 02:44:29.412411 24 util.go:239] Service reachability failing with error: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-7130 exec execpods7ljm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 169.169.238.26 80:
  Command stdout:

  stderr:
  + + nc -v -techo -w 2 hostName 169.169.238.26
   80
  nc: connect to 169.169.238.26 port 80 (tcp) timed out: Operation in progress
  command terminated with exit code 1

  error:
  exit status 1
  Retrying...
  I0115 02:44:29.412623 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-7130" for this suite. @ 01/15/25 02:44:29.422
• [25.443 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:385
  STEP: Creating a kubernetes client @ 01/15/25 02:44:29.432
  I0115 02:44:29.432346 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename daemonsets @ 01/15/25 02:44:29.433
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:44:29.462
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:44:29.473
  I0115 02:44:29.525606 24 daemon_set.go:388] Creating simple daemon set daemon-set
  STEP: Check that daemon pods launch on every node of the cluster. @ 01/15/25 02:44:29.531
  I0115 02:44:29.622094 24 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0115 02:44:29.622164 24 fixtures.go:131] Node 192.168.18.91 is running 0 daemon pod, expected 1
  E0115 02:44:30.096600      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:44:30.590133 24 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0115 02:44:30.590184 24 fixtures.go:131] Node 192.168.18.91 is running 0 daemon pod, expected 1
  E0115 02:44:31.098224      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:44:31.561338 24 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0115 02:44:31.561471 24 fixtures.go:136] Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Update daemon pods image. @ 01/15/25 02:44:31.618
  STEP: Check that daemon pods images are updated. @ 01/15/25 02:44:31.648
  I0115 02:44:31.659691 24 daemon_set.go:1193] Wrong image for pod: daemon-set-s4knf. Expected: registry.k8s.io/e2e-test-images/agnhost:2.53, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  I0115 02:44:31.659794 24 daemon_set.go:1193] Wrong image for pod: daemon-set-z8cgn. Expected: registry.k8s.io/e2e-test-images/agnhost:2.53, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  E0115 02:44:32.098888      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:44:32.669669 24 daemon_set.go:1193] Wrong image for pod: daemon-set-s4knf. Expected: registry.k8s.io/e2e-test-images/agnhost:2.53, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  E0115 02:44:33.100156      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:44:33.667570 24 daemon_set.go:1198] Pod daemon-set-nv8bm is not available
  I0115 02:44:33.667632 24 daemon_set.go:1193] Wrong image for pod: daemon-set-s4knf. Expected: registry.k8s.io/e2e-test-images/agnhost:2.53, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  E0115 02:44:34.101349      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:44:34.751730 24 daemon_set.go:1198] Pod daemon-set-nv8bm is not available
  I0115 02:44:34.751802 24 daemon_set.go:1193] Wrong image for pod: daemon-set-s4knf. Expected: registry.k8s.io/e2e-test-images/agnhost:2.53, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  E0115 02:44:35.104594      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:44:35.656928 24 daemon_set.go:1198] Pod daemon-set-rjgcs is not available
  STEP: Check that daemon pods are still running on every node of the cluster. @ 01/15/25 02:44:35.671
  I0115 02:44:35.693700 24 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0115 02:44:35.693810 24 fixtures.go:131] Node 192.168.18.92 is running 0 daemon pod, expected 1
  E0115 02:44:36.104870      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:44:36.786574 24 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0115 02:44:36.786665 24 fixtures.go:131] Node 192.168.18.92 is running 0 daemon pod, expected 1
  E0115 02:44:37.105309      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:44:37.693393 24 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0115 02:44:37.693554 24 fixtures.go:131] Node 192.168.18.92 is running 0 daemon pod, expected 1
  E0115 02:44:38.105552      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:44:38.739893 24 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0115 02:44:38.739958 24 fixtures.go:136] Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 01/15/25 02:44:38.796
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4544, will wait for the garbage collector to delete the pods @ 01/15/25 02:44:38.797
  I0115 02:44:38.862078 24 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 7.45835ms
  I0115 02:44:38.962534 24 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 100.453163ms
  E0115 02:44:39.105610      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:44:40.105674      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:44:41.070955 24 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0115 02:44:41.071071 24 fixtures.go:136] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0115 02:44:41.077551 24 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"182693"},"items":null}

  I0115 02:44:41.083143 24 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"182693"},"items":null}

  E0115 02:44:41.106156      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:44:41.109101 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-4544" for this suite. @ 01/15/25 02:44:41.118
• [11.695 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:90
  STEP: Creating a kubernetes client @ 01/15/25 02:44:41.128
  I0115 02:44:41.128379 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename emptydir @ 01/15/25 02:44:41.13
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:44:41.16
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:44:41.173
  STEP: Creating a pod to test emptydir volume type on tmpfs @ 01/15/25 02:44:41.181
  E0115 02:44:42.106805      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:44:43.108040      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:44:44.109729      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:44:45.110845      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 02:44:45.227
  I0115 02:44:45.244848 24 output.go:207] Trying to get logs from node 192.168.18.92 pod pod-ae28a5a5-611f-4d04-81ad-5b06ab07041b container test-container: <nil>
  STEP: delete the pod @ 01/15/25 02:44:45.316
  I0115 02:44:45.336242 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-733" for this suite. @ 01/15/25 02:44:45.343
• [4.222 seconds]
------------------------------
SSSS
------------------------------
[sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:356
  STEP: Creating a kubernetes client @ 01/15/25 02:44:45.35
  I0115 02:44:45.350044 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename endpointslice @ 01/15/25 02:44:45.351
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:44:45.369
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:44:45.375
  STEP: getting /apis @ 01/15/25 02:44:45.386
  STEP: getting /apis/discovery.k8s.io @ 01/15/25 02:44:45.426
  STEP: getting /apis/discovery.k8s.iov1 @ 01/15/25 02:44:45.431
  STEP: creating @ 01/15/25 02:44:45.44
  STEP: getting @ 01/15/25 02:44:45.483
  STEP: listing @ 01/15/25 02:44:45.493
  STEP: watching @ 01/15/25 02:44:45.501
  I0115 02:44:45.501229 24 endpointslice.go:447] starting watch
  STEP: cluster-wide listing @ 01/15/25 02:44:45.505
  STEP: cluster-wide watching @ 01/15/25 02:44:45.512
  I0115 02:44:45.512557 24 endpointslice.go:459] starting watch
  STEP: patching @ 01/15/25 02:44:45.515
  STEP: updating @ 01/15/25 02:44:45.523
  I0115 02:44:45.537891 24 endpointslice.go:482] waiting for watch events with expected annotations
  I0115 02:44:45.537976 24 endpointslice.go:495] saw patched and updated annotations
  STEP: deleting @ 01/15/25 02:44:45.538
  STEP: deleting a collection @ 01/15/25 02:44:45.555
  I0115 02:44:45.572402 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-3604" for this suite. @ 01/15/25 02:44:45.578
• [0.236 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application should create and stop a working application [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:393
  STEP: Creating a kubernetes client @ 01/15/25 02:44:45.586
  I0115 02:44:45.586152 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename kubectl @ 01/15/25 02:44:45.587
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:44:45.609
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:44:45.618
  STEP: creating all guestbook components @ 01/15/25 02:44:45.624
  I0115 02:44:45.624477 24 kubectl.go:399] apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-replica
    labels:
      app: agnhost
      role: replica
      tier: backend
  spec:
    ports:
    - port: 6379
    selector:
      app: agnhost
      role: replica
      tier: backend

  I0115 02:44:45.624606 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-6104 create -f -'
  I0115 02:44:45.888328 24 builder.go:146] stderr: ""
  I0115 02:44:45.888400 24 builder.go:147] stdout: "service/agnhost-replica created\n"
  I0115 02:44:45.888486 24 kubectl.go:399] apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-primary
    labels:
      app: agnhost
      role: primary
      tier: backend
  spec:
    ports:
    - port: 6379
      targetPort: 6379
    selector:
      app: agnhost
      role: primary
      tier: backend

  I0115 02:44:45.888608 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-6104 create -f -'
  E0115 02:44:46.112761      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:44:46.204603 24 builder.go:146] stderr: ""
  I0115 02:44:46.204689 24 builder.go:147] stdout: "service/agnhost-primary created\n"
  I0115 02:44:46.204760 24 kubectl.go:399] apiVersion: v1
  kind: Service
  metadata:
    name: frontend
    labels:
      app: guestbook
      tier: frontend
  spec:
    # if your cluster supports it, uncomment the following to automatically create
    # an external load-balanced IP for the frontend service.
    # type: LoadBalancer
    ports:
    - port: 80
    selector:
      app: guestbook
      tier: frontend

  I0115 02:44:46.204869 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-6104 create -f -'
  I0115 02:44:46.524446 24 builder.go:146] stderr: ""
  I0115 02:44:46.524563 24 builder.go:147] stdout: "service/frontend created\n"
  I0115 02:44:46.525769 24 kubectl.go:399] apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: frontend
  spec:
    replicas: 3
    selector:
      matchLabels:
        app: guestbook
        tier: frontend
    template:
      metadata:
        labels:
          app: guestbook
          tier: frontend
      spec:
        containers:
        - name: guestbook-frontend
          image: registry.k8s.io/e2e-test-images/agnhost:2.53
          args: [ "guestbook", "--backend-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 80

  I0115 02:44:46.526062 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-6104 create -f -'
  I0115 02:44:46.907669 24 builder.go:146] stderr: ""
  I0115 02:44:46.907777 24 builder.go:147] stdout: "deployment.apps/frontend created\n"
  I0115 02:44:46.907968 24 kubectl.go:399] apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-primary
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: agnhost
        role: primary
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: primary
          tier: backend
      spec:
        containers:
        - name: primary
          image: registry.k8s.io/e2e-test-images/agnhost:2.53
          args: [ "guestbook", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  I0115 02:44:46.908182 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-6104 create -f -'
  E0115 02:44:47.115375      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:44:47.266827 24 builder.go:146] stderr: ""
  I0115 02:44:47.266913 24 builder.go:147] stdout: "deployment.apps/agnhost-primary created\n"
  I0115 02:44:47.267057 24 kubectl.go:399] apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-replica
  spec:
    replicas: 2
    selector:
      matchLabels:
        app: agnhost
        role: replica
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: replica
          tier: backend
      spec:
        containers:
        - name: replica
          image: registry.k8s.io/e2e-test-images/agnhost:2.53
          args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  I0115 02:44:47.267261 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-6104 create -f -'
  I0115 02:44:47.714141 24 builder.go:146] stderr: ""
  I0115 02:44:47.714235 24 builder.go:147] stdout: "deployment.apps/agnhost-replica created\n"
  STEP: validating guestbook app @ 01/15/25 02:44:47.714
  I0115 02:44:47.714474 24 kubectl.go:2269] Waiting for all frontend pods to be Running.
  E0115 02:44:48.119328      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:44:49.122214      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:44:50.123828      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:44:51.124404      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:44:52.130317      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:44:52.765899 24 kubectl.go:2273] Waiting for frontend to serve content.
  I0115 02:44:52.836573 24 kubectl.go:2278] Trying to add a new entry to the guestbook.
  I0115 02:44:52.914699 24 kubectl.go:2283] Verifying that added entry can be retrieved.
  STEP: using delete to clean up resources @ 01/15/25 02:44:52.956
  I0115 02:44:52.958895 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-6104 delete --grace-period=0 --force -f -'
  E0115 02:44:53.134082      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:44:53.369448 24 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0115 02:44:53.369547 24 builder.go:147] stdout: "service \"agnhost-replica\" force deleted\n"
  STEP: using delete to clean up resources @ 01/15/25 02:44:53.369
  I0115 02:44:53.369750 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-6104 delete --grace-period=0 --force -f -'
  I0115 02:44:53.992178 24 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0115 02:44:53.992275 24 builder.go:147] stdout: "service \"agnhost-primary\" force deleted\n"
  STEP: using delete to clean up resources @ 01/15/25 02:44:53.992
  I0115 02:44:53.992503 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-6104 delete --grace-period=0 --force -f -'
  E0115 02:44:54.133784      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:44:54.769973 24 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0115 02:44:54.770074 24 builder.go:147] stdout: "service \"frontend\" force deleted\n"
  STEP: using delete to clean up resources @ 01/15/25 02:44:54.77
  I0115 02:44:54.770695 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-6104 delete --grace-period=0 --force -f -'
  I0115 02:44:55.098901 24 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0115 02:44:55.098996 24 builder.go:147] stdout: "deployment.apps \"frontend\" force deleted\n"
  STEP: using delete to clean up resources @ 01/15/25 02:44:55.099
  I0115 02:44:55.099363 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-6104 delete --grace-period=0 --force -f -'
  E0115 02:44:55.134368      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:44:56.101875 24 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0115 02:44:56.101961 24 builder.go:147] stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
  STEP: using delete to clean up resources @ 01/15/25 02:44:56.102
  I0115 02:44:56.102559 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-6104 delete --grace-period=0 --force -f -'
  E0115 02:44:56.140643      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:44:57.100159 24 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0115 02:44:57.100847 24 builder.go:147] stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
  I0115 02:44:57.101109 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-6104" for this suite. @ 01/15/25 02:44:57.126
  E0115 02:44:57.147039      24 retrywatcher.go:160] "Watch failed" err="context canceled"
• [11.574 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:1037
  STEP: Creating a kubernetes client @ 01/15/25 02:44:57.161
  I0115 02:44:57.162861 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename statefulset @ 01/15/25 02:44:57.204
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:44:57.368
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:44:57.389
  STEP: Creating service test in namespace statefulset-3618 @ 01/15/25 02:44:57.425
  STEP: Creating statefulset ss in namespace statefulset-3618 @ 01/15/25 02:44:57.554
  I0115 02:44:57.858096 24 wait.go:40] Found 0 stateful pods, waiting for 1
  E0115 02:44:58.148711      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:44:59.156488      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:45:00.156973      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:45:01.159144      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:45:02.160206      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:45:03.161497      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:45:04.162799      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:45:05.162919      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:45:06.163911      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:45:07.164696      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:45:07.845183 24 wait.go:50] Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Patch Statefulset to include a label @ 01/15/25 02:45:07.875
  STEP: Getting /status @ 01/15/25 02:45:07.902
  I0115 02:45:07.913711 24 statefulset.go:1073] StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
  STEP: updating the StatefulSet Status @ 01/15/25 02:45:07.914
  I0115 02:45:07.953785 24 statefulset.go:1093] updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the statefulset status to be updated @ 01/15/25 02:45:07.953
  I0115 02:45:07.970487 24 statefulset.go:1121] Observed &StatefulSet event: ADDED
  I0115 02:45:07.974548 24 statefulset.go:1114] Found Statefulset ss in namespace statefulset-3618 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  I0115 02:45:07.974698 24 statefulset.go:1125] Statefulset ss has an updated status
  STEP: patching the Statefulset Status @ 01/15/25 02:45:07.975
  I0115 02:45:07.976043 24 statefulset.go:1129] Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  I0115 02:45:08.017629 24 statefulset.go:1133] Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Statefulset status to be patched @ 01/15/25 02:45:08.018
  I0115 02:45:08.029252 24 statefulset.go:1158] Observed &StatefulSet event: ADDED
  I0115 02:45:08.029536 24 statefulset.go:138] Deleting all statefulset in ns statefulset-3618
  I0115 02:45:08.049206 24 rest.go:152] Scaling statefulset ss to 0
  E0115 02:45:08.165087      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:45:09.202563      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:45:10.218614      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:45:11.226067      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:45:12.225231      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:45:13.226547      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:45:14.231475      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:45:15.234515      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:45:16.235167      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:45:17.235351      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:45:18.121091 24 wait.go:151] Waiting for statefulset status.replicas updated to 0
  I0115 02:45:18.153908 24 rest.go:90] Deleting statefulset ss
  E0115 02:45:18.237209      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:45:18.267795 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-3618" for this suite. @ 01/15/25 02:45:18.289
• [21.253 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:86
  STEP: Creating a kubernetes client @ 01/15/25 02:45:18.421
  I0115 02:45:18.421976 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename projected @ 01/15/25 02:45:18.427
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:45:18.778
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:45:18.795
  STEP: Creating a pod to test downward API volume plugin @ 01/15/25 02:45:18.817
  E0115 02:45:19.243669      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:45:20.291166      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:45:21.339460      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:45:22.339921      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:45:23.340734      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:45:24.342207      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:45:25.343704      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:45:26.344837      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 02:45:26.998
  I0115 02:45:27.027842 24 output.go:207] Trying to get logs from node 192.168.18.92 pod downwardapi-volume-54013be4-66e6-4254-bdac-e8091b97aea4 container client-container: <nil>
  STEP: delete the pod @ 01/15/25 02:45:27.052
  I0115 02:45:27.100067 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9583" for this suite. @ 01/15/25 02:45:27.119
• [8.796 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:75
  STEP: Creating a kubernetes client @ 01/15/25 02:45:27.224
  I0115 02:45:27.224748 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename projected @ 01/15/25 02:45:27.248
  E0115 02:45:27.347615      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:45:27.349
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:45:27.369
  STEP: Creating configMap with name projected-configmap-test-volume-a2977e85-915b-4969-9299-76bcb716c79b @ 01/15/25 02:45:27.411
  STEP: Creating a pod to test consume configMaps @ 01/15/25 02:45:27.436
  E0115 02:45:28.350088      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:45:29.351948      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:45:30.353144      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:45:31.406829      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:45:32.407079      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:45:33.408728      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:45:34.409234      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:45:35.446033      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 02:45:35.798
  I0115 02:45:35.812904 24 output.go:207] Trying to get logs from node 192.168.18.92 pod pod-projected-configmaps-2c3c4462-5c69-433b-9b80-8ab4421eec98 container agnhost-container: <nil>
  STEP: delete the pod @ 01/15/25 02:45:35.837
  I0115 02:45:35.884312 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4873" for this suite. @ 01/15/25 02:45:35.919
• [8.721 seconds]
------------------------------
SSS
------------------------------
[sig-storage] VolumeAttachment Conformance should run through the lifecycle of a VolumeAttachment [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/volume_attachment.go:59
  STEP: Creating a kubernetes client @ 01/15/25 02:45:35.945
  I0115 02:45:35.946001 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename volumeattachment @ 01/15/25 02:45:35.956
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:45:36.015
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:45:36.039
  STEP: Create VolumeAttachment "va-e2e-9ndvj" on node "192.168.18.92" @ 01/15/25 02:45:36.07
  STEP: Get VolumeAttachment "va-e2e-9ndvj" on node "192.168.18.92" @ 01/15/25 02:45:36.089
  STEP: Patch VolumeAttachment "va-e2e-9ndvj" on node "192.168.18.92" @ 01/15/25 02:45:36.104
  STEP: List VolumeAttachments with "va-e2e-9ndvj=patched" label @ 01/15/25 02:45:36.128
  STEP: Delete VolumeAttachment "va-e2e-9ndvj" on node "192.168.18.92" @ 01/15/25 02:45:36.164
  STEP: Confirm deletion of VolumeAttachment "va-e2e-9ndvj" on node "192.168.18.92" @ 01/15/25 02:45:36.262
  STEP: Create VolumeAttachment "va-e2e-dgh7g" on node "192.168.18.92" @ 01/15/25 02:45:36.387
  STEP: Update the VolumeAttachment "va-e2e-dgh7g" on node "192.168.18.92" with label "va-e2e=updated" @ 01/15/25 02:45:36.429
  E0115 02:45:36.448136      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Create VolumeAttachment "va-e2e-gn9s9" on node "192.168.18.91" @ 01/15/25 02:45:36.535
  STEP: Update the VolumeAttachment "va-e2e-gn9s9" on node "192.168.18.91" with label "va-e2e=updated" @ 01/15/25 02:45:36.586
  STEP: DeleteCollection of VolumeAttachments with "va-e2e=updated" label @ 01/15/25 02:45:36.69
  STEP: Confirm deleteCollection of VolumeAttachments with "va-e2e=updated" label @ 01/15/25 02:45:36.823
  I0115 02:45:36.841600 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "volumeattachment-6852" for this suite. @ 01/15/25 02:45:36.865
• [0.950 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields in both the root and embedded object of a CR [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/field_validation.go:472
  STEP: Creating a kubernetes client @ 01/15/25 02:45:36.895
  I0115 02:45:36.896120 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename field-validation @ 01/15/25 02:45:36.899
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:45:36.958
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:45:36.976
  I0115 02:45:36.996569 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  E0115 02:45:37.447260      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:45:38.448016      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:45:39.448905      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  W0115 02:45:39.702856      24 warnings.go:70] unknown field "alpha"
  W0115 02:45:39.702975      24 warnings.go:70] unknown field "beta"
  W0115 02:45:39.702994      24 warnings.go:70] unknown field "delta"
  W0115 02:45:39.703005      24 warnings.go:70] unknown field "epsilon"
  W0115 02:45:39.703015      24 warnings.go:70] unknown field "gamma"
  I0115 02:45:40.367698 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-109" for this suite. @ 01/15/25 02:45:40.38
• [3.506 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:164
  STEP: Creating a kubernetes client @ 01/15/25 02:45:40.406
  I0115 02:45:40.408071 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename downward-api @ 01/15/25 02:45:40.41
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:45:40.447
  E0115 02:45:40.448955      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:45:40.463
  STEP: Creating the pod @ 01/15/25 02:45:40.478
  E0115 02:45:41.449950      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:45:42.451716      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:45:43.453781      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:45:44.454786      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:45:45.406323 24 pod_client.go:173] Successfully updated pod "annotationupdate467fafbe-6a23-4e9d-aeb7-453495a2372b"
  E0115 02:45:45.456484      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:45:46.456987      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:45:47.457707      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:45:47.510303 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-5573" for this suite. @ 01/15/25 02:45:47.526
• [7.140 seconds]
------------------------------
SSS
------------------------------
[sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance] [sig-node, Conformance]
k8s.io/kubernetes/test/e2e/common/node/configmap.go:140
  STEP: Creating a kubernetes client @ 01/15/25 02:45:47.545
  I0115 02:45:47.545821 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename configmap @ 01/15/25 02:45:47.548
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:45:47.599
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:45:47.618
  STEP: Creating configMap that has name configmap-test-emptyKey-2a012cfb-a290-4129-8d57-e2953010f317 @ 01/15/25 02:45:47.631
  I0115 02:45:47.642203 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-6196" for this suite. @ 01/15/25 02:45:47.673
• [0.155 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/daemon_set.go:305
  STEP: Creating a kubernetes client @ 01/15/25 02:45:47.703
  I0115 02:45:47.703243 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename daemonsets @ 01/15/25 02:45:47.705
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:45:47.744
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:45:47.771
  STEP: Creating a simple DaemonSet "daemon-set" @ 01/15/25 02:45:47.869
  STEP: Check that daemon pods launch on every node of the cluster. @ 01/15/25 02:45:47.891
  I0115 02:45:47.967906 24 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0115 02:45:47.968006 24 fixtures.go:131] Node 192.168.18.91 is running 0 daemon pod, expected 1
  E0115 02:45:48.458777      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:45:48.922926 24 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0115 02:45:48.923077 24 fixtures.go:131] Node 192.168.18.91 is running 0 daemon pod, expected 1
  E0115 02:45:49.461264      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:45:49.943202 24 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0115 02:45:49.943296 24 fixtures.go:131] Node 192.168.18.91 is running 0 daemon pod, expected 1
  E0115 02:45:50.462018      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:45:50.927341 24 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0115 02:45:50.927443 24 fixtures.go:131] Node 192.168.18.91 is running 0 daemon pod, expected 1
  E0115 02:45:51.463028      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:45:51.978193 24 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0115 02:45:51.978283 24 fixtures.go:131] Node 192.168.18.92 is running 0 daemon pod, expected 1
  E0115 02:45:52.474319      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:45:52.929629 24 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0115 02:45:52.929784 24 fixtures.go:136] Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. @ 01/15/25 02:45:52.945
  I0115 02:45:53.107848 24 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0115 02:45:53.107931 24 fixtures.go:131] Node 192.168.18.91 is running 0 daemon pod, expected 1
  E0115 02:45:53.464740      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:45:54.045794 24 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0115 02:45:54.045968 24 fixtures.go:131] Node 192.168.18.91 is running 0 daemon pod, expected 1
  E0115 02:45:54.465061      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:45:55.048240 24 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0115 02:45:55.048413 24 fixtures.go:131] Node 192.168.18.91 is running 0 daemon pod, expected 1
  E0115 02:45:55.466207      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:45:56.042772 24 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0115 02:45:56.043232 24 fixtures.go:131] Node 192.168.18.91 is running 0 daemon pod, expected 1
  E0115 02:45:56.483045      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:45:57.060493 24 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 1
  I0115 02:45:57.060629 24 fixtures.go:131] Node 192.168.18.91 is running 0 daemon pod, expected 1
  E0115 02:45:57.484946      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:45:58.023957 24 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 2
  I0115 02:45:58.024104 24 fixtures.go:136] Number of running nodes: 2, number of available pods: 2 in daemonset daemon-set
  STEP: Wait for the failed daemon pod to be completely deleted. @ 01/15/25 02:45:58.024
  STEP: Deleting DaemonSet "daemon-set" @ 01/15/25 02:45:58.06
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9560, will wait for the garbage collector to delete the pods @ 01/15/25 02:45:58.06
  I0115 02:45:58.141284 24 resources.go:139] Deleting DaemonSet.extensions daemon-set took: 15.060436ms
  I0115 02:45:58.260643 24 resources.go:163] Terminating DaemonSet.extensions daemon-set pods took: 119.356078ms
  E0115 02:45:58.486341      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:45:59.496773      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:46:00.498000      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:46:01.499219      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:46:02.500582      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:46:03.169797 24 fixtures.go:126] Number of nodes with available pods controlled by daemonset daemon-set: 0
  I0115 02:46:03.169946 24 fixtures.go:136] Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  I0115 02:46:03.180677 24 daemon_set.go:135] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"183424"},"items":null}

  I0115 02:46:03.192620 24 daemon_set.go:140] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"183424"},"items":null}

  I0115 02:46:03.257100 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-9560" for this suite. @ 01/15/25 02:46:03.28
• [15.597 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:454
  STEP: Creating a kubernetes client @ 01/15/25 02:46:03.303
  I0115 02:46:03.303886 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename resourcequota @ 01/15/25 02:46:03.309
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:46:03.37
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:46:03.39
  STEP: Counting existing ResourceQuota @ 01/15/25 02:46:03.414
  E0115 02:46:03.503808      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:46:04.504690      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:46:05.506251      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:46:06.506214      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:46:07.510694      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 01/15/25 02:46:08.422
  STEP: Ensuring resource quota status is calculated @ 01/15/25 02:46:08.442
  E0115 02:46:08.510570      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:46:09.518151      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Creating a ReplicaSet @ 01/15/25 02:46:10.462
  STEP: Ensuring resource quota status captures replicaset creation @ 01/15/25 02:46:10.499
  E0115 02:46:10.517073      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:46:11.522316      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Deleting a ReplicaSet @ 01/15/25 02:46:12.516
  E0115 02:46:12.518497      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota status released usage @ 01/15/25 02:46:12.536
  E0115 02:46:13.518991      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:46:14.520100      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:46:14.557428 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-8034" for this suite. @ 01/15/25 02:46:14.605
• [11.361 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:135
  STEP: Creating a kubernetes client @ 01/15/25 02:46:14.67
  I0115 02:46:14.670614 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename kubelet-test @ 01/15/25 02:46:14.681
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:46:14.742
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:46:14.752
  I0115 02:46:14.816927 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-8255" for this suite. @ 01/15/25 02:46:14.828
• [0.182 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/downwardapi_volume.go:223
  STEP: Creating a kubernetes client @ 01/15/25 02:46:14.848
  I0115 02:46:14.848966 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename downward-api @ 01/15/25 02:46:14.851
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:46:14.879
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:46:14.889
  STEP: Creating a pod to test downward API volume plugin @ 01/15/25 02:46:14.899
  E0115 02:46:15.521601      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:46:16.522442      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:46:17.526323      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:46:18.526907      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 02:46:18.949
  I0115 02:46:18.954396 24 output.go:207] Trying to get logs from node 192.168.18.92 pod downwardapi-volume-995c2bb3-9e50-4e70-ad80-dbed2140bac8 container client-container: <nil>
  STEP: delete the pod @ 01/15/25 02:46:18.964
  I0115 02:46:18.986575 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-943" for this suite. @ 01/15/25 02:46:18.996
• [4.156 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should allow expressions to refer variables. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/validatingadmissionpolicy.go:221
  STEP: Creating a kubernetes client @ 01/15/25 02:46:19.005
  I0115 02:46:19.005891 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename validating-admission-policy @ 01/15/25 02:46:19.007
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:46:19.032
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:46:19.038
  STEP: creating a policy with variables @ 01/15/25 02:46:19.053
  STEP: waiting until the marker is denied @ 01/15/25 02:46:19.083
  STEP: testing a replicated Deployment to be allowed @ 01/15/25 02:46:19.194
  STEP: testing a non-replicated ReplicaSet not to be denied @ 01/15/25 02:46:19.212
  I0115 02:46:19.354067 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "validating-admission-policy-6611" for this suite. @ 01/15/25 02:46:19.454
  E0115 02:46:19.526938      24 retrywatcher.go:160] "Watch failed" err="context canceled"
• [0.535 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/predicates.go:444
  STEP: Creating a kubernetes client @ 01/15/25 02:46:19.547
  I0115 02:46:19.547735 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename sched-pred @ 01/15/25 02:46:19.552
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:46:19.608
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:46:19.63
  I0115 02:46:19.639840 24 helper.go:125] Waiting up to 1m0s for all (but 0) nodes to be ready
  I0115 02:46:19.663431 24 util.go:396] Waiting for terminating namespaces to be deleted...
  I0115 02:46:19.673947 24 predicates.go:119] 
  Logging pods the apiserver thinks is on node 192.168.18.91 before test
  I0115 02:46:19.688713 24 predicates.go:957] calico-kube-controllers-7498b9bb4c-crlbm from kube-system started at 2025-01-14 15:20:19 +0000 UTC (1 container statuses recorded)
  I0115 02:46:19.688793 24 predicates.go:959] 	Container calico-kube-controllers ready: true, restart count 0
  I0115 02:46:19.688820 24 predicates.go:957] calico-node-zs5fv from kube-system started at 2025-01-14 13:30:35 +0000 UTC (1 container statuses recorded)
  I0115 02:46:19.688837 24 predicates.go:959] 	Container calico-node ready: true, restart count 0
  I0115 02:46:19.688856 24 predicates.go:957] coredns-668d6bf9bc-2fn8q from kube-system started at 2025-01-14 15:16:36 +0000 UTC (1 container statuses recorded)
  I0115 02:46:19.688873 24 predicates.go:959] 	Container coredns ready: true, restart count 0
  I0115 02:46:19.688891 24 predicates.go:957] coredns-668d6bf9bc-mpkf9 from kube-system started at 2025-01-14 15:16:35 +0000 UTC (1 container statuses recorded)
  I0115 02:46:19.688906 24 predicates.go:959] 	Container coredns ready: true, restart count 0
  I0115 02:46:19.688922 24 predicates.go:957] etcd-192.168.18.91 from kube-system started at 2025-01-14 07:47:31 +0000 UTC (1 container statuses recorded)
  I0115 02:46:19.688937 24 predicates.go:959] 	Container etcd ready: true, restart count 2
  I0115 02:46:19.688955 24 predicates.go:957] kube-apiserver-192.168.18.91 from kube-system started at 2025-01-14 07:47:31 +0000 UTC (1 container statuses recorded)
  I0115 02:46:19.688982 24 predicates.go:959] 	Container kube-apiserver ready: true, restart count 2
  I0115 02:46:19.689000 24 predicates.go:957] kube-controller-manager-192.168.18.91 from kube-system started at 2025-01-14 07:47:31 +0000 UTC (1 container statuses recorded)
  I0115 02:46:19.689026 24 predicates.go:959] 	Container kube-controller-manager ready: true, restart count 2
  I0115 02:46:19.689049 24 predicates.go:957] kube-proxy-nlmsc from kube-system started at 2025-01-14 13:23:11 +0000 UTC (1 container statuses recorded)
  I0115 02:46:19.689065 24 predicates.go:959] 	Container kube-proxy ready: true, restart count 0
  I0115 02:46:19.689082 24 predicates.go:957] kube-scheduler-192.168.18.91 from kube-system started at 2025-01-14 07:47:31 +0000 UTC (1 container statuses recorded)
  I0115 02:46:19.689097 24 predicates.go:959] 	Container kube-scheduler ready: true, restart count 2
  I0115 02:46:19.689114 24 predicates.go:957] sonobuoy-systemd-logs-daemon-set-7cfa3cb4906a48cc-vmmwc from sonobuoy started at 2025-01-15 01:17:18 +0000 UTC (2 container statuses recorded)
  I0115 02:46:19.689129 24 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I0115 02:46:19.689143 24 predicates.go:959] 	Container systemd-logs ready: true, restart count 0
  I0115 02:46:19.689161 24 predicates.go:957] replicated-54c98b4f84-ww8wq from validating-admission-policy-6611 started at 2025-01-15 02:46:19 +0000 UTC (1 container statuses recorded)
  I0115 02:46:19.689195 24 predicates.go:959] 	Container nginx ready: false, restart count 0
  I0115 02:46:19.689212 24 predicates.go:119] 
  Logging pods the apiserver thinks is on node 192.168.18.92 before test
  I0115 02:46:19.706176 24 predicates.go:957] calico-node-9mtz6 from kube-system started at 2025-01-14 13:30:35 +0000 UTC (1 container statuses recorded)
  I0115 02:46:19.706259 24 predicates.go:959] 	Container calico-node ready: true, restart count 0
  I0115 02:46:19.706287 24 predicates.go:957] kube-proxy-tf5gf from kube-system started at 2025-01-14 13:23:11 +0000 UTC (1 container statuses recorded)
  I0115 02:46:19.706305 24 predicates.go:959] 	Container kube-proxy ready: true, restart count 0
  I0115 02:46:19.706324 24 predicates.go:957] sonobuoy from sonobuoy started at 2025-01-15 01:17:16 +0000 UTC (1 container statuses recorded)
  I0115 02:46:19.706340 24 predicates.go:959] 	Container kube-sonobuoy ready: true, restart count 0
  I0115 02:46:19.706377 24 predicates.go:957] sonobuoy-e2e-job-62b29f02b7114b6e from sonobuoy started at 2025-01-15 01:17:17 +0000 UTC (2 container statuses recorded)
  I0115 02:46:19.706391 24 predicates.go:959] 	Container e2e ready: true, restart count 0
  I0115 02:46:19.706406 24 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I0115 02:46:19.706423 24 predicates.go:957] sonobuoy-systemd-logs-daemon-set-7cfa3cb4906a48cc-ljwvq from sonobuoy started at 2025-01-15 01:17:18 +0000 UTC (2 container statuses recorded)
  I0115 02:46:19.706453 24 predicates.go:959] 	Container sonobuoy-worker ready: true, restart count 0
  I0115 02:46:19.706468 24 predicates.go:959] 	Container systemd-logs ready: true, restart count 0
  I0115 02:46:19.706483 24 predicates.go:957] marker-deployment-54c98b4f84-97pmx from validating-admission-policy-6611 started at 2025-01-15 02:46:19 +0000 UTC (1 container statuses recorded)
  I0115 02:46:19.706497 24 predicates.go:959] 	Container nginx ready: false, restart count 0
  I0115 02:46:19.706513 24 predicates.go:957] non-replicated-4gfnk from validating-admission-policy-6611 started at 2025-01-15 02:46:19 +0000 UTC (1 container statuses recorded)
  I0115 02:46:19.706527 24 predicates.go:959] 	Container nginx ready: false, restart count 0
  I0115 02:46:19.706545 24 predicates.go:957] replicated-54c98b4f84-p6pvv from validating-admission-policy-6611 started at 2025-01-15 02:46:19 +0000 UTC (1 container statuses recorded)
  I0115 02:46:19.706558 24 predicates.go:959] 	Container nginx ready: false, restart count 0
  I0115 02:46:19.706586 24 predicates.go:957] replicated-54c98b4f84-pjn6p from validating-admission-policy-6611 started at 2025-01-15 02:46:19 +0000 UTC (1 container statuses recorded)
  I0115 02:46:19.706602 24 predicates.go:959] 	Container nginx ready: false, restart count 0
  STEP: Trying to schedule Pod with nonempty NodeSelector. @ 01/15/25 02:46:19.706
  STEP: Considering event: 
  Type = [Warning], Name = [restricted-pod.181abdb249e369a8], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match Pod's node affinity/selector. preemption: 0/2 nodes are available: 2 Preemption is not helpful for scheduling.] @ 01/15/25 02:46:19.783
  E0115 02:46:20.533018      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:46:20.848131 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-980" for this suite. @ 01/15/25 02:46:20.878
• [1.408 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:380
  STEP: Creating a kubernetes client @ 01/15/25 02:46:20.965
  I0115 02:46:20.965537 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename gc @ 01/15/25 02:46:20.972
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:46:21.053
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:46:21.064
  STEP: create the rc @ 01/15/25 02:46:21.095
  W0115 02:46:21.116163      24 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E0115 02:46:21.532202      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:46:22.538094      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:46:23.540072      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:46:24.548098      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:46:25.561764      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:46:26.569818      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: delete the rc @ 01/15/25 02:46:27.306
  STEP: wait for the rc to be deleted @ 01/15/25 02:46:27.473
  E0115 02:46:27.576768      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:46:28.593894      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:46:29.671712      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:46:30.677957      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:46:31.678652      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:46:32.678961      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods @ 01/15/25 02:46:32.697
  E0115 02:46:33.747130      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:46:34.753594      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:46:35.756279      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:46:36.760802      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:46:37.761020      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:46:38.772982      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:46:39.818658      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:46:40.836193      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:46:41.847107      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:46:42.867889      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:46:43.868309      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:46:44.883444      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:46:45.918389      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:46:46.920006      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:46:47.923070      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:46:48.924956      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:46:49.929840      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:46:50.944466      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:46:51.930915      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:46:52.933752      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:46:54.001922      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:46:55.008162      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:46:56.013445      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:46:57.019205      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:46:58.020235      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:46:59.025684      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:47:00.039115      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:47:01.041876      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:47:02.042402      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:47:03.045015      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:47:04.052621      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 01/15/25 02:47:04.228
  E0115 02:47:05.060326      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:47:06.060762      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:47:07.060999      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:47:08.067921      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:47:09.104638      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:47:10.116474      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:47:10.382505 24 garbage_collector.go:265] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0115 02:47:10.382706 24 delete.go:95] Deleting pod "simpletest.rc-25rjq" in namespace "gc-8309"
  I0115 02:47:10.453103 24 delete.go:95] Deleting pod "simpletest.rc-29b94" in namespace "gc-8309"
  I0115 02:47:10.659067 24 delete.go:95] Deleting pod "simpletest.rc-2b7xs" in namespace "gc-8309"
  I0115 02:47:10.804244 24 delete.go:95] Deleting pod "simpletest.rc-2ch7x" in namespace "gc-8309"
  I0115 02:47:10.970131 24 delete.go:95] Deleting pod "simpletest.rc-2qbtf" in namespace "gc-8309"
  I0115 02:47:11.106850 24 delete.go:95] Deleting pod "simpletest.rc-2xqkz" in namespace "gc-8309"
  E0115 02:47:11.155974      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:47:11.304835 24 delete.go:95] Deleting pod "simpletest.rc-2xr79" in namespace "gc-8309"
  I0115 02:47:11.460134 24 delete.go:95] Deleting pod "simpletest.rc-48r9k" in namespace "gc-8309"
  I0115 02:47:11.567417 24 delete.go:95] Deleting pod "simpletest.rc-4f6xb" in namespace "gc-8309"
  I0115 02:47:11.678384 24 delete.go:95] Deleting pod "simpletest.rc-4fx76" in namespace "gc-8309"
  I0115 02:47:11.826152 24 delete.go:95] Deleting pod "simpletest.rc-4hpgj" in namespace "gc-8309"
  I0115 02:47:12.043428 24 delete.go:95] Deleting pod "simpletest.rc-4kdb4" in namespace "gc-8309"
  E0115 02:47:12.157477      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:47:12.234659 24 delete.go:95] Deleting pod "simpletest.rc-5b785" in namespace "gc-8309"
  I0115 02:47:12.337925 24 delete.go:95] Deleting pod "simpletest.rc-5hqzl" in namespace "gc-8309"
  I0115 02:47:12.465769 24 delete.go:95] Deleting pod "simpletest.rc-5rngv" in namespace "gc-8309"
  I0115 02:47:12.871340 24 delete.go:95] Deleting pod "simpletest.rc-5xhrr" in namespace "gc-8309"
  I0115 02:47:13.142107 24 delete.go:95] Deleting pod "simpletest.rc-64qgw" in namespace "gc-8309"
  E0115 02:47:13.246511      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:47:13.304089 24 delete.go:95] Deleting pod "simpletest.rc-6q765" in namespace "gc-8309"
  I0115 02:47:13.443370 24 delete.go:95] Deleting pod "simpletest.rc-6vpgn" in namespace "gc-8309"
  I0115 02:47:13.986117 24 delete.go:95] Deleting pod "simpletest.rc-766nz" in namespace "gc-8309"
  I0115 02:47:14.148193 24 delete.go:95] Deleting pod "simpletest.rc-76bl2" in namespace "gc-8309"
  E0115 02:47:14.273890      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:47:14.645830 24 delete.go:95] Deleting pod "simpletest.rc-775sq" in namespace "gc-8309"
  I0115 02:47:14.873100 24 delete.go:95] Deleting pod "simpletest.rc-7mq7h" in namespace "gc-8309"
  I0115 02:47:15.110422 24 delete.go:95] Deleting pod "simpletest.rc-7mqcf" in namespace "gc-8309"
  I0115 02:47:15.197205 24 delete.go:95] Deleting pod "simpletest.rc-7tvvl" in namespace "gc-8309"
  E0115 02:47:15.274998      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:47:15.301338 24 delete.go:95] Deleting pod "simpletest.rc-7vgbx" in namespace "gc-8309"
  I0115 02:47:15.454254 24 delete.go:95] Deleting pod "simpletest.rc-868q7" in namespace "gc-8309"
  I0115 02:47:16.163331 24 delete.go:95] Deleting pod "simpletest.rc-8b27l" in namespace "gc-8309"
  E0115 02:47:16.298250      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:47:16.490918 24 delete.go:95] Deleting pod "simpletest.rc-8c56p" in namespace "gc-8309"
  I0115 02:47:16.928745 24 delete.go:95] Deleting pod "simpletest.rc-8gc84" in namespace "gc-8309"
  E0115 02:47:17.300013      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:47:17.877970 24 delete.go:95] Deleting pod "simpletest.rc-9784q" in namespace "gc-8309"
  I0115 02:47:18.266805 24 delete.go:95] Deleting pod "simpletest.rc-9k9qm" in namespace "gc-8309"
  E0115 02:47:18.324801      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:47:18.535372 24 delete.go:95] Deleting pod "simpletest.rc-9pt6s" in namespace "gc-8309"
  I0115 02:47:19.245382 24 delete.go:95] Deleting pod "simpletest.rc-9r6cd" in namespace "gc-8309"
  E0115 02:47:19.325480      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:47:19.738474 24 delete.go:95] Deleting pod "simpletest.rc-bj4qt" in namespace "gc-8309"
  I0115 02:47:19.970091 24 delete.go:95] Deleting pod "simpletest.rc-bwbk7" in namespace "gc-8309"
  E0115 02:47:20.363269      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:47:20.429852 24 delete.go:95] Deleting pod "simpletest.rc-ctmj4" in namespace "gc-8309"
  I0115 02:47:20.813003 24 delete.go:95] Deleting pod "simpletest.rc-ctrfl" in namespace "gc-8309"
  I0115 02:47:20.952825 24 delete.go:95] Deleting pod "simpletest.rc-d28z9" in namespace "gc-8309"
  I0115 02:47:21.141057 24 delete.go:95] Deleting pod "simpletest.rc-dddq5" in namespace "gc-8309"
  I0115 02:47:21.283947 24 delete.go:95] Deleting pod "simpletest.rc-dhzdf" in namespace "gc-8309"
  I0115 02:47:21.352677 24 delete.go:95] Deleting pod "simpletest.rc-f5vn2" in namespace "gc-8309"
  E0115 02:47:21.379621      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:47:21.434901 24 delete.go:95] Deleting pod "simpletest.rc-f72ct" in namespace "gc-8309"
  I0115 02:47:21.574377 24 delete.go:95] Deleting pod "simpletest.rc-f8f9f" in namespace "gc-8309"
  I0115 02:47:21.811765 24 delete.go:95] Deleting pod "simpletest.rc-f8nlf" in namespace "gc-8309"
  I0115 02:47:21.893042 24 delete.go:95] Deleting pod "simpletest.rc-gjbkg" in namespace "gc-8309"
  I0115 02:47:22.032669 24 delete.go:95] Deleting pod "simpletest.rc-gkh9f" in namespace "gc-8309"
  I0115 02:47:22.325051 24 delete.go:95] Deleting pod "simpletest.rc-gmpm2" in namespace "gc-8309"
  E0115 02:47:22.384158      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:47:22.463593 24 delete.go:95] Deleting pod "simpletest.rc-gr8t4" in namespace "gc-8309"
  I0115 02:47:22.521226 24 delete.go:95] Deleting pod "simpletest.rc-gvmjt" in namespace "gc-8309"
  I0115 02:47:22.646893 24 delete.go:95] Deleting pod "simpletest.rc-gxw64" in namespace "gc-8309"
  I0115 02:47:22.747989 24 delete.go:95] Deleting pod "simpletest.rc-h78xm" in namespace "gc-8309"
  I0115 02:47:22.855171 24 delete.go:95] Deleting pod "simpletest.rc-hzrxb" in namespace "gc-8309"
  I0115 02:47:22.913050 24 delete.go:95] Deleting pod "simpletest.rc-j6ptt" in namespace "gc-8309"
  I0115 02:47:22.961967 24 delete.go:95] Deleting pod "simpletest.rc-j97px" in namespace "gc-8309"
  I0115 02:47:23.059710 24 delete.go:95] Deleting pod "simpletest.rc-jgtn9" in namespace "gc-8309"
  I0115 02:47:23.142955 24 delete.go:95] Deleting pod "simpletest.rc-jnpds" in namespace "gc-8309"
  I0115 02:47:23.267569 24 delete.go:95] Deleting pod "simpletest.rc-jzm7c" in namespace "gc-8309"
  E0115 02:47:23.395842      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:47:23.426951 24 delete.go:95] Deleting pod "simpletest.rc-kxmct" in namespace "gc-8309"
  I0115 02:47:23.651615 24 delete.go:95] Deleting pod "simpletest.rc-l88kt" in namespace "gc-8309"
  I0115 02:47:23.863396 24 delete.go:95] Deleting pod "simpletest.rc-lcm9c" in namespace "gc-8309"
  I0115 02:47:23.933212 24 delete.go:95] Deleting pod "simpletest.rc-ldw5d" in namespace "gc-8309"
  I0115 02:47:24.047755 24 delete.go:95] Deleting pod "simpletest.rc-lqqld" in namespace "gc-8309"
  I0115 02:47:24.134746 24 delete.go:95] Deleting pod "simpletest.rc-m4bm6" in namespace "gc-8309"
  I0115 02:47:24.263039 24 delete.go:95] Deleting pod "simpletest.rc-mlxcz" in namespace "gc-8309"
  I0115 02:47:24.388462 24 delete.go:95] Deleting pod "simpletest.rc-n4lpm" in namespace "gc-8309"
  E0115 02:47:24.401926      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:47:24.538376 24 delete.go:95] Deleting pod "simpletest.rc-nh5b5" in namespace "gc-8309"
  I0115 02:47:24.634325 24 delete.go:95] Deleting pod "simpletest.rc-nzfmj" in namespace "gc-8309"
  I0115 02:47:24.682512 24 delete.go:95] Deleting pod "simpletest.rc-przvk" in namespace "gc-8309"
  I0115 02:47:24.872216 24 delete.go:95] Deleting pod "simpletest.rc-pxkfw" in namespace "gc-8309"
  I0115 02:47:24.964186 24 delete.go:95] Deleting pod "simpletest.rc-q7z7w" in namespace "gc-8309"
  I0115 02:47:25.150983 24 delete.go:95] Deleting pod "simpletest.rc-qgvcl" in namespace "gc-8309"
  I0115 02:47:25.305118 24 delete.go:95] Deleting pod "simpletest.rc-r6bz2" in namespace "gc-8309"
  E0115 02:47:25.424979      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:47:25.569335 24 delete.go:95] Deleting pod "simpletest.rc-rbp5z" in namespace "gc-8309"
  I0115 02:47:25.816616 24 delete.go:95] Deleting pod "simpletest.rc-rhm88" in namespace "gc-8309"
  I0115 02:47:26.039448 24 delete.go:95] Deleting pod "simpletest.rc-rmd7n" in namespace "gc-8309"
  I0115 02:47:26.320782 24 delete.go:95] Deleting pod "simpletest.rc-rvhwq" in namespace "gc-8309"
  I0115 02:47:26.387756 24 delete.go:95] Deleting pod "simpletest.rc-s8rl4" in namespace "gc-8309"
  E0115 02:47:26.436674      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:47:26.537089 24 delete.go:95] Deleting pod "simpletest.rc-sbw5h" in namespace "gc-8309"
  I0115 02:47:26.783002 24 delete.go:95] Deleting pod "simpletest.rc-sgmv4" in namespace "gc-8309"
  E0115 02:47:27.445642      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:47:27.455197 24 delete.go:95] Deleting pod "simpletest.rc-shqmn" in namespace "gc-8309"
  I0115 02:47:28.201127 24 delete.go:95] Deleting pod "simpletest.rc-swnlq" in namespace "gc-8309"
  E0115 02:47:28.448184      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:47:28.905666 24 delete.go:95] Deleting pod "simpletest.rc-szzbb" in namespace "gc-8309"
  I0115 02:47:29.049025 24 delete.go:95] Deleting pod "simpletest.rc-tc878" in namespace "gc-8309"
  I0115 02:47:29.138907 24 delete.go:95] Deleting pod "simpletest.rc-tm5hj" in namespace "gc-8309"
  I0115 02:47:29.182364 24 delete.go:95] Deleting pod "simpletest.rc-tmswm" in namespace "gc-8309"
  I0115 02:47:29.304139 24 delete.go:95] Deleting pod "simpletest.rc-trvcg" in namespace "gc-8309"
  I0115 02:47:29.449398 24 delete.go:95] Deleting pod "simpletest.rc-ttn9k" in namespace "gc-8309"
  E0115 02:47:29.461611      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:47:29.571408 24 delete.go:95] Deleting pod "simpletest.rc-tzvxq" in namespace "gc-8309"
  I0115 02:47:29.703090 24 delete.go:95] Deleting pod "simpletest.rc-v7m5n" in namespace "gc-8309"
  I0115 02:47:30.019246 24 delete.go:95] Deleting pod "simpletest.rc-vvfld" in namespace "gc-8309"
  I0115 02:47:30.222096 24 delete.go:95] Deleting pod "simpletest.rc-wcp8c" in namespace "gc-8309"
  I0115 02:47:30.311202 24 delete.go:95] Deleting pod "simpletest.rc-wvfls" in namespace "gc-8309"
  I0115 02:47:30.385886 24 delete.go:95] Deleting pod "simpletest.rc-x7r7r" in namespace "gc-8309"
  E0115 02:47:30.462154      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:47:30.680378 24 delete.go:95] Deleting pod "simpletest.rc-xcgtq" in namespace "gc-8309"
  I0115 02:47:30.772597 24 delete.go:95] Deleting pod "simpletest.rc-z4jq8" in namespace "gc-8309"
  I0115 02:47:30.952990 24 delete.go:95] Deleting pod "simpletest.rc-zkszm" in namespace "gc-8309"
  I0115 02:47:31.097455 24 delete.go:95] Deleting pod "simpletest.rc-zskjd" in namespace "gc-8309"
  I0115 02:47:31.203128 24 delete.go:95] Deleting pod "simpletest.rc-zssft" in namespace "gc-8309"
  I0115 02:47:31.308027 24 delete.go:95] Deleting pod "simpletest.rc-zv5rg" in namespace "gc-8309"
  I0115 02:47:31.369206 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-8309" for this suite. @ 01/15/25 02:47:31.409
• [70.477 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo should scale a replication controller [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:350
  STEP: Creating a kubernetes client @ 01/15/25 02:47:31.443
  I0115 02:47:31.443832 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename kubectl @ 01/15/25 02:47:31.452
  E0115 02:47:31.469481      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:47:31.62
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:47:31.656
  STEP: creating a replication controller @ 01/15/25 02:47:31.821
  I0115 02:47:31.821676 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-8001 create -f -'
  E0115 02:47:32.478971      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:47:33.578207      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:47:34.582497      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:47:34.631401 24 builder.go:146] stderr: ""
  I0115 02:47:34.631507 24 builder.go:147] stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 01/15/25 02:47:34.631
  I0115 02:47:34.631672 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-8001 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0115 02:47:35.389079 24 builder.go:146] stderr: ""
  I0115 02:47:35.389239 24 builder.go:147] stdout: "update-demo-nautilus-b5gzb update-demo-nautilus-pcb5x "
  I0115 02:47:35.389344 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-8001 get pods update-demo-nautilus-b5gzb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  E0115 02:47:35.591479      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:47:36.604366      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:47:36.704649 24 builder.go:146] stderr: ""
  I0115 02:47:36.704779 24 builder.go:147] stdout: ""
  I0115 02:47:36.704810 24 kubectl.go:2499] update-demo-nautilus-b5gzb is created but not running
  E0115 02:47:37.604574      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:47:38.605627      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:47:39.608773      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:47:40.611941      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:47:41.616657      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:47:41.705442 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-8001 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0115 02:47:42.605400 24 builder.go:146] stderr: ""
  I0115 02:47:42.605491 24 builder.go:147] stdout: "update-demo-nautilus-b5gzb update-demo-nautilus-pcb5x "
  I0115 02:47:42.605607 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-8001 get pods update-demo-nautilus-b5gzb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  E0115 02:47:42.616870      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:47:43.618209      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:47:44.648018      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:47:45.264810 24 builder.go:146] stderr: ""
  I0115 02:47:45.267032 24 builder.go:147] stdout: ""
  I0115 02:47:45.267099 24 kubectl.go:2499] update-demo-nautilus-b5gzb is created but not running
  E0115 02:47:45.649371      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:47:46.663594      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:47:47.670837      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:47:48.688738      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:47:49.693904      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:47:50.276040 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-8001 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  E0115 02:47:50.694743      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:47:51.056644 24 builder.go:146] stderr: ""
  I0115 02:47:51.056929 24 builder.go:147] stdout: "update-demo-nautilus-b5gzb update-demo-nautilus-pcb5x "
  I0115 02:47:51.057232 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-8001 get pods update-demo-nautilus-b5gzb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  E0115 02:47:51.698030      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:47:52.125621 24 builder.go:146] stderr: ""
  I0115 02:47:52.125712 24 builder.go:147] stdout: ""
  I0115 02:47:52.125742 24 kubectl.go:2499] update-demo-nautilus-b5gzb is created but not running
  E0115 02:47:52.702126      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:47:53.715399      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:47:54.718784      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:47:55.721295      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:47:56.728393      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:47:57.127670 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-8001 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0115 02:47:57.647703 24 builder.go:146] stderr: ""
  I0115 02:47:57.647780 24 builder.go:147] stdout: "update-demo-nautilus-b5gzb update-demo-nautilus-pcb5x "
  I0115 02:47:57.647896 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-8001 get pods update-demo-nautilus-b5gzb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  E0115 02:47:57.729166      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:47:58.115332 24 builder.go:146] stderr: ""
  I0115 02:47:58.115418 24 builder.go:147] stdout: ""
  I0115 02:47:58.115446 24 kubectl.go:2499] update-demo-nautilus-b5gzb is created but not running
  E0115 02:47:58.732220      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:47:59.739356      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:48:00.744392      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:48:01.747765      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:48:02.749440      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:48:03.116730 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-8001 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0115 02:48:03.482563 24 builder.go:146] stderr: ""
  I0115 02:48:03.482685 24 builder.go:147] stdout: "update-demo-nautilus-b5gzb update-demo-nautilus-pcb5x "
  I0115 02:48:03.482891 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-8001 get pods update-demo-nautilus-b5gzb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  E0115 02:48:03.750907      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:48:04.032368 24 builder.go:146] stderr: ""
  I0115 02:48:04.032462 24 builder.go:147] stdout: ""
  I0115 02:48:04.032492 24 kubectl.go:2499] update-demo-nautilus-b5gzb is created but not running
  E0115 02:48:04.752768      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:48:05.754353      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:48:06.754856      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:48:07.757162      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:48:08.757950      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:48:09.039058 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-8001 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  E0115 02:48:09.758311      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:48:09.939277 24 builder.go:146] stderr: ""
  I0115 02:48:09.939362 24 builder.go:147] stdout: "update-demo-nautilus-b5gzb update-demo-nautilus-pcb5x "
  I0115 02:48:09.939496 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-8001 get pods update-demo-nautilus-b5gzb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0115 02:48:10.395150 24 builder.go:146] stderr: ""
  I0115 02:48:10.395238 24 builder.go:147] stdout: ""
  I0115 02:48:10.395266 24 kubectl.go:2499] update-demo-nautilus-b5gzb is created but not running
  E0115 02:48:10.760195      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:48:11.764177      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:48:12.764909      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:48:13.765376      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:48:14.766204      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:48:15.396143 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-8001 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  E0115 02:48:15.766746      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:48:15.923885 24 builder.go:146] stderr: ""
  I0115 02:48:15.923961 24 builder.go:147] stdout: "update-demo-nautilus-b5gzb update-demo-nautilus-pcb5x "
  I0115 02:48:15.924070 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-8001 get pods update-demo-nautilus-b5gzb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0115 02:48:16.267393 24 builder.go:146] stderr: ""
  I0115 02:48:16.267496 24 builder.go:147] stdout: ""
  I0115 02:48:16.267668 24 kubectl.go:2499] update-demo-nautilus-b5gzb is created but not running
  E0115 02:48:16.769335      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:48:17.769989      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:48:18.771265      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:48:19.772061      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:48:20.773193      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:48:21.268329 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-8001 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0115 02:48:21.551021 24 builder.go:146] stderr: ""
  I0115 02:48:21.551162 24 builder.go:147] stdout: "update-demo-nautilus-b5gzb update-demo-nautilus-pcb5x "
  I0115 02:48:21.551281 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-8001 get pods update-demo-nautilus-b5gzb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  E0115 02:48:21.773261      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:48:21.947083 24 builder.go:146] stderr: ""
  I0115 02:48:21.947172 24 builder.go:147] stdout: "true"
  I0115 02:48:21.947302 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-8001 get pods update-demo-nautilus-b5gzb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0115 02:48:22.321868 24 builder.go:146] stderr: ""
  I0115 02:48:22.321951 24 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0115 02:48:22.321981 24 kubectl.go:2390] validating pod update-demo-nautilus-b5gzb
  I0115 02:48:22.338599 24 kubectl.go:2410] got data: {
    "image": "nautilus.jpg"
  }

  I0115 02:48:22.338727 24 kubectl.go:2415] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0115 02:48:22.338763 24 kubectl.go:2517] update-demo-nautilus-b5gzb is verified up and running
  I0115 02:48:22.338852 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-8001 get pods update-demo-nautilus-pcb5x -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  E0115 02:48:22.774573      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:48:22.847765 24 builder.go:146] stderr: ""
  I0115 02:48:22.847947 24 builder.go:147] stdout: "true"
  I0115 02:48:22.848051 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-8001 get pods update-demo-nautilus-pcb5x -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  I0115 02:48:23.193159 24 builder.go:146] stderr: ""
  I0115 02:48:23.193340 24 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0115 02:48:23.193446 24 kubectl.go:2390] validating pod update-demo-nautilus-pcb5x
  I0115 02:48:23.212869 24 kubectl.go:2410] got data: {
    "image": "nautilus.jpg"
  }

  I0115 02:48:23.213025 24 kubectl.go:2415] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0115 02:48:23.213067 24 kubectl.go:2517] update-demo-nautilus-pcb5x is verified up and running
  STEP: scaling down the replication controller @ 01/15/25 02:48:23.213
  I0115 02:48:23.222300 24 kubectl.go:319] scanned /root for discovery docs: <nil>
  I0115 02:48:23.222703 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-8001 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
  E0115 02:48:23.775591      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:48:24.546019 24 builder.go:146] stderr: ""
  I0115 02:48:24.546102 24 builder.go:147] stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 01/15/25 02:48:24.546
  I0115 02:48:24.546271 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-8001 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  E0115 02:48:24.776329      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:48:25.086937 24 builder.go:146] stderr: ""
  I0115 02:48:25.087077 24 builder.go:147] stdout: "update-demo-nautilus-b5gzb update-demo-nautilus-pcb5x "
  STEP: Replicas for name=update-demo: expected=1 actual=2 @ 01/15/25 02:48:25.087
  E0115 02:48:25.777337      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:48:26.778666      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:48:27.780148      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:48:28.780529      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:48:29.781017      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:48:30.087625 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-8001 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0115 02:48:30.280255 24 builder.go:146] stderr: ""
  I0115 02:48:30.280496 24 builder.go:147] stdout: "update-demo-nautilus-pcb5x "
  I0115 02:48:30.280816 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-8001 get pods update-demo-nautilus-pcb5x -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  I0115 02:48:30.507650 24 builder.go:146] stderr: ""
  I0115 02:48:30.507931 24 builder.go:147] stdout: "true"
  I0115 02:48:30.508411 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-8001 get pods update-demo-nautilus-pcb5x -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  E0115 02:48:30.784067      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:48:31.101278 24 builder.go:146] stderr: ""
  I0115 02:48:31.101361 24 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0115 02:48:31.101391 24 kubectl.go:2390] validating pod update-demo-nautilus-pcb5x
  I0115 02:48:31.118153 24 kubectl.go:2410] got data: {
    "image": "nautilus.jpg"
  }

  I0115 02:48:31.118281 24 kubectl.go:2415] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0115 02:48:31.118313 24 kubectl.go:2517] update-demo-nautilus-pcb5x is verified up and running
  STEP: scaling up the replication controller @ 01/15/25 02:48:31.118
  I0115 02:48:31.121776 24 kubectl.go:319] scanned /root for discovery docs: <nil>
  I0115 02:48:31.121894 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-8001 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
  E0115 02:48:31.784775      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:48:32.785312      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:48:32.939866 24 builder.go:146] stderr: ""
  I0115 02:48:32.939946 24 builder.go:147] stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 01/15/25 02:48:32.94
  I0115 02:48:32.940149 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-8001 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0115 02:48:33.502936 24 builder.go:146] stderr: ""
  I0115 02:48:33.503963 24 builder.go:147] stdout: "update-demo-nautilus-cqlsl update-demo-nautilus-pcb5x "
  I0115 02:48:33.504477 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-8001 get pods update-demo-nautilus-cqlsl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  E0115 02:48:33.786907      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:48:33.852624 24 builder.go:146] stderr: ""
  I0115 02:48:33.852976 24 builder.go:147] stdout: ""
  I0115 02:48:33.853016 24 kubectl.go:2499] update-demo-nautilus-cqlsl is created but not running
  E0115 02:48:34.786942      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:48:35.787278      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:48:36.827371      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:48:37.826852      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:48:38.829450      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:48:38.854176 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-8001 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  I0115 02:48:39.325229 24 builder.go:146] stderr: ""
  I0115 02:48:39.325423 24 builder.go:147] stdout: "update-demo-nautilus-cqlsl update-demo-nautilus-pcb5x "
  I0115 02:48:39.325604 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-8001 get pods update-demo-nautilus-cqlsl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  E0115 02:48:39.838859      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:48:40.379491 24 builder.go:146] stderr: ""
  I0115 02:48:40.379624 24 builder.go:147] stdout: "true"
  I0115 02:48:40.379765 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-8001 get pods update-demo-nautilus-cqlsl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  E0115 02:48:40.841952      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:48:41.101719 24 builder.go:146] stderr: ""
  I0115 02:48:41.101838 24 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0115 02:48:41.101875 24 kubectl.go:2390] validating pod update-demo-nautilus-cqlsl
  I0115 02:48:41.156425 24 kubectl.go:2410] got data: {
    "image": "nautilus.jpg"
  }

  I0115 02:48:41.156552 24 kubectl.go:2415] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0115 02:48:41.156606 24 kubectl.go:2517] update-demo-nautilus-cqlsl is verified up and running
  I0115 02:48:41.156707 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-8001 get pods update-demo-nautilus-pcb5x -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  E0115 02:48:41.851813      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:48:42.090460 24 builder.go:146] stderr: ""
  I0115 02:48:42.090766 24 builder.go:147] stdout: "true"
  I0115 02:48:42.090951 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-8001 get pods update-demo-nautilus-pcb5x -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  E0115 02:48:42.859789      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:48:42.968081 24 builder.go:146] stderr: ""
  I0115 02:48:42.968202 24 builder.go:147] stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  I0115 02:48:42.968242 24 kubectl.go:2390] validating pod update-demo-nautilus-pcb5x
  I0115 02:48:42.983302 24 kubectl.go:2410] got data: {
    "image": "nautilus.jpg"
  }

  I0115 02:48:42.983426 24 kubectl.go:2415] Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  I0115 02:48:42.983464 24 kubectl.go:2517] update-demo-nautilus-pcb5x is verified up and running
  STEP: using delete to clean up resources @ 01/15/25 02:48:42.983
  I0115 02:48:42.983638 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-8001 delete --grace-period=0 --force -f -'
  I0115 02:48:43.308554 24 builder.go:146] stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  I0115 02:48:43.308697 24 builder.go:147] stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
  I0115 02:48:43.308927 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-8001 get rc,svc -l name=update-demo --no-headers'
  E0115 02:48:43.863430      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:48:43.879065 24 builder.go:146] stderr: "No resources found in kubectl-8001 namespace.\n"
  I0115 02:48:43.879148 24 builder.go:147] stdout: ""
  I0115 02:48:43.879247 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-8001 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  E0115 02:48:44.931675      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:48:45.451782 24 builder.go:146] stderr: ""
  I0115 02:48:45.451882 24 builder.go:147] stdout: ""
  I0115 02:48:45.452117 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-8001" for this suite. @ 01/15/25 02:48:45.505
• [74.314 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] CSINodes CSI Conformance should run through the lifecycle of a csinode [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/csi_node.go:54
  STEP: Creating a kubernetes client @ 01/15/25 02:48:45.758
  I0115 02:48:45.758075 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename csinodes @ 01/15/25 02:48:45.762
  E0115 02:48:45.943991      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:48:45.948
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:48:46.005
  STEP: Creating initial csiNode "e2e-csinode-hrtsg" @ 01/15/25 02:48:46.333
  STEP: Getting initial csiNode "e2e-csinode-hrtsg" @ 01/15/25 02:48:46.422
  STEP: Patching initial csiNode: "e2e-csinode-hrtsg" @ 01/15/25 02:48:46.466
  STEP: Listing csiNodes with LabelSelector "e2e-csinode-hrtsg=patched" @ 01/15/25 02:48:46.593
  STEP: Delete initial csiNode: "e2e-csinode-hrtsg" @ 01/15/25 02:48:46.717
  STEP: Confirm deletion of csiNode "e2e-csinode-hrtsg" @ 01/15/25 02:48:46.787
  STEP: Creating replacement csiNode "e2e-csinode-2f7km" @ 01/15/25 02:48:46.839
  STEP: Getting replacement csiNode "e2e-csinode-2f7km" @ 01/15/25 02:48:46.902
  STEP: Updating replacement csiNode "e2e-csinode-2f7km" @ 01/15/25 02:48:46.941
  E0115 02:48:46.959941      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: DeleteCollection of CSINodes with "e2e-csinode-2f7km=updated" label @ 01/15/25 02:48:47.045
  STEP: Confirm deletion of replacement csiNode with LabelSelector "e2e-csinode-2f7km=updated" @ 01/15/25 02:48:47.163
  I0115 02:48:47.227102 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csinodes-8139" for this suite. @ 01/15/25 02:48:47.402
• [1.796 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance] [sig-node, Serial, Disruptive, Conformance]
k8s.io/kubernetes/test/e2e/node/taints.go:284
  STEP: Creating a kubernetes client @ 01/15/25 02:48:47.563
  I0115 02:48:47.563741 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename taint-single-pod @ 01/15/25 02:48:47.579
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:48:47.841
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:48:47.903
  I0115 02:48:47.940262 24 wait.go:51] Waiting up to 1m0s for all nodes to be ready
  E0115 02:48:47.960779      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:48:48.961883      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:48:49.969394      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:48:50.970474      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:48:51.971558      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:48:52.971900      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:48:53.972231      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:48:54.995277      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:48:55.996721      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:48:56.997685      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:48:57.998541      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:48:59.000499      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:49:00.001736      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:49:01.007173      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:49:02.010231      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:49:03.011662      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:49:04.011748      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:49:05.011923      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:49:06.012699      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:49:07.014720      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:49:08.015752      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:49:09.016126      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:49:10.017877      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:49:11.018362      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:49:12.020113      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:49:13.022211      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:49:14.023256      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:49:15.024016      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:49:16.024443      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:49:17.030663      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:49:18.031212      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:49:19.034887      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:49:20.034974      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:49:21.036071      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:49:22.036508      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:49:23.036666      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:49:24.039802      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:49:25.039760      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:49:26.041150      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:49:27.042118      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:49:28.042444      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:49:29.043415      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:49:30.043538      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:49:31.044449      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:49:32.045460      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:49:33.046322      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:49:34.046527      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:49:35.047497      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:49:36.048537      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:49:37.049402      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:49:38.050466      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:49:39.050228      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:49:40.051069      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:49:41.051983      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:49:42.052216      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:49:43.053124      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:49:44.053579      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:49:45.053969      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:49:46.054690      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:49:47.059684      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:49:47.942859 24 util.go:396] Waiting for terminating namespaces to be deleted...
  I0115 02:49:47.965649 24 taints.go:144] Starting informer...
  STEP: Starting pod... @ 01/15/25 02:49:47.966
  E0115 02:49:48.056685      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:49:48.224429 24 taints.go:294] Pod is running on 192.168.18.92. Tainting Node
  STEP: Trying to apply a taint on the Node @ 01/15/25 02:49:48.224
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 01/15/25 02:49:48.24
  STEP: Waiting short time to make sure Pod is queued for deletion @ 01/15/25 02:49:48.246
  I0115 02:49:48.246578 24 taints.go:313] Pod wasn't evicted. Proceeding
  I0115 02:49:48.246608 24 taints.go:320] Removing taint from Node
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 01/15/25 02:49:48.267
  STEP: Waiting some time to make sure that toleration time passed. @ 01/15/25 02:49:48.272
  E0115 02:49:49.057657      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:49:50.058881      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:49:51.059473      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:49:52.059835      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:49:53.060250      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:49:54.061299      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:49:55.061218      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:49:56.062913      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:49:57.066162      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:49:58.067620      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:49:59.068161      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:00.069092      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:01.070361      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:02.070932      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:03.072965      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:04.074500      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:05.074887      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:06.076687      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:07.078043      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:08.078180      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:09.079489      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:10.083064      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:11.081330      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:12.082145      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:13.082722      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:14.084375      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:15.083593      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:16.084818      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:17.092261      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:18.088237      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:19.088198      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:20.090219      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:21.090891      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:22.092336      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:23.120708      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:24.121083      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:25.122043      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:26.122424      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:27.123416      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:28.125099      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:29.125835      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:30.126900      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:31.128354      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:32.129110      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:33.129845      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:34.130908      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:35.130997      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:36.132027      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:37.133566      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:38.135333      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:39.136063      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:40.136895      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:41.138691      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:42.139009      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:43.140920      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:44.142059      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:45.142531      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:46.143628      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:47.144115      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:48.144249      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:49.144550      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:50.145276      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:51.148314      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:52.149948      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:53.151251      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:54.157515      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:55.156015      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:56.156870      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:57.158035      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:58.159340      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:50:59.160270      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:51:00.160905      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:51:01.162346      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:51:02.165058      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:51:03.166188      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:51:03.273147 24 taints.go:329] Pod wasn't evicted. Test successful
  I0115 02:51:03.273559 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "taint-single-pod-7286" for this suite. @ 01/15/25 02:51:03.32
• [135.775 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance] [sig-apps, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apps/controller_revision.go:126
  STEP: Creating a kubernetes client @ 01/15/25 02:51:03.338
  I0115 02:51:03.338741 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename controllerrevisions @ 01/15/25 02:51:03.339
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:51:03.366
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:51:03.371
  STEP: Creating DaemonSet "e2e-zb75t-daemon-set" @ 01/15/25 02:51:03.408
  STEP: Check that daemon pods launch on every node of the cluster. @ 01/15/25 02:51:03.414
  I0115 02:51:03.506285 24 fixtures.go:126] Number of nodes with available pods controlled by daemonset e2e-zb75t-daemon-set: 0
  I0115 02:51:03.506388 24 fixtures.go:131] Node 192.168.18.91 is running 0 daemon pod, expected 1
  E0115 02:51:04.166341      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:51:04.476915 24 fixtures.go:126] Number of nodes with available pods controlled by daemonset e2e-zb75t-daemon-set: 0
  I0115 02:51:04.476984 24 fixtures.go:131] Node 192.168.18.91 is running 0 daemon pod, expected 1
  E0115 02:51:05.167045      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:51:05.425987 24 fixtures.go:126] Number of nodes with available pods controlled by daemonset e2e-zb75t-daemon-set: 2
  I0115 02:51:05.426065 24 fixtures.go:136] Number of running nodes: 2, number of available pods: 2 in daemonset e2e-zb75t-daemon-set
  STEP: Confirm DaemonSet "e2e-zb75t-daemon-set" successfully created with "daemonset-name=e2e-zb75t-daemon-set" label @ 01/15/25 02:51:05.429
  STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-zb75t-daemon-set" @ 01/15/25 02:51:05.441
  I0115 02:51:05.445453 24 controller_revision.go:162] Located ControllerRevision: "e2e-zb75t-daemon-set-57dfb49c6d"
  STEP: Patching ControllerRevision "e2e-zb75t-daemon-set-57dfb49c6d" @ 01/15/25 02:51:05.451
  I0115 02:51:05.458791 24 controller_revision.go:173] e2e-zb75t-daemon-set-57dfb49c6d has been patched
  STEP: Create a new ControllerRevision @ 01/15/25 02:51:05.458
  I0115 02:51:05.466714 24 controller_revision.go:191] Created ControllerRevision: e2e-zb75t-daemon-set-cb8cc7fc8
  STEP: Confirm that there are two ControllerRevisions @ 01/15/25 02:51:05.466
  I0115 02:51:05.467602 24 controller_revision.go:254] Requesting list of ControllerRevisions to confirm quantity
  I0115 02:51:05.552963 24 controller_revision.go:265] Found 2 ControllerRevisions
  STEP: Deleting ControllerRevision "e2e-zb75t-daemon-set-57dfb49c6d" @ 01/15/25 02:51:05.553
  STEP: Confirm that there is only one ControllerRevision @ 01/15/25 02:51:05.568
  I0115 02:51:05.568195 24 controller_revision.go:254] Requesting list of ControllerRevisions to confirm quantity
  I0115 02:51:05.576007 24 controller_revision.go:265] Found 1 ControllerRevisions
  STEP: Updating ControllerRevision "e2e-zb75t-daemon-set-cb8cc7fc8" @ 01/15/25 02:51:05.583
  I0115 02:51:05.593514 24 controller_revision.go:220] e2e-zb75t-daemon-set-cb8cc7fc8 has been updated
  STEP: Generate another ControllerRevision by patching the Daemonset @ 01/15/25 02:51:05.593
  W0115 02:51:05.600893      24 warnings.go:70] unknown field "updateStrategy"
  STEP: Confirm that there are two ControllerRevisions @ 01/15/25 02:51:05.601
  I0115 02:51:05.601116 24 controller_revision.go:254] Requesting list of ControllerRevisions to confirm quantity
  I0115 02:51:05.621614 24 controller_revision.go:265] Found 2 ControllerRevisions
  STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-zb75t-daemon-set-cb8cc7fc8=updated" @ 01/15/25 02:51:05.621
  STEP: Confirm that there is only one ControllerRevision @ 01/15/25 02:51:05.628
  I0115 02:51:05.628240 24 controller_revision.go:254] Requesting list of ControllerRevisions to confirm quantity
  I0115 02:51:05.634316 24 controller_revision.go:265] Found 1 ControllerRevisions
  I0115 02:51:05.663235 24 controller_revision.go:246] ControllerRevision "e2e-zb75t-daemon-set-7c86db9fc9" has revision 3
  STEP: Deleting DaemonSet "e2e-zb75t-daemon-set" @ 01/15/25 02:51:05.683
  STEP: deleting DaemonSet.extensions e2e-zb75t-daemon-set in namespace controllerrevisions-2794, will wait for the garbage collector to delete the pods @ 01/15/25 02:51:05.683
  I0115 02:51:05.746232 24 resources.go:139] Deleting DaemonSet.extensions e2e-zb75t-daemon-set took: 7.042837ms
  I0115 02:51:05.847860 24 resources.go:163] Terminating DaemonSet.extensions e2e-zb75t-daemon-set pods took: 101.614997ms
  E0115 02:51:06.167016      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:51:07.168225      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:51:07.952495 24 fixtures.go:126] Number of nodes with available pods controlled by daemonset e2e-zb75t-daemon-set: 0
  I0115 02:51:07.952565 24 fixtures.go:136] Number of running nodes: 0, number of available pods: 0 in daemonset e2e-zb75t-daemon-set
  I0115 02:51:07.956623 24 controller_revision.go:73] daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"186176"},"items":null}

  I0115 02:51:07.960376 24 controller_revision.go:78] pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"186176"},"items":null}

  I0115 02:51:07.978109 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "controllerrevisions-2794" for this suite. @ 01/15/25 02:51:07.982
• [4.653 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:154
  STEP: Creating a kubernetes client @ 01/15/25 02:51:07.991
  I0115 02:51:07.991657 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename tables @ 01/15/25 02:51:07.992
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:51:08.01
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:51:08.014
  I0115 02:51:08.029476 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "tables-867" for this suite. @ 01/15/25 02:51:08.077
• [0.137 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:237
  STEP: Creating a kubernetes client @ 01/15/25 02:51:08.129
  I0115 02:51:08.129067 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename projected @ 01/15/25 02:51:08.131
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:51:08.156
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:51:08.162
  E0115 02:51:08.168294      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Creating a pod to test downward API volume plugin @ 01/15/25 02:51:08.17
  E0115 02:51:09.171639      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:51:10.171819      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:51:11.172263      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:51:12.172903      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 02:51:12.224
  I0115 02:51:12.227858 24 output.go:207] Trying to get logs from node 192.168.18.92 pod downwardapi-volume-2f8ebace-52f4-447f-83fc-26833fff2a83 container client-container: <nil>
  STEP: delete the pod @ 01/15/25 02:51:12.243
  I0115 02:51:12.256559 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6550" for this suite. @ 01/15/25 02:51:12.262
• [4.140 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:310
  STEP: Creating a kubernetes client @ 01/15/25 02:51:12.269
  I0115 02:51:12.269378 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename crd-publish-openapi @ 01/15/25 02:51:12.27
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:51:12.284
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:51:12.289
  STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation @ 01/15/25 02:51:12.294
  I0115 02:51:12.295415 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  E0115 02:51:13.173941      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:51:14.175286      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:51:15.176321      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:51:16.178940      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:51:17.180608      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:51:18.183457      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:51:19.187823      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:51:20.184549      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:51:21.185623      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:51:22.186505      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation @ 01/15/25 02:51:22.711
  I0115 02:51:22.712643 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  E0115 02:51:23.187099      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:51:24.188465      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:51:24.204272 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  E0115 02:51:25.193607      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:51:26.200327      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:51:27.202520      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:51:28.205497      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:51:29.205174      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:51:30.205907      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:51:31.131256 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-1738" for this suite. @ 01/15/25 02:51:31.144
• [18.882 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:241
  STEP: Creating a kubernetes client @ 01/15/25 02:51:31.151
  I0115 02:51:31.151648 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename configmap @ 01/15/25 02:51:31.152
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:51:31.17
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:51:31.176
  E0115 02:51:31.206887      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Creating configMap with name cm-test-opt-del-cd3f35bd-7efd-4891-84a8-a306c16c0629 @ 01/15/25 02:51:31.25
  STEP: Creating configMap with name cm-test-opt-upd-92c17436-4c68-452d-908a-8dc12bb7ebd2 @ 01/15/25 02:51:31.285
  STEP: Creating the pod @ 01/15/25 02:51:31.296
  E0115 02:51:32.207653      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:51:33.207828      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Deleting configmap cm-test-opt-del-cd3f35bd-7efd-4891-84a8-a306c16c0629 @ 01/15/25 02:51:33.374
  STEP: Updating configmap cm-test-opt-upd-92c17436-4c68-452d-908a-8dc12bb7ebd2 @ 01/15/25 02:51:33.384
  STEP: Creating configMap with name cm-test-opt-create-ca8cfb1c-282a-4301-bd22-2d17c615695e @ 01/15/25 02:51:33.391
  STEP: waiting to observe update in volume @ 01/15/25 02:51:33.4
  E0115 02:51:34.210387      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:51:35.211464      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:51:35.635866 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-7555" for this suite. @ 01/15/25 02:51:35.648
• [4.525 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:256
  STEP: Creating a kubernetes client @ 01/15/25 02:51:35.676
  I0115 02:51:35.676902 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename init-container @ 01/15/25 02:51:35.7
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:51:35.766
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:51:35.783
  STEP: creating the pod @ 01/15/25 02:51:35.804
  I0115 02:51:35.804953 24 init_container.go:294] PodSpec: initContainers in spec.initContainers
  E0115 02:51:36.218092      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:51:37.219341      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:51:38.219983      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:51:39.221023      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:51:40.222865      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:51:41.224342      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:51:42.229566      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:51:43.235542      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:51:44.232183      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:51:44.598994 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-1598" for this suite. @ 01/15/25 02:51:44.648
• [9.016 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should support configurable pod DNS nameservers [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:436
  STEP: Creating a kubernetes client @ 01/15/25 02:51:44.704
  I0115 02:51:44.704574 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename dns @ 01/15/25 02:51:44.709
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:51:44.76
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:51:44.771
  STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... @ 01/15/25 02:51:44.784
  I0115 02:51:44.819120 24 dns.go:448] Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-9302  892371b8-4d6a-40c4-a86b-4d8b9595bf5b 186414 0 2025-01-15 02:51:44 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2025-01-15 02:51:44 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2nj7k,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},ClusterTrustBundle:nil,},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,ClusterTrustBundle:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,ClusterTrustBundle:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,Image:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.53,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2nj7k,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,RecursiveReadOnly:nil,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,AppArmorProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},RestartPolicy:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,AppArmorProfile:nil,SupplementalGroupsPolicy:nil,SELinuxChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},Resources:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,ResourceClaimStatuses:[]PodResourceClaimStatus{},HostIPs:[]HostIP{},},}
  E0115 02:51:45.237000      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:51:46.236862      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:51:47.239401      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:51:48.241383      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Verifying customized DNS suffix list is configured on pod... @ 01/15/25 02:51:48.87
  I0115 02:51:48.871160 24 exec_util.go:59] ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-9302 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0115 02:51:48.871214 24 exec_util.go:64] ExecWithOptions: Clientset creation
  I0115 02:51:48.871348 24 exec_util.go:80] ExecWithOptions: execute(POST https://169.169.0.1:443/api/v1/namespaces/dns-9302/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&stderr=true&stdout=true)
  E0115 02:51:49.244066      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Verifying customized DNS server is configured on pod... @ 01/15/25 02:51:49.253
  I0115 02:51:49.253285 24 exec_util.go:59] ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-9302 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0115 02:51:49.253329 24 exec_util.go:64] ExecWithOptions: Clientset creation
  I0115 02:51:49.253480 24 exec_util.go:80] ExecWithOptions: execute(POST https://169.169.0.1:443/api/v1/namespaces/dns-9302/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&stderr=true&stdout=true)
  I0115 02:51:49.531741 24 dns.go:450] Deleting pod test-dns-nameservers...
  I0115 02:51:49.572732 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-9302" for this suite. @ 01/15/25 02:51:49.62
• [4.954 seconds]
------------------------------
S
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Environment:NotInUserNS] [Conformance] [sig-node, NodeConformance, Environment:NotInUserNS, Conformance]
k8s.io/kubernetes/test/e2e/common/node/sysctl.go:79
  STEP: Creating a kubernetes client @ 01/15/25 02:51:49.657
  I0115 02:51:49.657626 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename sysctl @ 01/15/25 02:51:49.667
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:51:49.853
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:51:49.99
  STEP: Creating a pod with the kernel.shm_rmid_forced sysctl @ 01/15/25 02:51:50.051
  STEP: Watching for error events or started pod @ 01/15/25 02:51:50.106
  E0115 02:51:50.243856      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:51:51.243612      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:51:52.243828      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:51:53.244130      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:51:54.244343      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:51:55.244833      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Waiting for pod completion @ 01/15/25 02:51:56.122
  E0115 02:51:56.246507      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:51:57.247183      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Checking that the pod succeeded @ 01/15/25 02:51:58.175
  STEP: Getting logs from the pod @ 01/15/25 02:51:58.175
  STEP: Checking that the sysctl is actually updated @ 01/15/25 02:51:58.21
  I0115 02:51:58.210832 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-7371" for this suite. @ 01/15/25 02:51:58.23
  E0115 02:51:58.247394      24 retrywatcher.go:160] "Watch failed" err="context canceled"
• [8.600 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/endpointslice.go:105
  STEP: Creating a kubernetes client @ 01/15/25 02:51:58.259
  I0115 02:51:58.259228 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename endpointslice @ 01/15/25 02:51:58.262
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:51:58.306
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:51:58.316
  I0115 02:51:58.517659 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-3426" for this suite. @ 01/15/25 02:51:58.531
• [0.289 seconds]
------------------------------
[sig-api-machinery] AggregatedDiscovery should support raw aggregated discovery request for CRDs [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/aggregated_discovery.go:194
  STEP: Creating a kubernetes client @ 01/15/25 02:51:58.549
  I0115 02:51:58.549145 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename aggregateddiscovery @ 01/15/25 02:51:58.554
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:51:58.62
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:51:58.631
  I0115 02:51:58.647972 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  E0115 02:51:59.262524      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:52:00.248833      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:52:01.250985      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:52:01.878221 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregateddiscovery-9966" for this suite. @ 01/15/25 02:52:01.9
• [3.378 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:56
  STEP: Creating a kubernetes client @ 01/15/25 02:52:01.927
  I0115 02:52:01.927050 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename projected @ 01/15/25 02:52:01.931
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:52:01.993
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:52:02.002
  STEP: Creating projection with secret that has name projected-secret-test-82e1472b-6751-4eff-beff-e7e8fa81f69b @ 01/15/25 02:52:02.012
  STEP: Creating a pod to test consume secrets @ 01/15/25 02:52:02.022
  E0115 02:52:02.252196      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:52:03.253075      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:52:04.260457      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:52:05.259950      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:52:06.260918      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:52:07.261071      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 02:52:08.09
  I0115 02:52:08.096698 24 output.go:207] Trying to get logs from node 192.168.18.92 pod pod-projected-secrets-8c558bb9-d4df-4c91-be88-e7b54961e3ab container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 01/15/25 02:52:08.115
  I0115 02:52:08.155879 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9560" for this suite. @ 01/15/25 02:52:08.172
• [6.263 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined should project all components that make up the projection API [Projection] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_combined.go:44
  STEP: Creating a kubernetes client @ 01/15/25 02:52:08.192
  I0115 02:52:08.192271 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename projected @ 01/15/25 02:52:08.196
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:52:08.262
  E0115 02:52:08.261237      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:52:08.281
  STEP: Creating configMap with name configmap-projected-all-test-volume-f6e75d89-c431-4409-a2b4-8c7560ada98d @ 01/15/25 02:52:08.293
  STEP: Creating secret with name secret-projected-all-test-volume-a8f9ee50-78b5-4d75-aafc-cb53b1d8cd54 @ 01/15/25 02:52:08.306
  STEP: Creating a pod to test Check all projections for projected volume plugin @ 01/15/25 02:52:08.322
  W0115 02:52:08.344641      24 warnings.go:70] volume "podinfo" (Projected): overlapping paths: "podname" (DownwardAPI) with "podname" (DownwardAPI)
  E0115 02:52:09.290630      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:52:10.293549      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:52:11.305043      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:52:12.305580      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:52:13.306505      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:52:14.309231      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 02:52:14.435
  I0115 02:52:14.497441 24 output.go:207] Trying to get logs from node 192.168.18.92 pod projected-volume-23715468-682e-4906-926f-30c5dd93d9d5 container projected-all-volume-test: <nil>
  STEP: delete the pod @ 01/15/25 02:52:14.572
  I0115 02:52:14.692182 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2475" for this suite. @ 01/15/25 02:52:14.712
• [6.556 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_secret.go:119
  STEP: Creating a kubernetes client @ 01/15/25 02:52:14.748
  I0115 02:52:14.748789 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename projected @ 01/15/25 02:52:14.754
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:52:14.8
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:52:14.812
  STEP: Creating secret with name projected-secret-test-a9ad2a6c-0a1e-4ce9-bf9d-f4ef2bea43d9 @ 01/15/25 02:52:14.825
  STEP: Creating a pod to test consume secrets @ 01/15/25 02:52:14.838
  E0115 02:52:15.310205      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:52:16.310883      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:52:17.311282      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:52:18.311939      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:52:19.312217      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:52:20.322223      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 02:52:20.948
  I0115 02:52:20.967107 24 output.go:207] Trying to get logs from node 192.168.18.92 pod pod-projected-secrets-6a37892c-4191-4099-9415-ac123aa4da7e container secret-volume-test: <nil>
  STEP: delete the pod @ 01/15/25 02:52:20.988
  I0115 02:52:21.032469 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4814" for this suite. @ 01/15/25 02:52:21.047
• [6.318 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:407
  STEP: Creating a kubernetes client @ 01/15/25 02:52:21.071
  I0115 02:52:21.071340 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename job @ 01/15/25 02:52:21.079
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:52:21.19
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:52:21.229
  STEP: Creating Indexed job @ 01/15/25 02:52:21.246
  STEP: Ensuring job reaches completions @ 01/15/25 02:52:21.259
  E0115 02:52:21.329909      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:52:22.325640      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:52:23.326927      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:52:24.328350      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:52:25.355842      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:52:26.366104      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:52:27.470005      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:52:28.470957      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:52:29.473210      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:52:30.479364      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:52:31.483955      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:52:32.488759      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:52:33.497543      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:52:34.497635      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:52:35.502400      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:52:36.503022      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:52:37.511940      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:52:38.512652      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:52:39.516163      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Ensuring pods with index for job exist @ 01/15/25 02:52:39.753
  I0115 02:52:39.769147 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-5062" for this suite. @ 01/15/25 02:52:39.781
• [18.728 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:248
  STEP: Creating a kubernetes client @ 01/15/25 02:52:39.799
  I0115 02:52:39.799668 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename container-runtime @ 01/15/25 02:52:39.802
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:52:39.842
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:52:39.856
  STEP: create the container @ 01/15/25 02:52:39.87
  W0115 02:52:39.895863      24 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 01/15/25 02:52:39.896
  E0115 02:52:40.517430      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:52:41.521037      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:52:42.521764      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:52:43.541101      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:52:44.541625      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:52:45.543023      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: get the container status @ 01/15/25 02:52:45.991
  STEP: the container should be terminated @ 01/15/25 02:52:45.999
  STEP: the termination message should be set @ 01/15/25 02:52:45.999
  I0115 02:52:45.999981 24 runtime.go:167] Expected: &{OK} to match Container's Termination Message: OK --
  STEP: delete the container @ 01/15/25 02:52:46
  I0115 02:52:46.055449 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-9241" for this suite. @ 01/15/25 02:52:46.074
• [6.294 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/discovery.go:126
  STEP: Creating a kubernetes client @ 01/15/25 02:52:46.094
  I0115 02:52:46.094065 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename discovery @ 01/15/25 02:52:46.095
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:52:46.157
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:52:46.177
  STEP: Setting up server cert @ 01/15/25 02:52:46.202
  E0115 02:52:46.547033      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:52:46.962688 24 discovery.go:139] Checking APIGroup: apiregistration.k8s.io
  I0115 02:52:46.967829 24 discovery.go:147] PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
  I0115 02:52:46.967934 24 discovery.go:148] Versions found [{apiregistration.k8s.io/v1 v1}]
  I0115 02:52:46.967957 24 discovery.go:154] apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
  I0115 02:52:46.967977 24 discovery.go:139] Checking APIGroup: apps
  I0115 02:52:46.972146 24 discovery.go:147] PreferredVersion.GroupVersion: apps/v1
  I0115 02:52:46.972266 24 discovery.go:148] Versions found [{apps/v1 v1}]
  I0115 02:52:46.972295 24 discovery.go:154] apps/v1 matches apps/v1
  I0115 02:52:46.972316 24 discovery.go:139] Checking APIGroup: events.k8s.io
  I0115 02:52:46.974573 24 discovery.go:147] PreferredVersion.GroupVersion: events.k8s.io/v1
  I0115 02:52:46.974713 24 discovery.go:148] Versions found [{events.k8s.io/v1 v1}]
  I0115 02:52:46.974745 24 discovery.go:154] events.k8s.io/v1 matches events.k8s.io/v1
  I0115 02:52:46.974765 24 discovery.go:139] Checking APIGroup: authentication.k8s.io
  I0115 02:52:46.977613 24 discovery.go:147] PreferredVersion.GroupVersion: authentication.k8s.io/v1
  I0115 02:52:46.977713 24 discovery.go:148] Versions found [{authentication.k8s.io/v1 v1}]
  I0115 02:52:46.977741 24 discovery.go:154] authentication.k8s.io/v1 matches authentication.k8s.io/v1
  I0115 02:52:46.977759 24 discovery.go:139] Checking APIGroup: authorization.k8s.io
  I0115 02:52:46.981083 24 discovery.go:147] PreferredVersion.GroupVersion: authorization.k8s.io/v1
  I0115 02:52:46.981163 24 discovery.go:148] Versions found [{authorization.k8s.io/v1 v1}]
  I0115 02:52:46.981187 24 discovery.go:154] authorization.k8s.io/v1 matches authorization.k8s.io/v1
  I0115 02:52:46.981207 24 discovery.go:139] Checking APIGroup: autoscaling
  I0115 02:52:46.985330 24 discovery.go:147] PreferredVersion.GroupVersion: autoscaling/v2
  I0115 02:52:46.985496 24 discovery.go:148] Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1}]
  I0115 02:52:46.985532 24 discovery.go:154] autoscaling/v2 matches autoscaling/v2
  I0115 02:52:46.985551 24 discovery.go:139] Checking APIGroup: batch
  I0115 02:52:46.993003 24 discovery.go:147] PreferredVersion.GroupVersion: batch/v1
  I0115 02:52:46.993087 24 discovery.go:148] Versions found [{batch/v1 v1}]
  I0115 02:52:46.993111 24 discovery.go:154] batch/v1 matches batch/v1
  I0115 02:52:46.993131 24 discovery.go:139] Checking APIGroup: certificates.k8s.io
  I0115 02:52:46.997401 24 discovery.go:147] PreferredVersion.GroupVersion: certificates.k8s.io/v1
  I0115 02:52:46.997546 24 discovery.go:148] Versions found [{certificates.k8s.io/v1 v1}]
  I0115 02:52:46.997589 24 discovery.go:154] certificates.k8s.io/v1 matches certificates.k8s.io/v1
  I0115 02:52:46.997609 24 discovery.go:139] Checking APIGroup: networking.k8s.io
  I0115 02:52:47.003309 24 discovery.go:147] PreferredVersion.GroupVersion: networking.k8s.io/v1
  I0115 02:52:47.003404 24 discovery.go:148] Versions found [{networking.k8s.io/v1 v1}]
  I0115 02:52:47.003427 24 discovery.go:154] networking.k8s.io/v1 matches networking.k8s.io/v1
  I0115 02:52:47.003445 24 discovery.go:139] Checking APIGroup: policy
  I0115 02:52:47.006952 24 discovery.go:147] PreferredVersion.GroupVersion: policy/v1
  I0115 02:52:47.007094 24 discovery.go:148] Versions found [{policy/v1 v1}]
  I0115 02:52:47.007130 24 discovery.go:154] policy/v1 matches policy/v1
  I0115 02:52:47.007150 24 discovery.go:139] Checking APIGroup: rbac.authorization.k8s.io
  I0115 02:52:47.010849 24 discovery.go:147] PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
  I0115 02:52:47.010927 24 discovery.go:148] Versions found [{rbac.authorization.k8s.io/v1 v1}]
  I0115 02:52:47.010950 24 discovery.go:154] rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
  I0115 02:52:47.010971 24 discovery.go:139] Checking APIGroup: storage.k8s.io
  I0115 02:52:47.014126 24 discovery.go:147] PreferredVersion.GroupVersion: storage.k8s.io/v1
  I0115 02:52:47.014232 24 discovery.go:148] Versions found [{storage.k8s.io/v1 v1}]
  I0115 02:52:47.014265 24 discovery.go:154] storage.k8s.io/v1 matches storage.k8s.io/v1
  I0115 02:52:47.014286 24 discovery.go:139] Checking APIGroup: admissionregistration.k8s.io
  I0115 02:52:47.019826 24 discovery.go:147] PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
  I0115 02:52:47.019981 24 discovery.go:148] Versions found [{admissionregistration.k8s.io/v1 v1}]
  I0115 02:52:47.020016 24 discovery.go:154] admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
  I0115 02:52:47.020037 24 discovery.go:139] Checking APIGroup: apiextensions.k8s.io
  I0115 02:52:47.023886 24 discovery.go:147] PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
  I0115 02:52:47.023959 24 discovery.go:148] Versions found [{apiextensions.k8s.io/v1 v1}]
  I0115 02:52:47.023983 24 discovery.go:154] apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
  I0115 02:52:47.024000 24 discovery.go:139] Checking APIGroup: scheduling.k8s.io
  I0115 02:52:47.027061 24 discovery.go:147] PreferredVersion.GroupVersion: scheduling.k8s.io/v1
  I0115 02:52:47.027173 24 discovery.go:148] Versions found [{scheduling.k8s.io/v1 v1}]
  I0115 02:52:47.027203 24 discovery.go:154] scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
  I0115 02:52:47.027223 24 discovery.go:139] Checking APIGroup: coordination.k8s.io
  I0115 02:52:47.030737 24 discovery.go:147] PreferredVersion.GroupVersion: coordination.k8s.io/v1
  I0115 02:52:47.030832 24 discovery.go:148] Versions found [{coordination.k8s.io/v1 v1}]
  I0115 02:52:47.030852 24 discovery.go:154] coordination.k8s.io/v1 matches coordination.k8s.io/v1
  I0115 02:52:47.030865 24 discovery.go:139] Checking APIGroup: node.k8s.io
  I0115 02:52:47.035145 24 discovery.go:147] PreferredVersion.GroupVersion: node.k8s.io/v1
  I0115 02:52:47.035485 24 discovery.go:148] Versions found [{node.k8s.io/v1 v1}]
  I0115 02:52:47.035538 24 discovery.go:154] node.k8s.io/v1 matches node.k8s.io/v1
  I0115 02:52:47.035560 24 discovery.go:139] Checking APIGroup: discovery.k8s.io
  I0115 02:52:47.040594 24 discovery.go:147] PreferredVersion.GroupVersion: discovery.k8s.io/v1
  I0115 02:52:47.040715 24 discovery.go:148] Versions found [{discovery.k8s.io/v1 v1}]
  I0115 02:52:47.040746 24 discovery.go:154] discovery.k8s.io/v1 matches discovery.k8s.io/v1
  I0115 02:52:47.040767 24 discovery.go:139] Checking APIGroup: flowcontrol.apiserver.k8s.io
  I0115 02:52:47.043841 24 discovery.go:147] PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1
  I0115 02:52:47.043951 24 discovery.go:148] Versions found [{flowcontrol.apiserver.k8s.io/v1 v1}]
  I0115 02:52:47.043984 24 discovery.go:154] flowcontrol.apiserver.k8s.io/v1 matches flowcontrol.apiserver.k8s.io/v1
  I0115 02:52:47.043998 24 discovery.go:139] Checking APIGroup: crd.projectcalico.org
  I0115 02:52:47.047923 24 discovery.go:147] PreferredVersion.GroupVersion: crd.projectcalico.org/v1
  I0115 02:52:47.048040 24 discovery.go:148] Versions found [{crd.projectcalico.org/v1 v1}]
  I0115 02:52:47.048072 24 discovery.go:154] crd.projectcalico.org/v1 matches crd.projectcalico.org/v1
  I0115 02:52:47.048285 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "discovery-8963" for this suite. @ 01/15/25 02:52:47.061
• [0.984 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:110
  STEP: Creating a kubernetes client @ 01/15/25 02:52:47.079
  I0115 02:52:47.080003 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename projected @ 01/15/25 02:52:47.091
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:52:47.13
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:52:47.145
  STEP: Creating configMap with name projected-configmap-test-volume-map-3abd3bbe-74dd-441e-97de-142f03deed1a @ 01/15/25 02:52:47.159
  STEP: Creating a pod to test consume configMaps @ 01/15/25 02:52:47.179
  E0115 02:52:47.548200      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:52:48.551234      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:52:49.560102      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:52:50.563498      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:52:51.575014      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:52:52.575806      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 02:52:53.253
  I0115 02:52:53.259688 24 output.go:207] Trying to get logs from node 192.168.18.92 pod pod-projected-configmaps-5bfb3f32-953b-43bc-af26-f7466f2af851 container agnhost-container: <nil>
  STEP: delete the pod @ 01/15/25 02:52:53.273
  I0115 02:52:53.298200 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8437" for this suite. @ 01/15/25 02:52:53.306
• [6.237 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:495
  STEP: Creating a kubernetes client @ 01/15/25 02:52:53.316
  I0115 02:52:53.316622 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename webhook @ 01/15/25 02:52:53.318
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:52:53.341
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:52:53.349
  STEP: Setting up server cert @ 01/15/25 02:52:53.471
  E0115 02:52:53.576990      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:52:54.577524      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 01/15/25 02:52:55.034
  STEP: Deploying the webhook pod @ 01/15/25 02:52:55.047
  STEP: Wait for the deployment to be ready @ 01/15/25 02:52:55.063
  I0115 02:52:55.074751 24 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0115 02:52:55.577997      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:52:56.578761      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 01/15/25 02:52:57.097
  STEP: Verifying the service has paired with the endpoint @ 01/15/25 02:52:57.12
  E0115 02:52:57.580560      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:52:58.122143 24 util.go:423] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Creating a mutating webhook configuration @ 01/15/25 02:52:58.137
  STEP: Updating a mutating webhook configuration's rules to not include the create operation @ 01/15/25 02:52:58.185
  STEP: Creating a configMap that should not be mutated @ 01/15/25 02:52:58.194
  STEP: Patching a mutating webhook configuration's rules to include the create operation @ 01/15/25 02:52:58.213
  STEP: Creating a configMap that should be mutated @ 01/15/25 02:52:58.222
  I0115 02:52:58.489305 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8530" for this suite. @ 01/15/25 02:52:58.501
  STEP: Destroying namespace "webhook-markers-28" for this suite. @ 01/15/25 02:52:58.528
• [5.227 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/disruption.go:111
  STEP: Creating a kubernetes client @ 01/15/25 02:52:58.543
  I0115 02:52:58.543416 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename disruption @ 01/15/25 02:52:58.548
  E0115 02:52:58.581404      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:52:58.622
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:52:58.63
  STEP: creating the pdb @ 01/15/25 02:52:58.637
  STEP: Waiting for the pdb to be processed @ 01/15/25 02:52:58.646
  E0115 02:52:59.582268      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:53:00.582801      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: updating the pdb @ 01/15/25 02:53:00.684
  STEP: Waiting for the pdb to be processed @ 01/15/25 02:53:00.743
  STEP: patching the pdb @ 01/15/25 02:53:00.767
  STEP: Waiting for the pdb to be processed @ 01/15/25 02:53:00.79
  E0115 02:53:01.583993      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:53:02.584552      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Waiting for the pdb to be deleted @ 01/15/25 02:53:02.862
  I0115 02:53:02.875443 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-8228" for this suite. @ 01/15/25 02:53:02.885
• [4.350 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:175
  STEP: Creating a kubernetes client @ 01/15/25 02:53:02.893
  I0115 02:53:02.893454 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename projected @ 01/15/25 02:53:02.894
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:53:02.911
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:53:02.918
  STEP: Creating configMap with name cm-test-opt-del-ac0f7dad-547d-4ebe-a768-7b2f2839fd60 @ 01/15/25 02:53:02.985
  STEP: Creating configMap with name cm-test-opt-upd-116cac06-cb60-446c-a5a3-35e98e97230e @ 01/15/25 02:53:02.99
  STEP: Creating the pod @ 01/15/25 02:53:02.997
  E0115 02:53:03.585766      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:53:04.587292      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:53:05.587690      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:53:06.589882      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Deleting configmap cm-test-opt-del-ac0f7dad-547d-4ebe-a768-7b2f2839fd60 @ 01/15/25 02:53:07.154
  STEP: Updating configmap cm-test-opt-upd-116cac06-cb60-446c-a5a3-35e98e97230e @ 01/15/25 02:53:07.167
  STEP: Creating configMap with name cm-test-opt-create-c4176209-cc20-4178-911d-bd7f574fa13e @ 01/15/25 02:53:07.182
  STEP: waiting to observe update in volume @ 01/15/25 02:53:07.193
  E0115 02:53:07.598748      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:53:08.591594      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:53:09.592472      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:53:10.593557      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:53:11.594514      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:53:12.595282      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:53:13.602999      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:53:14.603740      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:53:15.603976      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:53:16.617093      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:53:17.617986      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:53:18.624369      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:53:19.620838      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:53:20.622658      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:53:21.623031      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:53:22.623700      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:53:23.624154      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:53:24.625577      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:53:25.626225      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:53:26.627593      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:53:27.628506      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:53:28.629901      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:53:29.630511      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:53:30.631285      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:53:31.631660      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:53:32.635551      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:53:33.637006      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:53:34.636902      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:53:35.637917      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:53:36.641784      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:53:37.640811      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:53:38.642192      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:53:39.643820      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:53:40.643921      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:53:41.644772      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:53:42.646313      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:53:43.647060      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:53:44.650010      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:53:45.652438      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:53:46.653186      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:53:47.655772      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:53:48.657742      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:53:49.666798      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:53:50.668302      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:53:51.668884      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:53:52.670051      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:53:53.672053      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:53:54.672732      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:53:55.673295      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:53:56.675861      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:53:57.678664      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:53:58.678531      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:53:59.679731      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:54:00.680991      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:54:01.682028      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:54:02.683412      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:54:03.684681      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:54:04.685694      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:54:05.686918      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:54:06.687041      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:54:07.688167      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:54:08.689030      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:54:09.689541      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:54:10.690837      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:54:11.691199      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:54:12.694347      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:54:13.694760      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:54:14.696085      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:54:15.696620      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:54:16.697052      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:54:17.698456      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:54:18.699944      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:54:19.699781      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:54:20.700092      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:54:21.700886      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:54:22.700943      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:54:23.701248      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:54:24.702231      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:54:25.703494      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:54:26.704427      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:54:27.705012      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:54:28.528321 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5285" for this suite. @ 01/15/25 02:54:28.534
• [85.653 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/cronjob.go:168
  STEP: Creating a kubernetes client @ 01/15/25 02:54:28.547
  I0115 02:54:28.547410 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename cronjob @ 01/15/25 02:54:28.548
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:54:28.615
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:54:28.626
  STEP: Creating a ReplaceConcurrent cronjob @ 01/15/25 02:54:28.638
  STEP: Ensuring a job is scheduled @ 01/15/25 02:54:28.645
  E0115 02:54:28.706100      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:54:29.706773      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:54:30.707042      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:54:31.707645      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:54:32.708955      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:54:33.709574      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:54:34.710737      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:54:35.713035      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:54:36.713121      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:54:37.713850      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:54:38.714524      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:54:39.715180      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:54:40.715470      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:54:41.716298      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:54:42.717025      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:54:43.719035      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:54:44.719194      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:54:45.719558      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:54:46.721520      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:54:47.723072      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:54:48.725666      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:54:49.725678      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:54:50.726565      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:54:51.728904      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:54:52.728798      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:54:53.728919      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:54:54.729786      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:54:55.731671      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:54:56.733751      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:54:57.736169      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:54:58.737092      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:54:59.738473      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Ensuring exactly one is scheduled @ 01/15/25 02:55:00.673
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 01/15/25 02:55:00.73
  E0115 02:55:00.745430      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Ensuring the job is replaced with a new one @ 01/15/25 02:55:00.776
  E0115 02:55:01.746269      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:55:02.746820      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:55:03.747287      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:55:04.748773      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:55:05.750663      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:55:06.751462      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:55:07.751970      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:55:08.752940      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:55:09.754770      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:55:10.755186      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:55:11.756117      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:55:12.758068      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:55:13.759397      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:55:14.760807      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:55:15.762041      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:55:16.762799      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:55:17.763765      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:55:18.765493      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:55:19.766671      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:55:20.766767      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:55:21.768136      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:55:22.769252      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:55:23.769936      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:55:24.770394      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:55:25.770957      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:55:26.771798      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:55:27.772825      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:55:28.773834      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:55:29.774708      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:55:30.775879      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:55:31.777578      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:55:32.778771      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:55:33.779485      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:55:34.779663      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:55:35.780865      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:55:36.781310      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:55:37.782112      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:55:38.783930      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:55:39.784506      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:55:40.785781      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:55:41.787270      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:55:42.788156      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:55:43.790020      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:55:44.791698      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:55:45.792637      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:55:46.794320      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:55:47.795210      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:55:48.801205      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:55:49.811239      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:55:50.812223      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:55:51.816427      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:55:52.814927      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:55:53.816439      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:55:54.816966      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:55:55.818637      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:55:56.820301      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:55:57.852717      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:55:58.853740      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:55:59.853868      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Removing cronjob @ 01/15/25 02:56:00.785
  I0115 02:56:00.801335 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-6313" for this suite. @ 01/15/25 02:56:00.814
• [92.278 seconds]
------------------------------
SSSSS
------------------------------
[sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/hostport.go:63
  STEP: Creating a kubernetes client @ 01/15/25 02:56:00.825
  I0115 02:56:00.825472 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename hostport @ 01/15/25 02:56:00.828
  E0115 02:56:00.854074      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:56:00.867
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:56:00.878
  STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled @ 01/15/25 02:56:00.921
  E0115 02:56:01.854993      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:56:02.861663      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:56:03.862895      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:56:04.863293      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 192.168.18.92 on the node which pod1 resides and expect scheduled @ 01/15/25 02:56:05.016
  E0115 02:56:05.864341      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:56:06.870013      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:56:07.869622      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:56:08.869875      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 192.168.18.92 but use UDP protocol on the node which pod2 resides @ 01/15/25 02:56:09.075
  E0115 02:56:09.871009      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:56:10.871847      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:56:11.872458      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:56:12.873009      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:56:13.878903      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:56:14.879680      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 @ 01/15/25 02:56:15.191
  I0115 02:56:15.191993 24 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 192.168.18.92 http://127.0.0.1:54323/hostname] Namespace:hostport-9876 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0115 02:56:15.192133 24 exec_util.go:64] ExecWithOptions: Clientset creation
  I0115 02:56:15.192315 24 exec_util.go:80] ExecWithOptions: execute(POST https://169.169.0.1:443/api/v1/namespaces/hostport-9876/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+192.168.18.92+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&stderr=true&stdout=true)
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 192.168.18.92, port: 54323 @ 01/15/25 02:56:15.666
  I0115 02:56:15.666443 24 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://192.168.18.92:54323/hostname] Namespace:hostport-9876 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0115 02:56:15.666491 24 exec_util.go:64] ExecWithOptions: Clientset creation
  I0115 02:56:15.666602 24 exec_util.go:80] ExecWithOptions: execute(POST https://169.169.0.1:443/api/v1/namespaces/hostport-9876/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F192.168.18.92%3A54323%2Fhostname&container=e2e-host-exec&stderr=true&stdout=true)
  E0115 02:56:15.885564      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 192.168.18.92, port: 54323 UDP @ 01/15/25 02:56:15.897
  I0115 02:56:15.897754 24 exec_util.go:59] ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 192.168.18.92 54323] Namespace:hostport-9876 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  I0115 02:56:15.897794 24 exec_util.go:64] ExecWithOptions: Clientset creation
  I0115 02:56:15.897903 24 exec_util.go:80] ExecWithOptions: execute(POST https://169.169.0.1:443/api/v1/namespaces/hostport-9876/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+192.168.18.92+54323&container=e2e-host-exec&stderr=true&stdout=true)
  E0115 02:56:16.885702      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:56:17.885815      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:56:18.887005      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:56:19.888864      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:56:20.889593      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:56:21.128562 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "hostport-9876" for this suite. @ 01/15/25 02:56:21.141
• [20.334 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:235
  STEP: Creating a kubernetes client @ 01/15/25 02:56:21.16
  I0115 02:56:21.160636 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename webhook @ 01/15/25 02:56:21.162
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:56:21.293
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:56:21.325
  STEP: Setting up server cert @ 01/15/25 02:56:21.668
  E0115 02:56:21.889643      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:56:22.890801      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:56:23.893888      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 01/15/25 02:56:24.133
  STEP: Deploying the webhook pod @ 01/15/25 02:56:24.227
  STEP: Wait for the deployment to be ready @ 01/15/25 02:56:24.288
  I0115 02:56:24.359452 24 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0115 02:56:24.893913      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:56:25.895486      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:56:26.512170 24 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.January, 15, 2, 56, 24, 0, time.Local), LastTransitionTime:time.Date(2025, time.January, 15, 2, 56, 24, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.January, 15, 2, 56, 24, 0, time.Local), LastTransitionTime:time.Date(2025, time.January, 15, 2, 56, 24, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-bcbfc85d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0115 02:56:26.897563      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:56:27.897903      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 01/15/25 02:56:28.529
  STEP: Verifying the service has paired with the endpoint @ 01/15/25 02:56:28.557
  E0115 02:56:28.898431      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:56:29.562049 24 util.go:423] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API @ 01/15/25 02:56:29.696
  STEP: create a namespace for the webhook @ 01/15/25 02:56:29.878
  E0115 02:56:29.928693      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: create a configmap should be unconditionally rejected by the webhook @ 01/15/25 02:56:29.997
  I0115 02:56:30.304777 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-2994" for this suite. @ 01/15/25 02:56:30.328
  STEP: Destroying namespace "webhook-markers-4776" for this suite. @ 01/15/25 02:56:30.36
  STEP: Destroying namespace "fail-closed-namespace-3652" for this suite. @ 01/15/25 02:56:30.398
• [9.266 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:399
  STEP: Creating a kubernetes client @ 01/15/25 02:56:30.428
  I0115 02:56:30.428835 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename pods @ 01/15/25 02:56:30.431
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:56:30.481
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:56:30.494
  STEP: creating the pod @ 01/15/25 02:56:30.504
  STEP: submitting the pod to kubernetes @ 01/15/25 02:56:30.504
  W0115 02:56:30.530440      24 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  E0115 02:56:30.932097      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:56:31.934884      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:56:32.935934      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:56:33.936571      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:56:34.936810      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:56:35.937721      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: verifying the pod is in kubernetes @ 01/15/25 02:56:36.65
  STEP: updating the pod @ 01/15/25 02:56:36.712
  E0115 02:56:36.939921      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:56:37.299510 24 pod_client.go:173] Successfully updated pod "pod-update-activedeadlineseconds-fe32f881-1996-4d83-9f06-e407c467931e"
  E0115 02:56:37.938702      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:56:38.938641      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:56:39.345832 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-8264" for this suite. @ 01/15/25 02:56:39.364
• [8.965 seconds]
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:100
  STEP: Creating a kubernetes client @ 01/15/25 02:56:39.393
  I0115 02:56:39.393988 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename emptydir @ 01/15/25 02:56:39.395
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:56:39.427
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:56:39.437
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 01/15/25 02:56:39.446
  E0115 02:56:39.938950      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:56:40.939727      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:56:41.940434      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:56:42.940702      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:56:43.950676      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:56:44.947266      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:56:45.948997      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:56:46.950237      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 02:56:47.582
  I0115 02:56:47.595053 24 output.go:207] Trying to get logs from node 192.168.18.92 pod pod-d6edea99-228d-4d0c-a5a7-0be2bf4e7bd6 container test-container: <nil>
  STEP: delete the pod @ 01/15/25 02:56:47.641
  I0115 02:56:47.685075 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-1006" for this suite. @ 01/15/25 02:56:47.697
• [8.319 seconds]
------------------------------
S
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:57
  STEP: Creating a kubernetes client @ 01/15/25 02:56:47.713
  I0115 02:56:47.713817 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename secrets @ 01/15/25 02:56:47.716
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:56:47.753
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:56:47.762
  STEP: Creating secret with name secret-test-17beb112-d07c-417d-b455-d75af3cda291 @ 01/15/25 02:56:47.77
  STEP: Creating a pod to test consume secrets @ 01/15/25 02:56:47.78
  E0115 02:56:47.951384      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:56:48.951601      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:56:49.952916      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:56:50.953790      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 02:56:51.838
  I0115 02:56:51.849681 24 output.go:207] Trying to get logs from node 192.168.18.92 pod pod-secrets-112e8686-e616-45d3-8f65-3317a5145e42 container secret-volume-test: <nil>
  STEP: delete the pod @ 01/15/25 02:56:51.87
  I0115 02:56:51.909651 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-653" for this suite. @ 01/15/25 02:56:51.922
• [4.220 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:746
  STEP: Creating a kubernetes client @ 01/15/25 02:56:51.933
  I0115 02:56:51.933615 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename resourcequota @ 01/15/25 02:56:51.934
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:56:51.953
  E0115 02:56:51.954477      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:56:51.958
  STEP: Creating a ResourceQuota with terminating scope @ 01/15/25 02:56:51.964
  STEP: Ensuring ResourceQuota status is calculated @ 01/15/25 02:56:51.97
  E0115 02:56:52.956120      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:56:53.956932      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota with not terminating scope @ 01/15/25 02:56:53.984
  STEP: Ensuring ResourceQuota status is calculated @ 01/15/25 02:56:54.008
  E0115 02:56:54.957924      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:56:55.960170      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Creating a long running pod @ 01/15/25 02:56:56.03
  STEP: Ensuring resource quota with not terminating scope captures the pod usage @ 01/15/25 02:56:56.057
  E0115 02:56:56.960762      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:56:57.962825      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with terminating scope ignored the pod usage @ 01/15/25 02:56:58.066
  E0115 02:56:58.963274      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:56:59.965072      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 01/15/25 02:57:00.086
  STEP: Ensuring resource quota status released the pod usage @ 01/15/25 02:57:00.118
  E0115 02:57:00.966974      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:57:01.968531      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Creating a terminating pod @ 01/15/25 02:57:02.124
  STEP: Ensuring resource quota with terminating scope captures the pod usage @ 01/15/25 02:57:02.142
  E0115 02:57:02.969035      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:57:03.970224      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with not terminating scope ignored the pod usage @ 01/15/25 02:57:04.151
  E0115 02:57:04.974011      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:57:05.974861      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 01/15/25 02:57:06.156
  STEP: Ensuring resource quota status released the pod usage @ 01/15/25 02:57:06.172
  E0115 02:57:06.976194      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:57:07.978040      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:57:08.188430 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-5827" for this suite. @ 01/15/25 02:57:08.204
• [16.278 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/statefulset.go:968
  STEP: Creating a kubernetes client @ 01/15/25 02:57:08.211
  I0115 02:57:08.211467 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename statefulset @ 01/15/25 02:57:08.212
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:57:08.232
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:57:08.238
  STEP: Creating service test in namespace statefulset-7199 @ 01/15/25 02:57:08.246
  I0115 02:57:08.269902 24 wait.go:40] Found 0 stateful pods, waiting for 1
  E0115 02:57:08.979698      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:57:09.979937      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:57:10.982311      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:57:11.983238      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:57:12.984650      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:57:13.985805      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:57:14.987029      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:57:15.988945      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:57:16.989781      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:57:17.989639      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:57:18.270327 24 wait.go:50] Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: patching the StatefulSet @ 01/15/25 02:57:18.282
  I0115 02:57:18.313936 24 wait.go:50] Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  I0115 02:57:18.314037 24 wait.go:50] Waiting for pod test-ss-1 to enter Running - Ready=true, currently Pending - Ready=false
  E0115 02:57:18.991677      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:57:20.004627      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:57:20.994580      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:57:22.038587      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:57:23.023462      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:57:24.016929      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:57:25.017142      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:57:26.017616      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:57:27.020563      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:57:28.021605      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:57:28.312262 24 wait.go:50] Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  I0115 02:57:28.312517 24 wait.go:50] Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Listing all StatefulSets @ 01/15/25 02:57:28.334
  STEP: Delete all of the StatefulSets @ 01/15/25 02:57:28.35
  STEP: Verify that StatefulSets have been deleted @ 01/15/25 02:57:28.385
  I0115 02:57:28.404396 24 statefulset.go:138] Deleting all statefulset in ns statefulset-7199
  I0115 02:57:28.619371 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-7199" for this suite. @ 01/15/25 02:57:28.691
• [20.527 seconds]
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_downwardapi.go:251
  STEP: Creating a kubernetes client @ 01/15/25 02:57:28.739
  I0115 02:57:28.740042 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename projected @ 01/15/25 02:57:28.748
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:57:28.952
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:57:28.984
  STEP: Creating a pod to test downward API volume plugin @ 01/15/25 02:57:29.005
  E0115 02:57:29.021235      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:57:30.022444      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:57:31.022265      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:57:32.022862      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:57:33.023768      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:57:34.026631      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:57:35.027741      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 02:57:35.111
  I0115 02:57:35.116625 24 output.go:207] Trying to get logs from node 192.168.18.92 pod downwardapi-volume-771a3092-36d1-4a14-b7c9-eec6ae0f6ed2 container client-container: <nil>
  STEP: delete the pod @ 01/15/25 02:57:35.126
  I0115 02:57:35.143383 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5719" for this suite. @ 01/15/25 02:57:35.149
• [6.416 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/garbage_collector.go:714
  STEP: Creating a kubernetes client @ 01/15/25 02:57:35.156
  I0115 02:57:35.156408 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename gc @ 01/15/25 02:57:35.158
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:57:35.176
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:57:35.181
  STEP: create the rc1 @ 01/15/25 02:57:35.249
  STEP: create the rc2 @ 01/15/25 02:57:35.254
  E0115 02:57:36.031429      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:57:37.033633      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:57:38.039460      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:57:39.055640      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:57:40.049512      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:57:41.051325      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well @ 01/15/25 02:57:41.384
  E0115 02:57:42.051764      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:57:43.052435      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:57:44.067890      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:57:45.107751      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:57:46.130138      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:57:47.130528      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:57:48.131311      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:57:49.131473      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: delete the rc simpletest-rc-to-be-deleted @ 01/15/25 02:57:49.252
  STEP: wait for the rc to be deleted @ 01/15/25 02:57:49.413
  E0115 02:57:50.131645      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:57:51.141694      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:57:52.152206      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:57:53.152372      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:57:54.153678      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:57:54.785296 24 garbage_collector.go:762] 71 pods remaining
  I0115 02:57:54.785402 24 garbage_collector.go:769] 71 pods has nil DeletionTimestamp
  I0115 02:57:54.785426 24 garbage_collector.go:770] 
  E0115 02:57:55.185477      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:57:56.171148      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:57:57.181293      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:57:58.182812      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:57:59.191620      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 01/15/25 02:57:59.542
  E0115 02:58:00.194061      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:58:01.196959      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:58:02.199789      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:58:02.242065 24 garbage_collector.go:265] For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  I0115 02:58:02.242256 24 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-28qnt" in namespace "gc-8076"
  I0115 02:58:02.378422 24 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-44v2p" in namespace "gc-8076"
  I0115 02:58:02.643096 24 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-47tj8" in namespace "gc-8076"
  I0115 02:58:02.775458 24 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-48jgp" in namespace "gc-8076"
  I0115 02:58:02.869144 24 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-4gbtk" in namespace "gc-8076"
  I0115 02:58:02.968420 24 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-4hrm4" in namespace "gc-8076"
  I0115 02:58:03.064155 24 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-4pd2n" in namespace "gc-8076"
  E0115 02:58:03.199267      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:58:03.233517 24 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-5bqhq" in namespace "gc-8076"
  I0115 02:58:03.373014 24 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-5d945" in namespace "gc-8076"
  I0115 02:58:03.440257 24 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-644sp" in namespace "gc-8076"
  I0115 02:58:03.507813 24 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-67fkj" in namespace "gc-8076"
  I0115 02:58:03.564949 24 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-6gwhn" in namespace "gc-8076"
  I0115 02:58:03.655070 24 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-6vcml" in namespace "gc-8076"
  I0115 02:58:04.024901 24 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-7fmb2" in namespace "gc-8076"
  I0115 02:58:04.112660 24 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-7hl44" in namespace "gc-8076"
  E0115 02:58:04.200879      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:58:04.259323 24 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-7mrps" in namespace "gc-8076"
  I0115 02:58:04.570092 24 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-7x5xs" in namespace "gc-8076"
  I0115 02:58:04.700364 24 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-82d6s" in namespace "gc-8076"
  I0115 02:58:04.800129 24 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-86zgs" in namespace "gc-8076"
  I0115 02:58:04.912773 24 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-87q2d" in namespace "gc-8076"
  I0115 02:58:05.024691 24 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-89c78" in namespace "gc-8076"
  I0115 02:58:05.156994 24 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-8s7gq" in namespace "gc-8076"
  E0115 02:58:05.205166      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:58:05.222435 24 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-9t7f9" in namespace "gc-8076"
  I0115 02:58:05.305020 24 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-b5dm5" in namespace "gc-8076"
  I0115 02:58:05.394314 24 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-b94pt" in namespace "gc-8076"
  I0115 02:58:05.492714 24 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-bbsnl" in namespace "gc-8076"
  I0115 02:58:05.795646 24 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-bm2bn" in namespace "gc-8076"
  E0115 02:58:06.212103      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:58:06.217299 24 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-brqsx" in namespace "gc-8076"
  I0115 02:58:06.334176 24 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-btspn" in namespace "gc-8076"
  I0115 02:58:06.658918 24 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-c4b7t" in namespace "gc-8076"
  I0115 02:58:06.785522 24 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-cd474" in namespace "gc-8076"
  I0115 02:58:06.888758 24 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-cwh7k" in namespace "gc-8076"
  I0115 02:58:06.994981 24 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-cxcks" in namespace "gc-8076"
  I0115 02:58:07.102353 24 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-dnmpd" in namespace "gc-8076"
  E0115 02:58:07.221082      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:58:07.283325 24 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-dsdq8" in namespace "gc-8076"
  I0115 02:58:07.382486 24 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-f2zgx" in namespace "gc-8076"
  I0115 02:58:07.483161 24 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-fhfrw" in namespace "gc-8076"
  I0115 02:58:07.571068 24 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-flg4l" in namespace "gc-8076"
  I0115 02:58:07.861508 24 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-flvnh" in namespace "gc-8076"
  I0115 02:58:07.985059 24 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-fn6gp" in namespace "gc-8076"
  I0115 02:58:08.210714 24 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-fpwkw" in namespace "gc-8076"
  E0115 02:58:08.222567      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:58:08.500826 24 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-fwgkc" in namespace "gc-8076"
  I0115 02:58:08.691249 24 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-fwrzr" in namespace "gc-8076"
  I0115 02:58:08.958188 24 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-fznvm" in namespace "gc-8076"
  I0115 02:58:09.109812 24 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-gd4sz" in namespace "gc-8076"
  I0115 02:58:09.201531 24 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-gjd5z" in namespace "gc-8076"
  E0115 02:58:09.224221      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:58:09.261381 24 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-glwgf" in namespace "gc-8076"
  I0115 02:58:09.350810 24 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-hjpfq" in namespace "gc-8076"
  I0115 02:58:09.473360 24 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-j8lnt" in namespace "gc-8076"
  I0115 02:58:09.679509 24 delete.go:95] Deleting pod "simpletest-rc-to-be-deleted-jjdg5" in namespace "gc-8076"
  I0115 02:58:09.782624 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-8076" for this suite. @ 01/15/25 02:58:09.819
• [34.726 seconds]
------------------------------
S
------------------------------
[sig-instrumentation] Events API should delete a collection of events [Conformance] [sig-instrumentation, Conformance]
k8s.io/kubernetes/test/e2e/instrumentation/events.go:207
  STEP: Creating a kubernetes client @ 01/15/25 02:58:09.887
  I0115 02:58:09.887722 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename events @ 01/15/25 02:58:09.89
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:58:09.995
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:58:10.028
  STEP: Create set of events @ 01/15/25 02:58:10.071
  E0115 02:58:10.228094      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: get a list of Events with a label in the current namespace @ 01/15/25 02:58:10.261
  STEP: delete a list of events @ 01/15/25 02:58:10.286
  I0115 02:58:10.286284 24 events.go:224] requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 01/15/25 02:58:10.461
  I0115 02:58:10.486209 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-8438" for this suite. @ 01/15/25 02:58:10.522
• [0.674 seconds]
------------------------------
S
------------------------------
[sig-apps] Deployment should run the lifecycle of a Deployment [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/deployment.go:185
  STEP: Creating a kubernetes client @ 01/15/25 02:58:10.561
  I0115 02:58:10.561808 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename deployment @ 01/15/25 02:58:10.565
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:58:10.823
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:58:11.045
  STEP: creating a Deployment @ 01/15/25 02:58:11.136
  STEP: waiting for Deployment to be created @ 01/15/25 02:58:11.177
  STEP: waiting for all Replicas to be Ready @ 01/15/25 02:58:11.183
  I0115 02:58:11.195111 24 deployment.go:246] observed Deployment test-deployment in namespace deployment-4249 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0115 02:58:11.196690 24 deployment.go:248] observed Deployment test-deployment in namespace deployment-4249 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  E0115 02:58:11.233698      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:58:11.348325 24 deployment.go:246] observed Deployment test-deployment in namespace deployment-4249 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0115 02:58:11.348411 24 deployment.go:248] observed Deployment test-deployment in namespace deployment-4249 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0115 02:58:11.419290 24 deployment.go:246] observed Deployment test-deployment in namespace deployment-4249 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0115 02:58:11.419380 24 deployment.go:248] observed Deployment test-deployment in namespace deployment-4249 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0115 02:58:11.837745 24 deployment.go:246] observed Deployment test-deployment in namespace deployment-4249 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  I0115 02:58:11.837845 24 deployment.go:248] observed Deployment test-deployment in namespace deployment-4249 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  E0115 02:58:12.244037      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:58:13.244733      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:58:14.247587      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:58:15.247669      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:58:16.254085      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:58:17.259041      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:58:18.265999      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:58:19.309010      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:58:20.288457      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:58:21.289416      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:58:22.300825      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:58:23.331263      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:58:24.341908      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:58:25.344456      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:58:26.345416      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:58:27.345744      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:58:28.345943      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:58:29.346303      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:58:30.365326      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:58:31.359878      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:58:32.361394      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:58:33.360941      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:58:34.370086      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:58:35.387679      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:58:36.376827      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:58:37.377557      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:58:38.399978      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:58:39.421472      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:58:40.413539      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:58:41.416756      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:58:42.418215      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:58:42.819493 24 deployment.go:246] observed Deployment test-deployment in namespace deployment-4249 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  I0115 02:58:42.819566 24 deployment.go:248] observed Deployment test-deployment in namespace deployment-4249 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  I0115 02:58:42.916698 24 deployment.go:248] observed Deployment test-deployment in namespace deployment-4249 with ReadyReplicas 2 and labels map[test-deployment-static:true]
  STEP: patching the Deployment @ 01/15/25 02:58:42.916
  I0115 02:58:42.955033 24 deployment.go:290] observed event type ADDED
  STEP: waiting for Replicas to scale @ 01/15/25 02:58:42.956
  I0115 02:58:42.964028 24 deployment.go:309] observed Deployment test-deployment in namespace deployment-4249 with ReadyReplicas 0
  I0115 02:58:42.964099 24 deployment.go:311] observed Deployment test-deployment in namespace deployment-4249 with ReadyReplicas 0
  I0115 02:58:42.964123 24 deployment.go:309] observed Deployment test-deployment in namespace deployment-4249 with ReadyReplicas 0
  I0115 02:58:42.964140 24 deployment.go:311] observed Deployment test-deployment in namespace deployment-4249 with ReadyReplicas 0
  I0115 02:58:42.964167 24 deployment.go:309] observed Deployment test-deployment in namespace deployment-4249 with ReadyReplicas 0
  I0115 02:58:42.964247 24 deployment.go:311] observed Deployment test-deployment in namespace deployment-4249 with ReadyReplicas 0
  I0115 02:58:42.964860 24 deployment.go:309] observed Deployment test-deployment in namespace deployment-4249 with ReadyReplicas 0
  I0115 02:58:42.964905 24 deployment.go:311] observed Deployment test-deployment in namespace deployment-4249 with ReadyReplicas 0
  I0115 02:58:42.964928 24 deployment.go:309] observed Deployment test-deployment in namespace deployment-4249 with ReadyReplicas 1
  I0115 02:58:42.964945 24 deployment.go:311] observed Deployment test-deployment in namespace deployment-4249 with ReadyReplicas 1
  I0115 02:58:42.964969 24 deployment.go:309] observed Deployment test-deployment in namespace deployment-4249 with ReadyReplicas 2
  I0115 02:58:42.964986 24 deployment.go:311] observed Deployment test-deployment in namespace deployment-4249 with ReadyReplicas 2
  I0115 02:58:42.965306 24 deployment.go:309] observed Deployment test-deployment in namespace deployment-4249 with ReadyReplicas 2
  I0115 02:58:42.965341 24 deployment.go:311] observed Deployment test-deployment in namespace deployment-4249 with ReadyReplicas 2
  I0115 02:58:43.025892 24 deployment.go:309] observed Deployment test-deployment in namespace deployment-4249 with ReadyReplicas 2
  I0115 02:58:43.025984 24 deployment.go:311] observed Deployment test-deployment in namespace deployment-4249 with ReadyReplicas 2
  I0115 02:58:43.110832 24 deployment.go:309] observed Deployment test-deployment in namespace deployment-4249 with ReadyReplicas 2
  I0115 02:58:43.110904 24 deployment.go:311] observed Deployment test-deployment in namespace deployment-4249 with ReadyReplicas 2
  I0115 02:58:43.200350 24 deployment.go:309] observed Deployment test-deployment in namespace deployment-4249 with ReadyReplicas 1
  I0115 02:58:43.200415 24 deployment.go:311] observed Deployment test-deployment in namespace deployment-4249 with ReadyReplicas 1
  I0115 02:58:43.218241 24 deployment.go:309] observed Deployment test-deployment in namespace deployment-4249 with ReadyReplicas 1
  I0115 02:58:43.218333 24 deployment.go:311] observed Deployment test-deployment in namespace deployment-4249 with ReadyReplicas 1
  E0115 02:58:43.418372      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:58:44.418509      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:58:45.419017      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:58:46.422535      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:58:47.423011      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:58:48.424967      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:58:49.425164      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:58:50.426195      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:58:51.426967      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:58:52.060987 24 deployment.go:309] observed Deployment test-deployment in namespace deployment-4249 with ReadyReplicas 2
  I0115 02:58:52.062618 24 deployment.go:311] observed Deployment test-deployment in namespace deployment-4249 with ReadyReplicas 2
  I0115 02:58:52.221223 24 deployment.go:311] observed Deployment test-deployment in namespace deployment-4249 with ReadyReplicas 1
  STEP: listing Deployments @ 01/15/25 02:58:52.222
  I0115 02:58:52.244373 24 deployment.go:327] Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
  STEP: updating the Deployment @ 01/15/25 02:58:52.244
  I0115 02:58:52.303688 24 deployment.go:360] observed Deployment test-deployment in namespace deployment-4249 with ReadyReplicas 1
  STEP: fetching the DeploymentStatus @ 01/15/25 02:58:52.303
  I0115 02:58:52.335046 24 deployment.go:389] observed Deployment test-deployment in namespace deployment-4249 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  I0115 02:58:52.365620 24 deployment.go:389] observed Deployment test-deployment in namespace deployment-4249 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  E0115 02:58:52.429505      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:58:52.470782 24 deployment.go:389] observed Deployment test-deployment in namespace deployment-4249 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  I0115 02:58:52.553499 24 deployment.go:389] observed Deployment test-deployment in namespace deployment-4249 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  I0115 02:58:52.568862 24 deployment.go:389] observed Deployment test-deployment in namespace deployment-4249 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  E0115 02:58:53.437532      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:58:54.441798      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:58:55.447045      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:58:55.889083 24 deployment.go:389] observed Deployment test-deployment in namespace deployment-4249 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  I0115 02:58:55.977278 24 deployment.go:389] observed Deployment test-deployment in namespace deployment-4249 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
  I0115 02:58:56.051804 24 deployment.go:389] observed Deployment test-deployment in namespace deployment-4249 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  I0115 02:58:56.097794 24 deployment.go:389] observed Deployment test-deployment in namespace deployment-4249 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  E0115 02:58:56.448967      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:58:57.450083      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:58:57.896163 24 deployment.go:389] observed Deployment test-deployment in namespace deployment-4249 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
  STEP: patching the DeploymentStatus @ 01/15/25 02:58:57.942
  STEP: fetching the DeploymentStatus @ 01/15/25 02:58:57.965
  I0115 02:58:57.981520 24 deployment.go:449] observed Deployment test-deployment in namespace deployment-4249 with ReadyReplicas 1
  I0115 02:58:57.982456 24 deployment.go:449] observed Deployment test-deployment in namespace deployment-4249 with ReadyReplicas 1
  I0115 02:58:57.982538 24 deployment.go:449] observed Deployment test-deployment in namespace deployment-4249 with ReadyReplicas 1
  I0115 02:58:57.982712 24 deployment.go:449] observed Deployment test-deployment in namespace deployment-4249 with ReadyReplicas 1
  I0115 02:58:57.982808 24 deployment.go:449] observed Deployment test-deployment in namespace deployment-4249 with ReadyReplicas 1
  I0115 02:58:57.986007 24 deployment.go:449] observed Deployment test-deployment in namespace deployment-4249 with ReadyReplicas 2
  I0115 02:58:57.986121 24 deployment.go:449] observed Deployment test-deployment in namespace deployment-4249 with ReadyReplicas 3
  I0115 02:58:57.986215 24 deployment.go:449] observed Deployment test-deployment in namespace deployment-4249 with ReadyReplicas 2
  I0115 02:58:57.986499 24 deployment.go:449] observed Deployment test-deployment in namespace deployment-4249 with ReadyReplicas 2
  I0115 02:58:57.986902 24 deployment.go:449] observed Deployment test-deployment in namespace deployment-4249 with ReadyReplicas 3
  STEP: deleting the Deployment @ 01/15/25 02:58:57.986
  I0115 02:58:58.009772 24 deployment.go:475] observed event type MODIFIED
  I0115 02:58:58.011998 24 deployment.go:475] observed event type MODIFIED
  I0115 02:58:58.012068 24 deployment.go:475] observed event type MODIFIED
  I0115 02:58:58.014166 24 deployment.go:475] observed event type MODIFIED
  I0115 02:58:58.014297 24 deployment.go:475] observed event type MODIFIED
  I0115 02:58:58.014343 24 deployment.go:475] observed event type MODIFIED
  I0115 02:58:58.015207 24 deployment.go:475] observed event type MODIFIED
  I0115 02:58:58.015269 24 deployment.go:475] observed event type MODIFIED
  I0115 02:58:58.015300 24 deployment.go:475] observed event type MODIFIED
  I0115 02:58:58.016174 24 deployment.go:475] observed event type MODIFIED
  I0115 02:58:58.016253 24 deployment.go:475] observed event type MODIFIED
  I0115 02:58:58.016815 24 deployment.go:475] observed event type MODIFIED
  I0115 02:58:58.017409 24 deployment.go:475] observed event type MODIFIED
  I0115 02:58:58.026560 24 deployment.go:650] Log out all the ReplicaSets if there is no deployment created
  I0115 02:58:58.037907 24 deployment.go:657] ReplicaSet "test-deployment-564597bcc":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=25) "test-deployment-564597bcc",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4249",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "88ca4f48-2e39-45a5-8b54-f81012c5c472",
      ResourceVersion: (string) (len=6) "189612",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872506691,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=9) "564597bcc",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=15) "test-deployment",
          UID: (types.UID) (len=36) "4254be02-9a5c-4af1-be0d-a377a40c825b",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872506732,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=827) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              000000d0  65 2d 68 61 73 68 22 3a  7b 7d 2c 22 66 3a 74 65  |e-hash":{},"f:te|
              000000e0  73 74 2d 64 65 70 6c 6f  79 6d 65 6e 74 2d 73 74  |st-deployment-st|
              000000f0  61 74 69 63 22 3a 7b 7d  7d 2c 22 66 3a 6f 77 6e  |atic":{}},"f:own|
              00000100  65 72 52 65 66 65 72 65  6e 63 65 73 22 3a 7b 22  |erReferences":{"|
              00000110  2e 22 3a 7b 7d 2c 22 6b  3a 7b 5c 22 75 69 64 5c  |.":{},"k:{\"uid\|
              00000120  22 3a 5c 22 34 32 35 34  62 65 30 32 2d 39 61 35  |":\"4254be02-9a5|
              00000130  63 2d 34 61 66 31 2d 62  65 30 64 2d 61 33 37 37  |c-4af1-be0d-a377|
              00000140  61 34 30 63 38 32 35 62  5c 22 7d 22 3a 7b 7d 7d  |a40c825b\"}":{}}|
              00000150  7d 2c 22 66 3a 73 70 65  63 22 3a 7b 22 66 3a 72  |},"f:spec":{"f:r|
              00000160  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 73  |eplicas":{},"f:s|
              00000170  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 74  |elector":{},"f:t|
              00000180  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000190  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              000001a0  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 70 6f  |s":{".":{},"f:po|
              000001b0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001c0  3a 7b 7d 2c 22 66 3a 74  65 73 74 2d 64 65 70 6c  |:{},"f:test-depl|
              000001d0  6f 79 6d 65 6e 74 2d 73  74 61 74 69 63 22 3a 7b  |oyment-static":{|
              000001e0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000200  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 74 65 73  |:{\"name\":\"tes|
              00000210  74 2d 64 65 70 6c 6f 79  6d 65 6e 74 5c 22 7d 22  |t-deployment\"}"|
              00000220  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000230  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000240  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000250  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              00000260  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              00000270  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              00000280  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000290  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000002a0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000002b0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              000002c0  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              000002d0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000002e0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000002f0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000300  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000310  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000320  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000330  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872506732,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=9) "564597bcc",
          (string) (len=22) "test-deployment-static": (string) (len=4) "true"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=17) "pod-template-hash": (string) (len=9) "564597bcc",
            (string) (len=22) "test-deployment-static": (string) (len=4) "true"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=15) "test-deployment",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.53",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(1),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 3,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }


  I0115 02:58:58.057895 24 deployment.go:657] ReplicaSet "test-deployment-79899bcfcc":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=26) "test-deployment-79899bcfcc",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4249",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d631fe86-3fad-4bab-afa1-88d9b0495677",
      ResourceVersion: (string) (len=6) "189702",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872506732,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "79899bcfcc",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "3",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "3",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=15) "test-deployment",
          UID: (types.UID) (len=36) "4254be02-9a5c-4af1-be0d-a377a40c825b",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872506735,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=827) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              000000d0  65 2d 68 61 73 68 22 3a  7b 7d 2c 22 66 3a 74 65  |e-hash":{},"f:te|
              000000e0  73 74 2d 64 65 70 6c 6f  79 6d 65 6e 74 2d 73 74  |st-deployment-st|
              000000f0  61 74 69 63 22 3a 7b 7d  7d 2c 22 66 3a 6f 77 6e  |atic":{}},"f:own|
              00000100  65 72 52 65 66 65 72 65  6e 63 65 73 22 3a 7b 22  |erReferences":{"|
              00000110  2e 22 3a 7b 7d 2c 22 6b  3a 7b 5c 22 75 69 64 5c  |.":{},"k:{\"uid\|
              00000120  22 3a 5c 22 34 32 35 34  62 65 30 32 2d 39 61 35  |":\"4254be02-9a5|
              00000130  63 2d 34 61 66 31 2d 62  65 30 64 2d 61 33 37 37  |c-4af1-be0d-a377|
              00000140  61 34 30 63 38 32 35 62  5c 22 7d 22 3a 7b 7d 7d  |a40c825b\"}":{}}|
              00000150  7d 2c 22 66 3a 73 70 65  63 22 3a 7b 22 66 3a 72  |},"f:spec":{"f:r|
              00000160  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 73  |eplicas":{},"f:s|
              00000170  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 74  |elector":{},"f:t|
              00000180  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000190  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              000001a0  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 70 6f  |s":{".":{},"f:po|
              000001b0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001c0  3a 7b 7d 2c 22 66 3a 74  65 73 74 2d 64 65 70 6c  |:{},"f:test-depl|
              000001d0  6f 79 6d 65 6e 74 2d 73  74 61 74 69 63 22 3a 7b  |oyment-static":{|
              000001e0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000200  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 74 65 73  |:{\"name\":\"tes|
              00000210  74 2d 64 65 70 6c 6f 79  6d 65 6e 74 5c 22 7d 22  |t-deployment\"}"|
              00000220  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000230  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000240  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000250  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              00000260  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              00000270  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              00000280  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000290  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000002a0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000002b0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              000002c0  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              000002d0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000002e0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000002f0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000300  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000310  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000320  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000330  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872506737,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(2),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=10) "79899bcfcc",
          (string) (len=22) "test-deployment-static": (string) (len=4) "true"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=17) "pod-template-hash": (string) (len=10) "79899bcfcc",
            (string) (len=22) "test-deployment-static": (string) (len=4) "true"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=15) "test-deployment",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(1),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 2,
      FullyLabeledReplicas: (int32) 2,
      ReadyReplicas: (int32) 2,
      AvailableReplicas: (int32) 2,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }


  I0115 02:58:58.077761 24 deployment.go:669] pod: "test-deployment-79899bcfcc-lqwj8":
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=32) "test-deployment-79899bcfcc-lqwj8",
      GenerateName: (string) (len=27) "test-deployment-79899bcfcc-",
      Namespace: (string) (len=15) "deployment-4249",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "cba9be2e-dea9-4160-ba4a-329672bf4629",
      ResourceVersion: (string) (len=6) "189701",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872506735,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "79899bcfcc",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "0ffd50e3256adec826316e5556cc51cccbd14c66388ffa199216f750ccd8b20b",
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=14) "10.1.213.75/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=14) "10.1.213.75/32"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=26) "test-deployment-79899bcfcc",
          UID: (types.UID) (len=36) "d631fe86-3fad-4bab-afa1-88d9b0495677",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872506735,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=565) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 70 6f 64 2d 74 65 6d  |.":{},"f:pod-tem|
              00000040  70 6c 61 74 65 2d 68 61  73 68 22 3a 7b 7d 2c 22  |plate-hash":{},"|
              00000050  66 3a 74 65 73 74 2d 64  65 70 6c 6f 79 6d 65 6e  |f:test-deploymen|
              00000060  74 2d 73 74 61 74 69 63  22 3a 7b 7d 7d 2c 22 66  |t-static":{}},"f|
              00000070  3a 6f 77 6e 65 72 52 65  66 65 72 65 6e 63 65 73  |:ownerReferences|
              00000080  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 6b 3a 7b 5c 22  |":{".":{},"k:{\"|
              00000090  75 69 64 5c 22 3a 5c 22  64 36 33 31 66 65 38 36  |uid\":\"d631fe86|
              000000a0  2d 33 66 61 64 2d 34 62  61 62 2d 61 66 61 31 2d  |-3fad-4bab-afa1-|
              000000b0  38 38 64 39 62 30 34 39  35 36 37 37 5c 22 7d 22  |88d9b0495677\"}"|
              000000c0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000000d0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000000e0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 74  |"k:{\"name\":\"t|
              000000f0  65 73 74 2d 64 65 70 6c  6f 79 6d 65 6e 74 5c 22  |est-deployment\"|
              00000100  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000110  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000120  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000130  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000140  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000150  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000160  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000170  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000180  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000190  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              000001a0  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000001b0  3a 7b 7d 2c 22 66 3a 65  6e 61 62 6c 65 53 65 72  |:{},"f:enableSer|
              000001c0  76 69 63 65 4c 69 6e 6b  73 22 3a 7b 7d 2c 22 66  |viceLinks":{},"f|
              000001d0  3a 72 65 73 74 61 72 74  50 6f 6c 69 63 79 22 3a  |:restartPolicy":|
              000001e0  7b 7d 2c 22 66 3a 73 63  68 65 64 75 6c 65 72 4e  |{},"f:schedulerN|
              000001f0  61 6d 65 22 3a 7b 7d 2c  22 66 3a 73 65 63 75 72  |ame":{},"f:secur|
              00000200  69 74 79 43 6f 6e 74 65  78 74 22 3a 7b 7d 2c 22  |ityContext":{},"|
              00000210  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 47 72 61  |f:terminationGra|
              00000220  63 65 50 65 72 69 6f 64  53 65 63 6f 6e 64 73 22  |cePeriodSeconds"|
              00000230  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872506737,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872506737,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 31 2e 32 31 33 2e 37  35 5c 22 7d 22 3a 7b 22  |.1.213.75\"}":{"|
              00000270  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000280  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000290  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-hkkwb",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=15) "test-deployment",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-hkkwb",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(1),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=13) "192.168.18.91",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872506737,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872506736,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872506737,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872506737,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872506735,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "192.168.18.91",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "192.168.18.91"
        }
      },
      PodIP: (string) (len=11) "10.1.213.75",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.1.213.75"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872506736,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=15) "test-deployment",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63872506737,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://6bce1300f5947c04647fca3af15988c2d7c04d5fd59a2442af62122cef0ebd82",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-hkkwb",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }


  I0115 02:58:58.081946 24 deployment.go:669] pod: "test-deployment-79899bcfcc-x2tcq":
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=32) "test-deployment-79899bcfcc-x2tcq",
      GenerateName: (string) (len=27) "test-deployment-79899bcfcc-",
      Namespace: (string) (len=15) "deployment-4249",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "00bee63f-7c52-43fa-be83-4a18740025d9",
      ResourceVersion: (string) (len=6) "189664",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872506732,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "79899bcfcc",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=14) "10.1.155.55/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=14) "10.1.155.55/32",
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "312685b6df322e6f838d255a339603e9e86da1a8b4b955f893b9d0c9223479f2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=26) "test-deployment-79899bcfcc",
          UID: (types.UID) (len=36) "d631fe86-3fad-4bab-afa1-88d9b0495677",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872506732,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=565) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 70 6f 64 2d 74 65 6d  |.":{},"f:pod-tem|
              00000040  70 6c 61 74 65 2d 68 61  73 68 22 3a 7b 7d 2c 22  |plate-hash":{},"|
              00000050  66 3a 74 65 73 74 2d 64  65 70 6c 6f 79 6d 65 6e  |f:test-deploymen|
              00000060  74 2d 73 74 61 74 69 63  22 3a 7b 7d 7d 2c 22 66  |t-static":{}},"f|
              00000070  3a 6f 77 6e 65 72 52 65  66 65 72 65 6e 63 65 73  |:ownerReferences|
              00000080  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 6b 3a 7b 5c 22  |":{".":{},"k:{\"|
              00000090  75 69 64 5c 22 3a 5c 22  64 36 33 31 66 65 38 36  |uid\":\"d631fe86|
              000000a0  2d 33 66 61 64 2d 34 62  61 62 2d 61 66 61 31 2d  |-3fad-4bab-afa1-|
              000000b0  38 38 64 39 62 30 34 39  35 36 37 37 5c 22 7d 22  |88d9b0495677\"}"|
              000000c0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000000d0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000000e0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 74  |"k:{\"name\":\"t|
              000000f0  65 73 74 2d 64 65 70 6c  6f 79 6d 65 6e 74 5c 22  |est-deployment\"|
              00000100  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000110  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000120  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000130  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000140  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000150  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000160  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000170  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000180  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000190  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              000001a0  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000001b0  3a 7b 7d 2c 22 66 3a 65  6e 61 62 6c 65 53 65 72  |:{},"f:enableSer|
              000001c0  76 69 63 65 4c 69 6e 6b  73 22 3a 7b 7d 2c 22 66  |viceLinks":{},"f|
              000001d0  3a 72 65 73 74 61 72 74  50 6f 6c 69 63 79 22 3a  |:restartPolicy":|
              000001e0  7b 7d 2c 22 66 3a 73 63  68 65 64 75 6c 65 72 4e  |{},"f:schedulerN|
              000001f0  61 6d 65 22 3a 7b 7d 2c  22 66 3a 73 65 63 75 72  |ame":{},"f:secur|
              00000200  69 74 79 43 6f 6e 74 65  78 74 22 3a 7b 7d 2c 22  |ityContext":{},"|
              00000210  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 47 72 61  |f:terminationGra|
              00000220  63 65 50 65 72 69 6f 64  53 65 63 6f 6e 64 73 22  |cePeriodSeconds"|
              00000230  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872506733,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872506735,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 31 2e 31 35 35 2e 35  35 5c 22 7d 22 3a 7b 22  |.1.155.55\"}":{"|
              00000270  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000280  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000290  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-mxf5h",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=15) "test-deployment",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-mxf5h",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(1),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=13) "192.168.18.92",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872506735,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872506732,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872506735,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872506735,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872506732,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "192.168.18.92",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "192.168.18.92"
        }
      },
      PodIP: (string) (len=11) "10.1.155.55",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.1.155.55"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872506732,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=15) "test-deployment",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63872506735,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://65b20c3e05df50a15fb3cb225dc54752131f039456692f3405a7963f678ad999",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-mxf5h",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }


  I0115 02:58:58.085655 24 deployment.go:657] ReplicaSet "test-deployment-f78d658f9":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=25) "test-deployment-f78d658f9",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4249",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "bed15b84-8c02-45da-afdc-21e512bdfd7a",
      ResourceVersion: (string) (len=6) "189710",
      Generation: (int64) 4,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872506723,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=22) "test-deployment-static": (string) (len=4) "true",
        (string) (len=17) "pod-template-hash": (string) (len=9) "f78d658f9"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "2",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "3",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=15) "test-deployment",
          UID: (types.UID) (len=36) "4254be02-9a5c-4af1-be0d-a377a40c825b",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872506737,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=827) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              000000d0  65 2d 68 61 73 68 22 3a  7b 7d 2c 22 66 3a 74 65  |e-hash":{},"f:te|
              000000e0  73 74 2d 64 65 70 6c 6f  79 6d 65 6e 74 2d 73 74  |st-deployment-st|
              000000f0  61 74 69 63 22 3a 7b 7d  7d 2c 22 66 3a 6f 77 6e  |atic":{}},"f:own|
              00000100  65 72 52 65 66 65 72 65  6e 63 65 73 22 3a 7b 22  |erReferences":{"|
              00000110  2e 22 3a 7b 7d 2c 22 6b  3a 7b 5c 22 75 69 64 5c  |.":{},"k:{\"uid\|
              00000120  22 3a 5c 22 34 32 35 34  62 65 30 32 2d 39 61 35  |":\"4254be02-9a5|
              00000130  63 2d 34 61 66 31 2d 62  65 30 64 2d 61 33 37 37  |c-4af1-be0d-a377|
              00000140  61 34 30 63 38 32 35 62  5c 22 7d 22 3a 7b 7d 7d  |a40c825b\"}":{}}|
              00000150  7d 2c 22 66 3a 73 70 65  63 22 3a 7b 22 66 3a 72  |},"f:spec":{"f:r|
              00000160  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 73  |eplicas":{},"f:s|
              00000170  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 74  |elector":{},"f:t|
              00000180  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000190  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              000001a0  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 70 6f  |s":{".":{},"f:po|
              000001b0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001c0  3a 7b 7d 2c 22 66 3a 74  65 73 74 2d 64 65 70 6c  |:{},"f:test-depl|
              000001d0  6f 79 6d 65 6e 74 2d 73  74 61 74 69 63 22 3a 7b  |oyment-static":{|
              000001e0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000200  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 74 65 73  |:{\"name\":\"tes|
              00000210  74 2d 64 65 70 6c 6f 79  6d 65 6e 74 5c 22 7d 22  |t-deployment\"}"|
              00000220  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000230  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000240  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000250  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              00000260  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              00000270  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              00000280  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000290  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000002a0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000002b0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              000002c0  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              000002d0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000002e0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000002f0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000300  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000310  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000320  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000330  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872506737,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=9) "f78d658f9",
          (string) (len=22) "test-deployment-static": (string) (len=4) "true"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=17) "pod-template-hash": (string) (len=9) "f78d658f9",
            (string) (len=22) "test-deployment-static": (string) (len=4) "true"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=15) "test-deployment",
              Image: (string) (len=26) "registry.k8s.io/pause:3.10",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>),
                AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(2),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
            SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 4,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }


  I0115 02:58:58.161279 24 deployment.go:669] pod: "test-deployment-f78d658f9-pd5c7":
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=31) "test-deployment-f78d658f9-pd5c7",
      GenerateName: (string) (len=26) "test-deployment-f78d658f9-",
      Namespace: (string) (len=15) "deployment-4249",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "c33d5384-88d3-4950-be28-edf267c41478",
      ResourceVersion: (string) (len=6) "189706",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872506732,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872506739,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      DeletionGracePeriodSeconds: (*int64)(2),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=9) "f78d658f9",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=27) "cni.projectcalico.org/podIP": (string) (len=14) "10.1.213.84/32",
        (string) (len=28) "cni.projectcalico.org/podIPs": (string) (len=14) "10.1.213.84/32",
        (string) (len=33) "cni.projectcalico.org/containerID": (string) (len=64) "4f019325c869318d6ff5468ba78dfa46d3ddfb288bad8380549d14f781a1b01d"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=25) "test-deployment-f78d658f9",
          UID: (types.UID) (len=36) "bed15b84-8c02-45da-afdc-21e512bdfd7a",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872506732,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=565) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 70 6f 64 2d 74 65 6d  |.":{},"f:pod-tem|
              00000040  70 6c 61 74 65 2d 68 61  73 68 22 3a 7b 7d 2c 22  |plate-hash":{},"|
              00000050  66 3a 74 65 73 74 2d 64  65 70 6c 6f 79 6d 65 6e  |f:test-deploymen|
              00000060  74 2d 73 74 61 74 69 63  22 3a 7b 7d 7d 2c 22 66  |t-static":{}},"f|
              00000070  3a 6f 77 6e 65 72 52 65  66 65 72 65 6e 63 65 73  |:ownerReferences|
              00000080  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 6b 3a 7b 5c 22  |":{".":{},"k:{\"|
              00000090  75 69 64 5c 22 3a 5c 22  62 65 64 31 35 62 38 34  |uid\":\"bed15b84|
              000000a0  2d 38 63 30 32 2d 34 35  64 61 2d 61 66 64 63 2d  |-8c02-45da-afdc-|
              000000b0  32 31 65 35 31 32 62 64  66 64 37 61 5c 22 7d 22  |21e512bdfd7a\"}"|
              000000c0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000000d0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000000e0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 74  |"k:{\"name\":\"t|
              000000f0  65 73 74 2d 64 65 70 6c  6f 79 6d 65 6e 74 5c 22  |est-deployment\"|
              00000100  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000110  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000120  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000130  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000140  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000150  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000160  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000170  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000180  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000190  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              000001a0  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000001b0  3a 7b 7d 2c 22 66 3a 65  6e 61 62 6c 65 53 65 72  |:{},"f:enableSer|
              000001c0  76 69 63 65 4c 69 6e 6b  73 22 3a 7b 7d 2c 22 66  |viceLinks":{},"f|
              000001d0  3a 72 65 73 74 61 72 74  50 6f 6c 69 63 79 22 3a  |:restartPolicy":|
              000001e0  7b 7d 2c 22 66 3a 73 63  68 65 64 75 6c 65 72 4e  |{},"f:schedulerN|
              000001f0  61 6d 65 22 3a 7b 7d 2c  22 66 3a 73 65 63 75 72  |ame":{},"f:secur|
              00000200  69 74 79 43 6f 6e 74 65  78 74 22 3a 7b 7d 2c 22  |ityContext":{},"|
              00000210  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 47 72 61  |f:terminationGra|
              00000220  63 65 50 65 72 69 6f 64  53 65 63 6f 6e 64 73 22  |cePeriodSeconds"|
              00000230  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=6) "calico",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872506734,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=153) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 63 6e 69 2e 70 72  |".":{},"f:cni.pr|
              00000030  6f 6a 65 63 74 63 61 6c  69 63 6f 2e 6f 72 67 2f  |ojectcalico.org/|
              00000040  63 6f 6e 74 61 69 6e 65  72 49 44 22 3a 7b 7d 2c  |containerID":{},|
              00000050  22 66 3a 63 6e 69 2e 70  72 6f 6a 65 63 74 63 61  |"f:cni.projectca|
              00000060  6c 69 63 6f 2e 6f 72 67  2f 70 6f 64 49 50 22 3a  |lico.org/podIP":|
              00000070  7b 7d 2c 22 66 3a 63 6e  69 2e 70 72 6f 6a 65 63  |{},"f:cni.projec|
              00000080  74 63 61 6c 69 63 6f 2e  6f 72 67 2f 70 6f 64 49  |tcalico.org/podI|
              00000090  50 73 22 3a 7b 7d 7d 7d  7d                       |Ps":{}}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872506735,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 50 6f 64 52 65 61  64 79 54 6f 53 74 61 72  |\"PodReadyToStar|
              00000120  74 43 6f 6e 74 61 69 6e  65 72 73 5c 22 7d 22 3a  |tContainers\"}":|
              00000130  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000140  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000150  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000160  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000180  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000190  22 52 65 61 64 79 5c 22  7d 22 3a 7b 22 2e 22 3a  |"Ready\"}":{".":|
              000001a0  7b 7d 2c 22 66 3a 6c 61  73 74 50 72 6f 62 65 54  |{},"f:lastProbeT|
              000001b0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 54  |ime":{},"f:lastT|
              000001c0  72 61 6e 73 69 74 69 6f  6e 54 69 6d 65 22 3a 7b  |ransitionTime":{|
              000001d0  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              000001e0  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 53 74 61 74 75 73  |:containerStatus|
              00000200  65 73 22 3a 7b 7d 2c 22  66 3a 68 6f 73 74 49 50  |es":{},"f:hostIP|
              00000210  22 3a 7b 7d 2c 22 66 3a  68 6f 73 74 49 50 73 22  |":{},"f:hostIPs"|
              00000220  3a 7b 7d 2c 22 66 3a 70  68 61 73 65 22 3a 7b 7d  |:{},"f:phase":{}|
              00000230  2c 22 66 3a 70 6f 64 49  50 22 3a 7b 7d 2c 22 66  |,"f:podIP":{},"f|
              00000240  3a 70 6f 64 49 50 73 22  3a 7b 22 2e 22 3a 7b 7d  |:podIPs":{".":{}|
              00000250  2c 22 6b 3a 7b 5c 22 69  70 5c 22 3a 5c 22 31 30  |,"k:{\"ip\":\"10|
              00000260  2e 31 2e 32 31 33 2e 38  34 5c 22 7d 22 3a 7b 22  |.1.213.84\"}":{"|
              00000270  2e 22 3a 7b 7d 2c 22 66  3a 69 70 22 3a 7b 7d 7d  |.":{},"f:ip":{}}|
              00000280  7d 2c 22 66 3a 73 74 61  72 74 54 69 6d 65 22 3a  |},"f:startTime":|
              00000290  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-hhvk4",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  }),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>),
                  ClusterTrustBundle: (*v1.ClusterTrustBundleProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>),
            Image: (*v1.ImageVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=15) "test-deployment",
          Image: (string) (len=26) "registry.k8s.io/pause:3.10",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-hhvk4",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)(<nil>),
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>),
            AppArmorProfile: (*v1.AppArmorProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(2),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=13) "192.168.18.91",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        SupplementalGroupsPolicy: (*v1.SupplementalGroupsPolicy)(<nil>),
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>),
        AppArmorProfile: (*v1.AppArmorProfile)(<nil>),
        SELinuxChangePolicy: (*v1.PodSELinuxChangePolicy)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>,
      Resources: (*v1.ResourceRequirements)(<nil>)
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=5) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=25) "PodReadyToStartContainers",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872506735,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872506732,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872506735,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872506735,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63872506732,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "192.168.18.91",
      HostIPs: ([]v1.HostIP) (len=1) {
        (v1.HostIP) {
          IP: (string) (len=13) "192.168.18.91"
        }
      },
      PodIP: (string) (len=11) "10.1.213.84",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=11) "10.1.213.84"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63872506732,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=15) "test-deployment",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63872506735,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=26) "registry.k8s.io/pause:3.10",
          ImageID: (string) (len=71) "sha256:873ed75102791e5b0b8a7fcd41606c92fcec98d56d05ead4ac5131650004c136",
          ContainerID: (string) (len=77) "containerd://1f94d96f272a4697941e94a9841c31f8d6899e9b41631ba31bbf5e9dfa51dfa6",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>),
          VolumeMounts: ([]v1.VolumeMountStatus) (len=1) {
            (v1.VolumeMountStatus) {
              Name: (string) (len=21) "kube-api-access-hhvk4",
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              ReadOnly: (bool) true,
              RecursiveReadOnly: (*v1.RecursiveReadOnlyMode)((len=8) "Disabled")
            }
          },
          User: (*v1.ContainerUser)(<nil>),
          AllocatedResourcesStatus: ([]v1.ResourceStatus) <nil>
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }


  I0115 02:58:58.179180 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-4249" for this suite. @ 01/15/25 02:58:58.249
• [47.709 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should allow to use the pod failure policy on exit code to fail the job early [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/job.go:110
  STEP: Creating a kubernetes client @ 01/15/25 02:58:58.274
  I0115 02:58:58.274955 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename job @ 01/15/25 02:58:58.278
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:58:58.448
  E0115 02:58:58.450584      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:58:58.469
  STEP: Looking for a node to schedule job pod @ 01/15/25 02:58:58.495
  STEP: Creating a job @ 01/15/25 02:58:58.533
  STEP: Ensuring job fails @ 01/15/25 02:58:58.563
  E0115 02:58:59.453522      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:59:00.455254      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:59:01.456038      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:59:02.479620      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:59:03.479991      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:59:04.481501      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:59:05.483266      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:59:06.487471      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:59:06.716855 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-1883" for this suite. @ 01/15/25 02:59:06.726
• [8.466 seconds]
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:79
  STEP: Creating a kubernetes client @ 01/15/25 02:59:06.741
  I0115 02:59:06.741596 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename secrets @ 01/15/25 02:59:06.743
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:59:06.776
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:59:06.793
  STEP: Creating secret with name secret-test-map-1e02a488-f0c3-4eb9-a8f2-4fadd9529c84 @ 01/15/25 02:59:06.805
  STEP: Creating a pod to test consume secrets @ 01/15/25 02:59:06.814
  E0115 02:59:07.488295      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:59:08.490074      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:59:09.490609      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:59:10.491298      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:59:11.492551      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:59:12.492666      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:59:13.492634      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:59:14.494602      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 02:59:14.911
  I0115 02:59:14.927334 24 output.go:207] Trying to get logs from node 192.168.18.92 pod pod-secrets-a387fbcf-76fe-43de-a641-83d5bccf6021 container secret-volume-test: <nil>
  STEP: delete the pod @ 01/15/25 02:59:14.979
  I0115 02:59:15.003525 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-2498" for this suite. @ 01/15/25 02:59:15.011
• [8.278 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:58
  STEP: Creating a kubernetes client @ 01/15/25 02:59:15.02
  I0115 02:59:15.020211 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename configmap @ 01/15/25 02:59:15.022
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:59:15.048
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:59:15.054
  STEP: Creating configMap with name configmap-test-volume-24fc1aa3-0c86-4e7a-a3d8-7ea5d6607820 @ 01/15/25 02:59:15.061
  STEP: Creating a pod to test consume configMaps @ 01/15/25 02:59:15.068
  E0115 02:59:15.494899      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:59:16.496075      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:59:17.503969      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:59:18.505082      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 02:59:19.109
  I0115 02:59:19.115091 24 output.go:207] Trying to get logs from node 192.168.18.92 pod pod-configmaps-ca5d819c-3741-46b8-ab54-9c4749d6212e container agnhost-container: <nil>
  STEP: delete the pod @ 01/15/25 02:59:19.124
  I0115 02:59:19.147180 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-9670" for this suite. @ 01/15/25 02:59:19.154
• [4.144 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for pods for Hostname [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/dns.go:263
  STEP: Creating a kubernetes client @ 01/15/25 02:59:19.166
  I0115 02:59:19.166904 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename dns @ 01/15/25 02:59:19.17
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:59:19.199
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:59:19.213
  STEP: Creating a test headless service @ 01/15/25 02:59:19.245
  STEP: Running these commands on agnhost: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-4645.svc.cluster.local)" && echo OK > /results/agnhost_hosts@dns-querier-2.dns-test-service-2.dns-4645.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/agnhost_hosts@dns-querier-2;sleep 1; done
   @ 01/15/25 02:59:19.261
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-4645.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-4645.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
   @ 01/15/25 02:59:19.261
  STEP: creating a pod to probe DNS @ 01/15/25 02:59:19.261
  STEP: submitting the pod to kubernetes @ 01/15/25 02:59:19.261
  E0115 02:59:19.505932      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:59:20.514114      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:59:21.515363      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:59:22.516041      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 01/15/25 02:59:23.35
  STEP: looking for the results for each expected name from probers @ 01/15/25 02:59:23.363
  I0115 02:59:23.423549 24 dns_common.go:546] DNS probes using dns-4645/dns-test-f0bd32a5-3c31-4a57-9bc3-6b4b200d9897 succeeded

  STEP: deleting the pod @ 01/15/25 02:59:23.423
  STEP: deleting the test headless service @ 01/15/25 02:59:23.457
  E0115 02:59:23.516131      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:59:23.544645 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "dns-4645" for this suite. @ 01/15/25 02:59:23.555
• [4.396 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/crd_publish_openapi.go:70
  STEP: Creating a kubernetes client @ 01/15/25 02:59:23.562
  I0115 02:59:23.562747 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename crd-publish-openapi @ 01/15/25 02:59:23.564
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:59:23.579
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:59:23.585
  I0115 02:59:23.590383 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  E0115 02:59:24.517081      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with known and required properties @ 01/15/25 02:59:25.252
  I0115 02:59:25.253016 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=crd-publish-openapi-1406 --namespace=crd-publish-openapi-1406 create -f -'
  I0115 02:59:25.437551 24 builder.go:146] stderr: ""
  I0115 02:59:25.437640 24 builder.go:147] stdout: "e2e-test-crd-publish-openapi-4850-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  I0115 02:59:25.437832 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=crd-publish-openapi-1406 --namespace=crd-publish-openapi-1406 delete e2e-test-crd-publish-openapi-4850-crds test-foo'
  E0115 02:59:25.518208      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:59:25.591247 24 builder.go:146] stderr: ""
  I0115 02:59:25.591365 24 builder.go:147] stdout: "e2e-test-crd-publish-openapi-4850-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
  I0115 02:59:25.591448 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=crd-publish-openapi-1406 --namespace=crd-publish-openapi-1406 apply -f -'
  I0115 02:59:25.762245 24 builder.go:146] stderr: ""
  I0115 02:59:25.764658 24 builder.go:147] stdout: "e2e-test-crd-publish-openapi-4850-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  I0115 02:59:25.764759 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=crd-publish-openapi-1406 --namespace=crd-publish-openapi-1406 delete e2e-test-crd-publish-openapi-4850-crds test-foo'
  I0115 02:59:25.990880 24 builder.go:146] stderr: ""
  I0115 02:59:25.991003 24 builder.go:147] stdout: "e2e-test-crd-publish-openapi-4850-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
  STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values @ 01/15/25 02:59:25.991
  I0115 02:59:25.991138 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=crd-publish-openapi-1406 --namespace=crd-publish-openapi-1406 create -f -'
  I0115 02:59:26.172719 24 builder.go:135] rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema @ 01/15/25 02:59:26.173
  I0115 02:59:26.173487 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=crd-publish-openapi-1406 --namespace=crd-publish-openapi-1406 create -f -'
  E0115 02:59:26.523564      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:59:26.531163 24 builder.go:135] rc: 1
  I0115 02:59:26.531341 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=crd-publish-openapi-1406 --namespace=crd-publish-openapi-1406 apply -f -'
  I0115 02:59:26.750127 24 builder.go:135] rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request without required properties @ 01/15/25 02:59:26.752
  I0115 02:59:26.752243 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=crd-publish-openapi-1406 --namespace=crd-publish-openapi-1406 create -f -'
  I0115 02:59:26.987275 24 builder.go:135] rc: 1
  I0115 02:59:26.987970 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=crd-publish-openapi-1406 --namespace=crd-publish-openapi-1406 apply -f -'
  I0115 02:59:27.266438 24 builder.go:135] rc: 1
  STEP: kubectl explain works to explain CR properties @ 01/15/25 02:59:27.266
  I0115 02:59:27.266873 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=crd-publish-openapi-1406 explain e2e-test-crd-publish-openapi-4850-crds'
  I0115 02:59:27.505337 24 builder.go:146] stderr: ""
  I0115 02:59:27.505462 24 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-4850-crd\nVERSION:    v1\n\nDESCRIPTION:\n    Foo CRD for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Foo\n\n  status\t<Object>\n    Status of Foo\n\n\n"
  STEP: kubectl explain works to explain CR properties recursively @ 01/15/25 02:59:27.505
  I0115 02:59:27.506099 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=crd-publish-openapi-1406 explain e2e-test-crd-publish-openapi-4850-crds.metadata'
  E0115 02:59:27.524006      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:59:27.892801 24 builder.go:146] stderr: ""
  I0115 02:59:27.893693 24 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-4850-crd\nVERSION:    v1\n\nFIELD: metadata <ObjectMeta>\n\n\nDESCRIPTION:\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n    ObjectMeta is metadata that all persisted resources must have, which\n    includes all objects users must create.\n    \nFIELDS:\n  annotations\t<map[string]string>\n    Annotations is an unstructured key value map stored with a resource that may\n    be set by external tools to store and retrieve arbitrary metadata. They are\n    not queryable and should be preserved when modifying objects. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations\n\n  creationTimestamp\t<string>\n    CreationTimestamp is a timestamp representing the server time when this\n    object was created. It is not guaranteed to be set in happens-before order\n    across separate operations. Clients may not set this value. It is\n    represented in RFC3339 form and is in UTC.\n    \n    Populated by the system. Read-only. Null for lists. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  deletionGracePeriodSeconds\t<integer>\n    Number of seconds allowed for this object to gracefully terminate before it\n    will be removed from the system. Only set when deletionTimestamp is also\n    set. May only be shortened. Read-only.\n\n  deletionTimestamp\t<string>\n    DeletionTimestamp is RFC 3339 date and time at which this resource will be\n    deleted. This field is set by the server when a graceful deletion is\n    requested by the user, and is not directly settable by a client. The\n    resource is expected to be deleted (no longer visible from resource lists,\n    and not reachable by name) after the time in this field, once the finalizers\n    list is empty. As long as the finalizers list contains items, deletion is\n    blocked. Once the deletionTimestamp is set, this value may not be unset or\n    be set further into the future, although it may be shortened or the resource\n    may be deleted prior to this time. For example, a user may request that a\n    pod is deleted in 30 seconds. The Kubelet will react by sending a graceful\n    termination signal to the containers in the pod. After that 30 seconds, the\n    Kubelet will send a hard termination signal (SIGKILL) to the container and\n    after cleanup, remove the pod from the API. In the presence of network\n    partitions, this object may still exist after this timestamp, until an\n    administrator or automated process can determine the resource is fully\n    terminated. If not set, graceful deletion of the object has not been\n    requested.\n    \n    Populated by the system when a graceful deletion is requested. Read-only.\n    More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  finalizers\t<[]string>\n    Must be empty before the object is deleted from the registry. Each entry is\n    an identifier for the responsible component that will remove the entry from\n    the list. If the deletionTimestamp of the object is non-nil, entries in this\n    list can only be removed. Finalizers may be processed and removed in any\n    order.  Order is NOT enforced because it introduces significant risk of\n    stuck finalizers. finalizers is a shared field, any actor with permission\n    can reorder it. If the finalizer list is processed in order, then this can\n    lead to a situation in which the component responsible for the first\n    finalizer in the list is waiting for a signal (field value, external system,\n    or other) produced by a component responsible for a finalizer later in the\n    list, resulting in a deadlock. Without enforced ordering finalizers are free\n    to order amongst themselves and are not vulnerable to ordering changes in\n    the list.\n\n  generateName\t<string>\n    GenerateName is an optional prefix, used by the server, to generate a unique\n    name ONLY IF the Name field has not been provided. If this field is used,\n    the name returned to the client will be different than the name passed. This\n    value will also be combined with a unique suffix. The provided value has the\n    same validation rules as the Name field, and may be truncated by the length\n    of the suffix required to make the value unique on the server.\n    \n    If this field is specified and the generated name exists, the server will\n    return a 409.\n    \n    Applied only if Name is not specified. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n  generation\t<integer>\n    A sequence number representing a specific generation of the desired state.\n    Populated by the system. Read-only.\n\n  labels\t<map[string]string>\n    Map of string keys and values that can be used to organize and categorize\n    (scope and select) objects. May match selectors of replication controllers\n    and services. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/labels\n\n  managedFields\t<[]ManagedFieldsEntry>\n    ManagedFields maps workflow-id and version to the set of fields that are\n    managed by that workflow. This is mostly for internal housekeeping, and\n    users typically shouldn't need to set or understand this field. A workflow\n    can be the user's name, a controller's name, or the name of a specific apply\n    path like \"ci-cd\". The set of fields is always in the version that the\n    workflow used when modifying the object.\n\n  name\t<string>\n    Name must be unique within a namespace. Is required when creating resources,\n    although some resources may allow a client to request the generation of an\n    appropriate name automatically. Name is primarily intended for creation\n    idempotence and configuration definition. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#names\n\n  namespace\t<string>\n    Namespace defines the space within which each name must be unique. An empty\n    namespace is equivalent to the \"default\" namespace, but \"default\" is the\n    canonical representation. Not all objects are required to be scoped to a\n    namespace - the value of this field for those objects will be empty.\n    \n    Must be a DNS_LABEL. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces\n\n  ownerReferences\t<[]OwnerReference>\n    List of objects depended by this object. If ALL objects in the list have\n    been deleted, this object will be garbage collected. If this object is\n    managed by a controller, then an entry in this list will point to this\n    controller, with the controller field set to true. There cannot be more than\n    one managing controller.\n\n  resourceVersion\t<string>\n    An opaque value that represents the internal version of this object that can\n    be used by clients to determine when objects have changed. May be used for\n    optimistic concurrency, change detection, and the watch operation on a\n    resource or set of resources. Clients must treat these values as opaque and\n    passed unmodified back to the server. They may only be valid for a\n    particular resource or set of resources.\n    \n    Populated by the system. Read-only. Value must be treated as opaque by\n    clients and . More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n  selfLink\t<string>\n    Deprecated: selfLink is a legacy read-only field that is no longer populated\n    by the system.\n\n  uid\t<string>\n    UID is the unique in time and space value for this object. It is typically\n    generated by the server on successful creation of a resource and is not\n    allowed to change on PUT operations.\n    \n    Populated by the system. Read-only. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#uids\n\n\n"
  I0115 02:59:27.894234 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=crd-publish-openapi-1406 explain e2e-test-crd-publish-openapi-4850-crds.spec'
  I0115 02:59:28.115912 24 builder.go:146] stderr: ""
  I0115 02:59:28.116000 24 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-4850-crd\nVERSION:    v1\n\nFIELD: spec <Object>\n\n\nDESCRIPTION:\n    Specification of Foo\n    \nFIELDS:\n  bars\t<[]Object>\n    List of Bars and their specs.\n\n\n"
  I0115 02:59:28.117038 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=crd-publish-openapi-1406 explain e2e-test-crd-publish-openapi-4850-crds.spec.bars'
  I0115 02:59:28.288818 24 builder.go:146] stderr: ""
  I0115 02:59:28.288939 24 builder.go:147] stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-4850-crd\nVERSION:    v1\n\nFIELD: bars <[]Object>\n\n\nDESCRIPTION:\n    List of Bars and their specs.\n    \nFIELDS:\n  age\t<string>\n    Age of Bar.\n\n  bazs\t<[]string>\n    List of Bazs.\n\n  feeling\t<string>\n  enum: Great, Down\n    Whether Bar is feeling great.\n\n  name\t<string> -required-\n    Name of Bar.\n\n\n"
  STEP: kubectl explain works to return error when explain is called on property that doesn't exist @ 01/15/25 02:59:28.289
  I0115 02:59:28.289560 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=crd-publish-openapi-1406 explain e2e-test-crd-publish-openapi-4850-crds.spec.bars2'
  I0115 02:59:28.472517 24 builder.go:135] rc: 1
  E0115 02:59:28.525586      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:59:29.526675      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:59:30.286059 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-1406" for this suite. @ 01/15/25 02:59:30.304
• [6.752 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update validating webhook configurations with match conditions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:712
  STEP: Creating a kubernetes client @ 01/15/25 02:59:30.315
  I0115 02:59:30.315256 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename webhook @ 01/15/25 02:59:30.317
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:59:30.342
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:59:30.348
  STEP: Setting up server cert @ 01/15/25 02:59:30.454
  E0115 02:59:30.527402      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:59:31.528000      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 01/15/25 02:59:31.658
  STEP: Deploying the webhook pod @ 01/15/25 02:59:31.672
  STEP: Wait for the deployment to be ready @ 01/15/25 02:59:31.694
  I0115 02:59:31.709021 24 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0115 02:59:32.528142      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:59:33.530023      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:59:33.727605 24 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.January, 15, 2, 59, 31, 0, time.Local), LastTransitionTime:time.Date(2025, time.January, 15, 2, 59, 31, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.January, 15, 2, 59, 31, 0, time.Local), LastTransitionTime:time.Date(2025, time.January, 15, 2, 59, 31, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-bcbfc85d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0115 02:59:34.531264      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:59:35.532942      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 01/15/25 02:59:35.732
  STEP: Verifying the service has paired with the endpoint @ 01/15/25 02:59:35.742
  E0115 02:59:36.533015      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 02:59:36.744313 24 util.go:423] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: creating a validating webhook with match conditions @ 01/15/25 02:59:36.759
  STEP: verifying the validating webhook match conditions @ 01/15/25 02:59:36.789
  STEP: updating the validating webhook match conditions @ 01/15/25 02:59:36.794
  STEP: verifying the validating webhook match conditions @ 01/15/25 02:59:36.806
  I0115 02:59:36.901090 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-5917" for this suite. @ 01/15/25 02:59:36.909
  STEP: Destroying namespace "webhook-markers-8543" for this suite. @ 01/15/25 02:59:36.934
• [6.648 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:335
  STEP: Creating a kubernetes client @ 01/15/25 02:59:36.963
  I0115 02:59:36.963987 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename init-container @ 01/15/25 02:59:36.965
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 02:59:36.991
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 02:59:37.001
  STEP: creating the pod @ 01/15/25 02:59:37.015
  I0115 02:59:37.016495 24 init_container.go:374] PodSpec: initContainers in spec.initContainers
  E0115 02:59:37.534318      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:59:38.536515      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:59:39.536660      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:59:40.537586      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:59:41.538025      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:59:42.538293      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:59:43.538963      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:59:44.539680      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:59:45.539666      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:59:46.540026      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:59:47.541743      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:59:48.542163      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:59:49.543499      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:59:50.545450      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:59:51.547323      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:59:52.550182      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:59:53.550750      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:59:54.551154      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:59:55.552788      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:59:56.554226      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:59:57.554670      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:59:58.558809      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 02:59:59.559214      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:00:00.564490      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:00:01.565382      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:00:02.565038      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:00:03.570889      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:00:04.572692      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:00:05.574456      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:00:06.575168      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:00:07.576987      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:00:08.579549      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:00:09.589898      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:00:10.592019      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:00:11.594130      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:00:12.595956      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:00:13.597468      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:00:14.598045      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:00:15.598879      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:00:16.600860      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:00:17.602204      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:00:18.602175      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:00:19.604255      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:00:20.605717      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:00:21.607000      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:00:22.607742      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:00:23.608682      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:00:24.609386      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 03:00:25.248754 24 init_container.go:432] init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-fa5db064-6555-4c52-a209-4acf83e28595", GenerateName:"", Namespace:"init-container-9791", SelfLink:"", UID:"8e7bf84c-66a8-466b-a8fc-1d817d45ed4c", ResourceVersion:"190222", Generation:0, CreationTimestamp:time.Date(2025, time.January, 15, 2, 59, 37, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"16463077"}, Annotations:map[string]string{"cni.projectcalico.org/containerID":"d0f2a39a628fb9f3c04a9f89cffc3ae09dcc137b16083354f3715a931e819c30", "cni.projectcalico.org/podIP":"10.1.155.20/32", "cni.projectcalico.org/podIPs":"10.1.155.20/32"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 2, 59, 37, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0032b7bd8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"calico", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 2, 59, 38, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0032b7c20), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2025, time.January, 15, 3, 0, 25, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0032b7c50), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-nhhff", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc000f02b80), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil), Image:(*v1.ImageVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-nhhff", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(nil), MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-nhhff", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(nil), MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.10", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-nhhff", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(nil), MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0047022d8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"192.168.18.92", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc005d23b00), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc004702360)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc004702390)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc004702398), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00470239c), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc000d90fc0), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil), SchedulingGates:[]v1.PodSchedulingGate(nil), ResourceClaims:[]v1.PodResourceClaim(nil), Resources:(*v1.ResourceRequirements)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"PodReadyToStartContainers", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2025, time.January, 15, 2, 59, 39, 0, time.Local), Reason:"", Message:""}, v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2025, time.January, 15, 2, 59, 37, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2025, time.January, 15, 2, 59, 37, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2025, time.January, 15, 2, 59, 37, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2025, time.January, 15, 2, 59, 37, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.18.92", HostIPs:[]v1.HostIP{v1.HostIP{IP:"192.168.18.92"}}, PodIP:"10.1.155.20", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.1.155.20"}}, StartTime:time.Date(2025, time.January, 15, 2, 59, 37, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0038690a0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc003869110)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:a9155b13325b2abef48e71de77bb8ac015412a566829f621d06bfae5c699b1b9", ContainerID:"containerd://a5647d74c08d12fafc4b5fd6d930b610899a90ffbd6e9edbd8aefdda08e7ff06", Started:(*bool)(0xc00470245a), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil), VolumeMounts:[]v1.VolumeMountStatus{v1.VolumeMountStatus{Name:"kube-api-access-nhhff", MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(0xc000d90fe0)}}, User:(*v1.ContainerUser)(nil), AllocatedResourcesStatus:[]v1.ResourceStatus(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc000f02c00), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.36.1-1", ImageID:"", ContainerID:"", Started:(*bool)(0xc00470246d), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil), VolumeMounts:[]v1.VolumeMountStatus{v1.VolumeMountStatus{Name:"kube-api-access-nhhff", MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(0xc000d90ff0)}}, User:(*v1.ContainerUser)(nil), AllocatedResourcesStatus:[]v1.ResourceStatus(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc000f02be0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.10", ImageID:"", ContainerID:"", Started:(*bool)(0xc00470241f), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil), VolumeMounts:[]v1.VolumeMountStatus{v1.VolumeMountStatus{Name:"kube-api-access-nhhff", MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", ReadOnly:true, RecursiveReadOnly:(*v1.RecursiveReadOnlyMode)(0xc000d90fd0)}}, User:(*v1.ContainerUser)(nil), AllocatedResourcesStatus:[]v1.ResourceStatus(nil)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil), Resize:"", ResourceClaimStatuses:[]v1.PodResourceClaimStatus(nil)}}
  I0115 03:00:25.249134 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-9791" for this suite. @ 01/15/25 03:00:25.256
• [48.301 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/configmap_volume.go:110
  STEP: Creating a kubernetes client @ 01/15/25 03:00:25.265
  I0115 03:00:25.265085 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename configmap @ 01/15/25 03:00:25.266
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 03:00:25.282
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 03:00:25.288
  STEP: Creating configMap with name configmap-test-volume-map-c7e66be0-e65d-4127-9782-fd783dcf805f @ 01/15/25 03:00:25.294
  STEP: Creating a pod to test consume configMaps @ 01/15/25 03:00:25.299
  E0115 03:00:25.610141      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:00:26.609838      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:00:27.611959      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:00:28.611838      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 03:00:29.326
  I0115 03:00:29.332098 24 output.go:207] Trying to get logs from node 192.168.18.92 pod pod-configmaps-6542d249-a1d2-4551-8761-f09d3e05448c container agnhost-container: <nil>
  STEP: delete the pod @ 01/15/25 03:00:29.341
  I0115 03:00:29.357063 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-80" for this suite. @ 01/15/25 03:00:29.361
• [4.105 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Pods should be updated [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/pods.go:345
  STEP: Creating a kubernetes client @ 01/15/25 03:00:29.37
  I0115 03:00:29.370067 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename pods @ 01/15/25 03:00:29.371
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 03:00:29.387
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 03:00:29.391
  STEP: creating the pod @ 01/15/25 03:00:29.395
  STEP: submitting the pod to kubernetes @ 01/15/25 03:00:29.395
  E0115 03:00:29.612760      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:00:30.612852      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: verifying the pod is in kubernetes @ 01/15/25 03:00:31.429
  STEP: updating the pod @ 01/15/25 03:00:31.438
  E0115 03:00:31.613645      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 03:00:31.977451 24 pod_client.go:173] Successfully updated pod "pod-update-b2618580-2738-4fb4-8751-6c16709d9ae8"
  STEP: verifying the updated pod is in kubernetes @ 01/15/25 03:00:31.984
  I0115 03:00:31.989989 24 pods.go:391] Pod update OK
  I0115 03:00:31.990237 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-6810" for this suite. @ 01/15/25 03:00:31.995
• [2.634 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1473
  STEP: Creating a kubernetes client @ 01/15/25 03:00:32.003
  I0115 03:00:32.003796 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename services @ 01/15/25 03:00:32.004
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 03:00:32.021
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 03:00:32.026
  STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-6454 @ 01/15/25 03:00:32.032
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 01/15/25 03:00:32.044
  STEP: creating service externalsvc in namespace services-6454 @ 01/15/25 03:00:32.045
  STEP: creating replication controller externalsvc in namespace services-6454 @ 01/15/25 03:00:32.069
  I0115 03:00:32.079527      24 runners.go:193] Created replication controller with name: externalsvc, namespace: services-6454, replica count: 2
  E0115 03:00:32.613743      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:00:33.616389      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:00:34.616984      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 03:00:35.130415      24 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  STEP: changing the ClusterIP service to type=ExternalName @ 01/15/25 03:00:35.141
  I0115 03:00:35.160493 24 resource.go:361] Creating new exec pod
  E0115 03:00:35.618068      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:00:36.619220      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 03:00:37.180622 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-6454 exec execpodlqgkz -- /bin/sh -x -c nslookup clusterip-service.services-6454.svc.cluster.local'
  I0115 03:00:37.536193 24 builder.go:146] stderr: "+ nslookup clusterip-service.services-6454.svc.cluster.local\n"
  I0115 03:00:37.536267 24 builder.go:147] stdout: "Server:\t\t169.169.0.10\nAddress:\t169.169.0.10#53\n\nclusterip-service.services-6454.svc.cluster.local\tcanonical name = externalsvc.services-6454.svc.cluster.local.\nName:\texternalsvc.services-6454.svc.cluster.local\nAddress: 169.169.195.147\n\n"
  STEP: deleting ReplicationController externalsvc in namespace services-6454, will wait for the garbage collector to delete the pods @ 01/15/25 03:00:37.536
  I0115 03:00:37.598424 24 resources.go:139] Deleting ReplicationController externalsvc took: 7.356286ms
  E0115 03:00:37.619535      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 03:00:37.698907 24 resources.go:163] Terminating ReplicationController externalsvc pods took: 100.482133ms
  E0115 03:00:38.620135      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:00:39.620055      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 03:00:40.519654 24 service.go:1482] Cleaning up the ClusterIP to ExternalName test service
  I0115 03:00:40.534232 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-6454" for this suite. @ 01/15/25 03:00:40.541
• [8.546 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:2194
  STEP: Creating a kubernetes client @ 01/15/25 03:00:40.549
  I0115 03:00:40.549919 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename services @ 01/15/25 03:00:40.551
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 03:00:40.574
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 03:00:40.578
  STEP: creating service in namespace services-377 @ 01/15/25 03:00:40.583
  STEP: creating service affinity-nodeport in namespace services-377 @ 01/15/25 03:00:40.583
  STEP: creating replication controller affinity-nodeport in namespace services-377 @ 01/15/25 03:00:40.594
  I0115 03:00:40.600973      24 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-377, replica count: 3
  E0115 03:00:40.620057      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:00:41.637784      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:00:42.640003      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:00:43.641394      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 03:00:43.652570      24 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0115 03:00:43.669897 24 resource.go:361] Creating new exec pod
  E0115 03:00:44.641760      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:00:45.642362      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:00:46.644901      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 03:00:46.700722 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-377 exec execpod-affinitygx42k -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
  E0115 03:00:47.644701      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 03:00:47.831919 24 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport (169.169.4.119) 80 port [tcp/http] succeeded!\n"
  I0115 03:00:47.832076 24 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0115 03:00:47.832261 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-377 exec execpod-affinitygx42k -- /bin/sh -x -c echo hostName | nc -v -t -w 2 169.169.4.119 80'
  I0115 03:00:48.434945 24 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 169.169.4.119 80\nConnection to 169.169.4.119 80 port [tcp/http] succeeded!\n"
  I0115 03:00:48.435059 24 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0115 03:00:48.435253 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-377 exec execpod-affinitygx42k -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.18.91 30875'
  E0115 03:00:48.646004      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 03:00:49.025514 24 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.18.91 30875\nConnection to 192.168.18.91 30875 port [tcp/*] succeeded!\n"
  I0115 03:00:49.025741 24 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0115 03:00:49.025924 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-377 exec execpod-affinitygx42k -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.18.92 30875'
  I0115 03:00:49.428043 24 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.18.92 30875\nConnection to 192.168.18.92 30875 port [tcp/*] succeeded!\n"
  I0115 03:00:49.428170 24 builder.go:147] stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  I0115 03:00:49.428304 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-377 exec execpod-affinitygx42k -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://192.168.18.91:30875/ ; done'
  E0115 03:00:49.649049      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 03:00:50.139529 24 builder.go:146] stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.18.91:30875/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.18.91:30875/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.18.91:30875/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.18.91:30875/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.18.91:30875/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.18.91:30875/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.18.91:30875/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.18.91:30875/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.18.91:30875/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.18.91:30875/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.18.91:30875/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.18.91:30875/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.18.91:30875/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.18.91:30875/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.18.91:30875/\n+ echo\n+ curl -q -s --connect-timeout 2 http://192.168.18.91:30875/\n"
  I0115 03:00:50.139657 24 builder.go:147] stdout: "\naffinity-nodeport-krk9b\naffinity-nodeport-krk9b\naffinity-nodeport-krk9b\naffinity-nodeport-krk9b\naffinity-nodeport-krk9b\naffinity-nodeport-krk9b\naffinity-nodeport-krk9b\naffinity-nodeport-krk9b\naffinity-nodeport-krk9b\naffinity-nodeport-krk9b\naffinity-nodeport-krk9b\naffinity-nodeport-krk9b\naffinity-nodeport-krk9b\naffinity-nodeport-krk9b\naffinity-nodeport-krk9b\naffinity-nodeport-krk9b"
  I0115 03:00:50.139696 24 service.go:242] Received response from host: affinity-nodeport-krk9b
  I0115 03:00:50.139714 24 service.go:242] Received response from host: affinity-nodeport-krk9b
  I0115 03:00:50.139727 24 service.go:242] Received response from host: affinity-nodeport-krk9b
  I0115 03:00:50.139739 24 service.go:242] Received response from host: affinity-nodeport-krk9b
  I0115 03:00:50.139752 24 service.go:242] Received response from host: affinity-nodeport-krk9b
  I0115 03:00:50.139763 24 service.go:242] Received response from host: affinity-nodeport-krk9b
  I0115 03:00:50.139774 24 service.go:242] Received response from host: affinity-nodeport-krk9b
  I0115 03:00:50.139786 24 service.go:242] Received response from host: affinity-nodeport-krk9b
  I0115 03:00:50.139798 24 service.go:242] Received response from host: affinity-nodeport-krk9b
  I0115 03:00:50.139809 24 service.go:242] Received response from host: affinity-nodeport-krk9b
  I0115 03:00:50.139821 24 service.go:242] Received response from host: affinity-nodeport-krk9b
  I0115 03:00:50.139832 24 service.go:242] Received response from host: affinity-nodeport-krk9b
  I0115 03:00:50.139843 24 service.go:242] Received response from host: affinity-nodeport-krk9b
  I0115 03:00:50.139854 24 service.go:242] Received response from host: affinity-nodeport-krk9b
  I0115 03:00:50.139865 24 service.go:242] Received response from host: affinity-nodeport-krk9b
  I0115 03:00:50.139878 24 service.go:242] Received response from host: affinity-nodeport-krk9b
  I0115 03:00:50.139987 24 service.go:4203] Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-nodeport in namespace services-377, will wait for the garbage collector to delete the pods @ 01/15/25 03:00:50.189
  I0115 03:00:50.285852 24 resources.go:139] Deleting ReplicationController affinity-nodeport took: 36.094212ms
  I0115 03:00:50.487024 24 resources.go:163] Terminating ReplicationController affinity-nodeport pods took: 201.168156ms
  E0115 03:00:50.655579      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:00:51.656251      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:00:52.658679      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:00:53.659764      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:00:54.688929      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:00:55.690241      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 03:00:56.382336 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-377" for this suite. @ 01/15/25 03:00:56.402
• [15.870 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:999
  STEP: Creating a kubernetes client @ 01/15/25 03:00:56.42
  I0115 03:00:56.420713 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename resourcequota @ 01/15/25 03:00:56.423
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 03:00:56.474
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 03:00:56.485
  STEP: Creating a ResourceQuota @ 01/15/25 03:00:56.499
  STEP: Getting a ResourceQuota @ 01/15/25 03:00:56.514
  STEP: Listing all ResourceQuotas with LabelSelector @ 01/15/25 03:00:56.529
  STEP: Patching the ResourceQuota @ 01/15/25 03:00:56.536
  STEP: Deleting a Collection of ResourceQuotas @ 01/15/25 03:00:56.611
  E0115 03:00:56.697047      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Verifying the deleted ResourceQuota @ 01/15/25 03:00:56.706
  I0115 03:00:56.717903 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-5731" for this suite. @ 01/15/25 03:00:56.739
• [0.332 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject mutating webhook configurations with invalid match conditions [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:838
  STEP: Creating a kubernetes client @ 01/15/25 03:00:56.756
  I0115 03:00:56.756221 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename webhook @ 01/15/25 03:00:56.76
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 03:00:56.798
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 03:00:56.811
  STEP: Setting up server cert @ 01/15/25 03:00:56.896
  E0115 03:00:57.693957      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:00:58.694703      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 01/15/25 03:00:58.769
  STEP: Deploying the webhook pod @ 01/15/25 03:00:58.78
  STEP: Wait for the deployment to be ready @ 01/15/25 03:00:58.797
  I0115 03:00:58.807982 24 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0115 03:00:59.695822      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:01:00.696732      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 03:01:00.849291 24 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.January, 15, 3, 0, 58, 0, time.Local), LastTransitionTime:time.Date(2025, time.January, 15, 3, 0, 58, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.January, 15, 3, 0, 58, 0, time.Local), LastTransitionTime:time.Date(2025, time.January, 15, 3, 0, 58, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-bcbfc85d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0115 03:01:01.697728      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:01:02.698843      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 01/15/25 03:01:02.862
  STEP: Verifying the service has paired with the endpoint @ 01/15/25 03:01:02.89
  E0115 03:01:03.699987      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 03:01:03.892534 24 util.go:423] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: creating a mutating webhook with match conditions @ 01/15/25 03:01:03.916
  I0115 03:01:04.011163 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-3946" for this suite. @ 01/15/25 03:01:04.017
  STEP: Destroying namespace "webhook-markers-673" for this suite. @ 01/15/25 03:01:04.027
• [7.286 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] CSIInlineVolumes should support CSIVolumeSource in Pod API [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/csi_inline.go:50
  STEP: Creating a kubernetes client @ 01/15/25 03:01:04.041
  I0115 03:01:04.041131 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename csiinlinevolumes @ 01/15/25 03:01:04.042
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 03:01:04.062
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 03:01:04.068
  STEP: creating @ 01/15/25 03:01:04.074
  STEP: getting @ 01/15/25 03:01:04.101
  STEP: listing in namespace @ 01/15/25 03:01:04.108
  STEP: patching @ 01/15/25 03:01:04.122
  STEP: deleting @ 01/15/25 03:01:04.133
  I0115 03:01:04.147856 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-1941" for this suite. @ 01/15/25 03:01:04.158
• [0.126 seconds]
------------------------------
S
------------------------------
[sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:125
  STEP: Creating a kubernetes client @ 01/15/25 03:01:04.167
  I0115 03:01:04.167209 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename projected @ 01/15/25 03:01:04.168
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 03:01:04.192
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 03:01:04.199
  STEP: Creating projection with configMap that has name projected-configmap-test-upd-846b168b-859c-4013-8009-a64cc583ad4c @ 01/15/25 03:01:04.287
  STEP: Creating the pod @ 01/15/25 03:01:04.308
  E0115 03:01:04.701452      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:01:05.702358      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Updating configmap projected-configmap-test-upd-846b168b-859c-4013-8009-a64cc583ad4c @ 01/15/25 03:01:06.374
  STEP: waiting to observe update in volume @ 01/15/25 03:01:06.381
  E0115 03:01:06.702606      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:01:07.704036      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 03:01:08.463570 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5167" for this suite. @ 01/15/25 03:01:08.492
• [4.356 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to create a functioning NodePort service [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/service.go:1260
  STEP: Creating a kubernetes client @ 01/15/25 03:01:08.524
  I0115 03:01:08.525746 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename services @ 01/15/25 03:01:08.529
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 03:01:08.572
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 03:01:08.581
  STEP: creating service nodeport-test with type=NodePort in namespace services-6732 @ 01/15/25 03:01:08.592
  STEP: creating replication controller nodeport-test in namespace services-6732 @ 01/15/25 03:01:08.619
  I0115 03:01:08.640140      24 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-6732, replica count: 2
  E0115 03:01:08.704922      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:01:09.705114      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:01:10.707342      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 03:01:11.691970      24 runners.go:193] nodeport-test Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  E0115 03:01:11.711052      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:01:12.714513      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:01:13.714667      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 03:01:14.695669      24 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  I0115 03:01:14.695796 24 resource.go:361] Creating new exec pod
  E0115 03:01:14.715647      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:01:15.717863      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:01:16.718745      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:01:17.719777      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:01:18.720943      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:01:19.721762      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 03:01:19.744043 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-6732 exec execpodgzqgg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
  I0115 03:01:20.039577 24 builder.go:146] stderr: "+ + echonc hostName -v\n -t -w 2 nodeport-test 80\nConnection to nodeport-test (169.169.26.45) 80 port [tcp/http] succeeded!\n"
  I0115 03:01:20.039898 24 builder.go:147] stdout: ""
  E0115 03:01:20.723147      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 03:01:20.746263 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-6732 exec execpodgzqgg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
  I0115 03:01:20.982701 24 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test (169.169.26.45) 80 port [tcp/http] succeeded!\n"
  I0115 03:01:20.983135 24 builder.go:147] stdout: "nodeport-test-598cj"
  I0115 03:01:20.983263 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-6732 exec execpodgzqgg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 169.169.26.45 80'
  I0115 03:01:21.163877 24 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 169.169.26.45 80\nConnection to 169.169.26.45 80 port [tcp/http] succeeded!\n"
  I0115 03:01:21.163954 24 builder.go:147] stdout: "nodeport-test-598cj"
  I0115 03:01:21.164061 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-6732 exec execpodgzqgg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.18.91 32414'
  I0115 03:01:21.360966 24 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.18.91 32414\nConnection to 192.168.18.91 32414 port [tcp/*] succeeded!\n"
  I0115 03:01:21.361059 24 builder.go:147] stdout: ""
  E0115 03:01:21.724051      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 03:01:22.164896 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-6732 exec execpodgzqgg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.18.91 32414'
  I0115 03:01:22.381249 24 builder.go:146] stderr: "+ echo hostName\n+ nc -v -t -w 2 192.168.18.91 32414\nConnection to 192.168.18.91 32414 port [tcp/*] succeeded!\n"
  I0115 03:01:22.381315 24 builder.go:147] stdout: "nodeport-test-62tlm"
  I0115 03:01:22.381426 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=services-6732 exec execpodgzqgg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 192.168.18.92 32414'
  I0115 03:01:22.589614 24 builder.go:146] stderr: "+ + nc -v -t -w 2 192.168.18.92 32414\necho hostName\nConnection to 192.168.18.92 32414 port [tcp/*] succeeded!\n"
  I0115 03:01:22.589676 24 builder.go:147] stdout: "nodeport-test-62tlm"
  I0115 03:01:22.589861 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-6732" for this suite. @ 01/15/25 03:01:22.597
• [14.082 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/containers.go:42
  STEP: Creating a kubernetes client @ 01/15/25 03:01:22.606
  I0115 03:01:22.606119 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename containers @ 01/15/25 03:01:22.608
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 03:01:22.627
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 03:01:22.633
  E0115 03:01:22.724374      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:01:23.724810      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 03:01:24.684521 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-3223" for this suite. @ 01/15/25 03:01:24.691
• [2.094 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods [Conformance] [sig-cli, Conformance]
k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1388
  STEP: Creating a kubernetes client @ 01/15/25 03:01:24.7
  I0115 03:01:24.700873 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename kubectl @ 01/15/25 03:01:24.702
  E0115 03:01:24.724995      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 03:01:24.725
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 03:01:24.731
  I0115 03:01:24.739914 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-4265 create -f -'
  I0115 03:01:25.001097 24 builder.go:146] stderr: ""
  I0115 03:01:25.001198 24 builder.go:147] stdout: "replicationcontroller/agnhost-primary created\n"
  I0115 03:01:25.001327 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-4265 create -f -'
  I0115 03:01:25.353704 24 builder.go:146] stderr: ""
  I0115 03:01:25.353860 24 builder.go:147] stdout: "service/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 01/15/25 03:01:25.353
  E0115 03:01:25.725318      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 03:01:26.366895 24 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0115 03:01:26.366979 24 framework.go:733] Found 0 / 1
  E0115 03:01:26.725448      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 03:01:27.362747 24 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0115 03:01:27.362866 24 framework.go:733] Found 1 / 1
  I0115 03:01:27.362916 24 framework.go:742] WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  I0115 03:01:27.367788 24 framework.go:692] Selector matched 1 pods for map[app:agnhost]
  I0115 03:01:27.367886 24 framework.go:765] ForEach: Found 1 pods from the filter.  Now looping through them.
  I0115 03:01:27.368027 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-4265 describe pod agnhost-primary-g9xz5'
  I0115 03:01:27.532709 24 builder.go:146] stderr: ""
  I0115 03:01:27.533143 24 builder.go:147] stdout: "Name:             agnhost-primary-g9xz5\nNamespace:        kubectl-4265\nPriority:         0\nService Account:  default\nNode:             192.168.18.92/192.168.18.92\nStart Time:       Wed, 15 Jan 2025 03:01:25 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      cni.projectcalico.org/containerID: 04331b3db7b691dc0a12c52a62528b3047725edfcd7966f1f7f17799294ca12c\n                  cni.projectcalico.org/podIP: 10.1.155.53/32\n                  cni.projectcalico.org/podIPs: 10.1.155.53/32\nStatus:           Running\nIP:               10.1.155.53\nIPs:\n  IP:           10.1.155.53\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://9315d506ce36fa2d297a0ad49b52e89697e0edcc70a148c8c4a9ccb64a4d31e9\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.53\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:99c6b4bb4a1e1df3f0b3752168c89358794d02258ebebc26bf21c29399011a85\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 15 Jan 2025 03:01:26 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-d5bt4 (ro)\nConditions:\n  Type                        Status\n  PodReadyToStartContainers   True \n  Initialized                 True \n  Ready                       True \n  ContainersReady             True \n  PodScheduled                True \nVolumes:\n  kube-api-access-d5bt4:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  2s    default-scheduler  Successfully assigned kubectl-4265/agnhost-primary-g9xz5 to 192.168.18.92\n  Normal  Pulled     1s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.53\" already present on machine\n  Normal  Created    1s    kubelet            Created container: agnhost-primary\n  Normal  Started    1s    kubelet            Started container agnhost-primary\n"
  I0115 03:01:27.533371 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-4265 describe rc agnhost-primary'
  E0115 03:01:27.728520      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 03:01:27.852974 24 builder.go:146] stderr: ""
  I0115 03:01:27.853118 24 builder.go:147] stdout: "Name:         agnhost-primary\nNamespace:    kubectl-4265\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:         registry.k8s.io/e2e-test-images/agnhost:2.53\n    Port:          6379/TCP\n    Host Port:     0/TCP\n    Environment:   <none>\n    Mounts:        <none>\n  Volumes:         <none>\n  Node-Selectors:  <none>\n  Tolerations:     <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: agnhost-primary-g9xz5\n"
  I0115 03:01:27.854199 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-4265 describe service agnhost-primary'
  I0115 03:01:28.078101 24 builder.go:146] stderr: ""
  I0115 03:01:28.078226 24 builder.go:147] stdout: "Name:                     agnhost-primary\nNamespace:                kubectl-4265\nLabels:                   app=agnhost\n                          role=primary\nAnnotations:              <none>\nSelector:                 app=agnhost,role=primary\nType:                     ClusterIP\nIP Family Policy:         SingleStack\nIP Families:              IPv4\nIP:                       169.169.232.59\nIPs:                      169.169.232.59\nPort:                     <unset>  6379/TCP\nTargetPort:               agnhost-server/TCP\nEndpoints:                10.1.155.53:6379\nSession Affinity:         None\nInternal Traffic Policy:  Cluster\nEvents:                   <none>\n"
  I0115 03:01:28.086075 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-4265 describe node 192.168.18.91'
  I0115 03:01:28.667659 24 builder.go:146] stderr: ""
  I0115 03:01:28.667906 24 builder.go:147] stdout: "Name:               192.168.18.91\nRoles:              control-plane\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=192.168.18.91\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/control-plane=\n                    node.kubernetes.io/exclude-from-external-load-balancers=\nAnnotations:        kubeadm.alpha.kubernetes.io/cri-socket: unix:///var/run/containerd/containerd.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 192.168.18.91/24\n                    projectcalico.org/IPv4IPIPTunnelAddr: 10.1.213.64\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Sat, 11 Jan 2025 15:50:42 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  192.168.18.91\n  AcquireTime:     <unset>\n  RenewTime:       Wed, 15 Jan 2025 03:01:25 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Tue, 14 Jan 2025 13:32:11 +0000   Tue, 14 Jan 2025 13:32:11 +0000   CalicoIsUp                   Calico is running on this node\n  MemoryPressure       False   Wed, 15 Jan 2025 02:57:55 +0000   Sat, 11 Jan 2025 15:50:41 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Wed, 15 Jan 2025 02:57:55 +0000   Sat, 11 Jan 2025 15:50:41 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Wed, 15 Jan 2025 02:57:55 +0000   Sat, 11 Jan 2025 15:50:41 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Wed, 15 Jan 2025 02:57:55 +0000   Sat, 11 Jan 2025 16:31:52 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  192.168.18.91\n  Hostname:    192.168.18.91\nCapacity:\n  cpu:                4\n  ephemeral-storage:  38774276Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             3991592Ki\n  pods:               110\nAllocatable:\n  cpu:                4\n  ephemeral-storage:  35734372703\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             3889192Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 f7e2609502244a04ae48722b3879510d\n  System UUID:                aeb14d56-f970-254f-79fe-439244ea8ae3\n  Boot ID:                    f5285a01-971d-4846-b3ff-1edce9ff6417\n  Kernel Version:             5.15.63-1.el8.x86_64\n  OS Image:                   CentOS Linux 8\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  containerd://1.7.25\n  Kubelet Version:            v1.32.0\n  Kube-Proxy Version:         v1.32.0\nNon-terminated Pods:          (11 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                 calico-kube-controllers-7498b9bb4c-crlbm                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         11h\n  kube-system                 calico-node-zs5fv                                          250m (6%)     0 (0%)      0 (0%)           0 (0%)         13h\n  kube-system                 coredns-668d6bf9bc-2fn8q                                   100m (2%)     0 (0%)      70Mi (1%)        170Mi (4%)     11h\n  kube-system                 coredns-668d6bf9bc-mpkf9                                   100m (2%)     0 (0%)      70Mi (1%)        170Mi (4%)     11h\n  kube-system                 etcd-192.168.18.91                                         100m (2%)     0 (0%)      100Mi (2%)       0 (0%)         13h\n  kube-system                 kube-apiserver-192.168.18.91                               250m (6%)     0 (0%)      0 (0%)           0 (0%)         13h\n  kube-system                 kube-controller-manager-192.168.18.91                      200m (5%)     0 (0%)      0 (0%)           0 (0%)         13h\n  kube-system                 kube-proxy-nlmsc                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         13h\n  kube-system                 kube-scheduler-192.168.18.91                               100m (2%)     0 (0%)      0 (0%)           0 (0%)         13h\n  services-6732               nodeport-test-62tlm                                        0 (0%)        0 (0%)      0 (0%)           0 (0%)         20s\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-7cfa3cb4906a48cc-vmmwc    0 (0%)        0 (0%)      0 (0%)           0 (0%)         104m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests     Limits\n  --------           --------     ------\n  cpu                1100m (27%)  0 (0%)\n  memory             240Mi (6%)   340Mi (8%)\n  ephemeral-storage  0 (0%)       0 (0%)\n  hugepages-1Gi      0 (0%)       0 (0%)\n  hugepages-2Mi      0 (0%)       0 (0%)\nEvents:              <none>\n"
  I0115 03:01:28.668100 24 builder.go:121] Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2182528051 --namespace=kubectl-4265 describe namespace kubectl-4265'
  E0115 03:01:28.735413      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 03:01:28.998994 24 builder.go:146] stderr: ""
  I0115 03:01:28.999162 24 builder.go:147] stdout: "Name:         kubectl-4265\nLabels:       e2e-framework=kubectl\n              e2e-run=e51f20a0-d7bf-4a6e-8c2b-350d70a722da\n              kubernetes.io/metadata.name=kubectl-4265\n              pod-security.kubernetes.io/audit=baseline\n              pod-security.kubernetes.io/enforce=baseline\n              pod-security.kubernetes.io/warn=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
  I0115 03:01:28.999430 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-4265" for this suite. @ 01/15/25 03:01:29.012
• [4.331 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/security_context.go:531
  STEP: Creating a kubernetes client @ 01/15/25 03:01:29.033
  I0115 03:01:29.033279 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename security-context-test @ 01/15/25 03:01:29.035
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 03:01:29.125
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 03:01:29.135
  E0115 03:01:29.738970      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:01:30.739425      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:01:31.740407      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:01:32.741042      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:01:33.742435      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:01:34.745339      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:01:35.745602      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:01:36.746527      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 03:01:37.311268 24 security_context.go:538] Got logs for pod "busybox-privileged-false-c782d002-94ec-42f6-8757-8460b807fe4b": "ip: RTNETLINK answers: Operation not permitted\n"
  I0115 03:01:37.311543 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-1730" for this suite. @ 01/15/25 03:01:37.325
• [8.324 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:560
  STEP: Creating a kubernetes client @ 01/15/25 03:01:37.358
  I0115 03:01:37.359174 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename svcaccounts @ 01/15/25 03:01:37.361
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 03:01:37.409
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 03:01:37.424
  I0115 03:01:37.490167 24 service_accounts.go:647] created pod
  E0115 03:01:37.746645      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:01:38.747041      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:01:39.747909      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:01:40.748534      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:01:41.749348      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:01:42.749725      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 03:01:43.554
  E0115 03:01:43.751105      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:01:44.751647      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:01:45.752298      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:01:46.753194      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:01:47.753667      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:01:48.754715      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:01:49.755867      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:01:50.755670      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:01:51.757380      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:01:52.758175      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:01:53.759731      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:01:54.761200      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:01:55.763974      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:01:56.763953      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:01:57.765220      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:01:58.766099      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:01:59.767723      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:02:00.768354      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:02:01.769946      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:02:02.772199      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:02:03.777554      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:02:04.777628      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:02:05.778904      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:02:06.779954      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:02:07.780018      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:02:08.782597      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:02:09.782812      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:02:10.784282      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:02:11.784924      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:02:12.785566      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 03:02:13.556395 24 service_accounts.go:653] polling logs
  I0115 03:02:13.595103 24 service_accounts.go:663] Pod logs: 
  I0115 03:01:39.337309       1 log.go:245] OK: Got token
  I0115 03:01:39.337617       1 log.go:245] validating with in-cluster discovery
  I0115 03:01:39.340614       1 log.go:245] OK: got issuer https://kubernetes.default.svc.cluster.local
  I0115 03:01:39.340876       1 log.go:245] Full, not-validated claims: 
  openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-7835:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:(*jwt.NumericDate)(0xc0004b55f0), NotBefore:(*jwt.NumericDate)(0xc0004b56e0), IssuedAt:(*jwt.NumericDate)(0xc0004b5600), ID:"a4a2266c-5398-4d62-b5ae-74801ebd76e8"}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-7835", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"e4444e7a-0d76-4488-92fe-4f08395d6ee7"}}}
  I0115 03:01:39.400060       1 log.go:245] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc.cluster.local
  I0115 03:01:39.469339       1 log.go:245] OK: Validated signature on JWT
  I0115 03:01:39.469568       1 log.go:245] OK: Got valid claims from token!
  I0115 03:01:39.469626       1 log.go:245] Full, validated claims: 
  &openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc.cluster.local", Subject:"system:serviceaccount:svcaccounts-7835:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:(*jwt.NumericDate)(0xc0001f9008), NotBefore:(*jwt.NumericDate)(0xc0001f9040), IssuedAt:(*jwt.NumericDate)(0xc0001f9010), ID:"a4a2266c-5398-4d62-b5ae-74801ebd76e8"}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-7835", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"e4444e7a-0d76-4488-92fe-4f08395d6ee7"}}}

  I0115 03:02:13.595338 24 service_accounts.go:667] completed pod
  I0115 03:02:13.611429 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-7835" for this suite. @ 01/15/25 03:02:13.623
• [36.285 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:274
  STEP: Creating a kubernetes client @ 01/15/25 03:02:13.644
  I0115 03:02:13.644655 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename namespaces @ 01/15/25 03:02:13.646
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 03:02:13.69
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 03:02:13.704
  STEP: creating a Namespace @ 01/15/25 03:02:13.715
  STEP: patching the Namespace @ 01/15/25 03:02:13.778
  E0115 03:02:13.787635      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: get the Namespace and ensuring it has the label @ 01/15/25 03:02:13.796
  I0115 03:02:13.803206 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-203" for this suite. @ 01/15/25 03:02:13.813
  STEP: Destroying namespace "nspatchtest-6698a265-d97a-44d3-9809-3a8af9c0eeae-8127" for this suite. @ 01/15/25 03:02:13.825
• [0.197 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:180
  STEP: Creating a kubernetes client @ 01/15/25 03:02:13.841
  I0115 03:02:13.841863 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename emptydir @ 01/15/25 03:02:13.844
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 03:02:13.889
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 03:02:13.9
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 01/15/25 03:02:13.92
  E0115 03:02:14.791038      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:02:15.791074      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:02:16.793020      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:02:17.795787      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:02:18.797360      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:02:19.798480      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 03:02:19.977
  I0115 03:02:19.984249 24 output.go:207] Trying to get logs from node 192.168.18.92 pod pod-2a8f3478-1279-4714-86e6-8577a20ab177 container test-container: <nil>
  STEP: delete the pod @ 01/15/25 03:02:19.995
  I0115 03:02:20.013483 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-8373" for this suite. @ 01/15/25 03:02:20.02
• [6.187 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicy API operations [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/validatingadmissionpolicy.go:411
  STEP: Creating a kubernetes client @ 01/15/25 03:02:20.029
  I0115 03:02:20.029588 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename validating-admission-policy @ 01/15/25 03:02:20.03
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 03:02:20.052
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 03:02:20.06
  STEP: getting /apis @ 01/15/25 03:02:20.078
  STEP: getting /apis/admissionregistration.k8s.io @ 01/15/25 03:02:20.089
  STEP: getting /apis/admissionregistration.k8s.io/v1 @ 01/15/25 03:02:20.092
  STEP: creating @ 01/15/25 03:02:20.096
  STEP: getting @ 01/15/25 03:02:20.127
  STEP: listing @ 01/15/25 03:02:20.135
  STEP: watching @ 01/15/25 03:02:20.14
  I0115 03:02:20.140266 24 validatingadmissionpolicy.go:528] starting watch
  STEP: patching @ 01/15/25 03:02:20.143
  STEP: updating @ 01/15/25 03:02:20.155
  I0115 03:02:20.175884 24 validatingadmissionpolicy.go:557] waiting for watch events with expected annotations
  I0115 03:02:20.176001 24 validatingadmissionpolicy.go:573] missing expected annotations, waiting: map[string]string(nil)
  STEP: getting /status @ 01/15/25 03:02:20.176
  STEP: patching /status @ 01/15/25 03:02:20.182
  STEP: updating /status @ 01/15/25 03:02:20.191
  STEP: deleting @ 01/15/25 03:02:20.248
  STEP: deleting a collection @ 01/15/25 03:02:20.274
  I0115 03:02:20.308565 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "validating-admission-policy-1948" for this suite. @ 01/15/25 03:02:20.318
• [0.306 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/empty_dir.go:140
  STEP: Creating a kubernetes client @ 01/15/25 03:02:20.336
  I0115 03:02:20.336181 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename emptydir @ 01/15/25 03:02:20.338
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 03:02:20.365
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 03:02:20.373
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 01/15/25 03:02:20.383
  E0115 03:02:20.798591      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:02:21.801207      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:02:22.802600      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:02:23.808310      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 03:02:24.418
  I0115 03:02:24.424094 24 output.go:207] Trying to get logs from node 192.168.18.92 pod pod-10410df2-fd5a-4bc1-8f6c-49135b9ae027 container test-container: <nil>
  STEP: delete the pod @ 01/15/25 03:02:24.435
  I0115 03:02:24.455772 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-9007" for this suite. @ 01/15/25 03:02:24.462
• [4.136 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/kubelet.go:110
  STEP: Creating a kubernetes client @ 01/15/25 03:02:24.472
  I0115 03:02:24.472792 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename kubelet-test @ 01/15/25 03:02:24.475
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 03:02:24.498
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 03:02:24.504
  E0115 03:02:24.808973      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:02:25.810857      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:02:26.811808      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:02:27.812334      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 03:02:28.586687 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-6855" for this suite. @ 01/15/25 03:02:28.64
• [4.206 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:569
  STEP: Creating a kubernetes client @ 01/15/25 03:02:28.679
  I0115 03:02:28.679454 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename webhook @ 01/15/25 03:02:28.685
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 03:02:28.718
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 03:02:28.725
  E0115 03:02:28.813139      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Setting up server cert @ 01/15/25 03:02:28.814
  E0115 03:02:29.819310      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:02:30.820285      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 01/15/25 03:02:30.921
  STEP: Deploying the webhook pod @ 01/15/25 03:02:30.949
  STEP: Wait for the deployment to be ready @ 01/15/25 03:02:31.014
  I0115 03:02:31.067162 24 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0115 03:02:31.820968      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:02:32.822481      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 01/15/25 03:02:33.088
  STEP: Verifying the service has paired with the endpoint @ 01/15/25 03:02:33.105
  E0115 03:02:33.823371      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 03:02:34.106384 24 util.go:423] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Listing all of the created validation webhooks @ 01/15/25 03:02:34.196
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 01/15/25 03:02:34.248
  STEP: Deleting the collection of validation webhooks @ 01/15/25 03:02:34.298
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 01/15/25 03:02:34.36
  I0115 03:02:34.439109 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-7933" for this suite. @ 01/15/25 03:02:34.446
  STEP: Destroying namespace "webhook-markers-3885" for this suite. @ 01/15/25 03:02:34.459
• [5.788 seconds]
------------------------------
SSS
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance] [sig-network, Conformance]
k8s.io/kubernetes/test/e2e/network/proxy.go:380
  STEP: Creating a kubernetes client @ 01/15/25 03:02:34.467
  I0115 03:02:34.467412 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename proxy @ 01/15/25 03:02:34.469
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 03:02:34.495
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 03:02:34.508
  I0115 03:02:34.538823 24 proxy.go:387] Creating pod...
  E0115 03:02:34.882512      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:02:35.882682      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:02:36.883004      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:02:37.884230      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 03:02:38.616344 24 proxy.go:411] Creating service...
  I0115 03:02:38.657128 24 proxy.go:448] Starting http.Client for https://169.169.0.1:443/api/v1/namespaces/proxy-814/pods/agnhost/proxy?method=DELETE
  I0115 03:02:38.689763 24 proxy.go:530] http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  I0115 03:02:38.689851 24 proxy.go:448] Starting http.Client for https://169.169.0.1:443/api/v1/namespaces/proxy-814/pods/agnhost/proxy?method=OPTIONS
  I0115 03:02:38.696693 24 proxy.go:530] http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  I0115 03:02:38.696827 24 proxy.go:448] Starting http.Client for https://169.169.0.1:443/api/v1/namespaces/proxy-814/pods/agnhost/proxy?method=PATCH
  I0115 03:02:38.704283 24 proxy.go:530] http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  I0115 03:02:38.704342 24 proxy.go:448] Starting http.Client for https://169.169.0.1:443/api/v1/namespaces/proxy-814/pods/agnhost/proxy?method=POST
  I0115 03:02:38.708429 24 proxy.go:530] http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  I0115 03:02:38.708500 24 proxy.go:448] Starting http.Client for https://169.169.0.1:443/api/v1/namespaces/proxy-814/pods/agnhost/proxy?method=PUT
  I0115 03:02:38.713696 24 proxy.go:530] http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  I0115 03:02:38.713754 24 proxy.go:459] Starting http.Client for https://169.169.0.1:443/api/v1/namespaces/proxy-814/services/e2e-proxy-test-service/proxy?method=DELETE
  I0115 03:02:38.720847 24 proxy.go:530] http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  I0115 03:02:38.721007 24 proxy.go:459] Starting http.Client for https://169.169.0.1:443/api/v1/namespaces/proxy-814/services/e2e-proxy-test-service/proxy?method=OPTIONS
  I0115 03:02:38.728435 24 proxy.go:530] http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  I0115 03:02:38.728739 24 proxy.go:459] Starting http.Client for https://169.169.0.1:443/api/v1/namespaces/proxy-814/services/e2e-proxy-test-service/proxy?method=PATCH
  I0115 03:02:38.734551 24 proxy.go:530] http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  I0115 03:02:38.734615 24 proxy.go:459] Starting http.Client for https://169.169.0.1:443/api/v1/namespaces/proxy-814/services/e2e-proxy-test-service/proxy?method=POST
  I0115 03:02:38.739826 24 proxy.go:530] http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  I0115 03:02:38.739903 24 proxy.go:459] Starting http.Client for https://169.169.0.1:443/api/v1/namespaces/proxy-814/services/e2e-proxy-test-service/proxy?method=PUT
  I0115 03:02:38.745944 24 proxy.go:530] http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  I0115 03:02:38.746377 24 proxy.go:479] Starting http.Client for https://169.169.0.1:443/api/v1/namespaces/proxy-814/pods/agnhost/proxy?method=GET
  I0115 03:02:38.750205 24 proxy.go:487] http.Client request:GET StatusCode:301
  I0115 03:02:38.750364 24 proxy.go:479] Starting http.Client for https://169.169.0.1:443/api/v1/namespaces/proxy-814/services/e2e-proxy-test-service/proxy?method=GET
  I0115 03:02:38.754464 24 proxy.go:487] http.Client request:GET StatusCode:301
  I0115 03:02:38.754554 24 proxy.go:479] Starting http.Client for https://169.169.0.1:443/api/v1/namespaces/proxy-814/pods/agnhost/proxy?method=HEAD
  I0115 03:02:38.757879 24 proxy.go:487] http.Client request:HEAD StatusCode:301
  I0115 03:02:38.757946 24 proxy.go:479] Starting http.Client for https://169.169.0.1:443/api/v1/namespaces/proxy-814/services/e2e-proxy-test-service/proxy?method=HEAD
  I0115 03:02:38.762578 24 proxy.go:487] http.Client request:HEAD StatusCode:301
  I0115 03:02:38.762797 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-814" for this suite. @ 01/15/25 03:02:38.768
• [4.309 seconds]
------------------------------
SSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:746
  STEP: Creating a kubernetes client @ 01/15/25 03:02:38.776
  I0115 03:02:38.776379 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename sched-preemption @ 01/15/25 03:02:38.778
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 03:02:38.795
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 03:02:38.803
  I0115 03:02:38.823284 24 wait.go:51] Waiting up to 1m0s for all nodes to be ready
  E0115 03:02:38.884917      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:02:39.886166      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:02:40.886403      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:02:41.887538      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:02:42.888247      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:02:43.888838      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:02:44.890147      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:02:45.891398      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:02:46.892527      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:02:47.892972      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:02:48.893260      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:02:49.895250      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:02:50.896541      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:02:51.897863      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:02:52.898081      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:02:53.898337      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:02:54.899022      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:02:55.900298      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:02:56.900987      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:02:57.901765      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:02:58.902378      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:02:59.903232      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:03:00.904280      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:03:01.905966      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:03:02.906651      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:03:03.907083      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:03:04.908177      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:03:05.909396      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:03:06.909505      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:03:07.910908      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:03:08.911533      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:03:09.913012      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:03:10.913673      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:03:11.914391      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:03:12.914682      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:03:13.915864      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:03:14.917900      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:03:15.919245      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:03:16.920529      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:03:17.920837      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:03:18.921185      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:03:19.922834      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:03:20.924771      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:03:21.925875      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:03:22.926730      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:03:23.927630      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:03:24.928053      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:03:25.929376      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:03:26.929966      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:03:27.930578      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:03:28.931739      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:03:29.932506      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:03:30.933399      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:03:31.934056      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:03:32.934429      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:03:33.936429      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:03:34.937051      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:03:35.938986      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:03:36.941032      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:03:37.941666      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 03:03:38.831878 24 util.go:396] Waiting for terminating namespaces to be deleted...
  STEP: Creating a kubernetes client @ 01/15/25 03:03:38.837
  I0115 03:03:38.837641 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename sched-preemption-path @ 01/15/25 03:03:38.839
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 03:03:38.863
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 03:03:38.87
  STEP: Finding an available node @ 01/15/25 03:03:38.88
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 01/15/25 03:03:38.88
  E0115 03:03:38.943342      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:03:39.943735      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 01/15/25 03:03:40.923
  E0115 03:03:40.946380      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 03:03:40.959727 24 preemption.go:709] found a healthy node: 192.168.18.92
  STEP: Adding a custom resource @ 01/15/25 03:03:40.965
  E0115 03:03:41.946387      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:03:42.947395      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:03:43.947844      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:03:44.948530      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:03:45.949513      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:03:46.950370      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 03:03:47.052340 24 preemption.go:828] pods created so far: [1 1 1]
  I0115 03:03:47.052446 24 preemption.go:829] length of pods created so far: 3
  E0115 03:03:47.951253      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:03:48.952173      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:03:49.952636      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:03:50.954147      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 03:03:51.070768 24 preemption.go:846] pods created so far: [2 2 1]
  E0115 03:03:51.955342      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:03:52.957720      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:03:53.958269      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:03:54.959610      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:03:55.960350      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:03:56.960540      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:03:57.961489      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Removing a custom resource @ 01/15/25 03:03:58.073
  STEP: Removing a custom resource @ 01/15/25 03:03:58.164
  STEP: Removing a custom resource @ 01/15/25 03:03:58.181
  I0115 03:03:58.203364 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-path-1980" for this suite. @ 01/15/25 03:03:58.211
  I0115 03:03:58.221084 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-240" for this suite. @ 01/15/25 03:03:58.313
• [79.550 seconds]
------------------------------
SSSSSS
------------------------------
[sig-auth] ServiceAccounts should update a ServiceAccount [Conformance] [sig-auth, Conformance]
k8s.io/kubernetes/test/e2e/auth/service_accounts.go:839
  STEP: Creating a kubernetes client @ 01/15/25 03:03:58.326
  I0115 03:03:58.326358 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename svcaccounts @ 01/15/25 03:03:58.328
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 03:03:58.361
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 03:03:58.369
  STEP: Creating ServiceAccount "e2e-sa-n84cq"  @ 01/15/25 03:03:58.379
  I0115 03:03:58.387410 24 service_accounts.go:854] AutomountServiceAccountToken: false
  STEP: Updating ServiceAccount "e2e-sa-n84cq"  @ 01/15/25 03:03:58.387
  I0115 03:03:58.405977 24 service_accounts.go:868] AutomountServiceAccountToken: true
  I0115 03:03:58.406200 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-4461" for this suite. @ 01/15/25 03:03:58.418
• [0.103 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance] [sig-storage, Conformance]
k8s.io/kubernetes/test/e2e/storage/subpath.go:59
  STEP: Creating a kubernetes client @ 01/15/25 03:03:58.43
  I0115 03:03:58.430295 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename subpath @ 01/15/25 03:03:58.432
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 03:03:58.487
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 03:03:58.5
  STEP: Setting up data @ 01/15/25 03:03:58.525
  STEP: Creating pod pod-subpath-test-secret-zx28 @ 01/15/25 03:03:58.596
  STEP: Creating a pod to test atomic-volume-subpath @ 01/15/25 03:03:58.597
  E0115 03:03:58.961813      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:03:59.962036      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:04:00.962228      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:04:01.963105      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:04:02.963583      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:04:03.965231      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:04:04.966075      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:04:05.967376      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:04:06.968270      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:04:07.968973      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:04:08.969878      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:04:09.970912      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:04:10.971355      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:04:11.972689      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:04:12.973247      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:04:13.973877      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:04:14.974833      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:04:15.975356      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:04:16.975801      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:04:17.977517      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:04:18.978142      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:04:19.979434      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:04:20.980495      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:04:21.984191      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 03:04:22.8
  I0115 03:04:22.815613 24 output.go:207] Trying to get logs from node 192.168.18.92 pod pod-subpath-test-secret-zx28 container test-container-subpath-secret-zx28: <nil>
  STEP: delete the pod @ 01/15/25 03:04:22.874
  STEP: Deleting pod pod-subpath-test-secret-zx28 @ 01/15/25 03:04:22.895
  I0115 03:04:22.895815 24 delete.go:62] Deleting pod "pod-subpath-test-secret-zx28" in namespace "subpath-6783"
  I0115 03:04:22.901244 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-6783" for this suite. @ 01/15/25 03:04:22.906
• [24.482 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:270
  STEP: Creating a kubernetes client @ 01/15/25 03:04:22.912
  I0115 03:04:22.912129 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename webhook @ 01/15/25 03:04:22.912
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 03:04:22.929
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 03:04:22.933
  E0115 03:04:22.985748      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Setting up server cert @ 01/15/25 03:04:23.073
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 01/15/25 03:04:23.471
  STEP: Deploying the webhook pod @ 01/15/25 03:04:23.476
  STEP: Wait for the deployment to be ready @ 01/15/25 03:04:23.484
  I0115 03:04:23.490987 24 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0115 03:04:23.986453      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:04:24.988608      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 01/15/25 03:04:25.541
  STEP: Verifying the service has paired with the endpoint @ 01/15/25 03:04:25.594
  E0115 03:04:25.988829      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 03:04:26.595445 24 util.go:423] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 01/15/25 03:04:26.621
  STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 01/15/25 03:04:26.691
  STEP: Creating a dummy validating-webhook-configuration object @ 01/15/25 03:04:26.715
  STEP: Deleting the validating-webhook-configuration, which should be possible to remove @ 01/15/25 03:04:26.726
  STEP: Creating a dummy mutating-webhook-configuration object @ 01/15/25 03:04:26.732
  STEP: Deleting the mutating-webhook-configuration, which should be possible to remove @ 01/15/25 03:04:26.74
  I0115 03:04:26.837407 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-109" for this suite. @ 01/15/25 03:04:26.841
  STEP: Destroying namespace "webhook-markers-8585" for this suite. @ 01/15/25 03:04:26.846
• [3.941 seconds]
------------------------------
S
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/lifecycle_hook.go:137
  STEP: Creating a kubernetes client @ 01/15/25 03:04:26.853
  I0115 03:04:26.853393 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 01/15/25 03:04:26.854
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 03:04:26.87
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 03:04:26.875
  STEP: create the container to handle the HTTPGet hook request. @ 01/15/25 03:04:26.946
  E0115 03:04:26.989293      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:04:27.990955      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:04:28.994086      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 01/15/25 03:04:29.026
  E0115 03:04:29.991710      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:04:30.992491      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: check poststart hook @ 01/15/25 03:04:31.056
  STEP: delete the pod with lifecycle hook @ 01/15/25 03:04:31.07
  E0115 03:04:31.993324      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:04:32.993873      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:04:33.995608      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:04:34.995851      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 03:04:35.108966 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-4452" for this suite. @ 01/15/25 03:04:35.12
• [8.278 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:116
  STEP: Creating a kubernetes client @ 01/15/25 03:04:35.131
  I0115 03:04:35.131679 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename webhook @ 01/15/25 03:04:35.133
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 03:04:35.16
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 03:04:35.168
  STEP: Setting up server cert @ 01/15/25 03:04:35.256
  E0115 03:04:35.996570      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 01/15/25 03:04:36.331
  STEP: Deploying the webhook pod @ 01/15/25 03:04:36.341
  STEP: Wait for the deployment to be ready @ 01/15/25 03:04:36.36
  I0115 03:04:36.374940 24 deployment.go:223] deployment "sample-webhook-deployment" doesn't have the required revision set
  E0115 03:04:36.997971      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:04:38.001050      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 03:04:38.403827 24 deployment.go:104] deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2025, time.January, 15, 3, 4, 36, 0, time.Local), LastTransitionTime:time.Date(2025, time.January, 15, 3, 4, 36, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2025, time.January, 15, 3, 4, 36, 0, time.Local), LastTransitionTime:time.Date(2025, time.January, 15, 3, 4, 36, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-bcbfc85d\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E0115 03:04:39.001398      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:04:40.002079      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 01/15/25 03:04:40.438
  STEP: Verifying the service has paired with the endpoint @ 01/15/25 03:04:40.477
  E0115 03:04:41.002420      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 03:04:41.481005 24 util.go:423] Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: fetching the /apis discovery document @ 01/15/25 03:04:41.491
  STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document @ 01/15/25 03:04:41.494
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document @ 01/15/25 03:04:41.494
  STEP: fetching the /apis/admissionregistration.k8s.io discovery document @ 01/15/25 03:04:41.494
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document @ 01/15/25 03:04:41.497
  STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document @ 01/15/25 03:04:41.497
  STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document @ 01/15/25 03:04:41.501
  I0115 03:04:41.646716 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8753" for this suite. @ 01/15/25 03:04:41.657
  STEP: Destroying namespace "webhook-markers-3944" for this suite. @ 01/15/25 03:04:41.676
• [6.557 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/resource_quota.go:331
  STEP: Creating a kubernetes client @ 01/15/25 03:04:41.689
  I0115 03:04:41.689068 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename resourcequota @ 01/15/25 03:04:41.69
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 03:04:41.715
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 03:04:41.727
  E0115 03:04:42.003444      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:04:43.004098      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:04:44.004907      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:04:45.005890      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:04:46.006939      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:04:47.007394      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:04:48.008372      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:04:49.008492      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:04:50.008801      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:04:51.009249      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:04:52.009616      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:04:53.010662      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:04:54.011620      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:04:55.012089      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:04:56.013472      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:04:57.013962      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:04:58.014833      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Counting existing ResourceQuota @ 01/15/25 03:04:58.751
  E0115 03:04:59.015817      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:05:00.016193      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:05:01.017194      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:05:02.017977      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:05:03.018919      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 01/15/25 03:05:03.763
  STEP: Ensuring resource quota status is calculated @ 01/15/25 03:05:03.783
  E0115 03:05:04.021581      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:05:05.022172      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Creating a ConfigMap @ 01/15/25 03:05:05.788
  STEP: Ensuring resource quota status captures configMap creation @ 01/15/25 03:05:05.797
  E0115 03:05:06.023033      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:05:07.024329      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Deleting a ConfigMap @ 01/15/25 03:05:07.81
  STEP: Ensuring resource quota status released usage @ 01/15/25 03:05:07.828
  E0115 03:05:08.025262      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:05:09.026379      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 03:05:09.836855 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-7157" for this suite. @ 01/15/25 03:05:09.844
• [28.162 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/projected_configmap.go:90
  STEP: Creating a kubernetes client @ 01/15/25 03:05:09.851
  I0115 03:05:09.851076 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename projected @ 01/15/25 03:05:09.852
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 03:05:09.865
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 03:05:09.87
  STEP: Creating configMap with name projected-configmap-test-volume-map-f7d64146-52cf-49b2-a2d5-4627ecbd6088 @ 01/15/25 03:05:09.874
  STEP: Creating a pod to test consume configMaps @ 01/15/25 03:05:09.882
  E0115 03:05:10.027858      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:05:11.028757      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:05:12.030494      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:05:13.031438      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 03:05:13.913
  I0115 03:05:13.917160 24 output.go:207] Trying to get logs from node 192.168.18.92 pod pod-projected-configmaps-2c1d7abb-288c-47ca-a74a-552b34d65867 container agnhost-container: <nil>
  STEP: delete the pod @ 01/15/25 03:05:13.926
  I0115 03:05:13.945081 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-32" for this suite. @ 01/15/25 03:05:13.951
• [4.107 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/init_container.go:459
  STEP: Creating a kubernetes client @ 01/15/25 03:05:13.958
  I0115 03:05:13.958736 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename init-container @ 01/15/25 03:05:13.96
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 03:05:13.979
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 03:05:13.985
  STEP: creating the pod @ 01/15/25 03:05:13.99
  I0115 03:05:13.990671 24 init_container.go:499] PodSpec: initContainers in spec.initContainers
  E0115 03:05:14.031585      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:05:15.032150      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:05:16.033796      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:05:17.034677      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:05:18.035044      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 03:05:18.786606 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-6626" for this suite. @ 01/15/25 03:05:18.801
• [4.857 seconds]
------------------------------
S
------------------------------
[sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/expansion.go:48
  STEP: Creating a kubernetes client @ 01/15/25 03:05:18.816
  I0115 03:05:18.816699 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename var-expansion @ 01/15/25 03:05:18.818
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 03:05:18.846
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 03:05:18.854
  STEP: Creating a pod to test env composition @ 01/15/25 03:05:18.861
  E0115 03:05:19.037064      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:05:20.037300      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:05:21.038532      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:05:22.038639      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:05:23.039611      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:05:24.072065      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 03:05:24.93
  I0115 03:05:24.944804 24 output.go:207] Trying to get logs from node 192.168.18.92 pod var-expansion-36c340ae-def8-4579-8860-f32802a840b0 container dapi-container: <nil>
  STEP: delete the pod @ 01/15/25 03:05:24.987
  I0115 03:05:25.033809 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  E0115 03:05:25.073275      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Destroying namespace "var-expansion-5850" for this suite. @ 01/15/25 03:05:25.081
• [6.305 seconds]
------------------------------
S
------------------------------
[sig-apps] ReplicationController should serve a basic image on each replica with a public image [Conformance] [sig-apps, Conformance]
k8s.io/kubernetes/test/e2e/apps/rc.go:70
  STEP: Creating a kubernetes client @ 01/15/25 03:05:25.121
  I0115 03:05:25.121548 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename replication-controller @ 01/15/25 03:05:25.124
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 03:05:25.203
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 03:05:25.24
  STEP: Creating replication controller my-hostname-basic-09b314e5-1ed1-493e-a078-ea029ac181a4 @ 01/15/25 03:05:25.265
  I0115 03:05:25.293214 24 resource.go:87] Pod name my-hostname-basic-09b314e5-1ed1-493e-a078-ea029ac181a4: Found 0 pods out of 1
  E0115 03:05:26.077291      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:05:27.092292      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:05:28.093995      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:05:29.094186      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:05:30.095974      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 03:05:30.329589 24 resource.go:87] Pod name my-hostname-basic-09b314e5-1ed1-493e-a078-ea029ac181a4: Found 1 pods out of 1
  I0115 03:05:30.329671 24 rc.go:507] Ensuring all pods for ReplicationController "my-hostname-basic-09b314e5-1ed1-493e-a078-ea029ac181a4" are running
  I0115 03:05:30.335042 24 rc.go:523] Pod "my-hostname-basic-09b314e5-1ed1-493e-a078-ea029ac181a4-t8xx9" is running and ready(conditions: [{Type:PodReadyToStartContainers Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2025-01-15 03:05:28 +0000 UTC Reason: Message:} {Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2025-01-15 03:05:25 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2025-01-15 03:05:28 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2025-01-15 03:05:28 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2025-01-15 03:05:25 +0000 UTC Reason: Message:}])
  I0115 03:05:30.335140 24 rc.go:531] Trying to dial the pod
  STEP: trying to dial each unique pod @ 01/15/25 03:05:30.335
  I0115 03:05:30.487302 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-5870" for this suite. @ 01/15/25 03:05:30.495
• [5.387 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply an update to a Namespace [Conformance] [sig-api-machinery, Serial, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/namespace.go:372
  STEP: Creating a kubernetes client @ 01/15/25 03:05:30.508
  I0115 03:05:30.508435 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename namespaces @ 01/15/25 03:05:30.51
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 03:05:30.565
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 03:05:30.588
  STEP: Updating Namespace "namespaces-6511" @ 01/15/25 03:05:30.609
  I0115 03:05:30.661458 24 namespace.go:389] Namespace "namespaces-6511" now has labels, map[string]string{"e2e-framework":"namespaces", "e2e-run":"e51f20a0-d7bf-4a6e-8c2b-350d70a722da", "kubernetes.io/metadata.name":"namespaces-6511", "namespaces-6511":"updated", "pod-security.kubernetes.io/audit":"baseline", "pod-security.kubernetes.io/enforce":"baseline", "pod-security.kubernetes.io/warn":"baseline"}
  I0115 03:05:30.661672 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-6511" for this suite. @ 01/15/25 03:05:30.677
• [0.181 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance] [sig-scheduling, Serial, Conformance]
k8s.io/kubernetes/test/e2e/scheduling/preemption.go:124
  STEP: Creating a kubernetes client @ 01/15/25 03:05:30.69
  I0115 03:05:30.690625 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename sched-preemption @ 01/15/25 03:05:30.692
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 03:05:30.712
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 03:05:30.725
  I0115 03:05:30.751739 24 wait.go:51] Waiting up to 1m0s for all nodes to be ready
  E0115 03:05:31.096201      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:05:32.098648      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:05:33.099872      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:05:34.100888      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:05:35.101611      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:05:36.101894      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:05:37.102850      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:05:38.104102      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:05:39.104208      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:05:40.105223      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:05:41.106994      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:05:42.107675      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:05:43.109548      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:05:44.110647      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:05:45.111760      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:05:46.112767      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:05:47.113424      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:05:48.114852      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:05:49.115997      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:05:50.118075      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:05:51.118508      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:05:52.119471      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:05:53.120318      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:05:54.122199      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:05:55.122907      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:05:56.122832      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:05:57.123365      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:05:58.128766      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:05:59.129074      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:06:00.130150      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:06:01.131270      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:06:02.143358      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:06:03.151203      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:06:04.151625      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:06:05.151789      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:06:06.152294      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:06:07.152984      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:06:08.155054      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:06:09.155675      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:06:10.155654      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:06:11.156546      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:06:12.157698      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:06:13.157885      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:06:14.158698      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:06:15.160004      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:06:16.160785      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:06:17.161679      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:06:18.162680      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:06:19.164224      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:06:20.165106      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:06:21.166140      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:06:22.166805      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:06:23.167532      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:06:24.168288      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:06:25.170276      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:06:26.171649      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:06:27.173014      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:06:28.173109      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:06:29.176176      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:06:30.177636      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 03:06:30.767867 24 util.go:396] Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 01/15/25 03:06:30.777
  STEP: Adding a custom resource @ 01/15/25 03:06:30.777
  I0115 03:06:30.821192 24 preemption.go:168] Created pod: pod0-0-sched-preemption-low-priority
  I0115 03:06:30.828981 24 preemption.go:168] Created pod: pod0-1-sched-preemption-medium-priority
  STEP: Adding a custom resource @ 01/15/25 03:06:30.829
  I0115 03:06:30.859170 24 preemption.go:168] Created pod: pod1-0-sched-preemption-medium-priority
  I0115 03:06:30.867447 24 preemption.go:168] Created pod: pod1-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 01/15/25 03:06:30.867
  E0115 03:06:31.178586      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:06:32.179389      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Run a high priority pod that has same requirements as that of lower priority pod @ 01/15/25 03:06:32.924
  E0115 03:06:33.181035      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:06:34.182769      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:06:35.183897      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:06:36.184542      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Removing a custom resource @ 01/15/25 03:06:37.043
  STEP: Removing a custom resource @ 01/15/25 03:06:37.07
  I0115 03:06:37.106144 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-1120" for this suite. @ 01/15/25 03:06:37.123
• [66.454 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for API chunking should return chunks of results for list calls [Conformance] [sig-api-machinery, Conformance]
k8s.io/kubernetes/test/e2e/apimachinery/chunking.go:83
  STEP: Creating a kubernetes client @ 01/15/25 03:06:37.146
  I0115 03:06:37.146160 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename chunking @ 01/15/25 03:06:37.152
  E0115 03:06:37.186905      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 03:06:37.205
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 03:06:37.22
  STEP: creating a large number of resources @ 01/15/25 03:06:37.231
  E0115 03:06:38.187056      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:06:39.188321      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:06:40.188644      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:06:41.189019      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:06:42.190827      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 03:06:42.765899      24 request.go:729] Waited for 1.003987901s due to client-side throttling, not priority and fairness, request: POST:https://169.169.0.1:443/api/v1/namespaces/chunking-5131/podtemplates
  E0115 03:06:43.194155      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:06:44.195662      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:06:45.196427      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:06:46.196680      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:06:47.198787      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:06:48.200003      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:06:49.201076      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:06:50.202131      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:06:51.203073      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:06:52.204946      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:06:53.205324      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 03:06:53.418190      24 request.go:729] Waited for 1.008202549s due to client-side throttling, not priority and fairness, request: POST:https://169.169.0.1:443/api/v1/namespaces/chunking-5131/podtemplates
  E0115 03:06:54.205746      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: retrieving those results in paged fashion several times @ 01/15/25 03:06:54.877
  I0115 03:06:54.913192 24 chunking.go:98] Retrieved 17/17 results with rv 192903 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTAzLCJzdGFydCI6Ii90ZW1wbGF0ZS0wMDE2XHUwMDAwIn0
  I0115 03:06:54.966049 24 chunking.go:98] Retrieved 17/17 results with rv 192903 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTAzLCJzdGFydCI6InRlbXBsYXRlLTAwMzNcdTAwMDAifQ
  I0115 03:06:55.014381 24 chunking.go:98] Retrieved 17/17 results with rv 192903 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTAzLCJzdGFydCI6InRlbXBsYXRlLTAwNTBcdTAwMDAifQ
  I0115 03:06:55.061979 24 chunking.go:98] Retrieved 17/17 results with rv 192903 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTAzLCJzdGFydCI6InRlbXBsYXRlLTAwNjdcdTAwMDAifQ
  I0115 03:06:55.113801 24 chunking.go:98] Retrieved 17/17 results with rv 192903 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTAzLCJzdGFydCI6InRlbXBsYXRlLTAwODRcdTAwMDAifQ
  I0115 03:06:55.168194 24 chunking.go:98] Retrieved 17/17 results with rv 192903 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTAzLCJzdGFydCI6InRlbXBsYXRlLTAxMDFcdTAwMDAifQ
  E0115 03:06:55.206359      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 03:06:55.222324 24 chunking.go:98] Retrieved 17/17 results with rv 192903 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTAzLCJzdGFydCI6InRlbXBsYXRlLTAxMThcdTAwMDAifQ
  I0115 03:06:55.272005 24 chunking.go:98] Retrieved 17/17 results with rv 192903 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTAzLCJzdGFydCI6InRlbXBsYXRlLTAxMzVcdTAwMDAifQ
  I0115 03:06:55.318801 24 chunking.go:98] Retrieved 17/17 results with rv 192903 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTAzLCJzdGFydCI6InRlbXBsYXRlLTAxNTJcdTAwMDAifQ
  I0115 03:06:55.368555 24 chunking.go:98] Retrieved 17/17 results with rv 192903 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTAzLCJzdGFydCI6InRlbXBsYXRlLTAxNjlcdTAwMDAifQ
  I0115 03:06:55.424337 24 chunking.go:98] Retrieved 17/17 results with rv 192903 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTAzLCJzdGFydCI6InRlbXBsYXRlLTAxODZcdTAwMDAifQ
  I0115 03:06:55.466291 24 chunking.go:98] Retrieved 17/17 results with rv 192903 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTAzLCJzdGFydCI6InRlbXBsYXRlLTAyMDNcdTAwMDAifQ
  I0115 03:06:55.513262 24 chunking.go:98] Retrieved 17/17 results with rv 192903 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTAzLCJzdGFydCI6InRlbXBsYXRlLTAyMjBcdTAwMDAifQ
  I0115 03:06:55.560676 24 chunking.go:98] Retrieved 17/17 results with rv 192903 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTAzLCJzdGFydCI6InRlbXBsYXRlLTAyMzdcdTAwMDAifQ
  I0115 03:06:55.611553 24 chunking.go:98] Retrieved 17/17 results with rv 192903 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTAzLCJzdGFydCI6InRlbXBsYXRlLTAyNTRcdTAwMDAifQ
  I0115 03:06:55.660031 24 chunking.go:98] Retrieved 17/17 results with rv 192903 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTAzLCJzdGFydCI6InRlbXBsYXRlLTAyNzFcdTAwMDAifQ
  I0115 03:06:55.723734 24 chunking.go:98] Retrieved 17/17 results with rv 192903 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTAzLCJzdGFydCI6InRlbXBsYXRlLTAyODhcdTAwMDAifQ
  I0115 03:06:55.767969 24 chunking.go:98] Retrieved 17/17 results with rv 192903 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTAzLCJzdGFydCI6InRlbXBsYXRlLTAzMDVcdTAwMDAifQ
  I0115 03:06:55.820908 24 chunking.go:98] Retrieved 17/17 results with rv 192903 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTAzLCJzdGFydCI6InRlbXBsYXRlLTAzMjJcdTAwMDAifQ
  I0115 03:06:55.859977 24 chunking.go:98] Retrieved 17/17 results with rv 192903 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTAzLCJzdGFydCI6InRlbXBsYXRlLTAzMzlcdTAwMDAifQ
  I0115 03:06:55.911451 24 chunking.go:98] Retrieved 17/17 results with rv 192903 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTAzLCJzdGFydCI6InRlbXBsYXRlLTAzNTZcdTAwMDAifQ
  I0115 03:06:55.964805 24 chunking.go:98] Retrieved 17/17 results with rv 192903 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTAzLCJzdGFydCI6InRlbXBsYXRlLTAzNzNcdTAwMDAifQ
  I0115 03:06:56.011209 24 chunking.go:98] Retrieved 17/17 results with rv 192903 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTAzLCJzdGFydCI6InRlbXBsYXRlLTAzOTBcdTAwMDAifQ
  I0115 03:06:56.060441 24 chunking.go:98] Retrieved 9/17 results with rv 192903 and continue 
  I0115 03:06:56.115505 24 chunking.go:98] Retrieved 17/17 results with rv 192905 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTA1LCJzdGFydCI6Ii90ZW1wbGF0ZS0wMDE2XHUwMDAwIn0
  I0115 03:06:56.163460 24 chunking.go:98] Retrieved 17/17 results with rv 192905 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTA1LCJzdGFydCI6InRlbXBsYXRlLTAwMzNcdTAwMDAifQ
  E0115 03:06:56.207994      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 03:06:56.222159 24 chunking.go:98] Retrieved 17/17 results with rv 192905 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTA1LCJzdGFydCI6InRlbXBsYXRlLTAwNTBcdTAwMDAifQ
  I0115 03:06:56.280016 24 chunking.go:98] Retrieved 17/17 results with rv 192905 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTA1LCJzdGFydCI6InRlbXBsYXRlLTAwNjdcdTAwMDAifQ
  I0115 03:06:56.354406 24 chunking.go:98] Retrieved 17/17 results with rv 192905 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTA1LCJzdGFydCI6InRlbXBsYXRlLTAwODRcdTAwMDAifQ
  I0115 03:06:56.376055 24 chunking.go:98] Retrieved 17/17 results with rv 192905 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTA1LCJzdGFydCI6InRlbXBsYXRlLTAxMDFcdTAwMDAifQ
  I0115 03:06:56.426075 24 chunking.go:98] Retrieved 17/17 results with rv 192905 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTA1LCJzdGFydCI6InRlbXBsYXRlLTAxMThcdTAwMDAifQ
  I0115 03:06:56.478720 24 chunking.go:98] Retrieved 17/17 results with rv 192905 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTA1LCJzdGFydCI6InRlbXBsYXRlLTAxMzVcdTAwMDAifQ
  I0115 03:06:56.534135 24 chunking.go:98] Retrieved 17/17 results with rv 192905 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTA1LCJzdGFydCI6InRlbXBsYXRlLTAxNTJcdTAwMDAifQ
  I0115 03:06:56.563563 24 chunking.go:98] Retrieved 17/17 results with rv 192905 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTA1LCJzdGFydCI6InRlbXBsYXRlLTAxNjlcdTAwMDAifQ
  I0115 03:06:56.610796 24 chunking.go:98] Retrieved 17/17 results with rv 192905 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTA1LCJzdGFydCI6InRlbXBsYXRlLTAxODZcdTAwMDAifQ
  I0115 03:06:56.661124 24 chunking.go:98] Retrieved 17/17 results with rv 192905 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTA1LCJzdGFydCI6InRlbXBsYXRlLTAyMDNcdTAwMDAifQ
  I0115 03:06:56.713187 24 chunking.go:98] Retrieved 17/17 results with rv 192905 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTA1LCJzdGFydCI6InRlbXBsYXRlLTAyMjBcdTAwMDAifQ
  I0115 03:06:56.761292 24 chunking.go:98] Retrieved 17/17 results with rv 192905 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTA1LCJzdGFydCI6InRlbXBsYXRlLTAyMzdcdTAwMDAifQ
  I0115 03:06:56.809784 24 chunking.go:98] Retrieved 17/17 results with rv 192905 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTA1LCJzdGFydCI6InRlbXBsYXRlLTAyNTRcdTAwMDAifQ
  I0115 03:06:56.860144 24 chunking.go:98] Retrieved 17/17 results with rv 192905 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTA1LCJzdGFydCI6InRlbXBsYXRlLTAyNzFcdTAwMDAifQ
  I0115 03:06:56.923228 24 chunking.go:98] Retrieved 17/17 results with rv 192905 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTA1LCJzdGFydCI6InRlbXBsYXRlLTAyODhcdTAwMDAifQ
  I0115 03:06:56.961500 24 chunking.go:98] Retrieved 17/17 results with rv 192905 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTA1LCJzdGFydCI6InRlbXBsYXRlLTAzMDVcdTAwMDAifQ
  I0115 03:06:57.011249 24 chunking.go:98] Retrieved 17/17 results with rv 192905 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTA1LCJzdGFydCI6InRlbXBsYXRlLTAzMjJcdTAwMDAifQ
  I0115 03:06:57.061341 24 chunking.go:98] Retrieved 17/17 results with rv 192905 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTA1LCJzdGFydCI6InRlbXBsYXRlLTAzMzlcdTAwMDAifQ
  I0115 03:06:57.109996 24 chunking.go:98] Retrieved 17/17 results with rv 192905 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTA1LCJzdGFydCI6InRlbXBsYXRlLTAzNTZcdTAwMDAifQ
  I0115 03:06:57.160271 24 chunking.go:98] Retrieved 17/17 results with rv 192905 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTA1LCJzdGFydCI6InRlbXBsYXRlLTAzNzNcdTAwMDAifQ
  E0115 03:06:57.208505      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 03:06:57.214847 24 chunking.go:98] Retrieved 17/17 results with rv 192905 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTA1LCJzdGFydCI6InRlbXBsYXRlLTAzOTBcdTAwMDAifQ
  I0115 03:06:57.264321 24 chunking.go:98] Retrieved 9/17 results with rv 192905 and continue 
  I0115 03:06:57.311067 24 chunking.go:98] Retrieved 17/17 results with rv 192907 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTA3LCJzdGFydCI6Ii90ZW1wbGF0ZS0wMDE2XHUwMDAwIn0
  I0115 03:06:57.362313 24 chunking.go:98] Retrieved 17/17 results with rv 192907 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTA3LCJzdGFydCI6InRlbXBsYXRlLTAwMzNcdTAwMDAifQ
  I0115 03:06:57.422999 24 chunking.go:98] Retrieved 17/17 results with rv 192907 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTA3LCJzdGFydCI6InRlbXBsYXRlLTAwNTBcdTAwMDAifQ
  I0115 03:06:57.461217 24 chunking.go:98] Retrieved 17/17 results with rv 192907 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTA3LCJzdGFydCI6InRlbXBsYXRlLTAwNjdcdTAwMDAifQ
  I0115 03:06:57.557064 24 chunking.go:98] Retrieved 17/17 results with rv 192907 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTA3LCJzdGFydCI6InRlbXBsYXRlLTAwODRcdTAwMDAifQ
  I0115 03:06:57.578966 24 chunking.go:98] Retrieved 17/17 results with rv 192907 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTA3LCJzdGFydCI6InRlbXBsYXRlLTAxMDFcdTAwMDAifQ
  I0115 03:06:57.645635 24 chunking.go:98] Retrieved 17/17 results with rv 192907 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTA3LCJzdGFydCI6InRlbXBsYXRlLTAxMThcdTAwMDAifQ
  I0115 03:06:57.695552 24 chunking.go:98] Retrieved 17/17 results with rv 192907 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTA3LCJzdGFydCI6InRlbXBsYXRlLTAxMzVcdTAwMDAifQ
  I0115 03:06:57.722309 24 chunking.go:98] Retrieved 17/17 results with rv 192907 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTA3LCJzdGFydCI6InRlbXBsYXRlLTAxNTJcdTAwMDAifQ
  I0115 03:06:57.767914 24 chunking.go:98] Retrieved 17/17 results with rv 192907 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTA3LCJzdGFydCI6InRlbXBsYXRlLTAxNjlcdTAwMDAifQ
  I0115 03:06:57.812079 24 chunking.go:98] Retrieved 17/17 results with rv 192907 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTA3LCJzdGFydCI6InRlbXBsYXRlLTAxODZcdTAwMDAifQ
  I0115 03:06:57.865081 24 chunking.go:98] Retrieved 17/17 results with rv 192907 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTA3LCJzdGFydCI6InRlbXBsYXRlLTAyMDNcdTAwMDAifQ
  I0115 03:06:57.912490 24 chunking.go:98] Retrieved 17/17 results with rv 192907 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTA3LCJzdGFydCI6InRlbXBsYXRlLTAyMjBcdTAwMDAifQ
  I0115 03:06:57.965596 24 chunking.go:98] Retrieved 17/17 results with rv 192907 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTA3LCJzdGFydCI6InRlbXBsYXRlLTAyMzdcdTAwMDAifQ
  I0115 03:06:58.014928 24 chunking.go:98] Retrieved 17/17 results with rv 192907 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTA3LCJzdGFydCI6InRlbXBsYXRlLTAyNTRcdTAwMDAifQ
  I0115 03:06:58.069170 24 chunking.go:98] Retrieved 17/17 results with rv 192907 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTA3LCJzdGFydCI6InRlbXBsYXRlLTAyNzFcdTAwMDAifQ
  I0115 03:06:58.113117 24 chunking.go:98] Retrieved 17/17 results with rv 192907 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTA3LCJzdGFydCI6InRlbXBsYXRlLTAyODhcdTAwMDAifQ
  I0115 03:06:58.164655 24 chunking.go:98] Retrieved 17/17 results with rv 192907 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTA3LCJzdGFydCI6InRlbXBsYXRlLTAzMDVcdTAwMDAifQ
  E0115 03:06:58.208864      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  I0115 03:06:58.212254 24 chunking.go:98] Retrieved 17/17 results with rv 192907 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTA3LCJzdGFydCI6InRlbXBsYXRlLTAzMjJcdTAwMDAifQ
  I0115 03:06:58.264726 24 chunking.go:98] Retrieved 17/17 results with rv 192907 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTA3LCJzdGFydCI6InRlbXBsYXRlLTAzMzlcdTAwMDAifQ
  I0115 03:06:58.311845 24 chunking.go:98] Retrieved 17/17 results with rv 192907 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTA3LCJzdGFydCI6InRlbXBsYXRlLTAzNTZcdTAwMDAifQ
  I0115 03:06:58.360879 24 chunking.go:98] Retrieved 17/17 results with rv 192907 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTA3LCJzdGFydCI6InRlbXBsYXRlLTAzNzNcdTAwMDAifQ
  I0115 03:06:58.427872 24 chunking.go:98] Retrieved 17/17 results with rv 192907 and continue eyJ2IjoibWV0YS5rOHMuaW8vdjEiLCJydiI6MTkyOTA3LCJzdGFydCI6InRlbXBsYXRlLTAzOTBcdTAwMDAifQ
  I0115 03:06:58.465321 24 chunking.go:98] Retrieved 9/17 results with rv 192907 and continue 
  STEP: retrieving those results all at once @ 01/15/25 03:06:58.465
  I0115 03:06:58.533805 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "chunking-5131" for this suite. @ 01/15/25 03:06:58.572
• [21.494 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance] [sig-storage, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/storage/secrets_volume.go:89
  STEP: Creating a kubernetes client @ 01/15/25 03:06:58.64
  I0115 03:06:58.640542 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename secrets @ 01/15/25 03:06:58.646
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 03:06:58.701
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 03:06:58.714
  STEP: Creating secret with name secret-test-map-0933d4e1-2bbb-45b6-98f5-f8fc6ddaa821 @ 01/15/25 03:06:58.747
  STEP: Creating a pod to test consume secrets @ 01/15/25 03:06:58.813
  E0115 03:06:59.209056      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:07:00.211072      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:07:01.212453      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:07:02.213580      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:07:03.214637      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:07:04.215328      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:07:05.215706      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:07:06.224173      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 01/15/25 03:07:06.967
  I0115 03:07:06.986960 24 output.go:207] Trying to get logs from node 192.168.18.92 pod pod-secrets-733fbbfa-d0a6-4028-ad7d-31ded0b965ae container secret-volume-test: <nil>
  STEP: delete the pod @ 01/15/25 03:07:07.082
  I0115 03:07:07.204066 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  E0115 03:07:07.226554      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: Destroying namespace "secrets-4008" for this suite. @ 01/15/25 03:07:07.242
• [8.628 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance] [sig-node, NodeConformance, Conformance]
k8s.io/kubernetes/test/e2e/common/node/runtime.go:232
  STEP: Creating a kubernetes client @ 01/15/25 03:07:07.268
  I0115 03:07:07.268727 24 util.go:502] >>> kubeConfig: /tmp/kubeconfig-2182528051
  STEP: Building a namespace api object, basename container-runtime @ 01/15/25 03:07:07.277
  STEP: Waiting for a default service account to be provisioned in namespace @ 01/15/25 03:07:07.336
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 01/15/25 03:07:07.349
  STEP: create the container @ 01/15/25 03:07:07.367
  W0115 03:07:07.394744      24 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 01/15/25 03:07:07.395
  E0115 03:07:08.226676      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:07:09.226971      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:07:10.227420      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:07:11.228899      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:07:12.237969      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:07:13.230728      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:07:14.231188      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  E0115 03:07:15.231974      24 retrywatcher.go:160] "Watch failed" err="context canceled"
  STEP: get the container status @ 01/15/25 03:07:15.808
  STEP: the container should be terminated @ 01/15/25 03:07:15.849
  STEP: the termination message should be set @ 01/15/25 03:07:15.849
  I0115 03:07:15.850030 24 runtime.go:167] Expected: &{} to match Container's Termination Message:  --
  STEP: delete the container @ 01/15/25 03:07:15.85
  I0115 03:07:15.971690 24 helper.go:125] Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-544" for this suite. @ 01/15/25 03:07:16.014
• [8.772 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[SynchronizedAfterSuite] 
k8s.io/kubernetes/test/e2e/e2e.go:80
  I0115 03:07:16.043197 24 suites.go:34] Running AfterSuite actions on node 1
  I0115 03:07:16.043243 24 util.go:612] Skipping dumping logs from cluster
[SynchronizedAfterSuite] PASSED [0.000 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e suite report
k8s.io/kubernetes/test/e2e/e2e_test.go:158
[ReportAfterSuite] PASSED [0.000 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e JUnit report
k8s.io/kubernetes/test/e2e/framework/test_context.go:615
  E0115 03:07:16.233837      24 retrywatcher.go:160] "Watch failed" err="context canceled"
[ReportAfterSuite] PASSED [0.474 seconds]
------------------------------

Ran 411 of 6622 Specs in 6590.595 seconds
SUCCESS! -- 411 Passed | 0 Failed | 0 Pending | 6211 Skipped
PASS

Ginkgo ran 1 suite in 1h49m56.481130233s
Test Suite Passed
