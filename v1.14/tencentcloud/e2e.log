I0903 08:18:11.526037      16 test_context.go:405] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-356901984
I0903 08:18:11.526153      16 e2e.go:240] Starting e2e run "5deee41f-ce23-11e9-a824-e6b94fc13bb4" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1567498690 - Will randomize all specs
Will run 204 of 3585 specs

Sep  3 08:18:11.664: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
Sep  3 08:18:11.666: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Sep  3 08:18:11.686: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Sep  3 08:18:11.722: INFO: 9 / 9 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Sep  3 08:18:11.722: INFO: expected 3 pod replicas in namespace 'kube-system', 3 are Running and Ready.
Sep  3 08:18:11.722: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Sep  3 08:18:11.730: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'ip-masq-agent' (0 seconds elapsed)
Sep  3 08:18:11.730: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'tke-bridge-agent' (0 seconds elapsed)
Sep  3 08:18:11.730: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'tke-cni-agent' (0 seconds elapsed)
Sep  3 08:18:11.730: INFO: e2e test version: v1.14.3
Sep  3 08:18:11.731: INFO: kube-apiserver version: v1.14.3-tke.1
SSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:18:11.731: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename proxy
Sep  3 08:18:11.801: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep  3 08:18:11.814: INFO: (0) /api/v1/nodes/10.0.0.6:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.109942ms)
Sep  3 08:18:11.818: INFO: (1) /api/v1/nodes/10.0.0.6:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.716399ms)
Sep  3 08:18:11.823: INFO: (2) /api/v1/nodes/10.0.0.6:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.519166ms)
Sep  3 08:18:11.828: INFO: (3) /api/v1/nodes/10.0.0.6:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.759225ms)
Sep  3 08:18:11.833: INFO: (4) /api/v1/nodes/10.0.0.6:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.880261ms)
Sep  3 08:18:11.837: INFO: (5) /api/v1/nodes/10.0.0.6:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.809046ms)
Sep  3 08:18:11.844: INFO: (6) /api/v1/nodes/10.0.0.6:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.262212ms)
Sep  3 08:18:11.849: INFO: (7) /api/v1/nodes/10.0.0.6:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.2507ms)
Sep  3 08:18:11.854: INFO: (8) /api/v1/nodes/10.0.0.6:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.558307ms)
Sep  3 08:18:11.858: INFO: (9) /api/v1/nodes/10.0.0.6:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.622728ms)
Sep  3 08:18:11.863: INFO: (10) /api/v1/nodes/10.0.0.6:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.020923ms)
Sep  3 08:18:11.874: INFO: (11) /api/v1/nodes/10.0.0.6:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 11.098382ms)
Sep  3 08:18:11.880: INFO: (12) /api/v1/nodes/10.0.0.6:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.252036ms)
Sep  3 08:18:11.885: INFO: (13) /api/v1/nodes/10.0.0.6:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.051419ms)
Sep  3 08:18:11.891: INFO: (14) /api/v1/nodes/10.0.0.6:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.868214ms)
Sep  3 08:18:11.895: INFO: (15) /api/v1/nodes/10.0.0.6:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.747477ms)
Sep  3 08:18:11.902: INFO: (16) /api/v1/nodes/10.0.0.6:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.344289ms)
Sep  3 08:18:11.909: INFO: (17) /api/v1/nodes/10.0.0.6:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.20192ms)
Sep  3 08:18:11.914: INFO: (18) /api/v1/nodes/10.0.0.6:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.732279ms)
Sep  3 08:18:11.924: INFO: (19) /api/v1/nodes/10.0.0.6:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 10.814414ms)
[AfterEach] version v1
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:18:11.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-4245" for this suite.
Sep  3 08:18:17.952: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:18:18.099: INFO: namespace proxy-4245 deletion completed in 6.170538876s

• [SLOW TEST:6.368 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:18:18.100: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-6267714d-ce23-11e9-a824-e6b94fc13bb4
STEP: Creating a pod to test consume secrets
Sep  3 08:18:18.183: INFO: Waiting up to 5m0s for pod "pod-secrets-62686803-ce23-11e9-a824-e6b94fc13bb4" in namespace "secrets-1537" to be "success or failure"
Sep  3 08:18:18.187: INFO: Pod "pod-secrets-62686803-ce23-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.323651ms
Sep  3 08:18:20.193: INFO: Pod "pod-secrets-62686803-ce23-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009341026s
Sep  3 08:18:22.198: INFO: Pod "pod-secrets-62686803-ce23-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014698806s
STEP: Saw pod success
Sep  3 08:18:22.198: INFO: Pod "pod-secrets-62686803-ce23-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 08:18:22.202: INFO: Trying to get logs from node 10.0.0.9 pod pod-secrets-62686803-ce23-11e9-a824-e6b94fc13bb4 container secret-volume-test: <nil>
STEP: delete the pod
Sep  3 08:18:22.280: INFO: Waiting for pod pod-secrets-62686803-ce23-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 08:18:22.283: INFO: Pod pod-secrets-62686803-ce23-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:18:22.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1537" for this suite.
Sep  3 08:18:28.304: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:18:28.550: INFO: namespace secrets-1537 deletion completed in 6.26219359s

• [SLOW TEST:10.450 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:18:28.550: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0903 08:18:34.736538      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep  3 08:18:34.736: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:18:34.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2694" for this suite.
Sep  3 08:18:40.761: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:18:40.975: INFO: namespace gc-2694 deletion completed in 6.228921191s

• [SLOW TEST:12.425 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:18:40.975: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating api versions
Sep  3 08:18:41.043: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 api-versions'
Sep  3 08:18:41.105: INFO: stderr: ""
Sep  3 08:18:41.105: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ncustom.metrics.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:18:41.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7336" for this suite.
Sep  3 08:18:47.126: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:18:47.285: INFO: namespace kubectl-7336 deletion completed in 6.175018093s

• [SLOW TEST:6.310 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:18:47.285: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep  3 08:18:47.341: INFO: Creating ReplicaSet my-hostname-basic-73cbaf70-ce23-11e9-a824-e6b94fc13bb4
Sep  3 08:18:47.351: INFO: Pod name my-hostname-basic-73cbaf70-ce23-11e9-a824-e6b94fc13bb4: Found 0 pods out of 1
Sep  3 08:18:52.355: INFO: Pod name my-hostname-basic-73cbaf70-ce23-11e9-a824-e6b94fc13bb4: Found 1 pods out of 1
Sep  3 08:18:52.355: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-73cbaf70-ce23-11e9-a824-e6b94fc13bb4" is running
Sep  3 08:18:56.380: INFO: Pod "my-hostname-basic-73cbaf70-ce23-11e9-a824-e6b94fc13bb4-nmcmn" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-03 08:18:47 +0000 UTC Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-03 08:18:47 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-73cbaf70-ce23-11e9-a824-e6b94fc13bb4]} {Type:ContainersReady Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-03 08:18:47 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-73cbaf70-ce23-11e9-a824-e6b94fc13bb4]} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-03 08:18:47 +0000 UTC Reason: Message:}])
Sep  3 08:18:56.380: INFO: Trying to dial the pod
Sep  3 08:19:01.397: INFO: Controller my-hostname-basic-73cbaf70-ce23-11e9-a824-e6b94fc13bb4: Got expected result from replica 1 [my-hostname-basic-73cbaf70-ce23-11e9-a824-e6b94fc13bb4-nmcmn]: "my-hostname-basic-73cbaf70-ce23-11e9-a824-e6b94fc13bb4-nmcmn", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:19:01.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-5808" for this suite.
Sep  3 08:19:07.421: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:19:07.624: INFO: namespace replicaset-5808 deletion completed in 6.222490025s

• [SLOW TEST:20.339 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:19:07.624: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-7fea2c0d-ce23-11e9-a824-e6b94fc13bb4
STEP: Creating a pod to test consume configMaps
Sep  3 08:19:07.691: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-7feb2743-ce23-11e9-a824-e6b94fc13bb4" in namespace "projected-3488" to be "success or failure"
Sep  3 08:19:07.695: INFO: Pod "pod-projected-configmaps-7feb2743-ce23-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.528594ms
Sep  3 08:19:09.699: INFO: Pod "pod-projected-configmaps-7feb2743-ce23-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007964449s
STEP: Saw pod success
Sep  3 08:19:09.699: INFO: Pod "pod-projected-configmaps-7feb2743-ce23-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 08:19:09.703: INFO: Trying to get logs from node 10.0.0.9 pod pod-projected-configmaps-7feb2743-ce23-11e9-a824-e6b94fc13bb4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep  3 08:19:09.794: INFO: Waiting for pod pod-projected-configmaps-7feb2743-ce23-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 08:19:09.797: INFO: Pod pod-projected-configmaps-7feb2743-ce23-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:19:09.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3488" for this suite.
Sep  3 08:19:15.817: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:19:15.956: INFO: namespace projected-3488 deletion completed in 6.154002784s

• [SLOW TEST:8.332 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:19:15.956: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
STEP: reading a file in the container
Sep  3 08:19:24.550: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9087 pod-service-account-85320d50-ce23-11e9-a824-e6b94fc13bb4 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Sep  3 08:19:24.724: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9087 pod-service-account-85320d50-ce23-11e9-a824-e6b94fc13bb4 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Sep  3 08:19:24.948: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9087 pod-service-account-85320d50-ce23-11e9-a824-e6b94fc13bb4 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:19:25.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-9087" for this suite.
Sep  3 08:19:31.166: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:19:31.320: INFO: namespace svcaccounts-9087 deletion completed in 6.196240421s

• [SLOW TEST:15.364 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:19:31.322: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Sep  3 08:19:31.375: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep  3 08:19:31.384: INFO: Waiting for terminating namespaces to be deleted...
Sep  3 08:19:31.391: INFO: 
Logging pods the kubelet thinks is on node 10.0.0.6 before test
Sep  3 08:19:31.399: INFO: l7-lb-controller-85665d7887-mbmmm from kube-system started at 2019-09-03 07:25:10 +0000 UTC (1 container statuses recorded)
Sep  3 08:19:31.399: INFO: 	Container l7-lb-controller ready: true, restart count 2
Sep  3 08:19:31.399: INFO: coredns-6d58b575d7-prm6h from kube-system started at 2019-09-03 07:25:10 +0000 UTC (1 container statuses recorded)
Sep  3 08:19:31.399: INFO: 	Container coredns ready: true, restart count 1
Sep  3 08:19:31.399: INFO: tke-cni-agent-bfqbh from kube-system started at 2019-09-03 07:25:10 +0000 UTC (1 container statuses recorded)
Sep  3 08:19:31.399: INFO: 	Container tke-cni-agent ready: true, restart count 1
Sep  3 08:19:31.399: INFO: sonobuoy-systemd-logs-daemon-set-9498ee0a545f46b0-n2nmx from heptio-sonobuoy started at 2019-09-03 08:17:22 +0000 UTC (2 container statuses recorded)
Sep  3 08:19:31.399: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep  3 08:19:31.399: INFO: 	Container systemd-logs ready: true, restart count 0
Sep  3 08:19:31.399: INFO: coredns-6d58b575d7-6v8hl from kube-system started at 2019-09-03 07:25:10 +0000 UTC (1 container statuses recorded)
Sep  3 08:19:31.399: INFO: 	Container coredns ready: true, restart count 1
Sep  3 08:19:31.399: INFO: tke-bridge-agent-xxtpr from kube-system started at 2019-09-03 07:25:10 +0000 UTC (1 container statuses recorded)
Sep  3 08:19:31.399: INFO: 	Container tke-bridge-agent ready: true, restart count 1
Sep  3 08:19:31.399: INFO: ip-masq-agent-567fp from kube-system started at 2019-09-03 07:25:10 +0000 UTC (1 container statuses recorded)
Sep  3 08:19:31.399: INFO: 	Container ip-masq-agent ready: true, restart count 1
Sep  3 08:19:31.399: INFO: 
Logging pods the kubelet thinks is on node 10.0.0.9 before test
Sep  3 08:19:31.405: INFO: tke-bridge-agent-r6m4x from kube-system started at 2019-09-03 07:25:12 +0000 UTC (1 container statuses recorded)
Sep  3 08:19:31.405: INFO: 	Container tke-bridge-agent ready: true, restart count 1
Sep  3 08:19:31.405: INFO: tke-cni-agent-nx5pw from kube-system started at 2019-09-03 07:25:12 +0000 UTC (1 container statuses recorded)
Sep  3 08:19:31.405: INFO: 	Container tke-cni-agent ready: true, restart count 1
Sep  3 08:19:31.405: INFO: sonobuoy-systemd-logs-daemon-set-9498ee0a545f46b0-d2zzq from heptio-sonobuoy started at 2019-09-03 08:17:22 +0000 UTC (2 container statuses recorded)
Sep  3 08:19:31.405: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep  3 08:19:31.405: INFO: 	Container systemd-logs ready: true, restart count 0
Sep  3 08:19:31.405: INFO: ip-masq-agent-nttr5 from kube-system started at 2019-09-03 07:25:12 +0000 UTC (1 container statuses recorded)
Sep  3 08:19:31.405: INFO: 	Container ip-masq-agent ready: true, restart count 1
Sep  3 08:19:31.405: INFO: sonobuoy from heptio-sonobuoy started at 2019-09-03 08:17:16 +0000 UTC (1 container statuses recorded)
Sep  3 08:19:31.405: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep  3 08:19:31.405: INFO: sonobuoy-e2e-job-aaa506819e174e7a from heptio-sonobuoy started at 2019-09-03 08:17:22 +0000 UTC (2 container statuses recorded)
Sep  3 08:19:31.405: INFO: 	Container e2e ready: true, restart count 0
Sep  3 08:19:31.405: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15c0dfd3e0babcde], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:19:32.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9186" for this suite.
Sep  3 08:19:38.466: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:19:38.610: INFO: namespace sched-pred-9186 deletion completed in 6.175821825s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:7.288 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:19:38.610: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: getting the auto-created API token
Sep  3 08:19:39.201: INFO: created pod pod-service-account-defaultsa
Sep  3 08:19:39.201: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Sep  3 08:19:39.206: INFO: created pod pod-service-account-mountsa
Sep  3 08:19:39.206: INFO: pod pod-service-account-mountsa service account token volume mount: true
Sep  3 08:19:39.213: INFO: created pod pod-service-account-nomountsa
Sep  3 08:19:39.213: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Sep  3 08:19:39.223: INFO: created pod pod-service-account-defaultsa-mountspec
Sep  3 08:19:39.223: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Sep  3 08:19:39.232: INFO: created pod pod-service-account-mountsa-mountspec
Sep  3 08:19:39.232: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Sep  3 08:19:39.241: INFO: created pod pod-service-account-nomountsa-mountspec
Sep  3 08:19:39.241: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Sep  3 08:19:39.249: INFO: created pod pod-service-account-defaultsa-nomountspec
Sep  3 08:19:39.249: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Sep  3 08:19:39.257: INFO: created pod pod-service-account-mountsa-nomountspec
Sep  3 08:19:39.257: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Sep  3 08:19:39.264: INFO: created pod pod-service-account-nomountsa-nomountspec
Sep  3 08:19:39.264: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:19:39.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-7017" for this suite.
Sep  3 08:20:03.296: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:20:03.518: INFO: namespace svcaccounts-7017 deletion completed in 24.246329336s

• [SLOW TEST:24.908 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:20:03.518: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-a1491ce2-ce23-11e9-a824-e6b94fc13bb4
STEP: Creating a pod to test consume configMaps
Sep  3 08:20:03.679: INFO: Waiting up to 5m0s for pod "pod-configmaps-a14a0716-ce23-11e9-a824-e6b94fc13bb4" in namespace "configmap-1232" to be "success or failure"
Sep  3 08:20:03.682: INFO: Pod "pod-configmaps-a14a0716-ce23-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.282482ms
Sep  3 08:20:05.686: INFO: Pod "pod-configmaps-a14a0716-ce23-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007246144s
STEP: Saw pod success
Sep  3 08:20:05.686: INFO: Pod "pod-configmaps-a14a0716-ce23-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 08:20:05.689: INFO: Trying to get logs from node 10.0.0.6 pod pod-configmaps-a14a0716-ce23-11e9-a824-e6b94fc13bb4 container configmap-volume-test: <nil>
STEP: delete the pod
Sep  3 08:20:05.718: INFO: Waiting for pod pod-configmaps-a14a0716-ce23-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 08:20:05.724: INFO: Pod pod-configmaps-a14a0716-ce23-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:20:05.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1232" for this suite.
Sep  3 08:20:11.747: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:20:11.899: INFO: namespace configmap-1232 deletion completed in 6.169411025s

• [SLOW TEST:8.381 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:20:11.899: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-a63a7ab2-ce23-11e9-a824-e6b94fc13bb4
STEP: Creating a pod to test consume secrets
Sep  3 08:20:11.970: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a63b6803-ce23-11e9-a824-e6b94fc13bb4" in namespace "projected-1065" to be "success or failure"
Sep  3 08:20:11.973: INFO: Pod "pod-projected-secrets-a63b6803-ce23-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.338596ms
Sep  3 08:20:13.977: INFO: Pod "pod-projected-secrets-a63b6803-ce23-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007634465s
STEP: Saw pod success
Sep  3 08:20:13.977: INFO: Pod "pod-projected-secrets-a63b6803-ce23-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 08:20:13.981: INFO: Trying to get logs from node 10.0.0.9 pod pod-projected-secrets-a63b6803-ce23-11e9-a824-e6b94fc13bb4 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep  3 08:20:14.015: INFO: Waiting for pod pod-projected-secrets-a63b6803-ce23-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 08:20:14.063: INFO: Pod pod-projected-secrets-a63b6803-ce23-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:20:14.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1065" for this suite.
Sep  3 08:20:20.084: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:20:20.227: INFO: namespace projected-1065 deletion completed in 6.159616946s

• [SLOW TEST:8.328 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:20:20.228: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:20:20.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8625" for this suite.
Sep  3 08:20:26.342: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:20:26.491: INFO: namespace kubelet-test-8625 deletion completed in 6.167893802s

• [SLOW TEST:6.263 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:20:26.491: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-2910/configmap-test-aeed3606-ce23-11e9-a824-e6b94fc13bb4
STEP: Creating a pod to test consume configMaps
Sep  3 08:20:26.565: INFO: Waiting up to 5m0s for pod "pod-configmaps-aeee2780-ce23-11e9-a824-e6b94fc13bb4" in namespace "configmap-2910" to be "success or failure"
Sep  3 08:20:26.570: INFO: Pod "pod-configmaps-aeee2780-ce23-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.52885ms
Sep  3 08:20:28.577: INFO: Pod "pod-configmaps-aeee2780-ce23-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011969285s
STEP: Saw pod success
Sep  3 08:20:28.577: INFO: Pod "pod-configmaps-aeee2780-ce23-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 08:20:28.581: INFO: Trying to get logs from node 10.0.0.9 pod pod-configmaps-aeee2780-ce23-11e9-a824-e6b94fc13bb4 container env-test: <nil>
STEP: delete the pod
Sep  3 08:20:28.691: INFO: Waiting for pod pod-configmaps-aeee2780-ce23-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 08:20:28.694: INFO: Pod pod-configmaps-aeee2780-ce23-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:20:28.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2910" for this suite.
Sep  3 08:20:34.716: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:20:34.890: INFO: namespace configmap-2910 deletion completed in 6.190854823s

• [SLOW TEST:8.399 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:20:34.890: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1510
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep  3 08:20:34.946: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-504'
Sep  3 08:20:35.108: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep  3 08:20:35.108: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1515
Sep  3 08:20:35.126: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 delete jobs e2e-test-nginx-job --namespace=kubectl-504'
Sep  3 08:20:35.216: INFO: stderr: ""
Sep  3 08:20:35.216: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:20:35.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-504" for this suite.
Sep  3 08:20:41.235: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:20:41.460: INFO: namespace kubectl-504 deletion completed in 6.23948344s

• [SLOW TEST:6.570 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:20:41.461: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-2449
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep  3 08:20:41.532: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep  3 08:21:05.664: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.22.1.19:8080/dial?request=hostName&protocol=http&host=172.22.1.18&port=8080&tries=1'] Namespace:pod-network-test-2449 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  3 08:21:05.664: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
Sep  3 08:21:05.772: INFO: Waiting for endpoints: map[]
Sep  3 08:21:05.776: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.22.1.19:8080/dial?request=hostName&protocol=http&host=172.22.0.21&port=8080&tries=1'] Namespace:pod-network-test-2449 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  3 08:21:05.776: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
Sep  3 08:21:05.889: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:21:05.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-2449" for this suite.
Sep  3 08:21:29.913: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:21:30.121: INFO: namespace pod-network-test-2449 deletion completed in 24.223496718s

• [SLOW TEST:48.660 seconds]
[sig-network] Networking
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:21:30.121: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:21:30.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9792" for this suite.
Sep  3 08:21:36.215: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:21:36.448: INFO: namespace services-9792 deletion completed in 6.257912802s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:6.327 seconds]
[sig-network] Services
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:21:36.448: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-d8a46a8a-ce23-11e9-a824-e6b94fc13bb4
STEP: Creating secret with name s-test-opt-upd-d8a46ace-ce23-11e9-a824-e6b94fc13bb4
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-d8a46a8a-ce23-11e9-a824-e6b94fc13bb4
STEP: Updating secret s-test-opt-upd-d8a46ace-ce23-11e9-a824-e6b94fc13bb4
STEP: Creating secret with name s-test-opt-create-d8a46aff-ce23-11e9-a824-e6b94fc13bb4
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:21:40.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6205" for this suite.
Sep  3 08:22:04.720: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:22:04.921: INFO: namespace projected-6205 deletion completed in 24.22106465s

• [SLOW TEST:28.473 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:22:04.921: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Sep  3 08:22:11.044: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  3 08:22:11.047: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  3 08:22:13.047: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  3 08:22:13.053: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  3 08:22:15.047: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  3 08:22:15.054: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  3 08:22:17.047: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  3 08:22:17.052: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  3 08:22:19.047: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  3 08:22:19.076: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  3 08:22:21.047: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  3 08:22:21.052: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  3 08:22:23.047: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  3 08:22:23.052: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  3 08:22:25.047: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  3 08:22:25.052: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  3 08:22:27.047: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  3 08:22:27.052: INFO: Pod pod-with-poststart-exec-hook still exists
Sep  3 08:22:29.048: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep  3 08:22:29.052: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:22:29.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-17" for this suite.
Sep  3 08:22:53.072: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:22:53.298: INFO: namespace container-lifecycle-hook-17 deletion completed in 24.241984775s

• [SLOW TEST:48.377 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:22:53.298: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-7305
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep  3 08:22:53.348: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep  3 08:23:15.606: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.22.1.22:8080/dial?request=hostName&protocol=udp&host=172.22.0.24&port=8081&tries=1'] Namespace:pod-network-test-7305 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  3 08:23:15.606: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
Sep  3 08:23:15.706: INFO: Waiting for endpoints: map[]
Sep  3 08:23:15.721: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.22.1.22:8080/dial?request=hostName&protocol=udp&host=172.22.1.21&port=8081&tries=1'] Namespace:pod-network-test-7305 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  3 08:23:15.721: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
Sep  3 08:23:15.829: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:23:15.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7305" for this suite.
Sep  3 08:23:39.850: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:23:40.035: INFO: namespace pod-network-test-7305 deletion completed in 24.20063621s

• [SLOW TEST:46.737 seconds]
[sig-network] Networking
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:23:40.035: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-22490aa8-ce24-11e9-a824-e6b94fc13bb4
STEP: Creating a pod to test consume configMaps
Sep  3 08:23:40.105: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-224a0ac2-ce24-11e9-a824-e6b94fc13bb4" in namespace "projected-2997" to be "success or failure"
Sep  3 08:23:40.108: INFO: Pod "pod-projected-configmaps-224a0ac2-ce24-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.444281ms
Sep  3 08:23:42.112: INFO: Pod "pod-projected-configmaps-224a0ac2-ce24-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007842552s
STEP: Saw pod success
Sep  3 08:23:42.113: INFO: Pod "pod-projected-configmaps-224a0ac2-ce24-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 08:23:42.116: INFO: Trying to get logs from node 10.0.0.6 pod pod-projected-configmaps-224a0ac2-ce24-11e9-a824-e6b94fc13bb4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep  3 08:23:42.191: INFO: Waiting for pod pod-projected-configmaps-224a0ac2-ce24-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 08:23:42.195: INFO: Pod pod-projected-configmaps-224a0ac2-ce24-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:23:42.195: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2997" for this suite.
Sep  3 08:23:48.216: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:23:48.413: INFO: namespace projected-2997 deletion completed in 6.213635736s

• [SLOW TEST:8.378 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:23:48.414: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep  3 08:23:48.477: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:23:50.514: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1271" for this suite.
Sep  3 08:24:36.536: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:24:36.712: INFO: namespace pods-1271 deletion completed in 46.191331073s

• [SLOW TEST:48.298 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:24:36.712: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override command
Sep  3 08:24:36.770: INFO: Waiting up to 5m0s for pod "client-containers-44108e53-ce24-11e9-a824-e6b94fc13bb4" in namespace "containers-1497" to be "success or failure"
Sep  3 08:24:36.775: INFO: Pod "client-containers-44108e53-ce24-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 5.718356ms
Sep  3 08:24:38.779: INFO: Pod "client-containers-44108e53-ce24-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009945022s
Sep  3 08:24:40.784: INFO: Pod "client-containers-44108e53-ce24-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014009358s
STEP: Saw pod success
Sep  3 08:24:40.784: INFO: Pod "client-containers-44108e53-ce24-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 08:24:40.787: INFO: Trying to get logs from node 10.0.0.6 pod client-containers-44108e53-ce24-11e9-a824-e6b94fc13bb4 container test-container: <nil>
STEP: delete the pod
Sep  3 08:24:40.826: INFO: Waiting for pod client-containers-44108e53-ce24-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 08:24:40.845: INFO: Pod client-containers-44108e53-ce24-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:24:40.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1497" for this suite.
Sep  3 08:24:46.878: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:24:47.140: INFO: namespace containers-1497 deletion completed in 6.286847671s

• [SLOW TEST:10.428 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:24:47.140: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep  3 08:24:47.255: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4a50e8d0-ce24-11e9-a824-e6b94fc13bb4" in namespace "downward-api-4231" to be "success or failure"
Sep  3 08:24:47.264: INFO: Pod "downwardapi-volume-4a50e8d0-ce24-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 9.025192ms
Sep  3 08:24:49.269: INFO: Pod "downwardapi-volume-4a50e8d0-ce24-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013500431s
STEP: Saw pod success
Sep  3 08:24:49.269: INFO: Pod "downwardapi-volume-4a50e8d0-ce24-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 08:24:49.272: INFO: Trying to get logs from node 10.0.0.9 pod downwardapi-volume-4a50e8d0-ce24-11e9-a824-e6b94fc13bb4 container client-container: <nil>
STEP: delete the pod
Sep  3 08:24:49.301: INFO: Waiting for pod downwardapi-volume-4a50e8d0-ce24-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 08:24:49.304: INFO: Pod downwardapi-volume-4a50e8d0-ce24-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:24:49.304: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4231" for this suite.
Sep  3 08:24:55.326: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:24:55.567: INFO: namespace downward-api-4231 deletion completed in 6.258367547s

• [SLOW TEST:8.427 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:24:55.567: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-4f533589-ce24-11e9-a824-e6b94fc13bb4
STEP: Creating a pod to test consume configMaps
Sep  3 08:24:55.666: INFO: Waiting up to 5m0s for pod "pod-configmaps-4f541dc3-ce24-11e9-a824-e6b94fc13bb4" in namespace "configmap-7423" to be "success or failure"
Sep  3 08:24:55.673: INFO: Pod "pod-configmaps-4f541dc3-ce24-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.825625ms
Sep  3 08:24:57.677: INFO: Pod "pod-configmaps-4f541dc3-ce24-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011298698s
STEP: Saw pod success
Sep  3 08:24:57.677: INFO: Pod "pod-configmaps-4f541dc3-ce24-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 08:24:57.681: INFO: Trying to get logs from node 10.0.0.6 pod pod-configmaps-4f541dc3-ce24-11e9-a824-e6b94fc13bb4 container configmap-volume-test: <nil>
STEP: delete the pod
Sep  3 08:24:57.711: INFO: Waiting for pod pod-configmaps-4f541dc3-ce24-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 08:24:57.764: INFO: Pod pod-configmaps-4f541dc3-ce24-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:24:57.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7423" for this suite.
Sep  3 08:25:03.819: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:25:04.063: INFO: namespace configmap-7423 deletion completed in 6.294955219s

• [SLOW TEST:8.496 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:25:04.063: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-545fb7d8-ce24-11e9-a824-e6b94fc13bb4
STEP: Creating a pod to test consume secrets
Sep  3 08:25:04.167: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-5461178e-ce24-11e9-a824-e6b94fc13bb4" in namespace "projected-3704" to be "success or failure"
Sep  3 08:25:04.170: INFO: Pod "pod-projected-secrets-5461178e-ce24-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.634393ms
Sep  3 08:25:06.175: INFO: Pod "pod-projected-secrets-5461178e-ce24-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007989281s
STEP: Saw pod success
Sep  3 08:25:06.175: INFO: Pod "pod-projected-secrets-5461178e-ce24-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 08:25:06.184: INFO: Trying to get logs from node 10.0.0.9 pod pod-projected-secrets-5461178e-ce24-11e9-a824-e6b94fc13bb4 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep  3 08:25:06.214: INFO: Waiting for pod pod-projected-secrets-5461178e-ce24-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 08:25:06.217: INFO: Pod pod-projected-secrets-5461178e-ce24-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:25:06.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3704" for this suite.
Sep  3 08:25:12.249: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:25:12.438: INFO: namespace projected-3704 deletion completed in 6.211951584s

• [SLOW TEST:8.375 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:25:12.439: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Sep  3 08:25:12.557: INFO: Waiting up to 5m0s for pod "downward-api-59657cdb-ce24-11e9-a824-e6b94fc13bb4" in namespace "downward-api-393" to be "success or failure"
Sep  3 08:25:12.573: INFO: Pod "downward-api-59657cdb-ce24-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 16.1852ms
Sep  3 08:25:14.577: INFO: Pod "downward-api-59657cdb-ce24-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02045681s
Sep  3 08:25:16.582: INFO: Pod "downward-api-59657cdb-ce24-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024757016s
Sep  3 08:25:18.586: INFO: Pod "downward-api-59657cdb-ce24-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.029281309s
Sep  3 08:25:20.591: INFO: Pod "downward-api-59657cdb-ce24-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.033758767s
Sep  3 08:25:22.595: INFO: Pod "downward-api-59657cdb-ce24-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.038433852s
STEP: Saw pod success
Sep  3 08:25:22.595: INFO: Pod "downward-api-59657cdb-ce24-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 08:25:22.599: INFO: Trying to get logs from node 10.0.0.6 pod downward-api-59657cdb-ce24-11e9-a824-e6b94fc13bb4 container dapi-container: <nil>
STEP: delete the pod
Sep  3 08:25:22.632: INFO: Waiting for pod downward-api-59657cdb-ce24-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 08:25:22.635: INFO: Pod downward-api-59657cdb-ce24-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:25:22.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-393" for this suite.
Sep  3 08:25:28.655: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:25:28.834: INFO: namespace downward-api-393 deletion completed in 6.192986315s

• [SLOW TEST:16.395 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:25:28.834: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-9204
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-9204
STEP: Creating statefulset with conflicting port in namespace statefulset-9204
STEP: Waiting until pod test-pod will start running in namespace statefulset-9204
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-9204
Sep  3 08:25:32.964: INFO: Observed stateful pod in namespace: statefulset-9204, name: ss-0, uid: 657dcb4c-ce24-11e9-9b9a-9e20fc449913, status phase: Pending. Waiting for statefulset controller to delete.
Sep  3 08:25:33.362: INFO: Observed stateful pod in namespace: statefulset-9204, name: ss-0, uid: 657dcb4c-ce24-11e9-9b9a-9e20fc449913, status phase: Failed. Waiting for statefulset controller to delete.
Sep  3 08:25:33.373: INFO: Observed stateful pod in namespace: statefulset-9204, name: ss-0, uid: 657dcb4c-ce24-11e9-9b9a-9e20fc449913, status phase: Failed. Waiting for statefulset controller to delete.
Sep  3 08:25:33.380: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-9204
STEP: Removing pod with conflicting port in namespace statefulset-9204
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-9204 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Sep  3 08:25:35.412: INFO: Deleting all statefulset in ns statefulset-9204
Sep  3 08:25:35.417: INFO: Scaling statefulset ss to 0
Sep  3 08:25:45.441: INFO: Waiting for statefulset status.replicas updated to 0
Sep  3 08:25:45.445: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:25:45.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9204" for this suite.
Sep  3 08:25:51.492: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:25:51.652: INFO: namespace statefulset-9204 deletion completed in 6.178999832s

• [SLOW TEST:22.818 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:25:51.652: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Sep  3 08:25:55.761: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep  3 08:25:55.764: INFO: Pod pod-with-poststart-http-hook still exists
Sep  3 08:25:57.764: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep  3 08:25:57.769: INFO: Pod pod-with-poststart-http-hook still exists
Sep  3 08:25:59.764: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep  3 08:25:59.769: INFO: Pod pod-with-poststart-http-hook still exists
Sep  3 08:26:01.764: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep  3 08:26:01.769: INFO: Pod pod-with-poststart-http-hook still exists
Sep  3 08:26:03.764: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep  3 08:26:03.769: INFO: Pod pod-with-poststart-http-hook still exists
Sep  3 08:26:05.764: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep  3 08:26:05.769: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:26:05.769: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-1489" for this suite.
Sep  3 08:26:29.791: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:26:30.022: INFO: namespace container-lifecycle-hook-1489 deletion completed in 24.248746017s

• [SLOW TEST:38.370 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:26:30.022: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Sep  3 08:26:32.630: INFO: Successfully updated pod "annotationupdate879b019d-ce24-11e9-a824-e6b94fc13bb4"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:26:36.669: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2714" for this suite.
Sep  3 08:26:58.708: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:26:58.869: INFO: namespace projected-2714 deletion completed in 22.195018943s

• [SLOW TEST:28.847 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:26:58.869: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
Sep  3 08:26:58.925: INFO: namespace kubectl-1025
Sep  3 08:26:58.925: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 create -f - --namespace=kubectl-1025'
Sep  3 08:26:59.103: INFO: stderr: ""
Sep  3 08:26:59.103: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Sep  3 08:27:00.107: INFO: Selector matched 1 pods for map[app:redis]
Sep  3 08:27:00.107: INFO: Found 0 / 1
Sep  3 08:27:01.125: INFO: Selector matched 1 pods for map[app:redis]
Sep  3 08:27:01.125: INFO: Found 0 / 1
Sep  3 08:27:02.107: INFO: Selector matched 1 pods for map[app:redis]
Sep  3 08:27:02.107: INFO: Found 0 / 1
Sep  3 08:27:03.107: INFO: Selector matched 1 pods for map[app:redis]
Sep  3 08:27:03.107: INFO: Found 1 / 1
Sep  3 08:27:03.107: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Sep  3 08:27:03.111: INFO: Selector matched 1 pods for map[app:redis]
Sep  3 08:27:03.111: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep  3 08:27:03.111: INFO: wait on redis-master startup in kubectl-1025 
Sep  3 08:27:03.111: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 logs redis-master-zfnbq redis-master --namespace=kubectl-1025'
Sep  3 08:27:03.220: INFO: stderr: ""
Sep  3 08:27:03.220: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 03 Sep 08:27:01.958 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 03 Sep 08:27:01.958 # Server started, Redis version 3.2.12\n1:M 03 Sep 08:27:01.958 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 03 Sep 08:27:01.958 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Sep  3 08:27:03.221: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-1025'
Sep  3 08:27:03.336: INFO: stderr: ""
Sep  3 08:27:03.336: INFO: stdout: "service/rm2 exposed\n"
Sep  3 08:27:03.362: INFO: Service rm2 in namespace kubectl-1025 found.
STEP: exposing service
Sep  3 08:27:05.375: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-1025'
Sep  3 08:27:05.471: INFO: stderr: ""
Sep  3 08:27:05.471: INFO: stdout: "service/rm3 exposed\n"
Sep  3 08:27:05.476: INFO: Service rm3 in namespace kubectl-1025 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:27:07.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1025" for this suite.
Sep  3 08:27:31.580: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:27:31.747: INFO: namespace kubectl-1025 deletion completed in 24.249671227s

• [SLOW TEST:32.878 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create services for rc  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:27:31.747: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Sep  3 08:27:34.382: INFO: Successfully updated pod "pod-update-ac66a0b3-ce24-11e9-a824-e6b94fc13bb4"
STEP: verifying the updated pod is in kubernetes
Sep  3 08:27:34.389: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:27:34.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2033" for this suite.
Sep  3 08:27:56.470: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:27:56.623: INFO: namespace pods-2033 deletion completed in 22.224510596s

• [SLOW TEST:24.876 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:27:56.623: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-bb3b19b3-ce24-11e9-a824-e6b94fc13bb4
STEP: Creating configMap with name cm-test-opt-upd-bb3b19f1-ce24-11e9-a824-e6b94fc13bb4
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-bb3b19b3-ce24-11e9-a824-e6b94fc13bb4
STEP: Updating configmap cm-test-opt-upd-bb3b19f1-ce24-11e9-a824-e6b94fc13bb4
STEP: Creating configMap with name cm-test-opt-create-bb3b1a11-ce24-11e9-a824-e6b94fc13bb4
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:28:00.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8992" for this suite.
Sep  3 08:28:24.878: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:28:25.020: INFO: namespace projected-8992 deletion completed in 24.158294888s

• [SLOW TEST:28.397 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:28:25.021: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep  3 08:28:25.085: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cc26b2b4-ce24-11e9-a824-e6b94fc13bb4" in namespace "downward-api-6180" to be "success or failure"
Sep  3 08:28:25.088: INFO: Pod "downwardapi-volume-cc26b2b4-ce24-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.331835ms
Sep  3 08:28:27.092: INFO: Pod "downwardapi-volume-cc26b2b4-ce24-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007620251s
STEP: Saw pod success
Sep  3 08:28:27.092: INFO: Pod "downwardapi-volume-cc26b2b4-ce24-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 08:28:27.096: INFO: Trying to get logs from node 10.0.0.9 pod downwardapi-volume-cc26b2b4-ce24-11e9-a824-e6b94fc13bb4 container client-container: <nil>
STEP: delete the pod
Sep  3 08:28:27.184: INFO: Waiting for pod downwardapi-volume-cc26b2b4-ce24-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 08:28:27.187: INFO: Pod downwardapi-volume-cc26b2b4-ce24-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:28:27.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6180" for this suite.
Sep  3 08:28:33.210: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:28:33.397: INFO: namespace downward-api-6180 deletion completed in 6.205269271s

• [SLOW TEST:8.376 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:28:33.397: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service multi-endpoint-test in namespace services-163
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-163 to expose endpoints map[]
Sep  3 08:28:33.469: INFO: Get endpoints failed (4.387723ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Sep  3 08:28:34.475: INFO: successfully validated that service multi-endpoint-test in namespace services-163 exposes endpoints map[] (1.009468048s elapsed)
STEP: Creating pod pod1 in namespace services-163
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-163 to expose endpoints map[pod1:[100]]
Sep  3 08:28:36.602: INFO: successfully validated that service multi-endpoint-test in namespace services-163 exposes endpoints map[pod1:[100]] (2.033073481s elapsed)
STEP: Creating pod pod2 in namespace services-163
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-163 to expose endpoints map[pod1:[100] pod2:[101]]
Sep  3 08:28:39.673: INFO: successfully validated that service multi-endpoint-test in namespace services-163 exposes endpoints map[pod1:[100] pod2:[101]] (3.064509381s elapsed)
STEP: Deleting pod pod1 in namespace services-163
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-163 to expose endpoints map[pod2:[101]]
Sep  3 08:28:40.699: INFO: successfully validated that service multi-endpoint-test in namespace services-163 exposes endpoints map[pod2:[101]] (1.017396376s elapsed)
STEP: Deleting pod pod2 in namespace services-163
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-163 to expose endpoints map[]
Sep  3 08:28:41.778: INFO: successfully validated that service multi-endpoint-test in namespace services-163 exposes endpoints map[] (1.009006871s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:28:41.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-163" for this suite.
Sep  3 08:28:47.851: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:28:47.999: INFO: namespace services-163 deletion completed in 6.162673354s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:14.602 seconds]
[sig-network] Services
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:28:47.999: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
Sep  3 08:28:48.052: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 create -f - --namespace=kubectl-8776'
Sep  3 08:28:48.183: INFO: stderr: ""
Sep  3 08:28:48.183: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep  3 08:28:48.183: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8776'
Sep  3 08:28:48.255: INFO: stderr: ""
Sep  3 08:28:48.255: INFO: stdout: "update-demo-nautilus-4qnd5 update-demo-nautilus-l9px4 "
Sep  3 08:28:48.255: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 get pods update-demo-nautilus-4qnd5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8776'
Sep  3 08:28:48.318: INFO: stderr: ""
Sep  3 08:28:48.318: INFO: stdout: ""
Sep  3 08:28:48.318: INFO: update-demo-nautilus-4qnd5 is created but not running
Sep  3 08:28:53.319: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8776'
Sep  3 08:28:53.396: INFO: stderr: ""
Sep  3 08:28:53.396: INFO: stdout: "update-demo-nautilus-4qnd5 update-demo-nautilus-l9px4 "
Sep  3 08:28:53.396: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 get pods update-demo-nautilus-4qnd5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8776'
Sep  3 08:28:53.465: INFO: stderr: ""
Sep  3 08:28:53.465: INFO: stdout: "true"
Sep  3 08:28:53.465: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 get pods update-demo-nautilus-4qnd5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8776'
Sep  3 08:28:53.532: INFO: stderr: ""
Sep  3 08:28:53.532: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  3 08:28:53.532: INFO: validating pod update-demo-nautilus-4qnd5
Sep  3 08:28:53.537: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  3 08:28:53.537: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  3 08:28:53.537: INFO: update-demo-nautilus-4qnd5 is verified up and running
Sep  3 08:28:53.537: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 get pods update-demo-nautilus-l9px4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8776'
Sep  3 08:28:53.607: INFO: stderr: ""
Sep  3 08:28:53.607: INFO: stdout: "true"
Sep  3 08:28:53.607: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 get pods update-demo-nautilus-l9px4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8776'
Sep  3 08:28:53.675: INFO: stderr: ""
Sep  3 08:28:53.675: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  3 08:28:53.675: INFO: validating pod update-demo-nautilus-l9px4
Sep  3 08:28:53.680: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  3 08:28:53.680: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  3 08:28:53.680: INFO: update-demo-nautilus-l9px4 is verified up and running
STEP: scaling down the replication controller
Sep  3 08:28:53.681: INFO: scanned /root for discovery docs: <nil>
Sep  3 08:28:53.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-8776'
Sep  3 08:28:54.785: INFO: stderr: ""
Sep  3 08:28:54.785: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep  3 08:28:54.785: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8776'
Sep  3 08:28:54.867: INFO: stderr: ""
Sep  3 08:28:54.867: INFO: stdout: "update-demo-nautilus-4qnd5 update-demo-nautilus-l9px4 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Sep  3 08:28:59.867: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8776'
Sep  3 08:28:59.937: INFO: stderr: ""
Sep  3 08:28:59.937: INFO: stdout: "update-demo-nautilus-4qnd5 update-demo-nautilus-l9px4 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Sep  3 08:29:04.937: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8776'
Sep  3 08:29:05.073: INFO: stderr: ""
Sep  3 08:29:05.073: INFO: stdout: "update-demo-nautilus-4qnd5 update-demo-nautilus-l9px4 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Sep  3 08:29:10.073: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8776'
Sep  3 08:29:10.142: INFO: stderr: ""
Sep  3 08:29:10.142: INFO: stdout: "update-demo-nautilus-4qnd5 "
Sep  3 08:29:10.143: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 get pods update-demo-nautilus-4qnd5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8776'
Sep  3 08:29:10.213: INFO: stderr: ""
Sep  3 08:29:10.213: INFO: stdout: "true"
Sep  3 08:29:10.213: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 get pods update-demo-nautilus-4qnd5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8776'
Sep  3 08:29:10.286: INFO: stderr: ""
Sep  3 08:29:10.286: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  3 08:29:10.286: INFO: validating pod update-demo-nautilus-4qnd5
Sep  3 08:29:10.290: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  3 08:29:10.290: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  3 08:29:10.290: INFO: update-demo-nautilus-4qnd5 is verified up and running
STEP: scaling up the replication controller
Sep  3 08:29:10.291: INFO: scanned /root for discovery docs: <nil>
Sep  3 08:29:10.291: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-8776'
Sep  3 08:29:11.400: INFO: stderr: ""
Sep  3 08:29:11.400: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep  3 08:29:11.400: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8776'
Sep  3 08:29:11.469: INFO: stderr: ""
Sep  3 08:29:11.469: INFO: stdout: "update-demo-nautilus-4qnd5 update-demo-nautilus-645n2 "
Sep  3 08:29:11.469: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 get pods update-demo-nautilus-4qnd5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8776'
Sep  3 08:29:11.532: INFO: stderr: ""
Sep  3 08:29:11.533: INFO: stdout: "true"
Sep  3 08:29:11.533: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 get pods update-demo-nautilus-4qnd5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8776'
Sep  3 08:29:11.598: INFO: stderr: ""
Sep  3 08:29:11.598: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  3 08:29:11.598: INFO: validating pod update-demo-nautilus-4qnd5
Sep  3 08:29:11.602: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  3 08:29:11.602: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  3 08:29:11.602: INFO: update-demo-nautilus-4qnd5 is verified up and running
Sep  3 08:29:11.602: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 get pods update-demo-nautilus-645n2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8776'
Sep  3 08:29:11.665: INFO: stderr: ""
Sep  3 08:29:11.665: INFO: stdout: "true"
Sep  3 08:29:11.665: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 get pods update-demo-nautilus-645n2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8776'
Sep  3 08:29:11.734: INFO: stderr: ""
Sep  3 08:29:11.734: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  3 08:29:11.734: INFO: validating pod update-demo-nautilus-645n2
Sep  3 08:29:11.738: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  3 08:29:11.738: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  3 08:29:11.738: INFO: update-demo-nautilus-645n2 is verified up and running
STEP: using delete to clean up resources
Sep  3 08:29:11.738: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 delete --grace-period=0 --force -f - --namespace=kubectl-8776'
Sep  3 08:29:11.825: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  3 08:29:11.825: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Sep  3 08:29:11.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-8776'
Sep  3 08:29:11.906: INFO: stderr: "No resources found.\n"
Sep  3 08:29:11.906: INFO: stdout: ""
Sep  3 08:29:11.906: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 get pods -l name=update-demo --namespace=kubectl-8776 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep  3 08:29:11.974: INFO: stderr: ""
Sep  3 08:29:11.974: INFO: stdout: "update-demo-nautilus-4qnd5\nupdate-demo-nautilus-645n2\n"
Sep  3 08:29:12.474: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-8776'
Sep  3 08:29:12.573: INFO: stderr: "No resources found.\n"
Sep  3 08:29:12.573: INFO: stdout: ""
Sep  3 08:29:12.573: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 get pods -l name=update-demo --namespace=kubectl-8776 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep  3 08:29:12.646: INFO: stderr: ""
Sep  3 08:29:12.646: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:29:12.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8776" for this suite.
Sep  3 08:29:36.667: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:29:36.819: INFO: namespace kubectl-8776 deletion completed in 24.168179537s

• [SLOW TEST:48.820 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:29:36.819: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep  3 08:29:36.893: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f6f3f544-ce24-11e9-a824-e6b94fc13bb4" in namespace "downward-api-7678" to be "success or failure"
Sep  3 08:29:36.897: INFO: Pod "downwardapi-volume-f6f3f544-ce24-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.555511ms
Sep  3 08:29:38.901: INFO: Pod "downwardapi-volume-f6f3f544-ce24-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008035144s
STEP: Saw pod success
Sep  3 08:29:38.901: INFO: Pod "downwardapi-volume-f6f3f544-ce24-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 08:29:38.905: INFO: Trying to get logs from node 10.0.0.9 pod downwardapi-volume-f6f3f544-ce24-11e9-a824-e6b94fc13bb4 container client-container: <nil>
STEP: delete the pod
Sep  3 08:29:38.934: INFO: Waiting for pod downwardapi-volume-f6f3f544-ce24-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 08:29:38.940: INFO: Pod downwardapi-volume-f6f3f544-ce24-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:29:38.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7678" for this suite.
Sep  3 08:29:44.986: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:29:45.223: INFO: namespace downward-api-7678 deletion completed in 6.278526236s

• [SLOW TEST:8.404 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:29:45.223: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Sep  3 08:29:45.302: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-806,SelfLink:/api/v1/namespaces/watch-806/configmaps/e2e-watch-test-configmap-a,UID:fbf778e7-ce24-11e9-9b9a-9e20fc449913,ResourceVersion:86743857,Generation:0,CreationTimestamp:2019-09-03 08:29:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep  3 08:29:45.302: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-806,SelfLink:/api/v1/namespaces/watch-806/configmaps/e2e-watch-test-configmap-a,UID:fbf778e7-ce24-11e9-9b9a-9e20fc449913,ResourceVersion:86743857,Generation:0,CreationTimestamp:2019-09-03 08:29:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Sep  3 08:29:55.313: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-806,SelfLink:/api/v1/namespaces/watch-806/configmaps/e2e-watch-test-configmap-a,UID:fbf778e7-ce24-11e9-9b9a-9e20fc449913,ResourceVersion:86744515,Generation:0,CreationTimestamp:2019-09-03 08:29:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Sep  3 08:29:55.313: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-806,SelfLink:/api/v1/namespaces/watch-806/configmaps/e2e-watch-test-configmap-a,UID:fbf778e7-ce24-11e9-9b9a-9e20fc449913,ResourceVersion:86744515,Generation:0,CreationTimestamp:2019-09-03 08:29:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Sep  3 08:30:05.327: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-806,SelfLink:/api/v1/namespaces/watch-806/configmaps/e2e-watch-test-configmap-a,UID:fbf778e7-ce24-11e9-9b9a-9e20fc449913,ResourceVersion:86745176,Generation:0,CreationTimestamp:2019-09-03 08:29:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep  3 08:30:05.327: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-806,SelfLink:/api/v1/namespaces/watch-806/configmaps/e2e-watch-test-configmap-a,UID:fbf778e7-ce24-11e9-9b9a-9e20fc449913,ResourceVersion:86745176,Generation:0,CreationTimestamp:2019-09-03 08:29:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Sep  3 08:30:15.344: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-806,SelfLink:/api/v1/namespaces/watch-806/configmaps/e2e-watch-test-configmap-a,UID:fbf778e7-ce24-11e9-9b9a-9e20fc449913,ResourceVersion:86745835,Generation:0,CreationTimestamp:2019-09-03 08:29:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep  3 08:30:15.344: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-806,SelfLink:/api/v1/namespaces/watch-806/configmaps/e2e-watch-test-configmap-a,UID:fbf778e7-ce24-11e9-9b9a-9e20fc449913,ResourceVersion:86745835,Generation:0,CreationTimestamp:2019-09-03 08:29:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Sep  3 08:30:25.364: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-806,SelfLink:/api/v1/namespaces/watch-806/configmaps/e2e-watch-test-configmap-b,UID:13d69427-ce25-11e9-9b9a-9e20fc449913,ResourceVersion:86746492,Generation:0,CreationTimestamp:2019-09-03 08:30:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep  3 08:30:25.364: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-806,SelfLink:/api/v1/namespaces/watch-806/configmaps/e2e-watch-test-configmap-b,UID:13d69427-ce25-11e9-9b9a-9e20fc449913,ResourceVersion:86746492,Generation:0,CreationTimestamp:2019-09-03 08:30:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Sep  3 08:30:35.386: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-806,SelfLink:/api/v1/namespaces/watch-806/configmaps/e2e-watch-test-configmap-b,UID:13d69427-ce25-11e9-9b9a-9e20fc449913,ResourceVersion:86747151,Generation:0,CreationTimestamp:2019-09-03 08:30:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep  3 08:30:35.386: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-806,SelfLink:/api/v1/namespaces/watch-806/configmaps/e2e-watch-test-configmap-b,UID:13d69427-ce25-11e9-9b9a-9e20fc449913,ResourceVersion:86747151,Generation:0,CreationTimestamp:2019-09-03 08:30:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:30:45.387: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-806" for this suite.
Sep  3 08:30:51.415: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:30:51.575: INFO: namespace watch-806 deletion completed in 6.183721785s

• [SLOW TEST:66.352 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:30:51.576: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep  3 08:30:51.666: INFO: Pod name rollover-pod: Found 0 pods out of 1
Sep  3 08:30:56.670: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep  3 08:30:56.670: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Sep  3 08:30:58.675: INFO: Creating deployment "test-rollover-deployment"
Sep  3 08:30:58.773: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Sep  3 08:31:00.782: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Sep  3 08:31:00.795: INFO: Ensure that both replica sets have 1 created replica
Sep  3 08:31:00.803: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Sep  3 08:31:00.812: INFO: Updating deployment test-rollover-deployment
Sep  3 08:31:00.812: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Sep  3 08:31:02.821: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Sep  3 08:31:02.828: INFO: Make sure deployment "test-rollover-deployment" is complete
Sep  3 08:31:02.836: INFO: all replica sets need to contain the pod-template-hash label
Sep  3 08:31:02.836: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703096258, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703096258, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703096261, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703096258, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  3 08:31:04.868: INFO: all replica sets need to contain the pod-template-hash label
Sep  3 08:31:04.868: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703096258, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703096258, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703096261, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703096258, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  3 08:31:06.870: INFO: all replica sets need to contain the pod-template-hash label
Sep  3 08:31:06.870: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703096258, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703096258, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703096261, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703096258, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  3 08:31:08.844: INFO: all replica sets need to contain the pod-template-hash label
Sep  3 08:31:08.844: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703096258, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703096258, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703096261, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703096258, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  3 08:31:10.864: INFO: all replica sets need to contain the pod-template-hash label
Sep  3 08:31:10.864: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703096258, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703096258, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703096261, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703096258, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-766b4d6c9d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  3 08:31:12.845: INFO: 
Sep  3 08:31:12.845: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Sep  3 08:31:12.856: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-3218,SelfLink:/apis/apps/v1/namespaces/deployment-3218/deployments/test-rollover-deployment,UID:27c1e08b-ce25-11e9-9b9a-9e20fc449913,ResourceVersion:86749629,Generation:2,CreationTimestamp:2019-09-03 08:30:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-09-03 08:30:58 +0000 UTC 2019-09-03 08:30:58 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-09-03 08:31:11 +0000 UTC 2019-09-03 08:30:58 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-766b4d6c9d" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Sep  3 08:31:12.860: INFO: New ReplicaSet "test-rollover-deployment-766b4d6c9d" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-766b4d6c9d,GenerateName:,Namespace:deployment-3218,SelfLink:/apis/apps/v1/namespaces/deployment-3218/replicasets/test-rollover-deployment-766b4d6c9d,UID:28fb0a9a-ce25-11e9-9b9a-9e20fc449913,ResourceVersion:86749615,Generation:2,CreationTimestamp:2019-09-03 08:31:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 27c1e08b-ce25-11e9-9b9a-9e20fc449913 0xc00061abf7 0xc00061abf8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Sep  3 08:31:12.860: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Sep  3 08:31:12.860: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-3218,SelfLink:/apis/apps/v1/namespaces/deployment-3218/replicasets/test-rollover-controller,UID:2385229e-ce25-11e9-9b9a-9e20fc449913,ResourceVersion:86749626,Generation:2,CreationTimestamp:2019-09-03 08:30:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 27c1e08b-ce25-11e9-9b9a-9e20fc449913 0xc00061a277 0xc00061a278}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep  3 08:31:12.860: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6455657675,GenerateName:,Namespace:deployment-3218,SelfLink:/apis/apps/v1/namespaces/deployment-3218/replicasets/test-rollover-deployment-6455657675,UID:27c586e4-ce25-11e9-9b9a-9e20fc449913,ResourceVersion:86748893,Generation:2,CreationTimestamp:2019-09-03 08:30:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 27c1e08b-ce25-11e9-9b9a-9e20fc449913 0xc00061a8e7 0xc00061a8e8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6455657675,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep  3 08:31:12.864: INFO: Pod "test-rollover-deployment-766b4d6c9d-v5x6r" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-766b4d6c9d-v5x6r,GenerateName:test-rollover-deployment-766b4d6c9d-,Namespace:deployment-3218,SelfLink:/api/v1/namespaces/deployment-3218/pods/test-rollover-deployment-766b4d6c9d-v5x6r,UID:2900efa9-ce25-11e9-9b9a-9e20fc449913,ResourceVersion:86748946,Generation:0,CreationTimestamp:2019-09-03 08:31:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 766b4d6c9d,},Annotations:map[string]string{tke.cloud.tencent.com/networks-status: [{
    "name": "tke-bridge",
    "ips": [
        "172.22.0.37"
    ],
    "default": true,
    "dns": {}
}],},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-766b4d6c9d 28fb0a9a-ce25-11e9-9b9a-9e20fc449913 0xc000161737 0xc000161738}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-ncpxc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ncpxc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-ncpxc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.6,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 08:31:00 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 08:31:01 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 08:31:01 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 08:31:00 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.6,PodIP:172.22.0.37,StartTime:2019-09-03 08:31:00 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-09-03 08:31:01 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://c18f0b4fd9a1041cd71e7b55cea8120f25165ff70eea7993b65d816bf4b7c697}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:31:12.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3218" for this suite.
Sep  3 08:31:18.888: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:31:19.035: INFO: namespace deployment-3218 deletion completed in 6.166334436s

• [SLOW TEST:27.459 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:31:19.035: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-33df8f9f-ce25-11e9-a824-e6b94fc13bb4
STEP: Creating a pod to test consume configMaps
Sep  3 08:31:19.111: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-33e0acc5-ce25-11e9-a824-e6b94fc13bb4" in namespace "projected-5284" to be "success or failure"
Sep  3 08:31:19.114: INFO: Pod "pod-projected-configmaps-33e0acc5-ce25-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.440984ms
Sep  3 08:31:21.125: INFO: Pod "pod-projected-configmaps-33e0acc5-ce25-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014103216s
STEP: Saw pod success
Sep  3 08:31:21.125: INFO: Pod "pod-projected-configmaps-33e0acc5-ce25-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 08:31:21.128: INFO: Trying to get logs from node 10.0.0.9 pod pod-projected-configmaps-33e0acc5-ce25-11e9-a824-e6b94fc13bb4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep  3 08:31:21.161: INFO: Waiting for pod pod-projected-configmaps-33e0acc5-ce25-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 08:31:21.165: INFO: Pod pod-projected-configmaps-33e0acc5-ce25-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:31:21.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5284" for this suite.
Sep  3 08:31:27.188: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:31:27.343: INFO: namespace projected-5284 deletion completed in 6.173610989s

• [SLOW TEST:8.308 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:31:27.343: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating replication controller svc-latency-rc in namespace svc-latency-4983
I0903 08:31:27.413677      16 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-4983, replica count: 1
I0903 08:31:28.463970      16 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0903 08:31:29.464146      16 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep  3 08:31:29.664: INFO: Created: latency-svc-cr6sn
Sep  3 08:31:29.669: INFO: Got endpoints: latency-svc-cr6sn [105.28778ms]
Sep  3 08:31:29.691: INFO: Created: latency-svc-mbb8f
Sep  3 08:31:29.698: INFO: Created: latency-svc-xwxkg
Sep  3 08:31:29.705: INFO: Got endpoints: latency-svc-mbb8f [35.480459ms]
Sep  3 08:31:29.709: INFO: Got endpoints: latency-svc-xwxkg [39.431902ms]
Sep  3 08:31:29.711: INFO: Created: latency-svc-hdp48
Sep  3 08:31:29.722: INFO: Created: latency-svc-sdhnk
Sep  3 08:31:29.722: INFO: Got endpoints: latency-svc-hdp48 [52.676374ms]
Sep  3 08:31:29.727: INFO: Created: latency-svc-dzlqx
Sep  3 08:31:29.736: INFO: Got endpoints: latency-svc-sdhnk [66.192283ms]
Sep  3 08:31:29.738: INFO: Got endpoints: latency-svc-dzlqx [68.044614ms]
Sep  3 08:31:29.739: INFO: Created: latency-svc-tttq9
Sep  3 08:31:29.746: INFO: Got endpoints: latency-svc-tttq9 [75.725417ms]
Sep  3 08:31:29.751: INFO: Created: latency-svc-ncgvd
Sep  3 08:31:29.761: INFO: Got endpoints: latency-svc-ncgvd [90.58604ms]
Sep  3 08:31:29.761: INFO: Created: latency-svc-kncrt
Sep  3 08:31:29.769: INFO: Got endpoints: latency-svc-kncrt [98.808921ms]
Sep  3 08:31:29.777: INFO: Created: latency-svc-djnrp
Sep  3 08:31:29.787: INFO: Created: latency-svc-n55f5
Sep  3 08:31:29.789: INFO: Got endpoints: latency-svc-djnrp [118.815942ms]
Sep  3 08:31:29.798: INFO: Created: latency-svc-csdgx
Sep  3 08:31:29.802: INFO: Got endpoints: latency-svc-n55f5 [131.956943ms]
Sep  3 08:31:29.806: INFO: Got endpoints: latency-svc-csdgx [135.986187ms]
Sep  3 08:31:29.814: INFO: Created: latency-svc-55ltg
Sep  3 08:31:29.819: INFO: Created: latency-svc-b7rzk
Sep  3 08:31:29.826: INFO: Got endpoints: latency-svc-55ltg [155.83054ms]
Sep  3 08:31:29.827: INFO: Got endpoints: latency-svc-b7rzk [156.625928ms]
Sep  3 08:31:29.828: INFO: Created: latency-svc-szl4v
Sep  3 08:31:29.840: INFO: Created: latency-svc-499nm
Sep  3 08:31:29.842: INFO: Got endpoints: latency-svc-szl4v [171.415365ms]
Sep  3 08:31:29.846: INFO: Created: latency-svc-jzmdr
Sep  3 08:31:29.851: INFO: Got endpoints: latency-svc-499nm [180.443987ms]
Sep  3 08:31:29.856: INFO: Got endpoints: latency-svc-jzmdr [150.94785ms]
Sep  3 08:31:29.857: INFO: Created: latency-svc-zzdrm
Sep  3 08:31:29.864: INFO: Got endpoints: latency-svc-zzdrm [154.737804ms]
Sep  3 08:31:29.871: INFO: Created: latency-svc-wfvzt
Sep  3 08:31:29.876: INFO: Created: latency-svc-jswwt
Sep  3 08:31:29.879: INFO: Got endpoints: latency-svc-wfvzt [156.747563ms]
Sep  3 08:31:29.886: INFO: Got endpoints: latency-svc-jswwt [150.112197ms]
Sep  3 08:31:29.887: INFO: Created: latency-svc-zv5rf
Sep  3 08:31:29.909: INFO: Created: latency-svc-79zlc
Sep  3 08:31:29.913: INFO: Got endpoints: latency-svc-zv5rf [174.478106ms]
Sep  3 08:31:29.921: INFO: Got endpoints: latency-svc-79zlc [175.333098ms]
Sep  3 08:31:29.925: INFO: Created: latency-svc-b5vj9
Sep  3 08:31:29.934: INFO: Created: latency-svc-fdrg2
Sep  3 08:31:29.943: INFO: Got endpoints: latency-svc-b5vj9 [182.285223ms]
Sep  3 08:31:29.944: INFO: Created: latency-svc-btbkk
Sep  3 08:31:29.955: INFO: Created: latency-svc-rvh6m
Sep  3 08:31:29.955: INFO: Got endpoints: latency-svc-btbkk [165.927962ms]
Sep  3 08:31:29.955: INFO: Got endpoints: latency-svc-fdrg2 [186.19806ms]
Sep  3 08:31:29.963: INFO: Got endpoints: latency-svc-rvh6m [160.478044ms]
Sep  3 08:31:29.966: INFO: Created: latency-svc-nchxj
Sep  3 08:31:29.974: INFO: Created: latency-svc-rhp5l
Sep  3 08:31:29.977: INFO: Got endpoints: latency-svc-nchxj [170.300175ms]
Sep  3 08:31:29.982: INFO: Got endpoints: latency-svc-rhp5l [155.487463ms]
Sep  3 08:31:29.984: INFO: Created: latency-svc-k5vm9
Sep  3 08:31:29.995: INFO: Created: latency-svc-t2k6q
Sep  3 08:31:29.996: INFO: Got endpoints: latency-svc-k5vm9 [168.827648ms]
Sep  3 08:31:30.004: INFO: Created: latency-svc-mtkwx
Sep  3 08:31:30.009: INFO: Got endpoints: latency-svc-t2k6q [32.129918ms]
Sep  3 08:31:30.013: INFO: Got endpoints: latency-svc-mtkwx [171.145674ms]
Sep  3 08:31:30.017: INFO: Created: latency-svc-6ptw4
Sep  3 08:31:30.020: INFO: Created: latency-svc-sgtrj
Sep  3 08:31:30.028: INFO: Got endpoints: latency-svc-6ptw4 [176.666872ms]
Sep  3 08:31:30.037: INFO: Created: latency-svc-2ksl8
Sep  3 08:31:30.037: INFO: Got endpoints: latency-svc-sgtrj [181.261808ms]
Sep  3 08:31:30.044: INFO: Got endpoints: latency-svc-2ksl8 [179.776986ms]
Sep  3 08:31:30.049: INFO: Created: latency-svc-fxwbh
Sep  3 08:31:30.053: INFO: Created: latency-svc-fz7f4
Sep  3 08:31:30.058: INFO: Got endpoints: latency-svc-fxwbh [179.176546ms]
Sep  3 08:31:30.060: INFO: Got endpoints: latency-svc-fz7f4 [173.694758ms]
Sep  3 08:31:30.068: INFO: Created: latency-svc-vz2kw
Sep  3 08:31:30.078: INFO: Created: latency-svc-2pr72
Sep  3 08:31:30.080: INFO: Got endpoints: latency-svc-vz2kw [167.007057ms]
Sep  3 08:31:30.085: INFO: Created: latency-svc-hnlj2
Sep  3 08:31:30.087: INFO: Got endpoints: latency-svc-2pr72 [165.621061ms]
Sep  3 08:31:30.094: INFO: Created: latency-svc-qfn67
Sep  3 08:31:30.100: INFO: Got endpoints: latency-svc-hnlj2 [157.017008ms]
Sep  3 08:31:30.103: INFO: Created: latency-svc-j72dd
Sep  3 08:31:30.112: INFO: Created: latency-svc-6ckcp
Sep  3 08:31:30.137: INFO: Created: latency-svc-2f7wm
Sep  3 08:31:30.144: INFO: Created: latency-svc-kdvs9
Sep  3 08:31:30.150: INFO: Got endpoints: latency-svc-qfn67 [194.948002ms]
Sep  3 08:31:30.154: INFO: Created: latency-svc-mzgtr
Sep  3 08:31:30.162: INFO: Created: latency-svc-ccxm6
Sep  3 08:31:30.172: INFO: Created: latency-svc-8qhl6
Sep  3 08:31:30.181: INFO: Created: latency-svc-jz957
Sep  3 08:31:30.193: INFO: Created: latency-svc-kblrm
Sep  3 08:31:30.203: INFO: Created: latency-svc-kltn9
Sep  3 08:31:30.205: INFO: Got endpoints: latency-svc-j72dd [249.517004ms]
Sep  3 08:31:30.212: INFO: Created: latency-svc-gbs5g
Sep  3 08:31:30.223: INFO: Created: latency-svc-s9f4h
Sep  3 08:31:30.232: INFO: Created: latency-svc-fzbvp
Sep  3 08:31:30.240: INFO: Created: latency-svc-bqbb4
Sep  3 08:31:30.248: INFO: Got endpoints: latency-svc-6ckcp [285.15388ms]
Sep  3 08:31:30.250: INFO: Created: latency-svc-g947k
Sep  3 08:31:30.258: INFO: Created: latency-svc-x2b72
Sep  3 08:31:30.269: INFO: Created: latency-svc-mrkls
Sep  3 08:31:30.299: INFO: Got endpoints: latency-svc-2f7wm [316.961447ms]
Sep  3 08:31:30.330: INFO: Created: latency-svc-txvn8
Sep  3 08:31:30.358: INFO: Got endpoints: latency-svc-kdvs9 [361.959447ms]
Sep  3 08:31:30.370: INFO: Created: latency-svc-pv7wt
Sep  3 08:31:30.406: INFO: Got endpoints: latency-svc-mzgtr [397.302875ms]
Sep  3 08:31:30.420: INFO: Created: latency-svc-r98qx
Sep  3 08:31:30.459: INFO: Got endpoints: latency-svc-ccxm6 [445.868187ms]
Sep  3 08:31:30.478: INFO: Created: latency-svc-kkwq2
Sep  3 08:31:30.499: INFO: Got endpoints: latency-svc-8qhl6 [471.324894ms]
Sep  3 08:31:30.515: INFO: Created: latency-svc-smjv2
Sep  3 08:31:30.549: INFO: Got endpoints: latency-svc-jz957 [511.962185ms]
Sep  3 08:31:30.562: INFO: Created: latency-svc-skgkk
Sep  3 08:31:30.599: INFO: Got endpoints: latency-svc-kblrm [555.758194ms]
Sep  3 08:31:30.612: INFO: Created: latency-svc-mmvmc
Sep  3 08:31:30.650: INFO: Got endpoints: latency-svc-kltn9 [591.530884ms]
Sep  3 08:31:30.665: INFO: Created: latency-svc-l5vjc
Sep  3 08:31:30.698: INFO: Got endpoints: latency-svc-gbs5g [638.485736ms]
Sep  3 08:31:30.711: INFO: Created: latency-svc-p2c59
Sep  3 08:31:30.751: INFO: Got endpoints: latency-svc-s9f4h [671.418758ms]
Sep  3 08:31:30.768: INFO: Created: latency-svc-kswgw
Sep  3 08:31:30.800: INFO: Got endpoints: latency-svc-fzbvp [713.156948ms]
Sep  3 08:31:30.815: INFO: Created: latency-svc-8665p
Sep  3 08:31:30.851: INFO: Got endpoints: latency-svc-bqbb4 [750.610399ms]
Sep  3 08:31:30.867: INFO: Created: latency-svc-rf9qg
Sep  3 08:31:30.901: INFO: Got endpoints: latency-svc-g947k [751.028193ms]
Sep  3 08:31:30.919: INFO: Created: latency-svc-gr5jv
Sep  3 08:31:30.948: INFO: Got endpoints: latency-svc-x2b72 [743.083861ms]
Sep  3 08:31:30.962: INFO: Created: latency-svc-mnk65
Sep  3 08:31:30.998: INFO: Got endpoints: latency-svc-mrkls [750.416999ms]
Sep  3 08:31:31.012: INFO: Created: latency-svc-djs2h
Sep  3 08:31:31.051: INFO: Got endpoints: latency-svc-txvn8 [752.234507ms]
Sep  3 08:31:31.067: INFO: Created: latency-svc-vk6gd
Sep  3 08:31:31.100: INFO: Got endpoints: latency-svc-pv7wt [741.947732ms]
Sep  3 08:31:31.113: INFO: Created: latency-svc-tn6sj
Sep  3 08:31:31.152: INFO: Got endpoints: latency-svc-r98qx [746.167734ms]
Sep  3 08:31:31.168: INFO: Created: latency-svc-jcq8d
Sep  3 08:31:31.203: INFO: Got endpoints: latency-svc-kkwq2 [743.806785ms]
Sep  3 08:31:31.219: INFO: Created: latency-svc-79s9p
Sep  3 08:31:31.248: INFO: Got endpoints: latency-svc-smjv2 [749.516793ms]
Sep  3 08:31:31.266: INFO: Created: latency-svc-m9qf9
Sep  3 08:31:31.299: INFO: Got endpoints: latency-svc-skgkk [749.822813ms]
Sep  3 08:31:31.312: INFO: Created: latency-svc-m68c6
Sep  3 08:31:31.364: INFO: Got endpoints: latency-svc-mmvmc [764.302308ms]
Sep  3 08:31:31.383: INFO: Created: latency-svc-q258s
Sep  3 08:31:31.399: INFO: Got endpoints: latency-svc-l5vjc [749.003284ms]
Sep  3 08:31:31.417: INFO: Created: latency-svc-wr5qf
Sep  3 08:31:31.449: INFO: Got endpoints: latency-svc-p2c59 [750.624735ms]
Sep  3 08:31:31.463: INFO: Created: latency-svc-r86b4
Sep  3 08:31:31.499: INFO: Got endpoints: latency-svc-kswgw [748.45703ms]
Sep  3 08:31:31.528: INFO: Created: latency-svc-8bb4c
Sep  3 08:31:31.552: INFO: Got endpoints: latency-svc-8665p [751.932471ms]
Sep  3 08:31:31.566: INFO: Created: latency-svc-7kn2p
Sep  3 08:31:31.603: INFO: Got endpoints: latency-svc-rf9qg [752.694435ms]
Sep  3 08:31:31.616: INFO: Created: latency-svc-n9knp
Sep  3 08:31:31.648: INFO: Got endpoints: latency-svc-gr5jv [746.969085ms]
Sep  3 08:31:31.661: INFO: Created: latency-svc-9w27x
Sep  3 08:31:31.700: INFO: Got endpoints: latency-svc-mnk65 [751.80609ms]
Sep  3 08:31:31.713: INFO: Created: latency-svc-pzmsj
Sep  3 08:31:31.750: INFO: Got endpoints: latency-svc-djs2h [751.492363ms]
Sep  3 08:31:31.764: INFO: Created: latency-svc-cx7gk
Sep  3 08:31:31.798: INFO: Got endpoints: latency-svc-vk6gd [746.810638ms]
Sep  3 08:31:31.810: INFO: Created: latency-svc-m7pr5
Sep  3 08:31:31.848: INFO: Got endpoints: latency-svc-tn6sj [748.52461ms]
Sep  3 08:31:31.869: INFO: Created: latency-svc-mrkdc
Sep  3 08:31:31.899: INFO: Got endpoints: latency-svc-jcq8d [746.47899ms]
Sep  3 08:31:31.932: INFO: Created: latency-svc-wdj8h
Sep  3 08:31:31.982: INFO: Got endpoints: latency-svc-79s9p [779.473203ms]
Sep  3 08:31:31.998: INFO: Got endpoints: latency-svc-m9qf9 [749.853709ms]
Sep  3 08:31:32.002: INFO: Created: latency-svc-lrp78
Sep  3 08:31:32.018: INFO: Created: latency-svc-pgg4z
Sep  3 08:31:32.049: INFO: Got endpoints: latency-svc-m68c6 [750.392367ms]
Sep  3 08:31:32.064: INFO: Created: latency-svc-sgglr
Sep  3 08:31:32.116: INFO: Got endpoints: latency-svc-q258s [752.662735ms]
Sep  3 08:31:32.129: INFO: Created: latency-svc-p66fq
Sep  3 08:31:32.155: INFO: Got endpoints: latency-svc-wr5qf [756.35341ms]
Sep  3 08:31:32.171: INFO: Created: latency-svc-6mmb4
Sep  3 08:31:32.199: INFO: Got endpoints: latency-svc-r86b4 [750.456541ms]
Sep  3 08:31:32.215: INFO: Created: latency-svc-d7nwl
Sep  3 08:31:32.248: INFO: Got endpoints: latency-svc-8bb4c [748.795354ms]
Sep  3 08:31:32.262: INFO: Created: latency-svc-67tk4
Sep  3 08:31:32.298: INFO: Got endpoints: latency-svc-7kn2p [745.982472ms]
Sep  3 08:31:32.327: INFO: Created: latency-svc-jjc7k
Sep  3 08:31:32.350: INFO: Got endpoints: latency-svc-n9knp [746.799681ms]
Sep  3 08:31:32.366: INFO: Created: latency-svc-v686l
Sep  3 08:31:32.416: INFO: Got endpoints: latency-svc-9w27x [767.445987ms]
Sep  3 08:31:32.431: INFO: Created: latency-svc-lj4gg
Sep  3 08:31:32.451: INFO: Got endpoints: latency-svc-pzmsj [751.000049ms]
Sep  3 08:31:32.463: INFO: Created: latency-svc-k2nzz
Sep  3 08:31:32.499: INFO: Got endpoints: latency-svc-cx7gk [749.383329ms]
Sep  3 08:31:32.512: INFO: Created: latency-svc-fpllz
Sep  3 08:31:32.548: INFO: Got endpoints: latency-svc-m7pr5 [749.957322ms]
Sep  3 08:31:32.562: INFO: Created: latency-svc-dggzn
Sep  3 08:31:32.598: INFO: Got endpoints: latency-svc-mrkdc [749.539054ms]
Sep  3 08:31:32.613: INFO: Created: latency-svc-pwkrm
Sep  3 08:31:32.655: INFO: Got endpoints: latency-svc-wdj8h [756.570808ms]
Sep  3 08:31:32.702: INFO: Got endpoints: latency-svc-lrp78 [719.299632ms]
Sep  3 08:31:32.706: INFO: Created: latency-svc-dw744
Sep  3 08:31:32.718: INFO: Created: latency-svc-fchz2
Sep  3 08:31:32.748: INFO: Got endpoints: latency-svc-pgg4z [749.970033ms]
Sep  3 08:31:32.770: INFO: Created: latency-svc-mg4mw
Sep  3 08:31:32.802: INFO: Got endpoints: latency-svc-sgglr [752.950192ms]
Sep  3 08:31:32.831: INFO: Created: latency-svc-mztq9
Sep  3 08:31:32.857: INFO: Got endpoints: latency-svc-p66fq [740.447845ms]
Sep  3 08:31:32.869: INFO: Created: latency-svc-t7s25
Sep  3 08:31:32.908: INFO: Got endpoints: latency-svc-6mmb4 [752.971952ms]
Sep  3 08:31:32.953: INFO: Got endpoints: latency-svc-d7nwl [753.010799ms]
Sep  3 08:31:32.953: INFO: Created: latency-svc-ztf89
Sep  3 08:31:32.970: INFO: Created: latency-svc-d5sqx
Sep  3 08:31:33.006: INFO: Got endpoints: latency-svc-67tk4 [757.966258ms]
Sep  3 08:31:33.041: INFO: Created: latency-svc-nwbbl
Sep  3 08:31:33.050: INFO: Got endpoints: latency-svc-jjc7k [752.490819ms]
Sep  3 08:31:33.067: INFO: Created: latency-svc-rrfsn
Sep  3 08:31:33.099: INFO: Got endpoints: latency-svc-v686l [749.036024ms]
Sep  3 08:31:33.115: INFO: Created: latency-svc-2k99l
Sep  3 08:31:33.149: INFO: Got endpoints: latency-svc-lj4gg [733.45384ms]
Sep  3 08:31:33.163: INFO: Created: latency-svc-6bmlb
Sep  3 08:31:33.199: INFO: Got endpoints: latency-svc-k2nzz [747.977653ms]
Sep  3 08:31:33.211: INFO: Created: latency-svc-nnwtb
Sep  3 08:31:33.248: INFO: Got endpoints: latency-svc-fpllz [749.072783ms]
Sep  3 08:31:33.265: INFO: Created: latency-svc-9js98
Sep  3 08:31:33.300: INFO: Got endpoints: latency-svc-dggzn [752.307446ms]
Sep  3 08:31:33.313: INFO: Created: latency-svc-nf2z7
Sep  3 08:31:33.350: INFO: Got endpoints: latency-svc-pwkrm [751.560571ms]
Sep  3 08:31:33.364: INFO: Created: latency-svc-qqbp2
Sep  3 08:31:33.400: INFO: Got endpoints: latency-svc-dw744 [744.17519ms]
Sep  3 08:31:33.415: INFO: Created: latency-svc-6ngc2
Sep  3 08:31:33.452: INFO: Got endpoints: latency-svc-fchz2 [750.457759ms]
Sep  3 08:31:33.475: INFO: Created: latency-svc-7x7pv
Sep  3 08:31:33.500: INFO: Got endpoints: latency-svc-mg4mw [752.080019ms]
Sep  3 08:31:33.516: INFO: Created: latency-svc-5s7zs
Sep  3 08:31:33.549: INFO: Got endpoints: latency-svc-mztq9 [746.596306ms]
Sep  3 08:31:33.564: INFO: Created: latency-svc-2fvfk
Sep  3 08:31:33.599: INFO: Got endpoints: latency-svc-t7s25 [741.993271ms]
Sep  3 08:31:33.634: INFO: Created: latency-svc-8clj8
Sep  3 08:31:33.648: INFO: Got endpoints: latency-svc-ztf89 [740.145922ms]
Sep  3 08:31:33.666: INFO: Created: latency-svc-dk7v8
Sep  3 08:31:33.700: INFO: Got endpoints: latency-svc-d5sqx [747.924325ms]
Sep  3 08:31:33.726: INFO: Created: latency-svc-nx9g4
Sep  3 08:31:33.756: INFO: Got endpoints: latency-svc-nwbbl [749.390856ms]
Sep  3 08:31:33.774: INFO: Created: latency-svc-zchg7
Sep  3 08:31:33.799: INFO: Got endpoints: latency-svc-rrfsn [748.339813ms]
Sep  3 08:31:33.815: INFO: Created: latency-svc-n7n97
Sep  3 08:31:33.848: INFO: Got endpoints: latency-svc-2k99l [748.935558ms]
Sep  3 08:31:33.881: INFO: Created: latency-svc-g69zv
Sep  3 08:31:33.900: INFO: Got endpoints: latency-svc-6bmlb [751.415367ms]
Sep  3 08:31:33.916: INFO: Created: latency-svc-r6s9z
Sep  3 08:31:33.970: INFO: Got endpoints: latency-svc-nnwtb [771.720888ms]
Sep  3 08:31:33.993: INFO: Created: latency-svc-t6hzg
Sep  3 08:31:33.998: INFO: Got endpoints: latency-svc-9js98 [749.556009ms]
Sep  3 08:31:34.018: INFO: Created: latency-svc-6tkn9
Sep  3 08:31:34.055: INFO: Got endpoints: latency-svc-nf2z7 [754.446805ms]
Sep  3 08:31:34.087: INFO: Created: latency-svc-95484
Sep  3 08:31:34.101: INFO: Got endpoints: latency-svc-qqbp2 [751.384534ms]
Sep  3 08:31:34.124: INFO: Created: latency-svc-g2fdd
Sep  3 08:31:34.151: INFO: Got endpoints: latency-svc-6ngc2 [751.397465ms]
Sep  3 08:31:34.164: INFO: Created: latency-svc-t6dwg
Sep  3 08:31:34.199: INFO: Got endpoints: latency-svc-7x7pv [746.7504ms]
Sep  3 08:31:34.214: INFO: Created: latency-svc-dr65j
Sep  3 08:31:34.255: INFO: Got endpoints: latency-svc-5s7zs [754.334022ms]
Sep  3 08:31:34.270: INFO: Created: latency-svc-grd9r
Sep  3 08:31:34.299: INFO: Got endpoints: latency-svc-2fvfk [750.432051ms]
Sep  3 08:31:34.314: INFO: Created: latency-svc-k7bkv
Sep  3 08:31:34.352: INFO: Got endpoints: latency-svc-8clj8 [752.995011ms]
Sep  3 08:31:34.372: INFO: Created: latency-svc-cd5tp
Sep  3 08:31:34.400: INFO: Got endpoints: latency-svc-dk7v8 [751.257199ms]
Sep  3 08:31:34.413: INFO: Created: latency-svc-v4sp5
Sep  3 08:31:34.455: INFO: Got endpoints: latency-svc-nx9g4 [754.811108ms]
Sep  3 08:31:34.471: INFO: Created: latency-svc-h9fb5
Sep  3 08:31:34.499: INFO: Got endpoints: latency-svc-zchg7 [742.964662ms]
Sep  3 08:31:34.512: INFO: Created: latency-svc-6rf94
Sep  3 08:31:34.550: INFO: Got endpoints: latency-svc-n7n97 [751.050377ms]
Sep  3 08:31:34.563: INFO: Created: latency-svc-74tfq
Sep  3 08:31:34.600: INFO: Got endpoints: latency-svc-g69zv [751.795149ms]
Sep  3 08:31:34.617: INFO: Created: latency-svc-qph67
Sep  3 08:31:34.653: INFO: Got endpoints: latency-svc-r6s9z [752.092876ms]
Sep  3 08:31:34.671: INFO: Created: latency-svc-zj5qs
Sep  3 08:31:34.702: INFO: Got endpoints: latency-svc-t6hzg [731.308375ms]
Sep  3 08:31:34.719: INFO: Created: latency-svc-6pbm6
Sep  3 08:31:34.749: INFO: Got endpoints: latency-svc-6tkn9 [751.197238ms]
Sep  3 08:31:34.765: INFO: Created: latency-svc-jwlvf
Sep  3 08:31:34.798: INFO: Got endpoints: latency-svc-95484 [743.45433ms]
Sep  3 08:31:34.812: INFO: Created: latency-svc-shhpt
Sep  3 08:31:34.848: INFO: Got endpoints: latency-svc-g2fdd [747.003203ms]
Sep  3 08:31:34.863: INFO: Created: latency-svc-rn64q
Sep  3 08:31:34.899: INFO: Got endpoints: latency-svc-t6dwg [747.889725ms]
Sep  3 08:31:34.925: INFO: Created: latency-svc-95n8m
Sep  3 08:31:34.948: INFO: Got endpoints: latency-svc-dr65j [749.260056ms]
Sep  3 08:31:34.969: INFO: Created: latency-svc-cr7c6
Sep  3 08:31:35.001: INFO: Got endpoints: latency-svc-grd9r [745.909622ms]
Sep  3 08:31:35.018: INFO: Created: latency-svc-4jmxl
Sep  3 08:31:35.048: INFO: Got endpoints: latency-svc-k7bkv [749.114661ms]
Sep  3 08:31:35.062: INFO: Created: latency-svc-q4trg
Sep  3 08:31:35.099: INFO: Got endpoints: latency-svc-cd5tp [746.847278ms]
Sep  3 08:31:35.118: INFO: Created: latency-svc-9cw69
Sep  3 08:31:35.150: INFO: Got endpoints: latency-svc-v4sp5 [749.889067ms]
Sep  3 08:31:35.162: INFO: Created: latency-svc-62j27
Sep  3 08:31:35.199: INFO: Got endpoints: latency-svc-h9fb5 [744.065829ms]
Sep  3 08:31:35.214: INFO: Created: latency-svc-gm5vz
Sep  3 08:31:35.250: INFO: Got endpoints: latency-svc-6rf94 [751.372943ms]
Sep  3 08:31:35.267: INFO: Created: latency-svc-btdjv
Sep  3 08:31:35.300: INFO: Got endpoints: latency-svc-74tfq [750.424922ms]
Sep  3 08:31:35.316: INFO: Created: latency-svc-bxxkl
Sep  3 08:31:35.349: INFO: Got endpoints: latency-svc-qph67 [748.678489ms]
Sep  3 08:31:35.363: INFO: Created: latency-svc-4svwd
Sep  3 08:31:35.399: INFO: Got endpoints: latency-svc-zj5qs [746.085068ms]
Sep  3 08:31:35.412: INFO: Created: latency-svc-4ndxj
Sep  3 08:31:35.450: INFO: Got endpoints: latency-svc-6pbm6 [747.922798ms]
Sep  3 08:31:35.470: INFO: Created: latency-svc-stnk5
Sep  3 08:31:35.503: INFO: Got endpoints: latency-svc-jwlvf [753.9963ms]
Sep  3 08:31:35.523: INFO: Created: latency-svc-dc5q7
Sep  3 08:31:35.553: INFO: Got endpoints: latency-svc-shhpt [754.886103ms]
Sep  3 08:31:35.568: INFO: Created: latency-svc-rlh46
Sep  3 08:31:35.598: INFO: Got endpoints: latency-svc-rn64q [750.21379ms]
Sep  3 08:31:35.613: INFO: Created: latency-svc-v62x8
Sep  3 08:31:35.648: INFO: Got endpoints: latency-svc-95n8m [749.34906ms]
Sep  3 08:31:35.665: INFO: Created: latency-svc-r8p9x
Sep  3 08:31:35.699: INFO: Got endpoints: latency-svc-cr7c6 [750.286028ms]
Sep  3 08:31:35.712: INFO: Created: latency-svc-64f7p
Sep  3 08:31:35.763: INFO: Got endpoints: latency-svc-4jmxl [761.800954ms]
Sep  3 08:31:35.778: INFO: Created: latency-svc-hh2wc
Sep  3 08:31:35.798: INFO: Got endpoints: latency-svc-q4trg [749.846244ms]
Sep  3 08:31:35.811: INFO: Created: latency-svc-6lgtm
Sep  3 08:31:35.849: INFO: Got endpoints: latency-svc-9cw69 [750.422857ms]
Sep  3 08:31:35.872: INFO: Created: latency-svc-4srtt
Sep  3 08:31:35.901: INFO: Got endpoints: latency-svc-62j27 [751.29908ms]
Sep  3 08:31:35.917: INFO: Created: latency-svc-5dc7n
Sep  3 08:31:35.948: INFO: Got endpoints: latency-svc-gm5vz [748.669281ms]
Sep  3 08:31:35.964: INFO: Created: latency-svc-2866z
Sep  3 08:31:35.998: INFO: Got endpoints: latency-svc-btdjv [748.333416ms]
Sep  3 08:31:36.013: INFO: Created: latency-svc-h4sgf
Sep  3 08:31:36.048: INFO: Got endpoints: latency-svc-bxxkl [747.771268ms]
Sep  3 08:31:36.065: INFO: Created: latency-svc-sdcq6
Sep  3 08:31:36.098: INFO: Got endpoints: latency-svc-4svwd [749.56734ms]
Sep  3 08:31:36.113: INFO: Created: latency-svc-vplxz
Sep  3 08:31:36.150: INFO: Got endpoints: latency-svc-4ndxj [751.309091ms]
Sep  3 08:31:36.163: INFO: Created: latency-svc-w6zs6
Sep  3 08:31:36.201: INFO: Got endpoints: latency-svc-stnk5 [751.171284ms]
Sep  3 08:31:36.214: INFO: Created: latency-svc-2lfgp
Sep  3 08:31:36.250: INFO: Got endpoints: latency-svc-dc5q7 [746.656404ms]
Sep  3 08:31:36.263: INFO: Created: latency-svc-gq2md
Sep  3 08:31:36.298: INFO: Got endpoints: latency-svc-rlh46 [745.155412ms]
Sep  3 08:31:36.314: INFO: Created: latency-svc-v6fvw
Sep  3 08:31:36.349: INFO: Got endpoints: latency-svc-v62x8 [750.860982ms]
Sep  3 08:31:36.370: INFO: Created: latency-svc-d5p84
Sep  3 08:31:36.400: INFO: Got endpoints: latency-svc-r8p9x [751.176921ms]
Sep  3 08:31:36.414: INFO: Created: latency-svc-vdtjl
Sep  3 08:31:36.448: INFO: Got endpoints: latency-svc-64f7p [749.807279ms]
Sep  3 08:31:36.468: INFO: Created: latency-svc-876ph
Sep  3 08:31:36.499: INFO: Got endpoints: latency-svc-hh2wc [736.127688ms]
Sep  3 08:31:36.517: INFO: Created: latency-svc-vlvsb
Sep  3 08:31:36.558: INFO: Got endpoints: latency-svc-6lgtm [759.305869ms]
Sep  3 08:31:36.575: INFO: Created: latency-svc-pbwcv
Sep  3 08:31:36.599: INFO: Got endpoints: latency-svc-4srtt [749.998836ms]
Sep  3 08:31:36.623: INFO: Created: latency-svc-98t48
Sep  3 08:31:36.649: INFO: Got endpoints: latency-svc-5dc7n [748.353955ms]
Sep  3 08:31:36.665: INFO: Created: latency-svc-d5xmv
Sep  3 08:31:36.700: INFO: Got endpoints: latency-svc-2866z [751.960158ms]
Sep  3 08:31:36.735: INFO: Created: latency-svc-m7qr9
Sep  3 08:31:36.752: INFO: Got endpoints: latency-svc-h4sgf [753.17678ms]
Sep  3 08:31:36.768: INFO: Created: latency-svc-6d6wg
Sep  3 08:31:36.799: INFO: Got endpoints: latency-svc-sdcq6 [751.139829ms]
Sep  3 08:31:36.813: INFO: Created: latency-svc-p2sft
Sep  3 08:31:36.849: INFO: Got endpoints: latency-svc-vplxz [750.268797ms]
Sep  3 08:31:36.863: INFO: Created: latency-svc-r8zcs
Sep  3 08:31:36.899: INFO: Got endpoints: latency-svc-w6zs6 [748.848558ms]
Sep  3 08:31:36.914: INFO: Created: latency-svc-bk9rd
Sep  3 08:31:36.950: INFO: Got endpoints: latency-svc-2lfgp [749.326696ms]
Sep  3 08:31:36.964: INFO: Created: latency-svc-cdkjc
Sep  3 08:31:36.998: INFO: Got endpoints: latency-svc-gq2md [748.505163ms]
Sep  3 08:31:37.017: INFO: Created: latency-svc-x6n9h
Sep  3 08:31:37.048: INFO: Got endpoints: latency-svc-v6fvw [750.167887ms]
Sep  3 08:31:37.063: INFO: Created: latency-svc-6hl9q
Sep  3 08:31:37.101: INFO: Got endpoints: latency-svc-d5p84 [751.607934ms]
Sep  3 08:31:37.114: INFO: Created: latency-svc-gwjbp
Sep  3 08:31:37.152: INFO: Got endpoints: latency-svc-vdtjl [752.624198ms]
Sep  3 08:31:37.168: INFO: Created: latency-svc-526h8
Sep  3 08:31:37.200: INFO: Got endpoints: latency-svc-876ph [751.645405ms]
Sep  3 08:31:37.213: INFO: Created: latency-svc-r6zr5
Sep  3 08:31:37.250: INFO: Got endpoints: latency-svc-vlvsb [750.969594ms]
Sep  3 08:31:37.263: INFO: Created: latency-svc-kr6sn
Sep  3 08:31:37.300: INFO: Got endpoints: latency-svc-pbwcv [742.137499ms]
Sep  3 08:31:37.314: INFO: Created: latency-svc-254fs
Sep  3 08:31:37.349: INFO: Got endpoints: latency-svc-98t48 [749.352109ms]
Sep  3 08:31:37.362: INFO: Created: latency-svc-dd446
Sep  3 08:31:37.398: INFO: Got endpoints: latency-svc-d5xmv [748.884089ms]
Sep  3 08:31:37.413: INFO: Created: latency-svc-4ggg9
Sep  3 08:31:37.449: INFO: Got endpoints: latency-svc-m7qr9 [749.138279ms]
Sep  3 08:31:37.463: INFO: Created: latency-svc-wqcvb
Sep  3 08:31:37.499: INFO: Got endpoints: latency-svc-6d6wg [747.064372ms]
Sep  3 08:31:37.550: INFO: Got endpoints: latency-svc-p2sft [750.897597ms]
Sep  3 08:31:37.601: INFO: Got endpoints: latency-svc-r8zcs [752.608541ms]
Sep  3 08:31:37.653: INFO: Got endpoints: latency-svc-bk9rd [753.809854ms]
Sep  3 08:31:37.699: INFO: Got endpoints: latency-svc-cdkjc [748.766855ms]
Sep  3 08:31:37.751: INFO: Got endpoints: latency-svc-x6n9h [752.100431ms]
Sep  3 08:31:37.801: INFO: Got endpoints: latency-svc-6hl9q [752.505053ms]
Sep  3 08:31:37.852: INFO: Got endpoints: latency-svc-gwjbp [751.301503ms]
Sep  3 08:31:37.900: INFO: Got endpoints: latency-svc-526h8 [747.448801ms]
Sep  3 08:31:37.950: INFO: Got endpoints: latency-svc-r6zr5 [749.933862ms]
Sep  3 08:31:38.003: INFO: Got endpoints: latency-svc-kr6sn [753.707702ms]
Sep  3 08:31:38.049: INFO: Got endpoints: latency-svc-254fs [748.65688ms]
Sep  3 08:31:38.103: INFO: Got endpoints: latency-svc-dd446 [754.575196ms]
Sep  3 08:31:38.149: INFO: Got endpoints: latency-svc-4ggg9 [750.672128ms]
Sep  3 08:31:38.199: INFO: Got endpoints: latency-svc-wqcvb [749.456189ms]
Sep  3 08:31:38.199: INFO: Latencies: [32.129918ms 35.480459ms 39.431902ms 52.676374ms 66.192283ms 68.044614ms 75.725417ms 90.58604ms 98.808921ms 118.815942ms 131.956943ms 135.986187ms 150.112197ms 150.94785ms 154.737804ms 155.487463ms 155.83054ms 156.625928ms 156.747563ms 157.017008ms 160.478044ms 165.621061ms 165.927962ms 167.007057ms 168.827648ms 170.300175ms 171.145674ms 171.415365ms 173.694758ms 174.478106ms 175.333098ms 176.666872ms 179.176546ms 179.776986ms 180.443987ms 181.261808ms 182.285223ms 186.19806ms 194.948002ms 249.517004ms 285.15388ms 316.961447ms 361.959447ms 397.302875ms 445.868187ms 471.324894ms 511.962185ms 555.758194ms 591.530884ms 638.485736ms 671.418758ms 713.156948ms 719.299632ms 731.308375ms 733.45384ms 736.127688ms 740.145922ms 740.447845ms 741.947732ms 741.993271ms 742.137499ms 742.964662ms 743.083861ms 743.45433ms 743.806785ms 744.065829ms 744.17519ms 745.155412ms 745.909622ms 745.982472ms 746.085068ms 746.167734ms 746.47899ms 746.596306ms 746.656404ms 746.7504ms 746.799681ms 746.810638ms 746.847278ms 746.969085ms 747.003203ms 747.064372ms 747.448801ms 747.771268ms 747.889725ms 747.922798ms 747.924325ms 747.977653ms 748.333416ms 748.339813ms 748.353955ms 748.45703ms 748.505163ms 748.52461ms 748.65688ms 748.669281ms 748.678489ms 748.766855ms 748.795354ms 748.848558ms 748.884089ms 748.935558ms 749.003284ms 749.036024ms 749.072783ms 749.114661ms 749.138279ms 749.260056ms 749.326696ms 749.34906ms 749.352109ms 749.383329ms 749.390856ms 749.456189ms 749.516793ms 749.539054ms 749.556009ms 749.56734ms 749.807279ms 749.822813ms 749.846244ms 749.853709ms 749.889067ms 749.933862ms 749.957322ms 749.970033ms 749.998836ms 750.167887ms 750.21379ms 750.268797ms 750.286028ms 750.392367ms 750.416999ms 750.422857ms 750.424922ms 750.432051ms 750.456541ms 750.457759ms 750.610399ms 750.624735ms 750.672128ms 750.860982ms 750.897597ms 750.969594ms 751.000049ms 751.028193ms 751.050377ms 751.139829ms 751.171284ms 751.176921ms 751.197238ms 751.257199ms 751.29908ms 751.301503ms 751.309091ms 751.372943ms 751.384534ms 751.397465ms 751.415367ms 751.492363ms 751.560571ms 751.607934ms 751.645405ms 751.795149ms 751.80609ms 751.932471ms 751.960158ms 752.080019ms 752.092876ms 752.100431ms 752.234507ms 752.307446ms 752.490819ms 752.505053ms 752.608541ms 752.624198ms 752.662735ms 752.694435ms 752.950192ms 752.971952ms 752.995011ms 753.010799ms 753.17678ms 753.707702ms 753.809854ms 753.9963ms 754.334022ms 754.446805ms 754.575196ms 754.811108ms 754.886103ms 756.35341ms 756.570808ms 757.966258ms 759.305869ms 761.800954ms 764.302308ms 767.445987ms 771.720888ms 779.473203ms]
Sep  3 08:31:38.199: INFO: 50 %ile: 748.884089ms
Sep  3 08:31:38.199: INFO: 90 %ile: 752.995011ms
Sep  3 08:31:38.199: INFO: 99 %ile: 771.720888ms
Sep  3 08:31:38.199: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:31:38.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-4983" for this suite.
Sep  3 08:31:54.246: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:31:54.389: INFO: namespace svc-latency-4983 deletion completed in 16.181332303s

• [SLOW TEST:27.046 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:31:54.389: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-1654
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Sep  3 08:31:54.455: INFO: Found 0 stateful pods, waiting for 3
Sep  3 08:32:04.459: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep  3 08:32:04.459: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep  3 08:32:04.459: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Sep  3 08:32:04.471: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-1654 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  3 08:32:04.641: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep  3 08:32:04.641: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  3 08:32:04.641: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Sep  3 08:32:14.689: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Sep  3 08:32:24.710: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-1654 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  3 08:32:24.874: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep  3 08:32:24.874: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  3 08:32:24.874: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  3 08:32:34.907: INFO: Waiting for StatefulSet statefulset-1654/ss2 to complete update
Sep  3 08:32:34.907: INFO: Waiting for Pod statefulset-1654/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Sep  3 08:32:34.907: INFO: Waiting for Pod statefulset-1654/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Sep  3 08:32:44.924: INFO: Waiting for StatefulSet statefulset-1654/ss2 to complete update
Sep  3 08:32:44.924: INFO: Waiting for Pod statefulset-1654/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Sep  3 08:32:54.916: INFO: Waiting for StatefulSet statefulset-1654/ss2 to complete update
STEP: Rolling back to a previous revision
Sep  3 08:33:04.916: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-1654 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  3 08:33:05.080: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep  3 08:33:05.080: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  3 08:33:05.080: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  3 08:33:05.114: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Sep  3 08:33:15.142: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-1654 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  3 08:33:15.308: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep  3 08:33:15.308: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  3 08:33:15.308: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  3 08:33:25.371: INFO: Waiting for StatefulSet statefulset-1654/ss2 to complete update
Sep  3 08:33:25.371: INFO: Waiting for Pod statefulset-1654/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Sep  3 08:33:25.371: INFO: Waiting for Pod statefulset-1654/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Sep  3 08:33:25.371: INFO: Waiting for Pod statefulset-1654/ss2-2 to have revision ss2-787997d666 update revision ss2-c79899b9
Sep  3 08:33:35.381: INFO: Waiting for StatefulSet statefulset-1654/ss2 to complete update
Sep  3 08:33:35.381: INFO: Waiting for Pod statefulset-1654/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Sep  3 08:33:45.385: INFO: Waiting for StatefulSet statefulset-1654/ss2 to complete update
Sep  3 08:33:45.385: INFO: Waiting for Pod statefulset-1654/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Sep  3 08:33:55.380: INFO: Deleting all statefulset in ns statefulset-1654
Sep  3 08:33:55.385: INFO: Scaling statefulset ss2 to 0
Sep  3 08:34:25.405: INFO: Waiting for statefulset status.replicas updated to 0
Sep  3 08:34:25.410: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:34:25.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1654" for this suite.
Sep  3 08:34:33.456: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:34:33.604: INFO: namespace statefulset-1654 deletion completed in 8.164003327s

• [SLOW TEST:159.215 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:34:33.605: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep  3 08:34:33.681: INFO: Create a RollingUpdate DaemonSet
Sep  3 08:34:33.689: INFO: Check that daemon pods launch on every node of the cluster
Sep  3 08:34:33.697: INFO: Number of nodes with available pods: 0
Sep  3 08:34:33.697: INFO: Node 10.0.0.6 is running more than one daemon pod
Sep  3 08:34:34.764: INFO: Number of nodes with available pods: 0
Sep  3 08:34:34.764: INFO: Node 10.0.0.6 is running more than one daemon pod
Sep  3 08:34:35.767: INFO: Number of nodes with available pods: 2
Sep  3 08:34:35.767: INFO: Number of running nodes: 2, number of available pods: 2
Sep  3 08:34:35.767: INFO: Update the DaemonSet to trigger a rollout
Sep  3 08:34:35.783: INFO: Updating DaemonSet daemon-set
Sep  3 08:34:44.794: INFO: Roll back the DaemonSet before rollout is complete
Sep  3 08:34:44.813: INFO: Updating DaemonSet daemon-set
Sep  3 08:34:44.813: INFO: Make sure DaemonSet rollback is complete
Sep  3 08:34:44.837: INFO: Wrong image for pod: daemon-set-6jttz. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Sep  3 08:34:44.837: INFO: Pod daemon-set-6jttz is not available
Sep  3 08:34:45.846: INFO: Wrong image for pod: daemon-set-6jttz. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Sep  3 08:34:45.846: INFO: Pod daemon-set-6jttz is not available
Sep  3 08:34:46.848: INFO: Pod daemon-set-jwrjq is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6896, will wait for the garbage collector to delete the pods
Sep  3 08:34:46.934: INFO: Deleting DaemonSet.extensions daemon-set took: 16.099474ms
Sep  3 08:34:47.334: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.167167ms
Sep  3 08:36:04.338: INFO: Number of nodes with available pods: 0
Sep  3 08:36:04.338: INFO: Number of running nodes: 0, number of available pods: 0
Sep  3 08:36:04.344: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-6896/daemonsets","resourceVersion":"86770696"},"items":null}

Sep  3 08:36:04.350: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-6896/pods","resourceVersion":"86770696"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:36:04.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6896" for this suite.
Sep  3 08:36:10.384: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:36:10.609: INFO: namespace daemonsets-6896 deletion completed in 6.240203364s

• [SLOW TEST:97.004 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:36:10.609: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Sep  3 08:36:11.014: INFO: Pod name wrapped-volume-race-e1dc2d91-ce25-11e9-a824-e6b94fc13bb4: Found 0 pods out of 5
Sep  3 08:36:16.030: INFO: Pod name wrapped-volume-race-e1dc2d91-ce25-11e9-a824-e6b94fc13bb4: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-e1dc2d91-ce25-11e9-a824-e6b94fc13bb4 in namespace emptydir-wrapper-9364, will wait for the garbage collector to delete the pods
Sep  3 08:38:00.150: INFO: Deleting ReplicationController wrapped-volume-race-e1dc2d91-ce25-11e9-a824-e6b94fc13bb4 took: 15.358521ms
Sep  3 08:38:00.550: INFO: Terminating ReplicationController wrapped-volume-race-e1dc2d91-ce25-11e9-a824-e6b94fc13bb4 pods took: 400.133315ms
STEP: Creating RC which spawns configmap-volume pods
Sep  3 08:38:37.178: INFO: Pod name wrapped-volume-race-38fa2522-ce26-11e9-a824-e6b94fc13bb4: Found 0 pods out of 5
Sep  3 08:38:42.187: INFO: Pod name wrapped-volume-race-38fa2522-ce26-11e9-a824-e6b94fc13bb4: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-38fa2522-ce26-11e9-a824-e6b94fc13bb4 in namespace emptydir-wrapper-9364, will wait for the garbage collector to delete the pods
Sep  3 08:40:28.350: INFO: Deleting ReplicationController wrapped-volume-race-38fa2522-ce26-11e9-a824-e6b94fc13bb4 took: 16.718134ms
Sep  3 08:40:28.850: INFO: Terminating ReplicationController wrapped-volume-race-38fa2522-ce26-11e9-a824-e6b94fc13bb4 pods took: 500.158798ms
STEP: Creating RC which spawns configmap-volume pods
Sep  3 08:41:08.105: INFO: Pod name wrapped-volume-race-92eba409-ce26-11e9-a824-e6b94fc13bb4: Found 0 pods out of 5
Sep  3 08:41:13.113: INFO: Pod name wrapped-volume-race-92eba409-ce26-11e9-a824-e6b94fc13bb4: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-92eba409-ce26-11e9-a824-e6b94fc13bb4 in namespace emptydir-wrapper-9364, will wait for the garbage collector to delete the pods
Sep  3 08:43:09.212: INFO: Deleting ReplicationController wrapped-volume-race-92eba409-ce26-11e9-a824-e6b94fc13bb4 took: 14.120994ms
Sep  3 08:43:09.612: INFO: Terminating ReplicationController wrapped-volume-race-92eba409-ce26-11e9-a824-e6b94fc13bb4 pods took: 400.140074ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:43:47.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-9364" for this suite.
Sep  3 08:43:55.851: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:43:55.996: INFO: namespace emptydir-wrapper-9364 deletion completed in 8.159172721s

• [SLOW TEST:465.387 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:43:55.996: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1354
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep  3 08:43:56.047: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-1621'
Sep  3 08:43:56.175: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep  3 08:43:56.175: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Sep  3 08:43:56.194: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-tzzll]
Sep  3 08:43:56.194: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-tzzll" in namespace "kubectl-1621" to be "running and ready"
Sep  3 08:43:56.218: INFO: Pod "e2e-test-nginx-rc-tzzll": Phase="Pending", Reason="", readiness=false. Elapsed: 23.794943ms
Sep  3 08:43:58.223: INFO: Pod "e2e-test-nginx-rc-tzzll": Phase="Running", Reason="", readiness=true. Elapsed: 2.028494391s
Sep  3 08:43:58.223: INFO: Pod "e2e-test-nginx-rc-tzzll" satisfied condition "running and ready"
Sep  3 08:43:58.223: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-tzzll]
Sep  3 08:43:58.223: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 logs rc/e2e-test-nginx-rc --namespace=kubectl-1621'
Sep  3 08:43:58.324: INFO: stderr: ""
Sep  3 08:43:58.324: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1359
Sep  3 08:43:58.324: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 delete rc e2e-test-nginx-rc --namespace=kubectl-1621'
Sep  3 08:43:58.405: INFO: stderr: ""
Sep  3 08:43:58.405: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:43:58.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1621" for this suite.
Sep  3 08:44:04.437: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:44:04.603: INFO: namespace kubectl-1621 deletion completed in 6.193213353s

• [SLOW TEST:8.608 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:44:04.604: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Sep  3 08:44:08.715: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep  3 08:44:08.719: INFO: Pod pod-with-prestop-http-hook still exists
Sep  3 08:44:10.719: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep  3 08:44:10.723: INFO: Pod pod-with-prestop-http-hook still exists
Sep  3 08:44:12.719: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep  3 08:44:12.763: INFO: Pod pod-with-prestop-http-hook still exists
Sep  3 08:44:14.719: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep  3 08:44:14.723: INFO: Pod pod-with-prestop-http-hook still exists
Sep  3 08:44:16.719: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep  3 08:44:16.723: INFO: Pod pod-with-prestop-http-hook still exists
Sep  3 08:44:18.719: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep  3 08:44:18.723: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:44:18.734: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9798" for this suite.
Sep  3 08:44:42.754: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:44:42.911: INFO: namespace container-lifecycle-hook-9798 deletion completed in 24.17202428s

• [SLOW TEST:38.307 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:44:42.911: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name cm-test-opt-del-13070564-ce27-11e9-a824-e6b94fc13bb4
STEP: Creating configMap with name cm-test-opt-upd-1307059b-ce27-11e9-a824-e6b94fc13bb4
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-13070564-ce27-11e9-a824-e6b94fc13bb4
STEP: Updating configmap cm-test-opt-upd-1307059b-ce27-11e9-a824-e6b94fc13bb4
STEP: Creating configMap with name cm-test-opt-create-130705b5-ce27-11e9-a824-e6b94fc13bb4
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:44:47.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9720" for this suite.
Sep  3 08:45:11.211: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:45:11.392: INFO: namespace configmap-9720 deletion completed in 24.20045426s

• [SLOW TEST:28.481 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:45:11.392: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Sep  3 08:45:11.451: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:45:13.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4390" for this suite.
Sep  3 08:45:19.686: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:45:19.929: INFO: namespace init-container-4390 deletion completed in 6.261462736s

• [SLOW TEST:8.536 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:45:19.929: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep  3 08:45:19.984: INFO: Creating deployment "test-recreate-deployment"
Sep  3 08:45:19.994: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Sep  3 08:45:20.002: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Sep  3 08:45:22.009: INFO: Waiting deployment "test-recreate-deployment" to complete
Sep  3 08:45:22.013: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703097120, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703097120, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703097120, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703097120, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-7d57d5ff7c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  3 08:45:24.018: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Sep  3 08:45:24.041: INFO: Updating deployment test-recreate-deployment
Sep  3 08:45:24.041: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Sep  3 08:45:24.235: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-6235,SelfLink:/apis/apps/v1/namespaces/deployment-6235/deployments/test-recreate-deployment,UID:2915f237-ce27-11e9-9b9a-9e20fc449913,ResourceVersion:86808420,Generation:2,CreationTimestamp:2019-09-03 08:45:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-09-03 08:45:24 +0000 UTC 2019-09-03 08:45:24 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-09-03 08:45:24 +0000 UTC 2019-09-03 08:45:20 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-c9cbd8684" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Sep  3 08:45:24.241: INFO: New ReplicaSet "test-recreate-deployment-c9cbd8684" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-c9cbd8684,GenerateName:,Namespace:deployment-6235,SelfLink:/apis/apps/v1/namespaces/deployment-6235/replicasets/test-recreate-deployment-c9cbd8684,UID:2b924220-ce27-11e9-9b9a-9e20fc449913,ResourceVersion:86808417,Generation:1,CreationTimestamp:2019-09-03 08:45:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 2915f237-ce27-11e9-9b9a-9e20fc449913 0xc00302d3e0 0xc00302d3e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep  3 08:45:24.241: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Sep  3 08:45:24.241: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7d57d5ff7c,GenerateName:,Namespace:deployment-6235,SelfLink:/apis/apps/v1/namespaces/deployment-6235/replicasets/test-recreate-deployment-7d57d5ff7c,UID:29178c73-ce27-11e9-9b9a-9e20fc449913,ResourceVersion:86808402,Generation:2,CreationTimestamp:2019-09-03 08:45:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 2915f237-ce27-11e9-9b9a-9e20fc449913 0xc00302d317 0xc00302d318}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7d57d5ff7c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep  3 08:45:24.245: INFO: Pod "test-recreate-deployment-c9cbd8684-zm6fk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-c9cbd8684-zm6fk,GenerateName:test-recreate-deployment-c9cbd8684-,Namespace:deployment-6235,SelfLink:/api/v1/namespaces/deployment-6235/pods/test-recreate-deployment-c9cbd8684-zm6fk,UID:2b93d705-ce27-11e9-9b9a-9e20fc449913,ResourceVersion:86808419,Generation:0,CreationTimestamp:2019-09-03 08:45:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: c9cbd8684,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-c9cbd8684 2b924220-ce27-11e9-9b9a-9e20fc449913 0xc00302dc20 0xc00302dc21}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-lz7g8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lz7g8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-lz7g8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.6,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 08:45:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 08:45:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 08:45:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 08:45:24 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.6,PodIP:,StartTime:2019-09-03 08:45:24 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:45:24.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6235" for this suite.
Sep  3 08:45:30.266: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:45:30.424: INFO: namespace deployment-6235 deletion completed in 6.174279619s

• [SLOW TEST:10.495 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:45:30.424: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Sep  3 08:45:30.479: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep  3 08:45:30.490: INFO: Waiting for terminating namespaces to be deleted...
Sep  3 08:45:30.493: INFO: 
Logging pods the kubelet thinks is on node 10.0.0.6 before test
Sep  3 08:45:30.501: INFO: l7-lb-controller-85665d7887-mbmmm from kube-system started at 2019-09-03 07:25:10 +0000 UTC (1 container statuses recorded)
Sep  3 08:45:30.501: INFO: 	Container l7-lb-controller ready: true, restart count 2
Sep  3 08:45:30.501: INFO: coredns-6d58b575d7-prm6h from kube-system started at 2019-09-03 07:25:10 +0000 UTC (1 container statuses recorded)
Sep  3 08:45:30.501: INFO: 	Container coredns ready: true, restart count 1
Sep  3 08:45:30.501: INFO: tke-cni-agent-bfqbh from kube-system started at 2019-09-03 07:25:10 +0000 UTC (1 container statuses recorded)
Sep  3 08:45:30.501: INFO: 	Container tke-cni-agent ready: true, restart count 1
Sep  3 08:45:30.501: INFO: coredns-6d58b575d7-6v8hl from kube-system started at 2019-09-03 07:25:10 +0000 UTC (1 container statuses recorded)
Sep  3 08:45:30.501: INFO: 	Container coredns ready: true, restart count 1
Sep  3 08:45:30.501: INFO: tke-bridge-agent-xxtpr from kube-system started at 2019-09-03 07:25:10 +0000 UTC (1 container statuses recorded)
Sep  3 08:45:30.501: INFO: 	Container tke-bridge-agent ready: true, restart count 1
Sep  3 08:45:30.501: INFO: ip-masq-agent-567fp from kube-system started at 2019-09-03 07:25:10 +0000 UTC (1 container statuses recorded)
Sep  3 08:45:30.501: INFO: 	Container ip-masq-agent ready: true, restart count 1
Sep  3 08:45:30.501: INFO: sonobuoy-systemd-logs-daemon-set-9498ee0a545f46b0-n2nmx from heptio-sonobuoy started at 2019-09-03 08:17:22 +0000 UTC (2 container statuses recorded)
Sep  3 08:45:30.501: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep  3 08:45:30.501: INFO: 	Container systemd-logs ready: true, restart count 0
Sep  3 08:45:30.501: INFO: 
Logging pods the kubelet thinks is on node 10.0.0.9 before test
Sep  3 08:45:30.513: INFO: tke-bridge-agent-r6m4x from kube-system started at 2019-09-03 07:25:12 +0000 UTC (1 container statuses recorded)
Sep  3 08:45:30.513: INFO: 	Container tke-bridge-agent ready: true, restart count 1
Sep  3 08:45:30.513: INFO: tke-cni-agent-nx5pw from kube-system started at 2019-09-03 07:25:12 +0000 UTC (1 container statuses recorded)
Sep  3 08:45:30.513: INFO: 	Container tke-cni-agent ready: true, restart count 1
Sep  3 08:45:30.513: INFO: sonobuoy-systemd-logs-daemon-set-9498ee0a545f46b0-d2zzq from heptio-sonobuoy started at 2019-09-03 08:17:22 +0000 UTC (2 container statuses recorded)
Sep  3 08:45:30.513: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep  3 08:45:30.513: INFO: 	Container systemd-logs ready: true, restart count 0
Sep  3 08:45:30.513: INFO: ip-masq-agent-nttr5 from kube-system started at 2019-09-03 07:25:12 +0000 UTC (1 container statuses recorded)
Sep  3 08:45:30.513: INFO: 	Container ip-masq-agent ready: true, restart count 1
Sep  3 08:45:30.513: INFO: sonobuoy from heptio-sonobuoy started at 2019-09-03 08:17:16 +0000 UTC (1 container statuses recorded)
Sep  3 08:45:30.513: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep  3 08:45:30.513: INFO: sonobuoy-e2e-job-aaa506819e174e7a from heptio-sonobuoy started at 2019-09-03 08:17:22 +0000 UTC (2 container statuses recorded)
Sep  3 08:45:30.513: INFO: 	Container e2e ready: true, restart count 0
Sep  3 08:45:30.513: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: verifying the node has the label node 10.0.0.6
STEP: verifying the node has the label node 10.0.0.9
Sep  3 08:45:30.557: INFO: Pod sonobuoy requesting resource cpu=0m on Node 10.0.0.9
Sep  3 08:45:30.557: INFO: Pod sonobuoy-e2e-job-aaa506819e174e7a requesting resource cpu=0m on Node 10.0.0.9
Sep  3 08:45:30.557: INFO: Pod sonobuoy-systemd-logs-daemon-set-9498ee0a545f46b0-d2zzq requesting resource cpu=0m on Node 10.0.0.9
Sep  3 08:45:30.557: INFO: Pod sonobuoy-systemd-logs-daemon-set-9498ee0a545f46b0-n2nmx requesting resource cpu=0m on Node 10.0.0.6
Sep  3 08:45:30.557: INFO: Pod coredns-6d58b575d7-6v8hl requesting resource cpu=100m on Node 10.0.0.6
Sep  3 08:45:30.557: INFO: Pod coredns-6d58b575d7-prm6h requesting resource cpu=100m on Node 10.0.0.6
Sep  3 08:45:30.557: INFO: Pod ip-masq-agent-567fp requesting resource cpu=0m on Node 10.0.0.6
Sep  3 08:45:30.557: INFO: Pod ip-masq-agent-nttr5 requesting resource cpu=0m on Node 10.0.0.9
Sep  3 08:45:30.557: INFO: Pod l7-lb-controller-85665d7887-mbmmm requesting resource cpu=0m on Node 10.0.0.6
Sep  3 08:45:30.557: INFO: Pod tke-bridge-agent-r6m4x requesting resource cpu=0m on Node 10.0.0.9
Sep  3 08:45:30.557: INFO: Pod tke-bridge-agent-xxtpr requesting resource cpu=0m on Node 10.0.0.6
Sep  3 08:45:30.557: INFO: Pod tke-cni-agent-bfqbh requesting resource cpu=0m on Node 10.0.0.6
Sep  3 08:45:30.557: INFO: Pod tke-cni-agent-nx5pw requesting resource cpu=0m on Node 10.0.0.9
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2f630cfe-ce27-11e9-a824-e6b94fc13bb4.15c0e13ee56e4521], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4166/filler-pod-2f630cfe-ce27-11e9-a824-e6b94fc13bb4 to 10.0.0.6]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2f630cfe-ce27-11e9-a824-e6b94fc13bb4.15c0e13f062bb444], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2f630cfe-ce27-11e9-a824-e6b94fc13bb4.15c0e13f0768d1a0], Reason = [Created], Message = [Created container filler-pod-2f630cfe-ce27-11e9-a824-e6b94fc13bb4]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2f630cfe-ce27-11e9-a824-e6b94fc13bb4.15c0e13f0e0400dc], Reason = [Started], Message = [Started container filler-pod-2f630cfe-ce27-11e9-a824-e6b94fc13bb4]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2f649fec-ce27-11e9-a824-e6b94fc13bb4.15c0e13ee591e9d8], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4166/filler-pod-2f649fec-ce27-11e9-a824-e6b94fc13bb4 to 10.0.0.9]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2f649fec-ce27-11e9-a824-e6b94fc13bb4.15c0e13f04b59929], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2f649fec-ce27-11e9-a824-e6b94fc13bb4.15c0e13f064cd0da], Reason = [Created], Message = [Created container filler-pod-2f649fec-ce27-11e9-a824-e6b94fc13bb4]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2f649fec-ce27-11e9-a824-e6b94fc13bb4.15c0e13f0b9bf84d], Reason = [Started], Message = [Started container filler-pod-2f649fec-ce27-11e9-a824-e6b94fc13bb4]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15c0e13f5df7a02c], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu.]
STEP: removing the label node off the node 10.0.0.6
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.0.0.9
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:45:33.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4166" for this suite.
Sep  3 08:45:39.668: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:45:39.953: INFO: namespace sched-pred-4166 deletion completed in 6.300458894s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:9.529 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:45:39.953: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override all
Sep  3 08:45:40.012: INFO: Waiting up to 5m0s for pod "client-containers-3503e4f8-ce27-11e9-a824-e6b94fc13bb4" in namespace "containers-7714" to be "success or failure"
Sep  3 08:45:40.018: INFO: Pod "client-containers-3503e4f8-ce27-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.372597ms
Sep  3 08:45:42.023: INFO: Pod "client-containers-3503e4f8-ce27-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010886019s
Sep  3 08:45:44.027: INFO: Pod "client-containers-3503e4f8-ce27-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015309036s
STEP: Saw pod success
Sep  3 08:45:44.027: INFO: Pod "client-containers-3503e4f8-ce27-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 08:45:44.031: INFO: Trying to get logs from node 10.0.0.9 pod client-containers-3503e4f8-ce27-11e9-a824-e6b94fc13bb4 container test-container: <nil>
STEP: delete the pod
Sep  3 08:45:44.062: INFO: Waiting for pod client-containers-3503e4f8-ce27-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 08:45:44.065: INFO: Pod client-containers-3503e4f8-ce27-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:45:44.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7714" for this suite.
Sep  3 08:45:50.088: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:45:50.243: INFO: namespace containers-7714 deletion completed in 6.173684233s

• [SLOW TEST:10.290 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:45:50.243: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1108
STEP: creating the pod
Sep  3 08:45:50.317: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 create -f - --namespace=kubectl-2869'
Sep  3 08:45:50.494: INFO: stderr: ""
Sep  3 08:45:50.494: INFO: stdout: "pod/pause created\n"
Sep  3 08:45:50.494: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Sep  3 08:45:50.494: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-2869" to be "running and ready"
Sep  3 08:45:50.498: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 3.652184ms
Sep  3 08:45:52.502: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.007863745s
Sep  3 08:45:52.502: INFO: Pod "pause" satisfied condition "running and ready"
Sep  3 08:45:52.502: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: adding the label testing-label with value testing-label-value to a pod
Sep  3 08:45:52.502: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 label pods pause testing-label=testing-label-value --namespace=kubectl-2869'
Sep  3 08:45:52.579: INFO: stderr: ""
Sep  3 08:45:52.579: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Sep  3 08:45:52.579: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 get pod pause -L testing-label --namespace=kubectl-2869'
Sep  3 08:45:52.644: INFO: stderr: ""
Sep  3 08:45:52.644: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Sep  3 08:45:52.644: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 label pods pause testing-label- --namespace=kubectl-2869'
Sep  3 08:45:52.723: INFO: stderr: ""
Sep  3 08:45:52.723: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Sep  3 08:45:52.723: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 get pod pause -L testing-label --namespace=kubectl-2869'
Sep  3 08:45:52.788: INFO: stderr: ""
Sep  3 08:45:52.788: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1115
STEP: using delete to clean up resources
Sep  3 08:45:52.788: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 delete --grace-period=0 --force -f - --namespace=kubectl-2869'
Sep  3 08:45:52.916: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  3 08:45:52.916: INFO: stdout: "pod \"pause\" force deleted\n"
Sep  3 08:45:52.916: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 get rc,svc -l name=pause --no-headers --namespace=kubectl-2869'
Sep  3 08:45:53.059: INFO: stderr: "No resources found.\n"
Sep  3 08:45:53.060: INFO: stdout: ""
Sep  3 08:45:53.060: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 get pods -l name=pause --namespace=kubectl-2869 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep  3 08:45:53.124: INFO: stderr: ""
Sep  3 08:45:53.124: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:45:53.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2869" for this suite.
Sep  3 08:45:59.147: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:45:59.352: INFO: namespace kubectl-2869 deletion completed in 6.220793052s

• [SLOW TEST:9.109 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:45:59.352: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Sep  3 08:45:59.444: INFO: Waiting up to 5m0s for pod "pod-4097b06b-ce27-11e9-a824-e6b94fc13bb4" in namespace "emptydir-4560" to be "success or failure"
Sep  3 08:45:59.447: INFO: Pod "pod-4097b06b-ce27-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.573553ms
Sep  3 08:46:01.452: INFO: Pod "pod-4097b06b-ce27-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008232463s
STEP: Saw pod success
Sep  3 08:46:01.452: INFO: Pod "pod-4097b06b-ce27-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 08:46:01.472: INFO: Trying to get logs from node 10.0.0.9 pod pod-4097b06b-ce27-11e9-a824-e6b94fc13bb4 container test-container: <nil>
STEP: delete the pod
Sep  3 08:46:01.519: INFO: Waiting for pod pod-4097b06b-ce27-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 08:46:01.523: INFO: Pod pod-4097b06b-ce27-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:46:01.523: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4560" for this suite.
Sep  3 08:46:07.558: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:46:07.712: INFO: namespace emptydir-4560 deletion completed in 6.16987716s

• [SLOW TEST:8.359 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:46:07.712: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep  3 08:46:07.868: INFO: Waiting up to 5m0s for pod "downwardapi-volume-459eb660-ce27-11e9-a824-e6b94fc13bb4" in namespace "projected-5348" to be "success or failure"
Sep  3 08:46:07.872: INFO: Pod "downwardapi-volume-459eb660-ce27-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.54822ms
Sep  3 08:46:09.876: INFO: Pod "downwardapi-volume-459eb660-ce27-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007818981s
STEP: Saw pod success
Sep  3 08:46:09.876: INFO: Pod "downwardapi-volume-459eb660-ce27-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 08:46:09.880: INFO: Trying to get logs from node 10.0.0.6 pod downwardapi-volume-459eb660-ce27-11e9-a824-e6b94fc13bb4 container client-container: <nil>
STEP: delete the pod
Sep  3 08:46:09.910: INFO: Waiting for pod downwardapi-volume-459eb660-ce27-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 08:46:09.913: INFO: Pod downwardapi-volume-459eb660-ce27-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:46:09.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5348" for this suite.
Sep  3 08:46:15.938: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:46:16.118: INFO: namespace projected-5348 deletion completed in 6.200094362s

• [SLOW TEST:8.406 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:46:16.118: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep  3 08:46:16.213: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4a97de6d-ce27-11e9-a824-e6b94fc13bb4" in namespace "projected-3132" to be "success or failure"
Sep  3 08:46:16.218: INFO: Pod "downwardapi-volume-4a97de6d-ce27-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 5.333589ms
Sep  3 08:46:18.226: INFO: Pod "downwardapi-volume-4a97de6d-ce27-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013639003s
STEP: Saw pod success
Sep  3 08:46:18.226: INFO: Pod "downwardapi-volume-4a97de6d-ce27-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 08:46:18.263: INFO: Trying to get logs from node 10.0.0.9 pod downwardapi-volume-4a97de6d-ce27-11e9-a824-e6b94fc13bb4 container client-container: <nil>
STEP: delete the pod
Sep  3 08:46:18.291: INFO: Waiting for pod downwardapi-volume-4a97de6d-ce27-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 08:46:18.295: INFO: Pod downwardapi-volume-4a97de6d-ce27-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:46:18.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3132" for this suite.
Sep  3 08:46:24.314: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:46:24.472: INFO: namespace projected-3132 deletion completed in 6.172478639s

• [SLOW TEST:8.354 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:46:24.472: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Sep  3 08:46:27.099: INFO: Successfully updated pod "labelsupdate4f91f0d2-ce27-11e9-a824-e6b94fc13bb4"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:46:31.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1515" for this suite.
Sep  3 08:46:55.189: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:46:55.493: INFO: namespace projected-1515 deletion completed in 24.321101305s

• [SLOW TEST:31.021 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:46:55.493: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep  3 08:46:55.564: INFO: Waiting up to 5m0s for pod "downwardapi-volume-620c45b8-ce27-11e9-a824-e6b94fc13bb4" in namespace "projected-1723" to be "success or failure"
Sep  3 08:46:55.568: INFO: Pod "downwardapi-volume-620c45b8-ce27-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.223748ms
Sep  3 08:46:57.571: INFO: Pod "downwardapi-volume-620c45b8-ce27-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00693083s
STEP: Saw pod success
Sep  3 08:46:57.571: INFO: Pod "downwardapi-volume-620c45b8-ce27-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 08:46:57.575: INFO: Trying to get logs from node 10.0.0.9 pod downwardapi-volume-620c45b8-ce27-11e9-a824-e6b94fc13bb4 container client-container: <nil>
STEP: delete the pod
Sep  3 08:46:57.634: INFO: Waiting for pod downwardapi-volume-620c45b8-ce27-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 08:46:57.637: INFO: Pod downwardapi-volume-620c45b8-ce27-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:46:57.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1723" for this suite.
Sep  3 08:47:03.658: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:47:03.938: INFO: namespace projected-1723 deletion completed in 6.295523836s

• [SLOW TEST:8.445 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:47:03.938: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0903 08:47:34.611246      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep  3 08:47:34.611: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:47:34.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7190" for this suite.
Sep  3 08:47:40.630: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:47:40.783: INFO: namespace gc-7190 deletion completed in 6.167548002s

• [SLOW TEST:36.845 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:47:40.783: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep  3 08:47:40.842: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7d09889a-ce27-11e9-a824-e6b94fc13bb4" in namespace "projected-6931" to be "success or failure"
Sep  3 08:47:40.846: INFO: Pod "downwardapi-volume-7d09889a-ce27-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.676927ms
Sep  3 08:47:42.854: INFO: Pod "downwardapi-volume-7d09889a-ce27-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011682772s
STEP: Saw pod success
Sep  3 08:47:42.854: INFO: Pod "downwardapi-volume-7d09889a-ce27-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 08:47:42.858: INFO: Trying to get logs from node 10.0.0.6 pod downwardapi-volume-7d09889a-ce27-11e9-a824-e6b94fc13bb4 container client-container: <nil>
STEP: delete the pod
Sep  3 08:47:42.885: INFO: Waiting for pod downwardapi-volume-7d09889a-ce27-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 08:47:42.889: INFO: Pod downwardapi-volume-7d09889a-ce27-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:47:42.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6931" for this suite.
Sep  3 08:47:48.913: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:47:49.068: INFO: namespace projected-6931 deletion completed in 6.172834827s

• [SLOW TEST:8.285 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:47:49.068: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep  3 08:47:49.133: INFO: Waiting up to 5m0s for pod "downwardapi-volume-81f9e63d-ce27-11e9-a824-e6b94fc13bb4" in namespace "projected-8441" to be "success or failure"
Sep  3 08:47:49.139: INFO: Pod "downwardapi-volume-81f9e63d-ce27-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.452648ms
Sep  3 08:47:51.143: INFO: Pod "downwardapi-volume-81f9e63d-ce27-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01071534s
STEP: Saw pod success
Sep  3 08:47:51.143: INFO: Pod "downwardapi-volume-81f9e63d-ce27-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 08:47:51.147: INFO: Trying to get logs from node 10.0.0.9 pod downwardapi-volume-81f9e63d-ce27-11e9-a824-e6b94fc13bb4 container client-container: <nil>
STEP: delete the pod
Sep  3 08:47:51.176: INFO: Waiting for pod downwardapi-volume-81f9e63d-ce27-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 08:47:51.179: INFO: Pod downwardapi-volume-81f9e63d-ce27-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:47:51.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8441" for this suite.
Sep  3 08:47:57.201: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:47:57.354: INFO: namespace projected-8441 deletion completed in 6.167845583s

• [SLOW TEST:8.286 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:47:57.354: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: validating cluster-info
Sep  3 08:47:57.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 cluster-info'
Sep  3 08:47:57.554: INFO: stderr: ""
Sep  3 08:47:57.554: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://172.22.255.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://172.22.255.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns-tcp/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:47:57.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8875" for this suite.
Sep  3 08:48:03.583: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:48:03.724: INFO: namespace kubectl-8875 deletion completed in 6.157075933s

• [SLOW TEST:6.370 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:48:03.724: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:48:27.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-829" for this suite.
Sep  3 08:48:33.970: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:48:34.125: INFO: namespace namespaces-829 deletion completed in 6.173003753s
STEP: Destroying namespace "nsdeletetest-5846" for this suite.
Sep  3 08:48:34.131: INFO: Namespace nsdeletetest-5846 was already deleted
STEP: Destroying namespace "nsdeletetest-351" for this suite.
Sep  3 08:48:40.163: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:48:40.358: INFO: namespace nsdeletetest-351 deletion completed in 6.227117274s

• [SLOW TEST:36.634 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:48:40.358: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1583
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep  3 08:48:40.422: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-9453'
Sep  3 08:48:40.506: INFO: stderr: ""
Sep  3 08:48:40.506: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1588
Sep  3 08:48:40.510: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 delete pods e2e-test-nginx-pod --namespace=kubectl-9453'
Sep  3 08:48:54.252: INFO: stderr: ""
Sep  3 08:48:54.252: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:48:54.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9453" for this suite.
Sep  3 08:49:00.279: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:49:00.504: INFO: namespace kubectl-9453 deletion completed in 6.247269082s

• [SLOW TEST:20.146 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:49:00.504: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:49:02.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9324" for this suite.
Sep  3 08:49:42.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:49:42.846: INFO: namespace kubelet-test-9324 deletion completed in 40.216209958s

• [SLOW TEST:42.341 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a read only busybox container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:49:42.846: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1619
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep  3 08:49:42.920: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-5379'
Sep  3 08:49:43.019: INFO: stderr: ""
Sep  3 08:49:43.019: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Sep  3 08:49:48.070: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 get pod e2e-test-nginx-pod --namespace=kubectl-5379 -o json'
Sep  3 08:49:48.140: INFO: stderr: ""
Sep  3 08:49:48.140: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"tke.cloud.tencent.com/networks-status\": \"[{\\n    \\\"name\\\": \\\"tke-bridge\\\",\\n    \\\"ips\\\": [\\n        \\\"172.22.1.53\\\"\\n    ],\\n    \\\"default\\\": true,\\n    \\\"dns\\\": {}\\n}]\"\n        },\n        \"creationTimestamp\": \"2019-09-03T08:49:43Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-5379\",\n        \"resourceVersion\": \"86826063\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-5379/pods/e2e-test-nginx-pod\",\n        \"uid\": \"c5dbf7a9-ce27-11e9-9b9a-9e20fc449913\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-5lncx\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"10.0.0.9\",\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"volumes\": [\n            {\n                \"name\": \"default-token-5lncx\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-5lncx\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-03T08:49:43Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-03T08:49:44Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-03T08:49:44Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-03T08:49:43Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://eefd813c32db04568f7f0b068f9f3d241f2b3d0b399b9d863995932801645bd0\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-09-03T08:49:43Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.0.0.9\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.22.1.53\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-09-03T08:49:43Z\"\n    }\n}\n"
STEP: replace the image in the pod
Sep  3 08:49:48.140: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 replace -f - --namespace=kubectl-5379'
Sep  3 08:49:48.268: INFO: stderr: ""
Sep  3 08:49:48.269: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1624
Sep  3 08:49:48.274: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 delete pods e2e-test-nginx-pod --namespace=kubectl-5379'
Sep  3 08:49:54.247: INFO: stderr: ""
Sep  3 08:49:54.247: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:49:54.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5379" for this suite.
Sep  3 08:50:00.274: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:50:00.443: INFO: namespace kubectl-5379 deletion completed in 6.190877577s

• [SLOW TEST:17.597 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:50:00.443: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep  3 08:50:00.533: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d04c6894-ce27-11e9-a824-e6b94fc13bb4" in namespace "downward-api-4166" to be "success or failure"
Sep  3 08:50:00.537: INFO: Pod "downwardapi-volume-d04c6894-ce27-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.391731ms
Sep  3 08:50:02.542: INFO: Pod "downwardapi-volume-d04c6894-ce27-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008587741s
STEP: Saw pod success
Sep  3 08:50:02.542: INFO: Pod "downwardapi-volume-d04c6894-ce27-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 08:50:02.546: INFO: Trying to get logs from node 10.0.0.6 pod downwardapi-volume-d04c6894-ce27-11e9-a824-e6b94fc13bb4 container client-container: <nil>
STEP: delete the pod
Sep  3 08:50:02.582: INFO: Waiting for pod downwardapi-volume-d04c6894-ce27-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 08:50:02.586: INFO: Pod downwardapi-volume-d04c6894-ce27-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:50:02.586: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4166" for this suite.
Sep  3 08:50:08.607: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:50:08.797: INFO: namespace downward-api-4166 deletion completed in 6.206359676s

• [SLOW TEST:8.354 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:50:08.797: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:177
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:50:08.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6396" for this suite.
Sep  3 08:50:30.928: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:50:31.085: INFO: namespace pods-6396 deletion completed in 22.189990757s

• [SLOW TEST:22.287 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:50:31.085: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep  3 08:50:31.175: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Sep  3 08:50:31.191: INFO: Number of nodes with available pods: 0
Sep  3 08:50:31.191: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Sep  3 08:50:31.216: INFO: Number of nodes with available pods: 0
Sep  3 08:50:31.216: INFO: Node 10.0.0.6 is running more than one daemon pod
Sep  3 08:50:32.221: INFO: Number of nodes with available pods: 1
Sep  3 08:50:32.221: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Sep  3 08:50:32.245: INFO: Number of nodes with available pods: 1
Sep  3 08:50:32.245: INFO: Number of running nodes: 0, number of available pods: 1
Sep  3 08:50:33.252: INFO: Number of nodes with available pods: 0
Sep  3 08:50:33.252: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Sep  3 08:50:33.266: INFO: Number of nodes with available pods: 0
Sep  3 08:50:33.266: INFO: Node 10.0.0.6 is running more than one daemon pod
Sep  3 08:50:34.271: INFO: Number of nodes with available pods: 0
Sep  3 08:50:34.271: INFO: Node 10.0.0.6 is running more than one daemon pod
Sep  3 08:50:35.275: INFO: Number of nodes with available pods: 0
Sep  3 08:50:35.275: INFO: Node 10.0.0.6 is running more than one daemon pod
Sep  3 08:50:36.271: INFO: Number of nodes with available pods: 0
Sep  3 08:50:36.271: INFO: Node 10.0.0.6 is running more than one daemon pod
Sep  3 08:50:37.271: INFO: Number of nodes with available pods: 0
Sep  3 08:50:37.271: INFO: Node 10.0.0.6 is running more than one daemon pod
Sep  3 08:50:38.274: INFO: Number of nodes with available pods: 0
Sep  3 08:50:38.274: INFO: Node 10.0.0.6 is running more than one daemon pod
Sep  3 08:50:39.271: INFO: Number of nodes with available pods: 0
Sep  3 08:50:39.271: INFO: Node 10.0.0.6 is running more than one daemon pod
Sep  3 08:50:40.271: INFO: Number of nodes with available pods: 0
Sep  3 08:50:40.271: INFO: Node 10.0.0.6 is running more than one daemon pod
Sep  3 08:50:41.271: INFO: Number of nodes with available pods: 0
Sep  3 08:50:41.271: INFO: Node 10.0.0.6 is running more than one daemon pod
Sep  3 08:50:42.271: INFO: Number of nodes with available pods: 0
Sep  3 08:50:42.271: INFO: Node 10.0.0.6 is running more than one daemon pod
Sep  3 08:50:43.271: INFO: Number of nodes with available pods: 0
Sep  3 08:50:43.271: INFO: Node 10.0.0.6 is running more than one daemon pod
Sep  3 08:50:44.271: INFO: Number of nodes with available pods: 0
Sep  3 08:50:44.271: INFO: Node 10.0.0.6 is running more than one daemon pod
Sep  3 08:50:45.271: INFO: Number of nodes with available pods: 0
Sep  3 08:50:45.271: INFO: Node 10.0.0.6 is running more than one daemon pod
Sep  3 08:50:46.271: INFO: Number of nodes with available pods: 0
Sep  3 08:50:46.271: INFO: Node 10.0.0.6 is running more than one daemon pod
Sep  3 08:50:47.270: INFO: Number of nodes with available pods: 0
Sep  3 08:50:47.271: INFO: Node 10.0.0.6 is running more than one daemon pod
Sep  3 08:50:48.270: INFO: Number of nodes with available pods: 1
Sep  3 08:50:48.270: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2377, will wait for the garbage collector to delete the pods
Sep  3 08:50:48.346: INFO: Deleting DaemonSet.extensions daemon-set took: 13.662652ms
Sep  3 08:50:48.746: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.18991ms
Sep  3 08:50:57.050: INFO: Number of nodes with available pods: 0
Sep  3 08:50:57.050: INFO: Number of running nodes: 0, number of available pods: 0
Sep  3 08:50:57.054: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2377/daemonsets","resourceVersion":"86830978"},"items":null}

Sep  3 08:50:57.058: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2377/pods","resourceVersion":"86830978"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:50:57.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2377" for this suite.
Sep  3 08:51:03.111: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:51:03.290: INFO: namespace daemonsets-2377 deletion completed in 6.196307238s

• [SLOW TEST:32.205 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:51:03.290: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating secret secrets-73/secret-test-f5bf296e-ce27-11e9-a824-e6b94fc13bb4
STEP: Creating a pod to test consume secrets
Sep  3 08:51:03.368: INFO: Waiting up to 5m0s for pod "pod-configmaps-f5c026ff-ce27-11e9-a824-e6b94fc13bb4" in namespace "secrets-73" to be "success or failure"
Sep  3 08:51:03.372: INFO: Pod "pod-configmaps-f5c026ff-ce27-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.671081ms
Sep  3 08:51:05.377: INFO: Pod "pod-configmaps-f5c026ff-ce27-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008970916s
STEP: Saw pod success
Sep  3 08:51:05.377: INFO: Pod "pod-configmaps-f5c026ff-ce27-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 08:51:05.380: INFO: Trying to get logs from node 10.0.0.6 pod pod-configmaps-f5c026ff-ce27-11e9-a824-e6b94fc13bb4 container env-test: <nil>
STEP: delete the pod
Sep  3 08:51:05.426: INFO: Waiting for pod pod-configmaps-f5c026ff-ce27-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 08:51:05.429: INFO: Pod pod-configmaps-f5c026ff-ce27-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:51:05.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-73" for this suite.
Sep  3 08:51:11.451: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:51:11.631: INFO: namespace secrets-73 deletion completed in 6.195341045s

• [SLOW TEST:8.341 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:51:11.631: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-3675
Sep  3 08:51:13.779: INFO: Started pod liveness-http in namespace container-probe-3675
STEP: checking the pod's current state and verifying that restartCount is present
Sep  3 08:51:13.782: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:55:14.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3675" for this suite.
Sep  3 08:55:20.575: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:55:20.796: INFO: namespace container-probe-3675 deletion completed in 6.255514183s

• [SLOW TEST:249.165 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:55:20.796: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep  3 08:55:20.849: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 version'
Sep  3 08:55:20.910: INFO: stderr: ""
Sep  3 08:55:20.910: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.3\", GitCommit:\"5e53fd6bc17c0dec8434817e69b04a25d8ae0ff0\", GitTreeState:\"clean\", BuildDate:\"2019-06-06T01:44:30Z\", GoVersion:\"go1.12.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"14+\", GitVersion:\"v1.14.3-tke.1\", GitCommit:\"89a8fa856ecafcf11458b8e142edfe2a28c0bba9\", GitTreeState:\"clean\", BuildDate:\"2019-07-31T03:35:48Z\", GoVersion:\"go1.12.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:55:20.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-803" for this suite.
Sep  3 08:55:26.934: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:55:27.088: INFO: namespace kubectl-803 deletion completed in 6.173231099s

• [SLOW TEST:6.292 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:55:27.088: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-4696
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep  3 08:55:27.149: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep  3 08:55:47.246: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.22.1.56:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-4696 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  3 08:55:47.246: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
Sep  3 08:55:47.344: INFO: Found all expected endpoints: [netserver-0]
Sep  3 08:55:47.348: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.22.0.77:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-4696 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  3 08:55:47.348: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
Sep  3 08:55:47.443: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:55:47.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-4696" for this suite.
Sep  3 08:56:11.464: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:56:11.744: INFO: namespace pod-network-test-4696 deletion completed in 24.295222744s

• [SLOW TEST:44.656 seconds]
[sig-network] Networking
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:56:11.744: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep  3 08:56:11.849: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"ad9e09dc-ce28-11e9-9b9a-9e20fc449913", Controller:(*bool)(0xc003005d12), BlockOwnerDeletion:(*bool)(0xc003005d13)}}
Sep  3 08:56:11.856: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"ad9b3693-ce28-11e9-9b9a-9e20fc449913", Controller:(*bool)(0xc0026f932a), BlockOwnerDeletion:(*bool)(0xc0026f932b)}}
Sep  3 08:56:11.866: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"ad9d1459-ce28-11e9-9b9a-9e20fc449913", Controller:(*bool)(0xc003005e9a), BlockOwnerDeletion:(*bool)(0xc003005e9b)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:56:16.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7765" for this suite.
Sep  3 08:56:22.992: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:56:23.215: INFO: namespace gc-7765 deletion completed in 6.324233432s

• [SLOW TEST:11.471 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:56:23.215: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep  3 08:56:23.339: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b47653f6-ce28-11e9-a824-e6b94fc13bb4" in namespace "downward-api-4388" to be "success or failure"
Sep  3 08:56:23.342: INFO: Pod "downwardapi-volume-b47653f6-ce28-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.44597ms
Sep  3 08:56:25.354: INFO: Pod "downwardapi-volume-b47653f6-ce28-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014810335s
STEP: Saw pod success
Sep  3 08:56:25.354: INFO: Pod "downwardapi-volume-b47653f6-ce28-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 08:56:25.363: INFO: Trying to get logs from node 10.0.0.9 pod downwardapi-volume-b47653f6-ce28-11e9-a824-e6b94fc13bb4 container client-container: <nil>
STEP: delete the pod
Sep  3 08:56:25.391: INFO: Waiting for pod downwardapi-volume-b47653f6-ce28-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 08:56:25.394: INFO: Pod downwardapi-volume-b47653f6-ce28-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:56:25.394: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4388" for this suite.
Sep  3 08:56:31.416: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:56:31.604: INFO: namespace downward-api-4388 deletion completed in 6.204953365s

• [SLOW TEST:8.388 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:56:31.604: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap configmap-181/configmap-test-b96f49de-ce28-11e9-a824-e6b94fc13bb4
STEP: Creating a pod to test consume configMaps
Sep  3 08:56:31.680: INFO: Waiting up to 5m0s for pod "pod-configmaps-b970bdc6-ce28-11e9-a824-e6b94fc13bb4" in namespace "configmap-181" to be "success or failure"
Sep  3 08:56:31.683: INFO: Pod "pod-configmaps-b970bdc6-ce28-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.458005ms
Sep  3 08:56:33.689: INFO: Pod "pod-configmaps-b970bdc6-ce28-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008976991s
STEP: Saw pod success
Sep  3 08:56:33.689: INFO: Pod "pod-configmaps-b970bdc6-ce28-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 08:56:33.695: INFO: Trying to get logs from node 10.0.0.6 pod pod-configmaps-b970bdc6-ce28-11e9-a824-e6b94fc13bb4 container env-test: <nil>
STEP: delete the pod
Sep  3 08:56:33.783: INFO: Waiting for pod pod-configmaps-b970bdc6-ce28-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 08:56:33.786: INFO: Pod pod-configmaps-b970bdc6-ce28-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:56:33.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-181" for this suite.
Sep  3 08:56:39.823: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:56:39.984: INFO: namespace configmap-181 deletion completed in 6.193991656s

• [SLOW TEST:8.381 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:56:39.985: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Sep  3 08:56:44.101: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  3 08:56:44.105: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  3 08:56:46.105: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  3 08:56:46.109: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  3 08:56:48.105: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  3 08:56:48.111: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  3 08:56:50.105: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  3 08:56:50.112: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  3 08:56:52.105: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  3 08:56:52.109: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  3 08:56:54.105: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  3 08:56:54.109: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  3 08:56:56.105: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  3 08:56:56.109: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  3 08:56:58.105: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  3 08:56:58.112: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  3 08:57:00.105: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  3 08:57:00.110: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  3 08:57:02.105: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  3 08:57:02.109: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  3 08:57:04.105: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  3 08:57:04.109: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  3 08:57:06.105: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  3 08:57:06.117: INFO: Pod pod-with-prestop-exec-hook still exists
Sep  3 08:57:08.105: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep  3 08:57:08.112: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:57:08.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-7991" for this suite.
Sep  3 08:57:32.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:57:32.291: INFO: namespace container-lifecycle-hook-7991 deletion completed in 24.161460494s

• [SLOW TEST:52.307 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when create a pod with lifecycle hook
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:57:32.292: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-dd9ae340-ce28-11e9-a824-e6b94fc13bb4
STEP: Creating a pod to test consume secrets
Sep  3 08:57:32.432: INFO: Waiting up to 5m0s for pod "pod-secrets-dda640cf-ce28-11e9-a824-e6b94fc13bb4" in namespace "secrets-1779" to be "success or failure"
Sep  3 08:57:32.436: INFO: Pod "pod-secrets-dda640cf-ce28-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.760019ms
Sep  3 08:57:34.441: INFO: Pod "pod-secrets-dda640cf-ce28-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009032406s
STEP: Saw pod success
Sep  3 08:57:34.441: INFO: Pod "pod-secrets-dda640cf-ce28-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 08:57:34.444: INFO: Trying to get logs from node 10.0.0.9 pod pod-secrets-dda640cf-ce28-11e9-a824-e6b94fc13bb4 container secret-volume-test: <nil>
STEP: delete the pod
Sep  3 08:57:34.492: INFO: Waiting for pod pod-secrets-dda640cf-ce28-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 08:57:34.496: INFO: Pod pod-secrets-dda640cf-ce28-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:57:34.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1779" for this suite.
Sep  3 08:57:40.517: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:57:40.697: INFO: namespace secrets-1779 deletion completed in 6.197109925s
STEP: Destroying namespace "secret-namespace-2217" for this suite.
Sep  3 08:57:46.714: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:57:46.880: INFO: namespace secret-namespace-2217 deletion completed in 6.182381885s

• [SLOW TEST:14.588 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:57:46.880: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating pod
Sep  3 08:57:48.992: INFO: Pod pod-hostip-e64fae6f-ce28-11e9-a824-e6b94fc13bb4 has hostIP: 10.0.0.6
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:57:48.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5745" for this suite.
Sep  3 08:58:13.086: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:58:13.252: INFO: namespace pods-5745 deletion completed in 24.182674518s

• [SLOW TEST:26.372 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:58:13.253: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0903 08:58:14.386395      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep  3 08:58:14.386: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:58:14.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5520" for this suite.
Sep  3 08:58:20.484: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:58:20.702: INFO: namespace gc-5520 deletion completed in 6.234745751s

• [SLOW TEST:7.449 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:58:20.702: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-3507
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-3507
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-3507
Sep  3 08:58:20.774: INFO: Found 0 stateful pods, waiting for 1
Sep  3 08:58:30.778: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Sep  3 08:58:30.782: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-3507 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  3 08:58:30.959: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep  3 08:58:30.959: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  3 08:58:30.959: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  3 08:58:30.963: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Sep  3 08:58:41.004: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep  3 08:58:41.004: INFO: Waiting for statefulset status.replicas updated to 0
Sep  3 08:58:41.032: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999998971s
Sep  3 08:58:42.037: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.996285296s
Sep  3 08:58:43.042: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.991353309s
Sep  3 08:58:44.046: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.987134418s
Sep  3 08:58:45.050: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.982590679s
Sep  3 08:58:46.055: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.97836329s
Sep  3 08:58:47.059: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.97361664s
Sep  3 08:58:48.065: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.969404047s
Sep  3 08:58:49.070: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.963542408s
Sep  3 08:58:50.077: INFO: Verifying statefulset ss doesn't scale past 1 for another 959.013434ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-3507
Sep  3 08:58:51.082: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-3507 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  3 08:58:51.241: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep  3 08:58:51.241: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  3 08:58:51.241: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  3 08:58:51.248: INFO: Found 1 stateful pods, waiting for 3
Sep  3 08:59:01.254: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Sep  3 08:59:01.254: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Sep  3 08:59:01.254: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Sep  3 08:59:01.259: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-3507 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  3 08:59:01.421: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep  3 08:59:01.421: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  3 08:59:01.421: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  3 08:59:01.421: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-3507 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  3 08:59:01.606: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep  3 08:59:01.606: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  3 08:59:01.606: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  3 08:59:01.606: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-3507 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  3 08:59:01.768: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep  3 08:59:01.768: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  3 08:59:01.768: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  3 08:59:01.768: INFO: Waiting for statefulset status.replicas updated to 0
Sep  3 08:59:01.775: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Sep  3 08:59:11.784: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep  3 08:59:11.784: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Sep  3 08:59:11.784: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Sep  3 08:59:11.800: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999998897s
Sep  3 08:59:12.804: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996069749s
Sep  3 08:59:13.809: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.991654383s
Sep  3 08:59:14.814: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.987066877s
Sep  3 08:59:15.818: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.98174847s
Sep  3 08:59:16.823: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.977251301s
Sep  3 08:59:17.837: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.972274008s
Sep  3 08:59:18.841: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.958688315s
Sep  3 08:59:19.848: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.954351003s
Sep  3 08:59:20.853: INFO: Verifying statefulset ss doesn't scale past 3 for another 947.411053ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-3507
Sep  3 08:59:21.858: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-3507 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  3 08:59:22.016: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep  3 08:59:22.016: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  3 08:59:22.016: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  3 08:59:22.016: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-3507 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  3 08:59:22.186: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep  3 08:59:22.186: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  3 08:59:22.186: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  3 08:59:22.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-3507 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  3 08:59:22.356: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep  3 08:59:22.356: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  3 08:59:22.356: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  3 08:59:22.356: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Sep  3 08:59:42.378: INFO: Deleting all statefulset in ns statefulset-3507
Sep  3 08:59:42.383: INFO: Scaling statefulset ss to 0
Sep  3 08:59:42.396: INFO: Waiting for statefulset status.replicas updated to 0
Sep  3 08:59:42.401: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:59:42.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3507" for this suite.
Sep  3 08:59:48.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:59:48.617: INFO: namespace statefulset-3507 deletion completed in 6.187334693s

• [SLOW TEST:87.915 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:59:48.617: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Sep  3 08:59:48.684: INFO: Waiting up to 5m0s for pod "downward-api-2edd1c4f-ce29-11e9-a824-e6b94fc13bb4" in namespace "downward-api-7405" to be "success or failure"
Sep  3 08:59:48.687: INFO: Pod "downward-api-2edd1c4f-ce29-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.414608ms
Sep  3 08:59:50.692: INFO: Pod "downward-api-2edd1c4f-ce29-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007890601s
STEP: Saw pod success
Sep  3 08:59:50.692: INFO: Pod "downward-api-2edd1c4f-ce29-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 08:59:50.698: INFO: Trying to get logs from node 10.0.0.9 pod downward-api-2edd1c4f-ce29-11e9-a824-e6b94fc13bb4 container dapi-container: <nil>
STEP: delete the pod
Sep  3 08:59:50.792: INFO: Waiting for pod downward-api-2edd1c4f-ce29-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 08:59:50.815: INFO: Pod downward-api-2edd1c4f-ce29-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 08:59:50.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7405" for this suite.
Sep  3 08:59:56.838: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 08:59:56.997: INFO: namespace downward-api-7405 deletion completed in 6.177909515s

• [SLOW TEST:8.381 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 08:59:56.998: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1455
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep  3 08:59:57.062: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=kubectl-3339'
Sep  3 08:59:57.211: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep  3 08:59:57.212: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1460
Sep  3 09:00:01.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 delete deployment e2e-test-nginx-deployment --namespace=kubectl-3339'
Sep  3 09:00:01.324: INFO: stderr: ""
Sep  3 09:00:01.324: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:00:01.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3339" for this suite.
Sep  3 09:00:25.355: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:00:25.517: INFO: namespace kubectl-3339 deletion completed in 24.187538416s

• [SLOW TEST:28.520 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:00:25.518: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Sep  3 09:00:28.616: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:00:29.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-3676" for this suite.
Sep  3 09:00:53.672: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:00:53.829: INFO: namespace replicaset-3676 deletion completed in 24.180432742s

• [SLOW TEST:28.312 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:00:53.829: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-6508
Sep  3 09:00:57.924: INFO: Started pod liveness-http in namespace container-probe-6508
STEP: checking the pod's current state and verifying that restartCount is present
Sep  3 09:00:57.928: INFO: Initial restart count of pod liveness-http is 0
Sep  3 09:01:15.975: INFO: Restart count of pod container-probe-6508/liveness-http is now 1 (18.04678366s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:01:15.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6508" for this suite.
Sep  3 09:01:22.013: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:01:22.185: INFO: namespace container-probe-6508 deletion completed in 6.188811279s

• [SLOW TEST:28.356 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:01:22.185: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-66a4281d-ce29-11e9-a824-e6b94fc13bb4
STEP: Creating a pod to test consume secrets
Sep  3 09:01:22.274: INFO: Waiting up to 5m0s for pod "pod-secrets-66a54003-ce29-11e9-a824-e6b94fc13bb4" in namespace "secrets-1975" to be "success or failure"
Sep  3 09:01:22.277: INFO: Pod "pod-secrets-66a54003-ce29-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.565619ms
Sep  3 09:01:24.282: INFO: Pod "pod-secrets-66a54003-ce29-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008193529s
STEP: Saw pod success
Sep  3 09:01:24.282: INFO: Pod "pod-secrets-66a54003-ce29-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 09:01:24.292: INFO: Trying to get logs from node 10.0.0.9 pod pod-secrets-66a54003-ce29-11e9-a824-e6b94fc13bb4 container secret-volume-test: <nil>
STEP: delete the pod
Sep  3 09:01:24.317: INFO: Waiting for pod pod-secrets-66a54003-ce29-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 09:01:24.320: INFO: Pod pod-secrets-66a54003-ce29-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:01:24.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1975" for this suite.
Sep  3 09:01:30.345: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:01:30.509: INFO: namespace secrets-1975 deletion completed in 6.182537602s

• [SLOW TEST:8.324 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:01:30.509: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep  3 09:01:30.568: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:01:32.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9236" for this suite.
Sep  3 09:02:12.723: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:02:12.904: INFO: namespace pods-9236 deletion completed in 40.203980912s

• [SLOW TEST:42.395 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:02:12.904: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-84dd0752-ce29-11e9-a824-e6b94fc13bb4
STEP: Creating a pod to test consume secrets
Sep  3 09:02:12.975: INFO: Waiting up to 5m0s for pod "pod-secrets-84de7ab5-ce29-11e9-a824-e6b94fc13bb4" in namespace "secrets-6430" to be "success or failure"
Sep  3 09:02:12.980: INFO: Pod "pod-secrets-84de7ab5-ce29-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.719361ms
Sep  3 09:02:14.985: INFO: Pod "pod-secrets-84de7ab5-ce29-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009287347s
STEP: Saw pod success
Sep  3 09:02:14.985: INFO: Pod "pod-secrets-84de7ab5-ce29-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 09:02:14.990: INFO: Trying to get logs from node 10.0.0.6 pod pod-secrets-84de7ab5-ce29-11e9-a824-e6b94fc13bb4 container secret-volume-test: <nil>
STEP: delete the pod
Sep  3 09:02:15.090: INFO: Waiting for pod pod-secrets-84de7ab5-ce29-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 09:02:15.094: INFO: Pod pod-secrets-84de7ab5-ce29-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:02:15.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6430" for this suite.
Sep  3 09:02:21.117: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:02:21.277: INFO: namespace secrets-6430 deletion completed in 6.179152307s

• [SLOW TEST:8.373 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:02:21.278: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-89dbe1e0-ce29-11e9-a824-e6b94fc13bb4
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-89dbe1e0-ce29-11e9-a824-e6b94fc13bb4
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:02:25.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5256" for this suite.
Sep  3 09:02:47.424: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:02:47.588: INFO: namespace configmap-5256 deletion completed in 22.179206033s

• [SLOW TEST:26.310 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:02:47.588: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Sep  3 09:02:47.806: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-680,SelfLink:/api/v1/namespaces/watch-680/configmaps/e2e-watch-test-resource-version,UID:999c146e-ce29-11e9-9b9a-9e20fc449913,ResourceVersion:86878686,Generation:0,CreationTimestamp:2019-09-03 09:02:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep  3 09:02:47.806: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-680,SelfLink:/api/v1/namespaces/watch-680/configmaps/e2e-watch-test-resource-version,UID:999c146e-ce29-11e9-9b9a-9e20fc449913,ResourceVersion:86878687,Generation:0,CreationTimestamp:2019-09-03 09:02:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:02:47.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-680" for this suite.
Sep  3 09:02:53.831: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:02:53.999: INFO: namespace watch-680 deletion completed in 6.186271803s

• [SLOW TEST:6.411 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:02:53.999: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Sep  3 09:02:58.097: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-9d5dd176-ce29-11e9-a824-e6b94fc13bb4,GenerateName:,Namespace:events-5907,SelfLink:/api/v1/namespaces/events-5907/pods/send-events-9d5dd176-ce29-11e9-a824-e6b94fc13bb4,UID:9d5e76d8-ce29-11e9-9b9a-9e20fc449913,ResourceVersion:86879314,Generation:0,CreationTimestamp:2019-09-03 09:02:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 66322466,},Annotations:map[string]string{tke.cloud.tencent.com/networks-status: [{
    "name": "tke-bridge",
    "ips": [
        "172.22.1.65"
    ],
    "default": true,
    "dns": {}
}],},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-6qjr2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-6qjr2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-6qjr2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:02:54 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:02:56 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:02:56 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:02:54 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.9,PodIP:172.22.1.65,StartTime:2019-09-03 09:02:54 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-09-03 09:02:56 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://5edffb4efce1c6dcdca8027016a6a4f1fef04e410b467c05d94bafe0eee6af63}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Sep  3 09:03:00.163: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Sep  3 09:03:02.170: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:03:02.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-5907" for this suite.
Sep  3 09:03:42.236: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:03:42.394: INFO: namespace events-5907 deletion completed in 40.179092428s

• [SLOW TEST:48.395 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:03:42.394: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's args
Sep  3 09:03:42.456: INFO: Waiting up to 5m0s for pod "var-expansion-ba33ff31-ce29-11e9-a824-e6b94fc13bb4" in namespace "var-expansion-3554" to be "success or failure"
Sep  3 09:03:42.459: INFO: Pod "var-expansion-ba33ff31-ce29-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.477929ms
Sep  3 09:03:44.463: INFO: Pod "var-expansion-ba33ff31-ce29-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007871843s
STEP: Saw pod success
Sep  3 09:03:44.463: INFO: Pod "var-expansion-ba33ff31-ce29-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 09:03:44.467: INFO: Trying to get logs from node 10.0.0.6 pod var-expansion-ba33ff31-ce29-11e9-a824-e6b94fc13bb4 container dapi-container: <nil>
STEP: delete the pod
Sep  3 09:03:44.505: INFO: Waiting for pod var-expansion-ba33ff31-ce29-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 09:03:44.508: INFO: Pod var-expansion-ba33ff31-ce29-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:03:44.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3554" for this suite.
Sep  3 09:03:50.533: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:03:50.687: INFO: namespace var-expansion-3554 deletion completed in 6.174066314s

• [SLOW TEST:8.293 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:03:50.687: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Sep  3 09:03:50.754: INFO: Waiting up to 5m0s for pod "pod-bf264f05-ce29-11e9-a824-e6b94fc13bb4" in namespace "emptydir-3003" to be "success or failure"
Sep  3 09:03:50.758: INFO: Pod "pod-bf264f05-ce29-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.272305ms
Sep  3 09:03:52.763: INFO: Pod "pod-bf264f05-ce29-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008867074s
Sep  3 09:03:54.767: INFO: Pod "pod-bf264f05-ce29-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013440058s
STEP: Saw pod success
Sep  3 09:03:54.767: INFO: Pod "pod-bf264f05-ce29-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 09:03:54.771: INFO: Trying to get logs from node 10.0.0.9 pod pod-bf264f05-ce29-11e9-a824-e6b94fc13bb4 container test-container: <nil>
STEP: delete the pod
Sep  3 09:03:54.805: INFO: Waiting for pod pod-bf264f05-ce29-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 09:03:54.809: INFO: Pod pod-bf264f05-ce29-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:03:54.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3003" for this suite.
Sep  3 09:04:00.833: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:04:00.990: INFO: namespace emptydir-3003 deletion completed in 6.175955742s

• [SLOW TEST:10.303 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:04:00.990: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Sep  3 09:04:01.053: INFO: Waiting up to 5m0s for pod "pod-c549695d-ce29-11e9-a824-e6b94fc13bb4" in namespace "emptydir-7567" to be "success or failure"
Sep  3 09:04:01.060: INFO: Pod "pod-c549695d-ce29-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.908817ms
Sep  3 09:04:03.065: INFO: Pod "pod-c549695d-ce29-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011850018s
Sep  3 09:04:05.070: INFO: Pod "pod-c549695d-ce29-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016438217s
STEP: Saw pod success
Sep  3 09:04:05.070: INFO: Pod "pod-c549695d-ce29-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 09:04:05.073: INFO: Trying to get logs from node 10.0.0.6 pod pod-c549695d-ce29-11e9-a824-e6b94fc13bb4 container test-container: <nil>
STEP: delete the pod
Sep  3 09:04:05.177: INFO: Waiting for pod pod-c549695d-ce29-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 09:04:05.181: INFO: Pod pod-c549695d-ce29-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:04:05.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7567" for this suite.
Sep  3 09:04:11.202: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:04:11.415: INFO: namespace emptydir-7567 deletion completed in 6.228518553s

• [SLOW TEST:10.425 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:04:11.415: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep  3 09:04:11.472: INFO: Creating deployment "nginx-deployment"
Sep  3 09:04:11.478: INFO: Waiting for observed generation 1
Sep  3 09:04:13.486: INFO: Waiting for all required pods to come up
Sep  3 09:04:13.564: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Sep  3 09:04:17.575: INFO: Waiting for deployment "nginx-deployment" to complete
Sep  3 09:04:17.582: INFO: Updating deployment "nginx-deployment" with a non-existent image
Sep  3 09:04:17.591: INFO: Updating deployment nginx-deployment
Sep  3 09:04:17.591: INFO: Waiting for observed generation 2
Sep  3 09:04:19.599: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Sep  3 09:04:19.603: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Sep  3 09:04:19.606: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Sep  3 09:04:19.621: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Sep  3 09:04:19.621: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Sep  3 09:04:19.624: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Sep  3 09:04:19.673: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Sep  3 09:04:19.673: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Sep  3 09:04:19.682: INFO: Updating deployment nginx-deployment
Sep  3 09:04:19.682: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Sep  3 09:04:19.691: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Sep  3 09:04:19.700: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Sep  3 09:04:19.714: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-8259,SelfLink:/apis/apps/v1/namespaces/deployment-8259/deployments/nginx-deployment,UID:cb8131b3-ce29-11e9-9b9a-9e20fc449913,ResourceVersion:86885067,Generation:3,CreationTimestamp:2019-09-03 09:04:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[{Available True 2019-09-03 09:04:15 +0000 UTC 2019-09-03 09:04:15 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-09-03 09:04:17 +0000 UTC 2019-09-03 09:04:11 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-5f9595f595" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Sep  3 09:04:19.725: INFO: New ReplicaSet "nginx-deployment-5f9595f595" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595,GenerateName:,Namespace:deployment-8259,SelfLink:/apis/apps/v1/namespaces/deployment-8259/replicasets/nginx-deployment-5f9595f595,UID:cf272012-ce29-11e9-9b9a-9e20fc449913,ResourceVersion:86885071,Generation:3,CreationTimestamp:2019-09-03 09:04:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment cb8131b3-ce29-11e9-9b9a-9e20fc449913 0xc003119137 0xc003119138}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep  3 09:04:19.725: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Sep  3 09:04:19.725: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8,GenerateName:,Namespace:deployment-8259,SelfLink:/apis/apps/v1/namespaces/deployment-8259/replicasets/nginx-deployment-6f478d8d8,UID:cb824eda-ce29-11e9-9b9a-9e20fc449913,ResourceVersion:86885068,Generation:3,CreationTimestamp:2019-09-03 09:04:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment cb8131b3-ce29-11e9-9b9a-9e20fc449913 0xc003119207 0xc003119208}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Sep  3 09:04:19.732: INFO: Pod "nginx-deployment-5f9595f595-2l2gp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-2l2gp,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8259,SelfLink:/api/v1/namespaces/deployment-8259/pods/nginx-deployment-5f9595f595-2l2gp,UID:d0695639-ce29-11e9-9b9a-9e20fc449913,ResourceVersion:86885082,Generation:0,CreationTimestamp:2019-09-03 09:04:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 cf272012-ce29-11e9-9b9a-9e20fc449913 0xc003119b37 0xc003119b38}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-2xccm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2xccm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-2xccm true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:04:19 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  3 09:04:19.732: INFO: Pod "nginx-deployment-5f9595f595-8f2q4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-8f2q4,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8259,SelfLink:/api/v1/namespaces/deployment-8259/pods/nginx-deployment-5f9595f595-8f2q4,UID:cf2c10bd-ce29-11e9-9b9a-9e20fc449913,ResourceVersion:86884954,Generation:0,CreationTimestamp:2019-09-03 09:04:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{tke.cloud.tencent.com/networks-status: [{
    "name": "tke-bridge",
    "ips": [
        "172.22.0.98"
    ],
    "default": true,
    "dns": {}
}],},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 cf272012-ce29-11e9-9b9a-9e20fc449913 0xc003119c37 0xc003119c38}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-2xccm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2xccm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-2xccm true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.6,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:04:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:04:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:04:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:04:17 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.6,PodIP:,StartTime:2019-09-03 09:04:17 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  3 09:04:19.733: INFO: Pod "nginx-deployment-5f9595f595-kt2jw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-kt2jw,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8259,SelfLink:/api/v1/namespaces/deployment-8259/pods/nginx-deployment-5f9595f595-kt2jw,UID:cf2c0c44-ce29-11e9-9b9a-9e20fc449913,ResourceVersion:86884979,Generation:0,CreationTimestamp:2019-09-03 09:04:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{tke.cloud.tencent.com/networks-status: [{
    "name": "tke-bridge",
    "ips": [
        "172.22.1.72"
    ],
    "default": true,
    "dns": {}
}],},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 cf272012-ce29-11e9-9b9a-9e20fc449913 0xc003119db7 0xc003119db8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-2xccm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2xccm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-2xccm true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:04:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:04:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:04:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:04:17 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.9,PodIP:,StartTime:2019-09-03 09:04:17 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  3 09:04:19.733: INFO: Pod "nginx-deployment-5f9595f595-l42fs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-l42fs,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8259,SelfLink:/api/v1/namespaces/deployment-8259/pods/nginx-deployment-5f9595f595-l42fs,UID:cf383a23-ce29-11e9-9b9a-9e20fc449913,ResourceVersion:86884987,Generation:0,CreationTimestamp:2019-09-03 09:04:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{tke.cloud.tencent.com/networks-status: [{
    "name": "tke-bridge",
    "ips": [
        "172.22.1.73"
    ],
    "default": true,
    "dns": {}
}],},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 cf272012-ce29-11e9-9b9a-9e20fc449913 0xc003119ed7 0xc003119ed8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-2xccm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2xccm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-2xccm true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:04:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:04:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:04:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:04:17 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.9,PodIP:,StartTime:2019-09-03 09:04:17 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  3 09:04:19.733: INFO: Pod "nginx-deployment-5f9595f595-xm6mc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-xm6mc,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8259,SelfLink:/api/v1/namespaces/deployment-8259/pods/nginx-deployment-5f9595f595-xm6mc,UID:cf283a1c-ce29-11e9-9b9a-9e20fc449913,ResourceVersion:86884982,Generation:0,CreationTimestamp:2019-09-03 09:04:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{tke.cloud.tencent.com/networks-status: [{
    "name": "tke-bridge",
    "ips": [
        "172.22.0.99"
    ],
    "default": true,
    "dns": {}
}],},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 cf272012-ce29-11e9-9b9a-9e20fc449913 0xc003119ff7 0xc003119ff8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-2xccm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2xccm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-2xccm true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.6,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:04:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:04:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:04:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:04:17 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.6,PodIP:,StartTime:2019-09-03 09:04:17 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  3 09:04:19.733: INFO: Pod "nginx-deployment-5f9595f595-z7njc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-5f9595f595-z7njc,GenerateName:nginx-deployment-5f9595f595-,Namespace:deployment-8259,SelfLink:/api/v1/namespaces/deployment-8259/pods/nginx-deployment-5f9595f595-z7njc,UID:cf34284e-ce29-11e9-9b9a-9e20fc449913,ResourceVersion:86885003,Generation:0,CreationTimestamp:2019-09-03 09:04:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 5f9595f595,},Annotations:map[string]string{tke.cloud.tencent.com/networks-status: [{
    "name": "tke-bridge",
    "ips": [
        "172.22.0.100"
    ],
    "default": true,
    "dns": {}
}],},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-5f9595f595 cf272012-ce29-11e9-9b9a-9e20fc449913 0xc003128327 0xc003128328}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-2xccm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2xccm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-2xccm true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.6,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:04:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:04:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:04:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:04:17 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.6,PodIP:,StartTime:2019-09-03 09:04:17 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  3 09:04:19.733: INFO: Pod "nginx-deployment-6f478d8d8-26cjb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-26cjb,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8259,SelfLink:/api/v1/namespaces/deployment-8259/pods/nginx-deployment-6f478d8d8-26cjb,UID:d067729b-ce29-11e9-9b9a-9e20fc449913,ResourceVersion:86885084,Generation:0,CreationTimestamp:2019-09-03 09:04:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 cb824eda-ce29-11e9-9b9a-9e20fc449913 0xc003128517 0xc003128518}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-2xccm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2xccm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-2xccm true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.6,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:04:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:04:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:04:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:04:19 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.6,PodIP:,StartTime:2019-09-03 09:04:19 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  3 09:04:19.733: INFO: Pod "nginx-deployment-6f478d8d8-6vhdx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-6vhdx,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8259,SelfLink:/api/v1/namespaces/deployment-8259/pods/nginx-deployment-6f478d8d8-6vhdx,UID:d068dfcb-ce29-11e9-9b9a-9e20fc449913,ResourceVersion:86885079,Generation:0,CreationTimestamp:2019-09-03 09:04:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 cb824eda-ce29-11e9-9b9a-9e20fc449913 0xc003128757 0xc003128758}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-2xccm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2xccm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-2xccm true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:04:19 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  3 09:04:19.733: INFO: Pod "nginx-deployment-6f478d8d8-72tzp" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-72tzp,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8259,SelfLink:/api/v1/namespaces/deployment-8259/pods/nginx-deployment-6f478d8d8-72tzp,UID:cb8a1dc7-ce29-11e9-9b9a-9e20fc449913,ResourceVersion:86884640,Generation:0,CreationTimestamp:2019-09-03 09:04:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{tke.cloud.tencent.com/networks-status: [{
    "name": "tke-bridge",
    "ips": [
        "172.22.0.94"
    ],
    "default": true,
    "dns": {}
}],},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 cb824eda-ce29-11e9-9b9a-9e20fc449913 0xc0031293c7 0xc0031293c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-2xccm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2xccm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-2xccm true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.6,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:04:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:04:12 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:04:12 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:04:11 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.6,PodIP:172.22.0.94,StartTime:2019-09-03 09:04:11 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-03 09:04:12 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://0d10f6871e2339b3d8721cdbb3f8996e3ca9e76f5de3f3f5ad5d2cd30218f29f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  3 09:04:19.733: INFO: Pod "nginx-deployment-6f478d8d8-cz7dm" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-cz7dm,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8259,SelfLink:/api/v1/namespaces/deployment-8259/pods/nginx-deployment-6f478d8d8-cz7dm,UID:cb8a2b9a-ce29-11e9-9b9a-9e20fc449913,ResourceVersion:86884779,Generation:0,CreationTimestamp:2019-09-03 09:04:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{tke.cloud.tencent.com/networks-status: [{
    "name": "tke-bridge",
    "ips": [
        "172.22.0.97"
    ],
    "default": true,
    "dns": {}
}],},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 cb824eda-ce29-11e9-9b9a-9e20fc449913 0xc003129997 0xc003129998}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-2xccm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2xccm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-2xccm true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.6,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:04:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:04:13 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:04:13 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:04:11 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.6,PodIP:172.22.0.97,StartTime:2019-09-03 09:04:11 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-03 09:04:13 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://eaaf3b22c718d9a18c7bf2c04c2218a557c513f0cffd709a947681ca42126f3d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  3 09:04:19.733: INFO: Pod "nginx-deployment-6f478d8d8-jdjm7" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-jdjm7,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8259,SelfLink:/api/v1/namespaces/deployment-8259/pods/nginx-deployment-6f478d8d8-jdjm7,UID:cb8c7342-ce29-11e9-9b9a-9e20fc449913,ResourceVersion:86884599,Generation:0,CreationTimestamp:2019-09-03 09:04:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{tke.cloud.tencent.com/networks-status: [{
    "name": "tke-bridge",
    "ips": [
        "172.22.1.68"
    ],
    "default": true,
    "dns": {}
}],},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 cb824eda-ce29-11e9-9b9a-9e20fc449913 0xc003129ff7 0xc003129ff8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-2xccm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2xccm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-2xccm true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:04:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:04:12 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:04:12 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:04:11 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.9,PodIP:172.22.1.68,StartTime:2019-09-03 09:04:11 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-03 09:04:12 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://db27b94e92fa1ba35a65d31b712db538e9c55ea7be7850a86e7f2086615c3ab6}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  3 09:04:19.733: INFO: Pod "nginx-deployment-6f478d8d8-lm9r4" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-lm9r4,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8259,SelfLink:/api/v1/namespaces/deployment-8259/pods/nginx-deployment-6f478d8d8-lm9r4,UID:cb8a2971-ce29-11e9-9b9a-9e20fc449913,ResourceVersion:86884654,Generation:0,CreationTimestamp:2019-09-03 09:04:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{tke.cloud.tencent.com/networks-status: [{
    "name": "tke-bridge",
    "ips": [
        "172.22.1.67"
    ],
    "default": true,
    "dns": {}
}],},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 cb824eda-ce29-11e9-9b9a-9e20fc449913 0xc00076e1f7 0xc00076e1f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-2xccm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2xccm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-2xccm true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:04:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:04:12 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:04:12 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:04:11 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.9,PodIP:172.22.1.67,StartTime:2019-09-03 09:04:11 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-03 09:04:12 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://60b6d1bcf91b5e452d3ef25134ea2fed83b8ae2c132acebf153bc420683a6ed4}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  3 09:04:19.733: INFO: Pod "nginx-deployment-6f478d8d8-lmcnp" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-lmcnp,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8259,SelfLink:/api/v1/namespaces/deployment-8259/pods/nginx-deployment-6f478d8d8-lmcnp,UID:cb8c7062-ce29-11e9-9b9a-9e20fc449913,ResourceVersion:86884583,Generation:0,CreationTimestamp:2019-09-03 09:04:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{tke.cloud.tencent.com/networks-status: [{
    "name": "tke-bridge",
    "ips": [
        "172.22.0.95"
    ],
    "default": true,
    "dns": {}
}],},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 cb824eda-ce29-11e9-9b9a-9e20fc449913 0xc00076e3c7 0xc00076e3c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-2xccm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2xccm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-2xccm true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.6,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:04:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:04:12 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:04:12 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:04:11 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.6,PodIP:172.22.0.95,StartTime:2019-09-03 09:04:11 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-03 09:04:12 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://9e89d0e0ce0c846578d9f85ef5ca30a1b3bc83b8f616b51e34aa3d79553bd7da}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  3 09:04:19.734: INFO: Pod "nginx-deployment-6f478d8d8-lxr5m" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-lxr5m,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8259,SelfLink:/api/v1/namespaces/deployment-8259/pods/nginx-deployment-6f478d8d8-lxr5m,UID:d068e40d-ce29-11e9-9b9a-9e20fc449913,ResourceVersion:86885081,Generation:0,CreationTimestamp:2019-09-03 09:04:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 cb824eda-ce29-11e9-9b9a-9e20fc449913 0xc00076e5a7 0xc00076e5a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-2xccm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2xccm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-2xccm true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.6,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:04:19 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  3 09:04:19.734: INFO: Pod "nginx-deployment-6f478d8d8-mxrbk" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-mxrbk,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8259,SelfLink:/api/v1/namespaces/deployment-8259/pods/nginx-deployment-6f478d8d8-mxrbk,UID:cb8c6f3d-ce29-11e9-9b9a-9e20fc449913,ResourceVersion:86884510,Generation:0,CreationTimestamp:2019-09-03 09:04:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{tke.cloud.tencent.com/networks-status: [{
    "name": "tke-bridge",
    "ips": [
        "172.22.0.93"
    ],
    "default": true,
    "dns": {}
}],},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 cb824eda-ce29-11e9-9b9a-9e20fc449913 0xc00076e677 0xc00076e678}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-2xccm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2xccm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-2xccm true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.6,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:04:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:04:12 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:04:12 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:04:11 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.6,PodIP:172.22.0.93,StartTime:2019-09-03 09:04:11 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-03 09:04:12 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://e9cc66331c46d952b2fb3cb5765b338addc452c45516fa5ef612c99756555cf7}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  3 09:04:19.734: INFO: Pod "nginx-deployment-6f478d8d8-qvsmb" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-qvsmb,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8259,SelfLink:/api/v1/namespaces/deployment-8259/pods/nginx-deployment-6f478d8d8-qvsmb,UID:cb8a292c-ce29-11e9-9b9a-9e20fc449913,ResourceVersion:86884800,Generation:0,CreationTimestamp:2019-09-03 09:04:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{tke.cloud.tencent.com/networks-status: [{
    "name": "tke-bridge",
    "ips": [
        "172.22.1.70"
    ],
    "default": true,
    "dns": {}
}],},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 cb824eda-ce29-11e9-9b9a-9e20fc449913 0xc00076e9b7 0xc00076e9b8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-2xccm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2xccm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-2xccm true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:04:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:04:13 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:04:13 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:04:11 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.9,PodIP:172.22.1.70,StartTime:2019-09-03 09:04:11 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-03 09:04:12 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://5efba7c87624631a897ec61a402a12d62ee8ae78583df19fa9e6226f76a630b9}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep  3 09:04:19.734: INFO: Pod "nginx-deployment-6f478d8d8-wj4sg" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-6f478d8d8-wj4sg,GenerateName:nginx-deployment-6f478d8d8-,Namespace:deployment-8259,SelfLink:/api/v1/namespaces/deployment-8259/pods/nginx-deployment-6f478d8d8-wj4sg,UID:cb886da8-ce29-11e9-9b9a-9e20fc449913,ResourceVersion:86884541,Generation:0,CreationTimestamp:2019-09-03 09:04:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 6f478d8d8,},Annotations:map[string]string{tke.cloud.tencent.com/networks-status: [{
    "name": "tke-bridge",
    "ips": [
        "172.22.1.69"
    ],
    "default": true,
    "dns": {}
}],},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-6f478d8d8 cb824eda-ce29-11e9-9b9a-9e20fc449913 0xc00076ebd7 0xc00076ebd8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-2xccm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2xccm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-2xccm true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:04:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:04:12 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:04:12 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:04:11 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.9,PodIP:172.22.1.69,StartTime:2019-09-03 09:04:11 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-03 09:04:12 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://630bd6cf41a7cfe3f336b2f9fb5787ec7e0bcf2ff5a39b67826fdd57fe578bd1}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:04:19.734: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8259" for this suite.
Sep  3 09:04:27.768: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:04:27.912: INFO: namespace deployment-8259 deletion completed in 8.171600186s

• [SLOW TEST:16.497 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:04:27.912: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:04:32.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-5841" for this suite.
Sep  3 09:04:38.165: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:04:38.325: INFO: namespace emptydir-wrapper-5841 deletion completed in 6.194455179s

• [SLOW TEST:10.413 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:04:38.326: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:04:44.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-4383" for this suite.
Sep  3 09:04:50.646: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:04:50.805: INFO: namespace namespaces-4383 deletion completed in 6.182067993s
STEP: Destroying namespace "nsdeletetest-3326" for this suite.
Sep  3 09:04:50.808: INFO: Namespace nsdeletetest-3326 was already deleted
STEP: Destroying namespace "nsdeletetest-1877" for this suite.
Sep  3 09:04:56.823: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:04:57.025: INFO: namespace nsdeletetest-1877 deletion completed in 6.216760924s

• [SLOW TEST:18.700 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:04:57.025: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-http in namespace container-probe-8705
Sep  3 09:04:59.116: INFO: Started pod liveness-http in namespace container-probe-8705
STEP: checking the pod's current state and verifying that restartCount is present
Sep  3 09:04:59.119: INFO: Initial restart count of pod liveness-http is 0
Sep  3 09:05:15.202: INFO: Restart count of pod container-probe-8705/liveness-http is now 1 (16.083415048s elapsed)
Sep  3 09:05:35.264: INFO: Restart count of pod container-probe-8705/liveness-http is now 2 (36.145476299s elapsed)
Sep  3 09:05:57.317: INFO: Restart count of pod container-probe-8705/liveness-http is now 3 (58.197629593s elapsed)
Sep  3 09:06:17.367: INFO: Restart count of pod container-probe-8705/liveness-http is now 4 (1m18.248522358s elapsed)
Sep  3 09:07:27.676: INFO: Restart count of pod container-probe-8705/liveness-http is now 5 (2m28.557472447s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:07:27.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8705" for this suite.
Sep  3 09:07:33.792: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:07:33.947: INFO: namespace container-probe-8705 deletion completed in 6.173855661s

• [SLOW TEST:156.921 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:07:33.947: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:07:36.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6293" for this suite.
Sep  3 09:08:16.061: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:08:16.206: INFO: namespace kubelet-test-6293 deletion completed in 40.16096674s

• [SLOW TEST:42.259 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command in a pod
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:08:16.206: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep  3 09:08:16.259: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Sep  3 09:08:16.270: INFO: Pod name sample-pod: Found 0 pods out of 1
Sep  3 09:08:21.275: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep  3 09:08:21.275: INFO: Creating deployment "test-rolling-update-deployment"
Sep  3 09:08:21.282: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Sep  3 09:08:21.288: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Sep  3 09:08:23.297: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Sep  3 09:08:23.300: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Sep  3 09:08:23.311: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-6414,SelfLink:/apis/apps/v1/namespaces/deployment-6414/deployments/test-rolling-update-deployment,UID:60661a67-ce2a-11e9-9b9a-9e20fc449913,ResourceVersion:86901484,Generation:1,CreationTimestamp:2019-09-03 09:08:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-09-03 09:08:21 +0000 UTC 2019-09-03 09:08:21 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-09-03 09:08:22 +0000 UTC 2019-09-03 09:08:21 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-67599b4d9" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Sep  3 09:08:23.315: INFO: New ReplicaSet "test-rolling-update-deployment-67599b4d9" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-67599b4d9,GenerateName:,Namespace:deployment-6414,SelfLink:/apis/apps/v1/namespaces/deployment-6414/replicasets/test-rolling-update-deployment-67599b4d9,UID:606905d0-ce2a-11e9-9b9a-9e20fc449913,ResourceVersion:86901471,Generation:1,CreationTimestamp:2019-09-03 09:08:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 60661a67-ce2a-11e9-9b9a-9e20fc449913 0xc0020142d0 0xc0020142d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Sep  3 09:08:23.315: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Sep  3 09:08:23.315: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-6414,SelfLink:/apis/apps/v1/namespaces/deployment-6414/replicasets/test-rolling-update-controller,UID:5d68c37d-ce2a-11e9-9b9a-9e20fc449913,ResourceVersion:86901483,Generation:2,CreationTimestamp:2019-09-03 09:08:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 60661a67-ce2a-11e9-9b9a-9e20fc449913 0xc0020141f7 0xc0020141f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep  3 09:08:23.319: INFO: Pod "test-rolling-update-deployment-67599b4d9-qxjfs" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-67599b4d9-qxjfs,GenerateName:test-rolling-update-deployment-67599b4d9-,Namespace:deployment-6414,SelfLink:/api/v1/namespaces/deployment-6414/pods/test-rolling-update-deployment-67599b4d9-qxjfs,UID:606afb8a-ce2a-11e9-9b9a-9e20fc449913,ResourceVersion:86901469,Generation:0,CreationTimestamp:2019-09-03 09:08:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 67599b4d9,},Annotations:map[string]string{tke.cloud.tencent.com/networks-status: [{
    "name": "tke-bridge",
    "ips": [
        "172.22.1.78"
    ],
    "default": true,
    "dns": {}
}],},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-67599b4d9 606905d0-ce2a-11e9-9b9a-9e20fc449913 0xc00076f150 0xc00076f151}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kbvrt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kbvrt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-kbvrt true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:08:21 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:08:22 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:08:22 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:08:21 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.9,PodIP:172.22.1.78,StartTime:2019-09-03 09:08:21 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-09-03 09:08:21 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://1e040d283cb0d412ce04ef94080f583dc83456e0e7f5d7a607e2977c0fba2ee5}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:08:23.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6414" for this suite.
Sep  3 09:08:29.345: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:08:29.489: INFO: namespace deployment-6414 deletion completed in 6.162720975s

• [SLOW TEST:13.283 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:08:29.489: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:09:29.563: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7729" for this suite.
Sep  3 09:09:47.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:09:47.737: INFO: namespace container-probe-7729 deletion completed in 18.168019238s

• [SLOW TEST:78.249 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:09:47.738: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test hostPath mode
Sep  3 09:09:47.803: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-3932" to be "success or failure"
Sep  3 09:09:47.807: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 3.547243ms
Sep  3 09:09:49.811: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007829542s
STEP: Saw pod success
Sep  3 09:09:49.811: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Sep  3 09:09:49.814: INFO: Trying to get logs from node 10.0.0.9 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Sep  3 09:09:49.850: INFO: Waiting for pod pod-host-path-test to disappear
Sep  3 09:09:49.853: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:09:49.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-3932" for this suite.
Sep  3 09:09:55.895: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:09:56.088: INFO: namespace hostpath-3932 deletion completed in 6.22869894s

• [SLOW TEST:8.351 seconds]
[sig-storage] HostPath
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:09:56.088: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5731.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-5731.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5731.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-5731.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5731.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-5731.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5731.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-5731.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5731.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-5731.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5731.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-5731.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5731.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 102.255.22.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.22.255.102_udp@PTR;check="$$(dig +tcp +noall +answer +search 102.255.22.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.22.255.102_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5731.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-5731.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5731.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-5731.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5731.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-5731.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5731.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-5731.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5731.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-5731.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5731.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-5731.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5731.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 102.255.22.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.22.255.102_udp@PTR;check="$$(dig +tcp +noall +answer +search 102.255.22.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.22.255.102_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep  3 09:10:16.199: INFO: Unable to read wheezy_udp@dns-test-service.dns-5731.svc.cluster.local from pod dns-5731/dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4: the server could not find the requested resource (get pods dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4)
Sep  3 09:10:16.203: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5731.svc.cluster.local from pod dns-5731/dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4: the server could not find the requested resource (get pods dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4)
Sep  3 09:10:16.207: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5731.svc.cluster.local from pod dns-5731/dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4: the server could not find the requested resource (get pods dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4)
Sep  3 09:10:16.212: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5731.svc.cluster.local from pod dns-5731/dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4: the server could not find the requested resource (get pods dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4)
Sep  3 09:10:16.239: INFO: Unable to read jessie_udp@dns-test-service.dns-5731.svc.cluster.local from pod dns-5731/dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4: the server could not find the requested resource (get pods dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4)
Sep  3 09:10:16.243: INFO: Unable to read jessie_tcp@dns-test-service.dns-5731.svc.cluster.local from pod dns-5731/dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4: the server could not find the requested resource (get pods dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4)
Sep  3 09:10:16.249: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5731.svc.cluster.local from pod dns-5731/dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4: the server could not find the requested resource (get pods dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4)
Sep  3 09:10:16.253: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5731.svc.cluster.local from pod dns-5731/dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4: the server could not find the requested resource (get pods dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4)
Sep  3 09:10:16.285: INFO: Lookups using dns-5731/dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4 failed for: [wheezy_udp@dns-test-service.dns-5731.svc.cluster.local wheezy_tcp@dns-test-service.dns-5731.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5731.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5731.svc.cluster.local jessie_udp@dns-test-service.dns-5731.svc.cluster.local jessie_tcp@dns-test-service.dns-5731.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5731.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5731.svc.cluster.local]

Sep  3 09:10:21.290: INFO: Unable to read wheezy_udp@dns-test-service.dns-5731.svc.cluster.local from pod dns-5731/dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4: the server could not find the requested resource (get pods dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4)
Sep  3 09:10:21.294: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5731.svc.cluster.local from pod dns-5731/dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4: the server could not find the requested resource (get pods dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4)
Sep  3 09:10:21.363: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5731.svc.cluster.local from pod dns-5731/dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4: the server could not find the requested resource (get pods dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4)
Sep  3 09:10:21.367: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5731.svc.cluster.local from pod dns-5731/dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4: the server could not find the requested resource (get pods dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4)
Sep  3 09:10:21.394: INFO: Unable to read jessie_udp@dns-test-service.dns-5731.svc.cluster.local from pod dns-5731/dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4: the server could not find the requested resource (get pods dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4)
Sep  3 09:10:21.397: INFO: Unable to read jessie_tcp@dns-test-service.dns-5731.svc.cluster.local from pod dns-5731/dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4: the server could not find the requested resource (get pods dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4)
Sep  3 09:10:21.401: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5731.svc.cluster.local from pod dns-5731/dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4: the server could not find the requested resource (get pods dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4)
Sep  3 09:10:21.405: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5731.svc.cluster.local from pod dns-5731/dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4: the server could not find the requested resource (get pods dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4)
Sep  3 09:10:21.427: INFO: Lookups using dns-5731/dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4 failed for: [wheezy_udp@dns-test-service.dns-5731.svc.cluster.local wheezy_tcp@dns-test-service.dns-5731.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5731.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5731.svc.cluster.local jessie_udp@dns-test-service.dns-5731.svc.cluster.local jessie_tcp@dns-test-service.dns-5731.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5731.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5731.svc.cluster.local]

Sep  3 09:10:26.290: INFO: Unable to read wheezy_udp@dns-test-service.dns-5731.svc.cluster.local from pod dns-5731/dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4: the server could not find the requested resource (get pods dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4)
Sep  3 09:10:26.294: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5731.svc.cluster.local from pod dns-5731/dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4: the server could not find the requested resource (get pods dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4)
Sep  3 09:10:26.298: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5731.svc.cluster.local from pod dns-5731/dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4: the server could not find the requested resource (get pods dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4)
Sep  3 09:10:26.302: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5731.svc.cluster.local from pod dns-5731/dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4: the server could not find the requested resource (get pods dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4)
Sep  3 09:10:26.330: INFO: Unable to read jessie_udp@dns-test-service.dns-5731.svc.cluster.local from pod dns-5731/dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4: the server could not find the requested resource (get pods dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4)
Sep  3 09:10:26.334: INFO: Unable to read jessie_tcp@dns-test-service.dns-5731.svc.cluster.local from pod dns-5731/dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4: the server could not find the requested resource (get pods dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4)
Sep  3 09:10:26.337: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5731.svc.cluster.local from pod dns-5731/dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4: the server could not find the requested resource (get pods dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4)
Sep  3 09:10:26.341: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5731.svc.cluster.local from pod dns-5731/dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4: the server could not find the requested resource (get pods dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4)
Sep  3 09:10:26.370: INFO: Lookups using dns-5731/dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4 failed for: [wheezy_udp@dns-test-service.dns-5731.svc.cluster.local wheezy_tcp@dns-test-service.dns-5731.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5731.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5731.svc.cluster.local jessie_udp@dns-test-service.dns-5731.svc.cluster.local jessie_tcp@dns-test-service.dns-5731.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5731.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5731.svc.cluster.local]

Sep  3 09:10:31.294: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5731.svc.cluster.local from pod dns-5731/dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4: the server could not find the requested resource (get pods dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4)
Sep  3 09:10:31.364: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5731.svc.cluster.local from pod dns-5731/dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4: the server could not find the requested resource (get pods dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4)
Sep  3 09:10:31.397: INFO: Unable to read jessie_udp@dns-test-service.dns-5731.svc.cluster.local from pod dns-5731/dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4: the server could not find the requested resource (get pods dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4)
Sep  3 09:10:31.400: INFO: Unable to read jessie_tcp@dns-test-service.dns-5731.svc.cluster.local from pod dns-5731/dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4: the server could not find the requested resource (get pods dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4)
Sep  3 09:10:31.404: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5731.svc.cluster.local from pod dns-5731/dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4: the server could not find the requested resource (get pods dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4)
Sep  3 09:10:31.408: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5731.svc.cluster.local from pod dns-5731/dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4: the server could not find the requested resource (get pods dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4)
Sep  3 09:10:31.439: INFO: Lookups using dns-5731/dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4 failed for: [wheezy_tcp@dns-test-service.dns-5731.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5731.svc.cluster.local jessie_udp@dns-test-service.dns-5731.svc.cluster.local jessie_tcp@dns-test-service.dns-5731.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5731.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5731.svc.cluster.local]

Sep  3 09:10:36.378: INFO: DNS probes using dns-5731/dns-test-98f522d0-ce2a-11e9-a824-e6b94fc13bb4 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:10:36.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5731" for this suite.
Sep  3 09:10:42.497: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:10:42.797: INFO: namespace dns-5731 deletion completed in 6.31896332s

• [SLOW TEST:46.708 seconds]
[sig-network] DNS
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:10:42.797: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:11:03.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1336" for this suite.
Sep  3 09:11:09.156: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:11:09.330: INFO: namespace container-runtime-1336 deletion completed in 6.190925903s

• [SLOW TEST:26.533 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  blackbox test
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:37
    when starting a container that exits
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:11:09.330: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test use defaults
Sep  3 09:11:09.400: INFO: Waiting up to 5m0s for pod "client-containers-c499ff28-ce2a-11e9-a824-e6b94fc13bb4" in namespace "containers-7703" to be "success or failure"
Sep  3 09:11:09.404: INFO: Pod "client-containers-c499ff28-ce2a-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.523145ms
Sep  3 09:11:11.408: INFO: Pod "client-containers-c499ff28-ce2a-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008070612s
STEP: Saw pod success
Sep  3 09:11:11.408: INFO: Pod "client-containers-c499ff28-ce2a-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 09:11:11.414: INFO: Trying to get logs from node 10.0.0.6 pod client-containers-c499ff28-ce2a-11e9-a824-e6b94fc13bb4 container test-container: <nil>
STEP: delete the pod
Sep  3 09:11:11.497: INFO: Waiting for pod client-containers-c499ff28-ce2a-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 09:11:11.501: INFO: Pod client-containers-c499ff28-ce2a-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:11:11.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7703" for this suite.
Sep  3 09:11:17.566: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:11:17.729: INFO: namespace containers-7703 deletion completed in 6.223276999s

• [SLOW TEST:8.399 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:11:17.729: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Sep  3 09:11:20.331: INFO: Successfully updated pod "labelsupdatec99b18c0-ce2a-11e9-a824-e6b94fc13bb4"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:11:24.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5000" for this suite.
Sep  3 09:11:46.381: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:11:46.520: INFO: namespace downward-api-5000 deletion completed in 22.154515213s

• [SLOW TEST:28.791 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:11:46.520: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-5362
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a new StatefulSet
Sep  3 09:11:46.673: INFO: Found 0 stateful pods, waiting for 3
Sep  3 09:11:56.679: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep  3 09:11:56.679: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep  3 09:11:56.679: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Sep  3 09:11:56.769: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Sep  3 09:12:06.812: INFO: Updating stateful set ss2
Sep  3 09:12:06.829: INFO: Waiting for Pod statefulset-5362/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
Sep  3 09:12:16.841: INFO: Waiting for Pod statefulset-5362/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Sep  3 09:12:26.890: INFO: Found 2 stateful pods, waiting for 3
Sep  3 09:12:36.895: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep  3 09:12:36.895: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep  3 09:12:36.895: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Sep  3 09:12:36.930: INFO: Updating stateful set ss2
Sep  3 09:12:36.939: INFO: Waiting for Pod statefulset-5362/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Sep  3 09:12:46.971: INFO: Updating stateful set ss2
Sep  3 09:12:46.979: INFO: Waiting for StatefulSet statefulset-5362/ss2 to complete update
Sep  3 09:12:46.979: INFO: Waiting for Pod statefulset-5362/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Sep  3 09:12:56.988: INFO: Deleting all statefulset in ns statefulset-5362
Sep  3 09:12:56.992: INFO: Scaling statefulset ss2 to 0
Sep  3 09:13:17.013: INFO: Waiting for statefulset status.replicas updated to 0
Sep  3 09:13:17.018: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:13:17.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5362" for this suite.
Sep  3 09:13:25.069: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:13:25.230: INFO: namespace statefulset-5362 deletion completed in 8.18196768s

• [SLOW TEST:98.711 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:13:25.231: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating the pod
Sep  3 09:13:27.898: INFO: Successfully updated pod "annotationupdate15a392d8-ce2b-11e9-a824-e6b94fc13bb4"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:13:31.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5609" for this suite.
Sep  3 09:13:55.957: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:13:56.125: INFO: namespace downward-api-5609 deletion completed in 24.187971986s

• [SLOW TEST:30.895 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:13:56.125: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the initial replication controller
Sep  3 09:13:56.187: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 create -f - --namespace=kubectl-1409'
Sep  3 09:13:56.395: INFO: stderr: ""
Sep  3 09:13:56.395: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep  3 09:13:56.395: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1409'
Sep  3 09:13:56.462: INFO: stderr: ""
Sep  3 09:13:56.462: INFO: stdout: "update-demo-nautilus-pdbns update-demo-nautilus-scmd7 "
Sep  3 09:13:56.463: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 get pods update-demo-nautilus-pdbns -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1409'
Sep  3 09:13:56.531: INFO: stderr: ""
Sep  3 09:13:56.531: INFO: stdout: ""
Sep  3 09:13:56.531: INFO: update-demo-nautilus-pdbns is created but not running
Sep  3 09:14:01.531: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1409'
Sep  3 09:14:01.605: INFO: stderr: ""
Sep  3 09:14:01.605: INFO: stdout: "update-demo-nautilus-pdbns update-demo-nautilus-scmd7 "
Sep  3 09:14:01.605: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 get pods update-demo-nautilus-pdbns -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1409'
Sep  3 09:14:01.677: INFO: stderr: ""
Sep  3 09:14:01.677: INFO: stdout: "true"
Sep  3 09:14:01.677: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 get pods update-demo-nautilus-pdbns -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1409'
Sep  3 09:14:01.756: INFO: stderr: ""
Sep  3 09:14:01.756: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  3 09:14:01.756: INFO: validating pod update-demo-nautilus-pdbns
Sep  3 09:14:01.769: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  3 09:14:01.769: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  3 09:14:01.769: INFO: update-demo-nautilus-pdbns is verified up and running
Sep  3 09:14:01.769: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 get pods update-demo-nautilus-scmd7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1409'
Sep  3 09:14:01.837: INFO: stderr: ""
Sep  3 09:14:01.837: INFO: stdout: "true"
Sep  3 09:14:01.837: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 get pods update-demo-nautilus-scmd7 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1409'
Sep  3 09:14:01.910: INFO: stderr: ""
Sep  3 09:14:01.910: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  3 09:14:01.910: INFO: validating pod update-demo-nautilus-scmd7
Sep  3 09:14:01.915: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  3 09:14:01.915: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  3 09:14:01.915: INFO: update-demo-nautilus-scmd7 is verified up and running
STEP: rolling-update to new replication controller
Sep  3 09:14:01.916: INFO: scanned /root for discovery docs: <nil>
Sep  3 09:14:01.916: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-1409'
Sep  3 09:14:24.468: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Sep  3 09:14:24.468: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep  3 09:14:24.468: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1409'
Sep  3 09:14:24.547: INFO: stderr: ""
Sep  3 09:14:24.547: INFO: stdout: "update-demo-kitten-cbch6 update-demo-kitten-njlnx "
Sep  3 09:14:24.548: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 get pods update-demo-kitten-cbch6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1409'
Sep  3 09:14:24.615: INFO: stderr: ""
Sep  3 09:14:24.615: INFO: stdout: "true"
Sep  3 09:14:24.615: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 get pods update-demo-kitten-cbch6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1409'
Sep  3 09:14:24.679: INFO: stderr: ""
Sep  3 09:14:24.679: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Sep  3 09:14:24.679: INFO: validating pod update-demo-kitten-cbch6
Sep  3 09:14:24.684: INFO: got data: {
  "image": "kitten.jpg"
}

Sep  3 09:14:24.684: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Sep  3 09:14:24.684: INFO: update-demo-kitten-cbch6 is verified up and running
Sep  3 09:14:24.684: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 get pods update-demo-kitten-njlnx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1409'
Sep  3 09:14:24.751: INFO: stderr: ""
Sep  3 09:14:24.751: INFO: stdout: "true"
Sep  3 09:14:24.751: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 get pods update-demo-kitten-njlnx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1409'
Sep  3 09:14:24.821: INFO: stderr: ""
Sep  3 09:14:24.821: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Sep  3 09:14:24.821: INFO: validating pod update-demo-kitten-njlnx
Sep  3 09:14:24.825: INFO: got data: {
  "image": "kitten.jpg"
}

Sep  3 09:14:24.825: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Sep  3 09:14:24.825: INFO: update-demo-kitten-njlnx is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:14:24.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1409" for this suite.
Sep  3 09:14:46.858: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:14:47.019: INFO: namespace kubectl-1409 deletion completed in 22.187480432s

• [SLOW TEST:50.894 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:14:47.019: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Sep  3 09:14:47.140: INFO: Number of nodes with available pods: 0
Sep  3 09:14:47.140: INFO: Node 10.0.0.6 is running more than one daemon pod
Sep  3 09:14:48.153: INFO: Number of nodes with available pods: 0
Sep  3 09:14:48.153: INFO: Node 10.0.0.6 is running more than one daemon pod
Sep  3 09:14:49.172: INFO: Number of nodes with available pods: 2
Sep  3 09:14:49.172: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Sep  3 09:14:49.220: INFO: Number of nodes with available pods: 1
Sep  3 09:14:49.220: INFO: Node 10.0.0.6 is running more than one daemon pod
Sep  3 09:14:50.230: INFO: Number of nodes with available pods: 1
Sep  3 09:14:50.230: INFO: Node 10.0.0.6 is running more than one daemon pod
Sep  3 09:14:51.231: INFO: Number of nodes with available pods: 1
Sep  3 09:14:51.231: INFO: Node 10.0.0.6 is running more than one daemon pod
Sep  3 09:14:52.231: INFO: Number of nodes with available pods: 1
Sep  3 09:14:52.231: INFO: Node 10.0.0.6 is running more than one daemon pod
Sep  3 09:14:53.232: INFO: Number of nodes with available pods: 1
Sep  3 09:14:53.232: INFO: Node 10.0.0.6 is running more than one daemon pod
Sep  3 09:14:54.240: INFO: Number of nodes with available pods: 1
Sep  3 09:14:54.240: INFO: Node 10.0.0.6 is running more than one daemon pod
Sep  3 09:14:55.230: INFO: Number of nodes with available pods: 1
Sep  3 09:14:55.230: INFO: Node 10.0.0.6 is running more than one daemon pod
Sep  3 09:14:56.230: INFO: Number of nodes with available pods: 1
Sep  3 09:14:56.230: INFO: Node 10.0.0.6 is running more than one daemon pod
Sep  3 09:14:57.233: INFO: Number of nodes with available pods: 1
Sep  3 09:14:57.233: INFO: Node 10.0.0.6 is running more than one daemon pod
Sep  3 09:14:58.233: INFO: Number of nodes with available pods: 1
Sep  3 09:14:58.233: INFO: Node 10.0.0.6 is running more than one daemon pod
Sep  3 09:14:59.231: INFO: Number of nodes with available pods: 2
Sep  3 09:14:59.231: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7660, will wait for the garbage collector to delete the pods
Sep  3 09:14:59.328: INFO: Deleting DaemonSet.extensions daemon-set took: 14.840588ms
Sep  3 09:14:59.728: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.244979ms
Sep  3 09:15:07.034: INFO: Number of nodes with available pods: 0
Sep  3 09:15:07.034: INFO: Number of running nodes: 0, number of available pods: 0
Sep  3 09:15:07.041: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7660/daemonsets","resourceVersion":"86928906"},"items":null}

Sep  3 09:15:07.044: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7660/pods","resourceVersion":"86928906"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:15:07.060: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7660" for this suite.
Sep  3 09:15:13.083: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:15:13.443: INFO: namespace daemonsets-7660 deletion completed in 6.378763844s

• [SLOW TEST:26.423 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:15:13.443: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep  3 09:15:13.550: INFO: Waiting up to 5m0s for pod "downwardapi-volume-561fa34d-ce2b-11e9-a824-e6b94fc13bb4" in namespace "projected-1631" to be "success or failure"
Sep  3 09:15:13.555: INFO: Pod "downwardapi-volume-561fa34d-ce2b-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 5.120678ms
Sep  3 09:15:15.560: INFO: Pod "downwardapi-volume-561fa34d-ce2b-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010278913s
STEP: Saw pod success
Sep  3 09:15:15.560: INFO: Pod "downwardapi-volume-561fa34d-ce2b-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 09:15:15.564: INFO: Trying to get logs from node 10.0.0.9 pod downwardapi-volume-561fa34d-ce2b-11e9-a824-e6b94fc13bb4 container client-container: <nil>
STEP: delete the pod
Sep  3 09:15:15.638: INFO: Waiting for pod downwardapi-volume-561fa34d-ce2b-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 09:15:15.642: INFO: Pod downwardapi-volume-561fa34d-ce2b-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:15:15.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1631" for this suite.
Sep  3 09:15:21.672: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:15:21.850: INFO: namespace projected-1631 deletion completed in 6.19751187s

• [SLOW TEST:8.408 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:15:21.851: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Sep  3 09:15:27.978: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8488 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  3 09:15:27.978: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
Sep  3 09:15:28.084: INFO: Exec stderr: ""
Sep  3 09:15:28.084: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8488 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  3 09:15:28.084: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
Sep  3 09:15:28.181: INFO: Exec stderr: ""
Sep  3 09:15:28.181: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8488 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  3 09:15:28.181: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
Sep  3 09:15:28.279: INFO: Exec stderr: ""
Sep  3 09:15:28.279: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8488 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  3 09:15:28.280: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
Sep  3 09:15:28.384: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Sep  3 09:15:28.384: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8488 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  3 09:15:28.384: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
Sep  3 09:15:28.501: INFO: Exec stderr: ""
Sep  3 09:15:28.501: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8488 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  3 09:15:28.501: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
Sep  3 09:15:28.597: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Sep  3 09:15:28.597: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8488 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  3 09:15:28.597: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
Sep  3 09:15:28.696: INFO: Exec stderr: ""
Sep  3 09:15:28.696: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8488 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  3 09:15:28.696: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
Sep  3 09:15:28.787: INFO: Exec stderr: ""
Sep  3 09:15:28.787: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8488 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  3 09:15:28.787: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
Sep  3 09:15:28.882: INFO: Exec stderr: ""
Sep  3 09:15:28.882: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8488 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  3 09:15:28.882: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
Sep  3 09:15:28.971: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:15:28.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-8488" for this suite.
Sep  3 09:16:19.016: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:16:19.219: INFO: namespace e2e-kubelet-etc-hosts-8488 deletion completed in 50.219277558s

• [SLOW TEST:57.369 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:16:19.220: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep  3 09:16:19.303: INFO: (0) /api/v1/nodes/10.0.0.6/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.405935ms)
Sep  3 09:16:19.308: INFO: (1) /api/v1/nodes/10.0.0.6/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.75295ms)
Sep  3 09:16:19.313: INFO: (2) /api/v1/nodes/10.0.0.6/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.747357ms)
Sep  3 09:16:19.318: INFO: (3) /api/v1/nodes/10.0.0.6/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.847098ms)
Sep  3 09:16:19.322: INFO: (4) /api/v1/nodes/10.0.0.6/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.714014ms)
Sep  3 09:16:19.330: INFO: (5) /api/v1/nodes/10.0.0.6/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.719517ms)
Sep  3 09:16:19.335: INFO: (6) /api/v1/nodes/10.0.0.6/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.792898ms)
Sep  3 09:16:19.340: INFO: (7) /api/v1/nodes/10.0.0.6/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.898371ms)
Sep  3 09:16:19.345: INFO: (8) /api/v1/nodes/10.0.0.6/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.750652ms)
Sep  3 09:16:19.352: INFO: (9) /api/v1/nodes/10.0.0.6/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.795955ms)
Sep  3 09:16:19.363: INFO: (10) /api/v1/nodes/10.0.0.6/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 11.079769ms)
Sep  3 09:16:19.373: INFO: (11) /api/v1/nodes/10.0.0.6/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.763989ms)
Sep  3 09:16:19.378: INFO: (12) /api/v1/nodes/10.0.0.6/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.214248ms)
Sep  3 09:16:19.384: INFO: (13) /api/v1/nodes/10.0.0.6/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.899013ms)
Sep  3 09:16:19.391: INFO: (14) /api/v1/nodes/10.0.0.6/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.115523ms)
Sep  3 09:16:19.395: INFO: (15) /api/v1/nodes/10.0.0.6/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.75518ms)
Sep  3 09:16:19.400: INFO: (16) /api/v1/nodes/10.0.0.6/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.69122ms)
Sep  3 09:16:19.405: INFO: (17) /api/v1/nodes/10.0.0.6/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.921757ms)
Sep  3 09:16:19.410: INFO: (18) /api/v1/nodes/10.0.0.6/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.957386ms)
Sep  3 09:16:19.415: INFO: (19) /api/v1/nodes/10.0.0.6/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.933413ms)
[AfterEach] version v1
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:16:19.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-5873" for this suite.
Sep  3 09:16:25.434: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:16:25.607: INFO: namespace proxy-5873 deletion completed in 6.18773786s

• [SLOW TEST:6.387 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:16:25.607: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-projected-zbxw
STEP: Creating a pod to test atomic-volume-subpath
Sep  3 09:16:25.717: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-zbxw" in namespace "subpath-7202" to be "success or failure"
Sep  3 09:16:25.746: INFO: Pod "pod-subpath-test-projected-zbxw": Phase="Pending", Reason="", readiness=false. Elapsed: 28.358237ms
Sep  3 09:16:27.750: INFO: Pod "pod-subpath-test-projected-zbxw": Phase="Running", Reason="", readiness=true. Elapsed: 2.03262096s
Sep  3 09:16:29.773: INFO: Pod "pod-subpath-test-projected-zbxw": Phase="Running", Reason="", readiness=true. Elapsed: 4.055396072s
Sep  3 09:16:31.777: INFO: Pod "pod-subpath-test-projected-zbxw": Phase="Running", Reason="", readiness=true. Elapsed: 6.059692513s
Sep  3 09:16:33.784: INFO: Pod "pod-subpath-test-projected-zbxw": Phase="Running", Reason="", readiness=true. Elapsed: 8.066403019s
Sep  3 09:16:35.797: INFO: Pod "pod-subpath-test-projected-zbxw": Phase="Running", Reason="", readiness=true. Elapsed: 10.079416724s
Sep  3 09:16:37.801: INFO: Pod "pod-subpath-test-projected-zbxw": Phase="Running", Reason="", readiness=true. Elapsed: 12.083874458s
Sep  3 09:16:39.806: INFO: Pod "pod-subpath-test-projected-zbxw": Phase="Running", Reason="", readiness=true. Elapsed: 14.08919791s
Sep  3 09:16:41.817: INFO: Pod "pod-subpath-test-projected-zbxw": Phase="Running", Reason="", readiness=true. Elapsed: 16.099659785s
Sep  3 09:16:43.824: INFO: Pod "pod-subpath-test-projected-zbxw": Phase="Running", Reason="", readiness=true. Elapsed: 18.106929212s
Sep  3 09:16:45.828: INFO: Pod "pod-subpath-test-projected-zbxw": Phase="Running", Reason="", readiness=true. Elapsed: 20.111185678s
Sep  3 09:16:47.836: INFO: Pod "pod-subpath-test-projected-zbxw": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.118543852s
STEP: Saw pod success
Sep  3 09:16:47.836: INFO: Pod "pod-subpath-test-projected-zbxw" satisfied condition "success or failure"
Sep  3 09:16:47.840: INFO: Trying to get logs from node 10.0.0.6 pod pod-subpath-test-projected-zbxw container test-container-subpath-projected-zbxw: <nil>
STEP: delete the pod
Sep  3 09:16:47.876: INFO: Waiting for pod pod-subpath-test-projected-zbxw to disappear
Sep  3 09:16:47.882: INFO: Pod pod-subpath-test-projected-zbxw no longer exists
STEP: Deleting pod pod-subpath-test-projected-zbxw
Sep  3 09:16:47.882: INFO: Deleting pod "pod-subpath-test-projected-zbxw" in namespace "subpath-7202"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:16:47.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7202" for this suite.
Sep  3 09:16:53.911: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:16:54.087: INFO: namespace subpath-7202 deletion completed in 6.194158515s

• [SLOW TEST:28.480 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:16:54.087: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Sep  3 09:16:54.155: INFO: Waiting up to 5m0s for pod "downward-api-9216b7ae-ce2b-11e9-a824-e6b94fc13bb4" in namespace "downward-api-3042" to be "success or failure"
Sep  3 09:16:54.164: INFO: Pod "downward-api-9216b7ae-ce2b-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.243274ms
Sep  3 09:16:56.176: INFO: Pod "downward-api-9216b7ae-ce2b-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020828834s
STEP: Saw pod success
Sep  3 09:16:56.176: INFO: Pod "downward-api-9216b7ae-ce2b-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 09:16:56.180: INFO: Trying to get logs from node 10.0.0.9 pod downward-api-9216b7ae-ce2b-11e9-a824-e6b94fc13bb4 container dapi-container: <nil>
STEP: delete the pod
Sep  3 09:16:56.224: INFO: Waiting for pod downward-api-9216b7ae-ce2b-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 09:16:56.227: INFO: Pod downward-api-9216b7ae-ce2b-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:16:56.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3042" for this suite.
Sep  3 09:17:02.249: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:17:02.424: INFO: namespace downward-api-3042 deletion completed in 6.192039566s

• [SLOW TEST:8.337 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:17:02.424: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep  3 09:17:02.489: INFO: Waiting up to 5m0s for pod "downwardapi-volume-970f3636-ce2b-11e9-a824-e6b94fc13bb4" in namespace "projected-8062" to be "success or failure"
Sep  3 09:17:02.496: INFO: Pod "downwardapi-volume-970f3636-ce2b-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 7.009358ms
Sep  3 09:17:04.501: INFO: Pod "downwardapi-volume-970f3636-ce2b-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011311137s
STEP: Saw pod success
Sep  3 09:17:04.501: INFO: Pod "downwardapi-volume-970f3636-ce2b-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 09:17:04.504: INFO: Trying to get logs from node 10.0.0.6 pod downwardapi-volume-970f3636-ce2b-11e9-a824-e6b94fc13bb4 container client-container: <nil>
STEP: delete the pod
Sep  3 09:17:04.589: INFO: Waiting for pod downwardapi-volume-970f3636-ce2b-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 09:17:04.594: INFO: Pod downwardapi-volume-970f3636-ce2b-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:17:04.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8062" for this suite.
Sep  3 09:17:10.635: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:17:10.808: INFO: namespace projected-8062 deletion completed in 6.208092557s

• [SLOW TEST:8.384 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:17:10.808: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:17:13.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6866" for this suite.
Sep  3 09:17:35.943: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:17:36.090: INFO: namespace replication-controller-6866 deletion completed in 22.167589485s

• [SLOW TEST:25.283 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:17:36.091: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Sep  3 09:17:36.151: INFO: Waiting up to 5m0s for pod "pod-ab1fa40e-ce2b-11e9-a824-e6b94fc13bb4" in namespace "emptydir-6164" to be "success or failure"
Sep  3 09:17:36.156: INFO: Pod "pod-ab1fa40e-ce2b-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 5.10713ms
Sep  3 09:17:38.167: INFO: Pod "pod-ab1fa40e-ce2b-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015886564s
STEP: Saw pod success
Sep  3 09:17:38.167: INFO: Pod "pod-ab1fa40e-ce2b-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 09:17:38.170: INFO: Trying to get logs from node 10.0.0.6 pod pod-ab1fa40e-ce2b-11e9-a824-e6b94fc13bb4 container test-container: <nil>
STEP: delete the pod
Sep  3 09:17:38.196: INFO: Waiting for pod pod-ab1fa40e-ce2b-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 09:17:38.199: INFO: Pod pod-ab1fa40e-ce2b-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:17:38.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6164" for this suite.
Sep  3 09:17:44.227: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:17:44.371: INFO: namespace emptydir-6164 deletion completed in 6.166500584s

• [SLOW TEST:8.280 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:17:44.371: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep  3 09:17:44.442: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b0108387-ce2b-11e9-a824-e6b94fc13bb4" in namespace "projected-5840" to be "success or failure"
Sep  3 09:17:44.445: INFO: Pod "downwardapi-volume-b0108387-ce2b-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.311063ms
Sep  3 09:17:46.463: INFO: Pod "downwardapi-volume-b0108387-ce2b-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021315797s
STEP: Saw pod success
Sep  3 09:17:46.463: INFO: Pod "downwardapi-volume-b0108387-ce2b-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 09:17:46.467: INFO: Trying to get logs from node 10.0.0.6 pod downwardapi-volume-b0108387-ce2b-11e9-a824-e6b94fc13bb4 container client-container: <nil>
STEP: delete the pod
Sep  3 09:17:46.495: INFO: Waiting for pod downwardapi-volume-b0108387-ce2b-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 09:17:46.498: INFO: Pod downwardapi-volume-b0108387-ce2b-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:17:46.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5840" for this suite.
Sep  3 09:17:52.522: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:17:52.681: INFO: namespace projected-5840 deletion completed in 6.178169365s

• [SLOW TEST:8.310 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:17:52.681: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Sep  3 09:17:52.783: INFO: Pod name pod-release: Found 0 pods out of 1
Sep  3 09:17:57.788: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:17:58.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7943" for this suite.
Sep  3 09:18:04.835: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:18:05.009: INFO: namespace replication-controller-7943 deletion completed in 6.195770259s

• [SLOW TEST:12.328 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:18:05.009: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating replication controller my-hostname-basic-bc5db28f-ce2b-11e9-a824-e6b94fc13bb4
Sep  3 09:18:05.081: INFO: Pod name my-hostname-basic-bc5db28f-ce2b-11e9-a824-e6b94fc13bb4: Found 0 pods out of 1
Sep  3 09:18:10.085: INFO: Pod name my-hostname-basic-bc5db28f-ce2b-11e9-a824-e6b94fc13bb4: Found 1 pods out of 1
Sep  3 09:18:10.085: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-bc5db28f-ce2b-11e9-a824-e6b94fc13bb4" are running
Sep  3 09:18:10.088: INFO: Pod "my-hostname-basic-bc5db28f-ce2b-11e9-a824-e6b94fc13bb4-7jh8s" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-03 09:18:05 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-03 09:18:06 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-03 09:18:06 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-03 09:18:05 +0000 UTC Reason: Message:}])
Sep  3 09:18:10.088: INFO: Trying to dial the pod
Sep  3 09:18:15.101: INFO: Controller my-hostname-basic-bc5db28f-ce2b-11e9-a824-e6b94fc13bb4: Got expected result from replica 1 [my-hostname-basic-bc5db28f-ce2b-11e9-a824-e6b94fc13bb4-7jh8s]: "my-hostname-basic-bc5db28f-ce2b-11e9-a824-e6b94fc13bb4-7jh8s", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:18:15.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-222" for this suite.
Sep  3 09:18:21.157: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:18:21.394: INFO: namespace replication-controller-222 deletion completed in 6.287372882s

• [SLOW TEST:16.385 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:18:21.394: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-c6212e77-ce2b-11e9-a824-e6b94fc13bb4
STEP: Creating a pod to test consume configMaps
Sep  3 09:18:21.476: INFO: Waiting up to 5m0s for pod "pod-configmaps-c622189d-ce2b-11e9-a824-e6b94fc13bb4" in namespace "configmap-8008" to be "success or failure"
Sep  3 09:18:21.486: INFO: Pod "pod-configmaps-c622189d-ce2b-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 10.493201ms
Sep  3 09:18:23.491: INFO: Pod "pod-configmaps-c622189d-ce2b-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01569459s
STEP: Saw pod success
Sep  3 09:18:23.491: INFO: Pod "pod-configmaps-c622189d-ce2b-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 09:18:23.495: INFO: Trying to get logs from node 10.0.0.9 pod pod-configmaps-c622189d-ce2b-11e9-a824-e6b94fc13bb4 container configmap-volume-test: <nil>
STEP: delete the pod
Sep  3 09:18:23.520: INFO: Waiting for pod pod-configmaps-c622189d-ce2b-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 09:18:23.524: INFO: Pod pod-configmaps-c622189d-ce2b-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:18:23.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8008" for this suite.
Sep  3 09:18:29.557: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:18:29.718: INFO: namespace configmap-8008 deletion completed in 6.189348294s

• [SLOW TEST:8.323 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:18:29.718: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-cb16a9dc-ce2b-11e9-a824-e6b94fc13bb4
STEP: Creating a pod to test consume configMaps
Sep  3 09:18:29.786: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-cb179df4-ce2b-11e9-a824-e6b94fc13bb4" in namespace "projected-2790" to be "success or failure"
Sep  3 09:18:29.790: INFO: Pod "pod-projected-configmaps-cb179df4-ce2b-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.844331ms
Sep  3 09:18:31.808: INFO: Pod "pod-projected-configmaps-cb179df4-ce2b-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021566429s
STEP: Saw pod success
Sep  3 09:18:31.808: INFO: Pod "pod-projected-configmaps-cb179df4-ce2b-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 09:18:31.815: INFO: Trying to get logs from node 10.0.0.6 pod pod-projected-configmaps-cb179df4-ce2b-11e9-a824-e6b94fc13bb4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep  3 09:18:31.843: INFO: Waiting for pod pod-projected-configmaps-cb179df4-ce2b-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 09:18:31.846: INFO: Pod pod-projected-configmaps-cb179df4-ce2b-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:18:31.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2790" for this suite.
Sep  3 09:18:37.869: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:18:38.115: INFO: namespace projected-2790 deletion completed in 6.263545409s

• [SLOW TEST:8.397 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:18:38.115: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-d019b0f5-ce2b-11e9-a824-e6b94fc13bb4
STEP: Creating a pod to test consume configMaps
Sep  3 09:18:38.192: INFO: Waiting up to 5m0s for pod "pod-configmaps-d01aa47a-ce2b-11e9-a824-e6b94fc13bb4" in namespace "configmap-1686" to be "success or failure"
Sep  3 09:18:38.199: INFO: Pod "pod-configmaps-d01aa47a-ce2b-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 7.186013ms
Sep  3 09:18:40.204: INFO: Pod "pod-configmaps-d01aa47a-ce2b-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011868564s
STEP: Saw pod success
Sep  3 09:18:40.204: INFO: Pod "pod-configmaps-d01aa47a-ce2b-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 09:18:40.207: INFO: Trying to get logs from node 10.0.0.9 pod pod-configmaps-d01aa47a-ce2b-11e9-a824-e6b94fc13bb4 container configmap-volume-test: <nil>
STEP: delete the pod
Sep  3 09:18:40.243: INFO: Waiting for pod pod-configmaps-d01aa47a-ce2b-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 09:18:40.246: INFO: Pod pod-configmaps-d01aa47a-ce2b-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:18:40.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1686" for this suite.
Sep  3 09:18:46.271: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:18:46.519: INFO: namespace configmap-1686 deletion completed in 6.265713029s

• [SLOW TEST:8.404 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:18:46.519: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep  3 09:18:46.577: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 version --client'
Sep  3 09:18:46.629: INFO: stderr: ""
Sep  3 09:18:46.629: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.3\", GitCommit:\"5e53fd6bc17c0dec8434817e69b04a25d8ae0ff0\", GitTreeState:\"clean\", BuildDate:\"2019-06-06T01:44:30Z\", GoVersion:\"go1.12.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Sep  3 09:18:46.630: INFO: Not supported for server versions before "1.14.3"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:18:46.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8881" for this suite.
Sep  3 09:18:52.657: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:18:52.814: INFO: namespace kubectl-8881 deletion completed in 6.175368168s

S [SKIPPING] [6.295 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should check if kubectl describe prints relevant information for rc and pods  [Conformance] [It]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692

    Not supported for server versions before "1.14.3"

    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:922
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:18:52.814: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: executing a command with run --rm and attach with stdin
Sep  3 09:18:52.873: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 --namespace=kubectl-3206 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Sep  3 09:18:54.656: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Sep  3 09:18:54.656: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:18:56.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3206" for this suite.
Sep  3 09:19:08.692: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:19:08.931: INFO: namespace kubectl-3206 deletion completed in 12.259957992s

• [SLOW TEST:16.116 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:19:08.931: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-b6jf
STEP: Creating a pod to test atomic-volume-subpath
Sep  3 09:19:09.001: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-b6jf" in namespace "subpath-7939" to be "success or failure"
Sep  3 09:19:09.004: INFO: Pod "pod-subpath-test-configmap-b6jf": Phase="Pending", Reason="", readiness=false. Elapsed: 3.417248ms
Sep  3 09:19:11.024: INFO: Pod "pod-subpath-test-configmap-b6jf": Phase="Running", Reason="", readiness=true. Elapsed: 2.022968447s
Sep  3 09:19:13.028: INFO: Pod "pod-subpath-test-configmap-b6jf": Phase="Running", Reason="", readiness=true. Elapsed: 4.027162493s
Sep  3 09:19:15.032: INFO: Pod "pod-subpath-test-configmap-b6jf": Phase="Running", Reason="", readiness=true. Elapsed: 6.031468063s
Sep  3 09:19:17.037: INFO: Pod "pod-subpath-test-configmap-b6jf": Phase="Running", Reason="", readiness=true. Elapsed: 8.035741359s
Sep  3 09:19:19.064: INFO: Pod "pod-subpath-test-configmap-b6jf": Phase="Running", Reason="", readiness=true. Elapsed: 10.06268683s
Sep  3 09:19:21.068: INFO: Pod "pod-subpath-test-configmap-b6jf": Phase="Running", Reason="", readiness=true. Elapsed: 12.067195045s
Sep  3 09:19:23.073: INFO: Pod "pod-subpath-test-configmap-b6jf": Phase="Running", Reason="", readiness=true. Elapsed: 14.071632522s
Sep  3 09:19:25.077: INFO: Pod "pod-subpath-test-configmap-b6jf": Phase="Running", Reason="", readiness=true. Elapsed: 16.076038109s
Sep  3 09:19:27.081: INFO: Pod "pod-subpath-test-configmap-b6jf": Phase="Running", Reason="", readiness=true. Elapsed: 18.080283122s
Sep  3 09:19:29.086: INFO: Pod "pod-subpath-test-configmap-b6jf": Phase="Running", Reason="", readiness=true. Elapsed: 20.084872732s
Sep  3 09:19:31.090: INFO: Pod "pod-subpath-test-configmap-b6jf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.089078825s
STEP: Saw pod success
Sep  3 09:19:31.090: INFO: Pod "pod-subpath-test-configmap-b6jf" satisfied condition "success or failure"
Sep  3 09:19:31.094: INFO: Trying to get logs from node 10.0.0.9 pod pod-subpath-test-configmap-b6jf container test-container-subpath-configmap-b6jf: <nil>
STEP: delete the pod
Sep  3 09:19:31.188: INFO: Waiting for pod pod-subpath-test-configmap-b6jf to disappear
Sep  3 09:19:31.191: INFO: Pod pod-subpath-test-configmap-b6jf no longer exists
STEP: Deleting pod pod-subpath-test-configmap-b6jf
Sep  3 09:19:31.191: INFO: Deleting pod "pod-subpath-test-configmap-b6jf" in namespace "subpath-7939"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:19:31.195: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7939" for this suite.
Sep  3 09:19:37.216: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:19:37.372: INFO: namespace subpath-7939 deletion completed in 6.173104824s

• [SLOW TEST:28.441 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:19:37.372: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:79
Sep  3 09:19:37.425: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep  3 09:19:37.435: INFO: Waiting for terminating namespaces to be deleted...
Sep  3 09:19:37.438: INFO: 
Logging pods the kubelet thinks is on node 10.0.0.6 before test
Sep  3 09:19:37.445: INFO: tke-cni-agent-bfqbh from kube-system started at 2019-09-03 07:25:10 +0000 UTC (1 container statuses recorded)
Sep  3 09:19:37.445: INFO: 	Container tke-cni-agent ready: true, restart count 1
Sep  3 09:19:37.445: INFO: sonobuoy-systemd-logs-daemon-set-9498ee0a545f46b0-n2nmx from heptio-sonobuoy started at 2019-09-03 08:17:22 +0000 UTC (2 container statuses recorded)
Sep  3 09:19:37.445: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Sep  3 09:19:37.445: INFO: 	Container systemd-logs ready: true, restart count 1
Sep  3 09:19:37.445: INFO: tke-bridge-agent-xxtpr from kube-system started at 2019-09-03 07:25:10 +0000 UTC (1 container statuses recorded)
Sep  3 09:19:37.445: INFO: 	Container tke-bridge-agent ready: true, restart count 1
Sep  3 09:19:37.445: INFO: ip-masq-agent-567fp from kube-system started at 2019-09-03 07:25:10 +0000 UTC (1 container statuses recorded)
Sep  3 09:19:37.445: INFO: 	Container ip-masq-agent ready: true, restart count 1
Sep  3 09:19:37.445: INFO: l7-lb-controller-85665d7887-mbmmm from kube-system started at 2019-09-03 07:25:10 +0000 UTC (1 container statuses recorded)
Sep  3 09:19:37.445: INFO: 	Container l7-lb-controller ready: true, restart count 2
Sep  3 09:19:37.445: INFO: coredns-6d58b575d7-prm6h from kube-system started at 2019-09-03 07:25:10 +0000 UTC (1 container statuses recorded)
Sep  3 09:19:37.445: INFO: 	Container coredns ready: true, restart count 1
Sep  3 09:19:37.445: INFO: coredns-6d58b575d7-6v8hl from kube-system started at 2019-09-03 07:25:10 +0000 UTC (1 container statuses recorded)
Sep  3 09:19:37.445: INFO: 	Container coredns ready: true, restart count 1
Sep  3 09:19:37.446: INFO: 
Logging pods the kubelet thinks is on node 10.0.0.9 before test
Sep  3 09:19:37.452: INFO: sonobuoy from heptio-sonobuoy started at 2019-09-03 08:17:16 +0000 UTC (1 container statuses recorded)
Sep  3 09:19:37.452: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep  3 09:19:37.452: INFO: sonobuoy-e2e-job-aaa506819e174e7a from heptio-sonobuoy started at 2019-09-03 08:17:22 +0000 UTC (2 container statuses recorded)
Sep  3 09:19:37.452: INFO: 	Container e2e ready: true, restart count 0
Sep  3 09:19:37.452: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep  3 09:19:37.452: INFO: ip-masq-agent-nttr5 from kube-system started at 2019-09-03 07:25:12 +0000 UTC (1 container statuses recorded)
Sep  3 09:19:37.452: INFO: 	Container ip-masq-agent ready: true, restart count 1
Sep  3 09:19:37.452: INFO: tke-cni-agent-nx5pw from kube-system started at 2019-09-03 07:25:12 +0000 UTC (1 container statuses recorded)
Sep  3 09:19:37.452: INFO: 	Container tke-cni-agent ready: true, restart count 1
Sep  3 09:19:37.452: INFO: sonobuoy-systemd-logs-daemon-set-9498ee0a545f46b0-d2zzq from heptio-sonobuoy started at 2019-09-03 08:17:22 +0000 UTC (2 container statuses recorded)
Sep  3 09:19:37.452: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Sep  3 09:19:37.452: INFO: 	Container systemd-logs ready: true, restart count 1
Sep  3 09:19:37.452: INFO: tke-bridge-agent-r6m4x from kube-system started at 2019-09-03 07:25:12 +0000 UTC (1 container statuses recorded)
Sep  3 09:19:37.452: INFO: 	Container tke-bridge-agent ready: true, restart count 1
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-f4a5315e-ce2b-11e9-a824-e6b94fc13bb4 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-f4a5315e-ce2b-11e9-a824-e6b94fc13bb4 off the node 10.0.0.6
STEP: verifying the node doesn't have the label kubernetes.io/e2e-f4a5315e-ce2b-11e9-a824-e6b94fc13bb4
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:19:41.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-3900" for this suite.
Sep  3 09:20:03.595: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:20:03.745: INFO: namespace sched-pred-3900 deletion completed in 22.187611826s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:70

• [SLOW TEST:26.373 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:20:03.745: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep  3 09:20:03.805: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0322308f-ce2c-11e9-a824-e6b94fc13bb4" in namespace "downward-api-1742" to be "success or failure"
Sep  3 09:20:03.810: INFO: Pod "downwardapi-volume-0322308f-ce2c-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 5.093402ms
Sep  3 09:20:05.815: INFO: Pod "downwardapi-volume-0322308f-ce2c-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009633672s
STEP: Saw pod success
Sep  3 09:20:05.815: INFO: Pod "downwardapi-volume-0322308f-ce2c-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 09:20:05.819: INFO: Trying to get logs from node 10.0.0.9 pod downwardapi-volume-0322308f-ce2c-11e9-a824-e6b94fc13bb4 container client-container: <nil>
STEP: delete the pod
Sep  3 09:20:05.857: INFO: Waiting for pod downwardapi-volume-0322308f-ce2c-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 09:20:05.860: INFO: Pod downwardapi-volume-0322308f-ce2c-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:20:05.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1742" for this suite.
Sep  3 09:20:11.976: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:20:12.133: INFO: namespace downward-api-1742 deletion completed in 6.265448936s

• [SLOW TEST:8.388 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:20:12.133: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep  3 09:20:12.255: INFO: Waiting up to 5m0s for pod "downwardapi-volume-082b8a0a-ce2c-11e9-a824-e6b94fc13bb4" in namespace "downward-api-9074" to be "success or failure"
Sep  3 09:20:12.259: INFO: Pod "downwardapi-volume-082b8a0a-ce2c-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.556387ms
Sep  3 09:20:14.263: INFO: Pod "downwardapi-volume-082b8a0a-ce2c-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008176106s
STEP: Saw pod success
Sep  3 09:20:14.263: INFO: Pod "downwardapi-volume-082b8a0a-ce2c-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 09:20:14.268: INFO: Trying to get logs from node 10.0.0.6 pod downwardapi-volume-082b8a0a-ce2c-11e9-a824-e6b94fc13bb4 container client-container: <nil>
STEP: delete the pod
Sep  3 09:20:14.311: INFO: Waiting for pod downwardapi-volume-082b8a0a-ce2c-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 09:20:14.315: INFO: Pod downwardapi-volume-082b8a0a-ce2c-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:20:14.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9074" for this suite.
Sep  3 09:20:20.338: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:20:20.498: INFO: namespace downward-api-9074 deletion completed in 6.178354135s

• [SLOW TEST:8.364 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:20:20.498: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1190
STEP: creating an rc
Sep  3 09:20:20.554: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 create -f - --namespace=kubectl-4672'
Sep  3 09:20:20.744: INFO: stderr: ""
Sep  3 09:20:20.744: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Waiting for Redis master to start.
Sep  3 09:20:21.749: INFO: Selector matched 1 pods for map[app:redis]
Sep  3 09:20:21.749: INFO: Found 0 / 1
Sep  3 09:20:22.749: INFO: Selector matched 1 pods for map[app:redis]
Sep  3 09:20:22.749: INFO: Found 1 / 1
Sep  3 09:20:22.749: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Sep  3 09:20:22.752: INFO: Selector matched 1 pods for map[app:redis]
Sep  3 09:20:22.752: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Sep  3 09:20:22.752: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 logs redis-master-t84rj redis-master --namespace=kubectl-4672'
Sep  3 09:20:22.890: INFO: stderr: ""
Sep  3 09:20:22.890: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 03 Sep 09:20:21.493 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 03 Sep 09:20:21.493 # Server started, Redis version 3.2.12\n1:M 03 Sep 09:20:21.493 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 03 Sep 09:20:21.493 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Sep  3 09:20:22.890: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 log redis-master-t84rj redis-master --namespace=kubectl-4672 --tail=1'
Sep  3 09:20:22.973: INFO: stderr: ""
Sep  3 09:20:22.973: INFO: stdout: "1:M 03 Sep 09:20:21.493 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Sep  3 09:20:22.973: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 log redis-master-t84rj redis-master --namespace=kubectl-4672 --limit-bytes=1'
Sep  3 09:20:23.058: INFO: stderr: ""
Sep  3 09:20:23.058: INFO: stdout: " "
STEP: exposing timestamps
Sep  3 09:20:23.058: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 log redis-master-t84rj redis-master --namespace=kubectl-4672 --tail=1 --timestamps'
Sep  3 09:20:23.146: INFO: stderr: ""
Sep  3 09:20:23.146: INFO: stdout: "2019-09-03T09:20:21.494316021Z 1:M 03 Sep 09:20:21.493 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Sep  3 09:20:25.646: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 log redis-master-t84rj redis-master --namespace=kubectl-4672 --since=1s'
Sep  3 09:20:25.726: INFO: stderr: ""
Sep  3 09:20:25.726: INFO: stdout: ""
Sep  3 09:20:25.726: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 log redis-master-t84rj redis-master --namespace=kubectl-4672 --since=24h'
Sep  3 09:20:25.808: INFO: stderr: ""
Sep  3 09:20:25.809: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 03 Sep 09:20:21.493 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 03 Sep 09:20:21.493 # Server started, Redis version 3.2.12\n1:M 03 Sep 09:20:21.493 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 03 Sep 09:20:21.493 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1196
STEP: using delete to clean up resources
Sep  3 09:20:25.809: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 delete --grace-period=0 --force -f - --namespace=kubectl-4672'
Sep  3 09:20:25.890: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  3 09:20:25.890: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Sep  3 09:20:25.890: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 get rc,svc -l name=nginx --no-headers --namespace=kubectl-4672'
Sep  3 09:20:25.963: INFO: stderr: "No resources found.\n"
Sep  3 09:20:25.963: INFO: stdout: ""
Sep  3 09:20:25.963: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 get pods -l name=nginx --namespace=kubectl-4672 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep  3 09:20:26.029: INFO: stderr: ""
Sep  3 09:20:26.029: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:20:26.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4672" for this suite.
Sep  3 09:20:32.053: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:20:32.208: INFO: namespace kubectl-4672 deletion completed in 6.172643897s

• [SLOW TEST:11.710 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:20:32.208: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep  3 09:20:32.278: INFO: Waiting up to 5m0s for pod "downwardapi-volume-141abfd1-ce2c-11e9-a824-e6b94fc13bb4" in namespace "downward-api-7823" to be "success or failure"
Sep  3 09:20:32.284: INFO: Pod "downwardapi-volume-141abfd1-ce2c-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.514767ms
Sep  3 09:20:34.288: INFO: Pod "downwardapi-volume-141abfd1-ce2c-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010848839s
STEP: Saw pod success
Sep  3 09:20:34.288: INFO: Pod "downwardapi-volume-141abfd1-ce2c-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 09:20:34.292: INFO: Trying to get logs from node 10.0.0.6 pod downwardapi-volume-141abfd1-ce2c-11e9-a824-e6b94fc13bb4 container client-container: <nil>
STEP: delete the pod
Sep  3 09:20:34.325: INFO: Waiting for pod downwardapi-volume-141abfd1-ce2c-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 09:20:34.329: INFO: Pod downwardapi-volume-141abfd1-ce2c-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:20:34.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7823" for this suite.
Sep  3 09:20:40.358: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:20:40.493: INFO: namespace downward-api-7823 deletion completed in 6.158795786s

• [SLOW TEST:8.285 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:20:40.493: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Sep  3 09:20:40.587: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2288,SelfLink:/api/v1/namespaces/watch-2288/configmaps/e2e-watch-test-label-changed,UID:190a53fd-ce2c-11e9-9b9a-9e20fc449913,ResourceVersion:86951590,Generation:0,CreationTimestamp:2019-09-03 09:20:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep  3 09:20:40.587: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2288,SelfLink:/api/v1/namespaces/watch-2288/configmaps/e2e-watch-test-label-changed,UID:190a53fd-ce2c-11e9-9b9a-9e20fc449913,ResourceVersion:86951592,Generation:0,CreationTimestamp:2019-09-03 09:20:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Sep  3 09:20:40.587: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2288,SelfLink:/api/v1/namespaces/watch-2288/configmaps/e2e-watch-test-label-changed,UID:190a53fd-ce2c-11e9-9b9a-9e20fc449913,ResourceVersion:86951595,Generation:0,CreationTimestamp:2019-09-03 09:20:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Sep  3 09:20:50.655: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2288,SelfLink:/api/v1/namespaces/watch-2288/configmaps/e2e-watch-test-label-changed,UID:190a53fd-ce2c-11e9-9b9a-9e20fc449913,ResourceVersion:86952265,Generation:0,CreationTimestamp:2019-09-03 09:20:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep  3 09:20:50.655: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2288,SelfLink:/api/v1/namespaces/watch-2288/configmaps/e2e-watch-test-label-changed,UID:190a53fd-ce2c-11e9-9b9a-9e20fc449913,ResourceVersion:86952267,Generation:0,CreationTimestamp:2019-09-03 09:20:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Sep  3 09:20:50.655: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2288,SelfLink:/api/v1/namespaces/watch-2288/configmaps/e2e-watch-test-label-changed,UID:190a53fd-ce2c-11e9-9b9a-9e20fc449913,ResourceVersion:86952269,Generation:0,CreationTimestamp:2019-09-03 09:20:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:20:50.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2288" for this suite.
Sep  3 09:20:56.685: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:20:56.840: INFO: namespace watch-2288 deletion completed in 6.17142533s

• [SLOW TEST:16.347 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:20:56.840: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Performing setup for networking test in namespace pod-network-test-3979
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep  3 09:20:56.966: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep  3 09:21:15.066: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.22.1.100 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3979 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  3 09:21:15.066: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
Sep  3 09:21:16.167: INFO: Found all expected endpoints: [netserver-0]
Sep  3 09:21:16.172: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.22.0.130 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3979 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep  3 09:21:16.172: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
Sep  3 09:21:17.295: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:21:17.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3979" for this suite.
Sep  3 09:21:41.316: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:21:41.535: INFO: namespace pod-network-test-3979 deletion completed in 24.233719244s

• [SLOW TEST:44.694 seconds]
[sig-network] Networking
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:21:41.535: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Sep  3 09:21:41.630: INFO: Number of nodes with available pods: 0
Sep  3 09:21:41.630: INFO: Node 10.0.0.6 is running more than one daemon pod
Sep  3 09:21:42.640: INFO: Number of nodes with available pods: 1
Sep  3 09:21:42.640: INFO: Node 10.0.0.9 is running more than one daemon pod
Sep  3 09:21:43.643: INFO: Number of nodes with available pods: 2
Sep  3 09:21:43.643: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Sep  3 09:21:43.666: INFO: Number of nodes with available pods: 2
Sep  3 09:21:43.666: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9425, will wait for the garbage collector to delete the pods
Sep  3 09:21:44.755: INFO: Deleting DaemonSet.extensions daemon-set took: 13.025383ms
Sep  3 09:21:45.155: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.137838ms
Sep  3 09:23:24.260: INFO: Number of nodes with available pods: 0
Sep  3 09:23:24.260: INFO: Number of running nodes: 0, number of available pods: 0
Sep  3 09:23:24.266: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9425/daemonsets","resourceVersion":"86962536"},"items":null}

Sep  3 09:23:24.270: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9425/pods","resourceVersion":"86962536"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:23:24.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9425" for this suite.
Sep  3 09:23:30.318: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:23:30.495: INFO: namespace daemonsets-9425 deletion completed in 6.193339537s

• [SLOW TEST:108.960 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:23:30.495: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on node default medium
Sep  3 09:23:30.561: INFO: Waiting up to 5m0s for pod "pod-7e5eb677-ce2c-11e9-a824-e6b94fc13bb4" in namespace "emptydir-5986" to be "success or failure"
Sep  3 09:23:30.565: INFO: Pod "pod-7e5eb677-ce2c-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.47322ms
Sep  3 09:23:32.569: INFO: Pod "pod-7e5eb677-ce2c-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008038747s
STEP: Saw pod success
Sep  3 09:23:32.569: INFO: Pod "pod-7e5eb677-ce2c-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 09:23:32.573: INFO: Trying to get logs from node 10.0.0.9 pod pod-7e5eb677-ce2c-11e9-a824-e6b94fc13bb4 container test-container: <nil>
STEP: delete the pod
Sep  3 09:23:32.603: INFO: Waiting for pod pod-7e5eb677-ce2c-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 09:23:32.606: INFO: Pod pod-7e5eb677-ce2c-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:23:32.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5986" for this suite.
Sep  3 09:23:38.627: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:23:38.786: INFO: namespace emptydir-5986 deletion completed in 6.174827522s

• [SLOW TEST:8.291 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:23:38.786: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-map-8351ca8c-ce2c-11e9-a824-e6b94fc13bb4
STEP: Creating a pod to test consume secrets
Sep  3 09:23:38.900: INFO: Waiting up to 5m0s for pod "pod-secrets-8353bb45-ce2c-11e9-a824-e6b94fc13bb4" in namespace "secrets-7314" to be "success or failure"
Sep  3 09:23:38.904: INFO: Pod "pod-secrets-8353bb45-ce2c-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.419535ms
Sep  3 09:23:40.908: INFO: Pod "pod-secrets-8353bb45-ce2c-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007795996s
STEP: Saw pod success
Sep  3 09:23:40.908: INFO: Pod "pod-secrets-8353bb45-ce2c-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 09:23:40.913: INFO: Trying to get logs from node 10.0.0.9 pod pod-secrets-8353bb45-ce2c-11e9-a824-e6b94fc13bb4 container secret-volume-test: <nil>
STEP: delete the pod
Sep  3 09:23:40.945: INFO: Waiting for pod pod-secrets-8353bb45-ce2c-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 09:23:40.948: INFO: Pod pod-secrets-8353bb45-ce2c-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:23:40.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7314" for this suite.
Sep  3 09:23:46.970: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:23:47.152: INFO: namespace secrets-7314 deletion completed in 6.198922033s

• [SLOW TEST:8.366 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:23:47.152: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Sep  3 09:23:47.234: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-1780,SelfLink:/api/v1/namespaces/watch-1780/configmaps/e2e-watch-test-watch-closed,UID:884bc13e-ce2c-11e9-9b9a-9e20fc449913,ResourceVersion:86964123,Generation:0,CreationTimestamp:2019-09-03 09:23:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep  3 09:23:47.234: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-1780,SelfLink:/api/v1/namespaces/watch-1780/configmaps/e2e-watch-test-watch-closed,UID:884bc13e-ce2c-11e9-9b9a-9e20fc449913,ResourceVersion:86964125,Generation:0,CreationTimestamp:2019-09-03 09:23:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Sep  3 09:23:47.263: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-1780,SelfLink:/api/v1/namespaces/watch-1780/configmaps/e2e-watch-test-watch-closed,UID:884bc13e-ce2c-11e9-9b9a-9e20fc449913,ResourceVersion:86964128,Generation:0,CreationTimestamp:2019-09-03 09:23:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep  3 09:23:47.263: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-1780,SelfLink:/api/v1/namespaces/watch-1780/configmaps/e2e-watch-test-watch-closed,UID:884bc13e-ce2c-11e9-9b9a-9e20fc449913,ResourceVersion:86964129,Generation:0,CreationTimestamp:2019-09-03 09:23:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:23:47.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1780" for this suite.
Sep  3 09:23:53.289: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:23:53.550: INFO: namespace watch-1780 deletion completed in 6.281250231s

• [SLOW TEST:6.398 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:23:53.550: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-1104
Sep  3 09:23:55.666: INFO: Started pod liveness-exec in namespace container-probe-1104
STEP: checking the pod's current state and verifying that restartCount is present
Sep  3 09:23:55.671: INFO: Initial restart count of pod liveness-exec is 0
Sep  3 09:24:45.821: INFO: Restart count of pod container-probe-1104/liveness-exec is now 1 (50.150878014s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:24:45.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1104" for this suite.
Sep  3 09:24:51.868: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:24:52.028: INFO: namespace container-probe-1104 deletion completed in 6.182470756s

• [SLOW TEST:58.478 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:24:52.029: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep  3 09:24:54.197: INFO: Waiting up to 5m0s for pod "client-envvars-b038e437-ce2c-11e9-a824-e6b94fc13bb4" in namespace "pods-8249" to be "success or failure"
Sep  3 09:24:54.202: INFO: Pod "client-envvars-b038e437-ce2c-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 5.006484ms
Sep  3 09:24:56.206: INFO: Pod "client-envvars-b038e437-ce2c-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009046308s
STEP: Saw pod success
Sep  3 09:24:56.206: INFO: Pod "client-envvars-b038e437-ce2c-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 09:24:56.209: INFO: Trying to get logs from node 10.0.0.9 pod client-envvars-b038e437-ce2c-11e9-a824-e6b94fc13bb4 container env3cont: <nil>
STEP: delete the pod
Sep  3 09:24:56.278: INFO: Waiting for pod client-envvars-b038e437-ce2c-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 09:24:56.282: INFO: Pod client-envvars-b038e437-ce2c-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:24:56.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8249" for this suite.
Sep  3 09:25:38.312: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:25:38.512: INFO: namespace pods-8249 deletion completed in 42.226245022s

• [SLOW TEST:46.484 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:25:38.513: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test override arguments
Sep  3 09:25:38.574: INFO: Waiting up to 5m0s for pod "client-containers-caac0e1f-ce2c-11e9-a824-e6b94fc13bb4" in namespace "containers-9498" to be "success or failure"
Sep  3 09:25:38.578: INFO: Pod "client-containers-caac0e1f-ce2c-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.529862ms
Sep  3 09:25:40.582: INFO: Pod "client-containers-caac0e1f-ce2c-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007937729s
STEP: Saw pod success
Sep  3 09:25:40.582: INFO: Pod "client-containers-caac0e1f-ce2c-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 09:25:40.586: INFO: Trying to get logs from node 10.0.0.6 pod client-containers-caac0e1f-ce2c-11e9-a824-e6b94fc13bb4 container test-container: <nil>
STEP: delete the pod
Sep  3 09:25:40.704: INFO: Waiting for pod client-containers-caac0e1f-ce2c-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 09:25:40.707: INFO: Pod client-containers-caac0e1f-ce2c-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:25:40.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9498" for this suite.
Sep  3 09:25:46.743: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:25:46.905: INFO: namespace containers-9498 deletion completed in 6.189950218s

• [SLOW TEST:8.393 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:25:46.905: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-configmap-429n
STEP: Creating a pod to test atomic-volume-subpath
Sep  3 09:25:46.978: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-429n" in namespace "subpath-1018" to be "success or failure"
Sep  3 09:25:46.981: INFO: Pod "pod-subpath-test-configmap-429n": Phase="Pending", Reason="", readiness=false. Elapsed: 3.513203ms
Sep  3 09:25:48.986: INFO: Pod "pod-subpath-test-configmap-429n": Phase="Running", Reason="", readiness=true. Elapsed: 2.008147119s
Sep  3 09:25:50.990: INFO: Pod "pod-subpath-test-configmap-429n": Phase="Running", Reason="", readiness=true. Elapsed: 4.01264932s
Sep  3 09:25:52.995: INFO: Pod "pod-subpath-test-configmap-429n": Phase="Running", Reason="", readiness=true. Elapsed: 6.017080281s
Sep  3 09:25:54.999: INFO: Pod "pod-subpath-test-configmap-429n": Phase="Running", Reason="", readiness=true. Elapsed: 8.021718509s
Sep  3 09:25:57.004: INFO: Pod "pod-subpath-test-configmap-429n": Phase="Running", Reason="", readiness=true. Elapsed: 10.026061196s
Sep  3 09:25:59.008: INFO: Pod "pod-subpath-test-configmap-429n": Phase="Running", Reason="", readiness=true. Elapsed: 12.030470992s
Sep  3 09:26:01.013: INFO: Pod "pod-subpath-test-configmap-429n": Phase="Running", Reason="", readiness=true. Elapsed: 14.035506748s
Sep  3 09:26:03.018: INFO: Pod "pod-subpath-test-configmap-429n": Phase="Running", Reason="", readiness=true. Elapsed: 16.040288119s
Sep  3 09:26:05.022: INFO: Pod "pod-subpath-test-configmap-429n": Phase="Running", Reason="", readiness=true. Elapsed: 18.04423618s
Sep  3 09:26:07.026: INFO: Pod "pod-subpath-test-configmap-429n": Phase="Running", Reason="", readiness=true. Elapsed: 20.048434005s
Sep  3 09:26:09.031: INFO: Pod "pod-subpath-test-configmap-429n": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.052866411s
STEP: Saw pod success
Sep  3 09:26:09.031: INFO: Pod "pod-subpath-test-configmap-429n" satisfied condition "success or failure"
Sep  3 09:26:09.040: INFO: Trying to get logs from node 10.0.0.9 pod pod-subpath-test-configmap-429n container test-container-subpath-configmap-429n: <nil>
STEP: delete the pod
Sep  3 09:26:09.082: INFO: Waiting for pod pod-subpath-test-configmap-429n to disappear
Sep  3 09:26:09.093: INFO: Pod pod-subpath-test-configmap-429n no longer exists
STEP: Deleting pod pod-subpath-test-configmap-429n
Sep  3 09:26:09.093: INFO: Deleting pod "pod-subpath-test-configmap-429n" in namespace "subpath-1018"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:26:09.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1018" for this suite.
Sep  3 09:26:15.124: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:26:15.296: INFO: namespace subpath-1018 deletion completed in 6.194042537s

• [SLOW TEST:28.391 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:26:15.296: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-e0999365-ce2c-11e9-a824-e6b94fc13bb4
STEP: Creating a pod to test consume secrets
Sep  3 09:26:15.380: INFO: Waiting up to 5m0s for pod "pod-secrets-e09be2bd-ce2c-11e9-a824-e6b94fc13bb4" in namespace "secrets-5537" to be "success or failure"
Sep  3 09:26:15.383: INFO: Pod "pod-secrets-e09be2bd-ce2c-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.141686ms
Sep  3 09:26:17.394: INFO: Pod "pod-secrets-e09be2bd-ce2c-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013415442s
STEP: Saw pod success
Sep  3 09:26:17.394: INFO: Pod "pod-secrets-e09be2bd-ce2c-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 09:26:17.397: INFO: Trying to get logs from node 10.0.0.6 pod pod-secrets-e09be2bd-ce2c-11e9-a824-e6b94fc13bb4 container secret-env-test: <nil>
STEP: delete the pod
Sep  3 09:26:17.488: INFO: Waiting for pod pod-secrets-e09be2bd-ce2c-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 09:26:17.491: INFO: Pod pod-secrets-e09be2bd-ce2c-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:26:17.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5537" for this suite.
Sep  3 09:26:23.524: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:26:23.664: INFO: namespace secrets-5537 deletion completed in 6.168397204s

• [SLOW TEST:8.368 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:26:23.665: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:26:27.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8399" for this suite.
Sep  3 09:26:33.757: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:26:33.913: INFO: namespace kubelet-test-8399 deletion completed in 6.171165525s

• [SLOW TEST:10.248 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:26:33.913: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1318
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep  3 09:26:33.971: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-3770'
Sep  3 09:26:34.129: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep  3 09:26:34.129: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1324
Sep  3 09:26:36.139: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 delete deployment e2e-test-nginx-deployment --namespace=kubectl-3770'
Sep  3 09:26:36.224: INFO: stderr: ""
Sep  3 09:26:36.224: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:26:36.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3770" for this suite.
Sep  3 09:26:42.249: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:26:42.406: INFO: namespace kubectl-3770 deletion completed in 6.175949648s

• [SLOW TEST:8.493 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:26:42.406: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-f0c21e38-ce2c-11e9-a824-e6b94fc13bb4
STEP: Creating a pod to test consume secrets
Sep  3 09:26:42.481: INFO: Waiting up to 5m0s for pod "pod-secrets-f0c2ff28-ce2c-11e9-a824-e6b94fc13bb4" in namespace "secrets-5552" to be "success or failure"
Sep  3 09:26:42.488: INFO: Pod "pod-secrets-f0c2ff28-ce2c-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.540341ms
Sep  3 09:26:44.492: INFO: Pod "pod-secrets-f0c2ff28-ce2c-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011030698s
STEP: Saw pod success
Sep  3 09:26:44.492: INFO: Pod "pod-secrets-f0c2ff28-ce2c-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 09:26:44.496: INFO: Trying to get logs from node 10.0.0.9 pod pod-secrets-f0c2ff28-ce2c-11e9-a824-e6b94fc13bb4 container secret-volume-test: <nil>
STEP: delete the pod
Sep  3 09:26:44.533: INFO: Waiting for pod pod-secrets-f0c2ff28-ce2c-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 09:26:44.538: INFO: Pod pod-secrets-f0c2ff28-ce2c-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:26:44.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5552" for this suite.
Sep  3 09:26:50.564: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:26:50.758: INFO: namespace secrets-5552 deletion completed in 6.2150107s

• [SLOW TEST:8.351 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:26:50.758: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Starting the proxy
Sep  3 09:26:50.822: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-356901984 proxy --unix-socket=/tmp/kubectl-proxy-unix376407615/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:26:50.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5477" for this suite.
Sep  3 09:26:56.898: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:26:57.092: INFO: namespace kubectl-5477 deletion completed in 6.21278532s

• [SLOW TEST:6.335 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:26:57.093: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-f9833dc1-ce2c-11e9-a824-e6b94fc13bb4
STEP: Creating a pod to test consume secrets
Sep  3 09:26:57.171: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f9849bca-ce2c-11e9-a824-e6b94fc13bb4" in namespace "projected-1749" to be "success or failure"
Sep  3 09:26:57.174: INFO: Pod "pod-projected-secrets-f9849bca-ce2c-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.465107ms
Sep  3 09:26:59.179: INFO: Pod "pod-projected-secrets-f9849bca-ce2c-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008576428s
STEP: Saw pod success
Sep  3 09:26:59.179: INFO: Pod "pod-projected-secrets-f9849bca-ce2c-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 09:26:59.183: INFO: Trying to get logs from node 10.0.0.6 pod pod-projected-secrets-f9849bca-ce2c-11e9-a824-e6b94fc13bb4 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep  3 09:26:59.282: INFO: Waiting for pod pod-projected-secrets-f9849bca-ce2c-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 09:26:59.285: INFO: Pod pod-projected-secrets-f9849bca-ce2c-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:26:59.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1749" for this suite.
Sep  3 09:27:05.308: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:27:05.493: INFO: namespace projected-1749 deletion completed in 6.203140523s

• [SLOW TEST:8.401 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:27:05.493: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7047.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7047.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep  3 09:27:07.644: INFO: DNS probes using dns-7047/dns-test-fe89517d-ce2c-11e9-a824-e6b94fc13bb4 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:27:07.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7047" for this suite.
Sep  3 09:27:13.698: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:27:13.909: INFO: namespace dns-7047 deletion completed in 6.235797868s

• [SLOW TEST:8.415 seconds]
[sig-network] DNS
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:27:13.909: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace statefulset-6292
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating stateful set ss in namespace statefulset-6292
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-6292
Sep  3 09:27:13.981: INFO: Found 0 stateful pods, waiting for 1
Sep  3 09:27:23.986: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Sep  3 09:27:23.991: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  3 09:27:24.176: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep  3 09:27:24.176: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  3 09:27:24.176: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  3 09:27:24.182: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Sep  3 09:27:34.191: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep  3 09:27:34.191: INFO: Waiting for statefulset status.replicas updated to 0
Sep  3 09:27:34.212: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Sep  3 09:27:34.212: INFO: ss-0  10.0.0.6  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:14 +0000 UTC  }]
Sep  3 09:27:34.212: INFO: 
Sep  3 09:27:34.212: INFO: StatefulSet ss has not reached scale 3, at 1
Sep  3 09:27:35.217: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996045431s
Sep  3 09:27:36.222: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.99130488s
Sep  3 09:27:37.227: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.986210265s
Sep  3 09:27:38.264: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.981374719s
Sep  3 09:27:39.268: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.944709991s
Sep  3 09:27:40.273: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.940123365s
Sep  3 09:27:41.284: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.935555047s
Sep  3 09:27:42.288: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.924752274s
Sep  3 09:27:43.294: INFO: Verifying statefulset ss doesn't scale past 3 for another 920.321198ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-6292
Sep  3 09:27:44.313: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  3 09:27:44.486: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep  3 09:27:44.486: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  3 09:27:44.486: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  3 09:27:44.486: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  3 09:27:44.643: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Sep  3 09:27:44.643: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  3 09:27:44.643: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  3 09:27:44.644: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  3 09:27:44.810: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Sep  3 09:27:44.810: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep  3 09:27:44.810: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep  3 09:27:44.815: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Sep  3 09:27:54.825: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Sep  3 09:27:54.825: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Sep  3 09:27:54.825: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Sep  3 09:27:54.828: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  3 09:27:55.000: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep  3 09:27:55.000: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  3 09:27:55.000: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  3 09:27:55.000: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  3 09:27:55.166: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep  3 09:27:55.166: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  3 09:27:55.166: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  3 09:27:55.166: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep  3 09:27:55.346: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep  3 09:27:55.346: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep  3 09:27:55.346: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep  3 09:27:55.346: INFO: Waiting for statefulset status.replicas updated to 0
Sep  3 09:27:55.353: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Sep  3 09:28:05.364: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep  3 09:28:05.364: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Sep  3 09:28:05.364: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Sep  3 09:28:05.384: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Sep  3 09:28:05.384: INFO: ss-0  10.0.0.6  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:14 +0000 UTC  }]
Sep  3 09:28:05.384: INFO: ss-1  10.0.0.9  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:34 +0000 UTC  }]
Sep  3 09:28:05.384: INFO: ss-2  10.0.0.6  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:34 +0000 UTC  }]
Sep  3 09:28:05.384: INFO: 
Sep  3 09:28:05.384: INFO: StatefulSet ss has not reached scale 0, at 3
Sep  3 09:28:06.389: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Sep  3 09:28:06.389: INFO: ss-0  10.0.0.6  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:14 +0000 UTC  }]
Sep  3 09:28:06.389: INFO: ss-1  10.0.0.9  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:34 +0000 UTC  }]
Sep  3 09:28:06.389: INFO: ss-2  10.0.0.6  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:34 +0000 UTC  }]
Sep  3 09:28:06.389: INFO: 
Sep  3 09:28:06.389: INFO: StatefulSet ss has not reached scale 0, at 3
Sep  3 09:28:07.394: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Sep  3 09:28:07.394: INFO: ss-0  10.0.0.6  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:14 +0000 UTC  }]
Sep  3 09:28:07.394: INFO: ss-2  10.0.0.6  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:34 +0000 UTC  }]
Sep  3 09:28:07.394: INFO: 
Sep  3 09:28:07.394: INFO: StatefulSet ss has not reached scale 0, at 2
Sep  3 09:28:08.398: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Sep  3 09:28:08.398: INFO: ss-0  10.0.0.6  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:14 +0000 UTC  }]
Sep  3 09:28:08.398: INFO: ss-2  10.0.0.6  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:34 +0000 UTC  }]
Sep  3 09:28:08.398: INFO: 
Sep  3 09:28:08.398: INFO: StatefulSet ss has not reached scale 0, at 2
Sep  3 09:28:09.404: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Sep  3 09:28:09.404: INFO: ss-0  10.0.0.6  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:14 +0000 UTC  }]
Sep  3 09:28:09.404: INFO: ss-2  10.0.0.6  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:34 +0000 UTC  }]
Sep  3 09:28:09.404: INFO: 
Sep  3 09:28:09.404: INFO: StatefulSet ss has not reached scale 0, at 2
Sep  3 09:28:10.409: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Sep  3 09:28:10.409: INFO: ss-0  10.0.0.6  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:14 +0000 UTC  }]
Sep  3 09:28:10.409: INFO: ss-2  10.0.0.6  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:34 +0000 UTC  }]
Sep  3 09:28:10.409: INFO: 
Sep  3 09:28:10.409: INFO: StatefulSet ss has not reached scale 0, at 2
Sep  3 09:28:11.414: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Sep  3 09:28:11.414: INFO: ss-0  10.0.0.6  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:14 +0000 UTC  }]
Sep  3 09:28:11.414: INFO: ss-2  10.0.0.6  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:34 +0000 UTC  }]
Sep  3 09:28:11.414: INFO: 
Sep  3 09:28:11.414: INFO: StatefulSet ss has not reached scale 0, at 2
Sep  3 09:28:12.419: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Sep  3 09:28:12.419: INFO: ss-0  10.0.0.6  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:14 +0000 UTC  }]
Sep  3 09:28:12.419: INFO: ss-2  10.0.0.6  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:34 +0000 UTC  }]
Sep  3 09:28:12.419: INFO: 
Sep  3 09:28:12.419: INFO: StatefulSet ss has not reached scale 0, at 2
Sep  3 09:28:13.423: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Sep  3 09:28:13.423: INFO: ss-0  10.0.0.6  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:14 +0000 UTC  }]
Sep  3 09:28:13.423: INFO: ss-2  10.0.0.6  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:34 +0000 UTC  }]
Sep  3 09:28:13.423: INFO: 
Sep  3 09:28:13.423: INFO: StatefulSet ss has not reached scale 0, at 2
Sep  3 09:28:14.428: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Sep  3 09:28:14.432: INFO: ss-0  10.0.0.6  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:14 +0000 UTC  }]
Sep  3 09:28:14.432: INFO: ss-2  10.0.0.6  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:55 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:27:34 +0000 UTC  }]
Sep  3 09:28:14.432: INFO: 
Sep  3 09:28:14.432: INFO: StatefulSet ss has not reached scale 0, at 2
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-6292
Sep  3 09:28:15.437: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  3 09:28:15.531: INFO: rc: 1
Sep  3 09:28:15.531: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc002426600 exit status 1 <nil> <nil> true [0xc0030b2318 0xc0030b2368 0xc0030b23f8] [0xc0030b2318 0xc0030b2368 0xc0030b23f8] [0xc0030b2340 0xc0030b23b8] [0x9c00a0 0x9c00a0] 0xc001cbf8c0 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Sep  3 09:28:25.531: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  3 09:28:25.594: INFO: rc: 1
Sep  3 09:28:25.594: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0037698f0 exit status 1 <nil> <nil> true [0xc001e7c078 0xc001e7c098 0xc001e7c0b0] [0xc001e7c078 0xc001e7c098 0xc001e7c0b0] [0xc001e7c088 0xc001e7c0a8] [0x9c00a0 0x9c00a0] 0xc00393f200 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Sep  3 09:28:35.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  3 09:28:35.654: INFO: rc: 1
Sep  3 09:28:35.654: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc003769c20 exit status 1 <nil> <nil> true [0xc001e7c0b8 0xc001e7c0d0 0xc001e7c0e8] [0xc001e7c0b8 0xc001e7c0d0 0xc001e7c0e8] [0xc001e7c0c8 0xc001e7c0e0] [0x9c00a0 0x9c00a0] 0xc00393f620 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Sep  3 09:28:45.654: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  3 09:28:45.716: INFO: rc: 1
Sep  3 09:28:45.716: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00270f530 exit status 1 <nil> <nil> true [0xc00274a1d8 0xc00274a1f0 0xc00274a208] [0xc00274a1d8 0xc00274a1f0 0xc00274a208] [0xc00274a1e8 0xc00274a200] [0x9c00a0 0x9c00a0] 0xc002631500 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Sep  3 09:28:55.717: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  3 09:28:55.786: INFO: rc: 1
Sep  3 09:28:55.786: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002426960 exit status 1 <nil> <nil> true [0xc0030b2408 0xc0030b2448 0xc0030b2478] [0xc0030b2408 0xc0030b2448 0xc0030b2478] [0xc0030b2430 0xc0030b2468] [0x9c00a0 0x9c00a0] 0xc001cbfe00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Sep  3 09:29:05.786: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  3 09:29:05.850: INFO: rc: 1
Sep  3 09:29:05.850: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002426cc0 exit status 1 <nil> <nil> true [0xc0030b2488 0xc0030b24c0 0xc0030b2508] [0xc0030b2488 0xc0030b24c0 0xc0030b2508] [0xc0030b24b0 0xc0030b24f8] [0x9c00a0 0x9c00a0] 0xc000aee2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Sep  3 09:29:15.850: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  3 09:29:15.910: INFO: rc: 1
Sep  3 09:29:15.910: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00270f8c0 exit status 1 <nil> <nil> true [0xc00274a210 0xc00274a228 0xc00274a240] [0xc00274a210 0xc00274a228 0xc00274a240] [0xc00274a220 0xc00274a238] [0x9c00a0 0x9c00a0] 0xc002631860 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Sep  3 09:29:25.910: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  3 09:29:25.974: INFO: rc: 1
Sep  3 09:29:25.974: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002427050 exit status 1 <nil> <nil> true [0xc0030b2520 0xc0030b2558 0xc0030b2598] [0xc0030b2520 0xc0030b2558 0xc0030b2598] [0xc0030b2548 0xc0030b2580] [0x9c00a0 0x9c00a0] 0xc000aee6c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Sep  3 09:29:35.974: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  3 09:29:36.035: INFO: rc: 1
Sep  3 09:29:36.035: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00270fbf0 exit status 1 <nil> <nil> true [0xc00274a248 0xc00274a260 0xc00274a278] [0xc00274a248 0xc00274a260 0xc00274a278] [0xc00274a258 0xc00274a270] [0x9c00a0 0x9c00a0] 0xc002631f80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Sep  3 09:29:46.035: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  3 09:29:46.098: INFO: rc: 1
Sep  3 09:29:46.098: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002427500 exit status 1 <nil> <nil> true [0xc0030b25a8 0xc0030b25e0 0xc0030b2610] [0xc0030b25a8 0xc0030b25e0 0xc0030b2610] [0xc0030b25d0 0xc0030b2600] [0x9c00a0 0x9c00a0] 0xc000aeea80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Sep  3 09:29:56.098: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  3 09:29:56.157: INFO: rc: 1
Sep  3 09:29:56.157: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002792300 exit status 1 <nil> <nil> true [0xc0030b2028 0xc0030b2058 0xc0030b2098] [0xc0030b2028 0xc0030b2058 0xc0030b2098] [0xc0030b2048 0xc0030b2078] [0x9c00a0 0x9c00a0] 0xc001cbe540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Sep  3 09:30:06.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  3 09:30:06.217: INFO: rc: 1
Sep  3 09:30:06.217: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002374300 exit status 1 <nil> <nil> true [0xc00274a000 0xc00274a020 0xc00274a038] [0xc00274a000 0xc00274a020 0xc00274a038] [0xc00274a018 0xc00274a030] [0x9c00a0 0x9c00a0] 0xc00261d3e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Sep  3 09:30:16.217: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  3 09:30:16.277: INFO: rc: 1
Sep  3 09:30:16.277: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001d6e330 exit status 1 <nil> <nil> true [0xc001e7c000 0xc001e7c018 0xc001e7c030] [0xc001e7c000 0xc001e7c018 0xc001e7c030] [0xc001e7c010 0xc001e7c028] [0x9c00a0 0x9c00a0] 0xc0026302a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Sep  3 09:30:26.278: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  3 09:30:26.351: INFO: rc: 1
Sep  3 09:30:26.351: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001d6e810 exit status 1 <nil> <nil> true [0xc001e7c038 0xc001e7c050 0xc001e7c068] [0xc001e7c038 0xc001e7c050 0xc001e7c068] [0xc001e7c048 0xc001e7c060] [0x9c00a0 0x9c00a0] 0xc002630600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Sep  3 09:30:36.351: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  3 09:30:36.414: INFO: rc: 1
Sep  3 09:30:36.414: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001d6ecf0 exit status 1 <nil> <nil> true [0xc001e7c070 0xc001e7c088 0xc001e7c0a8] [0xc001e7c070 0xc001e7c088 0xc001e7c0a8] [0xc001e7c080 0xc001e7c0a0] [0x9c00a0 0x9c00a0] 0xc0026309c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Sep  3 09:30:46.414: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  3 09:30:46.474: INFO: rc: 1
Sep  3 09:30:46.474: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0027926c0 exit status 1 <nil> <nil> true [0xc0030b20a8 0xc0030b20d8 0xc0030b2108] [0xc0030b20a8 0xc0030b20d8 0xc0030b2108] [0xc0030b20c8 0xc0030b20f8] [0x9c00a0 0x9c00a0] 0xc001cbec60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Sep  3 09:30:56.475: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  3 09:30:56.535: INFO: rc: 1
Sep  3 09:30:56.535: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001d6f080 exit status 1 <nil> <nil> true [0xc001e7c0b0 0xc001e7c0c8 0xc001e7c0e0] [0xc001e7c0b0 0xc001e7c0c8 0xc001e7c0e0] [0xc001e7c0c0 0xc001e7c0d8] [0x9c00a0 0x9c00a0] 0xc002630d80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Sep  3 09:31:06.536: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  3 09:31:06.599: INFO: rc: 1
Sep  3 09:31:06.599: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002792a20 exit status 1 <nil> <nil> true [0xc0030b2120 0xc0030b2150 0xc0030b2190] [0xc0030b2120 0xc0030b2150 0xc0030b2190] [0xc0030b2140 0xc0030b2178] [0x9c00a0 0x9c00a0] 0xc001cbf800 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Sep  3 09:31:16.599: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  3 09:31:16.667: INFO: rc: 1
Sep  3 09:31:16.667: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002792e10 exit status 1 <nil> <nil> true [0xc0030b21a0 0xc0030b21e0 0xc0030b2210] [0xc0030b21a0 0xc0030b21e0 0xc0030b2210] [0xc0030b21c8 0xc0030b2200] [0x9c00a0 0x9c00a0] 0xc001cbfda0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Sep  3 09:31:26.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  3 09:31:26.731: INFO: rc: 1
Sep  3 09:31:26.731: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0023747e0 exit status 1 <nil> <nil> true [0xc00274a040 0xc00274a058 0xc00274a070] [0xc00274a040 0xc00274a058 0xc00274a070] [0xc00274a050 0xc00274a068] [0x9c00a0 0x9c00a0] 0xc00261dc80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Sep  3 09:31:36.732: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  3 09:31:36.792: INFO: rc: 1
Sep  3 09:31:36.792: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002426630 exit status 1 <nil> <nil> true [0xc002128030 0xc002128098 0xc0021280b8] [0xc002128030 0xc002128098 0xc0021280b8] [0xc002128088 0xc0021280b0] [0x9c00a0 0x9c00a0] 0xc000aee420 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Sep  3 09:31:46.792: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  3 09:31:46.857: INFO: rc: 1
Sep  3 09:31:46.857: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0024269c0 exit status 1 <nil> <nil> true [0xc0021280c0 0xc0021280f8 0xc002128130] [0xc0021280c0 0xc0021280f8 0xc002128130] [0xc0021280f0 0xc002128110] [0x9c00a0 0x9c00a0] 0xc000aee7e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Sep  3 09:31:56.857: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  3 09:31:56.916: INFO: rc: 1
Sep  3 09:31:56.916: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001d6e300 exit status 1 <nil> <nil> true [0xc001e7c008 0xc001e7c020 0xc001e7c038] [0xc001e7c008 0xc001e7c020 0xc001e7c038] [0xc001e7c018 0xc001e7c030] [0x9c00a0 0x9c00a0] 0xc0026302a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Sep  3 09:32:06.916: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  3 09:32:07.026: INFO: rc: 1
Sep  3 09:32:07.026: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001d6e7e0 exit status 1 <nil> <nil> true [0xc001e7c040 0xc001e7c058 0xc001e7c070] [0xc001e7c040 0xc001e7c058 0xc001e7c070] [0xc001e7c050 0xc001e7c068] [0x9c00a0 0x9c00a0] 0xc002630600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Sep  3 09:32:17.027: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  3 09:32:17.086: INFO: rc: 1
Sep  3 09:32:17.086: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001d6ecc0 exit status 1 <nil> <nil> true [0xc001e7c078 0xc001e7c098 0xc001e7c0b0] [0xc001e7c078 0xc001e7c098 0xc001e7c0b0] [0xc001e7c088 0xc001e7c0a8] [0x9c00a0 0x9c00a0] 0xc0026309c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Sep  3 09:32:27.086: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  3 09:32:27.145: INFO: rc: 1
Sep  3 09:32:27.145: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002792330 exit status 1 <nil> <nil> true [0xc002128030 0xc002128098 0xc0021280b8] [0xc002128030 0xc002128098 0xc0021280b8] [0xc002128088 0xc0021280b0] [0x9c00a0 0x9c00a0] 0xc000aee420 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Sep  3 09:32:37.145: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  3 09:32:37.205: INFO: rc: 1
Sep  3 09:32:37.205: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001d6f050 exit status 1 <nil> <nil> true [0xc001e7c0b8 0xc001e7c0d0 0xc001e7c0e8] [0xc001e7c0b8 0xc001e7c0d0 0xc001e7c0e8] [0xc001e7c0c8 0xc001e7c0e0] [0x9c00a0 0x9c00a0] 0xc002630d80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Sep  3 09:32:47.206: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  3 09:32:47.277: INFO: rc: 1
Sep  3 09:32:47.277: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002426660 exit status 1 <nil> <nil> true [0xc0030b2008 0xc0030b2048 0xc0030b2078] [0xc0030b2008 0xc0030b2048 0xc0030b2078] [0xc0030b2038 0xc0030b2068] [0x9c00a0 0x9c00a0] 0xc001cbe540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Sep  3 09:32:57.277: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  3 09:32:57.344: INFO: rc: 1
Sep  3 09:32:57.344: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0024269f0 exit status 1 <nil> <nil> true [0xc0030b2098 0xc0030b20c8 0xc0030b20f8] [0xc0030b2098 0xc0030b20c8 0xc0030b20f8] [0xc0030b20b8 0xc0030b20e8] [0x9c00a0 0x9c00a0] 0xc001cbec60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Sep  3 09:33:07.344: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  3 09:33:07.407: INFO: rc: 1
Sep  3 09:33:07.407: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002792720 exit status 1 <nil> <nil> true [0xc0021280c0 0xc0021280f8 0xc002128130] [0xc0021280c0 0xc0021280f8 0xc002128130] [0xc0021280f0 0xc002128110] [0x9c00a0 0x9c00a0] 0xc000aee7e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Sep  3 09:33:17.407: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 exec --namespace=statefulset-6292 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep  3 09:33:17.466: INFO: rc: 1
Sep  3 09:33:17.466: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: 
Sep  3 09:33:17.466: INFO: Scaling statefulset ss to 0
Sep  3 09:33:17.480: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Sep  3 09:33:17.484: INFO: Deleting all statefulset in ns statefulset-6292
Sep  3 09:33:17.489: INFO: Scaling statefulset ss to 0
Sep  3 09:33:17.506: INFO: Waiting for statefulset status.replicas updated to 0
Sep  3 09:33:17.511: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:33:17.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6292" for this suite.
Sep  3 09:33:23.554: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:33:23.701: INFO: namespace statefulset-6292 deletion completed in 6.162727114s

• [SLOW TEST:369.793 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:33:23.702: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name projected-secret-test-dff23c42-ce2d-11e9-a824-e6b94fc13bb4
STEP: Creating a pod to test consume secrets
Sep  3 09:33:23.776: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-dff32ec1-ce2d-11e9-a824-e6b94fc13bb4" in namespace "projected-2015" to be "success or failure"
Sep  3 09:33:23.780: INFO: Pod "pod-projected-secrets-dff32ec1-ce2d-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.458087ms
Sep  3 09:33:25.784: INFO: Pod "pod-projected-secrets-dff32ec1-ce2d-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007859918s
STEP: Saw pod success
Sep  3 09:33:25.784: INFO: Pod "pod-projected-secrets-dff32ec1-ce2d-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 09:33:25.788: INFO: Trying to get logs from node 10.0.0.9 pod pod-projected-secrets-dff32ec1-ce2d-11e9-a824-e6b94fc13bb4 container secret-volume-test: <nil>
STEP: delete the pod
Sep  3 09:33:25.890: INFO: Waiting for pod pod-projected-secrets-dff32ec1-ce2d-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 09:33:25.895: INFO: Pod pod-projected-secrets-dff32ec1-ce2d-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:33:25.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2015" for this suite.
Sep  3 09:33:31.916: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:33:32.116: INFO: namespace projected-2015 deletion completed in 6.215235556s

• [SLOW TEST:8.415 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:33:32.117: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:265
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating a replication controller
Sep  3 09:33:32.167: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 create -f - --namespace=kubectl-2311'
Sep  3 09:33:32.297: INFO: stderr: ""
Sep  3 09:33:32.297: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep  3 09:33:32.297: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2311'
Sep  3 09:33:32.366: INFO: stderr: ""
Sep  3 09:33:32.366: INFO: stdout: "update-demo-nautilus-76vw8 update-demo-nautilus-pmgcf "
Sep  3 09:33:32.366: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 get pods update-demo-nautilus-76vw8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2311'
Sep  3 09:33:32.432: INFO: stderr: ""
Sep  3 09:33:32.432: INFO: stdout: ""
Sep  3 09:33:32.432: INFO: update-demo-nautilus-76vw8 is created but not running
Sep  3 09:33:37.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2311'
Sep  3 09:33:37.501: INFO: stderr: ""
Sep  3 09:33:37.501: INFO: stdout: "update-demo-nautilus-76vw8 update-demo-nautilus-pmgcf "
Sep  3 09:33:37.501: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 get pods update-demo-nautilus-76vw8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2311'
Sep  3 09:33:37.564: INFO: stderr: ""
Sep  3 09:33:37.564: INFO: stdout: "true"
Sep  3 09:33:37.564: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 get pods update-demo-nautilus-76vw8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2311'
Sep  3 09:33:37.633: INFO: stderr: ""
Sep  3 09:33:37.633: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  3 09:33:37.633: INFO: validating pod update-demo-nautilus-76vw8
Sep  3 09:33:37.638: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  3 09:33:37.638: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  3 09:33:37.638: INFO: update-demo-nautilus-76vw8 is verified up and running
Sep  3 09:33:37.638: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 get pods update-demo-nautilus-pmgcf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2311'
Sep  3 09:33:37.711: INFO: stderr: ""
Sep  3 09:33:37.711: INFO: stdout: "true"
Sep  3 09:33:37.712: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 get pods update-demo-nautilus-pmgcf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2311'
Sep  3 09:33:37.773: INFO: stderr: ""
Sep  3 09:33:37.773: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep  3 09:33:37.773: INFO: validating pod update-demo-nautilus-pmgcf
Sep  3 09:33:37.778: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep  3 09:33:37.778: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep  3 09:33:37.778: INFO: update-demo-nautilus-pmgcf is verified up and running
STEP: using delete to clean up resources
Sep  3 09:33:37.778: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 delete --grace-period=0 --force -f - --namespace=kubectl-2311'
Sep  3 09:33:37.867: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  3 09:33:37.867: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Sep  3 09:33:37.867: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-2311'
Sep  3 09:33:37.940: INFO: stderr: "No resources found.\n"
Sep  3 09:33:37.940: INFO: stdout: ""
Sep  3 09:33:37.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 get pods -l name=update-demo --namespace=kubectl-2311 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep  3 09:33:38.007: INFO: stderr: ""
Sep  3 09:33:38.007: INFO: stdout: "update-demo-nautilus-76vw8\nupdate-demo-nautilus-pmgcf\n"
Sep  3 09:33:38.507: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-2311'
Sep  3 09:33:38.582: INFO: stderr: "No resources found.\n"
Sep  3 09:33:38.582: INFO: stdout: ""
Sep  3 09:33:38.582: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 get pods -l name=update-demo --namespace=kubectl-2311 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep  3 09:33:38.651: INFO: stderr: ""
Sep  3 09:33:38.651: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:33:38.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2311" for this suite.
Sep  3 09:34:02.681: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:34:02.856: INFO: namespace kubectl-2311 deletion completed in 24.198651551s

• [SLOW TEST:30.740 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:34:02.857: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test env composition
Sep  3 09:34:02.926: INFO: Waiting up to 5m0s for pod "var-expansion-f749a5d1-ce2d-11e9-a824-e6b94fc13bb4" in namespace "var-expansion-470" to be "success or failure"
Sep  3 09:34:02.932: INFO: Pod "var-expansion-f749a5d1-ce2d-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.36541ms
Sep  3 09:34:04.950: INFO: Pod "var-expansion-f749a5d1-ce2d-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023960233s
STEP: Saw pod success
Sep  3 09:34:04.950: INFO: Pod "var-expansion-f749a5d1-ce2d-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 09:34:04.964: INFO: Trying to get logs from node 10.0.0.6 pod var-expansion-f749a5d1-ce2d-11e9-a824-e6b94fc13bb4 container dapi-container: <nil>
STEP: delete the pod
Sep  3 09:34:04.993: INFO: Waiting for pod var-expansion-f749a5d1-ce2d-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 09:34:04.996: INFO: Pod var-expansion-f749a5d1-ce2d-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:34:04.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-470" for this suite.
Sep  3 09:34:11.068: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:34:11.218: INFO: namespace var-expansion-470 deletion completed in 6.21660451s

• [SLOW TEST:8.361 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:34:11.218: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0903 09:34:21.393298      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep  3 09:34:21.393: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:34:21.393: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4963" for this suite.
Sep  3 09:34:27.412: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:34:27.576: INFO: namespace gc-4963 deletion completed in 6.178163653s

• [SLOW TEST:16.358 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:34:27.576: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-06079edd-ce2e-11e9-a824-e6b94fc13bb4
STEP: Creating a pod to test consume configMaps
Sep  3 09:34:27.668: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-060893c7-ce2e-11e9-a824-e6b94fc13bb4" in namespace "projected-3690" to be "success or failure"
Sep  3 09:34:27.671: INFO: Pod "pod-projected-configmaps-060893c7-ce2e-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.320429ms
Sep  3 09:34:29.676: INFO: Pod "pod-projected-configmaps-060893c7-ce2e-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007642118s
STEP: Saw pod success
Sep  3 09:34:29.676: INFO: Pod "pod-projected-configmaps-060893c7-ce2e-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 09:34:29.680: INFO: Trying to get logs from node 10.0.0.9 pod pod-projected-configmaps-060893c7-ce2e-11e9-a824-e6b94fc13bb4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep  3 09:34:29.732: INFO: Waiting for pod pod-projected-configmaps-060893c7-ce2e-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 09:34:29.736: INFO: Pod pod-projected-configmaps-060893c7-ce2e-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:34:29.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3690" for this suite.
Sep  3 09:34:35.757: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:34:35.924: INFO: namespace projected-3690 deletion completed in 6.183151941s

• [SLOW TEST:8.348 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:34:35.924: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep  3 09:34:35.979: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:34:37.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-33" for this suite.
Sep  3 09:34:43.115: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:34:43.322: INFO: namespace custom-resource-definition-33 deletion completed in 6.249557985s

• [SLOW TEST:7.399 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:34:43.322: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with configMap that has name projected-configmap-test-upd-0f760d27-ce2e-11e9-a824-e6b94fc13bb4
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-0f760d27-ce2e-11e9-a824-e6b94fc13bb4
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:34:47.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9635" for this suite.
Sep  3 09:35:11.590: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:35:11.745: INFO: namespace projected-9635 deletion completed in 24.179083316s

• [SLOW TEST:28.423 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:35:11.745: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Sep  3 09:35:14.379: INFO: Successfully updated pod "pod-update-activedeadlineseconds-205a3522-ce2e-11e9-a824-e6b94fc13bb4"
Sep  3 09:35:14.379: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-205a3522-ce2e-11e9-a824-e6b94fc13bb4" in namespace "pods-129" to be "terminated due to deadline exceeded"
Sep  3 09:35:14.394: INFO: Pod "pod-update-activedeadlineseconds-205a3522-ce2e-11e9-a824-e6b94fc13bb4": Phase="Running", Reason="", readiness=true. Elapsed: 14.932243ms
Sep  3 09:35:16.467: INFO: Pod "pod-update-activedeadlineseconds-205a3522-ce2e-11e9-a824-e6b94fc13bb4": Phase="Running", Reason="", readiness=true. Elapsed: 2.08724128s
Sep  3 09:35:18.471: INFO: Pod "pod-update-activedeadlineseconds-205a3522-ce2e-11e9-a824-e6b94fc13bb4": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.091437211s
Sep  3 09:35:18.471: INFO: Pod "pod-update-activedeadlineseconds-205a3522-ce2e-11e9-a824-e6b94fc13bb4" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:35:18.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-129" for this suite.
Sep  3 09:35:24.490: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:35:24.878: INFO: namespace pods-129 deletion completed in 6.402348035s

• [SLOW TEST:13.133 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:35:24.878: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Sep  3 09:35:24.932: INFO: PodSpec: initContainers in spec.initContainers
Sep  3 09:36:08.042: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-282c5c41-ce2e-11e9-a824-e6b94fc13bb4", GenerateName:"", Namespace:"init-container-284", SelfLink:"/api/v1/namespaces/init-container-284/pods/pod-init-282c5c41-ce2e-11e9-a824-e6b94fc13bb4", UID:"282cecbf-ce2e-11e9-9b9a-9e20fc449913", ResourceVersion:"87013845", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63703100124, loc:(*time.Location)(0x8a1a0e0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"932413531"}, Annotations:map[string]string{"tke.cloud.tencent.com/networks-status":"[{\n    \"name\": \"tke-bridge\",\n    \"ips\": [\n        \"172.22.0.144\"\n    ],\n    \"default\": true,\n    \"dns\": {}\n}]"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-4stmh", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc002072000), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-4stmh", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-4stmh", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-4stmh", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001f04088), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"10.0.0.6", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0031220c0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration(nil), HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(nil), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc001f04100)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703100124, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703100124, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703100124, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703100124, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.0.0.6", PodIP:"172.22.0.144", StartTime:(*v1.Time)(0xc0023821e0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001ff6070)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001ff60e0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://cb4bb8cb6d8c5ad23ea315d76ef4793fe479047707c9ef6e000e4da3537afb55"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002382220), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002382200), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:36:08.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-284" for this suite.
Sep  3 09:36:30.093: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:36:30.238: INFO: namespace init-container-284 deletion completed in 22.169228251s

• [SLOW TEST:65.360 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:36:30.239: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-4f20de3d-ce2e-11e9-a824-e6b94fc13bb4
STEP: Creating a pod to test consume configMaps
Sep  3 09:36:30.304: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4f21c946-ce2e-11e9-a824-e6b94fc13bb4" in namespace "projected-7126" to be "success or failure"
Sep  3 09:36:30.308: INFO: Pod "pod-projected-configmaps-4f21c946-ce2e-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.053472ms
Sep  3 09:36:32.313: INFO: Pod "pod-projected-configmaps-4f21c946-ce2e-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009289624s
STEP: Saw pod success
Sep  3 09:36:32.313: INFO: Pod "pod-projected-configmaps-4f21c946-ce2e-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 09:36:32.317: INFO: Trying to get logs from node 10.0.0.9 pod pod-projected-configmaps-4f21c946-ce2e-11e9-a824-e6b94fc13bb4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep  3 09:36:32.377: INFO: Waiting for pod pod-projected-configmaps-4f21c946-ce2e-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 09:36:32.380: INFO: Pod pod-projected-configmaps-4f21c946-ce2e-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:36:32.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7126" for this suite.
Sep  3 09:36:38.410: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:36:38.563: INFO: namespace projected-7126 deletion completed in 6.175884739s

• [SLOW TEST:8.324 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:36:38.563: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:135
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Sep  3 09:36:38.652: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:36:46.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8898" for this suite.
Sep  3 09:36:52.991: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:36:53.242: INFO: namespace pods-8898 deletion completed in 6.268062474s

• [SLOW TEST:14.679 seconds]
[k8s.io] Pods
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:36:53.242: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating Redis RC
Sep  3 09:36:53.313: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 create -f - --namespace=kubectl-2570'
Sep  3 09:36:53.508: INFO: stderr: ""
Sep  3 09:36:53.508: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Sep  3 09:36:54.513: INFO: Selector matched 1 pods for map[app:redis]
Sep  3 09:36:54.513: INFO: Found 1 / 1
Sep  3 09:36:54.513: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Sep  3 09:36:54.516: INFO: Selector matched 1 pods for map[app:redis]
Sep  3 09:36:54.516: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep  3 09:36:54.516: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 patch pod redis-master-8qph5 --namespace=kubectl-2570 -p {"metadata":{"annotations":{"x":"y"}}}'
Sep  3 09:36:54.609: INFO: stderr: ""
Sep  3 09:36:54.609: INFO: stdout: "pod/redis-master-8qph5 patched\n"
STEP: checking annotations
Sep  3 09:36:54.613: INFO: Selector matched 1 pods for map[app:redis]
Sep  3 09:36:54.613: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:36:54.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2570" for this suite.
Sep  3 09:37:18.641: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:37:18.793: INFO: namespace kubectl-2570 deletion completed in 24.173668724s

• [SLOW TEST:25.550 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:37:18.793: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Sep  3 09:37:18.875: INFO: Waiting up to 5m0s for pod "pod-6c146fc1-ce2e-11e9-a824-e6b94fc13bb4" in namespace "emptydir-3227" to be "success or failure"
Sep  3 09:37:18.892: INFO: Pod "pod-6c146fc1-ce2e-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 17.160917ms
Sep  3 09:37:20.896: INFO: Pod "pod-6c146fc1-ce2e-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021614748s
STEP: Saw pod success
Sep  3 09:37:20.896: INFO: Pod "pod-6c146fc1-ce2e-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 09:37:20.900: INFO: Trying to get logs from node 10.0.0.6 pod pod-6c146fc1-ce2e-11e9-a824-e6b94fc13bb4 container test-container: <nil>
STEP: delete the pod
Sep  3 09:37:20.990: INFO: Waiting for pod pod-6c146fc1-ce2e-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 09:37:20.993: INFO: Pod pod-6c146fc1-ce2e-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:37:20.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3227" for this suite.
Sep  3 09:37:27.019: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:37:27.184: INFO: namespace emptydir-3227 deletion completed in 6.186001387s

• [SLOW TEST:8.391 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:37:27.184: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting the proxy server
Sep  3 09:37:27.250: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-356901984 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:37:27.312: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3466" for this suite.
Sep  3 09:37:33.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:37:33.533: INFO: namespace kubectl-3466 deletion completed in 6.213826721s

• [SLOW TEST:6.348 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:37:33.533: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep  3 09:37:59.615: INFO: Container started at 2019-09-03 09:37:34 +0000 UTC, pod became ready at 2019-09-03 09:37:58 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:37:59.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2062" for this suite.
Sep  3 09:38:21.636: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:38:21.801: INFO: namespace container-probe-2062 deletion completed in 22.180287394s

• [SLOW TEST:48.268 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:38:21.801: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-downwardapi-jljs
STEP: Creating a pod to test atomic-volume-subpath
Sep  3 09:38:21.879: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-jljs" in namespace "subpath-1527" to be "success or failure"
Sep  3 09:38:21.886: INFO: Pod "pod-subpath-test-downwardapi-jljs": Phase="Pending", Reason="", readiness=false. Elapsed: 6.761577ms
Sep  3 09:38:23.891: INFO: Pod "pod-subpath-test-downwardapi-jljs": Phase="Running", Reason="", readiness=true. Elapsed: 2.011276898s
Sep  3 09:38:25.896: INFO: Pod "pod-subpath-test-downwardapi-jljs": Phase="Running", Reason="", readiness=true. Elapsed: 4.016337212s
Sep  3 09:38:27.900: INFO: Pod "pod-subpath-test-downwardapi-jljs": Phase="Running", Reason="", readiness=true. Elapsed: 6.020803267s
Sep  3 09:38:29.905: INFO: Pod "pod-subpath-test-downwardapi-jljs": Phase="Running", Reason="", readiness=true. Elapsed: 8.02526633s
Sep  3 09:38:31.909: INFO: Pod "pod-subpath-test-downwardapi-jljs": Phase="Running", Reason="", readiness=true. Elapsed: 10.029408147s
Sep  3 09:38:33.913: INFO: Pod "pod-subpath-test-downwardapi-jljs": Phase="Running", Reason="", readiness=true. Elapsed: 12.033497806s
Sep  3 09:38:35.917: INFO: Pod "pod-subpath-test-downwardapi-jljs": Phase="Running", Reason="", readiness=true. Elapsed: 14.037882452s
Sep  3 09:38:37.922: INFO: Pod "pod-subpath-test-downwardapi-jljs": Phase="Running", Reason="", readiness=true. Elapsed: 16.042195474s
Sep  3 09:38:39.926: INFO: Pod "pod-subpath-test-downwardapi-jljs": Phase="Running", Reason="", readiness=true. Elapsed: 18.046666834s
Sep  3 09:38:41.935: INFO: Pod "pod-subpath-test-downwardapi-jljs": Phase="Running", Reason="", readiness=true. Elapsed: 20.0552712s
Sep  3 09:38:43.939: INFO: Pod "pod-subpath-test-downwardapi-jljs": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.059742023s
STEP: Saw pod success
Sep  3 09:38:43.939: INFO: Pod "pod-subpath-test-downwardapi-jljs" satisfied condition "success or failure"
Sep  3 09:38:43.943: INFO: Trying to get logs from node 10.0.0.6 pod pod-subpath-test-downwardapi-jljs container test-container-subpath-downwardapi-jljs: <nil>
STEP: delete the pod
Sep  3 09:38:43.972: INFO: Waiting for pod pod-subpath-test-downwardapi-jljs to disappear
Sep  3 09:38:43.984: INFO: Pod pod-subpath-test-downwardapi-jljs no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-jljs
Sep  3 09:38:43.984: INFO: Deleting pod "pod-subpath-test-downwardapi-jljs" in namespace "subpath-1527"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:38:43.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1527" for this suite.
Sep  3 09:38:50.015: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:38:50.221: INFO: namespace subpath-1527 deletion completed in 6.226864202s

• [SLOW TEST:28.420 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:38:50.222: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep  3 09:38:50.291: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a2925a00-ce2e-11e9-a824-e6b94fc13bb4" in namespace "downward-api-9616" to be "success or failure"
Sep  3 09:38:50.295: INFO: Pod "downwardapi-volume-a2925a00-ce2e-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.374456ms
Sep  3 09:38:52.301: INFO: Pod "downwardapi-volume-a2925a00-ce2e-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009546209s
STEP: Saw pod success
Sep  3 09:38:52.301: INFO: Pod "downwardapi-volume-a2925a00-ce2e-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 09:38:52.304: INFO: Trying to get logs from node 10.0.0.9 pod downwardapi-volume-a2925a00-ce2e-11e9-a824-e6b94fc13bb4 container client-container: <nil>
STEP: delete the pod
Sep  3 09:38:52.336: INFO: Waiting for pod downwardapi-volume-a2925a00-ce2e-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 09:38:52.339: INFO: Pod downwardapi-volume-a2925a00-ce2e-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:38:52.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9616" for this suite.
Sep  3 09:38:58.365: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:38:58.563: INFO: namespace downward-api-9616 deletion completed in 6.218830946s

• [SLOW TEST:8.341 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] version v1
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:38:58.563: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-mfws5 in namespace proxy-7830
I0903 09:38:58.648692      16 runners.go:184] Created replication controller with name: proxy-service-mfws5, namespace: proxy-7830, replica count: 1
I0903 09:38:59.699034      16 runners.go:184] proxy-service-mfws5 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0903 09:39:00.699187      16 runners.go:184] proxy-service-mfws5 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0903 09:39:01.699318      16 runners.go:184] proxy-service-mfws5 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0903 09:39:02.699463      16 runners.go:184] proxy-service-mfws5 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0903 09:39:03.699626      16 runners.go:184] proxy-service-mfws5 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0903 09:39:04.699763      16 runners.go:184] proxy-service-mfws5 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0903 09:39:05.699935      16 runners.go:184] proxy-service-mfws5 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0903 09:39:06.700144      16 runners.go:184] proxy-service-mfws5 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0903 09:39:07.700315      16 runners.go:184] proxy-service-mfws5 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0903 09:39:08.700470      16 runners.go:184] proxy-service-mfws5 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0903 09:39:09.700625      16 runners.go:184] proxy-service-mfws5 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep  3 09:39:09.706: INFO: setup took 11.083679872s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Sep  3 09:39:09.765: INFO: (0) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:160/proxy/: foo (200; 58.460966ms)
Sep  3 09:39:09.768: INFO: (0) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:1080/proxy/rewriteme">test<... (200; 62.179841ms)
Sep  3 09:39:09.768: INFO: (0) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:160/proxy/: foo (200; 61.712145ms)
Sep  3 09:39:09.769: INFO: (0) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:1080/proxy/rewriteme">... (200; 62.27115ms)
Sep  3 09:39:09.769: INFO: (0) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:162/proxy/: bar (200; 63.130985ms)
Sep  3 09:39:09.769: INFO: (0) /api/v1/namespaces/proxy-7830/services/http:proxy-service-mfws5:portname1/proxy/: foo (200; 62.372619ms)
Sep  3 09:39:09.769: INFO: (0) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:162/proxy/: bar (200; 63.112826ms)
Sep  3 09:39:09.771: INFO: (0) /api/v1/namespaces/proxy-7830/services/proxy-service-mfws5:portname2/proxy/: bar (200; 64.341215ms)
Sep  3 09:39:09.771: INFO: (0) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk/proxy/rewriteme">test</a> (200; 65.166513ms)
Sep  3 09:39:09.771: INFO: (0) /api/v1/namespaces/proxy-7830/services/http:proxy-service-mfws5:portname2/proxy/: bar (200; 64.546089ms)
Sep  3 09:39:09.772: INFO: (0) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:460/proxy/: tls baz (200; 65.737429ms)
Sep  3 09:39:09.773: INFO: (0) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:462/proxy/: tls qux (200; 66.552938ms)
Sep  3 09:39:09.773: INFO: (0) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:443/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:443/proxy/tlsrewritem... (200; 66.711658ms)
Sep  3 09:39:09.773: INFO: (0) /api/v1/namespaces/proxy-7830/services/proxy-service-mfws5:portname1/proxy/: foo (200; 67.098552ms)
Sep  3 09:39:09.776: INFO: (0) /api/v1/namespaces/proxy-7830/services/https:proxy-service-mfws5:tlsportname2/proxy/: tls qux (200; 69.805493ms)
Sep  3 09:39:09.776: INFO: (0) /api/v1/namespaces/proxy-7830/services/https:proxy-service-mfws5:tlsportname1/proxy/: tls baz (200; 69.263486ms)
Sep  3 09:39:09.781: INFO: (1) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:162/proxy/: bar (200; 4.982201ms)
Sep  3 09:39:09.781: INFO: (1) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:443/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:443/proxy/tlsrewritem... (200; 5.252031ms)
Sep  3 09:39:09.781: INFO: (1) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:162/proxy/: bar (200; 5.169061ms)
Sep  3 09:39:09.782: INFO: (1) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk/proxy/rewriteme">test</a> (200; 5.165924ms)
Sep  3 09:39:09.783: INFO: (1) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:1080/proxy/rewriteme">test<... (200; 6.000989ms)
Sep  3 09:39:09.784: INFO: (1) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:160/proxy/: foo (200; 6.801805ms)
Sep  3 09:39:09.784: INFO: (1) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:462/proxy/: tls qux (200; 7.215005ms)
Sep  3 09:39:09.784: INFO: (1) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:460/proxy/: tls baz (200; 7.380422ms)
Sep  3 09:39:09.784: INFO: (1) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:1080/proxy/rewriteme">... (200; 7.213102ms)
Sep  3 09:39:09.784: INFO: (1) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:160/proxy/: foo (200; 7.331539ms)
Sep  3 09:39:09.784: INFO: (1) /api/v1/namespaces/proxy-7830/services/proxy-service-mfws5:portname2/proxy/: bar (200; 8.016881ms)
Sep  3 09:39:09.785: INFO: (1) /api/v1/namespaces/proxy-7830/services/http:proxy-service-mfws5:portname2/proxy/: bar (200; 8.560142ms)
Sep  3 09:39:09.785: INFO: (1) /api/v1/namespaces/proxy-7830/services/https:proxy-service-mfws5:tlsportname2/proxy/: tls qux (200; 8.90657ms)
Sep  3 09:39:09.787: INFO: (1) /api/v1/namespaces/proxy-7830/services/proxy-service-mfws5:portname1/proxy/: foo (200; 9.901176ms)
Sep  3 09:39:09.787: INFO: (1) /api/v1/namespaces/proxy-7830/services/https:proxy-service-mfws5:tlsportname1/proxy/: tls baz (200; 10.007851ms)
Sep  3 09:39:09.787: INFO: (1) /api/v1/namespaces/proxy-7830/services/http:proxy-service-mfws5:portname1/proxy/: foo (200; 10.584599ms)
Sep  3 09:39:09.793: INFO: (2) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:162/proxy/: bar (200; 5.54349ms)
Sep  3 09:39:09.793: INFO: (2) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:462/proxy/: tls qux (200; 5.721787ms)
Sep  3 09:39:09.794: INFO: (2) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:160/proxy/: foo (200; 6.054712ms)
Sep  3 09:39:09.794: INFO: (2) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:443/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:443/proxy/tlsrewritem... (200; 6.123344ms)
Sep  3 09:39:09.794: INFO: (2) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:1080/proxy/rewriteme">... (200; 6.231606ms)
Sep  3 09:39:09.794: INFO: (2) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:160/proxy/: foo (200; 6.245754ms)
Sep  3 09:39:09.794: INFO: (2) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:162/proxy/: bar (200; 6.649628ms)
Sep  3 09:39:09.794: INFO: (2) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:1080/proxy/rewriteme">test<... (200; 6.697093ms)
Sep  3 09:39:09.795: INFO: (2) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk/proxy/rewriteme">test</a> (200; 6.672145ms)
Sep  3 09:39:09.795: INFO: (2) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:460/proxy/: tls baz (200; 7.060472ms)
Sep  3 09:39:09.797: INFO: (2) /api/v1/namespaces/proxy-7830/services/https:proxy-service-mfws5:tlsportname1/proxy/: tls baz (200; 9.540382ms)
Sep  3 09:39:09.797: INFO: (2) /api/v1/namespaces/proxy-7830/services/https:proxy-service-mfws5:tlsportname2/proxy/: tls qux (200; 9.59494ms)
Sep  3 09:39:09.798: INFO: (2) /api/v1/namespaces/proxy-7830/services/http:proxy-service-mfws5:portname2/proxy/: bar (200; 10.151719ms)
Sep  3 09:39:09.798: INFO: (2) /api/v1/namespaces/proxy-7830/services/http:proxy-service-mfws5:portname1/proxy/: foo (200; 10.352174ms)
Sep  3 09:39:09.798: INFO: (2) /api/v1/namespaces/proxy-7830/services/proxy-service-mfws5:portname2/proxy/: bar (200; 10.671387ms)
Sep  3 09:39:09.798: INFO: (2) /api/v1/namespaces/proxy-7830/services/proxy-service-mfws5:portname1/proxy/: foo (200; 10.620774ms)
Sep  3 09:39:09.806: INFO: (3) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:462/proxy/: tls qux (200; 7.557723ms)
Sep  3 09:39:09.806: INFO: (3) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:1080/proxy/rewriteme">test<... (200; 7.289239ms)
Sep  3 09:39:09.806: INFO: (3) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:162/proxy/: bar (200; 7.49362ms)
Sep  3 09:39:09.806: INFO: (3) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk/proxy/rewriteme">test</a> (200; 7.712097ms)
Sep  3 09:39:09.807: INFO: (3) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:160/proxy/: foo (200; 7.909938ms)
Sep  3 09:39:09.807: INFO: (3) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:160/proxy/: foo (200; 7.660368ms)
Sep  3 09:39:09.807: INFO: (3) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:162/proxy/: bar (200; 8.256561ms)
Sep  3 09:39:09.807: INFO: (3) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:460/proxy/: tls baz (200; 7.847804ms)
Sep  3 09:39:09.807: INFO: (3) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:1080/proxy/rewriteme">... (200; 8.075622ms)
Sep  3 09:39:09.807: INFO: (3) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:443/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:443/proxy/tlsrewritem... (200; 7.861992ms)
Sep  3 09:39:09.808: INFO: (3) /api/v1/namespaces/proxy-7830/services/proxy-service-mfws5:portname2/proxy/: bar (200; 9.881789ms)
Sep  3 09:39:09.811: INFO: (3) /api/v1/namespaces/proxy-7830/services/proxy-service-mfws5:portname1/proxy/: foo (200; 11.844332ms)
Sep  3 09:39:09.811: INFO: (3) /api/v1/namespaces/proxy-7830/services/http:proxy-service-mfws5:portname2/proxy/: bar (200; 12.329151ms)
Sep  3 09:39:09.811: INFO: (3) /api/v1/namespaces/proxy-7830/services/http:proxy-service-mfws5:portname1/proxy/: foo (200; 12.15581ms)
Sep  3 09:39:09.811: INFO: (3) /api/v1/namespaces/proxy-7830/services/https:proxy-service-mfws5:tlsportname1/proxy/: tls baz (200; 12.152141ms)
Sep  3 09:39:09.811: INFO: (3) /api/v1/namespaces/proxy-7830/services/https:proxy-service-mfws5:tlsportname2/proxy/: tls qux (200; 12.734337ms)
Sep  3 09:39:09.815: INFO: (4) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:162/proxy/: bar (200; 3.800101ms)
Sep  3 09:39:09.816: INFO: (4) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk/proxy/rewriteme">test</a> (200; 3.983983ms)
Sep  3 09:39:09.816: INFO: (4) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:1080/proxy/rewriteme">test<... (200; 4.08609ms)
Sep  3 09:39:09.816: INFO: (4) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:160/proxy/: foo (200; 4.041331ms)
Sep  3 09:39:09.816: INFO: (4) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:462/proxy/: tls qux (200; 3.769489ms)
Sep  3 09:39:09.816: INFO: (4) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:162/proxy/: bar (200; 4.297227ms)
Sep  3 09:39:09.817: INFO: (4) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:1080/proxy/rewriteme">... (200; 4.595961ms)
Sep  3 09:39:09.817: INFO: (4) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:443/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:443/proxy/tlsrewritem... (200; 4.575393ms)
Sep  3 09:39:09.817: INFO: (4) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:160/proxy/: foo (200; 4.634942ms)
Sep  3 09:39:09.817: INFO: (4) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:460/proxy/: tls baz (200; 4.814498ms)
Sep  3 09:39:09.821: INFO: (4) /api/v1/namespaces/proxy-7830/services/http:proxy-service-mfws5:portname1/proxy/: foo (200; 9.396714ms)
Sep  3 09:39:09.821: INFO: (4) /api/v1/namespaces/proxy-7830/services/proxy-service-mfws5:portname1/proxy/: foo (200; 8.953374ms)
Sep  3 09:39:09.821: INFO: (4) /api/v1/namespaces/proxy-7830/services/https:proxy-service-mfws5:tlsportname2/proxy/: tls qux (200; 9.462312ms)
Sep  3 09:39:09.821: INFO: (4) /api/v1/namespaces/proxy-7830/services/proxy-service-mfws5:portname2/proxy/: bar (200; 9.8158ms)
Sep  3 09:39:09.821: INFO: (4) /api/v1/namespaces/proxy-7830/services/http:proxy-service-mfws5:portname2/proxy/: bar (200; 10.004343ms)
Sep  3 09:39:09.823: INFO: (4) /api/v1/namespaces/proxy-7830/services/https:proxy-service-mfws5:tlsportname1/proxy/: tls baz (200; 11.190019ms)
Sep  3 09:39:09.827: INFO: (5) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:162/proxy/: bar (200; 3.959729ms)
Sep  3 09:39:09.828: INFO: (5) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk/proxy/rewriteme">test</a> (200; 4.662682ms)
Sep  3 09:39:09.828: INFO: (5) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:1080/proxy/rewriteme">test<... (200; 4.618544ms)
Sep  3 09:39:09.829: INFO: (5) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:162/proxy/: bar (200; 4.770552ms)
Sep  3 09:39:09.829: INFO: (5) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:462/proxy/: tls qux (200; 4.209986ms)
Sep  3 09:39:09.829: INFO: (5) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:460/proxy/: tls baz (200; 4.639814ms)
Sep  3 09:39:09.829: INFO: (5) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:160/proxy/: foo (200; 5.159042ms)
Sep  3 09:39:09.829: INFO: (5) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:160/proxy/: foo (200; 4.667889ms)
Sep  3 09:39:09.829: INFO: (5) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:1080/proxy/rewriteme">... (200; 4.986561ms)
Sep  3 09:39:09.829: INFO: (5) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:443/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:443/proxy/tlsrewritem... (200; 4.663449ms)
Sep  3 09:39:09.835: INFO: (5) /api/v1/namespaces/proxy-7830/services/https:proxy-service-mfws5:tlsportname2/proxy/: tls qux (200; 11.500887ms)
Sep  3 09:39:09.838: INFO: (5) /api/v1/namespaces/proxy-7830/services/proxy-service-mfws5:portname1/proxy/: foo (200; 14.022257ms)
Sep  3 09:39:09.839: INFO: (5) /api/v1/namespaces/proxy-7830/services/http:proxy-service-mfws5:portname1/proxy/: foo (200; 14.728048ms)
Sep  3 09:39:09.839: INFO: (5) /api/v1/namespaces/proxy-7830/services/http:proxy-service-mfws5:portname2/proxy/: bar (200; 14.858762ms)
Sep  3 09:39:09.840: INFO: (5) /api/v1/namespaces/proxy-7830/services/proxy-service-mfws5:portname2/proxy/: bar (200; 15.215568ms)
Sep  3 09:39:09.840: INFO: (5) /api/v1/namespaces/proxy-7830/services/https:proxy-service-mfws5:tlsportname1/proxy/: tls baz (200; 15.538487ms)
Sep  3 09:39:09.844: INFO: (6) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:460/proxy/: tls baz (200; 4.006826ms)
Sep  3 09:39:09.863: INFO: (6) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:160/proxy/: foo (200; 23.147208ms)
Sep  3 09:39:09.863: INFO: (6) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:462/proxy/: tls qux (200; 23.417943ms)
Sep  3 09:39:09.864: INFO: (6) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:1080/proxy/rewriteme">... (200; 23.01508ms)
Sep  3 09:39:09.864: INFO: (6) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:160/proxy/: foo (200; 23.323167ms)
Sep  3 09:39:09.864: INFO: (6) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:162/proxy/: bar (200; 23.539528ms)
Sep  3 09:39:09.864: INFO: (6) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:443/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:443/proxy/tlsrewritem... (200; 23.946454ms)
Sep  3 09:39:09.864: INFO: (6) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:1080/proxy/rewriteme">test<... (200; 23.382365ms)
Sep  3 09:39:09.884: INFO: (6) /api/v1/namespaces/proxy-7830/services/https:proxy-service-mfws5:tlsportname2/proxy/: tls qux (200; 43.584546ms)
Sep  3 09:39:09.884: INFO: (6) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk/proxy/rewriteme">test</a> (200; 43.610292ms)
Sep  3 09:39:09.885: INFO: (6) /api/v1/namespaces/proxy-7830/services/https:proxy-service-mfws5:tlsportname1/proxy/: tls baz (200; 45.176986ms)
Sep  3 09:39:09.885: INFO: (6) /api/v1/namespaces/proxy-7830/services/proxy-service-mfws5:portname1/proxy/: foo (200; 44.610111ms)
Sep  3 09:39:09.885: INFO: (6) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:162/proxy/: bar (200; 44.882926ms)
Sep  3 09:39:09.885: INFO: (6) /api/v1/namespaces/proxy-7830/services/http:proxy-service-mfws5:portname2/proxy/: bar (200; 44.986189ms)
Sep  3 09:39:09.885: INFO: (6) /api/v1/namespaces/proxy-7830/services/http:proxy-service-mfws5:portname1/proxy/: foo (200; 45.411979ms)
Sep  3 09:39:09.886: INFO: (6) /api/v1/namespaces/proxy-7830/services/proxy-service-mfws5:portname2/proxy/: bar (200; 45.327925ms)
Sep  3 09:39:09.892: INFO: (7) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:460/proxy/: tls baz (200; 6.845042ms)
Sep  3 09:39:09.894: INFO: (7) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:462/proxy/: tls qux (200; 8.070893ms)
Sep  3 09:39:09.894: INFO: (7) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:162/proxy/: bar (200; 8.562395ms)
Sep  3 09:39:09.894: INFO: (7) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:1080/proxy/rewriteme">test<... (200; 8.416441ms)
Sep  3 09:39:09.894: INFO: (7) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk/proxy/rewriteme">test</a> (200; 8.506803ms)
Sep  3 09:39:09.894: INFO: (7) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:162/proxy/: bar (200; 8.720065ms)
Sep  3 09:39:09.894: INFO: (7) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:160/proxy/: foo (200; 8.785762ms)
Sep  3 09:39:09.895: INFO: (7) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:160/proxy/: foo (200; 8.493036ms)
Sep  3 09:39:09.895: INFO: (7) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:1080/proxy/rewriteme">... (200; 8.711194ms)
Sep  3 09:39:09.895: INFO: (7) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:443/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:443/proxy/tlsrewritem... (200; 9.115928ms)
Sep  3 09:39:09.895: INFO: (7) /api/v1/namespaces/proxy-7830/services/proxy-service-mfws5:portname1/proxy/: foo (200; 9.238818ms)
Sep  3 09:39:09.897: INFO: (7) /api/v1/namespaces/proxy-7830/services/https:proxy-service-mfws5:tlsportname2/proxy/: tls qux (200; 11.313483ms)
Sep  3 09:39:09.897: INFO: (7) /api/v1/namespaces/proxy-7830/services/http:proxy-service-mfws5:portname2/proxy/: bar (200; 11.252988ms)
Sep  3 09:39:09.898: INFO: (7) /api/v1/namespaces/proxy-7830/services/http:proxy-service-mfws5:portname1/proxy/: foo (200; 11.665957ms)
Sep  3 09:39:09.898: INFO: (7) /api/v1/namespaces/proxy-7830/services/proxy-service-mfws5:portname2/proxy/: bar (200; 11.635003ms)
Sep  3 09:39:09.898: INFO: (7) /api/v1/namespaces/proxy-7830/services/https:proxy-service-mfws5:tlsportname1/proxy/: tls baz (200; 11.68325ms)
Sep  3 09:39:09.901: INFO: (8) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:160/proxy/: foo (200; 3.608057ms)
Sep  3 09:39:09.902: INFO: (8) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:460/proxy/: tls baz (200; 4.01773ms)
Sep  3 09:39:09.902: INFO: (8) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:462/proxy/: tls qux (200; 4.319954ms)
Sep  3 09:39:09.902: INFO: (8) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:1080/proxy/rewriteme">... (200; 4.546959ms)
Sep  3 09:39:09.903: INFO: (8) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:162/proxy/: bar (200; 3.926501ms)
Sep  3 09:39:09.903: INFO: (8) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:160/proxy/: foo (200; 4.530482ms)
Sep  3 09:39:09.903: INFO: (8) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk/proxy/rewriteme">test</a> (200; 4.337467ms)
Sep  3 09:39:09.903: INFO: (8) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:162/proxy/: bar (200; 4.508936ms)
Sep  3 09:39:09.903: INFO: (8) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:443/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:443/proxy/tlsrewritem... (200; 4.759655ms)
Sep  3 09:39:09.903: INFO: (8) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:1080/proxy/rewriteme">test<... (200; 4.412598ms)
Sep  3 09:39:09.905: INFO: (8) /api/v1/namespaces/proxy-7830/services/proxy-service-mfws5:portname1/proxy/: foo (200; 6.951168ms)
Sep  3 09:39:09.910: INFO: (8) /api/v1/namespaces/proxy-7830/services/http:proxy-service-mfws5:portname2/proxy/: bar (200; 11.537097ms)
Sep  3 09:39:09.910: INFO: (8) /api/v1/namespaces/proxy-7830/services/http:proxy-service-mfws5:portname1/proxy/: foo (200; 11.97336ms)
Sep  3 09:39:09.910: INFO: (8) /api/v1/namespaces/proxy-7830/services/https:proxy-service-mfws5:tlsportname1/proxy/: tls baz (200; 11.887085ms)
Sep  3 09:39:09.910: INFO: (8) /api/v1/namespaces/proxy-7830/services/proxy-service-mfws5:portname2/proxy/: bar (200; 11.681255ms)
Sep  3 09:39:09.910: INFO: (8) /api/v1/namespaces/proxy-7830/services/https:proxy-service-mfws5:tlsportname2/proxy/: tls qux (200; 11.367284ms)
Sep  3 09:39:09.915: INFO: (9) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk/proxy/rewriteme">test</a> (200; 4.573102ms)
Sep  3 09:39:09.915: INFO: (9) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:162/proxy/: bar (200; 4.890547ms)
Sep  3 09:39:09.915: INFO: (9) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:1080/proxy/rewriteme">test<... (200; 4.533244ms)
Sep  3 09:39:09.916: INFO: (9) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:160/proxy/: foo (200; 5.676759ms)
Sep  3 09:39:09.916: INFO: (9) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:162/proxy/: bar (200; 5.616342ms)
Sep  3 09:39:09.917: INFO: (9) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:460/proxy/: tls baz (200; 5.811375ms)
Sep  3 09:39:09.917: INFO: (9) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:160/proxy/: foo (200; 5.71723ms)
Sep  3 09:39:09.932: INFO: (9) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:443/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:443/proxy/tlsrewritem... (200; 20.921407ms)
Sep  3 09:39:09.932: INFO: (9) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:1080/proxy/rewriteme">... (200; 21.355077ms)
Sep  3 09:39:09.933: INFO: (9) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:462/proxy/: tls qux (200; 21.575516ms)
Sep  3 09:39:09.933: INFO: (9) /api/v1/namespaces/proxy-7830/services/proxy-service-mfws5:portname2/proxy/: bar (200; 21.564285ms)
Sep  3 09:39:09.933: INFO: (9) /api/v1/namespaces/proxy-7830/services/http:proxy-service-mfws5:portname2/proxy/: bar (200; 21.444462ms)
Sep  3 09:39:09.933: INFO: (9) /api/v1/namespaces/proxy-7830/services/https:proxy-service-mfws5:tlsportname1/proxy/: tls baz (200; 22.066438ms)
Sep  3 09:39:09.933: INFO: (9) /api/v1/namespaces/proxy-7830/services/https:proxy-service-mfws5:tlsportname2/proxy/: tls qux (200; 22.56425ms)
Sep  3 09:39:09.933: INFO: (9) /api/v1/namespaces/proxy-7830/services/proxy-service-mfws5:portname1/proxy/: foo (200; 22.137991ms)
Sep  3 09:39:09.933: INFO: (9) /api/v1/namespaces/proxy-7830/services/http:proxy-service-mfws5:portname1/proxy/: foo (200; 22.03057ms)
Sep  3 09:39:09.937: INFO: (10) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:162/proxy/: bar (200; 3.836998ms)
Sep  3 09:39:09.937: INFO: (10) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:1080/proxy/rewriteme">test<... (200; 4.193695ms)
Sep  3 09:39:09.938: INFO: (10) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:162/proxy/: bar (200; 4.502508ms)
Sep  3 09:39:09.938: INFO: (10) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk/proxy/rewriteme">test</a> (200; 5.288014ms)
Sep  3 09:39:09.939: INFO: (10) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:160/proxy/: foo (200; 5.227383ms)
Sep  3 09:39:09.939: INFO: (10) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:462/proxy/: tls qux (200; 4.973705ms)
Sep  3 09:39:09.939: INFO: (10) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:160/proxy/: foo (200; 5.12238ms)
Sep  3 09:39:09.939: INFO: (10) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:1080/proxy/rewriteme">... (200; 5.189678ms)
Sep  3 09:39:09.939: INFO: (10) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:460/proxy/: tls baz (200; 5.16446ms)
Sep  3 09:39:09.939: INFO: (10) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:443/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:443/proxy/tlsrewritem... (200; 5.257827ms)
Sep  3 09:39:09.943: INFO: (10) /api/v1/namespaces/proxy-7830/services/https:proxy-service-mfws5:tlsportname2/proxy/: tls qux (200; 9.563479ms)
Sep  3 09:39:09.943: INFO: (10) /api/v1/namespaces/proxy-7830/services/proxy-service-mfws5:portname1/proxy/: foo (200; 9.759568ms)
Sep  3 09:39:09.943: INFO: (10) /api/v1/namespaces/proxy-7830/services/http:proxy-service-mfws5:portname1/proxy/: foo (200; 9.527786ms)
Sep  3 09:39:09.944: INFO: (10) /api/v1/namespaces/proxy-7830/services/http:proxy-service-mfws5:portname2/proxy/: bar (200; 9.86947ms)
Sep  3 09:39:09.944: INFO: (10) /api/v1/namespaces/proxy-7830/services/https:proxy-service-mfws5:tlsportname1/proxy/: tls baz (200; 9.838464ms)
Sep  3 09:39:09.944: INFO: (10) /api/v1/namespaces/proxy-7830/services/proxy-service-mfws5:portname2/proxy/: bar (200; 10.143972ms)
Sep  3 09:39:09.948: INFO: (11) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:460/proxy/: tls baz (200; 4.103438ms)
Sep  3 09:39:09.949: INFO: (11) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:162/proxy/: bar (200; 4.356443ms)
Sep  3 09:39:09.949: INFO: (11) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:1080/proxy/rewriteme">... (200; 4.977631ms)
Sep  3 09:39:09.949: INFO: (11) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk/proxy/rewriteme">test</a> (200; 5.27413ms)
Sep  3 09:39:09.949: INFO: (11) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:443/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:443/proxy/tlsrewritem... (200; 4.915199ms)
Sep  3 09:39:09.949: INFO: (11) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:160/proxy/: foo (200; 5.212327ms)
Sep  3 09:39:09.950: INFO: (11) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:462/proxy/: tls qux (200; 5.177764ms)
Sep  3 09:39:09.950: INFO: (11) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:1080/proxy/rewriteme">test<... (200; 5.051014ms)
Sep  3 09:39:09.950: INFO: (11) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:160/proxy/: foo (200; 4.990679ms)
Sep  3 09:39:09.950: INFO: (11) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:162/proxy/: bar (200; 4.887672ms)
Sep  3 09:39:09.951: INFO: (11) /api/v1/namespaces/proxy-7830/services/proxy-service-mfws5:portname1/proxy/: foo (200; 6.508368ms)
Sep  3 09:39:09.952: INFO: (11) /api/v1/namespaces/proxy-7830/services/https:proxy-service-mfws5:tlsportname1/proxy/: tls baz (200; 7.276575ms)
Sep  3 09:39:09.952: INFO: (11) /api/v1/namespaces/proxy-7830/services/http:proxy-service-mfws5:portname2/proxy/: bar (200; 7.616269ms)
Sep  3 09:39:09.952: INFO: (11) /api/v1/namespaces/proxy-7830/services/http:proxy-service-mfws5:portname1/proxy/: foo (200; 7.962588ms)
Sep  3 09:39:09.952: INFO: (11) /api/v1/namespaces/proxy-7830/services/proxy-service-mfws5:portname2/proxy/: bar (200; 7.76835ms)
Sep  3 09:39:09.953: INFO: (11) /api/v1/namespaces/proxy-7830/services/https:proxy-service-mfws5:tlsportname2/proxy/: tls qux (200; 7.560248ms)
Sep  3 09:39:09.957: INFO: (12) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:162/proxy/: bar (200; 3.910956ms)
Sep  3 09:39:09.957: INFO: (12) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:460/proxy/: tls baz (200; 3.988752ms)
Sep  3 09:39:09.957: INFO: (12) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:1080/proxy/rewriteme">... (200; 4.217476ms)
Sep  3 09:39:09.958: INFO: (12) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:1080/proxy/rewriteme">test<... (200; 4.334556ms)
Sep  3 09:39:09.958: INFO: (12) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:462/proxy/: tls qux (200; 4.752143ms)
Sep  3 09:39:09.958: INFO: (12) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk/proxy/rewriteme">test</a> (200; 4.478603ms)
Sep  3 09:39:09.958: INFO: (12) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:160/proxy/: foo (200; 4.699231ms)
Sep  3 09:39:09.958: INFO: (12) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:443/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:443/proxy/tlsrewritem... (200; 5.286757ms)
Sep  3 09:39:09.959: INFO: (12) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:160/proxy/: foo (200; 5.403311ms)
Sep  3 09:39:09.959: INFO: (12) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:162/proxy/: bar (200; 5.151774ms)
Sep  3 09:39:09.961: INFO: (12) /api/v1/namespaces/proxy-7830/services/proxy-service-mfws5:portname1/proxy/: foo (200; 8.305051ms)
Sep  3 09:39:09.963: INFO: (12) /api/v1/namespaces/proxy-7830/services/https:proxy-service-mfws5:tlsportname1/proxy/: tls baz (200; 9.923144ms)
Sep  3 09:39:09.963: INFO: (12) /api/v1/namespaces/proxy-7830/services/https:proxy-service-mfws5:tlsportname2/proxy/: tls qux (200; 9.5906ms)
Sep  3 09:39:09.963: INFO: (12) /api/v1/namespaces/proxy-7830/services/http:proxy-service-mfws5:portname1/proxy/: foo (200; 10.167926ms)
Sep  3 09:39:09.963: INFO: (12) /api/v1/namespaces/proxy-7830/services/proxy-service-mfws5:portname2/proxy/: bar (200; 9.96683ms)
Sep  3 09:39:09.963: INFO: (12) /api/v1/namespaces/proxy-7830/services/http:proxy-service-mfws5:portname2/proxy/: bar (200; 9.966232ms)
Sep  3 09:39:09.967: INFO: (13) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:460/proxy/: tls baz (200; 3.736527ms)
Sep  3 09:39:09.968: INFO: (13) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:462/proxy/: tls qux (200; 4.227286ms)
Sep  3 09:39:09.968: INFO: (13) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:160/proxy/: foo (200; 4.516692ms)
Sep  3 09:39:09.969: INFO: (13) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:443/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:443/proxy/tlsrewritem... (200; 4.803532ms)
Sep  3 09:39:09.969: INFO: (13) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk/proxy/rewriteme">test</a> (200; 4.768258ms)
Sep  3 09:39:09.969: INFO: (13) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:162/proxy/: bar (200; 4.948176ms)
Sep  3 09:39:09.971: INFO: (13) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:1080/proxy/rewriteme">... (200; 6.186863ms)
Sep  3 09:39:09.971: INFO: (13) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:162/proxy/: bar (200; 6.918764ms)
Sep  3 09:39:09.971: INFO: (13) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:160/proxy/: foo (200; 6.68387ms)
Sep  3 09:39:09.977: INFO: (13) /api/v1/namespaces/proxy-7830/services/http:proxy-service-mfws5:portname1/proxy/: foo (200; 13.81739ms)
Sep  3 09:39:09.978: INFO: (13) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:1080/proxy/rewriteme">test<... (200; 13.307938ms)
Sep  3 09:39:09.978: INFO: (13) /api/v1/namespaces/proxy-7830/services/http:proxy-service-mfws5:portname2/proxy/: bar (200; 13.717065ms)
Sep  3 09:39:09.978: INFO: (13) /api/v1/namespaces/proxy-7830/services/proxy-service-mfws5:portname2/proxy/: bar (200; 13.861101ms)
Sep  3 09:39:09.978: INFO: (13) /api/v1/namespaces/proxy-7830/services/https:proxy-service-mfws5:tlsportname1/proxy/: tls baz (200; 14.216831ms)
Sep  3 09:39:09.980: INFO: (13) /api/v1/namespaces/proxy-7830/services/https:proxy-service-mfws5:tlsportname2/proxy/: tls qux (200; 16.309394ms)
Sep  3 09:39:09.981: INFO: (13) /api/v1/namespaces/proxy-7830/services/proxy-service-mfws5:portname1/proxy/: foo (200; 16.078717ms)
Sep  3 09:39:09.990: INFO: (14) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:462/proxy/: tls qux (200; 8.82865ms)
Sep  3 09:39:09.990: INFO: (14) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:160/proxy/: foo (200; 8.636618ms)
Sep  3 09:39:09.990: INFO: (14) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:443/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:443/proxy/tlsrewritem... (200; 9.334858ms)
Sep  3 09:39:09.990: INFO: (14) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:160/proxy/: foo (200; 9.430775ms)
Sep  3 09:39:09.991: INFO: (14) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:162/proxy/: bar (200; 9.402078ms)
Sep  3 09:39:09.991: INFO: (14) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:1080/proxy/rewriteme">... (200; 9.239144ms)
Sep  3 09:39:09.991: INFO: (14) /api/v1/namespaces/proxy-7830/services/http:proxy-service-mfws5:portname2/proxy/: bar (200; 9.906543ms)
Sep  3 09:39:09.991: INFO: (14) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:1080/proxy/rewriteme">test<... (200; 9.65688ms)
Sep  3 09:39:09.991: INFO: (14) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:162/proxy/: bar (200; 9.538872ms)
Sep  3 09:39:09.992: INFO: (14) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk/proxy/rewriteme">test</a> (200; 10.193765ms)
Sep  3 09:39:09.992: INFO: (14) /api/v1/namespaces/proxy-7830/services/proxy-service-mfws5:portname1/proxy/: foo (200; 11.33244ms)
Sep  3 09:39:09.992: INFO: (14) /api/v1/namespaces/proxy-7830/services/https:proxy-service-mfws5:tlsportname1/proxy/: tls baz (200; 11.246601ms)
Sep  3 09:39:09.992: INFO: (14) /api/v1/namespaces/proxy-7830/services/proxy-service-mfws5:portname2/proxy/: bar (200; 10.751566ms)
Sep  3 09:39:09.992: INFO: (14) /api/v1/namespaces/proxy-7830/services/https:proxy-service-mfws5:tlsportname2/proxy/: tls qux (200; 10.321676ms)
Sep  3 09:39:09.992: INFO: (14) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:460/proxy/: tls baz (200; 10.417222ms)
Sep  3 09:39:09.992: INFO: (14) /api/v1/namespaces/proxy-7830/services/http:proxy-service-mfws5:portname1/proxy/: foo (200; 10.995968ms)
Sep  3 09:39:09.997: INFO: (15) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:160/proxy/: foo (200; 4.920353ms)
Sep  3 09:39:09.997: INFO: (15) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:162/proxy/: bar (200; 5.012453ms)
Sep  3 09:39:09.998: INFO: (15) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:162/proxy/: bar (200; 5.262215ms)
Sep  3 09:39:09.998: INFO: (15) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:1080/proxy/rewriteme">... (200; 5.065897ms)
Sep  3 09:39:09.998: INFO: (15) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:443/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:443/proxy/tlsrewritem... (200; 5.154924ms)
Sep  3 09:39:09.998: INFO: (15) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk/proxy/rewriteme">test</a> (200; 5.619057ms)
Sep  3 09:39:09.998: INFO: (15) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:460/proxy/: tls baz (200; 5.403957ms)
Sep  3 09:39:09.998: INFO: (15) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:1080/proxy/rewriteme">test<... (200; 5.582169ms)
Sep  3 09:39:09.998: INFO: (15) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:160/proxy/: foo (200; 6.268192ms)
Sep  3 09:39:09.999: INFO: (15) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:462/proxy/: tls qux (200; 6.166431ms)
Sep  3 09:39:10.000: INFO: (15) /api/v1/namespaces/proxy-7830/services/http:proxy-service-mfws5:portname2/proxy/: bar (200; 8.063852ms)
Sep  3 09:39:10.001: INFO: (15) /api/v1/namespaces/proxy-7830/services/https:proxy-service-mfws5:tlsportname2/proxy/: tls qux (200; 8.628085ms)
Sep  3 09:39:10.002: INFO: (15) /api/v1/namespaces/proxy-7830/services/proxy-service-mfws5:portname2/proxy/: bar (200; 9.496613ms)
Sep  3 09:39:10.002: INFO: (15) /api/v1/namespaces/proxy-7830/services/http:proxy-service-mfws5:portname1/proxy/: foo (200; 8.724456ms)
Sep  3 09:39:10.002: INFO: (15) /api/v1/namespaces/proxy-7830/services/proxy-service-mfws5:portname1/proxy/: foo (200; 9.009971ms)
Sep  3 09:39:10.002: INFO: (15) /api/v1/namespaces/proxy-7830/services/https:proxy-service-mfws5:tlsportname1/proxy/: tls baz (200; 8.893529ms)
Sep  3 09:39:10.006: INFO: (16) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:460/proxy/: tls baz (200; 3.75789ms)
Sep  3 09:39:10.006: INFO: (16) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:462/proxy/: tls qux (200; 3.962287ms)
Sep  3 09:39:10.007: INFO: (16) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:160/proxy/: foo (200; 4.353293ms)
Sep  3 09:39:10.019: INFO: (16) /api/v1/namespaces/proxy-7830/services/proxy-service-mfws5:portname1/proxy/: foo (200; 15.651114ms)
Sep  3 09:39:10.019: INFO: (16) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:1080/proxy/rewriteme">... (200; 15.59207ms)
Sep  3 09:39:10.019: INFO: (16) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:1080/proxy/rewriteme">test<... (200; 16.371462ms)
Sep  3 09:39:10.019: INFO: (16) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:443/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:443/proxy/tlsrewritem... (200; 16.701032ms)
Sep  3 09:39:10.019: INFO: (16) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk/proxy/rewriteme">test</a> (200; 16.427029ms)
Sep  3 09:39:10.019: INFO: (16) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:160/proxy/: foo (200; 16.313489ms)
Sep  3 09:39:10.019: INFO: (16) /api/v1/namespaces/proxy-7830/services/http:proxy-service-mfws5:portname1/proxy/: foo (200; 17.272961ms)
Sep  3 09:39:10.019: INFO: (16) /api/v1/namespaces/proxy-7830/services/http:proxy-service-mfws5:portname2/proxy/: bar (200; 16.846708ms)
Sep  3 09:39:10.019: INFO: (16) /api/v1/namespaces/proxy-7830/services/proxy-service-mfws5:portname2/proxy/: bar (200; 16.978209ms)
Sep  3 09:39:10.019: INFO: (16) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:162/proxy/: bar (200; 16.454776ms)
Sep  3 09:39:10.019: INFO: (16) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:162/proxy/: bar (200; 16.704954ms)
Sep  3 09:39:10.019: INFO: (16) /api/v1/namespaces/proxy-7830/services/https:proxy-service-mfws5:tlsportname1/proxy/: tls baz (200; 17.273785ms)
Sep  3 09:39:10.019: INFO: (16) /api/v1/namespaces/proxy-7830/services/https:proxy-service-mfws5:tlsportname2/proxy/: tls qux (200; 16.644485ms)
Sep  3 09:39:10.033: INFO: (17) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk/proxy/rewriteme">test</a> (200; 13.258106ms)
Sep  3 09:39:10.033: INFO: (17) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:162/proxy/: bar (200; 13.454248ms)
Sep  3 09:39:10.034: INFO: (17) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:1080/proxy/rewriteme">test<... (200; 14.085222ms)
Sep  3 09:39:10.034: INFO: (17) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:162/proxy/: bar (200; 13.941827ms)
Sep  3 09:39:10.034: INFO: (17) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:160/proxy/: foo (200; 14.009992ms)
Sep  3 09:39:10.034: INFO: (17) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:1080/proxy/rewriteme">... (200; 13.858842ms)
Sep  3 09:39:10.034: INFO: (17) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:460/proxy/: tls baz (200; 14.084646ms)
Sep  3 09:39:10.034: INFO: (17) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:160/proxy/: foo (200; 13.955494ms)
Sep  3 09:39:10.034: INFO: (17) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:462/proxy/: tls qux (200; 13.864891ms)
Sep  3 09:39:10.034: INFO: (17) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:443/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:443/proxy/tlsrewritem... (200; 13.933583ms)
Sep  3 09:39:10.034: INFO: (17) /api/v1/namespaces/proxy-7830/services/http:proxy-service-mfws5:portname1/proxy/: foo (200; 14.759602ms)
Sep  3 09:39:10.038: INFO: (17) /api/v1/namespaces/proxy-7830/services/http:proxy-service-mfws5:portname2/proxy/: bar (200; 18.134516ms)
Sep  3 09:39:10.038: INFO: (17) /api/v1/namespaces/proxy-7830/services/https:proxy-service-mfws5:tlsportname2/proxy/: tls qux (200; 17.881739ms)
Sep  3 09:39:10.038: INFO: (17) /api/v1/namespaces/proxy-7830/services/https:proxy-service-mfws5:tlsportname1/proxy/: tls baz (200; 18.123043ms)
Sep  3 09:39:10.038: INFO: (17) /api/v1/namespaces/proxy-7830/services/proxy-service-mfws5:portname1/proxy/: foo (200; 18.359758ms)
Sep  3 09:39:10.038: INFO: (17) /api/v1/namespaces/proxy-7830/services/proxy-service-mfws5:portname2/proxy/: bar (200; 18.691814ms)
Sep  3 09:39:10.042: INFO: (18) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:460/proxy/: tls baz (200; 3.833953ms)
Sep  3 09:39:10.043: INFO: (18) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:462/proxy/: tls qux (200; 4.01387ms)
Sep  3 09:39:10.043: INFO: (18) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:162/proxy/: bar (200; 4.487802ms)
Sep  3 09:39:10.043: INFO: (18) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:443/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:443/proxy/tlsrewritem... (200; 4.689354ms)
Sep  3 09:39:10.044: INFO: (18) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:162/proxy/: bar (200; 4.934764ms)
Sep  3 09:39:10.045: INFO: (18) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:160/proxy/: foo (200; 5.766663ms)
Sep  3 09:39:10.045: INFO: (18) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:160/proxy/: foo (200; 5.916589ms)
Sep  3 09:39:10.045: INFO: (18) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk/proxy/rewriteme">test</a> (200; 5.76724ms)
Sep  3 09:39:10.045: INFO: (18) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:1080/proxy/rewriteme">... (200; 5.756357ms)
Sep  3 09:39:10.045: INFO: (18) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:1080/proxy/rewriteme">test<... (200; 5.902089ms)
Sep  3 09:39:10.046: INFO: (18) /api/v1/namespaces/proxy-7830/services/http:proxy-service-mfws5:portname1/proxy/: foo (200; 7.009853ms)
Sep  3 09:39:10.049: INFO: (18) /api/v1/namespaces/proxy-7830/services/https:proxy-service-mfws5:tlsportname1/proxy/: tls baz (200; 10.535969ms)
Sep  3 09:39:10.050: INFO: (18) /api/v1/namespaces/proxy-7830/services/proxy-service-mfws5:portname1/proxy/: foo (200; 10.653099ms)
Sep  3 09:39:10.050: INFO: (18) /api/v1/namespaces/proxy-7830/services/https:proxy-service-mfws5:tlsportname2/proxy/: tls qux (200; 10.685146ms)
Sep  3 09:39:10.050: INFO: (18) /api/v1/namespaces/proxy-7830/services/http:proxy-service-mfws5:portname2/proxy/: bar (200; 11.017694ms)
Sep  3 09:39:10.050: INFO: (18) /api/v1/namespaces/proxy-7830/services/proxy-service-mfws5:portname2/proxy/: bar (200; 11.116151ms)
Sep  3 09:39:10.054: INFO: (19) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:462/proxy/: tls qux (200; 3.968219ms)
Sep  3 09:39:10.063: INFO: (19) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:1080/proxy/rewriteme">test<... (200; 12.87427ms)
Sep  3 09:39:10.063: INFO: (19) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:162/proxy/: bar (200; 12.607972ms)
Sep  3 09:39:10.063: INFO: (19) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk/proxy/rewriteme">test</a> (200; 13.061241ms)
Sep  3 09:39:10.064: INFO: (19) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:162/proxy/: bar (200; 13.352958ms)
Sep  3 09:39:10.064: INFO: (19) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:160/proxy/: foo (200; 13.093458ms)
Sep  3 09:39:10.064: INFO: (19) /api/v1/namespaces/proxy-7830/pods/proxy-service-mfws5-tflkk:160/proxy/: foo (200; 13.287498ms)
Sep  3 09:39:10.064: INFO: (19) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:460/proxy/: tls baz (200; 13.270032ms)
Sep  3 09:39:10.064: INFO: (19) /api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:443/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/https:proxy-service-mfws5-tflkk:443/proxy/tlsrewritem... (200; 13.108434ms)
Sep  3 09:39:10.065: INFO: (19) /api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:1080/proxy/: <a href="/api/v1/namespaces/proxy-7830/pods/http:proxy-service-mfws5-tflkk:1080/proxy/rewriteme">... (200; 13.830934ms)
Sep  3 09:39:10.067: INFO: (19) /api/v1/namespaces/proxy-7830/services/proxy-service-mfws5:portname2/proxy/: bar (200; 17.182603ms)
Sep  3 09:39:10.068: INFO: (19) /api/v1/namespaces/proxy-7830/services/http:proxy-service-mfws5:portname2/proxy/: bar (200; 17.436153ms)
Sep  3 09:39:10.068: INFO: (19) /api/v1/namespaces/proxy-7830/services/https:proxy-service-mfws5:tlsportname1/proxy/: tls baz (200; 17.388329ms)
Sep  3 09:39:10.068: INFO: (19) /api/v1/namespaces/proxy-7830/services/proxy-service-mfws5:portname1/proxy/: foo (200; 17.47176ms)
Sep  3 09:39:10.068: INFO: (19) /api/v1/namespaces/proxy-7830/services/http:proxy-service-mfws5:portname1/proxy/: foo (200; 17.677038ms)
Sep  3 09:39:10.068: INFO: (19) /api/v1/namespaces/proxy-7830/services/https:proxy-service-mfws5:tlsportname2/proxy/: tls qux (200; 18.045924ms)
STEP: deleting ReplicationController proxy-service-mfws5 in namespace proxy-7830, will wait for the garbage collector to delete the pods
Sep  3 09:39:10.140: INFO: Deleting ReplicationController proxy-service-mfws5 took: 13.242116ms
Sep  3 09:39:10.540: INFO: Terminating ReplicationController proxy-service-mfws5 pods took: 400.173875ms
[AfterEach] version v1
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:39:17.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-7830" for this suite.
Sep  3 09:39:23.064: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:39:23.226: INFO: namespace proxy-7830 deletion completed in 6.178217249s

• [SLOW TEST:24.663 seconds]
[sig-network] Proxy
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:39:23.226: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep  3 09:39:23.394: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Sep  3 09:39:23.411: INFO: Number of nodes with available pods: 0
Sep  3 09:39:23.411: INFO: Node 10.0.0.6 is running more than one daemon pod
Sep  3 09:39:24.421: INFO: Number of nodes with available pods: 1
Sep  3 09:39:24.421: INFO: Node 10.0.0.6 is running more than one daemon pod
Sep  3 09:39:25.425: INFO: Number of nodes with available pods: 2
Sep  3 09:39:25.425: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Sep  3 09:39:25.462: INFO: Wrong image for pod: daemon-set-8s4dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  3 09:39:25.462: INFO: Wrong image for pod: daemon-set-sj545. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  3 09:39:26.471: INFO: Wrong image for pod: daemon-set-8s4dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  3 09:39:26.471: INFO: Wrong image for pod: daemon-set-sj545. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  3 09:39:27.471: INFO: Wrong image for pod: daemon-set-8s4dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  3 09:39:27.471: INFO: Pod daemon-set-8s4dn is not available
Sep  3 09:39:27.471: INFO: Wrong image for pod: daemon-set-sj545. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  3 09:39:28.471: INFO: Wrong image for pod: daemon-set-8s4dn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  3 09:39:28.471: INFO: Pod daemon-set-8s4dn is not available
Sep  3 09:39:28.471: INFO: Wrong image for pod: daemon-set-sj545. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  3 09:39:29.471: INFO: Wrong image for pod: daemon-set-sj545. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  3 09:39:30.489: INFO: Wrong image for pod: daemon-set-sj545. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep  3 09:39:30.489: INFO: Pod daemon-set-sj545 is not available
Sep  3 09:39:31.471: INFO: Pod daemon-set-8fssc is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Sep  3 09:39:31.500: INFO: Number of nodes with available pods: 1
Sep  3 09:39:31.500: INFO: Node 10.0.0.6 is running more than one daemon pod
Sep  3 09:39:32.510: INFO: Number of nodes with available pods: 2
Sep  3 09:39:32.510: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1978, will wait for the garbage collector to delete the pods
Sep  3 09:39:32.600: INFO: Deleting DaemonSet.extensions daemon-set took: 12.991081ms
Sep  3 09:39:33.000: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.120516ms
Sep  3 09:39:47.004: INFO: Number of nodes with available pods: 0
Sep  3 09:39:47.004: INFO: Number of running nodes: 0, number of available pods: 0
Sep  3 09:39:47.008: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1978/daemonsets","resourceVersion":"87028702"},"items":null}

Sep  3 09:39:47.012: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1978/pods","resourceVersion":"87028702"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:39:47.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1978" for this suite.
Sep  3 09:39:53.061: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:39:53.232: INFO: namespace daemonsets-1978 deletion completed in 6.199133623s

• [SLOW TEST:30.007 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:39:53.232: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating all guestbook components
Sep  3 09:39:53.322: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Sep  3 09:39:53.322: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 create -f - --namespace=kubectl-6694'
Sep  3 09:39:53.463: INFO: stderr: ""
Sep  3 09:39:53.463: INFO: stdout: "service/redis-slave created\n"
Sep  3 09:39:53.463: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Sep  3 09:39:53.463: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 create -f - --namespace=kubectl-6694'
Sep  3 09:39:53.605: INFO: stderr: ""
Sep  3 09:39:53.605: INFO: stdout: "service/redis-master created\n"
Sep  3 09:39:53.605: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Sep  3 09:39:53.605: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 create -f - --namespace=kubectl-6694'
Sep  3 09:39:53.751: INFO: stderr: ""
Sep  3 09:39:53.751: INFO: stdout: "service/frontend created\n"
Sep  3 09:39:53.751: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Sep  3 09:39:53.751: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 create -f - --namespace=kubectl-6694'
Sep  3 09:39:53.893: INFO: stderr: ""
Sep  3 09:39:53.893: INFO: stdout: "deployment.apps/frontend created\n"
Sep  3 09:39:53.893: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Sep  3 09:39:53.893: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 create -f - --namespace=kubectl-6694'
Sep  3 09:39:54.030: INFO: stderr: ""
Sep  3 09:39:54.030: INFO: stdout: "deployment.apps/redis-master created\n"
Sep  3 09:39:54.030: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Sep  3 09:39:54.030: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 create -f - --namespace=kubectl-6694'
Sep  3 09:39:54.164: INFO: stderr: ""
Sep  3 09:39:54.165: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Sep  3 09:39:54.165: INFO: Waiting for all frontend pods to be Running.
Sep  3 09:40:19.215: INFO: Waiting for frontend to serve content.
Sep  3 09:40:20.233: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection refused [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection refu...', 111)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stream in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Sep  3 09:40:25.251: INFO: Trying to add a new entry to the guestbook.
Sep  3 09:40:25.269: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Sep  3 09:40:25.283: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 delete --grace-period=0 --force -f - --namespace=kubectl-6694'
Sep  3 09:40:25.394: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  3 09:40:25.394: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Sep  3 09:40:25.394: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 delete --grace-period=0 --force -f - --namespace=kubectl-6694'
Sep  3 09:40:25.489: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  3 09:40:25.489: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Sep  3 09:40:25.489: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 delete --grace-period=0 --force -f - --namespace=kubectl-6694'
Sep  3 09:40:25.593: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  3 09:40:25.593: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Sep  3 09:40:25.593: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 delete --grace-period=0 --force -f - --namespace=kubectl-6694'
Sep  3 09:40:25.673: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  3 09:40:25.673: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Sep  3 09:40:25.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 delete --grace-period=0 --force -f - --namespace=kubectl-6694'
Sep  3 09:40:25.748: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  3 09:40:25.748: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Sep  3 09:40:25.748: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 delete --grace-period=0 --force -f - --namespace=kubectl-6694'
Sep  3 09:40:25.838: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep  3 09:40:25.838: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:40:25.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6694" for this suite.
Sep  3 09:41:05.861: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:41:06.058: INFO: namespace kubectl-6694 deletion completed in 40.213732683s

• [SLOW TEST:72.825 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
S
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:41:06.058: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Sep  3 09:41:06.125: INFO: Waiting up to 5m0s for pod "downward-api-f388b2ac-ce2e-11e9-a824-e6b94fc13bb4" in namespace "downward-api-7134" to be "success or failure"
Sep  3 09:41:06.130: INFO: Pod "downward-api-f388b2ac-ce2e-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 5.216281ms
Sep  3 09:41:08.135: INFO: Pod "downward-api-f388b2ac-ce2e-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009684176s
STEP: Saw pod success
Sep  3 09:41:08.135: INFO: Pod "downward-api-f388b2ac-ce2e-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 09:41:08.138: INFO: Trying to get logs from node 10.0.0.6 pod downward-api-f388b2ac-ce2e-11e9-a824-e6b94fc13bb4 container dapi-container: <nil>
STEP: delete the pod
Sep  3 09:41:08.193: INFO: Waiting for pod downward-api-f388b2ac-ce2e-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 09:41:08.196: INFO: Pod downward-api-f388b2ac-ce2e-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:41:08.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7134" for this suite.
Sep  3 09:41:14.270: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:41:14.496: INFO: namespace downward-api-7134 deletion completed in 6.294463334s

• [SLOW TEST:8.438 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:41:14.496: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Sep  3 09:41:14.589: INFO: Waiting up to 5m0s for pod "pod-f8934c80-ce2e-11e9-a824-e6b94fc13bb4" in namespace "emptydir-9917" to be "success or failure"
Sep  3 09:41:14.593: INFO: Pod "pod-f8934c80-ce2e-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.613705ms
Sep  3 09:41:16.601: INFO: Pod "pod-f8934c80-ce2e-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011412964s
STEP: Saw pod success
Sep  3 09:41:16.601: INFO: Pod "pod-f8934c80-ce2e-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 09:41:16.604: INFO: Trying to get logs from node 10.0.0.6 pod pod-f8934c80-ce2e-11e9-a824-e6b94fc13bb4 container test-container: <nil>
STEP: delete the pod
Sep  3 09:41:16.677: INFO: Waiting for pod pod-f8934c80-ce2e-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 09:41:16.680: INFO: Pod pod-f8934c80-ce2e-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:41:16.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9917" for this suite.
Sep  3 09:41:22.708: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:41:22.870: INFO: namespace emptydir-9917 deletion completed in 6.178999259s

• [SLOW TEST:8.374 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:41:22.870: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:41:24.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6642" for this suite.
Sep  3 09:42:05.004: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:42:05.216: INFO: namespace kubelet-test-6642 deletion completed in 40.242176126s

• [SLOW TEST:42.346 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:42:05.216: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on tmpfs
Sep  3 09:42:05.283: INFO: Waiting up to 5m0s for pod "pod-16caf596-ce2f-11e9-a824-e6b94fc13bb4" in namespace "emptydir-2708" to be "success or failure"
Sep  3 09:42:05.286: INFO: Pod "pod-16caf596-ce2f-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.471957ms
Sep  3 09:42:07.292: INFO: Pod "pod-16caf596-ce2f-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009010133s
STEP: Saw pod success
Sep  3 09:42:07.292: INFO: Pod "pod-16caf596-ce2f-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 09:42:07.296: INFO: Trying to get logs from node 10.0.0.6 pod pod-16caf596-ce2f-11e9-a824-e6b94fc13bb4 container test-container: <nil>
STEP: delete the pod
Sep  3 09:42:07.392: INFO: Waiting for pod pod-16caf596-ce2f-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 09:42:07.395: INFO: Pod pod-16caf596-ce2f-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:42:07.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2708" for this suite.
Sep  3 09:42:13.418: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:42:13.603: INFO: namespace emptydir-2708 deletion completed in 6.202744839s

• [SLOW TEST:8.387 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:42:13.603: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-1bcbf4b5-ce2f-11e9-a824-e6b94fc13bb4
STEP: Creating a pod to test consume secrets
Sep  3 09:42:13.687: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-1bcd4216-ce2f-11e9-a824-e6b94fc13bb4" in namespace "projected-6516" to be "success or failure"
Sep  3 09:42:13.691: INFO: Pod "pod-projected-secrets-1bcd4216-ce2f-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.40518ms
Sep  3 09:42:15.695: INFO: Pod "pod-projected-secrets-1bcd4216-ce2f-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007704909s
STEP: Saw pod success
Sep  3 09:42:15.695: INFO: Pod "pod-projected-secrets-1bcd4216-ce2f-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 09:42:15.699: INFO: Trying to get logs from node 10.0.0.9 pod pod-projected-secrets-1bcd4216-ce2f-11e9-a824-e6b94fc13bb4 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep  3 09:42:15.729: INFO: Waiting for pod pod-projected-secrets-1bcd4216-ce2f-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 09:42:15.733: INFO: Pod pod-projected-secrets-1bcd4216-ce2f-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:42:15.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6516" for this suite.
Sep  3 09:42:21.753: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:42:21.911: INFO: namespace projected-6516 deletion completed in 6.174065332s

• [SLOW TEST:8.308 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:42:21.912: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on tmpfs
Sep  3 09:42:21.972: INFO: Waiting up to 5m0s for pod "pod-20bde5fd-ce2f-11e9-a824-e6b94fc13bb4" in namespace "emptydir-937" to be "success or failure"
Sep  3 09:42:21.977: INFO: Pod "pod-20bde5fd-ce2f-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 5.075131ms
Sep  3 09:42:23.982: INFO: Pod "pod-20bde5fd-ce2f-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009575436s
STEP: Saw pod success
Sep  3 09:42:23.982: INFO: Pod "pod-20bde5fd-ce2f-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 09:42:23.985: INFO: Trying to get logs from node 10.0.0.6 pod pod-20bde5fd-ce2f-11e9-a824-e6b94fc13bb4 container test-container: <nil>
STEP: delete the pod
Sep  3 09:42:24.084: INFO: Waiting for pod pod-20bde5fd-ce2f-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 09:42:24.088: INFO: Pod pod-20bde5fd-ce2f-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:42:24.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-937" for this suite.
Sep  3 09:42:30.163: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:42:30.320: INFO: namespace emptydir-937 deletion completed in 6.227046744s

• [SLOW TEST:8.408 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:42:30.320: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:213
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1414
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep  3 09:42:30.381: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-8049'
Sep  3 09:42:30.460: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep  3 09:42:30.460: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Sep  3 09:42:30.466: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Sep  3 09:42:30.475: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Sep  3 09:42:30.484: INFO: scanned /root for discovery docs: <nil>
Sep  3 09:42:30.484: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-8049'
Sep  3 09:42:46.299: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Sep  3 09:42:46.299: INFO: stdout: "Created e2e-test-nginx-rc-6ee6eb6f7cb92caacc6ed9905e07fffc\nScaling up e2e-test-nginx-rc-6ee6eb6f7cb92caacc6ed9905e07fffc from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-6ee6eb6f7cb92caacc6ed9905e07fffc up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-6ee6eb6f7cb92caacc6ed9905e07fffc to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Sep  3 09:42:46.299: INFO: stdout: "Created e2e-test-nginx-rc-6ee6eb6f7cb92caacc6ed9905e07fffc\nScaling up e2e-test-nginx-rc-6ee6eb6f7cb92caacc6ed9905e07fffc from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-6ee6eb6f7cb92caacc6ed9905e07fffc up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-6ee6eb6f7cb92caacc6ed9905e07fffc to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Sep  3 09:42:46.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-8049'
Sep  3 09:42:46.366: INFO: stderr: ""
Sep  3 09:42:46.366: INFO: stdout: "e2e-test-nginx-rc-6ee6eb6f7cb92caacc6ed9905e07fffc-g9tq6 "
Sep  3 09:42:46.366: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 get pods e2e-test-nginx-rc-6ee6eb6f7cb92caacc6ed9905e07fffc-g9tq6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8049'
Sep  3 09:42:46.433: INFO: stderr: ""
Sep  3 09:42:46.433: INFO: stdout: "true"
Sep  3 09:42:46.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 get pods e2e-test-nginx-rc-6ee6eb6f7cb92caacc6ed9905e07fffc-g9tq6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8049'
Sep  3 09:42:46.505: INFO: stderr: ""
Sep  3 09:42:46.505: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Sep  3 09:42:46.505: INFO: e2e-test-nginx-rc-6ee6eb6f7cb92caacc6ed9905e07fffc-g9tq6 is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1420
Sep  3 09:42:46.505: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-356901984 delete rc e2e-test-nginx-rc --namespace=kubectl-8049'
Sep  3 09:42:46.583: INFO: stderr: ""
Sep  3 09:42:46.583: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:42:46.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8049" for this suite.
Sep  3 09:43:10.610: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:43:10.784: INFO: namespace kubectl-8049 deletion completed in 24.195088269s

• [SLOW TEST:40.464 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:43:10.784: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward api env vars
Sep  3 09:43:10.850: INFO: Waiting up to 5m0s for pod "downward-api-3ddfd8e4-ce2f-11e9-a824-e6b94fc13bb4" in namespace "downward-api-14" to be "success or failure"
Sep  3 09:43:10.853: INFO: Pod "downward-api-3ddfd8e4-ce2f-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.41327ms
Sep  3 09:43:12.858: INFO: Pod "downward-api-3ddfd8e4-ce2f-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007727848s
STEP: Saw pod success
Sep  3 09:43:12.858: INFO: Pod "downward-api-3ddfd8e4-ce2f-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 09:43:12.861: INFO: Trying to get logs from node 10.0.0.9 pod downward-api-3ddfd8e4-ce2f-11e9-a824-e6b94fc13bb4 container dapi-container: <nil>
STEP: delete the pod
Sep  3 09:43:12.897: INFO: Waiting for pod downward-api-3ddfd8e4-ce2f-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 09:43:12.900: INFO: Pod downward-api-3ddfd8e4-ce2f-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:43:12.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-14" for this suite.
Sep  3 09:43:18.937: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:43:19.085: INFO: namespace downward-api-14 deletion completed in 6.179631543s

• [SLOW TEST:8.301 seconds]
[sig-node] Downward API
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:43:19.085: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name projected-configmap-test-volume-map-42d2002b-ce2f-11e9-a824-e6b94fc13bb4
STEP: Creating a pod to test consume configMaps
Sep  3 09:43:19.154: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-42d35372-ce2f-11e9-a824-e6b94fc13bb4" in namespace "projected-6844" to be "success or failure"
Sep  3 09:43:19.161: INFO: Pod "pod-projected-configmaps-42d35372-ce2f-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.971983ms
Sep  3 09:43:21.165: INFO: Pod "pod-projected-configmaps-42d35372-ce2f-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01143478s
STEP: Saw pod success
Sep  3 09:43:21.165: INFO: Pod "pod-projected-configmaps-42d35372-ce2f-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 09:43:21.169: INFO: Trying to get logs from node 10.0.0.6 pod pod-projected-configmaps-42d35372-ce2f-11e9-a824-e6b94fc13bb4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep  3 09:43:21.196: INFO: Waiting for pod pod-projected-configmaps-42d35372-ce2f-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 09:43:21.199: INFO: Pod pod-projected-configmaps-42d35372-ce2f-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:43:21.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6844" for this suite.
Sep  3 09:43:27.220: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:43:27.356: INFO: namespace projected-6844 deletion completed in 6.151777856s

• [SLOW TEST:8.271 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:43:27.356: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test substitution in container's command
Sep  3 09:43:27.419: INFO: Waiting up to 5m0s for pod "var-expansion-47c0b54e-ce2f-11e9-a824-e6b94fc13bb4" in namespace "var-expansion-6055" to be "success or failure"
Sep  3 09:43:27.423: INFO: Pod "var-expansion-47c0b54e-ce2f-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.293451ms
Sep  3 09:43:29.427: INFO: Pod "var-expansion-47c0b54e-ce2f-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007574828s
STEP: Saw pod success
Sep  3 09:43:29.427: INFO: Pod "var-expansion-47c0b54e-ce2f-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 09:43:29.431: INFO: Trying to get logs from node 10.0.0.9 pod var-expansion-47c0b54e-ce2f-11e9-a824-e6b94fc13bb4 container dapi-container: <nil>
STEP: delete the pod
Sep  3 09:43:29.458: INFO: Waiting for pod var-expansion-47c0b54e-ce2f-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 09:43:29.466: INFO: Pod var-expansion-47c0b54e-ce2f-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:43:29.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-6055" for this suite.
Sep  3 09:43:35.489: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:43:35.642: INFO: namespace var-expansion-6055 deletion completed in 6.171117405s

• [SLOW TEST:8.286 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:43:35.642: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap that has name configmap-test-emptyKey-4cb4889d-ce2f-11e9-a824-e6b94fc13bb4
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:43:35.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4691" for this suite.
Sep  3 09:43:41.755: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:43:41.916: INFO: namespace configmap-4691 deletion completed in 6.186844458s

• [SLOW TEST:6.275 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:43:41.917: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-upd-506ffa98-ce2f-11e9-a824-e6b94fc13bb4
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:43:44.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7528" for this suite.
Sep  3 09:44:08.081: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:44:08.228: INFO: namespace configmap-7528 deletion completed in 24.189314219s

• [SLOW TEST:26.311 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:44:08.228: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:86
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating service endpoint-test2 in namespace services-879
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-879 to expose endpoints map[]
Sep  3 09:44:08.366: INFO: Get endpoints failed (5.193525ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Sep  3 09:44:09.441: INFO: successfully validated that service endpoint-test2 in namespace services-879 exposes endpoints map[] (1.080670745s elapsed)
STEP: Creating pod pod1 in namespace services-879
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-879 to expose endpoints map[pod1:[80]]
Sep  3 09:44:10.491: INFO: successfully validated that service endpoint-test2 in namespace services-879 exposes endpoints map[pod1:[80]] (1.027265118s elapsed)
STEP: Creating pod pod2 in namespace services-879
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-879 to expose endpoints map[pod1:[80] pod2:[80]]
Sep  3 09:44:12.539: INFO: successfully validated that service endpoint-test2 in namespace services-879 exposes endpoints map[pod1:[80] pod2:[80]] (2.039327605s elapsed)
STEP: Deleting pod pod1 in namespace services-879
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-879 to expose endpoints map[pod2:[80]]
Sep  3 09:44:13.571: INFO: successfully validated that service endpoint-test2 in namespace services-879 exposes endpoints map[pod2:[80]] (1.020270814s elapsed)
STEP: Deleting pod pod2 in namespace services-879
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-879 to expose endpoints map[]
Sep  3 09:44:14.717: INFO: successfully validated that service endpoint-test2 in namespace services-879 exposes endpoints map[] (1.093735776s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:44:14.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-879" for this suite.
Sep  3 09:44:36.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:44:36.996: INFO: namespace services-879 deletion completed in 22.160523798s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91

• [SLOW TEST:28.768 seconds]
[sig-network] Services
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:44:36.996: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Sep  3 09:44:37.052: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:44:40.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4889" for this suite.
Sep  3 09:45:04.586: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:45:04.737: INFO: namespace init-container-4889 deletion completed in 24.166271971s

• [SLOW TEST:27.740 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:45:04.737: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating projection with secret that has name projected-secret-test-map-81cc3123-ce2f-11e9-a824-e6b94fc13bb4
STEP: Creating a pod to test consume secrets
Sep  3 09:45:04.808: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-81cd1209-ce2f-11e9-a824-e6b94fc13bb4" in namespace "projected-3356" to be "success or failure"
Sep  3 09:45:04.812: INFO: Pod "pod-projected-secrets-81cd1209-ce2f-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.25699ms
Sep  3 09:45:06.816: INFO: Pod "pod-projected-secrets-81cd1209-ce2f-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007712164s
STEP: Saw pod success
Sep  3 09:45:06.816: INFO: Pod "pod-projected-secrets-81cd1209-ce2f-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 09:45:06.820: INFO: Trying to get logs from node 10.0.0.6 pod pod-projected-secrets-81cd1209-ce2f-11e9-a824-e6b94fc13bb4 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep  3 09:45:06.876: INFO: Waiting for pod pod-projected-secrets-81cd1209-ce2f-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 09:45:06.879: INFO: Pod pod-projected-secrets-81cd1209-ce2f-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:45:06.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3356" for this suite.
Sep  3 09:45:12.902: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:45:13.058: INFO: namespace projected-3356 deletion completed in 6.173990503s

• [SLOW TEST:8.321 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:45:13.058: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0666 on node default medium
Sep  3 09:45:13.122: INFO: Waiting up to 5m0s for pod "pod-86c128f1-ce2f-11e9-a824-e6b94fc13bb4" in namespace "emptydir-3327" to be "success or failure"
Sep  3 09:45:13.127: INFO: Pod "pod-86c128f1-ce2f-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.728929ms
Sep  3 09:45:15.132: INFO: Pod "pod-86c128f1-ce2f-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009189621s
STEP: Saw pod success
Sep  3 09:45:15.132: INFO: Pod "pod-86c128f1-ce2f-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 09:45:15.135: INFO: Trying to get logs from node 10.0.0.9 pod pod-86c128f1-ce2f-11e9-a824-e6b94fc13bb4 container test-container: <nil>
STEP: delete the pod
Sep  3 09:45:15.164: INFO: Waiting for pod pod-86c128f1-ce2f-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 09:45:15.171: INFO: Pod pod-86c128f1-ce2f-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:45:15.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3327" for this suite.
Sep  3 09:45:21.195: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:45:21.503: INFO: namespace emptydir-3327 deletion completed in 6.326613294s

• [SLOW TEST:8.445 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:45:21.503: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-4628.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-4628.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4628.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-4628.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-4628.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4628.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep  3 09:45:23.696: INFO: DNS probes using dns-4628/dns-test-8bcb6de7-ce2f-11e9-a824-e6b94fc13bb4 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:45:23.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4628" for this suite.
Sep  3 09:45:29.766: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:45:29.925: INFO: namespace dns-4628 deletion completed in 6.195441393s

• [SLOW TEST:8.421 seconds]
[sig-network] DNS
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:45:29.925: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0777 on tmpfs
Sep  3 09:45:30.066: INFO: Waiting up to 5m0s for pod "pod-90db3174-ce2f-11e9-a824-e6b94fc13bb4" in namespace "emptydir-664" to be "success or failure"
Sep  3 09:45:30.070: INFO: Pod "pod-90db3174-ce2f-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.450597ms
Sep  3 09:45:32.074: INFO: Pod "pod-90db3174-ce2f-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007804603s
STEP: Saw pod success
Sep  3 09:45:32.074: INFO: Pod "pod-90db3174-ce2f-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 09:45:32.078: INFO: Trying to get logs from node 10.0.0.9 pod pod-90db3174-ce2f-11e9-a824-e6b94fc13bb4 container test-container: <nil>
STEP: delete the pod
Sep  3 09:45:32.106: INFO: Waiting for pod pod-90db3174-ce2f-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 09:45:32.109: INFO: Pod pod-90db3174-ce2f-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:45:32.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-664" for this suite.
Sep  3 09:45:38.132: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:45:38.285: INFO: namespace emptydir-664 deletion completed in 6.171042343s

• [SLOW TEST:8.360 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:45:38.285: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-95cc29b7-ce2f-11e9-a824-e6b94fc13bb4
STEP: Creating a pod to test consume configMaps
Sep  3 09:45:38.370: INFO: Waiting up to 5m0s for pod "pod-configmaps-95cd17c9-ce2f-11e9-a824-e6b94fc13bb4" in namespace "configmap-9535" to be "success or failure"
Sep  3 09:45:38.374: INFO: Pod "pod-configmaps-95cd17c9-ce2f-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.365858ms
Sep  3 09:45:40.379: INFO: Pod "pod-configmaps-95cd17c9-ce2f-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008258884s
STEP: Saw pod success
Sep  3 09:45:40.379: INFO: Pod "pod-configmaps-95cd17c9-ce2f-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 09:45:40.382: INFO: Trying to get logs from node 10.0.0.9 pod pod-configmaps-95cd17c9-ce2f-11e9-a824-e6b94fc13bb4 container configmap-volume-test: <nil>
STEP: delete the pod
Sep  3 09:45:40.412: INFO: Waiting for pod pod-configmaps-95cd17c9-ce2f-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 09:45:40.415: INFO: Pod pod-configmaps-95cd17c9-ce2f-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:45:40.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9535" for this suite.
Sep  3 09:45:46.435: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:45:46.699: INFO: namespace configmap-9535 deletion completed in 6.278793714s

• [SLOW TEST:8.414 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:45:46.699: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name secret-test-9adda6d2-ce2f-11e9-a824-e6b94fc13bb4
STEP: Creating a pod to test consume secrets
Sep  3 09:45:46.866: INFO: Waiting up to 5m0s for pod "pod-secrets-9ade9282-ce2f-11e9-a824-e6b94fc13bb4" in namespace "secrets-3735" to be "success or failure"
Sep  3 09:45:46.870: INFO: Pod "pod-secrets-9ade9282-ce2f-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.889989ms
Sep  3 09:45:48.874: INFO: Pod "pod-secrets-9ade9282-ce2f-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007907534s
STEP: Saw pod success
Sep  3 09:45:48.874: INFO: Pod "pod-secrets-9ade9282-ce2f-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 09:45:48.877: INFO: Trying to get logs from node 10.0.0.9 pod pod-secrets-9ade9282-ce2f-11e9-a824-e6b94fc13bb4 container secret-volume-test: <nil>
STEP: delete the pod
Sep  3 09:45:48.928: INFO: Waiting for pod pod-secrets-9ade9282-ce2f-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 09:45:48.933: INFO: Pod pod-secrets-9ade9282-ce2f-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:45:48.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3735" for this suite.
Sep  3 09:45:54.956: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:45:55.109: INFO: namespace secrets-3735 deletion completed in 6.168217678s

• [SLOW TEST:8.410 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:45:55.109: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0903 09:46:35.218380      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep  3 09:46:35.218: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:46:35.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4758" for this suite.
Sep  3 09:46:43.240: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:46:43.411: INFO: namespace gc-4758 deletion completed in 8.188266031s

• [SLOW TEST:48.302 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:46:43.411: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-bc9d0feb-ce2f-11e9-a824-e6b94fc13bb4
STEP: Creating a pod to test consume configMaps
Sep  3 09:46:43.493: INFO: Waiting up to 5m0s for pod "pod-configmaps-bc9f4684-ce2f-11e9-a824-e6b94fc13bb4" in namespace "configmap-5379" to be "success or failure"
Sep  3 09:46:43.496: INFO: Pod "pod-configmaps-bc9f4684-ce2f-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.309291ms
Sep  3 09:46:45.501: INFO: Pod "pod-configmaps-bc9f4684-ce2f-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007567703s
STEP: Saw pod success
Sep  3 09:46:45.501: INFO: Pod "pod-configmaps-bc9f4684-ce2f-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 09:46:45.504: INFO: Trying to get logs from node 10.0.0.6 pod pod-configmaps-bc9f4684-ce2f-11e9-a824-e6b94fc13bb4 container configmap-volume-test: <nil>
STEP: delete the pod
Sep  3 09:46:45.549: INFO: Waiting for pod pod-configmaps-bc9f4684-ce2f-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 09:46:45.552: INFO: Pod pod-configmaps-bc9f4684-ce2f-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:46:45.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5379" for this suite.
Sep  3 09:46:51.571: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:46:51.746: INFO: namespace configmap-5379 deletion completed in 6.189243382s

• [SLOW TEST:8.336 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:46:51.747: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-projected-all-test-volume-c19ca998-ce2f-11e9-a824-e6b94fc13bb4
STEP: Creating secret with name secret-projected-all-test-volume-c19ca97e-ce2f-11e9-a824-e6b94fc13bb4
STEP: Creating a pod to test Check all projections for projected volume plugin
Sep  3 09:46:51.880: INFO: Waiting up to 5m0s for pod "projected-volume-c19ca943-ce2f-11e9-a824-e6b94fc13bb4" in namespace "projected-8469" to be "success or failure"
Sep  3 09:46:51.883: INFO: Pod "projected-volume-c19ca943-ce2f-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.579968ms
Sep  3 09:46:53.889: INFO: Pod "projected-volume-c19ca943-ce2f-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009781918s
STEP: Saw pod success
Sep  3 09:46:53.889: INFO: Pod "projected-volume-c19ca943-ce2f-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 09:46:53.893: INFO: Trying to get logs from node 10.0.0.9 pod projected-volume-c19ca943-ce2f-11e9-a824-e6b94fc13bb4 container projected-all-volume-test: <nil>
STEP: delete the pod
Sep  3 09:46:53.918: INFO: Waiting for pod projected-volume-c19ca943-ce2f-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 09:46:53.922: INFO: Pod projected-volume-c19ca943-ce2f-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:46:53.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8469" for this suite.
Sep  3 09:46:59.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:47:00.101: INFO: namespace projected-8469 deletion completed in 6.174116579s

• [SLOW TEST:8.354 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:47:00.101: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
Sep  3 09:47:00.172: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Sep  3 09:47:05.177: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep  3 09:47:05.177: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Sep  3 09:47:05.205: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-6919,SelfLink:/apis/apps/v1/namespaces/deployment-6919/deployments/test-cleanup-deployment,UID:c98ecc33-ce2f-11e9-9b9a-9e20fc449913,ResourceVersion:87058749,Generation:1,CreationTimestamp:2019-09-03 09:47:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Sep  3 09:47:05.208: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
Sep  3 09:47:05.208: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Sep  3 09:47:05.209: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:deployment-6919,SelfLink:/apis/apps/v1/namespaces/deployment-6919/replicasets/test-cleanup-controller,UID:c68fcdb5-ce2f-11e9-9b9a-9e20fc449913,ResourceVersion:87058751,Generation:1,CreationTimestamp:2019-09-03 09:47:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment c98ecc33-ce2f-11e9-9b9a-9e20fc449913 0xc00270ab67 0xc00270ab68}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Sep  3 09:47:05.215: INFO: Pod "test-cleanup-controller-mjmmn" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-mjmmn,GenerateName:test-cleanup-controller-,Namespace:deployment-6919,SelfLink:/api/v1/namespaces/deployment-6919/pods/test-cleanup-controller-mjmmn,UID:c691d5bc-ce2f-11e9-9b9a-9e20fc449913,ResourceVersion:87058499,Generation:0,CreationTimestamp:2019-09-03 09:47:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{tke.cloud.tencent.com/networks-status: [{
    "name": "tke-bridge",
    "ips": [
        "172.22.0.171"
    ],
    "default": true,
    "dns": {}
}],},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller c68fcdb5-ce2f-11e9-9b9a-9e20fc449913 0xc00270b0d7 0xc00270b0d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-x5tpn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-x5tpn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-x5tpn true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.6,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:47:00 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:47:01 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:47:01 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-03 09:47:00 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.6,PodIP:172.22.0.171,StartTime:2019-09-03 09:47:00 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-03 09:47:00 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://0963ff0103465cfa9b12ea04937c37eebfef78dc6ef14c1663c5fa644d06a33c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:47:05.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6919" for this suite.
Sep  3 09:47:11.251: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:47:11.449: INFO: namespace deployment-6919 deletion completed in 6.225639229s

• [SLOW TEST:11.348 seconds]
[sig-apps] Deployment
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:47:11.450: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating server pod server in namespace prestop-2972
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-2972
STEP: Deleting pre-stop pod
Sep  3 09:47:24.558: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:47:24.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-2972" for this suite.
Sep  3 09:48:04.592: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:48:04.810: INFO: namespace prestop-2972 deletion completed in 40.233095338s

• [SLOW TEST:53.361 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:48:04.810: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on tmpfs
Sep  3 09:48:04.876: INFO: Waiting up to 5m0s for pod "pod-ed210b0c-ce2f-11e9-a824-e6b94fc13bb4" in namespace "emptydir-1338" to be "success or failure"
Sep  3 09:48:04.880: INFO: Pod "pod-ed210b0c-ce2f-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.551673ms
Sep  3 09:48:06.885: INFO: Pod "pod-ed210b0c-ce2f-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008078974s
STEP: Saw pod success
Sep  3 09:48:06.885: INFO: Pod "pod-ed210b0c-ce2f-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 09:48:06.888: INFO: Trying to get logs from node 10.0.0.6 pod pod-ed210b0c-ce2f-11e9-a824-e6b94fc13bb4 container test-container: <nil>
STEP: delete the pod
Sep  3 09:48:06.917: INFO: Waiting for pod pod-ed210b0c-ce2f-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 09:48:06.920: INFO: Pod pod-ed210b0c-ce2f-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:48:06.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1338" for this suite.
Sep  3 09:48:12.975: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:48:13.129: INFO: namespace emptydir-1338 deletion completed in 6.203744229s

• [SLOW TEST:8.318 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:48:13.129: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:69
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Registering the sample API server.
Sep  3 09:48:13.557: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Sep  3 09:48:15.641: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703100893, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703100893, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703100893, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703100893, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5f8686f69f\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  3 09:48:17.667: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703100893, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703100893, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703100893, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703100893, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5f8686f69f\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  3 09:48:19.645: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703100893, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703100893, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703100893, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703100893, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5f8686f69f\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  3 09:48:21.651: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703100893, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703100893, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703100893, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703100893, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5f8686f69f\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  3 09:48:23.650: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703100893, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703100893, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703100893, loc:(*time.Location)(0x8a1a0e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703100893, loc:(*time.Location)(0x8a1a0e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5f8686f69f\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep  3 09:48:27.976: INFO: Waited 2.322725045s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:60
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:48:28.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-5389" for this suite.
Sep  3 09:48:34.634: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:48:34.833: INFO: namespace aggregator-5389 deletion completed in 6.263823518s

• [SLOW TEST:21.704 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:48:34.833: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod pod-subpath-test-secret-hs7m
STEP: Creating a pod to test atomic-volume-subpath
Sep  3 09:48:34.947: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-hs7m" in namespace "subpath-1157" to be "success or failure"
Sep  3 09:48:34.950: INFO: Pod "pod-subpath-test-secret-hs7m": Phase="Pending", Reason="", readiness=false. Elapsed: 3.545424ms
Sep  3 09:48:36.955: INFO: Pod "pod-subpath-test-secret-hs7m": Phase="Running", Reason="", readiness=true. Elapsed: 2.008485849s
Sep  3 09:48:38.960: INFO: Pod "pod-subpath-test-secret-hs7m": Phase="Running", Reason="", readiness=true. Elapsed: 4.012808924s
Sep  3 09:48:40.964: INFO: Pod "pod-subpath-test-secret-hs7m": Phase="Running", Reason="", readiness=true. Elapsed: 6.016923603s
Sep  3 09:48:42.970: INFO: Pod "pod-subpath-test-secret-hs7m": Phase="Running", Reason="", readiness=true. Elapsed: 8.022719666s
Sep  3 09:48:44.974: INFO: Pod "pod-subpath-test-secret-hs7m": Phase="Running", Reason="", readiness=true. Elapsed: 10.02696006s
Sep  3 09:48:46.978: INFO: Pod "pod-subpath-test-secret-hs7m": Phase="Running", Reason="", readiness=true. Elapsed: 12.031372453s
Sep  3 09:48:48.984: INFO: Pod "pod-subpath-test-secret-hs7m": Phase="Running", Reason="", readiness=true. Elapsed: 14.037472585s
Sep  3 09:48:50.989: INFO: Pod "pod-subpath-test-secret-hs7m": Phase="Running", Reason="", readiness=true. Elapsed: 16.042165394s
Sep  3 09:48:52.993: INFO: Pod "pod-subpath-test-secret-hs7m": Phase="Running", Reason="", readiness=true. Elapsed: 18.046154481s
Sep  3 09:48:54.998: INFO: Pod "pod-subpath-test-secret-hs7m": Phase="Running", Reason="", readiness=true. Elapsed: 20.050910226s
Sep  3 09:48:57.003: INFO: Pod "pod-subpath-test-secret-hs7m": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.055853589s
STEP: Saw pod success
Sep  3 09:48:57.003: INFO: Pod "pod-subpath-test-secret-hs7m" satisfied condition "success or failure"
Sep  3 09:48:57.007: INFO: Trying to get logs from node 10.0.0.6 pod pod-subpath-test-secret-hs7m container test-container-subpath-secret-hs7m: <nil>
STEP: delete the pod
Sep  3 09:48:57.031: INFO: Waiting for pod pod-subpath-test-secret-hs7m to disappear
Sep  3 09:48:57.034: INFO: Pod pod-subpath-test-secret-hs7m no longer exists
STEP: Deleting pod pod-subpath-test-secret-hs7m
Sep  3 09:48:57.034: INFO: Deleting pod "pod-subpath-test-secret-hs7m" in namespace "subpath-1157"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:48:57.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1157" for this suite.
Sep  3 09:49:03.057: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:49:03.209: INFO: namespace subpath-1157 deletion completed in 6.167258961s

• [SLOW TEST:28.376 seconds]
[sig-storage] Subpath
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:49:03.209: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating configMap with name configmap-test-volume-map-0ff0faa1-ce30-11e9-a824-e6b94fc13bb4
STEP: Creating a pod to test consume configMaps
Sep  3 09:49:03.293: INFO: Waiting up to 5m0s for pod "pod-configmaps-0ff23c8b-ce30-11e9-a824-e6b94fc13bb4" in namespace "configmap-5139" to be "success or failure"
Sep  3 09:49:03.297: INFO: Pod "pod-configmaps-0ff23c8b-ce30-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.479137ms
Sep  3 09:49:05.311: INFO: Pod "pod-configmaps-0ff23c8b-ce30-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017394583s
STEP: Saw pod success
Sep  3 09:49:05.311: INFO: Pod "pod-configmaps-0ff23c8b-ce30-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 09:49:05.314: INFO: Trying to get logs from node 10.0.0.9 pod pod-configmaps-0ff23c8b-ce30-11e9-a824-e6b94fc13bb4 container configmap-volume-test: <nil>
STEP: delete the pod
Sep  3 09:49:05.353: INFO: Waiting for pod pod-configmaps-0ff23c8b-ce30-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 09:49:05.357: INFO: Pod pod-configmaps-0ff23c8b-ce30-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:49:05.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5139" for this suite.
Sep  3 09:49:11.382: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:49:11.603: INFO: namespace configmap-5139 deletion completed in 6.240824888s

• [SLOW TEST:8.394 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:49:11.603: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0903 09:49:21.769328      16 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep  3 09:49:21.769: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:49:21.769: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4650" for this suite.
Sep  3 09:49:29.790: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:49:29.997: INFO: namespace gc-4650 deletion completed in 8.224137602s

• [SLOW TEST:18.394 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:49:29.997: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: creating the pod
Sep  3 09:49:30.047: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:49:33.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7678" for this suite.
Sep  3 09:49:39.838: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:49:40.206: INFO: namespace init-container-7678 deletion completed in 6.382668818s

• [SLOW TEST:10.208 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:49:40.206: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating pod liveness-exec in namespace container-probe-2720
Sep  3 09:49:42.288: INFO: Started pod liveness-exec in namespace container-probe-2720
STEP: checking the pod's current state and verifying that restartCount is present
Sep  3 09:49:42.291: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:53:43.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2720" for this suite.
Sep  3 09:53:49.312: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:53:49.484: INFO: namespace container-probe-2720 deletion completed in 6.188865143s

• [SLOW TEST:249.278 seconds]
[k8s.io] Probing container
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:687
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:53:49.484: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test downward API volume plugin
Sep  3 09:53:49.551: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ba92274a-ce30-11e9-a824-e6b94fc13bb4" in namespace "projected-9466" to be "success or failure"
Sep  3 09:53:49.555: INFO: Pod "downwardapi-volume-ba92274a-ce30-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.387289ms
Sep  3 09:53:51.562: INFO: Pod "downwardapi-volume-ba92274a-ce30-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011064127s
STEP: Saw pod success
Sep  3 09:53:51.562: INFO: Pod "downwardapi-volume-ba92274a-ce30-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 09:53:51.567: INFO: Trying to get logs from node 10.0.0.6 pod downwardapi-volume-ba92274a-ce30-11e9-a824-e6b94fc13bb4 container client-container: <nil>
STEP: delete the pod
Sep  3 09:53:51.597: INFO: Waiting for pod downwardapi-volume-ba92274a-ce30-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 09:53:51.600: INFO: Pod downwardapi-volume-ba92274a-ce30-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:53:51.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9466" for this suite.
Sep  3 09:53:57.619: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:53:57.809: INFO: namespace projected-9466 deletion completed in 6.205331547s

• [SLOW TEST:8.325 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:53:57.810: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir 0644 on node default medium
Sep  3 09:53:57.871: INFO: Waiting up to 5m0s for pod "pod-bf879b33-ce30-11e9-a824-e6b94fc13bb4" in namespace "emptydir-9294" to be "success or failure"
Sep  3 09:53:57.874: INFO: Pod "pod-bf879b33-ce30-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.554846ms
Sep  3 09:53:59.879: INFO: Pod "pod-bf879b33-ce30-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008184926s
STEP: Saw pod success
Sep  3 09:53:59.879: INFO: Pod "pod-bf879b33-ce30-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 09:53:59.883: INFO: Trying to get logs from node 10.0.0.6 pod pod-bf879b33-ce30-11e9-a824-e6b94fc13bb4 container test-container: <nil>
STEP: delete the pod
Sep  3 09:53:59.969: INFO: Waiting for pod pod-bf879b33-ce30-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 09:53:59.972: INFO: Pod pod-bf879b33-ce30-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:53:59.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9294" for this suite.
Sep  3 09:54:05.991: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:54:06.138: INFO: namespace emptydir-9294 deletion completed in 6.161584777s

• [SLOW TEST:8.329 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:54:06.139: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating secret with name s-test-opt-del-c480aedc-ce30-11e9-a824-e6b94fc13bb4
STEP: Creating secret with name s-test-opt-upd-c480af18-ce30-11e9-a824-e6b94fc13bb4
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-c480aedc-ce30-11e9-a824-e6b94fc13bb4
STEP: Updating secret s-test-opt-upd-c480af18-ce30-11e9-a824-e6b94fc13bb4
STEP: Creating secret with name s-test-opt-create-c480af38-ce30-11e9-a824-e6b94fc13bb4
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:54:10.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3733" for this suite.
Sep  3 09:54:34.427: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:54:34.594: INFO: namespace secrets-3733 deletion completed in 24.184180001s

• [SLOW TEST:28.455 seconds]
[sig-storage] Secrets
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:149
STEP: Creating a kubernetes client
Sep  3 09:54:34.594: INFO: >>> kubeConfig: /tmp/kubeconfig-356901984
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
STEP: Creating a pod to test emptydir volume type on node default medium
Sep  3 09:54:34.659: INFO: Waiting up to 5m0s for pod "pod-d574b684-ce30-11e9-a824-e6b94fc13bb4" in namespace "emptydir-7216" to be "success or failure"
Sep  3 09:54:34.662: INFO: Pod "pod-d574b684-ce30-11e9-a824-e6b94fc13bb4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.553696ms
Sep  3 09:54:36.668: INFO: Pod "pod-d574b684-ce30-11e9-a824-e6b94fc13bb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009045716s
STEP: Saw pod success
Sep  3 09:54:36.668: INFO: Pod "pod-d574b684-ce30-11e9-a824-e6b94fc13bb4" satisfied condition "success or failure"
Sep  3 09:54:36.671: INFO: Trying to get logs from node 10.0.0.9 pod pod-d574b684-ce30-11e9-a824-e6b94fc13bb4 container test-container: <nil>
STEP: delete the pod
Sep  3 09:54:36.700: INFO: Waiting for pod pod-d574b684-ce30-11e9-a824-e6b94fc13bb4 to disappear
Sep  3 09:54:36.704: INFO: Pod pod-d574b684-ce30-11e9-a824-e6b94fc13bb4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
Sep  3 09:54:36.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7216" for this suite.
Sep  3 09:54:42.729: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep  3 09:54:42.882: INFO: namespace emptydir-7216 deletion completed in 6.173225033s

• [SLOW TEST:8.289 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.14.3-beta.0.37+5e53fd6bc17c0d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
------------------------------
SSSSSSSSSSSSSSep  3 09:54:42.882: INFO: Running AfterSuite actions on all nodes
Sep  3 09:54:42.882: INFO: Running AfterSuite actions on node 1
Sep  3 09:54:42.882: INFO: Skipping dumping logs from cluster

Ran 203 of 3585 Specs in 5791.219 seconds
SUCCESS! -- 203 Passed | 0 Failed | 0 Pending | 3382 Skipped PASS

Ginkgo ran 1 suite in 1h36m32.297009449s
Test Suite Passed
