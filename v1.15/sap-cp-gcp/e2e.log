Conformance test: not doing test setup.
I0814 06:36:14.945603    4167 e2e.go:241] Starting e2e run "d3f05482-845a-4a68-9b16-f4516f4d69e1" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1565764573 - Will randomize all specs
Will run 212 of 4413 specs

Aug 14 06:36:54.872: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Aug 14 06:36:54.876: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Aug 14 06:36:54.965: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Aug 14 06:36:55.042: INFO: 15 / 15 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Aug 14 06:36:55.042: INFO: expected 9 pod replicas in namespace 'kube-system', 9 are Running and Ready.
Aug 14 06:36:55.042: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Aug 14 06:36:55.063: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Aug 14 06:36:55.063: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Aug 14 06:36:55.063: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'node-exporter' (0 seconds elapsed)
Aug 14 06:36:55.063: INFO: e2e test version: v1.15.2
Aug 14 06:36:55.076: INFO: kube-apiserver version: v1.15.2
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 06:36:55.077: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
Aug 14 06:36:55.334: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Aug 14 06:36:55.380: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1186
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Aug 14 06:36:55.555: INFO: Waiting up to 5m0s for pod "pod-a01a7d87-5ab2-4bcd-95ca-1cbd9413d512" in namespace "emptydir-1186" to be "success or failure"
Aug 14 06:36:55.568: INFO: Pod "pod-a01a7d87-5ab2-4bcd-95ca-1cbd9413d512": Phase="Pending", Reason="", readiness=false. Elapsed: 13.372323ms
Aug 14 06:36:57.583: INFO: Pod "pod-a01a7d87-5ab2-4bcd-95ca-1cbd9413d512": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027852538s
Aug 14 06:36:59.598: INFO: Pod "pod-a01a7d87-5ab2-4bcd-95ca-1cbd9413d512": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.043326506s
STEP: Saw pod success
Aug 14 06:36:59.598: INFO: Pod "pod-a01a7d87-5ab2-4bcd-95ca-1cbd9413d512" satisfied condition "success or failure"
Aug 14 06:36:59.612: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod pod-a01a7d87-5ab2-4bcd-95ca-1cbd9413d512 container test-container: <nil>
STEP: delete the pod
Aug 14 06:36:59.785: INFO: Waiting for pod pod-a01a7d87-5ab2-4bcd-95ca-1cbd9413d512 to disappear
Aug 14 06:36:59.799: INFO: Pod pod-a01a7d87-5ab2-4bcd-95ca-1cbd9413d512 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 06:36:59.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1186" for this suite.
Aug 14 06:37:05.856: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 06:37:06.369: INFO: namespace emptydir-1186 deletion completed in 6.556164503s
•SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 06:37:06.369: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-3887
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-3887
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Aug 14 06:37:06.710: INFO: Found 1 stateful pods, waiting for 3
Aug 14 06:37:16.726: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 14 06:37:16.726: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 14 06:37:16.726: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Aug 14 06:37:16.768: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-3887 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 14 06:37:17.487: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 14 06:37:17.487: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 14 06:37:17.487: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Aug 14 06:37:27.583: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Aug 14 06:37:27.626: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-3887 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 14 06:37:28.249: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug 14 06:37:28.249: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 14 06:37:28.249: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 14 06:37:38.336: INFO: Waiting for StatefulSet statefulset-3887/ss2 to complete update
Aug 14 06:37:38.336: INFO: Waiting for Pod statefulset-3887/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Aug 14 06:37:38.336: INFO: Waiting for Pod statefulset-3887/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Aug 14 06:37:48.365: INFO: Waiting for StatefulSet statefulset-3887/ss2 to complete update
Aug 14 06:37:48.365: INFO: Waiting for Pod statefulset-3887/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Aug 14 06:37:48.365: INFO: Waiting for Pod statefulset-3887/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Aug 14 06:37:58.365: INFO: Waiting for StatefulSet statefulset-3887/ss2 to complete update
Aug 14 06:37:58.365: INFO: Waiting for Pod statefulset-3887/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Rolling back to a previous revision
Aug 14 06:38:08.366: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-3887 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 14 06:38:09.172: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 14 06:38:09.172: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 14 06:38:09.172: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 14 06:38:19.272: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Aug 14 06:38:19.317: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-3887 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 14 06:38:19.875: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug 14 06:38:19.875: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 14 06:38:19.875: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 14 06:38:39.961: INFO: Waiting for StatefulSet statefulset-3887/ss2 to complete update
Aug 14 06:38:39.961: INFO: Waiting for Pod statefulset-3887/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Aug 14 06:38:49.990: INFO: Deleting all statefulset in ns statefulset-3887
Aug 14 06:38:50.004: INFO: Scaling statefulset ss2 to 0
Aug 14 06:39:20.062: INFO: Waiting for statefulset status.replicas updated to 0
Aug 14 06:39:20.076: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 06:39:20.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3887" for this suite.
Aug 14 06:39:26.175: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 06:39:26.705: INFO: namespace statefulset-3887 deletion completed in 6.572857857s
•SSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 06:39:26.706: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-4274
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's command
Aug 14 06:39:26.992: INFO: Waiting up to 5m0s for pod "var-expansion-48a73db7-2535-4fb9-b80f-9951cadd16c3" in namespace "var-expansion-4274" to be "success or failure"
Aug 14 06:39:27.005: INFO: Pod "var-expansion-48a73db7-2535-4fb9-b80f-9951cadd16c3": Phase="Pending", Reason="", readiness=false. Elapsed: 13.444326ms
Aug 14 06:39:29.020: INFO: Pod "var-expansion-48a73db7-2535-4fb9-b80f-9951cadd16c3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028103861s
Aug 14 06:39:31.034: INFO: Pod "var-expansion-48a73db7-2535-4fb9-b80f-9951cadd16c3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.042484095s
STEP: Saw pod success
Aug 14 06:39:31.034: INFO: Pod "var-expansion-48a73db7-2535-4fb9-b80f-9951cadd16c3" satisfied condition "success or failure"
Aug 14 06:39:31.048: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod var-expansion-48a73db7-2535-4fb9-b80f-9951cadd16c3 container dapi-container: <nil>
STEP: delete the pod
Aug 14 06:39:31.097: INFO: Waiting for pod var-expansion-48a73db7-2535-4fb9-b80f-9951cadd16c3 to disappear
Aug 14 06:39:31.110: INFO: Pod var-expansion-48a73db7-2535-4fb9-b80f-9951cadd16c3 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 06:39:31.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4274" for this suite.
Aug 14 06:39:37.171: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 06:39:37.715: INFO: namespace var-expansion-4274 deletion completed in 6.590681549s
•SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 06:39:37.716: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4928
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Aug 14 06:39:37.994: INFO: Waiting up to 5m0s for pod "pod-2cba53fb-a566-479b-8737-074dbf749722" in namespace "emptydir-4928" to be "success or failure"
Aug 14 06:39:38.008: INFO: Pod "pod-2cba53fb-a566-479b-8737-074dbf749722": Phase="Pending", Reason="", readiness=false. Elapsed: 13.426104ms
Aug 14 06:39:40.023: INFO: Pod "pod-2cba53fb-a566-479b-8737-074dbf749722": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.028545608s
STEP: Saw pod success
Aug 14 06:39:40.023: INFO: Pod "pod-2cba53fb-a566-479b-8737-074dbf749722" satisfied condition "success or failure"
Aug 14 06:39:40.036: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod pod-2cba53fb-a566-479b-8737-074dbf749722 container test-container: <nil>
STEP: delete the pod
Aug 14 06:39:40.074: INFO: Waiting for pod pod-2cba53fb-a566-479b-8737-074dbf749722 to disappear
Aug 14 06:39:40.088: INFO: Pod pod-2cba53fb-a566-479b-8737-074dbf749722 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 06:39:40.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4928" for this suite.
Aug 14 06:39:46.145: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 06:39:46.662: INFO: namespace emptydir-4928 deletion completed in 6.559715614s
•SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 06:39:46.662: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-8548
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Aug 14 06:39:48.025: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 06:39:48.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8548" for this suite.
Aug 14 06:39:54.115: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 06:39:54.668: INFO: namespace container-runtime-8548 deletion completed in 6.597325352s
•SSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 06:39:54.668: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-3026
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 06:40:15.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3026" for this suite.
Aug 14 06:40:21.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 06:40:22.096: INFO: namespace container-runtime-3026 deletion completed in 6.553847333s
•SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 06:40:22.097: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6928
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-1772fde3-eb6c-4b4a-b95e-fc91a97f016f
STEP: Creating a pod to test consume configMaps
Aug 14 06:40:22.495: INFO: Waiting up to 5m0s for pod "pod-configmaps-ae1eb0a9-12a4-4111-8ccb-1294635eb86c" in namespace "configmap-6928" to be "success or failure"
Aug 14 06:40:22.508: INFO: Pod "pod-configmaps-ae1eb0a9-12a4-4111-8ccb-1294635eb86c": Phase="Pending", Reason="", readiness=false. Elapsed: 13.209998ms
Aug 14 06:40:24.523: INFO: Pod "pod-configmaps-ae1eb0a9-12a4-4111-8ccb-1294635eb86c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027927928s
STEP: Saw pod success
Aug 14 06:40:24.523: INFO: Pod "pod-configmaps-ae1eb0a9-12a4-4111-8ccb-1294635eb86c" satisfied condition "success or failure"
Aug 14 06:40:24.537: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod pod-configmaps-ae1eb0a9-12a4-4111-8ccb-1294635eb86c container configmap-volume-test: <nil>
STEP: delete the pod
Aug 14 06:40:24.575: INFO: Waiting for pod pod-configmaps-ae1eb0a9-12a4-4111-8ccb-1294635eb86c to disappear
Aug 14 06:40:24.589: INFO: Pod pod-configmaps-ae1eb0a9-12a4-4111-8ccb-1294635eb86c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 06:40:24.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6928" for this suite.
Aug 14 06:40:30.644: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 06:40:31.162: INFO: namespace configmap-6928 deletion completed in 6.559385059s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 06:40:31.163: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-6755
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Aug 14 06:40:31.368: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 06:40:35.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6755" for this suite.
Aug 14 06:40:59.698: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 06:41:00.229: INFO: namespace init-container-6755 deletion completed in 24.574076868s
•SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 06:41:00.229: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4981
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-8426
STEP: Creating secret with name secret-test-be2b7ae4-105c-43c3-a307-8a24db09e493
STEP: Creating a pod to test consume secrets
Aug 14 06:41:00.707: INFO: Waiting up to 5m0s for pod "pod-secrets-a693fef0-b50b-4103-b0f3-68c9e05c228e" in namespace "secrets-4981" to be "success or failure"
Aug 14 06:41:00.721: INFO: Pod "pod-secrets-a693fef0-b50b-4103-b0f3-68c9e05c228e": Phase="Pending", Reason="", readiness=false. Elapsed: 13.601884ms
Aug 14 06:41:02.735: INFO: Pod "pod-secrets-a693fef0-b50b-4103-b0f3-68c9e05c228e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027655605s
STEP: Saw pod success
Aug 14 06:41:02.735: INFO: Pod "pod-secrets-a693fef0-b50b-4103-b0f3-68c9e05c228e" satisfied condition "success or failure"
Aug 14 06:41:02.749: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod pod-secrets-a693fef0-b50b-4103-b0f3-68c9e05c228e container secret-volume-test: <nil>
STEP: delete the pod
Aug 14 06:41:02.787: INFO: Waiting for pod pod-secrets-a693fef0-b50b-4103-b0f3-68c9e05c228e to disappear
Aug 14 06:41:02.801: INFO: Pod pod-secrets-a693fef0-b50b-4103-b0f3-68c9e05c228e no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 06:41:02.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4981" for this suite.
Aug 14 06:41:08.860: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 06:41:09.378: INFO: namespace secrets-4981 deletion completed in 6.562805092s
STEP: Destroying namespace "secret-namespace-8426" for this suite.
Aug 14 06:41:15.423: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 06:41:15.957: INFO: namespace secret-namespace-8426 deletion completed in 6.579500964s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 06:41:15.958: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4550
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-7baa1da7-44f2-4508-a547-c453e62e18ed
STEP: Creating a pod to test consume secrets
Aug 14 06:41:16.292: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-25a7b3a0-c85c-46fe-b5f3-0f59ac935734" in namespace "projected-4550" to be "success or failure"
Aug 14 06:41:16.305: INFO: Pod "pod-projected-secrets-25a7b3a0-c85c-46fe-b5f3-0f59ac935734": Phase="Pending", Reason="", readiness=false. Elapsed: 13.123226ms
Aug 14 06:41:18.320: INFO: Pod "pod-projected-secrets-25a7b3a0-c85c-46fe-b5f3-0f59ac935734": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027641331s
STEP: Saw pod success
Aug 14 06:41:18.320: INFO: Pod "pod-projected-secrets-25a7b3a0-c85c-46fe-b5f3-0f59ac935734" satisfied condition "success or failure"
Aug 14 06:41:18.334: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod pod-projected-secrets-25a7b3a0-c85c-46fe-b5f3-0f59ac935734 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 14 06:41:18.371: INFO: Waiting for pod pod-projected-secrets-25a7b3a0-c85c-46fe-b5f3-0f59ac935734 to disappear
Aug 14 06:41:18.384: INFO: Pod pod-projected-secrets-25a7b3a0-c85c-46fe-b5f3-0f59ac935734 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 06:41:18.384: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4550" for this suite.
Aug 14 06:41:24.441: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 06:41:24.948: INFO: namespace projected-4550 deletion completed in 6.54967818s
•
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 06:41:24.948: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-350
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-mfnl
STEP: Creating a pod to test atomic-volume-subpath
Aug 14 06:41:25.317: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-mfnl" in namespace "subpath-350" to be "success or failure"
Aug 14 06:41:25.331: INFO: Pod "pod-subpath-test-configmap-mfnl": Phase="Pending", Reason="", readiness=false. Elapsed: 13.594233ms
Aug 14 06:41:27.348: INFO: Pod "pod-subpath-test-configmap-mfnl": Phase="Running", Reason="", readiness=true. Elapsed: 2.030709059s
Aug 14 06:41:29.362: INFO: Pod "pod-subpath-test-configmap-mfnl": Phase="Running", Reason="", readiness=true. Elapsed: 4.045206781s
Aug 14 06:41:31.377: INFO: Pod "pod-subpath-test-configmap-mfnl": Phase="Running", Reason="", readiness=true. Elapsed: 6.059531188s
Aug 14 06:41:33.391: INFO: Pod "pod-subpath-test-configmap-mfnl": Phase="Running", Reason="", readiness=true. Elapsed: 8.073727429s
Aug 14 06:41:35.405: INFO: Pod "pod-subpath-test-configmap-mfnl": Phase="Running", Reason="", readiness=true. Elapsed: 10.088104835s
Aug 14 06:41:37.420: INFO: Pod "pod-subpath-test-configmap-mfnl": Phase="Running", Reason="", readiness=true. Elapsed: 12.102537336s
Aug 14 06:41:39.434: INFO: Pod "pod-subpath-test-configmap-mfnl": Phase="Running", Reason="", readiness=true. Elapsed: 14.116747629s
Aug 14 06:41:41.453: INFO: Pod "pod-subpath-test-configmap-mfnl": Phase="Running", Reason="", readiness=true. Elapsed: 16.135550127s
Aug 14 06:41:43.468: INFO: Pod "pod-subpath-test-configmap-mfnl": Phase="Running", Reason="", readiness=true. Elapsed: 18.150463926s
Aug 14 06:41:45.482: INFO: Pod "pod-subpath-test-configmap-mfnl": Phase="Running", Reason="", readiness=true. Elapsed: 20.164807861s
Aug 14 06:41:47.496: INFO: Pod "pod-subpath-test-configmap-mfnl": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.178916609s
STEP: Saw pod success
Aug 14 06:41:47.496: INFO: Pod "pod-subpath-test-configmap-mfnl" satisfied condition "success or failure"
Aug 14 06:41:47.510: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod pod-subpath-test-configmap-mfnl container test-container-subpath-configmap-mfnl: <nil>
STEP: delete the pod
Aug 14 06:41:47.548: INFO: Waiting for pod pod-subpath-test-configmap-mfnl to disappear
Aug 14 06:41:47.561: INFO: Pod pod-subpath-test-configmap-mfnl no longer exists
STEP: Deleting pod pod-subpath-test-configmap-mfnl
Aug 14 06:41:47.561: INFO: Deleting pod "pod-subpath-test-configmap-mfnl" in namespace "subpath-350"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 06:41:47.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-350" for this suite.
Aug 14 06:41:53.631: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 06:41:54.183: INFO: namespace subpath-350 deletion completed in 6.593616728s
•SSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 06:41:54.183: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-63
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-7602
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-1221
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 06:42:00.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-63" for this suite.
Aug 14 06:42:07.029: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 06:42:07.537: INFO: namespace namespaces-63 deletion completed in 6.551264625s
STEP: Destroying namespace "nsdeletetest-7602" for this suite.
Aug 14 06:42:07.550: INFO: Namespace nsdeletetest-7602 was already deleted
STEP: Destroying namespace "nsdeletetest-1221" for this suite.
Aug 14 06:42:15.605: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 06:42:16.521: INFO: namespace nsdeletetest-1221 deletion completed in 8.970282584s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 06:42:16.521: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-3517
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 06:42:20.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-3517" for this suite.
Aug 14 06:42:42.218: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 06:42:42.725: INFO: namespace replication-controller-3517 deletion completed in 22.585721232s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 06:42:42.725: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7377
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-585303b6-81d7-4303-bf0b-318be00d83a6
STEP: Creating a pod to test consume configMaps
Aug 14 06:42:43.091: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-8ff13bf1-32ce-42af-8beb-010991336a99" in namespace "projected-7377" to be "success or failure"
Aug 14 06:42:43.104: INFO: Pod "pod-projected-configmaps-8ff13bf1-32ce-42af-8beb-010991336a99": Phase="Pending", Reason="", readiness=false. Elapsed: 13.548871ms
Aug 14 06:42:45.119: INFO: Pod "pod-projected-configmaps-8ff13bf1-32ce-42af-8beb-010991336a99": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.028124035s
STEP: Saw pod success
Aug 14 06:42:45.119: INFO: Pod "pod-projected-configmaps-8ff13bf1-32ce-42af-8beb-010991336a99" satisfied condition "success or failure"
Aug 14 06:42:45.132: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod pod-projected-configmaps-8ff13bf1-32ce-42af-8beb-010991336a99 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 14 06:42:45.173: INFO: Waiting for pod pod-projected-configmaps-8ff13bf1-32ce-42af-8beb-010991336a99 to disappear
Aug 14 06:42:45.186: INFO: Pod pod-projected-configmaps-8ff13bf1-32ce-42af-8beb-010991336a99 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 06:42:45.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7377" for this suite.
Aug 14 06:42:51.243: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 06:42:51.786: INFO: namespace projected-7377 deletion completed in 6.585032576s
•SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 06:42:51.786: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2922
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-0fe05899-a233-458a-beba-b71c81c9f205
STEP: Creating a pod to test consume secrets
Aug 14 06:42:52.202: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ba30aef3-5f9e-421b-942f-78c7ce0f0416" in namespace "projected-2922" to be "success or failure"
Aug 14 06:42:52.215: INFO: Pod "pod-projected-secrets-ba30aef3-5f9e-421b-942f-78c7ce0f0416": Phase="Pending", Reason="", readiness=false. Elapsed: 13.565068ms
Aug 14 06:42:54.230: INFO: Pod "pod-projected-secrets-ba30aef3-5f9e-421b-942f-78c7ce0f0416": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027983803s
STEP: Saw pod success
Aug 14 06:42:54.230: INFO: Pod "pod-projected-secrets-ba30aef3-5f9e-421b-942f-78c7ce0f0416" satisfied condition "success or failure"
Aug 14 06:42:54.247: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod pod-projected-secrets-ba30aef3-5f9e-421b-942f-78c7ce0f0416 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 14 06:42:54.288: INFO: Waiting for pod pod-projected-secrets-ba30aef3-5f9e-421b-942f-78c7ce0f0416 to disappear
Aug 14 06:42:54.301: INFO: Pod pod-projected-secrets-ba30aef3-5f9e-421b-942f-78c7ce0f0416 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 06:42:54.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2922" for this suite.
Aug 14 06:43:00.359: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 06:43:00.876: INFO: namespace projected-2922 deletion completed in 6.561404861s
•SSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 06:43:00.876: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-574
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Aug 14 06:43:01.184: INFO: Waiting up to 5m0s for pod "downward-api-197a8987-51aa-4db5-aa3c-b943786dd4b4" in namespace "downward-api-574" to be "success or failure"
Aug 14 06:43:01.197: INFO: Pod "downward-api-197a8987-51aa-4db5-aa3c-b943786dd4b4": Phase="Pending", Reason="", readiness=false. Elapsed: 13.015899ms
Aug 14 06:43:03.211: INFO: Pod "downward-api-197a8987-51aa-4db5-aa3c-b943786dd4b4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027149505s
STEP: Saw pod success
Aug 14 06:43:03.211: INFO: Pod "downward-api-197a8987-51aa-4db5-aa3c-b943786dd4b4" satisfied condition "success or failure"
Aug 14 06:43:03.225: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod downward-api-197a8987-51aa-4db5-aa3c-b943786dd4b4 container dapi-container: <nil>
STEP: delete the pod
Aug 14 06:43:03.265: INFO: Waiting for pod downward-api-197a8987-51aa-4db5-aa3c-b943786dd4b4 to disappear
Aug 14 06:43:03.278: INFO: Pod downward-api-197a8987-51aa-4db5-aa3c-b943786dd4b4 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 06:43:03.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-574" for this suite.
Aug 14 06:43:09.336: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 06:43:09.843: INFO: namespace downward-api-574 deletion completed in 6.550406358s
•SSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 06:43:09.843: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-8091
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-8091
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating stateful set ss in namespace statefulset-8091
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-8091
Aug 14 06:43:10.109: INFO: Found 0 stateful pods, waiting for 1
Aug 14 06:43:20.125: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Aug 14 06:43:20.140: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8091 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 14 06:43:20.940: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 14 06:43:20.940: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 14 06:43:20.940: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 14 06:43:20.955: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Aug 14 06:43:30.971: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 14 06:43:30.971: INFO: Waiting for statefulset status.replicas updated to 0
Aug 14 06:43:31.029: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999172s
Aug 14 06:43:32.045: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.9858093s
Aug 14 06:43:33.060: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.970404375s
Aug 14 06:43:34.075: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.955374493s
Aug 14 06:43:35.090: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.940219893s
Aug 14 06:43:36.105: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.925201782s
Aug 14 06:43:37.123: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.908750574s
Aug 14 06:43:38.139: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.891664628s
Aug 14 06:43:39.153: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.876469014s
Aug 14 06:43:40.168: INFO: Verifying statefulset ss doesn't scale past 3 for another 861.955141ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-8091
Aug 14 06:43:41.183: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8091 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 14 06:43:41.735: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug 14 06:43:41.736: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 14 06:43:41.736: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 14 06:43:41.736: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8091 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 14 06:43:42.383: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Aug 14 06:43:42.383: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 14 06:43:42.383: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 14 06:43:42.383: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8091 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 14 06:43:42.948: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Aug 14 06:43:42.948: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 14 06:43:42.948: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 14 06:43:42.963: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 14 06:43:42.963: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 14 06:43:42.963: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Aug 14 06:43:42.977: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8091 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 14 06:43:43.551: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 14 06:43:43.551: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 14 06:43:43.551: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 14 06:43:43.551: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8091 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 14 06:43:44.149: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 14 06:43:44.149: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 14 06:43:44.149: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 14 06:43:44.149: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8091 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 14 06:43:44.661: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 14 06:43:44.661: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 14 06:43:44.661: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 14 06:43:44.661: INFO: Waiting for statefulset status.replicas updated to 0
Aug 14 06:43:44.675: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Aug 14 06:43:54.705: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 14 06:43:54.705: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Aug 14 06:43:54.705: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Aug 14 06:43:54.748: INFO: POD   NODE                                               PHASE    GRACE  CONDITIONS
Aug 14 06:43:54.748: INFO: ss-0  shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 06:43:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 06:43:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 06:43:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 06:43:10 +0000 UTC  }]
Aug 14 06:43:54.748: INFO: ss-1  shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 06:43:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 06:43:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 06:43:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 06:43:31 +0000 UTC  }]
Aug 14 06:43:54.748: INFO: ss-2  shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 06:43:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 06:43:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 06:43:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 06:43:31 +0000 UTC  }]
Aug 14 06:43:54.748: INFO: 
Aug 14 06:43:54.748: INFO: StatefulSet ss has not reached scale 0, at 3
Aug 14 06:43:55.763: INFO: POD   NODE                                               PHASE    GRACE  CONDITIONS
Aug 14 06:43:55.763: INFO: ss-0  shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 06:43:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 06:43:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 06:43:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 06:43:10 +0000 UTC  }]
Aug 14 06:43:55.763: INFO: ss-1  shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 06:43:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 06:43:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 06:43:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 06:43:31 +0000 UTC  }]
Aug 14 06:43:55.763: INFO: ss-2  shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 06:43:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 06:43:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 06:43:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 06:43:31 +0000 UTC  }]
Aug 14 06:43:55.763: INFO: 
Aug 14 06:43:55.763: INFO: StatefulSet ss has not reached scale 0, at 3
Aug 14 06:43:56.778: INFO: POD   NODE                                               PHASE    GRACE  CONDITIONS
Aug 14 06:43:56.778: INFO: ss-0  shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 06:43:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 06:43:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 06:43:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 06:43:10 +0000 UTC  }]
Aug 14 06:43:56.778: INFO: ss-2  shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 06:43:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 06:43:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 06:43:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 06:43:31 +0000 UTC  }]
Aug 14 06:43:56.778: INFO: 
Aug 14 06:43:56.778: INFO: StatefulSet ss has not reached scale 0, at 2
Aug 14 06:43:57.792: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.956047838s
Aug 14 06:43:58.807: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.941454469s
Aug 14 06:43:59.821: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.926889265s
Aug 14 06:44:00.835: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.912437938s
Aug 14 06:44:01.850: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.898443164s
Aug 14 06:44:02.864: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.884181828s
Aug 14 06:44:03.879: INFO: Verifying statefulset ss doesn't scale past 0 for another 869.941423ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-8091
Aug 14 06:44:04.893: INFO: Scaling statefulset ss to 0
Aug 14 06:44:04.935: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Aug 14 06:44:04.949: INFO: Deleting all statefulset in ns statefulset-8091
Aug 14 06:44:04.963: INFO: Scaling statefulset ss to 0
Aug 14 06:44:05.004: INFO: Waiting for statefulset status.replicas updated to 0
Aug 14 06:44:05.018: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 06:44:05.060: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8091" for this suite.
Aug 14 06:44:11.117: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 06:44:11.633: INFO: namespace statefulset-8091 deletion completed in 6.559287641s
•SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 06:44:11.633: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5401
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Aug 14 06:44:12.092: INFO: namespace kubectl-5401
Aug 14 06:44:12.092: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-5401'
Aug 14 06:44:12.930: INFO: stderr: ""
Aug 14 06:44:12.930: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Aug 14 06:44:13.945: INFO: Selector matched 1 pods for map[app:redis]
Aug 14 06:44:13.945: INFO: Found 0 / 1
Aug 14 06:44:14.945: INFO: Selector matched 1 pods for map[app:redis]
Aug 14 06:44:14.945: INFO: Found 0 / 1
Aug 14 06:44:15.945: INFO: Selector matched 1 pods for map[app:redis]
Aug 14 06:44:15.945: INFO: Found 0 / 1
Aug 14 06:44:16.945: INFO: Selector matched 1 pods for map[app:redis]
Aug 14 06:44:16.945: INFO: Found 1 / 1
Aug 14 06:44:16.945: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug 14 06:44:16.959: INFO: Selector matched 1 pods for map[app:redis]
Aug 14 06:44:16.959: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug 14 06:44:16.959: INFO: wait on redis-master startup in kubectl-5401 
Aug 14 06:44:16.959: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs redis-master-s26cx redis-master --namespace=kubectl-5401'
Aug 14 06:44:17.206: INFO: stderr: ""
Aug 14 06:44:17.206: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 14 Aug 06:44:14.910 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 14 Aug 06:44:14.910 # Server started, Redis version 3.2.12\n1:M 14 Aug 06:44:14.910 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 14 Aug 06:44:14.910 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Aug 14 06:44:17.206: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-5401'
Aug 14 06:44:17.386: INFO: stderr: ""
Aug 14 06:44:17.386: INFO: stdout: "service/rm2 exposed\n"
Aug 14 06:44:17.399: INFO: Service rm2 in namespace kubectl-5401 found.
STEP: exposing service
Aug 14 06:44:19.428: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-5401'
Aug 14 06:44:19.622: INFO: stderr: ""
Aug 14 06:44:19.622: INFO: stdout: "service/rm3 exposed\n"
Aug 14 06:44:19.636: INFO: Service rm3 in namespace kubectl-5401 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 06:44:21.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5401" for this suite.
Aug 14 06:44:45.720: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 06:44:46.317: INFO: namespace kubectl-5401 deletion completed in 24.638760371s
•SS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 06:44:46.317: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-3485
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-fb21ccb1-64ca-4420-a071-1005b93867a6 in namespace container-probe-3485
Aug 14 06:44:50.705: INFO: Started pod liveness-fb21ccb1-64ca-4420-a071-1005b93867a6 in namespace container-probe-3485
STEP: checking the pod's current state and verifying that restartCount is present
Aug 14 06:44:50.719: INFO: Initial restart count of pod liveness-fb21ccb1-64ca-4420-a071-1005b93867a6 is 0
Aug 14 06:45:12.900: INFO: Restart count of pod container-probe-3485/liveness-fb21ccb1-64ca-4420-a071-1005b93867a6 is now 1 (22.180445065s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 06:45:12.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3485" for this suite.
Aug 14 06:45:18.974: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 06:45:19.486: INFO: namespace container-probe-3485 deletion completed in 6.553938808s
•SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 06:45:19.487: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4721
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Aug 14 06:45:19.863: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-4721'
Aug 14 06:45:20.233: INFO: stderr: ""
Aug 14 06:45:20.233: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Aug 14 06:45:21.247: INFO: Selector matched 1 pods for map[app:redis]
Aug 14 06:45:21.248: INFO: Found 0 / 1
Aug 14 06:45:22.248: INFO: Selector matched 1 pods for map[app:redis]
Aug 14 06:45:22.248: INFO: Found 1 / 1
Aug 14 06:45:22.248: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Aug 14 06:45:22.263: INFO: Selector matched 1 pods for map[app:redis]
Aug 14 06:45:22.263: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug 14 06:45:22.263: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config patch pod redis-master-ql68r --namespace=kubectl-4721 -p {"metadata":{"annotations":{"x":"y"}}}'
Aug 14 06:45:22.415: INFO: stderr: ""
Aug 14 06:45:22.415: INFO: stdout: "pod/redis-master-ql68r patched\n"
STEP: checking annotations
Aug 14 06:45:22.429: INFO: Selector matched 1 pods for map[app:redis]
Aug 14 06:45:22.429: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 06:45:22.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4721" for this suite.
Aug 14 06:45:44.485: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 06:45:45.025: INFO: namespace kubectl-4721 deletion completed in 22.582541746s
•S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 06:45:45.025: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2570
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1421
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 14 06:45:45.267: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-2570'
Aug 14 06:45:45.622: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 14 06:45:45.622: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1427
Aug 14 06:45:45.636: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete deployment e2e-test-nginx-deployment --namespace=kubectl-2570'
Aug 14 06:45:45.780: INFO: stderr: ""
Aug 14 06:45:45.780: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 06:45:45.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2570" for this suite.
Aug 14 06:46:03.837: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 06:46:04.383: INFO: namespace kubectl-2570 deletion completed in 18.589070973s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 06:46:04.384: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2229
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1211
STEP: creating the pod
Aug 14 06:46:04.682: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-2229'
Aug 14 06:46:04.985: INFO: stderr: ""
Aug 14 06:46:04.985: INFO: stdout: "pod/pause created\n"
Aug 14 06:46:04.985: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Aug 14 06:46:04.986: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-2229" to be "running and ready"
Aug 14 06:46:04.999: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 13.124744ms
Aug 14 06:46:07.013: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.027671985s
Aug 14 06:46:07.013: INFO: Pod "pause" satisfied condition "running and ready"
Aug 14 06:46:07.013: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: adding the label testing-label with value testing-label-value to a pod
Aug 14 06:46:07.013: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config label pods pause testing-label=testing-label-value --namespace=kubectl-2229'
Aug 14 06:46:07.152: INFO: stderr: ""
Aug 14 06:46:07.152: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Aug 14 06:46:07.152: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pod pause -L testing-label --namespace=kubectl-2229'
Aug 14 06:46:07.271: INFO: stderr: ""
Aug 14 06:46:07.272: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Aug 14 06:46:07.272: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config label pods pause testing-label- --namespace=kubectl-2229'
Aug 14 06:46:07.439: INFO: stderr: ""
Aug 14 06:46:07.439: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Aug 14 06:46:07.439: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pod pause -L testing-label --namespace=kubectl-2229'
Aug 14 06:46:07.562: INFO: stderr: ""
Aug 14 06:46:07.562: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1218
STEP: using delete to clean up resources
Aug 14 06:46:07.562: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-2229'
Aug 14 06:46:07.701: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 14 06:46:07.701: INFO: stdout: "pod \"pause\" force deleted\n"
Aug 14 06:46:07.701: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get rc,svc -l name=pause --no-headers --namespace=kubectl-2229'
Aug 14 06:46:07.850: INFO: stderr: "No resources found.\n"
Aug 14 06:46:07.851: INFO: stdout: ""
Aug 14 06:46:07.851: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -l name=pause --namespace=kubectl-2229 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 14 06:46:07.979: INFO: stderr: ""
Aug 14 06:46:07.979: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 06:46:07.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2229" for this suite.
Aug 14 06:46:14.038: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 06:46:14.570: INFO: namespace kubectl-2229 deletion completed in 6.575574845s
•SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 06:46:14.570: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7980
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-751ed77f-437a-4a00-bc76-5d145df4684c
STEP: Creating a pod to test consume configMaps
Aug 14 06:46:14.803: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ab57e07d-b681-4219-af13-9ee3e8d4e6d9" in namespace "projected-7980" to be "success or failure"
Aug 14 06:46:14.817: INFO: Pod "pod-projected-configmaps-ab57e07d-b681-4219-af13-9ee3e8d4e6d9": Phase="Pending", Reason="", readiness=false. Elapsed: 14.053481ms
Aug 14 06:46:16.831: INFO: Pod "pod-projected-configmaps-ab57e07d-b681-4219-af13-9ee3e8d4e6d9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.028133169s
STEP: Saw pod success
Aug 14 06:46:16.832: INFO: Pod "pod-projected-configmaps-ab57e07d-b681-4219-af13-9ee3e8d4e6d9" satisfied condition "success or failure"
Aug 14 06:46:16.845: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod pod-projected-configmaps-ab57e07d-b681-4219-af13-9ee3e8d4e6d9 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 14 06:46:16.884: INFO: Waiting for pod pod-projected-configmaps-ab57e07d-b681-4219-af13-9ee3e8d4e6d9 to disappear
Aug 14 06:46:16.898: INFO: Pod pod-projected-configmaps-ab57e07d-b681-4219-af13-9ee3e8d4e6d9 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 06:46:16.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7980" for this suite.
Aug 14 06:46:22.954: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 06:46:23.471: INFO: namespace projected-7980 deletion completed in 6.559203389s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 06:46:23.472: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-5842
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Aug 14 06:46:27.748: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-3e5b6807-18eb-4ff6-9ca7-a56ac59bb68d,GenerateName:,Namespace:events-5842,SelfLink:/api/v1/namespaces/events-5842/pods/send-events-3e5b6807-18eb-4ff6-9ca7-a56ac59bb68d,UID:b4372e3c-2254-4d91-9ec6-7c2f8be9e9cb,ResourceVersion:4861,Generation:0,CreationTimestamp:2019-08-14 06:46:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 671569185,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.32/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-69sls {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-69sls,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-69sls true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0036bf180} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0036bf1a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 06:46:23 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 06:46:26 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 06:46:26 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 06:46:23 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:100.96.1.32,StartTime:2019-08-14 06:46:23 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-08-14 06:46:25 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://f627835433520b234ca865bb6dba156b326fa8e8d5f063f6de2a8ce3ebc2daef}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Aug 14 06:46:29.763: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Aug 14 06:46:31.778: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 06:46:31.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-5842" for this suite.
Aug 14 06:47:11.851: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 06:47:12.405: INFO: namespace events-5842 deletion completed in 40.596081152s
•SSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 06:47:12.405: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-8690
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 14 06:47:12.672: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 06:47:14.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8690" for this suite.
Aug 14 06:47:55.041: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 06:47:55.569: INFO: namespace pods-8690 deletion completed in 40.571633813s
•S
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 06:47:55.569: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-1622
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 06:48:00.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-1622" for this suite.
Aug 14 06:48:06.062: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 06:48:06.609: INFO: namespace emptydir-wrapper-1622 deletion completed in 6.591108355s
•SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 06:48:06.609: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8849
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-8505fa39-234a-44f7-a967-0d15180eb707
STEP: Creating a pod to test consume secrets
Aug 14 06:48:06.903: INFO: Waiting up to 5m0s for pod "pod-secrets-d565fa20-46b7-4e54-837f-d57ac0af28c0" in namespace "secrets-8849" to be "success or failure"
Aug 14 06:48:06.916: INFO: Pod "pod-secrets-d565fa20-46b7-4e54-837f-d57ac0af28c0": Phase="Pending", Reason="", readiness=false. Elapsed: 13.314625ms
Aug 14 06:48:08.931: INFO: Pod "pod-secrets-d565fa20-46b7-4e54-837f-d57ac0af28c0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027576914s
STEP: Saw pod success
Aug 14 06:48:08.931: INFO: Pod "pod-secrets-d565fa20-46b7-4e54-837f-d57ac0af28c0" satisfied condition "success or failure"
Aug 14 06:48:08.944: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod pod-secrets-d565fa20-46b7-4e54-837f-d57ac0af28c0 container secret-volume-test: <nil>
STEP: delete the pod
Aug 14 06:48:08.988: INFO: Waiting for pod pod-secrets-d565fa20-46b7-4e54-837f-d57ac0af28c0 to disappear
Aug 14 06:48:09.001: INFO: Pod pod-secrets-d565fa20-46b7-4e54-837f-d57ac0af28c0 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 06:48:09.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8849" for this suite.
Aug 14 06:48:15.058: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 06:48:15.574: INFO: namespace secrets-8849 deletion completed in 6.557940768s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 06:48:15.574: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3644
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 14 06:48:15.878: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c14198a5-3772-4a9f-a77d-e9d55b5f2f1c" in namespace "downward-api-3644" to be "success or failure"
Aug 14 06:48:15.891: INFO: Pod "downwardapi-volume-c14198a5-3772-4a9f-a77d-e9d55b5f2f1c": Phase="Pending", Reason="", readiness=false. Elapsed: 13.174623ms
Aug 14 06:48:17.905: INFO: Pod "downwardapi-volume-c14198a5-3772-4a9f-a77d-e9d55b5f2f1c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027496589s
STEP: Saw pod success
Aug 14 06:48:17.906: INFO: Pod "downwardapi-volume-c14198a5-3772-4a9f-a77d-e9d55b5f2f1c" satisfied condition "success or failure"
Aug 14 06:48:17.919: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod downwardapi-volume-c14198a5-3772-4a9f-a77d-e9d55b5f2f1c container client-container: <nil>
STEP: delete the pod
Aug 14 06:48:17.958: INFO: Waiting for pod downwardapi-volume-c14198a5-3772-4a9f-a77d-e9d55b5f2f1c to disappear
Aug 14 06:48:17.972: INFO: Pod downwardapi-volume-c14198a5-3772-4a9f-a77d-e9d55b5f2f1c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 06:48:17.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3644" for this suite.
Aug 14 06:48:26.031: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 06:48:26.549: INFO: namespace downward-api-3644 deletion completed in 8.561226894s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 06:48:26.550: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2599
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Aug 14 06:48:26.906: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 06:48:36.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2599" for this suite.
Aug 14 06:48:42.431: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 06:48:42.935: INFO: namespace pods-2599 deletion completed in 6.546424943s
•SSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 06:48:42.935: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9740
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Aug 14 06:48:45.798: INFO: Successfully updated pod "annotationupdate6db97092-066a-48b5-82a5-a520e33c3c4a"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 06:48:49.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9740" for this suite.
Aug 14 06:49:11.920: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 06:49:12.482: INFO: namespace downward-api-9740 deletion completed in 22.605827558s
•SSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 06:49:12.482: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-7783
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-7783.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-7783.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7783.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-7783.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-7783.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7783.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 14 06:49:25.475: INFO: DNS probes using dns-7783/dns-test-12a831fb-4dd1-423b-8d9b-854f6fc3503b succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 06:49:25.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7783" for this suite.
Aug 14 06:49:31.555: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 06:49:32.070: INFO: namespace dns-7783 deletion completed in 6.558979925s
•SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 06:49:32.070: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-1617
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 06:49:34.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1617" for this suite.
Aug 14 06:50:18.503: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 06:50:19.045: INFO: namespace kubelet-test-1617 deletion completed in 44.585082741s
•S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 06:50:19.046: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-706
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: executing a command with run --rm and attach with stdin
Aug 14 06:50:19.275: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-706 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Aug 14 06:50:21.020: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Aug 14 06:50:21.020: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 06:50:23.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-706" for this suite.
Aug 14 06:50:29.143: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 06:50:29.661: INFO: namespace kubectl-706 deletion completed in 6.5799192s
•SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 06:50:29.661: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-8710
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating replication controller my-hostname-basic-a35153a0-63cb-4321-a863-a71f50f5cf59
Aug 14 06:50:29.996: INFO: Pod name my-hostname-basic-a35153a0-63cb-4321-a863-a71f50f5cf59: Found 1 pods out of 1
Aug 14 06:50:29.996: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-a35153a0-63cb-4321-a863-a71f50f5cf59" are running
Aug 14 06:50:32.062: INFO: Pod "my-hostname-basic-a35153a0-63cb-4321-a863-a71f50f5cf59-xklll" is running (conditions: [{Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-14 06:50:29 +0000 UTC Reason: Message:}])
Aug 14 06:50:32.062: INFO: Trying to dial the pod
Aug 14 06:50:37.247: INFO: Controller my-hostname-basic-a35153a0-63cb-4321-a863-a71f50f5cf59: Got expected result from replica 1 [my-hostname-basic-a35153a0-63cb-4321-a863-a71f50f5cf59-xklll]: "my-hostname-basic-a35153a0-63cb-4321-a863-a71f50f5cf59-xklll", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 06:50:37.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8710" for this suite.
Aug 14 06:50:45.343: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 06:50:45.882: INFO: namespace replication-controller-8710 deletion completed in 8.609251498s
•S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 06:50:45.882: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-5193
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 14 06:50:46.078: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 06:50:46.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-5193" for this suite.
Aug 14 06:50:52.492: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 06:50:53.001: INFO: namespace custom-resource-definition-5193 deletion completed in 6.552469383s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 06:50:53.001: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-934
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 14 06:50:53.385: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f8fe7b38-3d9c-406f-82c8-d86e22845c45" in namespace "projected-934" to be "success or failure"
Aug 14 06:50:53.398: INFO: Pod "downwardapi-volume-f8fe7b38-3d9c-406f-82c8-d86e22845c45": Phase="Pending", Reason="", readiness=false. Elapsed: 13.369939ms
Aug 14 06:50:55.413: INFO: Pod "downwardapi-volume-f8fe7b38-3d9c-406f-82c8-d86e22845c45": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027992651s
STEP: Saw pod success
Aug 14 06:50:55.413: INFO: Pod "downwardapi-volume-f8fe7b38-3d9c-406f-82c8-d86e22845c45" satisfied condition "success or failure"
Aug 14 06:50:55.426: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod downwardapi-volume-f8fe7b38-3d9c-406f-82c8-d86e22845c45 container client-container: <nil>
STEP: delete the pod
Aug 14 06:50:55.464: INFO: Waiting for pod downwardapi-volume-f8fe7b38-3d9c-406f-82c8-d86e22845c45 to disappear
Aug 14 06:50:55.478: INFO: Pod downwardapi-volume-f8fe7b38-3d9c-406f-82c8-d86e22845c45 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 06:50:55.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-934" for this suite.
Aug 14 06:51:01.534: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 06:51:01.923: INFO: namespace projected-934 deletion completed in 6.429157559s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 06:51:01.923: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-8607
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Aug 14 06:51:10.285: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 14 06:51:10.295: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 14 06:51:12.296: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 14 06:51:12.309: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 14 06:51:14.296: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 14 06:51:14.307: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 14 06:51:16.296: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 14 06:51:16.307: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 14 06:51:18.296: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 14 06:51:18.307: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 14 06:51:20.296: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 14 06:51:20.307: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 14 06:51:22.296: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 14 06:51:22.308: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 14 06:51:24.296: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 14 06:51:24.307: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 14 06:51:26.296: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 14 06:51:26.307: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 14 06:51:28.296: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 14 06:51:28.308: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 14 06:51:30.296: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 14 06:51:30.307: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 14 06:51:32.296: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 14 06:51:32.309: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 14 06:51:34.296: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 14 06:51:34.307: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 14 06:51:36.296: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 14 06:51:36.307: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 14 06:51:38.296: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 14 06:51:38.307: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 06:51:38.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8607" for this suite.
Aug 14 06:52:00.358: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 06:52:00.750: INFO: namespace container-lifecycle-hook-8607 deletion completed in 22.426406094s
•SSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 06:52:00.751: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-7358
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 14 06:52:19.018: INFO: Container started at 2019-08-14 06:52:01 +0000 UTC, pod became ready at 2019-08-14 06:52:18 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 06:52:19.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7358" for this suite.
Aug 14 06:52:41.063: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 06:52:41.491: INFO: namespace container-probe-7358 deletion completed in 22.461140348s
•
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 06:52:41.491: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-7800
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-7800
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Aug 14 06:52:41.800: INFO: Found 1 stateful pods, waiting for 3
Aug 14 06:52:51.813: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 14 06:52:51.813: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 14 06:52:51.813: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Aug 14 06:52:51.878: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Aug 14 06:52:51.931: INFO: Updating stateful set ss2
Aug 14 06:52:51.952: INFO: Waiting for Pod statefulset-7800/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Restoring Pods to the correct revision when they are deleted
Aug 14 06:53:02.015: INFO: Found 2 stateful pods, waiting for 3
Aug 14 06:53:12.028: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 14 06:53:12.028: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 14 06:53:12.028: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Aug 14 06:53:12.081: INFO: Updating stateful set ss2
Aug 14 06:53:12.103: INFO: Waiting for Pod statefulset-7800/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Aug 14 06:53:22.158: INFO: Updating stateful set ss2
Aug 14 06:53:22.178: INFO: Waiting for StatefulSet statefulset-7800/ss2 to complete update
Aug 14 06:53:22.179: INFO: Waiting for Pod statefulset-7800/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Aug 14 06:53:32.200: INFO: Deleting all statefulset in ns statefulset-7800
Aug 14 06:53:32.211: INFO: Scaling statefulset ss2 to 0
Aug 14 06:54:02.255: INFO: Waiting for statefulset status.replicas updated to 0
Aug 14 06:54:02.265: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 06:54:02.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7800" for this suite.
Aug 14 06:54:08.343: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 06:54:08.732: INFO: namespace statefulset-7800 deletion completed in 6.42267279s
•SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 06:54:08.733: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-5318
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:76
Aug 14 06:54:09.060: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Registering the sample API server.
Aug 14 06:54:09.633: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701362449, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701362449, loc:(*time.Location)(0x80bfa40)}}, Reason:"NewReplicaSetCreated", Message:"Created new replica set \"sample-apiserver-deployment-7c4bdb86cc\""}, v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701362449, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701362449, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}}, CollisionCount:(*int32)(nil)}
Aug 14 06:54:11.645: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701362449, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701362449, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701362449, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701362449, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 14 06:54:13.645: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701362449, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701362449, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701362449, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701362449, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 14 06:54:15.644: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701362449, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701362449, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701362449, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701362449, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 14 06:54:17.644: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701362449, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701362449, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701362449, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701362449, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 14 06:54:19.644: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701362449, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701362449, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701362449, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701362449, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 14 06:54:21.645: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701362449, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701362449, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701362449, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701362449, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 14 06:54:25.360: INFO: Waited 1.703127328s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:67
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 06:54:26.343: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-5318" for this suite.
Aug 14 06:54:32.388: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 06:54:32.775: INFO: namespace aggregator-5318 deletion completed in 6.421196296s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 06:54:32.776: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7043
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Aug 14 06:54:32.986: INFO: Waiting up to 5m0s for pod "downward-api-d1ecd280-2128-4bc6-b42f-960cff29cd09" in namespace "downward-api-7043" to be "success or failure"
Aug 14 06:54:32.996: INFO: Pod "downward-api-d1ecd280-2128-4bc6-b42f-960cff29cd09": Phase="Pending", Reason="", readiness=false. Elapsed: 10.33362ms
Aug 14 06:54:35.008: INFO: Pod "downward-api-d1ecd280-2128-4bc6-b42f-960cff29cd09": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021695961s
STEP: Saw pod success
Aug 14 06:54:35.008: INFO: Pod "downward-api-d1ecd280-2128-4bc6-b42f-960cff29cd09" satisfied condition "success or failure"
Aug 14 06:54:35.018: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod downward-api-d1ecd280-2128-4bc6-b42f-960cff29cd09 container dapi-container: <nil>
STEP: delete the pod
Aug 14 06:54:35.054: INFO: Waiting for pod downward-api-d1ecd280-2128-4bc6-b42f-960cff29cd09 to disappear
Aug 14 06:54:35.066: INFO: Pod downward-api-d1ecd280-2128-4bc6-b42f-960cff29cd09 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 06:54:35.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7043" for this suite.
Aug 14 06:54:41.118: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 06:54:41.507: INFO: namespace downward-api-7043 deletion completed in 6.422637717s
•SSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 06:54:41.507: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-4987
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
STEP: reading a file in the container
Aug 14 06:54:44.433: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl exec --namespace=svcaccounts-4987 pod-service-account-58b192cf-05a3-4008-91b2-2195dbf8bff7 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Aug 14 06:54:45.038: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl exec --namespace=svcaccounts-4987 pod-service-account-58b192cf-05a3-4008-91b2-2195dbf8bff7 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Aug 14 06:54:45.648: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl exec --namespace=svcaccounts-4987 pod-service-account-58b192cf-05a3-4008-91b2-2195dbf8bff7 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 06:54:46.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4987" for this suite.
Aug 14 06:54:54.441: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 06:54:54.863: INFO: namespace svcaccounts-4987 deletion completed in 8.454991943s
•SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 06:54:54.864: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-4196
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 14 06:54:55.072: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Aug 14 06:54:55.096: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Aug 14 06:54:57.117: INFO: Creating deployment "test-rolling-update-deployment"
Aug 14 06:54:57.129: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Aug 14 06:54:57.151: INFO: deployment "test-rolling-update-deployment" doesn't have the required revision set
Aug 14 06:54:59.173: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Aug 14 06:54:59.184: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Aug 14 06:54:59.215: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-4196,SelfLink:/apis/apps/v1/namespaces/deployment-4196/deployments/test-rolling-update-deployment,UID:24d364a6-3843-4d9a-91ae-ac6bf69a5952,ResourceVersion:6837,Generation:1,CreationTimestamp:2019-08-14 06:54:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-08-14 06:54:57 +0000 UTC 2019-08-14 06:54:57 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-08-14 06:54:58 +0000 UTC 2019-08-14 06:54:57 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-79f6b9d75c" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Aug 14 06:54:59.226: INFO: New ReplicaSet "test-rolling-update-deployment-79f6b9d75c" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c,GenerateName:,Namespace:deployment-4196,SelfLink:/apis/apps/v1/namespaces/deployment-4196/replicasets/test-rolling-update-deployment-79f6b9d75c,UID:5ef291c6-d11a-472c-b9ec-8cc9d1820257,ResourceVersion:6830,Generation:1,CreationTimestamp:2019-08-14 06:54:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 24d364a6-3843-4d9a-91ae-ac6bf69a5952 0xc0037ae747 0xc0037ae748}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Aug 14 06:54:59.226: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Aug 14 06:54:59.226: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-4196,SelfLink:/apis/apps/v1/namespaces/deployment-4196/replicasets/test-rolling-update-controller,UID:539763a4-a114-4460-b666-bdef206b8eb9,ResourceVersion:6836,Generation:2,CreationTimestamp:2019-08-14 06:54:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 24d364a6-3843-4d9a-91ae-ac6bf69a5952 0xc0037ae66f 0xc0037ae680}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 14 06:54:59.237: INFO: Pod "test-rolling-update-deployment-79f6b9d75c-df6fw" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c-df6fw,GenerateName:test-rolling-update-deployment-79f6b9d75c-,Namespace:deployment-4196,SelfLink:/api/v1/namespaces/deployment-4196/pods/test-rolling-update-deployment-79f6b9d75c-df6fw,UID:8609a97c-1e0d-4bbe-81e8-0ea768e0f8b4,ResourceVersion:6829,Generation:0,CreationTimestamp:2019-08-14 06:54:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.57/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-79f6b9d75c 5ef291c6-d11a-472c-b9ec-8cc9d1820257 0xc0037af017 0xc0037af018}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nfpwc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nfpwc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-nfpwc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0037af080} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0037af0a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 06:54:57 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 06:54:58 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 06:54:58 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 06:54:57 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:100.96.1.57,StartTime:2019-08-14 06:54:57 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-08-14 06:54:58 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://bb93c13284b968d50d1ddda870018fc5911d5a1098057410abb3a5c8abd2bf2c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 06:54:59.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4196" for this suite.
Aug 14 06:55:05.289: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 06:55:05.687: INFO: namespace deployment-4196 deletion completed in 6.43156863s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 06:55:05.688: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3676
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-projected-all-test-volume-b5233f5c-341b-48ec-b72f-1780107d312d
STEP: Creating secret with name secret-projected-all-test-volume-f20a55b0-5a4a-46d8-aea6-b7f7181a147f
STEP: Creating a pod to test Check all projections for projected volume plugin
Aug 14 06:55:05.909: INFO: Waiting up to 5m0s for pod "projected-volume-c55c906d-8100-4db2-b11f-bfe050e4df98" in namespace "projected-3676" to be "success or failure"
Aug 14 06:55:05.923: INFO: Pod "projected-volume-c55c906d-8100-4db2-b11f-bfe050e4df98": Phase="Pending", Reason="", readiness=false. Elapsed: 14.586467ms
Aug 14 06:55:07.935: INFO: Pod "projected-volume-c55c906d-8100-4db2-b11f-bfe050e4df98": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025953296s
STEP: Saw pod success
Aug 14 06:55:07.935: INFO: Pod "projected-volume-c55c906d-8100-4db2-b11f-bfe050e4df98" satisfied condition "success or failure"
Aug 14 06:55:07.945: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod projected-volume-c55c906d-8100-4db2-b11f-bfe050e4df98 container projected-all-volume-test: <nil>
STEP: delete the pod
Aug 14 06:55:07.977: INFO: Waiting for pod projected-volume-c55c906d-8100-4db2-b11f-bfe050e4df98 to disappear
Aug 14 06:55:07.987: INFO: Pod projected-volume-c55c906d-8100-4db2-b11f-bfe050e4df98 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 06:55:07.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3676" for this suite.
Aug 14 06:55:14.039: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 06:55:14.459: INFO: namespace projected-3676 deletion completed in 6.453122027s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 06:55:14.460: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-27
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Aug 14 06:55:15.242: INFO: Pod name wrapped-volume-race-cadacc0b-c221-4719-8406-6c6435ad345f: Found 1 pods out of 5
Aug 14 06:55:20.267: INFO: Pod name wrapped-volume-race-cadacc0b-c221-4719-8406-6c6435ad345f: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-cadacc0b-c221-4719-8406-6c6435ad345f in namespace emptydir-wrapper-27, will wait for the garbage collector to delete the pods
Aug 14 06:55:26.411: INFO: Deleting ReplicationController wrapped-volume-race-cadacc0b-c221-4719-8406-6c6435ad345f took: 14.891018ms
Aug 14 06:55:26.811: INFO: Terminating ReplicationController wrapped-volume-race-cadacc0b-c221-4719-8406-6c6435ad345f pods took: 400.287796ms
STEP: Creating RC which spawns configmap-volume pods
Aug 14 06:56:05.551: INFO: Pod name wrapped-volume-race-82cabf36-ee34-4535-8d59-5142444fa8a4: Found 1 pods out of 5
Aug 14 06:56:10.576: INFO: Pod name wrapped-volume-race-82cabf36-ee34-4535-8d59-5142444fa8a4: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-82cabf36-ee34-4535-8d59-5142444fa8a4 in namespace emptydir-wrapper-27, will wait for the garbage collector to delete the pods
Aug 14 06:56:10.704: INFO: Deleting ReplicationController wrapped-volume-race-82cabf36-ee34-4535-8d59-5142444fa8a4 took: 13.864814ms
Aug 14 06:56:10.804: INFO: Terminating ReplicationController wrapped-volume-race-82cabf36-ee34-4535-8d59-5142444fa8a4 pods took: 100.249043ms
STEP: Creating RC which spawns configmap-volume pods
Aug 14 06:56:45.641: INFO: Pod name wrapped-volume-race-c0c22ae3-39cf-46c5-b6d2-b89c2923a12a: Found 1 pods out of 5
Aug 14 06:56:50.662: INFO: Pod name wrapped-volume-race-c0c22ae3-39cf-46c5-b6d2-b89c2923a12a: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-c0c22ae3-39cf-46c5-b6d2-b89c2923a12a in namespace emptydir-wrapper-27, will wait for the garbage collector to delete the pods
Aug 14 06:56:50.792: INFO: Deleting ReplicationController wrapped-volume-race-c0c22ae3-39cf-46c5-b6d2-b89c2923a12a took: 13.852948ms
Aug 14 06:56:51.192: INFO: Terminating ReplicationController wrapped-volume-race-c0c22ae3-39cf-46c5-b6d2-b89c2923a12a pods took: 400.324149ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 06:57:36.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-27" for this suite.
Aug 14 06:57:42.195: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 06:57:42.582: INFO: namespace emptydir-wrapper-27 deletion completed in 6.418800832s
•SSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 06:57:42.583: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-1767
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Aug 14 06:57:43.142: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-1767,SelfLink:/api/v1/namespaces/watch-1767/configmaps/e2e-watch-test-resource-version,UID:b209b38b-6961-4bd8-8745-293c91592dae,ResourceVersion:7576,Generation:0,CreationTimestamp:2019-08-14 06:57:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 14 06:57:43.143: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-1767,SelfLink:/api/v1/namespaces/watch-1767/configmaps/e2e-watch-test-resource-version,UID:b209b38b-6961-4bd8-8745-293c91592dae,ResourceVersion:7577,Generation:0,CreationTimestamp:2019-08-14 06:57:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 06:57:43.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1767" for this suite.
Aug 14 06:57:49.185: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 06:57:49.561: INFO: namespace watch-1767 deletion completed in 6.408267319s
•SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 06:57:49.562: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7439
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Aug 14 06:57:52.544: INFO: Successfully updated pod "labelsupdate8e2ba546-2b4a-4605-a338-119751f10792"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 06:57:54.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7439" for this suite.
Aug 14 06:58:16.631: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 06:58:17.015: INFO: namespace projected-7439 deletion completed in 22.417247267s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 06:58:17.016: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5537
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 14 06:58:17.381: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7034dc9e-fb18-4e88-ae2a-80aa0a9fe9ae" in namespace "downward-api-5537" to be "success or failure"
Aug 14 06:58:17.391: INFO: Pod "downwardapi-volume-7034dc9e-fb18-4e88-ae2a-80aa0a9fe9ae": Phase="Pending", Reason="", readiness=false. Elapsed: 9.946689ms
Aug 14 06:58:19.406: INFO: Pod "downwardapi-volume-7034dc9e-fb18-4e88-ae2a-80aa0a9fe9ae": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024113368s
STEP: Saw pod success
Aug 14 06:58:19.406: INFO: Pod "downwardapi-volume-7034dc9e-fb18-4e88-ae2a-80aa0a9fe9ae" satisfied condition "success or failure"
Aug 14 06:58:19.416: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod downwardapi-volume-7034dc9e-fb18-4e88-ae2a-80aa0a9fe9ae container client-container: <nil>
STEP: delete the pod
Aug 14 06:58:19.449: INFO: Waiting for pod downwardapi-volume-7034dc9e-fb18-4e88-ae2a-80aa0a9fe9ae to disappear
Aug 14 06:58:19.459: INFO: Pod downwardapi-volume-7034dc9e-fb18-4e88-ae2a-80aa0a9fe9ae no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 06:58:19.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5537" for this suite.
Aug 14 06:58:25.511: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 06:58:25.910: INFO: namespace downward-api-5537 deletion completed in 6.433352166s
•SSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 06:58:25.911: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-4837
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4837.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-4837.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4837.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-4837.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4837.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-4837.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4837.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-4837.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4837.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-4837.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4837.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-4837.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4837.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 226.68.64.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.64.68.226_udp@PTR;check="$$(dig +tcp +noall +answer +search 226.68.64.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.64.68.226_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4837.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-4837.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4837.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-4837.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4837.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-4837.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4837.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-4837.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4837.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-4837.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4837.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-4837.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4837.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 226.68.64.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.64.68.226_udp@PTR;check="$$(dig +tcp +noall +answer +search 226.68.64.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.64.68.226_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 14 06:58:28.343: INFO: Unable to read wheezy_udp@dns-test-service.dns-4837.svc.cluster.local from pod dns-4837/dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001: the server could not find the requested resource (get pods dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001)
Aug 14 06:58:28.386: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4837.svc.cluster.local from pod dns-4837/dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001: the server could not find the requested resource (get pods dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001)
Aug 14 06:58:28.398: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4837.svc.cluster.local from pod dns-4837/dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001: the server could not find the requested resource (get pods dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001)
Aug 14 06:58:28.411: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4837.svc.cluster.local from pod dns-4837/dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001: the server could not find the requested resource (get pods dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001)
Aug 14 06:58:28.843: INFO: Unable to read jessie_udp@dns-test-service.dns-4837.svc.cluster.local from pod dns-4837/dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001: the server could not find the requested resource (get pods dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001)
Aug 14 06:58:28.855: INFO: Unable to read jessie_tcp@dns-test-service.dns-4837.svc.cluster.local from pod dns-4837/dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001: the server could not find the requested resource (get pods dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001)
Aug 14 06:58:28.950: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4837.svc.cluster.local from pod dns-4837/dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001: the server could not find the requested resource (get pods dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001)
Aug 14 06:58:29.301: INFO: Lookups using dns-4837/dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001 failed for: [wheezy_udp@dns-test-service.dns-4837.svc.cluster.local wheezy_tcp@dns-test-service.dns-4837.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4837.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4837.svc.cluster.local jessie_udp@dns-test-service.dns-4837.svc.cluster.local jessie_tcp@dns-test-service.dns-4837.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4837.svc.cluster.local]

Aug 14 06:58:34.314: INFO: Unable to read wheezy_udp@dns-test-service.dns-4837.svc.cluster.local from pod dns-4837/dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001: the server could not find the requested resource (get pods dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001)
Aug 14 06:58:34.326: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4837.svc.cluster.local from pod dns-4837/dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001: the server could not find the requested resource (get pods dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001)
Aug 14 06:58:34.842: INFO: Unable to read jessie_udp@dns-test-service.dns-4837.svc.cluster.local from pod dns-4837/dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001: the server could not find the requested resource (get pods dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001)
Aug 14 06:58:34.861: INFO: Unable to read jessie_tcp@dns-test-service.dns-4837.svc.cluster.local from pod dns-4837/dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001: the server could not find the requested resource (get pods dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001)
Aug 14 06:58:35.386: INFO: Lookups using dns-4837/dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001 failed for: [wheezy_udp@dns-test-service.dns-4837.svc.cluster.local wheezy_tcp@dns-test-service.dns-4837.svc.cluster.local jessie_udp@dns-test-service.dns-4837.svc.cluster.local jessie_tcp@dns-test-service.dns-4837.svc.cluster.local]

Aug 14 06:58:39.316: INFO: Unable to read wheezy_udp@dns-test-service.dns-4837.svc.cluster.local from pod dns-4837/dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001: the server could not find the requested resource (get pods dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001)
Aug 14 06:58:39.330: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4837.svc.cluster.local from pod dns-4837/dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001: the server could not find the requested resource (get pods dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001)
Aug 14 06:58:40.027: INFO: Unable to read jessie_udp@dns-test-service.dns-4837.svc.cluster.local from pod dns-4837/dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001: the server could not find the requested resource (get pods dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001)
Aug 14 06:58:40.055: INFO: Unable to read jessie_tcp@dns-test-service.dns-4837.svc.cluster.local from pod dns-4837/dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001: the server could not find the requested resource (get pods dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001)
Aug 14 06:58:40.559: INFO: Lookups using dns-4837/dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001 failed for: [wheezy_udp@dns-test-service.dns-4837.svc.cluster.local wheezy_tcp@dns-test-service.dns-4837.svc.cluster.local jessie_udp@dns-test-service.dns-4837.svc.cluster.local jessie_tcp@dns-test-service.dns-4837.svc.cluster.local]

Aug 14 06:58:44.318: INFO: Unable to read wheezy_udp@dns-test-service.dns-4837.svc.cluster.local from pod dns-4837/dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001: the server could not find the requested resource (get pods dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001)
Aug 14 06:58:44.330: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4837.svc.cluster.local from pod dns-4837/dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001: the server could not find the requested resource (get pods dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001)
Aug 14 06:58:44.887: INFO: Unable to read jessie_udp@dns-test-service.dns-4837.svc.cluster.local from pod dns-4837/dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001: the server could not find the requested resource (get pods dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001)
Aug 14 06:58:44.898: INFO: Unable to read jessie_tcp@dns-test-service.dns-4837.svc.cluster.local from pod dns-4837/dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001: the server could not find the requested resource (get pods dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001)
Aug 14 06:58:45.413: INFO: Lookups using dns-4837/dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001 failed for: [wheezy_udp@dns-test-service.dns-4837.svc.cluster.local wheezy_tcp@dns-test-service.dns-4837.svc.cluster.local jessie_udp@dns-test-service.dns-4837.svc.cluster.local jessie_tcp@dns-test-service.dns-4837.svc.cluster.local]

Aug 14 06:58:49.314: INFO: Unable to read wheezy_udp@dns-test-service.dns-4837.svc.cluster.local from pod dns-4837/dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001: the server could not find the requested resource (get pods dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001)
Aug 14 06:58:49.356: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4837.svc.cluster.local from pod dns-4837/dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001: the server could not find the requested resource (get pods dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001)
Aug 14 06:58:49.872: INFO: Unable to read jessie_udp@dns-test-service.dns-4837.svc.cluster.local from pod dns-4837/dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001: the server could not find the requested resource (get pods dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001)
Aug 14 06:58:49.884: INFO: Unable to read jessie_tcp@dns-test-service.dns-4837.svc.cluster.local from pod dns-4837/dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001: the server could not find the requested resource (get pods dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001)
Aug 14 06:58:50.405: INFO: Lookups using dns-4837/dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001 failed for: [wheezy_udp@dns-test-service.dns-4837.svc.cluster.local wheezy_tcp@dns-test-service.dns-4837.svc.cluster.local jessie_udp@dns-test-service.dns-4837.svc.cluster.local jessie_tcp@dns-test-service.dns-4837.svc.cluster.local]

Aug 14 06:58:54.313: INFO: Unable to read wheezy_udp@dns-test-service.dns-4837.svc.cluster.local from pod dns-4837/dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001: the server could not find the requested resource (get pods dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001)
Aug 14 06:58:54.326: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4837.svc.cluster.local from pod dns-4837/dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001: the server could not find the requested resource (get pods dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001)
Aug 14 06:58:54.883: INFO: Unable to read jessie_udp@dns-test-service.dns-4837.svc.cluster.local from pod dns-4837/dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001: the server could not find the requested resource (get pods dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001)
Aug 14 06:58:54.896: INFO: Unable to read jessie_tcp@dns-test-service.dns-4837.svc.cluster.local from pod dns-4837/dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001: the server could not find the requested resource (get pods dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001)
Aug 14 06:58:55.370: INFO: Lookups using dns-4837/dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001 failed for: [wheezy_udp@dns-test-service.dns-4837.svc.cluster.local wheezy_tcp@dns-test-service.dns-4837.svc.cluster.local jessie_udp@dns-test-service.dns-4837.svc.cluster.local jessie_tcp@dns-test-service.dns-4837.svc.cluster.local]

Aug 14 06:59:00.575: INFO: DNS probes using dns-4837/dns-test-faba94c4-d1d0-44eb-8b41-80f10d884001 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 06:59:00.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4837" for this suite.
Aug 14 06:59:06.676: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 06:59:07.053: INFO: namespace dns-4837 deletion completed in 6.40976307s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 06:59:07.054: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-7280
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service endpoint-test2 in namespace services-7280
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7280 to expose endpoints map[]
Aug 14 06:59:07.388: INFO: successfully validated that service endpoint-test2 in namespace services-7280 exposes endpoints map[] (9.770694ms elapsed)
STEP: Creating pod pod1 in namespace services-7280
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7280 to expose endpoints map[pod1:[80]]
Aug 14 06:59:09.463: INFO: successfully validated that service endpoint-test2 in namespace services-7280 exposes endpoints map[pod1:[80]] (2.061612884s elapsed)
STEP: Creating pod pod2 in namespace services-7280
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7280 to expose endpoints map[pod1:[80] pod2:[80]]
Aug 14 06:59:11.568: INFO: successfully validated that service endpoint-test2 in namespace services-7280 exposes endpoints map[pod1:[80] pod2:[80]] (2.094592958s elapsed)
STEP: Deleting pod pod1 in namespace services-7280
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7280 to expose endpoints map[pod2:[80]]
Aug 14 06:59:11.601: INFO: successfully validated that service endpoint-test2 in namespace services-7280 exposes endpoints map[pod2:[80]] (20.254563ms elapsed)
STEP: Deleting pod pod2 in namespace services-7280
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7280 to expose endpoints map[]
Aug 14 06:59:11.623: INFO: successfully validated that service endpoint-test2 in namespace services-7280 exposes endpoints map[] (9.820395ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 06:59:11.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7280" for this suite.
Aug 14 06:59:35.695: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 06:59:36.118: INFO: namespace services-7280 deletion completed in 24.454977428s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92
•
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 06:59:36.118: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-1943
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0814 06:59:42.547919    4167 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 14 06:59:42.771: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 06:59:42.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1943" for this suite.
Aug 14 06:59:48.825: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 06:59:49.213: INFO: namespace gc-1943 deletion completed in 6.422494245s
•SS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 06:59:49.213: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9851
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-060ebecc-149e-4073-ac0a-1cd711f31913
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 06:59:53.734: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9851" for this suite.
Aug 14 07:00:15.787: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:00:16.173: INFO: namespace configmap-9851 deletion completed in 22.419113708s
•
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:00:16.173: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4045
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-3a270ac4-aabf-4129-9dfc-7543d6954382
STEP: Creating a pod to test consume secrets
Aug 14 07:00:16.483: INFO: Waiting up to 5m0s for pod "pod-secrets-0f194e86-592c-4a1b-9241-768db45627b4" in namespace "secrets-4045" to be "success or failure"
Aug 14 07:00:16.494: INFO: Pod "pod-secrets-0f194e86-592c-4a1b-9241-768db45627b4": Phase="Pending", Reason="", readiness=false. Elapsed: 10.39783ms
Aug 14 07:00:18.505: INFO: Pod "pod-secrets-0f194e86-592c-4a1b-9241-768db45627b4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021888562s
STEP: Saw pod success
Aug 14 07:00:18.505: INFO: Pod "pod-secrets-0f194e86-592c-4a1b-9241-768db45627b4" satisfied condition "success or failure"
Aug 14 07:00:18.516: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod pod-secrets-0f194e86-592c-4a1b-9241-768db45627b4 container secret-volume-test: <nil>
STEP: delete the pod
Aug 14 07:00:18.552: INFO: Waiting for pod pod-secrets-0f194e86-592c-4a1b-9241-768db45627b4 to disappear
Aug 14 07:00:18.562: INFO: Pod pod-secrets-0f194e86-592c-4a1b-9241-768db45627b4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:00:18.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4045" for this suite.
Aug 14 07:00:24.614: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:00:24.998: INFO: namespace secrets-4045 deletion completed in 6.417753969s
•SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:00:24.998: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5711
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Aug 14 07:00:25.282: INFO: Waiting up to 5m0s for pod "pod-05f6fa9a-d1a9-403f-8061-1047f0c4faea" in namespace "emptydir-5711" to be "success or failure"
Aug 14 07:00:25.326: INFO: Pod "pod-05f6fa9a-d1a9-403f-8061-1047f0c4faea": Phase="Pending", Reason="", readiness=false. Elapsed: 43.056405ms
Aug 14 07:00:27.337: INFO: Pod "pod-05f6fa9a-d1a9-403f-8061-1047f0c4faea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.054119218s
STEP: Saw pod success
Aug 14 07:00:27.337: INFO: Pod "pod-05f6fa9a-d1a9-403f-8061-1047f0c4faea" satisfied condition "success or failure"
Aug 14 07:00:27.347: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod pod-05f6fa9a-d1a9-403f-8061-1047f0c4faea container test-container: <nil>
STEP: delete the pod
Aug 14 07:00:27.378: INFO: Waiting for pod pod-05f6fa9a-d1a9-403f-8061-1047f0c4faea to disappear
Aug 14 07:00:27.389: INFO: Pod pod-05f6fa9a-d1a9-403f-8061-1047f0c4faea no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:00:27.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5711" for this suite.
Aug 14 07:00:33.443: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:00:33.825: INFO: namespace emptydir-5711 deletion completed in 6.416685766s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:00:33.826: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1691
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on tmpfs
Aug 14 07:00:34.175: INFO: Waiting up to 5m0s for pod "pod-2e9cb74e-67c4-42b9-b4f5-c44e44e9c795" in namespace "emptydir-1691" to be "success or failure"
Aug 14 07:00:34.185: INFO: Pod "pod-2e9cb74e-67c4-42b9-b4f5-c44e44e9c795": Phase="Pending", Reason="", readiness=false. Elapsed: 9.86095ms
Aug 14 07:00:36.196: INFO: Pod "pod-2e9cb74e-67c4-42b9-b4f5-c44e44e9c795": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021238222s
STEP: Saw pod success
Aug 14 07:00:36.196: INFO: Pod "pod-2e9cb74e-67c4-42b9-b4f5-c44e44e9c795" satisfied condition "success or failure"
Aug 14 07:00:36.207: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod pod-2e9cb74e-67c4-42b9-b4f5-c44e44e9c795 container test-container: <nil>
STEP: delete the pod
Aug 14 07:00:36.241: INFO: Waiting for pod pod-2e9cb74e-67c4-42b9-b4f5-c44e44e9c795 to disappear
Aug 14 07:00:36.251: INFO: Pod pod-2e9cb74e-67c4-42b9-b4f5-c44e44e9c795 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:00:36.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1691" for this suite.
Aug 14 07:00:42.304: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:00:42.692: INFO: namespace emptydir-1691 deletion completed in 6.422235298s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:00:42.692: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-2337
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 14 07:00:43.009: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"5169b42c-6e48-4718-b8bf-cba46a09912a", Controller:(*bool)(0xc00359b36a), BlockOwnerDeletion:(*bool)(0xc00359b36b)}}
Aug 14 07:00:43.020: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"0119c7b4-08a3-4735-88c8-ffe62de070d9", Controller:(*bool)(0xc003212196), BlockOwnerDeletion:(*bool)(0xc003212197)}}
Aug 14 07:00:43.032: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"c17d87f0-b987-4e2f-bbdb-36ad70cdaa37", Controller:(*bool)(0xc002944d26), BlockOwnerDeletion:(*bool)(0xc002944d27)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:00:48.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2337" for this suite.
Aug 14 07:00:54.108: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:00:54.497: INFO: namespace gc-2337 deletion completed in 6.423013441s
•SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:00:54.497: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5513
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-a2941193-7ab9-4ffa-ade7-c1f99ff37840
STEP: Creating a pod to test consume configMaps
Aug 14 07:00:54.882: INFO: Waiting up to 5m0s for pod "pod-configmaps-99253588-ce08-402e-9984-e6ec978fb16f" in namespace "configmap-5513" to be "success or failure"
Aug 14 07:00:54.892: INFO: Pod "pod-configmaps-99253588-ce08-402e-9984-e6ec978fb16f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.002627ms
Aug 14 07:00:56.903: INFO: Pod "pod-configmaps-99253588-ce08-402e-9984-e6ec978fb16f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021097788s
STEP: Saw pod success
Aug 14 07:00:56.903: INFO: Pod "pod-configmaps-99253588-ce08-402e-9984-e6ec978fb16f" satisfied condition "success or failure"
Aug 14 07:00:56.914: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod pod-configmaps-99253588-ce08-402e-9984-e6ec978fb16f container configmap-volume-test: <nil>
STEP: delete the pod
Aug 14 07:00:56.947: INFO: Waiting for pod pod-configmaps-99253588-ce08-402e-9984-e6ec978fb16f to disappear
Aug 14 07:00:56.957: INFO: Pod pod-configmaps-99253588-ce08-402e-9984-e6ec978fb16f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:00:56.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5513" for this suite.
Aug 14 07:01:03.010: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:01:03.392: INFO: namespace configmap-5513 deletion completed in 6.415089658s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:01:03.393: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3106
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating secret secrets-3106/secret-test-cdb1a871-e336-4156-817c-f8b54106eaae
STEP: Creating a pod to test consume secrets
Aug 14 07:01:03.686: INFO: Waiting up to 5m0s for pod "pod-configmaps-2af504c2-c88f-445d-b258-ff57c48f90d6" in namespace "secrets-3106" to be "success or failure"
Aug 14 07:01:03.696: INFO: Pod "pod-configmaps-2af504c2-c88f-445d-b258-ff57c48f90d6": Phase="Pending", Reason="", readiness=false. Elapsed: 9.92692ms
Aug 14 07:01:05.707: INFO: Pod "pod-configmaps-2af504c2-c88f-445d-b258-ff57c48f90d6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020930418s
STEP: Saw pod success
Aug 14 07:01:05.707: INFO: Pod "pod-configmaps-2af504c2-c88f-445d-b258-ff57c48f90d6" satisfied condition "success or failure"
Aug 14 07:01:05.717: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod pod-configmaps-2af504c2-c88f-445d-b258-ff57c48f90d6 container env-test: <nil>
STEP: delete the pod
Aug 14 07:01:05.749: INFO: Waiting for pod pod-configmaps-2af504c2-c88f-445d-b258-ff57c48f90d6 to disappear
Aug 14 07:01:05.758: INFO: Pod pod-configmaps-2af504c2-c88f-445d-b258-ff57c48f90d6 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:01:05.759: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3106" for this suite.
Aug 14 07:01:11.811: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:01:12.202: INFO: namespace secrets-3106 deletion completed in 6.425173729s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:01:12.203: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-1644
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-1644
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 14 07:01:12.468: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug 14 07:01:34.665: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.1.76:8080/dial?request=hostName&protocol=http&host=100.96.0.37&port=8080&tries=1'] Namespace:pod-network-test-1644 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 07:01:34.665: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Aug 14 07:01:35.203: INFO: Waiting for endpoints: map[]
Aug 14 07:01:35.214: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.1.76:8080/dial?request=hostName&protocol=http&host=100.96.1.75&port=8080&tries=1'] Namespace:pod-network-test-1644 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 07:01:35.214: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Aug 14 07:01:35.749: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:01:35.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-1644" for this suite.
Aug 14 07:01:57.803: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:01:58.222: INFO: namespace pod-network-test-1644 deletion completed in 22.454452216s
•SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:01:58.223: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-1062
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Aug 14 07:02:00.521: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:02:00.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1062" for this suite.
Aug 14 07:02:06.599: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:02:06.986: INFO: namespace container-runtime-1062 deletion completed in 6.419963328s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:02:06.987: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-737
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Aug 14 07:02:07.270: INFO: Waiting up to 5m0s for pod "pod-11f59e77-0cad-4ef7-9c42-5e376e07c670" in namespace "emptydir-737" to be "success or failure"
Aug 14 07:02:07.280: INFO: Pod "pod-11f59e77-0cad-4ef7-9c42-5e376e07c670": Phase="Pending", Reason="", readiness=false. Elapsed: 9.756719ms
Aug 14 07:02:09.292: INFO: Pod "pod-11f59e77-0cad-4ef7-9c42-5e376e07c670": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021924055s
STEP: Saw pod success
Aug 14 07:02:09.292: INFO: Pod "pod-11f59e77-0cad-4ef7-9c42-5e376e07c670" satisfied condition "success or failure"
Aug 14 07:02:09.303: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod pod-11f59e77-0cad-4ef7-9c42-5e376e07c670 container test-container: <nil>
STEP: delete the pod
Aug 14 07:02:09.334: INFO: Waiting for pod pod-11f59e77-0cad-4ef7-9c42-5e376e07c670 to disappear
Aug 14 07:02:09.344: INFO: Pod pod-11f59e77-0cad-4ef7-9c42-5e376e07c670 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:02:09.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-737" for this suite.
Aug 14 07:02:15.396: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:02:15.784: INFO: namespace emptydir-737 deletion completed in 6.422207872s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:02:15.785: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-3563
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 14 07:02:16.113: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Aug 14 07:02:16.145: INFO: Number of nodes with available pods: 0
Aug 14 07:02:16.145: INFO: Node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw is running more than one daemon pod
Aug 14 07:02:17.175: INFO: Number of nodes with available pods: 0
Aug 14 07:02:17.175: INFO: Node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw is running more than one daemon pod
Aug 14 07:02:18.176: INFO: Number of nodes with available pods: 2
Aug 14 07:02:18.176: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Aug 14 07:02:18.258: INFO: Wrong image for pod: daemon-set-44blm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 14 07:02:18.258: INFO: Wrong image for pod: daemon-set-pfb88. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 14 07:02:19.280: INFO: Wrong image for pod: daemon-set-44blm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 14 07:02:19.280: INFO: Wrong image for pod: daemon-set-pfb88. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 14 07:02:20.280: INFO: Wrong image for pod: daemon-set-44blm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 14 07:02:20.280: INFO: Wrong image for pod: daemon-set-pfb88. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 14 07:02:21.280: INFO: Wrong image for pod: daemon-set-44blm. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 14 07:02:21.280: INFO: Pod daemon-set-44blm is not available
Aug 14 07:02:21.280: INFO: Wrong image for pod: daemon-set-pfb88. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 14 07:02:22.281: INFO: Wrong image for pod: daemon-set-pfb88. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 14 07:02:22.281: INFO: Pod daemon-set-vnw46 is not available
Aug 14 07:02:23.280: INFO: Wrong image for pod: daemon-set-pfb88. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 14 07:02:23.280: INFO: Pod daemon-set-vnw46 is not available
Aug 14 07:02:24.280: INFO: Wrong image for pod: daemon-set-pfb88. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 14 07:02:24.280: INFO: Pod daemon-set-vnw46 is not available
Aug 14 07:02:25.280: INFO: Wrong image for pod: daemon-set-pfb88. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 14 07:02:26.280: INFO: Wrong image for pod: daemon-set-pfb88. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 14 07:02:26.280: INFO: Pod daemon-set-pfb88 is not available
Aug 14 07:02:27.281: INFO: Pod daemon-set-9flwv is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Aug 14 07:02:27.321: INFO: Number of nodes with available pods: 1
Aug 14 07:02:27.321: INFO: Node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp is running more than one daemon pod
Aug 14 07:02:28.352: INFO: Number of nodes with available pods: 2
Aug 14 07:02:28.352: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3563, will wait for the garbage collector to delete the pods
Aug 14 07:02:28.479: INFO: Deleting DaemonSet.extensions daemon-set took: 13.806713ms
Aug 14 07:02:28.880: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.633608ms
Aug 14 07:02:36.391: INFO: Number of nodes with available pods: 0
Aug 14 07:02:36.391: INFO: Number of running nodes: 0, number of available pods: 0
Aug 14 07:02:36.401: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-3563/daemonsets","resourceVersion":"8869"},"items":null}

Aug 14 07:02:36.412: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-3563/pods","resourceVersion":"8869"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:02:36.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3563" for this suite.
Aug 14 07:02:42.498: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:02:42.889: INFO: namespace daemonsets-3563 deletion completed in 6.424963193s
•SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:02:42.890: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-8272
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Aug 14 07:02:43.166: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug 14 07:02:43.188: INFO: Waiting for terminating namespaces to be deleted...
Aug 14 07:02:43.198: INFO: 
Logging pods the kubelet thinks is on node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw before test
Aug 14 07:02:43.227: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-88d6cff74-rw8q9 from kube-system started at 2019-08-14 06:27:10 +0000 UTC (1 container statuses recorded)
Aug 14 07:02:43.227: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Aug 14 07:02:43.227: INFO: metrics-server-f5b59f6cc-xc2ch from kube-system started at 2019-08-14 06:27:10 +0000 UTC (1 container statuses recorded)
Aug 14 07:02:43.227: INFO: 	Container metrics-server ready: true, restart count 0
Aug 14 07:02:43.227: INFO: coredns-85cc454dd8-l4hk9 from kube-system started at 2019-08-14 06:27:14 +0000 UTC (1 container statuses recorded)
Aug 14 07:02:43.227: INFO: 	Container coredns ready: true, restart count 0
Aug 14 07:02:43.227: INFO: addons-nginx-ingress-controller-6496d947df-dqs5z from kube-system started at 2019-08-14 06:27:10 +0000 UTC (1 container statuses recorded)
Aug 14 07:02:43.227: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Aug 14 07:02:43.227: INFO: coredns-85cc454dd8-zsj57 from kube-system started at 2019-08-14 06:27:10 +0000 UTC (1 container statuses recorded)
Aug 14 07:02:43.227: INFO: 	Container coredns ready: true, restart count 0
Aug 14 07:02:43.227: INFO: calico-kube-controllers-5f4b46ffb5-m6pdj from kube-system started at 2019-08-14 06:27:10 +0000 UTC (1 container statuses recorded)
Aug 14 07:02:43.227: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Aug 14 07:02:43.227: INFO: blackbox-exporter-954dd954b-8xcv9 from kube-system started at 2019-08-14 06:26:55 +0000 UTC (1 container statuses recorded)
Aug 14 07:02:43.227: INFO: 	Container blackbox-exporter ready: true, restart count 0
Aug 14 07:02:43.227: INFO: kube-proxy-n2x65 from kube-system started at 2019-08-14 06:26:55 +0000 UTC (1 container statuses recorded)
Aug 14 07:02:43.227: INFO: 	Container kube-proxy ready: true, restart count 0
Aug 14 07:02:43.227: INFO: calico-node-gb7zk from kube-system started at 2019-08-14 06:26:55 +0000 UTC (1 container statuses recorded)
Aug 14 07:02:43.227: INFO: 	Container calico-node ready: true, restart count 1
Aug 14 07:02:43.227: INFO: node-exporter-hmlnc from kube-system started at 2019-08-14 06:26:55 +0000 UTC (1 container statuses recorded)
Aug 14 07:02:43.227: INFO: 	Container node-exporter ready: true, restart count 0
Aug 14 07:02:43.227: INFO: vpn-shoot-7d7bc8fd7d-997f6 from kube-system started at 2019-08-14 06:27:10 +0000 UTC (1 container statuses recorded)
Aug 14 07:02:43.227: INFO: 	Container vpn-shoot ready: true, restart count 0
Aug 14 07:02:43.227: INFO: addons-kubernetes-dashboard-5c8d9945bc-8t28x from kube-system started at 2019-08-14 06:27:10 +0000 UTC (1 container statuses recorded)
Aug 14 07:02:43.227: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Aug 14 07:02:43.227: INFO: 
Logging pods the kubelet thinks is on node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp before test
Aug 14 07:02:43.263: INFO: calico-node-ksxzt from kube-system started at 2019-08-14 06:26:56 +0000 UTC (1 container statuses recorded)
Aug 14 07:02:43.263: INFO: 	Container calico-node ready: true, restart count 1
Aug 14 07:02:43.263: INFO: kube-proxy-2nsfn from kube-system started at 2019-08-14 06:26:56 +0000 UTC (1 container statuses recorded)
Aug 14 07:02:43.263: INFO: 	Container kube-proxy ready: true, restart count 0
Aug 14 07:02:43.263: INFO: node-exporter-wq6g7 from kube-system started at 2019-08-14 06:26:56 +0000 UTC (1 container statuses recorded)
Aug 14 07:02:43.263: INFO: 	Container node-exporter ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15bab8079bda1f2b], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:02:44.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-8272" for this suite.
Aug 14 07:02:52.375: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:02:52.762: INFO: namespace sched-pred-8272 deletion completed in 8.420842312s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72
•SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:02:52.763: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7272
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Aug 14 07:02:53.073: INFO: Waiting up to 5m0s for pod "pod-c34171f6-a583-48f3-b1d8-a446a916a7d3" in namespace "emptydir-7272" to be "success or failure"
Aug 14 07:02:53.083: INFO: Pod "pod-c34171f6-a583-48f3-b1d8-a446a916a7d3": Phase="Pending", Reason="", readiness=false. Elapsed: 10.168678ms
Aug 14 07:02:55.095: INFO: Pod "pod-c34171f6-a583-48f3-b1d8-a446a916a7d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021820312s
STEP: Saw pod success
Aug 14 07:02:55.095: INFO: Pod "pod-c34171f6-a583-48f3-b1d8-a446a916a7d3" satisfied condition "success or failure"
Aug 14 07:02:55.105: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod pod-c34171f6-a583-48f3-b1d8-a446a916a7d3 container test-container: <nil>
STEP: delete the pod
Aug 14 07:02:55.138: INFO: Waiting for pod pod-c34171f6-a583-48f3-b1d8-a446a916a7d3 to disappear
Aug 14 07:02:55.149: INFO: Pod pod-c34171f6-a583-48f3-b1d8-a446a916a7d3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:02:55.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7272" for this suite.
Aug 14 07:03:01.201: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:03:01.842: INFO: namespace emptydir-7272 deletion completed in 6.675411088s
•SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:03:01.843: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6519
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-1d2fe284-f9a5-4004-82a8-5b2b5b0746c9
STEP: Creating a pod to test consume configMaps
Aug 14 07:03:02.180: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0251086e-13fa-49a1-b33c-6b6a84ae270b" in namespace "projected-6519" to be "success or failure"
Aug 14 07:03:02.190: INFO: Pod "pod-projected-configmaps-0251086e-13fa-49a1-b33c-6b6a84ae270b": Phase="Pending", Reason="", readiness=false. Elapsed: 10.122338ms
Aug 14 07:03:04.203: INFO: Pod "pod-projected-configmaps-0251086e-13fa-49a1-b33c-6b6a84ae270b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022289383s
STEP: Saw pod success
Aug 14 07:03:04.203: INFO: Pod "pod-projected-configmaps-0251086e-13fa-49a1-b33c-6b6a84ae270b" satisfied condition "success or failure"
Aug 14 07:03:04.213: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod pod-projected-configmaps-0251086e-13fa-49a1-b33c-6b6a84ae270b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 14 07:03:04.247: INFO: Waiting for pod pod-projected-configmaps-0251086e-13fa-49a1-b33c-6b6a84ae270b to disappear
Aug 14 07:03:04.258: INFO: Pod pod-projected-configmaps-0251086e-13fa-49a1-b33c-6b6a84ae270b no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:03:04.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6519" for this suite.
Aug 14 07:03:10.315: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:03:10.703: INFO: namespace projected-6519 deletion completed in 6.426352425s
•SSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:03:10.703: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-5819
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Aug 14 07:03:15.072: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 14 07:03:15.083: INFO: Pod pod-with-prestop-http-hook still exists
Aug 14 07:03:17.084: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 14 07:03:17.095: INFO: Pod pod-with-prestop-http-hook still exists
Aug 14 07:03:19.084: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 14 07:03:19.095: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:03:19.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5819" for this suite.
Aug 14 07:03:41.168: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:03:41.568: INFO: namespace container-lifecycle-hook-5819 deletion completed in 22.435531295s
•SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:03:41.568: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1426
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the initial replication controller
Aug 14 07:03:41.863: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-1426'
Aug 14 07:03:42.486: INFO: stderr: ""
Aug 14 07:03:42.486: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 14 07:03:42.486: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1426'
Aug 14 07:03:42.627: INFO: stderr: ""
Aug 14 07:03:42.627: INFO: stdout: "update-demo-nautilus-52cl5 update-demo-nautilus-tdhz2 "
Aug 14 07:03:42.628: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-52cl5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1426'
Aug 14 07:03:42.747: INFO: stderr: ""
Aug 14 07:03:42.747: INFO: stdout: ""
Aug 14 07:03:42.747: INFO: update-demo-nautilus-52cl5 is created but not running
Aug 14 07:03:47.747: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1426'
Aug 14 07:03:47.887: INFO: stderr: ""
Aug 14 07:03:47.887: INFO: stdout: "update-demo-nautilus-52cl5 update-demo-nautilus-tdhz2 "
Aug 14 07:03:47.887: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-52cl5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1426'
Aug 14 07:03:48.038: INFO: stderr: ""
Aug 14 07:03:48.038: INFO: stdout: "true"
Aug 14 07:03:48.038: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-52cl5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1426'
Aug 14 07:03:48.159: INFO: stderr: ""
Aug 14 07:03:48.159: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 14 07:03:48.159: INFO: validating pod update-demo-nautilus-52cl5
Aug 14 07:03:48.257: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 14 07:03:48.257: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 14 07:03:48.257: INFO: update-demo-nautilus-52cl5 is verified up and running
Aug 14 07:03:48.257: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-tdhz2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1426'
Aug 14 07:03:48.385: INFO: stderr: ""
Aug 14 07:03:48.385: INFO: stdout: "true"
Aug 14 07:03:48.385: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-tdhz2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1426'
Aug 14 07:03:48.492: INFO: stderr: ""
Aug 14 07:03:48.492: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 14 07:03:48.492: INFO: validating pod update-demo-nautilus-tdhz2
Aug 14 07:03:48.587: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 14 07:03:48.587: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 14 07:03:48.587: INFO: update-demo-nautilus-tdhz2 is verified up and running
STEP: rolling-update to new replication controller
Aug 14 07:03:48.590: INFO: scanned /root for discovery docs: <nil>
Aug 14 07:03:48.590: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-1426'
Aug 14 07:04:06.352: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Aug 14 07:04:06.352: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 14 07:04:06.352: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1426'
Aug 14 07:04:06.483: INFO: stderr: ""
Aug 14 07:04:06.483: INFO: stdout: "update-demo-kitten-2vjc9 update-demo-kitten-tsd2j "
Aug 14 07:04:06.483: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-kitten-2vjc9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1426'
Aug 14 07:04:06.625: INFO: stderr: ""
Aug 14 07:04:06.625: INFO: stdout: "true"
Aug 14 07:04:06.625: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-kitten-2vjc9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1426'
Aug 14 07:04:06.755: INFO: stderr: ""
Aug 14 07:04:06.755: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Aug 14 07:04:06.755: INFO: validating pod update-demo-kitten-2vjc9
Aug 14 07:04:06.852: INFO: got data: {
  "image": "kitten.jpg"
}

Aug 14 07:04:06.852: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Aug 14 07:04:06.852: INFO: update-demo-kitten-2vjc9 is verified up and running
Aug 14 07:04:06.852: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-kitten-tsd2j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1426'
Aug 14 07:04:06.974: INFO: stderr: ""
Aug 14 07:04:06.974: INFO: stdout: "true"
Aug 14 07:04:06.974: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-kitten-tsd2j -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1426'
Aug 14 07:04:07.109: INFO: stderr: ""
Aug 14 07:04:07.109: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Aug 14 07:04:07.109: INFO: validating pod update-demo-kitten-tsd2j
Aug 14 07:04:07.206: INFO: got data: {
  "image": "kitten.jpg"
}

Aug 14 07:04:07.206: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Aug 14 07:04:07.206: INFO: update-demo-kitten-tsd2j is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:04:07.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1426" for this suite.
Aug 14 07:04:29.260: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:04:29.659: INFO: namespace kubectl-1426 deletion completed in 22.434228652s
•SS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:04:29.659: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-3736
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override command
Aug 14 07:04:29.880: INFO: Waiting up to 5m0s for pod "client-containers-2fb8841c-2a0a-4a44-9cd6-d72f610b1b89" in namespace "containers-3736" to be "success or failure"
Aug 14 07:04:29.890: INFO: Pod "client-containers-2fb8841c-2a0a-4a44-9cd6-d72f610b1b89": Phase="Pending", Reason="", readiness=false. Elapsed: 10.038729ms
Aug 14 07:04:31.902: INFO: Pod "client-containers-2fb8841c-2a0a-4a44-9cd6-d72f610b1b89": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022410891s
Aug 14 07:04:33.914: INFO: Pod "client-containers-2fb8841c-2a0a-4a44-9cd6-d72f610b1b89": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034052093s
STEP: Saw pod success
Aug 14 07:04:33.914: INFO: Pod "client-containers-2fb8841c-2a0a-4a44-9cd6-d72f610b1b89" satisfied condition "success or failure"
Aug 14 07:04:33.925: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod client-containers-2fb8841c-2a0a-4a44-9cd6-d72f610b1b89 container test-container: <nil>
STEP: delete the pod
Aug 14 07:04:33.962: INFO: Waiting for pod client-containers-2fb8841c-2a0a-4a44-9cd6-d72f610b1b89 to disappear
Aug 14 07:04:33.972: INFO: Pod client-containers-2fb8841c-2a0a-4a44-9cd6-d72f610b1b89 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:04:33.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3736" for this suite.
Aug 14 07:04:40.026: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:04:40.424: INFO: namespace containers-3736 deletion completed in 6.433192891s
•SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:04:40.424: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1096
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-58af4f6c-756f-4d49-b86c-f616c360b127
STEP: Creating secret with name s-test-opt-upd-9bdfb96e-a6f4-419e-8e51-b1ce1a5922e0
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-58af4f6c-756f-4d49-b86c-f616c360b127
STEP: Updating secret s-test-opt-upd-9bdfb96e-a6f4-419e-8e51-b1ce1a5922e0
STEP: Creating secret with name s-test-opt-create-aa55ef1b-0fd0-4e24-bbf7-639a798127d7
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:04:45.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1096" for this suite.
Aug 14 07:05:07.240: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:05:07.637: INFO: namespace secrets-1096 deletion completed in 22.430979893s
•
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:05:07.637: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5679
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-cd2e14dc-c6cf-4b47-b3ee-85f9cef85ca2
STEP: Creating configMap with name cm-test-opt-upd-8a94e003-0b68-4621-b368-dd0c8c7e5c1a
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-cd2e14dc-c6cf-4b47-b3ee-85f9cef85ca2
STEP: Updating configmap cm-test-opt-upd-8a94e003-0b68-4621-b368-dd0c8c7e5c1a
STEP: Creating configMap with name cm-test-opt-create-66d1534b-c8c4-4653-a7f8-b8759a87ac0e
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:05:12.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5679" for this suite.
Aug 14 07:05:34.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:05:34.837: INFO: namespace configmap-5679 deletion completed in 22.426703104s
•SSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:05:34.838: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7687
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-7687/configmap-test-4d08fd15-864f-4ffc-b82e-f11d4fb8a559
STEP: Creating a pod to test consume configMaps
Aug 14 07:05:35.096: INFO: Waiting up to 5m0s for pod "pod-configmaps-524f003a-d26d-425d-94ba-94eb08a38033" in namespace "configmap-7687" to be "success or failure"
Aug 14 07:05:35.120: INFO: Pod "pod-configmaps-524f003a-d26d-425d-94ba-94eb08a38033": Phase="Pending", Reason="", readiness=false. Elapsed: 24.368571ms
Aug 14 07:05:37.136: INFO: Pod "pod-configmaps-524f003a-d26d-425d-94ba-94eb08a38033": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.040124099s
STEP: Saw pod success
Aug 14 07:05:37.136: INFO: Pod "pod-configmaps-524f003a-d26d-425d-94ba-94eb08a38033" satisfied condition "success or failure"
Aug 14 07:05:37.147: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod pod-configmaps-524f003a-d26d-425d-94ba-94eb08a38033 container env-test: <nil>
STEP: delete the pod
Aug 14 07:05:37.179: INFO: Waiting for pod pod-configmaps-524f003a-d26d-425d-94ba-94eb08a38033 to disappear
Aug 14 07:05:37.189: INFO: Pod pod-configmaps-524f003a-d26d-425d-94ba-94eb08a38033 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:05:37.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7687" for this suite.
Aug 14 07:05:43.241: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:05:43.628: INFO: namespace configmap-7687 deletion completed in 6.421086752s
•
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:05:43.629: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-3103
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's args
Aug 14 07:05:43.970: INFO: Waiting up to 5m0s for pod "var-expansion-6d97ed2f-e48e-4bf5-8772-ec58c8adb607" in namespace "var-expansion-3103" to be "success or failure"
Aug 14 07:05:43.980: INFO: Pod "var-expansion-6d97ed2f-e48e-4bf5-8772-ec58c8adb607": Phase="Pending", Reason="", readiness=false. Elapsed: 10.08162ms
Aug 14 07:05:45.991: INFO: Pod "var-expansion-6d97ed2f-e48e-4bf5-8772-ec58c8adb607": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021804588s
STEP: Saw pod success
Aug 14 07:05:45.991: INFO: Pod "var-expansion-6d97ed2f-e48e-4bf5-8772-ec58c8adb607" satisfied condition "success or failure"
Aug 14 07:05:46.002: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod var-expansion-6d97ed2f-e48e-4bf5-8772-ec58c8adb607 container dapi-container: <nil>
STEP: delete the pod
Aug 14 07:05:46.034: INFO: Waiting for pod var-expansion-6d97ed2f-e48e-4bf5-8772-ec58c8adb607 to disappear
Aug 14 07:05:46.044: INFO: Pod var-expansion-6d97ed2f-e48e-4bf5-8772-ec58c8adb607 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:05:46.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3103" for this suite.
Aug 14 07:05:52.110: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:05:52.511: INFO: namespace var-expansion-3103 deletion completed in 6.448410549s
•SSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:05:52.511: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-9811
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 14 07:05:52.890: INFO: (0) /api/v1/nodes/shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 16.192558ms)
Aug 14 07:05:52.933: INFO: (1) /api/v1/nodes/shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 43.064527ms)
Aug 14 07:05:52.946: INFO: (2) /api/v1/nodes/shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.332881ms)
Aug 14 07:05:52.958: INFO: (3) /api/v1/nodes/shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.390599ms)
Aug 14 07:05:52.971: INFO: (4) /api/v1/nodes/shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.498302ms)
Aug 14 07:05:52.984: INFO: (5) /api/v1/nodes/shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.719518ms)
Aug 14 07:05:52.996: INFO: (6) /api/v1/nodes/shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.69234ms)
Aug 14 07:05:53.009: INFO: (7) /api/v1/nodes/shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.915661ms)
Aug 14 07:05:53.023: INFO: (8) /api/v1/nodes/shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 13.087922ms)
Aug 14 07:05:53.036: INFO: (9) /api/v1/nodes/shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.936549ms)
Aug 14 07:05:53.048: INFO: (10) /api/v1/nodes/shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.442151ms)
Aug 14 07:05:53.061: INFO: (11) /api/v1/nodes/shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.46227ms)
Aug 14 07:05:53.073: INFO: (12) /api/v1/nodes/shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 11.910848ms)
Aug 14 07:05:53.084: INFO: (13) /api/v1/nodes/shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 11.799802ms)
Aug 14 07:05:53.097: INFO: (14) /api/v1/nodes/shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.563196ms)
Aug 14 07:05:53.110: INFO: (15) /api/v1/nodes/shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.879859ms)
Aug 14 07:05:53.123: INFO: (16) /api/v1/nodes/shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.529394ms)
Aug 14 07:05:53.136: INFO: (17) /api/v1/nodes/shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.821765ms)
Aug 14 07:05:53.148: INFO: (18) /api/v1/nodes/shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.277232ms)
Aug 14 07:05:53.161: INFO: (19) /api/v1/nodes/shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.541281ms)
[AfterEach] version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:05:53.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-9811" for this suite.
Aug 14 07:05:59.206: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:05:59.638: INFO: namespace proxy-9811 deletion completed in 6.466408344s
•SSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:05:59.638: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4553
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Aug 14 07:06:02.031: INFO: Asynchronously running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Aug 14 07:06:17.185: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:06:17.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4553" for this suite.
Aug 14 07:06:23.243: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:06:23.642: INFO: namespace pods-4553 deletion completed in 6.434632696s
•SSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:06:23.643: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-2634
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
Aug 14 07:06:24.514: INFO: created pod pod-service-account-defaultsa
Aug 14 07:06:24.514: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Aug 14 07:06:24.526: INFO: created pod pod-service-account-mountsa
Aug 14 07:06:24.527: INFO: pod pod-service-account-mountsa service account token volume mount: true
Aug 14 07:06:24.537: INFO: created pod pod-service-account-nomountsa
Aug 14 07:06:24.538: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Aug 14 07:06:24.548: INFO: created pod pod-service-account-defaultsa-mountspec
Aug 14 07:06:24.548: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Aug 14 07:06:24.559: INFO: created pod pod-service-account-mountsa-mountspec
Aug 14 07:06:24.560: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Aug 14 07:06:24.571: INFO: created pod pod-service-account-nomountsa-mountspec
Aug 14 07:06:24.571: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Aug 14 07:06:24.584: INFO: created pod pod-service-account-defaultsa-nomountspec
Aug 14 07:06:24.584: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Aug 14 07:06:24.597: INFO: created pod pod-service-account-mountsa-nomountspec
Aug 14 07:06:24.597: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Aug 14 07:06:24.608: INFO: created pod pod-service-account-nomountsa-nomountspec
Aug 14 07:06:24.608: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:06:24.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-2634" for this suite.
Aug 14 07:06:32.666: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:06:33.060: INFO: namespace svcaccounts-2634 deletion completed in 8.427326345s
•SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:06:33.060: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2472
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-bc19cb2e-296e-487e-9030-7de94e30fbbb
STEP: Creating a pod to test consume secrets
Aug 14 07:06:33.382: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-0590973a-e423-437d-aa5c-3bd97808b14c" in namespace "projected-2472" to be "success or failure"
Aug 14 07:06:33.393: INFO: Pod "pod-projected-secrets-0590973a-e423-437d-aa5c-3bd97808b14c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.979229ms
Aug 14 07:06:35.405: INFO: Pod "pod-projected-secrets-0590973a-e423-437d-aa5c-3bd97808b14c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022464737s
STEP: Saw pod success
Aug 14 07:06:35.405: INFO: Pod "pod-projected-secrets-0590973a-e423-437d-aa5c-3bd97808b14c" satisfied condition "success or failure"
Aug 14 07:06:35.415: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod pod-projected-secrets-0590973a-e423-437d-aa5c-3bd97808b14c container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 14 07:06:35.449: INFO: Waiting for pod pod-projected-secrets-0590973a-e423-437d-aa5c-3bd97808b14c to disappear
Aug 14 07:06:35.460: INFO: Pod pod-projected-secrets-0590973a-e423-437d-aa5c-3bd97808b14c no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:06:35.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2472" for this suite.
Aug 14 07:06:41.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:06:41.903: INFO: namespace projected-2472 deletion completed in 6.424541767s
•
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:06:41.903: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8674
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Aug 14 07:06:42.274: INFO: Waiting up to 5m0s for pod "downward-api-47185fde-4170-402f-9667-260795a1d814" in namespace "downward-api-8674" to be "success or failure"
Aug 14 07:06:42.284: INFO: Pod "downward-api-47185fde-4170-402f-9667-260795a1d814": Phase="Pending", Reason="", readiness=false. Elapsed: 9.916491ms
Aug 14 07:06:44.295: INFO: Pod "downward-api-47185fde-4170-402f-9667-260795a1d814": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02093535s
STEP: Saw pod success
Aug 14 07:06:44.295: INFO: Pod "downward-api-47185fde-4170-402f-9667-260795a1d814" satisfied condition "success or failure"
Aug 14 07:06:44.305: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod downward-api-47185fde-4170-402f-9667-260795a1d814 container dapi-container: <nil>
STEP: delete the pod
Aug 14 07:06:44.338: INFO: Waiting for pod downward-api-47185fde-4170-402f-9667-260795a1d814 to disappear
Aug 14 07:06:44.348: INFO: Pod downward-api-47185fde-4170-402f-9667-260795a1d814 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:06:44.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8674" for this suite.
Aug 14 07:06:50.402: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:06:50.826: INFO: namespace downward-api-8674 deletion completed in 6.457543889s
•SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:06:50.826: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6400
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 14 07:06:51.170: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ffeab4e5-9b7e-43e7-94a2-bd832a84f25f" in namespace "downward-api-6400" to be "success or failure"
Aug 14 07:06:51.181: INFO: Pod "downwardapi-volume-ffeab4e5-9b7e-43e7-94a2-bd832a84f25f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.51887ms
Aug 14 07:06:53.192: INFO: Pod "downwardapi-volume-ffeab4e5-9b7e-43e7-94a2-bd832a84f25f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022267463s
STEP: Saw pod success
Aug 14 07:06:53.192: INFO: Pod "downwardapi-volume-ffeab4e5-9b7e-43e7-94a2-bd832a84f25f" satisfied condition "success or failure"
Aug 14 07:06:53.203: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod downwardapi-volume-ffeab4e5-9b7e-43e7-94a2-bd832a84f25f container client-container: <nil>
STEP: delete the pod
Aug 14 07:06:53.237: INFO: Waiting for pod downwardapi-volume-ffeab4e5-9b7e-43e7-94a2-bd832a84f25f to disappear
Aug 14 07:06:53.247: INFO: Pod downwardapi-volume-ffeab4e5-9b7e-43e7-94a2-bd832a84f25f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:06:53.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6400" for this suite.
Aug 14 07:06:59.300: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:06:59.705: INFO: namespace downward-api-6400 deletion completed in 6.437943507s
•SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:06:59.705: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-352
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 14 07:07:00.070: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ea80fd49-2b16-4d7f-86b3-81bdf9c3747c" in namespace "downward-api-352" to be "success or failure"
Aug 14 07:07:00.081: INFO: Pod "downwardapi-volume-ea80fd49-2b16-4d7f-86b3-81bdf9c3747c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.091684ms
Aug 14 07:07:02.093: INFO: Pod "downwardapi-volume-ea80fd49-2b16-4d7f-86b3-81bdf9c3747c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02220096s
STEP: Saw pod success
Aug 14 07:07:02.093: INFO: Pod "downwardapi-volume-ea80fd49-2b16-4d7f-86b3-81bdf9c3747c" satisfied condition "success or failure"
Aug 14 07:07:02.103: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod downwardapi-volume-ea80fd49-2b16-4d7f-86b3-81bdf9c3747c container client-container: <nil>
STEP: delete the pod
Aug 14 07:07:02.143: INFO: Waiting for pod downwardapi-volume-ea80fd49-2b16-4d7f-86b3-81bdf9c3747c to disappear
Aug 14 07:07:02.153: INFO: Pod downwardapi-volume-ea80fd49-2b16-4d7f-86b3-81bdf9c3747c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:07:02.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-352" for this suite.
Aug 14 07:07:10.207: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:07:10.596: INFO: namespace downward-api-352 deletion completed in 8.423861944s
•SS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:07:10.596: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-5834
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Aug 14 07:07:10.993: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5834,SelfLink:/api/v1/namespaces/watch-5834/configmaps/e2e-watch-test-configmap-a,UID:019a431d-38aa-4699-aa9e-2e8a24655e08,ResourceVersion:10110,Generation:0,CreationTimestamp:2019-08-14 07:07:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 14 07:07:10.994: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5834,SelfLink:/api/v1/namespaces/watch-5834/configmaps/e2e-watch-test-configmap-a,UID:019a431d-38aa-4699-aa9e-2e8a24655e08,ResourceVersion:10110,Generation:0,CreationTimestamp:2019-08-14 07:07:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Aug 14 07:07:21.018: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5834,SelfLink:/api/v1/namespaces/watch-5834/configmaps/e2e-watch-test-configmap-a,UID:019a431d-38aa-4699-aa9e-2e8a24655e08,ResourceVersion:10134,Generation:0,CreationTimestamp:2019-08-14 07:07:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Aug 14 07:07:21.018: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5834,SelfLink:/api/v1/namespaces/watch-5834/configmaps/e2e-watch-test-configmap-a,UID:019a431d-38aa-4699-aa9e-2e8a24655e08,ResourceVersion:10134,Generation:0,CreationTimestamp:2019-08-14 07:07:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Aug 14 07:07:31.042: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5834,SelfLink:/api/v1/namespaces/watch-5834/configmaps/e2e-watch-test-configmap-a,UID:019a431d-38aa-4699-aa9e-2e8a24655e08,ResourceVersion:10157,Generation:0,CreationTimestamp:2019-08-14 07:07:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 14 07:07:31.042: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5834,SelfLink:/api/v1/namespaces/watch-5834/configmaps/e2e-watch-test-configmap-a,UID:019a431d-38aa-4699-aa9e-2e8a24655e08,ResourceVersion:10157,Generation:0,CreationTimestamp:2019-08-14 07:07:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Aug 14 07:07:41.057: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5834,SelfLink:/api/v1/namespaces/watch-5834/configmaps/e2e-watch-test-configmap-a,UID:019a431d-38aa-4699-aa9e-2e8a24655e08,ResourceVersion:10180,Generation:0,CreationTimestamp:2019-08-14 07:07:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 14 07:07:41.057: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5834,SelfLink:/api/v1/namespaces/watch-5834/configmaps/e2e-watch-test-configmap-a,UID:019a431d-38aa-4699-aa9e-2e8a24655e08,ResourceVersion:10180,Generation:0,CreationTimestamp:2019-08-14 07:07:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Aug 14 07:07:51.072: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-5834,SelfLink:/api/v1/namespaces/watch-5834/configmaps/e2e-watch-test-configmap-b,UID:3c92087c-0275-4a09-987d-771689d9d058,ResourceVersion:10231,Generation:0,CreationTimestamp:2019-08-14 07:07:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 14 07:07:51.072: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-5834,SelfLink:/api/v1/namespaces/watch-5834/configmaps/e2e-watch-test-configmap-b,UID:3c92087c-0275-4a09-987d-771689d9d058,ResourceVersion:10231,Generation:0,CreationTimestamp:2019-08-14 07:07:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Aug 14 07:08:01.087: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-5834,SelfLink:/api/v1/namespaces/watch-5834/configmaps/e2e-watch-test-configmap-b,UID:3c92087c-0275-4a09-987d-771689d9d058,ResourceVersion:10254,Generation:0,CreationTimestamp:2019-08-14 07:07:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 14 07:08:01.087: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-5834,SelfLink:/api/v1/namespaces/watch-5834/configmaps/e2e-watch-test-configmap-b,UID:3c92087c-0275-4a09-987d-771689d9d058,ResourceVersion:10254,Generation:0,CreationTimestamp:2019-08-14 07:07:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:08:11.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-5834" for this suite.
Aug 14 07:08:17.141: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:08:17.538: INFO: namespace watch-5834 deletion completed in 6.429131138s
•SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:08:17.538: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-217
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-projected-rmld
STEP: Creating a pod to test atomic-volume-subpath
Aug 14 07:08:17.802: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-rmld" in namespace "subpath-217" to be "success or failure"
Aug 14 07:08:17.811: INFO: Pod "pod-subpath-test-projected-rmld": Phase="Pending", Reason="", readiness=false. Elapsed: 9.696321ms
Aug 14 07:08:19.823: INFO: Pod "pod-subpath-test-projected-rmld": Phase="Running", Reason="", readiness=true. Elapsed: 2.021105678s
Aug 14 07:08:21.835: INFO: Pod "pod-subpath-test-projected-rmld": Phase="Running", Reason="", readiness=true. Elapsed: 4.032973753s
Aug 14 07:08:23.846: INFO: Pod "pod-subpath-test-projected-rmld": Phase="Running", Reason="", readiness=true. Elapsed: 6.044715404s
Aug 14 07:08:25.858: INFO: Pod "pod-subpath-test-projected-rmld": Phase="Running", Reason="", readiness=true. Elapsed: 8.05614906s
Aug 14 07:08:27.869: INFO: Pod "pod-subpath-test-projected-rmld": Phase="Running", Reason="", readiness=true. Elapsed: 10.067238732s
Aug 14 07:08:29.880: INFO: Pod "pod-subpath-test-projected-rmld": Phase="Running", Reason="", readiness=true. Elapsed: 12.078287546s
Aug 14 07:08:31.891: INFO: Pod "pod-subpath-test-projected-rmld": Phase="Running", Reason="", readiness=true. Elapsed: 14.089441348s
Aug 14 07:08:33.903: INFO: Pod "pod-subpath-test-projected-rmld": Phase="Running", Reason="", readiness=true. Elapsed: 16.100966824s
Aug 14 07:08:35.914: INFO: Pod "pod-subpath-test-projected-rmld": Phase="Running", Reason="", readiness=true. Elapsed: 18.112372036s
Aug 14 07:08:37.926: INFO: Pod "pod-subpath-test-projected-rmld": Phase="Running", Reason="", readiness=true. Elapsed: 20.124001128s
Aug 14 07:08:39.938: INFO: Pod "pod-subpath-test-projected-rmld": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.136020692s
STEP: Saw pod success
Aug 14 07:08:39.938: INFO: Pod "pod-subpath-test-projected-rmld" satisfied condition "success or failure"
Aug 14 07:08:39.948: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod pod-subpath-test-projected-rmld container test-container-subpath-projected-rmld: <nil>
STEP: delete the pod
Aug 14 07:08:39.981: INFO: Waiting for pod pod-subpath-test-projected-rmld to disappear
Aug 14 07:08:39.991: INFO: Pod pod-subpath-test-projected-rmld no longer exists
STEP: Deleting pod pod-subpath-test-projected-rmld
Aug 14 07:08:39.992: INFO: Deleting pod "pod-subpath-test-projected-rmld" in namespace "subpath-217"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:08:40.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-217" for this suite.
Aug 14 07:08:46.056: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:08:46.440: INFO: namespace subpath-217 deletion completed in 6.419154744s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:08:46.441: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8777
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap that has name configmap-test-emptyKey-0f04106c-095f-462d-9199-a151a7386836
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:08:46.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8777" for this suite.
Aug 14 07:08:52.723: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:08:53.110: INFO: namespace configmap-8777 deletion completed in 6.42227708s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:08:53.111: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9736
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Aug 14 07:08:53.469: INFO: Waiting up to 5m0s for pod "pod-142ca09b-c164-4ed6-b078-977a06bbf579" in namespace "emptydir-9736" to be "success or failure"
Aug 14 07:08:53.480: INFO: Pod "pod-142ca09b-c164-4ed6-b078-977a06bbf579": Phase="Pending", Reason="", readiness=false. Elapsed: 10.227095ms
Aug 14 07:08:55.491: INFO: Pod "pod-142ca09b-c164-4ed6-b078-977a06bbf579": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021492148s
STEP: Saw pod success
Aug 14 07:08:55.491: INFO: Pod "pod-142ca09b-c164-4ed6-b078-977a06bbf579" satisfied condition "success or failure"
Aug 14 07:08:55.501: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod pod-142ca09b-c164-4ed6-b078-977a06bbf579 container test-container: <nil>
STEP: delete the pod
Aug 14 07:08:55.533: INFO: Waiting for pod pod-142ca09b-c164-4ed6-b078-977a06bbf579 to disappear
Aug 14 07:08:55.543: INFO: Pod pod-142ca09b-c164-4ed6-b078-977a06bbf579 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:08:55.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9736" for this suite.
Aug 14 07:09:01.596: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:09:01.988: INFO: namespace emptydir-9736 deletion completed in 6.425440546s
•SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:09:01.988: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2092
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating all guestbook components
Aug 14 07:09:02.266: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Aug 14 07:09:02.266: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-2092'
Aug 14 07:09:02.573: INFO: stderr: ""
Aug 14 07:09:02.573: INFO: stdout: "service/redis-slave created\n"
Aug 14 07:09:02.574: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Aug 14 07:09:02.574: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-2092'
Aug 14 07:09:02.853: INFO: stderr: ""
Aug 14 07:09:02.853: INFO: stdout: "service/redis-master created\n"
Aug 14 07:09:02.869: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Aug 14 07:09:02.869: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-2092'
Aug 14 07:09:03.110: INFO: stderr: ""
Aug 14 07:09:03.110: INFO: stdout: "service/frontend created\n"
Aug 14 07:09:03.112: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Aug 14 07:09:03.112: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-2092'
Aug 14 07:09:03.411: INFO: stderr: ""
Aug 14 07:09:03.411: INFO: stdout: "deployment.apps/frontend created\n"
Aug 14 07:09:03.412: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Aug 14 07:09:03.412: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-2092'
Aug 14 07:09:03.625: INFO: stderr: ""
Aug 14 07:09:03.625: INFO: stdout: "deployment.apps/redis-master created\n"
Aug 14 07:09:03.626: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Aug 14 07:09:03.627: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-2092'
Aug 14 07:09:03.898: INFO: stderr: ""
Aug 14 07:09:03.899: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Aug 14 07:09:03.899: INFO: Waiting for all frontend pods to be Running.
Aug 14 07:09:23.950: INFO: Waiting for frontend to serve content.
Aug 14 07:09:24.049: INFO: Trying to add a new entry to the guestbook.
Aug 14 07:09:24.176: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Aug 14 07:09:24.224: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-2092'
Aug 14 07:09:24.360: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 14 07:09:24.360: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Aug 14 07:09:24.360: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-2092'
Aug 14 07:09:24.503: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 14 07:09:24.503: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Aug 14 07:09:24.503: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-2092'
Aug 14 07:09:24.644: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 14 07:09:24.644: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Aug 14 07:09:24.644: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-2092'
Aug 14 07:09:24.776: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 14 07:09:24.776: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Aug 14 07:09:24.777: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-2092'
Aug 14 07:09:24.922: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 14 07:09:24.922: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Aug 14 07:09:24.922: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-2092'
Aug 14 07:09:25.072: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 14 07:09:25.073: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:09:25.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2092" for this suite.
Aug 14 07:10:07.126: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:10:07.511: INFO: namespace kubectl-2092 deletion completed in 42.419341008s
•SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:10:07.511: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1330
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating cluster-info
Aug 14 07:10:07.860: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config cluster-info'
Aug 14 07:10:07.990: INFO: stderr: ""
Aug 14 07:10:07.990: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mkubernetes-dashboard\x1b[0m is running at \x1b[0;33mhttps://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:10:07.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1330" for this suite.
Aug 14 07:10:14.035: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:10:14.423: INFO: namespace kubectl-1330 deletion completed in 6.422014347s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:10:14.424: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-3630
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:10:14.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3630" for this suite.
Aug 14 07:10:36.824: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:10:37.252: INFO: namespace pods-3630 deletion completed in 22.461575735s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:10:37.254: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-9028
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-4336
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-3776
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:11:01.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-9028" for this suite.
Aug 14 07:11:08.024: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:11:08.419: INFO: namespace namespaces-9028 deletion completed in 6.429013811s
STEP: Destroying namespace "nsdeletetest-4336" for this suite.
Aug 14 07:11:08.429: INFO: Namespace nsdeletetest-4336 was already deleted
STEP: Destroying namespace "nsdeletetest-3776" for this suite.
Aug 14 07:11:14.464: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:11:14.887: INFO: namespace nsdeletetest-3776 deletion completed in 6.458045199s
•SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:11:14.888: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-9736
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-9736
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 14 07:11:15.166: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug 14 07:11:39.365: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.1.114:8080/dial?request=hostName&protocol=udp&host=100.96.1.113&port=8081&tries=1'] Namespace:pod-network-test-9736 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 07:11:39.365: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Aug 14 07:11:39.918: INFO: Waiting for endpoints: map[]
Aug 14 07:11:39.929: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.1.114:8080/dial?request=hostName&protocol=udp&host=100.96.0.45&port=8081&tries=1'] Namespace:pod-network-test-9736 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 07:11:39.929: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Aug 14 07:11:40.413: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:11:40.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-9736" for this suite.
Aug 14 07:12:02.467: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:12:02.896: INFO: namespace pod-network-test-9736 deletion completed in 22.463882788s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:12:02.897: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-2164
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 14 07:12:03.193: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Aug 14 07:12:05.215: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Aug 14 07:12:07.227: INFO: Creating deployment "test-rollover-deployment"
Aug 14 07:12:07.248: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Aug 14 07:12:09.270: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Aug 14 07:12:09.292: INFO: Ensure that both replica sets have 1 created replica
Aug 14 07:12:09.314: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Aug 14 07:12:09.336: INFO: Updating deployment test-rollover-deployment
Aug 14 07:12:09.336: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Aug 14 07:12:11.371: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Aug 14 07:12:11.393: INFO: Make sure deployment "test-rollover-deployment" is complete
Aug 14 07:12:11.413: INFO: all replica sets need to contain the pod-template-hash label
Aug 14 07:12:11.413: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701363527, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701363527, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701363531, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701363527, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 14 07:12:13.437: INFO: all replica sets need to contain the pod-template-hash label
Aug 14 07:12:13.437: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701363527, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701363527, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701363531, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701363527, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 14 07:12:15.436: INFO: all replica sets need to contain the pod-template-hash label
Aug 14 07:12:15.436: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701363527, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701363527, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701363531, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701363527, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 14 07:12:17.439: INFO: all replica sets need to contain the pod-template-hash label
Aug 14 07:12:17.439: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701363527, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701363527, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701363531, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701363527, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 14 07:12:19.436: INFO: all replica sets need to contain the pod-template-hash label
Aug 14 07:12:19.436: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701363527, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701363527, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701363531, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701363527, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 14 07:12:21.437: INFO: 
Aug 14 07:12:21.437: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Aug 14 07:12:21.468: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-2164,SelfLink:/apis/apps/v1/namespaces/deployment-2164/deployments/test-rollover-deployment,UID:2039610f-8b31-4061-ba4b-6d57c7f08260,ResourceVersion:11303,Generation:2,CreationTimestamp:2019-08-14 07:12:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-08-14 07:12:07 +0000 UTC 2019-08-14 07:12:07 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-08-14 07:12:21 +0000 UTC 2019-08-14 07:12:07 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-854595fc44" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Aug 14 07:12:21.479: INFO: New ReplicaSet "test-rollover-deployment-854595fc44" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44,GenerateName:,Namespace:deployment-2164,SelfLink:/apis/apps/v1/namespaces/deployment-2164/replicasets/test-rollover-deployment-854595fc44,UID:9b282c96-901e-4f37-a8a9-5085aae40721,ResourceVersion:11295,Generation:2,CreationTimestamp:2019-08-14 07:12:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 2039610f-8b31-4061-ba4b-6d57c7f08260 0xc0039f63e7 0xc0039f63e8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Aug 14 07:12:21.479: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Aug 14 07:12:21.480: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-2164,SelfLink:/apis/apps/v1/namespaces/deployment-2164/replicasets/test-rollover-controller,UID:5817fd0c-dcdf-4cfd-99a4-55b1390a53be,ResourceVersion:11301,Generation:2,CreationTimestamp:2019-08-14 07:12:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 2039610f-8b31-4061-ba4b-6d57c7f08260 0xc0039f6307 0xc0039f6308}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 14 07:12:21.480: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-9b8b997cf,GenerateName:,Namespace:deployment-2164,SelfLink:/apis/apps/v1/namespaces/deployment-2164/replicasets/test-rollover-deployment-9b8b997cf,UID:6e48b16f-95b3-46bf-9f88-ed2e52ee89bb,ResourceVersion:11262,Generation:2,CreationTimestamp:2019-08-14 07:12:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 2039610f-8b31-4061-ba4b-6d57c7f08260 0xc0039f64b0 0xc0039f64b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 14 07:12:21.491: INFO: Pod "test-rollover-deployment-854595fc44-fnvhf" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44-fnvhf,GenerateName:test-rollover-deployment-854595fc44-,Namespace:deployment-2164,SelfLink:/api/v1/namespaces/deployment-2164/pods/test-rollover-deployment-854595fc44-fnvhf,UID:4346f28f-1891-45b0-89cb-0dbc8a209914,ResourceVersion:11269,Generation:0,CreationTimestamp:2019-08-14 07:12:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.117/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-854595fc44 9b282c96-901e-4f37-a8a9-5085aae40721 0xc0039f7137 0xc0039f7138}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kz49p {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kz49p,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-kz49p true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0039f71a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0039f71c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:12:09 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:12:11 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:12:11 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:12:09 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:100.96.1.117,StartTime:2019-08-14 07:12:09 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-08-14 07:12:10 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://dec0295f55f42e78f38fc4e763caf00bbb9fd860532fb05747640de92ffb0671}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:12:21.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2164" for this suite.
Aug 14 07:12:29.545: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:12:29.941: INFO: namespace deployment-2164 deletion completed in 8.430003713s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:12:29.941: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2540
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on node default medium
Aug 14 07:12:30.184: INFO: Waiting up to 5m0s for pod "pod-0328e40e-f5b0-4e15-a776-b87c9a37f24b" in namespace "emptydir-2540" to be "success or failure"
Aug 14 07:12:30.195: INFO: Pod "pod-0328e40e-f5b0-4e15-a776-b87c9a37f24b": Phase="Pending", Reason="", readiness=false. Elapsed: 10.11861ms
Aug 14 07:12:32.205: INFO: Pod "pod-0328e40e-f5b0-4e15-a776-b87c9a37f24b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020802151s
STEP: Saw pod success
Aug 14 07:12:32.205: INFO: Pod "pod-0328e40e-f5b0-4e15-a776-b87c9a37f24b" satisfied condition "success or failure"
Aug 14 07:12:32.216: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod pod-0328e40e-f5b0-4e15-a776-b87c9a37f24b container test-container: <nil>
STEP: delete the pod
Aug 14 07:12:32.251: INFO: Waiting for pod pod-0328e40e-f5b0-4e15-a776-b87c9a37f24b to disappear
Aug 14 07:12:32.262: INFO: Pod pod-0328e40e-f5b0-4e15-a776-b87c9a37f24b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:12:32.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2540" for this suite.
Aug 14 07:12:38.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:12:38.746: INFO: namespace emptydir-2540 deletion completed in 6.465270637s
•SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:12:38.746: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-9147
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Aug 14 07:12:39.062: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug 14 07:12:39.083: INFO: Waiting for terminating namespaces to be deleted...
Aug 14 07:12:39.093: INFO: 
Logging pods the kubelet thinks is on node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw before test
Aug 14 07:12:39.118: INFO: addons-nginx-ingress-controller-6496d947df-dqs5z from kube-system started at 2019-08-14 06:27:10 +0000 UTC (1 container statuses recorded)
Aug 14 07:12:39.118: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Aug 14 07:12:39.118: INFO: coredns-85cc454dd8-zsj57 from kube-system started at 2019-08-14 06:27:10 +0000 UTC (1 container statuses recorded)
Aug 14 07:12:39.118: INFO: 	Container coredns ready: true, restart count 0
Aug 14 07:12:39.118: INFO: calico-kube-controllers-5f4b46ffb5-m6pdj from kube-system started at 2019-08-14 06:27:10 +0000 UTC (1 container statuses recorded)
Aug 14 07:12:39.118: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Aug 14 07:12:39.118: INFO: blackbox-exporter-954dd954b-8xcv9 from kube-system started at 2019-08-14 06:26:55 +0000 UTC (1 container statuses recorded)
Aug 14 07:12:39.118: INFO: 	Container blackbox-exporter ready: true, restart count 0
Aug 14 07:12:39.118: INFO: kube-proxy-n2x65 from kube-system started at 2019-08-14 06:26:55 +0000 UTC (1 container statuses recorded)
Aug 14 07:12:39.118: INFO: 	Container kube-proxy ready: true, restart count 0
Aug 14 07:12:39.118: INFO: calico-node-gb7zk from kube-system started at 2019-08-14 06:26:55 +0000 UTC (1 container statuses recorded)
Aug 14 07:12:39.118: INFO: 	Container calico-node ready: true, restart count 1
Aug 14 07:12:39.118: INFO: node-exporter-hmlnc from kube-system started at 2019-08-14 06:26:55 +0000 UTC (1 container statuses recorded)
Aug 14 07:12:39.118: INFO: 	Container node-exporter ready: true, restart count 0
Aug 14 07:12:39.118: INFO: vpn-shoot-7d7bc8fd7d-997f6 from kube-system started at 2019-08-14 06:27:10 +0000 UTC (1 container statuses recorded)
Aug 14 07:12:39.118: INFO: 	Container vpn-shoot ready: true, restart count 0
Aug 14 07:12:39.118: INFO: addons-kubernetes-dashboard-5c8d9945bc-8t28x from kube-system started at 2019-08-14 06:27:10 +0000 UTC (1 container statuses recorded)
Aug 14 07:12:39.118: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Aug 14 07:12:39.118: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-88d6cff74-rw8q9 from kube-system started at 2019-08-14 06:27:10 +0000 UTC (1 container statuses recorded)
Aug 14 07:12:39.118: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Aug 14 07:12:39.118: INFO: metrics-server-f5b59f6cc-xc2ch from kube-system started at 2019-08-14 06:27:10 +0000 UTC (1 container statuses recorded)
Aug 14 07:12:39.118: INFO: 	Container metrics-server ready: true, restart count 0
Aug 14 07:12:39.118: INFO: coredns-85cc454dd8-l4hk9 from kube-system started at 2019-08-14 06:27:14 +0000 UTC (1 container statuses recorded)
Aug 14 07:12:39.118: INFO: 	Container coredns ready: true, restart count 0
Aug 14 07:12:39.118: INFO: 
Logging pods the kubelet thinks is on node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp before test
Aug 14 07:12:39.158: INFO: kube-proxy-2nsfn from kube-system started at 2019-08-14 06:26:56 +0000 UTC (1 container statuses recorded)
Aug 14 07:12:39.158: INFO: 	Container kube-proxy ready: true, restart count 0
Aug 14 07:12:39.158: INFO: node-exporter-wq6g7 from kube-system started at 2019-08-14 06:26:56 +0000 UTC (1 container statuses recorded)
Aug 14 07:12:39.158: INFO: 	Container node-exporter ready: true, restart count 0
Aug 14 07:12:39.158: INFO: calico-node-ksxzt from kube-system started at 2019-08-14 06:26:56 +0000 UTC (1 container statuses recorded)
Aug 14 07:12:39.158: INFO: 	Container calico-node ready: true, restart count 1
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: verifying the node has the label node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw
STEP: verifying the node has the label node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp
Aug 14 07:12:39.232: INFO: Pod addons-kubernetes-dashboard-5c8d9945bc-8t28x requesting resource cpu=50m on Node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw
Aug 14 07:12:39.232: INFO: Pod addons-nginx-ingress-controller-6496d947df-dqs5z requesting resource cpu=100m on Node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw
Aug 14 07:12:39.232: INFO: Pod addons-nginx-ingress-nginx-ingress-k8s-backend-88d6cff74-rw8q9 requesting resource cpu=0m on Node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw
Aug 14 07:12:39.232: INFO: Pod blackbox-exporter-954dd954b-8xcv9 requesting resource cpu=5m on Node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw
Aug 14 07:12:39.232: INFO: Pod calico-kube-controllers-5f4b46ffb5-m6pdj requesting resource cpu=0m on Node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw
Aug 14 07:12:39.232: INFO: Pod calico-node-gb7zk requesting resource cpu=100m on Node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw
Aug 14 07:12:39.232: INFO: Pod calico-node-ksxzt requesting resource cpu=100m on Node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp
Aug 14 07:12:39.232: INFO: Pod coredns-85cc454dd8-l4hk9 requesting resource cpu=50m on Node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw
Aug 14 07:12:39.232: INFO: Pod coredns-85cc454dd8-zsj57 requesting resource cpu=50m on Node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw
Aug 14 07:12:39.232: INFO: Pod kube-proxy-2nsfn requesting resource cpu=20m on Node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp
Aug 14 07:12:39.232: INFO: Pod kube-proxy-n2x65 requesting resource cpu=20m on Node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw
Aug 14 07:12:39.232: INFO: Pod metrics-server-f5b59f6cc-xc2ch requesting resource cpu=20m on Node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw
Aug 14 07:12:39.232: INFO: Pod node-exporter-hmlnc requesting resource cpu=5m on Node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw
Aug 14 07:12:39.232: INFO: Pod node-exporter-wq6g7 requesting resource cpu=5m on Node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp
Aug 14 07:12:39.232: INFO: Pod vpn-shoot-7d7bc8fd7d-997f6 requesting resource cpu=100m on Node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-33629099-89cd-4af8-aa00-5902a5c2a1f0.15bab8925c64ffe2], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9147/filler-pod-33629099-89cd-4af8-aa00-5902a5c2a1f0 to shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-33629099-89cd-4af8-aa00-5902a5c2a1f0.15bab8928510af72], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-33629099-89cd-4af8-aa00-5902a5c2a1f0.15bab89287c1061f], Reason = [Created], Message = [Created container filler-pod-33629099-89cd-4af8-aa00-5902a5c2a1f0]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-33629099-89cd-4af8-aa00-5902a5c2a1f0.15bab89290102b7a], Reason = [Started], Message = [Started container filler-pod-33629099-89cd-4af8-aa00-5902a5c2a1f0]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-8640ab35-b187-404e-96ff-846dcbb1e9f6.15bab8925d1a17cf], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9147/filler-pod-8640ab35-b187-404e-96ff-846dcbb1e9f6 to shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-8640ab35-b187-404e-96ff-846dcbb1e9f6.15bab89286243ed8], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-8640ab35-b187-404e-96ff-846dcbb1e9f6.15bab89289183817], Reason = [Created], Message = [Created container filler-pod-8640ab35-b187-404e-96ff-846dcbb1e9f6]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-8640ab35-b187-404e-96ff-846dcbb1e9f6.15bab892913d6239], Reason = [Started], Message = [Started container filler-pod-8640ab35-b187-404e-96ff-846dcbb1e9f6]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15bab892d80b776a], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu.]
STEP: removing the label node off the node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:12:42.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9147" for this suite.
Aug 14 07:12:48.448: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:12:48.835: INFO: namespace sched-pred-9147 deletion completed in 6.419926774s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72
•SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:12:48.835: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-1053
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:12:51.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1053" for this suite.
Aug 14 07:13:39.282: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:13:39.713: INFO: namespace kubelet-test-1053 deletion completed in 48.463274358s
•
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:13:39.713: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-3515
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Aug 14 07:13:39.994: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:13:41.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-3515" for this suite.
Aug 14 07:13:47.105: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:13:47.551: INFO: namespace replication-controller-3515 deletion completed in 6.483311198s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:13:47.552: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1125
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Aug 14 07:13:47.785: INFO: Waiting up to 5m0s for pod "pod-81276807-6592-462b-9da6-09f837291636" in namespace "emptydir-1125" to be "success or failure"
Aug 14 07:13:47.796: INFO: Pod "pod-81276807-6592-462b-9da6-09f837291636": Phase="Pending", Reason="", readiness=false. Elapsed: 10.072534ms
Aug 14 07:13:49.807: INFO: Pod "pod-81276807-6592-462b-9da6-09f837291636": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021343016s
STEP: Saw pod success
Aug 14 07:13:49.807: INFO: Pod "pod-81276807-6592-462b-9da6-09f837291636" satisfied condition "success or failure"
Aug 14 07:13:49.818: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod pod-81276807-6592-462b-9da6-09f837291636 container test-container: <nil>
STEP: delete the pod
Aug 14 07:13:49.853: INFO: Waiting for pod pod-81276807-6592-462b-9da6-09f837291636 to disappear
Aug 14 07:13:49.863: INFO: Pod pod-81276807-6592-462b-9da6-09f837291636 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:13:49.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1125" for this suite.
Aug 14 07:13:55.914: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:13:56.300: INFO: namespace emptydir-1125 deletion completed in 6.418300511s
•SSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:13:56.300: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6904
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with configMap that has name projected-configmap-test-upd-ff3e7c78-efaf-4ba1-9190-a117f88d25a4
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-ff3e7c78-efaf-4ba1-9190-a117f88d25a4
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:14:00.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6904" for this suite.
Aug 14 07:14:24.815: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:14:25.212: INFO: namespace projected-6904 deletion completed in 24.432200983s
•SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:14:25.213: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5583
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 14 07:14:25.490: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7d79dc1e-be97-4722-be5c-b05550699d4e" in namespace "downward-api-5583" to be "success or failure"
Aug 14 07:14:25.500: INFO: Pod "downwardapi-volume-7d79dc1e-be97-4722-be5c-b05550699d4e": Phase="Pending", Reason="", readiness=false. Elapsed: 10.21371ms
Aug 14 07:14:27.512: INFO: Pod "downwardapi-volume-7d79dc1e-be97-4722-be5c-b05550699d4e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021895085s
STEP: Saw pod success
Aug 14 07:14:27.512: INFO: Pod "downwardapi-volume-7d79dc1e-be97-4722-be5c-b05550699d4e" satisfied condition "success or failure"
Aug 14 07:14:27.523: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod downwardapi-volume-7d79dc1e-be97-4722-be5c-b05550699d4e container client-container: <nil>
STEP: delete the pod
Aug 14 07:14:27.558: INFO: Waiting for pod downwardapi-volume-7d79dc1e-be97-4722-be5c-b05550699d4e to disappear
Aug 14 07:14:27.569: INFO: Pod downwardapi-volume-7d79dc1e-be97-4722-be5c-b05550699d4e no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:14:27.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5583" for this suite.
Aug 14 07:14:33.622: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:14:34.033: INFO: namespace downward-api-5583 deletion completed in 6.445285629s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:14:34.033: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-3995
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Aug 14 07:14:40.465: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3995 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 07:14:40.465: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Aug 14 07:14:45.889: INFO: Exec stderr: ""
Aug 14 07:14:45.889: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3995 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 07:14:45.889: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Aug 14 07:14:46.449: INFO: Exec stderr: ""
Aug 14 07:14:46.449: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3995 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 07:14:46.449: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Aug 14 07:14:46.893: INFO: Exec stderr: ""
Aug 14 07:14:46.893: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3995 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 07:14:46.893: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Aug 14 07:14:47.347: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Aug 14 07:14:47.347: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3995 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 07:14:47.347: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Aug 14 07:14:47.809: INFO: Exec stderr: ""
Aug 14 07:14:47.809: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3995 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 07:14:47.809: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Aug 14 07:14:48.251: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Aug 14 07:14:48.251: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3995 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 07:14:48.251: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Aug 14 07:14:48.707: INFO: Exec stderr: ""
Aug 14 07:14:48.707: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3995 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 07:14:48.707: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Aug 14 07:14:49.183: INFO: Exec stderr: ""
Aug 14 07:14:49.183: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3995 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 07:14:49.183: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Aug 14 07:14:49.780: INFO: Exec stderr: ""
Aug 14 07:14:49.780: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3995 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 07:14:49.780: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Aug 14 07:14:50.232: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:14:50.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-3995" for this suite.
Aug 14 07:15:38.286: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:15:38.678: INFO: namespace e2e-kubelet-etc-hosts-3995 deletion completed in 48.425996802s
•SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:15:38.678: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9244
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1293
STEP: creating an rc
Aug 14 07:15:38.961: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-9244'
Aug 14 07:15:39.451: INFO: stderr: ""
Aug 14 07:15:39.451: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Waiting for Redis master to start.
Aug 14 07:15:40.462: INFO: Selector matched 1 pods for map[app:redis]
Aug 14 07:15:40.463: INFO: Found 0 / 1
Aug 14 07:15:41.463: INFO: Selector matched 1 pods for map[app:redis]
Aug 14 07:15:41.463: INFO: Found 1 / 1
Aug 14 07:15:41.463: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug 14 07:15:41.475: INFO: Selector matched 1 pods for map[app:redis]
Aug 14 07:15:41.475: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Aug 14 07:15:41.475: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs redis-master-m6f2m redis-master --namespace=kubectl-9244'
Aug 14 07:15:41.623: INFO: stderr: ""
Aug 14 07:15:41.623: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 14 Aug 07:15:40.298 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 14 Aug 07:15:40.298 # Server started, Redis version 3.2.12\n1:M 14 Aug 07:15:40.298 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 14 Aug 07:15:40.298 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Aug 14 07:15:41.623: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config log redis-master-m6f2m redis-master --namespace=kubectl-9244 --tail=1'
Aug 14 07:15:41.759: INFO: stderr: ""
Aug 14 07:15:41.759: INFO: stdout: "1:M 14 Aug 07:15:40.298 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Aug 14 07:15:41.759: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config log redis-master-m6f2m redis-master --namespace=kubectl-9244 --limit-bytes=1'
Aug 14 07:15:41.921: INFO: stderr: ""
Aug 14 07:15:41.921: INFO: stdout: " "
STEP: exposing timestamps
Aug 14 07:15:41.921: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config log redis-master-m6f2m redis-master --namespace=kubectl-9244 --tail=1 --timestamps'
Aug 14 07:15:42.054: INFO: stderr: ""
Aug 14 07:15:42.054: INFO: stdout: "2019-08-14T07:15:40.299387888Z 1:M 14 Aug 07:15:40.298 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Aug 14 07:15:44.554: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config log redis-master-m6f2m redis-master --namespace=kubectl-9244 --since=1s'
Aug 14 07:15:44.693: INFO: stderr: ""
Aug 14 07:15:44.693: INFO: stdout: ""
Aug 14 07:15:44.693: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config log redis-master-m6f2m redis-master --namespace=kubectl-9244 --since=24h'
Aug 14 07:15:44.825: INFO: stderr: ""
Aug 14 07:15:44.825: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 14 Aug 07:15:40.298 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 14 Aug 07:15:40.298 # Server started, Redis version 3.2.12\n1:M 14 Aug 07:15:40.298 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 14 Aug 07:15:40.298 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1299
STEP: using delete to clean up resources
Aug 14 07:15:44.825: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-9244'
Aug 14 07:15:44.966: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 14 07:15:44.966: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Aug 14 07:15:44.966: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get rc,svc -l name=nginx --no-headers --namespace=kubectl-9244'
Aug 14 07:15:45.103: INFO: stderr: "No resources found.\n"
Aug 14 07:15:45.103: INFO: stdout: ""
Aug 14 07:15:45.103: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -l name=nginx --namespace=kubectl-9244 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 14 07:15:45.219: INFO: stderr: ""
Aug 14 07:15:45.219: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:15:45.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9244" for this suite.
Aug 14 07:15:51.273: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:15:51.708: INFO: namespace kubectl-9244 deletion completed in 6.469886584s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:15:51.709: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8224
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Aug 14 07:15:54.670: INFO: Successfully updated pod "annotationupdate2022b29e-d26f-4260-ba15-9381b9c801e0"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:15:58.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8224" for this suite.
Aug 14 07:16:20.776: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:16:21.173: INFO: namespace projected-8224 deletion completed in 22.430783953s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:16:21.174: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8217
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Aug 14 07:16:21.461: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-8217'
Aug 14 07:16:21.737: INFO: stderr: ""
Aug 14 07:16:21.737: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 14 07:16:21.737: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8217'
Aug 14 07:16:21.859: INFO: stderr: ""
Aug 14 07:16:21.859: INFO: stdout: "update-demo-nautilus-hzmkz update-demo-nautilus-kvzx8 "
Aug 14 07:16:21.859: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-hzmkz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8217'
Aug 14 07:16:22.031: INFO: stderr: ""
Aug 14 07:16:22.031: INFO: stdout: ""
Aug 14 07:16:22.031: INFO: update-demo-nautilus-hzmkz is created but not running
Aug 14 07:16:27.031: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8217'
Aug 14 07:16:27.161: INFO: stderr: ""
Aug 14 07:16:27.161: INFO: stdout: "update-demo-nautilus-hzmkz update-demo-nautilus-kvzx8 "
Aug 14 07:16:27.161: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-hzmkz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8217'
Aug 14 07:16:27.279: INFO: stderr: ""
Aug 14 07:16:27.279: INFO: stdout: "true"
Aug 14 07:16:27.279: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-hzmkz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8217'
Aug 14 07:16:27.394: INFO: stderr: ""
Aug 14 07:16:27.395: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 14 07:16:27.395: INFO: validating pod update-demo-nautilus-hzmkz
Aug 14 07:16:27.490: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 14 07:16:27.490: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 14 07:16:27.490: INFO: update-demo-nautilus-hzmkz is verified up and running
Aug 14 07:16:27.490: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-kvzx8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8217'
Aug 14 07:16:27.613: INFO: stderr: ""
Aug 14 07:16:27.613: INFO: stdout: "true"
Aug 14 07:16:27.613: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-kvzx8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8217'
Aug 14 07:16:27.727: INFO: stderr: ""
Aug 14 07:16:27.727: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 14 07:16:27.727: INFO: validating pod update-demo-nautilus-kvzx8
Aug 14 07:16:27.824: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 14 07:16:27.824: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 14 07:16:27.824: INFO: update-demo-nautilus-kvzx8 is verified up and running
STEP: using delete to clean up resources
Aug 14 07:16:27.824: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-8217'
Aug 14 07:16:27.947: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 14 07:16:27.947: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Aug 14 07:16:27.947: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get rc,svc -l name=update-demo --no-headers --namespace=kubectl-8217'
Aug 14 07:16:28.091: INFO: stderr: "No resources found.\n"
Aug 14 07:16:28.091: INFO: stdout: ""
Aug 14 07:16:28.091: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -l name=update-demo --namespace=kubectl-8217 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 14 07:16:28.212: INFO: stderr: ""
Aug 14 07:16:28.212: INFO: stdout: "update-demo-nautilus-hzmkz\nupdate-demo-nautilus-kvzx8\n"
Aug 14 07:16:28.712: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get rc,svc -l name=update-demo --no-headers --namespace=kubectl-8217'
Aug 14 07:16:28.843: INFO: stderr: "No resources found.\n"
Aug 14 07:16:28.843: INFO: stdout: ""
Aug 14 07:16:28.843: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -l name=update-demo --namespace=kubectl-8217 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 14 07:16:28.961: INFO: stderr: ""
Aug 14 07:16:28.961: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:16:28.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8217" for this suite.
Aug 14 07:16:51.016: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:16:51.445: INFO: namespace kubectl-8217 deletion completed in 22.464270494s
•SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:16:51.446: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-2566
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-9f826d95-e3a4-4b4f-9280-4fb993f0074f in namespace container-probe-2566
Aug 14 07:16:53.798: INFO: Started pod liveness-9f826d95-e3a4-4b4f-9280-4fb993f0074f in namespace container-probe-2566
STEP: checking the pod's current state and verifying that restartCount is present
Aug 14 07:16:53.808: INFO: Initial restart count of pod liveness-9f826d95-e3a4-4b4f-9280-4fb993f0074f is 0
Aug 14 07:17:13.933: INFO: Restart count of pod container-probe-2566/liveness-9f826d95-e3a4-4b4f-9280-4fb993f0074f is now 1 (20.124832017s elapsed)
Aug 14 07:17:34.050: INFO: Restart count of pod container-probe-2566/liveness-9f826d95-e3a4-4b4f-9280-4fb993f0074f is now 2 (40.241322433s elapsed)
Aug 14 07:17:54.168: INFO: Restart count of pod container-probe-2566/liveness-9f826d95-e3a4-4b4f-9280-4fb993f0074f is now 3 (1m0.359983537s elapsed)
Aug 14 07:18:14.283: INFO: Restart count of pod container-probe-2566/liveness-9f826d95-e3a4-4b4f-9280-4fb993f0074f is now 4 (1m20.474699782s elapsed)
Aug 14 07:19:14.632: INFO: Restart count of pod container-probe-2566/liveness-9f826d95-e3a4-4b4f-9280-4fb993f0074f is now 5 (2m20.824120401s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:19:14.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2566" for this suite.
Aug 14 07:19:20.700: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:19:21.133: INFO: namespace container-probe-2566 deletion completed in 6.466582894s
•SSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:19:21.133: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-661
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test env composition
Aug 14 07:19:21.395: INFO: Waiting up to 5m0s for pod "var-expansion-faeb3a09-5a3f-4e46-b77e-23ef4ab13618" in namespace "var-expansion-661" to be "success or failure"
Aug 14 07:19:21.406: INFO: Pod "var-expansion-faeb3a09-5a3f-4e46-b77e-23ef4ab13618": Phase="Pending", Reason="", readiness=false. Elapsed: 10.12843ms
Aug 14 07:19:23.417: INFO: Pod "var-expansion-faeb3a09-5a3f-4e46-b77e-23ef4ab13618": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021608s
STEP: Saw pod success
Aug 14 07:19:23.417: INFO: Pod "var-expansion-faeb3a09-5a3f-4e46-b77e-23ef4ab13618" satisfied condition "success or failure"
Aug 14 07:19:23.428: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod var-expansion-faeb3a09-5a3f-4e46-b77e-23ef4ab13618 container dapi-container: <nil>
STEP: delete the pod
Aug 14 07:19:23.464: INFO: Waiting for pod var-expansion-faeb3a09-5a3f-4e46-b77e-23ef4ab13618 to disappear
Aug 14 07:19:23.475: INFO: Pod var-expansion-faeb3a09-5a3f-4e46-b77e-23ef4ab13618 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:19:23.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-661" for this suite.
Aug 14 07:19:29.529: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:19:29.986: INFO: namespace var-expansion-661 deletion completed in 6.491839066s
•SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:19:29.987: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3282
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting the proxy server
Aug 14 07:19:30.177: INFO: Asynchronously running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:19:30.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3282" for this suite.
Aug 14 07:19:36.354: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:19:36.748: INFO: namespace kubectl-3282 deletion completed in 6.427372521s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:19:36.748: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-7989
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test use defaults
Aug 14 07:19:37.080: INFO: Waiting up to 5m0s for pod "client-containers-0ea1de65-46d8-4d45-a3c8-ed40666d4c79" in namespace "containers-7989" to be "success or failure"
Aug 14 07:19:37.090: INFO: Pod "client-containers-0ea1de65-46d8-4d45-a3c8-ed40666d4c79": Phase="Pending", Reason="", readiness=false. Elapsed: 9.880848ms
Aug 14 07:19:39.102: INFO: Pod "client-containers-0ea1de65-46d8-4d45-a3c8-ed40666d4c79": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021188262s
STEP: Saw pod success
Aug 14 07:19:39.102: INFO: Pod "client-containers-0ea1de65-46d8-4d45-a3c8-ed40666d4c79" satisfied condition "success or failure"
Aug 14 07:19:39.113: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod client-containers-0ea1de65-46d8-4d45-a3c8-ed40666d4c79 container test-container: <nil>
STEP: delete the pod
Aug 14 07:19:39.145: INFO: Waiting for pod client-containers-0ea1de65-46d8-4d45-a3c8-ed40666d4c79 to disappear
Aug 14 07:19:39.156: INFO: Pod client-containers-0ea1de65-46d8-4d45-a3c8-ed40666d4c79 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:19:39.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7989" for this suite.
Aug 14 07:19:45.210: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:19:45.617: INFO: namespace containers-7989 deletion completed in 6.442512502s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:19:45.618: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-7728
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:19:51.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7728" for this suite.
Aug 14 07:19:57.434: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:19:57.824: INFO: namespace watch-7728 deletion completed in 6.496386986s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:19:57.825: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7347
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-5f289e6f-7060-4e9b-9c68-9c3afe6da52b
STEP: Creating a pod to test consume configMaps
Aug 14 07:19:58.193: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2933f979-7b84-4a38-805c-f1a193a9cd17" in namespace "projected-7347" to be "success or failure"
Aug 14 07:19:58.203: INFO: Pod "pod-projected-configmaps-2933f979-7b84-4a38-805c-f1a193a9cd17": Phase="Pending", Reason="", readiness=false. Elapsed: 10.124743ms
Aug 14 07:20:00.215: INFO: Pod "pod-projected-configmaps-2933f979-7b84-4a38-805c-f1a193a9cd17": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021634175s
STEP: Saw pod success
Aug 14 07:20:00.215: INFO: Pod "pod-projected-configmaps-2933f979-7b84-4a38-805c-f1a193a9cd17" satisfied condition "success or failure"
Aug 14 07:20:00.226: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod pod-projected-configmaps-2933f979-7b84-4a38-805c-f1a193a9cd17 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 14 07:20:00.261: INFO: Waiting for pod pod-projected-configmaps-2933f979-7b84-4a38-805c-f1a193a9cd17 to disappear
Aug 14 07:20:00.272: INFO: Pod pod-projected-configmaps-2933f979-7b84-4a38-805c-f1a193a9cd17 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:20:00.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7347" for this suite.
Aug 14 07:20:06.330: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:20:06.759: INFO: namespace projected-7347 deletion completed in 6.467859477s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:20:06.759: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7150
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-75efa043-a7b0-4aa0-a234-dbc5c78a8c58
STEP: Creating a pod to test consume configMaps
Aug 14 07:20:07.006: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-35556b85-a924-4608-b372-cfd93f9b0237" in namespace "projected-7150" to be "success or failure"
Aug 14 07:20:07.016: INFO: Pod "pod-projected-configmaps-35556b85-a924-4608-b372-cfd93f9b0237": Phase="Pending", Reason="", readiness=false. Elapsed: 10.295693ms
Aug 14 07:20:09.028: INFO: Pod "pod-projected-configmaps-35556b85-a924-4608-b372-cfd93f9b0237": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021842s
STEP: Saw pod success
Aug 14 07:20:09.028: INFO: Pod "pod-projected-configmaps-35556b85-a924-4608-b372-cfd93f9b0237" satisfied condition "success or failure"
Aug 14 07:20:09.039: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod pod-projected-configmaps-35556b85-a924-4608-b372-cfd93f9b0237 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 14 07:20:09.073: INFO: Waiting for pod pod-projected-configmaps-35556b85-a924-4608-b372-cfd93f9b0237 to disappear
Aug 14 07:20:09.083: INFO: Pod pod-projected-configmaps-35556b85-a924-4608-b372-cfd93f9b0237 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:20:09.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7150" for this suite.
Aug 14 07:20:15.138: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:20:15.580: INFO: namespace projected-7150 deletion completed in 6.477540678s
•SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:20:15.580: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-6613
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Aug 14 07:20:45.972: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0814 07:20:45.972141    4167 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:20:45.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6613" for this suite.
Aug 14 07:20:52.016: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:20:52.412: INFO: namespace gc-6613 deletion completed in 6.429966069s
•SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:20:52.413: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8693
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating api versions
Aug 14 07:20:52.679: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config api-versions'
Aug 14 07:20:52.814: INFO: stderr: ""
Aug 14 07:20:52.814: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:20:52.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8693" for this suite.
Aug 14 07:20:58.861: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:20:59.249: INFO: namespace kubectl-8693 deletion completed in 6.42327864s
•S
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:20:59.249: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-9019
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 14 07:20:59.477: INFO: Creating deployment "nginx-deployment"
Aug 14 07:20:59.489: INFO: Waiting for observed generation 1
Aug 14 07:21:01.511: INFO: Waiting for all required pods to come up
Aug 14 07:21:01.531: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Aug 14 07:21:03.562: INFO: Waiting for deployment "nginx-deployment" to complete
Aug 14 07:21:03.583: INFO: Updating deployment "nginx-deployment" with a non-existent image
Aug 14 07:21:03.604: INFO: Updating deployment nginx-deployment
Aug 14 07:21:03.604: INFO: Waiting for observed generation 2
Aug 14 07:21:05.627: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Aug 14 07:21:05.638: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Aug 14 07:21:05.649: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Aug 14 07:21:05.681: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Aug 14 07:21:05.681: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Aug 14 07:21:05.692: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Aug 14 07:21:05.714: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Aug 14 07:21:05.714: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Aug 14 07:21:05.736: INFO: Updating deployment nginx-deployment
Aug 14 07:21:05.736: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Aug 14 07:21:05.756: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Aug 14 07:21:07.778: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Aug 14 07:21:07.808: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-9019,SelfLink:/apis/apps/v1/namespaces/deployment-9019/deployments/nginx-deployment,UID:8cf2c9ce-950a-4398-b563-56bc5444bd23,ResourceVersion:13471,Generation:3,CreationTimestamp:2019-08-14 07:20:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-08-14 07:21:05 +0000 UTC 2019-08-14 07:21:05 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-08-14 07:21:06 +0000 UTC 2019-08-14 07:20:59 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-55fb7cb77f" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Aug 14 07:21:07.819: INFO: New ReplicaSet "nginx-deployment-55fb7cb77f" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f,GenerateName:,Namespace:deployment-9019,SelfLink:/apis/apps/v1/namespaces/deployment-9019/replicasets/nginx-deployment-55fb7cb77f,UID:ab4c4c38-da63-4260-a22f-45c5bbb988bc,ResourceVersion:13469,Generation:3,CreationTimestamp:2019-08-14 07:21:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 8cf2c9ce-950a-4398-b563-56bc5444bd23 0xc0012263e7 0xc0012263e8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 14 07:21:07.819: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Aug 14 07:21:07.819: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498,GenerateName:,Namespace:deployment-9019,SelfLink:/apis/apps/v1/namespaces/deployment-9019/replicasets/nginx-deployment-7b8c6f4498,UID:54e47f2c-f656-4b40-b640-90f6c98ed5ca,ResourceVersion:13468,Generation:3,CreationTimestamp:2019-08-14 07:20:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 8cf2c9ce-950a-4398-b563-56bc5444bd23 0xc001226507 0xc001226508}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Aug 14 07:21:07.848: INFO: Pod "nginx-deployment-55fb7cb77f-6mxz8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-6mxz8,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-9019,SelfLink:/api/v1/namespaces/deployment-9019/pods/nginx-deployment-55fb7cb77f-6mxz8,UID:7d23b31b-bcd8-4b16-b844-caadea833158,ResourceVersion:13453,Generation:0,CreationTimestamp:2019-08-14 07:21:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.143/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f ab4c4c38-da63-4260-a22f-45c5bbb988bc 0xc0039f6977 0xc0039f6978}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdwlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdwlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-xdwlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0039f69e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0039f6a00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:03 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:100.96.1.143,StartTime:2019-08-14 07:21:03 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 07:21:07.849: INFO: Pod "nginx-deployment-55fb7cb77f-7w4t5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-7w4t5,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-9019,SelfLink:/api/v1/namespaces/deployment-9019/pods/nginx-deployment-55fb7cb77f-7w4t5,UID:7a192113-b8af-4af0-ab78-14358f6528fa,ResourceVersion:13391,Generation:0,CreationTimestamp:2019-08-14 07:21:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.53/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f ab4c4c38-da63-4260-a22f-45c5bbb988bc 0xc0039f6b00 0xc0039f6b01}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdwlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdwlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-xdwlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0039f6b70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0039f6b90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:03 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.2,PodIP:,StartTime:2019-08-14 07:21:03 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 07:21:07.849: INFO: Pod "nginx-deployment-55fb7cb77f-8sjts" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-8sjts,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-9019,SelfLink:/api/v1/namespaces/deployment-9019/pods/nginx-deployment-55fb7cb77f-8sjts,UID:e2886189-dcc1-41ff-bed0-218df6857b37,ResourceVersion:13442,Generation:0,CreationTimestamp:2019-08-14 07:21:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f ab4c4c38-da63-4260-a22f-45c5bbb988bc 0xc0039f6c60 0xc0039f6c61}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdwlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdwlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-xdwlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0039f6cd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0039f6cf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:05 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:,StartTime:2019-08-14 07:21:05 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 07:21:07.849: INFO: Pod "nginx-deployment-55fb7cb77f-b2bsg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-b2bsg,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-9019,SelfLink:/api/v1/namespaces/deployment-9019/pods/nginx-deployment-55fb7cb77f-b2bsg,UID:e09601bb-6068-4fab-824f-97745912c9f5,ResourceVersion:13440,Generation:0,CreationTimestamp:2019-08-14 07:21:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f ab4c4c38-da63-4260-a22f-45c5bbb988bc 0xc0039f6dc0 0xc0039f6dc1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdwlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdwlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-xdwlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0039f6e30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0039f6e50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:05 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:,StartTime:2019-08-14 07:21:05 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 07:21:07.849: INFO: Pod "nginx-deployment-55fb7cb77f-fmd2n" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-fmd2n,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-9019,SelfLink:/api/v1/namespaces/deployment-9019/pods/nginx-deployment-55fb7cb77f-fmd2n,UID:211838ad-94ad-48f8-b4d7-ae8e0e241f0b,ResourceVersion:13394,Generation:0,CreationTimestamp:2019-08-14 07:21:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.145/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f ab4c4c38-da63-4260-a22f-45c5bbb988bc 0xc0039f6f30 0xc0039f6f31}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdwlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdwlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-xdwlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0039f6fa0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0039f6fc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:03 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:,StartTime:2019-08-14 07:21:03 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 07:21:07.849: INFO: Pod "nginx-deployment-55fb7cb77f-fq5qc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-fq5qc,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-9019,SelfLink:/api/v1/namespaces/deployment-9019/pods/nginx-deployment-55fb7cb77f-fq5qc,UID:c6f9b1c2-d4ab-43fa-954c-48fa7ec9b90f,ResourceVersion:13472,Generation:0,CreationTimestamp:2019-08-14 07:21:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.54/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f ab4c4c38-da63-4260-a22f-45c5bbb988bc 0xc0039f70a0 0xc0039f70a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdwlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdwlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-xdwlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0039f7110} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0039f7130}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:05 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.2,PodIP:,StartTime:2019-08-14 07:21:05 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 07:21:07.849: INFO: Pod "nginx-deployment-55fb7cb77f-g8489" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-g8489,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-9019,SelfLink:/api/v1/namespaces/deployment-9019/pods/nginx-deployment-55fb7cb77f-g8489,UID:f052a4b8-37df-400c-9f60-3bc1ff60c87d,ResourceVersion:13408,Generation:0,CreationTimestamp:2019-08-14 07:21:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.52/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f ab4c4c38-da63-4260-a22f-45c5bbb988bc 0xc0039f7210 0xc0039f7211}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdwlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdwlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-xdwlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0039f7280} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0039f72a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:03 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.2,PodIP:100.96.0.52,StartTime:2019-08-14 07:21:03 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 07:21:07.850: INFO: Pod "nginx-deployment-55fb7cb77f-j8b4v" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-j8b4v,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-9019,SelfLink:/api/v1/namespaces/deployment-9019/pods/nginx-deployment-55fb7cb77f-j8b4v,UID:3ca7bfae-0039-4eb8-b8e9-a86341228119,ResourceVersion:13393,Generation:0,CreationTimestamp:2019-08-14 07:21:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.144/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f ab4c4c38-da63-4260-a22f-45c5bbb988bc 0xc0039f73a0 0xc0039f73a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdwlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdwlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-xdwlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0039f7410} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0039f7430}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:03 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:,StartTime:2019-08-14 07:21:03 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 07:21:07.850: INFO: Pod "nginx-deployment-55fb7cb77f-jwsxr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-jwsxr,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-9019,SelfLink:/api/v1/namespaces/deployment-9019/pods/nginx-deployment-55fb7cb77f-jwsxr,UID:83e0fc53-043a-4f1b-87eb-e0a037523921,ResourceVersion:13478,Generation:0,CreationTimestamp:2019-08-14 07:21:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.56/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f ab4c4c38-da63-4260-a22f-45c5bbb988bc 0xc0039f7510 0xc0039f7511}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdwlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdwlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-xdwlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0039f7580} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0039f75a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:05 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.2,PodIP:,StartTime:2019-08-14 07:21:05 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 07:21:07.850: INFO: Pod "nginx-deployment-55fb7cb77f-px66r" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-px66r,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-9019,SelfLink:/api/v1/namespaces/deployment-9019/pods/nginx-deployment-55fb7cb77f-px66r,UID:95263258-3366-4c8a-bd04-e7f11a777aa8,ResourceVersion:13438,Generation:0,CreationTimestamp:2019-08-14 07:21:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f ab4c4c38-da63-4260-a22f-45c5bbb988bc 0xc0039f7690 0xc0039f7691}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdwlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdwlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-xdwlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0039f7700} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0039f7720}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:05 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:,StartTime:2019-08-14 07:21:05 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 07:21:07.850: INFO: Pod "nginx-deployment-55fb7cb77f-slh7g" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-slh7g,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-9019,SelfLink:/api/v1/namespaces/deployment-9019/pods/nginx-deployment-55fb7cb77f-slh7g,UID:17b32dc2-e5c6-4b79-baf8-740697659c0c,ResourceVersion:13443,Generation:0,CreationTimestamp:2019-08-14 07:21:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f ab4c4c38-da63-4260-a22f-45c5bbb988bc 0xc0039f77f0 0xc0039f77f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdwlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdwlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-xdwlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0039f7860} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0039f7880}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:05 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:,StartTime:2019-08-14 07:21:05 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 07:21:07.850: INFO: Pod "nginx-deployment-55fb7cb77f-thvdx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-thvdx,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-9019,SelfLink:/api/v1/namespaces/deployment-9019/pods/nginx-deployment-55fb7cb77f-thvdx,UID:989a36d2-d0fd-482e-9abb-0a43f51833f5,ResourceVersion:13482,Generation:0,CreationTimestamp:2019-08-14 07:21:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.58/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f ab4c4c38-da63-4260-a22f-45c5bbb988bc 0xc0039f7960 0xc0039f7961}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdwlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdwlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-xdwlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0039f79d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0039f79f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:05 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.2,PodIP:,StartTime:2019-08-14 07:21:05 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 07:21:07.850: INFO: Pod "nginx-deployment-55fb7cb77f-zhgqt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-zhgqt,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-9019,SelfLink:/api/v1/namespaces/deployment-9019/pods/nginx-deployment-55fb7cb77f-zhgqt,UID:94543744-41c1-4b4b-a40f-65abfa43997a,ResourceVersion:13463,Generation:0,CreationTimestamp:2019-08-14 07:21:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f ab4c4c38-da63-4260-a22f-45c5bbb988bc 0xc0039f7ac0 0xc0039f7ac1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdwlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdwlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-xdwlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0039f7b30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0039f7b50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:06 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.2,PodIP:,StartTime:2019-08-14 07:21:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 07:21:07.851: INFO: Pod "nginx-deployment-7b8c6f4498-2hh8d" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-2hh8d,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-9019,SelfLink:/api/v1/namespaces/deployment-9019/pods/nginx-deployment-7b8c6f4498-2hh8d,UID:5b39674b-e5fb-4a34-b503-2d40b8bc53ef,ResourceVersion:13464,Generation:0,CreationTimestamp:2019-08-14 07:21:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 54e47f2c-f656-4b40-b640-90f6c98ed5ca 0xc0039f7c20 0xc0039f7c21}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdwlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdwlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xdwlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0039f7c80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0039f7ca0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:06 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.2,PodIP:,StartTime:2019-08-14 07:21:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 07:21:07.851: INFO: Pod "nginx-deployment-7b8c6f4498-5gmlr" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-5gmlr,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-9019,SelfLink:/api/v1/namespaces/deployment-9019/pods/nginx-deployment-7b8c6f4498-5gmlr,UID:5da9ecad-06c8-4004-ab6e-12967ac42852,ResourceVersion:13333,Generation:0,CreationTimestamp:2019-08-14 07:20:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.136/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 54e47f2c-f656-4b40-b640-90f6c98ed5ca 0xc0039f7d70 0xc0039f7d71}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdwlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdwlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xdwlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0039f7dd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0039f7df0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:20:59 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:01 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:01 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:20:59 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:100.96.1.136,StartTime:2019-08-14 07:20:59 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-14 07:21:01 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://33276c84297cb05f68a2166532cd06da2b5a62da7016b87da31e4273b07a5f84}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 07:21:07.851: INFO: Pod "nginx-deployment-7b8c6f4498-5pg87" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-5pg87,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-9019,SelfLink:/api/v1/namespaces/deployment-9019/pods/nginx-deployment-7b8c6f4498-5pg87,UID:7a7a7ec3-a49d-411f-b2d0-db5d895eb3c7,ResourceVersion:13462,Generation:0,CreationTimestamp:2019-08-14 07:21:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 54e47f2c-f656-4b40-b640-90f6c98ed5ca 0xc0039f7ec0 0xc0039f7ec1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdwlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdwlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xdwlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0039f7f20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0039f7f40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:06 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:,StartTime:2019-08-14 07:21:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 07:21:07.851: INFO: Pod "nginx-deployment-7b8c6f4498-7kzdh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-7kzdh,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-9019,SelfLink:/api/v1/namespaces/deployment-9019/pods/nginx-deployment-7b8c6f4498-7kzdh,UID:36f9b72f-d271-4fb2-8223-33d93175607d,ResourceVersion:13467,Generation:0,CreationTimestamp:2019-08-14 07:21:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 54e47f2c-f656-4b40-b640-90f6c98ed5ca 0xc00345c000 0xc00345c001}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdwlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdwlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xdwlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00345c060} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00345c080}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:06 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.2,PodIP:,StartTime:2019-08-14 07:21:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 07:21:07.852: INFO: Pod "nginx-deployment-7b8c6f4498-8479j" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-8479j,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-9019,SelfLink:/api/v1/namespaces/deployment-9019/pods/nginx-deployment-7b8c6f4498-8479j,UID:087af918-0f32-42ed-808d-3bb84c1fb7b5,ResourceVersion:13346,Generation:0,CreationTimestamp:2019-08-14 07:20:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.138/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 54e47f2c-f656-4b40-b640-90f6c98ed5ca 0xc00345c150 0xc00345c151}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdwlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdwlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xdwlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00345c1b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00345c1d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:20:59 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:02 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:02 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:20:59 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:100.96.1.138,StartTime:2019-08-14 07:20:59 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-14 07:21:01 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://0e85cf105214ffdfea5bfbf0949f417abedebb817026e981713b801dd8aaaa19}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 07:21:07.852: INFO: Pod "nginx-deployment-7b8c6f4498-86rdg" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-86rdg,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-9019,SelfLink:/api/v1/namespaces/deployment-9019/pods/nginx-deployment-7b8c6f4498-86rdg,UID:6aace0f4-5aa7-4513-b0f0-52ca9757471a,ResourceVersion:13347,Generation:0,CreationTimestamp:2019-08-14 07:20:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.141/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 54e47f2c-f656-4b40-b640-90f6c98ed5ca 0xc00345c2b0 0xc00345c2b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdwlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdwlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xdwlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00345c310} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00345c330}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:20:59 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:02 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:02 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:20:59 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:100.96.1.141,StartTime:2019-08-14 07:20:59 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-14 07:21:02 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://137fcd7d06d77b6364289297436ea50497d5a2231efbea09164ad7b8558bed92}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 07:21:07.852: INFO: Pod "nginx-deployment-7b8c6f4498-bzmdc" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-bzmdc,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-9019,SelfLink:/api/v1/namespaces/deployment-9019/pods/nginx-deployment-7b8c6f4498-bzmdc,UID:0ffa6b6b-d05d-40c4-b3b3-8e98c9f5dc59,ResourceVersion:13317,Generation:0,CreationTimestamp:2019-08-14 07:20:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.49/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 54e47f2c-f656-4b40-b640-90f6c98ed5ca 0xc00345c410 0xc00345c411}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdwlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdwlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xdwlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00345c470} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00345c490}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:20:59 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:00 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:20:59 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.2,PodIP:100.96.0.49,StartTime:2019-08-14 07:20:59 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-14 07:21:00 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://c161bd8cd145c4a9294564e49d35baf44dcaf3c359eebebced34f9c72cf85734}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 07:21:07.852: INFO: Pod "nginx-deployment-7b8c6f4498-dmvhk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-dmvhk,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-9019,SelfLink:/api/v1/namespaces/deployment-9019/pods/nginx-deployment-7b8c6f4498-dmvhk,UID:7b0b514e-270d-42ae-b261-05d48afed8d9,ResourceVersion:13473,Generation:0,CreationTimestamp:2019-08-14 07:21:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.55/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 54e47f2c-f656-4b40-b640-90f6c98ed5ca 0xc00345c570 0xc00345c571}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdwlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdwlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xdwlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00345c5e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00345c600}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:05 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.2,PodIP:,StartTime:2019-08-14 07:21:05 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 07:21:07.852: INFO: Pod "nginx-deployment-7b8c6f4498-gsgjd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-gsgjd,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-9019,SelfLink:/api/v1/namespaces/deployment-9019/pods/nginx-deployment-7b8c6f4498-gsgjd,UID:b94fa47a-8e76-403d-a200-52b9930c9840,ResourceVersion:13476,Generation:0,CreationTimestamp:2019-08-14 07:21:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.147/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 54e47f2c-f656-4b40-b640-90f6c98ed5ca 0xc00345c6d0 0xc00345c6d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdwlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdwlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xdwlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00345c730} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00345c750}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:05 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:,StartTime:2019-08-14 07:21:05 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 07:21:07.863: INFO: Pod "nginx-deployment-7b8c6f4498-hqmsr" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-hqmsr,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-9019,SelfLink:/api/v1/namespaces/deployment-9019/pods/nginx-deployment-7b8c6f4498-hqmsr,UID:25817f02-d5e8-4093-b6d8-22051600fb84,ResourceVersion:13320,Generation:0,CreationTimestamp:2019-08-14 07:20:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.51/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 54e47f2c-f656-4b40-b640-90f6c98ed5ca 0xc00345c820 0xc00345c821}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdwlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdwlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xdwlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00345c880} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00345c8a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:20:59 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:00 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:20:59 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.2,PodIP:100.96.0.51,StartTime:2019-08-14 07:20:59 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-14 07:21:00 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://700ef8cdf13efaa779673bc9c4031c2787e805b170d81d484cf44b8e1ba99ae8}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 07:21:07.864: INFO: Pod "nginx-deployment-7b8c6f4498-k7fr4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-k7fr4,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-9019,SelfLink:/api/v1/namespaces/deployment-9019/pods/nginx-deployment-7b8c6f4498-k7fr4,UID:57a30d77-ee09-4011-8a06-dcfc92ca807c,ResourceVersion:13475,Generation:0,CreationTimestamp:2019-08-14 07:21:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.146/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 54e47f2c-f656-4b40-b640-90f6c98ed5ca 0xc00345c980 0xc00345c981}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdwlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdwlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xdwlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00345c9e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00345ca00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:05 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:,StartTime:2019-08-14 07:21:05 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 07:21:07.864: INFO: Pod "nginx-deployment-7b8c6f4498-k96m2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-k96m2,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-9019,SelfLink:/api/v1/namespaces/deployment-9019/pods/nginx-deployment-7b8c6f4498-k96m2,UID:3d43a669-46bb-42cd-bab9-c300ccf8b681,ResourceVersion:13465,Generation:0,CreationTimestamp:2019-08-14 07:21:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 54e47f2c-f656-4b40-b640-90f6c98ed5ca 0xc00345cac0 0xc00345cac1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdwlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdwlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xdwlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00345cb20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00345cb40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:06 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:,StartTime:2019-08-14 07:21:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 07:21:07.864: INFO: Pod "nginx-deployment-7b8c6f4498-n9q4l" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-n9q4l,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-9019,SelfLink:/api/v1/namespaces/deployment-9019/pods/nginx-deployment-7b8c6f4498-n9q4l,UID:5e13bac3-031c-4668-9370-e553661b3c53,ResourceVersion:13343,Generation:0,CreationTimestamp:2019-08-14 07:20:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.142/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 54e47f2c-f656-4b40-b640-90f6c98ed5ca 0xc00345cc10 0xc00345cc11}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdwlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdwlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xdwlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00345cc70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00345cc90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:20:59 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:02 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:02 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:20:59 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:100.96.1.142,StartTime:2019-08-14 07:20:59 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-14 07:21:02 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://719997923f13e0e9db0e01e4b17e766c7c9ede492c9a99346e9bca0b29658a86}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 07:21:07.865: INFO: Pod "nginx-deployment-7b8c6f4498-qgsnh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-qgsnh,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-9019,SelfLink:/api/v1/namespaces/deployment-9019/pods/nginx-deployment-7b8c6f4498-qgsnh,UID:ffd1c779-f222-4635-93b4-22fa775731a5,ResourceVersion:13466,Generation:0,CreationTimestamp:2019-08-14 07:21:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 54e47f2c-f656-4b40-b640-90f6c98ed5ca 0xc00345cd60 0xc00345cd61}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdwlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdwlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xdwlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00345cdc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00345cde0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:06 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.2,PodIP:,StartTime:2019-08-14 07:21:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 07:21:07.865: INFO: Pod "nginx-deployment-7b8c6f4498-qj55w" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-qj55w,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-9019,SelfLink:/api/v1/namespaces/deployment-9019/pods/nginx-deployment-7b8c6f4498-qj55w,UID:82ddb402-0c7f-4291-835d-f35dba096cf1,ResourceVersion:13436,Generation:0,CreationTimestamp:2019-08-14 07:21:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 54e47f2c-f656-4b40-b640-90f6c98ed5ca 0xc00345cea0 0xc00345cea1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdwlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdwlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xdwlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00345cf00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00345cf20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:05 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:,StartTime:2019-08-14 07:21:05 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 07:21:07.865: INFO: Pod "nginx-deployment-7b8c6f4498-rrphx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-rrphx,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-9019,SelfLink:/api/v1/namespaces/deployment-9019/pods/nginx-deployment-7b8c6f4498-rrphx,UID:a8f93c98-5727-4e9d-9923-7e6a07eb6698,ResourceVersion:13481,Generation:0,CreationTimestamp:2019-08-14 07:21:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.148/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 54e47f2c-f656-4b40-b640-90f6c98ed5ca 0xc00345cff0 0xc00345cff1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdwlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdwlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xdwlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00345d050} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00345d070}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:05 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:,StartTime:2019-08-14 07:21:05 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 07:21:07.865: INFO: Pod "nginx-deployment-7b8c6f4498-tt227" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-tt227,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-9019,SelfLink:/api/v1/namespaces/deployment-9019/pods/nginx-deployment-7b8c6f4498-tt227,UID:76c67833-b4e7-4522-8361-b47e3d469a05,ResourceVersion:13337,Generation:0,CreationTimestamp:2019-08-14 07:20:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.140/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 54e47f2c-f656-4b40-b640-90f6c98ed5ca 0xc00345d140 0xc00345d141}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdwlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdwlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xdwlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00345d1a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00345d1c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:20:59 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:02 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:02 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:20:59 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:100.96.1.140,StartTime:2019-08-14 07:20:59 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-14 07:21:02 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://e16e5d017df43a909b036388aab1b81b9d41b47b5871ab2accc50e7e63dcfba4}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 07:21:07.865: INFO: Pod "nginx-deployment-7b8c6f4498-w4rm9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-w4rm9,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-9019,SelfLink:/api/v1/namespaces/deployment-9019/pods/nginx-deployment-7b8c6f4498-w4rm9,UID:597ced76-b9ea-4792-8116-4c37286ae527,ResourceVersion:13483,Generation:0,CreationTimestamp:2019-08-14 07:21:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.59/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 54e47f2c-f656-4b40-b640-90f6c98ed5ca 0xc00345d2a0 0xc00345d2a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdwlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdwlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xdwlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00345d300} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00345d320}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:05 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.2,PodIP:,StartTime:2019-08-14 07:21:05 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 07:21:07.866: INFO: Pod "nginx-deployment-7b8c6f4498-x77lw" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-x77lw,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-9019,SelfLink:/api/v1/namespaces/deployment-9019/pods/nginx-deployment-7b8c6f4498-x77lw,UID:01060caf-84a4-4b3e-8066-0f328a52c76e,ResourceVersion:13314,Generation:0,CreationTimestamp:2019-08-14 07:20:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.50/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 54e47f2c-f656-4b40-b640-90f6c98ed5ca 0xc00345d3f0 0xc00345d3f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdwlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdwlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xdwlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00345d450} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00345d470}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:20:59 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:00 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:20:59 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.2,PodIP:100.96.0.50,StartTime:2019-08-14 07:20:59 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-14 07:21:00 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://d7f5c603509090b8006bf78b093bdcb26d9e105d1aa82aa2700414ee66c2d4d6}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 14 07:21:07.866: INFO: Pod "nginx-deployment-7b8c6f4498-z2g85" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-z2g85,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-9019,SelfLink:/api/v1/namespaces/deployment-9019/pods/nginx-deployment-7b8c6f4498-z2g85,UID:1e3779be-e2c9-4de7-b824-79e2b86f8f47,ResourceVersion:13479,Generation:0,CreationTimestamp:2019-08-14 07:21:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.57/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 54e47f2c-f656-4b40-b640-90f6c98ed5ca 0xc00345d550 0xc00345d551}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xdwlg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xdwlg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-xdwlg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00345d5b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00345d5d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:21:05 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.2,PodIP:,StartTime:2019-08-14 07:21:05 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:21:07.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9019" for this suite.
Aug 14 07:21:15.910: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:21:16.304: INFO: namespace deployment-9019 deletion completed in 8.427081021s
•SSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:21:16.304: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-185
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-185/configmap-test-a963f814-c00d-4518-b0fd-a0b600c5843a
STEP: Creating a pod to test consume configMaps
Aug 14 07:21:16.600: INFO: Waiting up to 5m0s for pod "pod-configmaps-ac2c26ee-d002-49d8-8dc6-01febd6efcf7" in namespace "configmap-185" to be "success or failure"
Aug 14 07:21:16.611: INFO: Pod "pod-configmaps-ac2c26ee-d002-49d8-8dc6-01febd6efcf7": Phase="Pending", Reason="", readiness=false. Elapsed: 10.143281ms
Aug 14 07:21:18.625: INFO: Pod "pod-configmaps-ac2c26ee-d002-49d8-8dc6-01febd6efcf7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024295254s
STEP: Saw pod success
Aug 14 07:21:18.625: INFO: Pod "pod-configmaps-ac2c26ee-d002-49d8-8dc6-01febd6efcf7" satisfied condition "success or failure"
Aug 14 07:21:18.636: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod pod-configmaps-ac2c26ee-d002-49d8-8dc6-01febd6efcf7 container env-test: <nil>
STEP: delete the pod
Aug 14 07:21:18.669: INFO: Waiting for pod pod-configmaps-ac2c26ee-d002-49d8-8dc6-01febd6efcf7 to disappear
Aug 14 07:21:18.679: INFO: Pod pod-configmaps-ac2c26ee-d002-49d8-8dc6-01febd6efcf7 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:21:18.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-185" for this suite.
Aug 14 07:21:24.731: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:21:25.127: INFO: namespace configmap-185 deletion completed in 6.429114562s
•SSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:21:25.127: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-5349
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:21:29.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5349" for this suite.
Aug 14 07:21:35.599: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:21:36.023: INFO: namespace kubelet-test-5349 deletion completed in 6.458643988s
•SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:21:36.024: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-6002
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Aug 14 07:21:39.048: INFO: Successfully updated pod "pod-update-fecceb10-c28f-4572-98f4-81abba2fb8fe"
STEP: verifying the updated pod is in kubernetes
Aug 14 07:21:39.069: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:21:39.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6002" for this suite.
Aug 14 07:22:01.124: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:22:01.550: INFO: namespace pods-6002 deletion completed in 22.459274261s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:22:01.551: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-207
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1686
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 14 07:22:01.870: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-207'
Aug 14 07:22:02.041: INFO: stderr: ""
Aug 14 07:22:02.041: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1691
Aug 14 07:22:02.054: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete pods e2e-test-nginx-pod --namespace=kubectl-207'
Aug 14 07:22:16.373: INFO: stderr: ""
Aug 14 07:22:16.373: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:22:16.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-207" for this suite.
Aug 14 07:22:22.426: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:22:22.812: INFO: namespace kubectl-207 deletion completed in 6.418692206s
•SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:22:22.813: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1921
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 14 07:22:23.079: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config version'
Aug 14 07:22:23.196: INFO: stderr: ""
Aug 14 07:22:23.196: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.2\", GitCommit:\"f6278300bebbb750328ac16ee6dd3aa7d3549568\", GitTreeState:\"clean\", BuildDate:\"2019-08-05T09:23:26Z\", GoVersion:\"go1.12.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.2\", GitCommit:\"f6278300bebbb750328ac16ee6dd3aa7d3549568\", GitTreeState:\"clean\", BuildDate:\"2019-08-05T09:15:22Z\", GoVersion:\"go1.12.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:22:23.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1921" for this suite.
Aug 14 07:22:29.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:22:29.639: INFO: namespace kubectl-1921 deletion completed in 6.430948037s
•S
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:22:29.639: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-2773
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Aug 14 07:22:32.036: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:22:32.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-2773" for this suite.
Aug 14 07:22:38.115: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:22:38.516: INFO: namespace container-runtime-2773 deletion completed in 6.434543051s
•SSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:22:38.516: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3510
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-5562932d-1d4f-4689-8c99-82aad323ccf3
STEP: Creating a pod to test consume secrets
Aug 14 07:22:38.900: INFO: Waiting up to 5m0s for pod "pod-secrets-cb9e91c0-f9b7-40a6-9809-98cea131da0e" in namespace "secrets-3510" to be "success or failure"
Aug 14 07:22:38.910: INFO: Pod "pod-secrets-cb9e91c0-f9b7-40a6-9809-98cea131da0e": Phase="Pending", Reason="", readiness=false. Elapsed: 10.123116ms
Aug 14 07:22:40.921: INFO: Pod "pod-secrets-cb9e91c0-f9b7-40a6-9809-98cea131da0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021576282s
STEP: Saw pod success
Aug 14 07:22:40.921: INFO: Pod "pod-secrets-cb9e91c0-f9b7-40a6-9809-98cea131da0e" satisfied condition "success or failure"
Aug 14 07:22:40.932: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod pod-secrets-cb9e91c0-f9b7-40a6-9809-98cea131da0e container secret-env-test: <nil>
STEP: delete the pod
Aug 14 07:22:40.966: INFO: Waiting for pod pod-secrets-cb9e91c0-f9b7-40a6-9809-98cea131da0e to disappear
Aug 14 07:22:40.976: INFO: Pod pod-secrets-cb9e91c0-f9b7-40a6-9809-98cea131da0e no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:22:40.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3510" for this suite.
Aug 14 07:22:47.029: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:22:47.487: INFO: namespace secrets-3510 deletion completed in 6.491130265s
•SSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:22:47.487: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5945
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-a25030b5-a524-486f-b645-48a0269185b6
STEP: Creating configMap with name cm-test-opt-upd-067cfc26-f3b5-4bb2-8921-5c05bcbeaef9
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-a25030b5-a524-486f-b645-48a0269185b6
STEP: Updating configmap cm-test-opt-upd-067cfc26-f3b5-4bb2-8921-5c05bcbeaef9
STEP: Creating configMap with name cm-test-opt-create-7b1428c2-7176-4ca4-8642-214eb2b84349
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:22:54.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5945" for this suite.
Aug 14 07:23:16.464: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:23:16.859: INFO: namespace projected-5945 deletion completed in 22.427894896s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:23:16.859: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-665
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1558
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 14 07:23:17.170: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/apps.v1 --namespace=kubectl-665'
Aug 14 07:23:17.307: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 14 07:23:17.307: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
Aug 14 07:23:19.328: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete deployment e2e-test-nginx-deployment --namespace=kubectl-665'
Aug 14 07:23:19.475: INFO: stderr: ""
Aug 14 07:23:19.475: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:23:19.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-665" for this suite.
Aug 14 07:23:25.540: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:23:26.228: INFO: namespace kubectl-665 deletion completed in 6.73426447s
•SSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:23:26.229: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-873
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 14 07:23:26.638: INFO: Create a RollingUpdate DaemonSet
Aug 14 07:23:26.649: INFO: Check that daemon pods launch on every node of the cluster
Aug 14 07:23:26.669: INFO: Number of nodes with available pods: 0
Aug 14 07:23:26.669: INFO: Node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw is running more than one daemon pod
Aug 14 07:23:27.700: INFO: Number of nodes with available pods: 0
Aug 14 07:23:27.700: INFO: Node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw is running more than one daemon pod
Aug 14 07:23:28.701: INFO: Number of nodes with available pods: 2
Aug 14 07:23:28.701: INFO: Number of running nodes: 2, number of available pods: 2
Aug 14 07:23:28.702: INFO: Update the DaemonSet to trigger a rollout
Aug 14 07:23:28.723: INFO: Updating DaemonSet daemon-set
Aug 14 07:23:35.776: INFO: Roll back the DaemonSet before rollout is complete
Aug 14 07:23:35.797: INFO: Updating DaemonSet daemon-set
Aug 14 07:23:35.797: INFO: Make sure DaemonSet rollback is complete
Aug 14 07:23:35.808: INFO: Wrong image for pod: daemon-set-wrmws. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Aug 14 07:23:35.808: INFO: Pod daemon-set-wrmws is not available
Aug 14 07:23:36.830: INFO: Wrong image for pod: daemon-set-wrmws. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Aug 14 07:23:36.830: INFO: Pod daemon-set-wrmws is not available
Aug 14 07:23:37.830: INFO: Wrong image for pod: daemon-set-wrmws. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Aug 14 07:23:37.830: INFO: Pod daemon-set-wrmws is not available
Aug 14 07:23:38.830: INFO: Pod daemon-set-vjk9g is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-873, will wait for the garbage collector to delete the pods
Aug 14 07:23:38.947: INFO: Deleting DaemonSet.extensions daemon-set took: 13.634025ms
Aug 14 07:23:39.347: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.453018ms
Aug 14 07:25:16.458: INFO: Number of nodes with available pods: 0
Aug 14 07:25:16.458: INFO: Number of running nodes: 0, number of available pods: 0
Aug 14 07:25:16.469: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-873/daemonsets","resourceVersion":"14523"},"items":null}

Aug 14 07:25:16.479: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-873/pods","resourceVersion":"14523"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:25:16.521: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-873" for this suite.
Aug 14 07:25:22.651: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:25:23.046: INFO: namespace daemonsets-873 deletion completed in 6.512656034s
•
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:25:23.046: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-7445
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Aug 14 07:25:25.984: INFO: Successfully updated pod "pod-update-activedeadlineseconds-8d48e62a-ba58-433f-a3bf-d8fcefff6d30"
Aug 14 07:25:25.984: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-8d48e62a-ba58-433f-a3bf-d8fcefff6d30" in namespace "pods-7445" to be "terminated due to deadline exceeded"
Aug 14 07:25:25.994: INFO: Pod "pod-update-activedeadlineseconds-8d48e62a-ba58-433f-a3bf-d8fcefff6d30": Phase="Running", Reason="", readiness=true. Elapsed: 10.317992ms
Aug 14 07:25:28.006: INFO: Pod "pod-update-activedeadlineseconds-8d48e62a-ba58-433f-a3bf-d8fcefff6d30": Phase="Running", Reason="", readiness=true. Elapsed: 2.021574288s
Aug 14 07:25:30.017: INFO: Pod "pod-update-activedeadlineseconds-8d48e62a-ba58-433f-a3bf-d8fcefff6d30": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.033325393s
Aug 14 07:25:30.017: INFO: Pod "pod-update-activedeadlineseconds-8d48e62a-ba58-433f-a3bf-d8fcefff6d30" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:25:30.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7445" for this suite.
Aug 14 07:25:36.071: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:25:36.463: INFO: namespace pods-7445 deletion completed in 6.426062713s
•
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:25:36.463: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-1775
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating replication controller svc-latency-rc in namespace svc-latency-1775
I0814 07:25:36.696440    4167 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: svc-latency-1775, replica count: 1
I0814 07:25:37.747180    4167 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0814 07:25:38.747496    4167 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 14 07:25:38.864: INFO: Created: latency-svc-lbbwf
Aug 14 07:25:38.868: INFO: Got endpoints: latency-svc-lbbwf [20.409075ms]
Aug 14 07:25:38.885: INFO: Created: latency-svc-jmp57
Aug 14 07:25:38.889: INFO: Got endpoints: latency-svc-jmp57 [20.740516ms]
Aug 14 07:25:38.891: INFO: Created: latency-svc-65f46
Aug 14 07:25:38.894: INFO: Got endpoints: latency-svc-65f46 [25.796981ms]
Aug 14 07:25:38.899: INFO: Created: latency-svc-jnrl7
Aug 14 07:25:38.904: INFO: Created: latency-svc-j4vmd
Aug 14 07:25:38.904: INFO: Got endpoints: latency-svc-jnrl7 [35.663202ms]
Aug 14 07:25:38.908: INFO: Got endpoints: latency-svc-j4vmd [39.876372ms]
Aug 14 07:25:38.908: INFO: Created: latency-svc-d688g
Aug 14 07:25:38.913: INFO: Got endpoints: latency-svc-d688g [44.561418ms]
Aug 14 07:25:38.913: INFO: Created: latency-svc-89hww
Aug 14 07:25:38.915: INFO: Got endpoints: latency-svc-89hww [46.51ms]
Aug 14 07:25:38.918: INFO: Created: latency-svc-dwmpx
Aug 14 07:25:38.920: INFO: Got endpoints: latency-svc-dwmpx [51.927682ms]
Aug 14 07:25:38.924: INFO: Created: latency-svc-9f7kw
Aug 14 07:25:38.928: INFO: Created: latency-svc-9hqww
Aug 14 07:25:38.933: INFO: Created: latency-svc-jkvcr
Aug 14 07:25:38.939: INFO: Created: latency-svc-hfzsb
Aug 14 07:25:38.939: INFO: Got endpoints: latency-svc-9f7kw [70.628538ms]
Aug 14 07:25:38.939: INFO: Got endpoints: latency-svc-9hqww [71.209132ms]
Aug 14 07:25:38.940: INFO: Got endpoints: latency-svc-jkvcr [71.425414ms]
Aug 14 07:25:38.942: INFO: Got endpoints: latency-svc-hfzsb [73.411126ms]
Aug 14 07:25:38.944: INFO: Created: latency-svc-vs467
Aug 14 07:25:38.949: INFO: Created: latency-svc-bc884
Aug 14 07:25:38.954: INFO: Created: latency-svc-lqtkm
Aug 14 07:25:38.959: INFO: Created: latency-svc-khkvd
Aug 14 07:25:38.964: INFO: Created: latency-svc-cl8x5
Aug 14 07:25:38.968: INFO: Created: latency-svc-7ghsv
Aug 14 07:25:38.973: INFO: Created: latency-svc-dsw6w
Aug 14 07:25:38.982: INFO: Created: latency-svc-jvxpr
Aug 14 07:25:38.998: INFO: Created: latency-svc-2rg5h
Aug 14 07:25:39.002: INFO: Created: latency-svc-qx78m
Aug 14 07:25:39.007: INFO: Created: latency-svc-4fqk8
Aug 14 07:25:39.011: INFO: Created: latency-svc-x5xrk
Aug 14 07:25:39.016: INFO: Created: latency-svc-qvb56
Aug 14 07:25:39.020: INFO: Created: latency-svc-6x62g
Aug 14 07:25:39.025: INFO: Created: latency-svc-k7mpx
Aug 14 07:25:39.040: INFO: Got endpoints: latency-svc-bc884 [171.474416ms]
Aug 14 07:25:39.040: INFO: Got endpoints: latency-svc-cl8x5 [151.69223ms]
Aug 14 07:25:39.041: INFO: Got endpoints: latency-svc-khkvd [172.376631ms]
Aug 14 07:25:39.041: INFO: Got endpoints: latency-svc-lqtkm [172.786468ms]
Aug 14 07:25:39.041: INFO: Got endpoints: latency-svc-vs467 [172.777239ms]
Aug 14 07:25:39.042: INFO: Got endpoints: latency-svc-7ghsv [148.066905ms]
Aug 14 07:25:39.043: INFO: Got endpoints: latency-svc-jvxpr [134.604498ms]
Aug 14 07:25:39.045: INFO: Got endpoints: latency-svc-4fqk8 [125.091491ms]
Aug 14 07:25:39.045: INFO: Got endpoints: latency-svc-x5xrk [106.230862ms]
Aug 14 07:25:39.045: INFO: Got endpoints: latency-svc-dsw6w [141.048145ms]
Aug 14 07:25:39.045: INFO: Got endpoints: latency-svc-qx78m [130.383929ms]
Aug 14 07:25:39.045: INFO: Got endpoints: latency-svc-2rg5h [132.69624ms]
Aug 14 07:25:39.047: INFO: Got endpoints: latency-svc-qvb56 [107.728054ms]
Aug 14 07:25:39.048: INFO: Got endpoints: latency-svc-6x62g [108.041763ms]
Aug 14 07:25:39.048: INFO: Got endpoints: latency-svc-k7mpx [106.384505ms]
Aug 14 07:25:39.055: INFO: Created: latency-svc-lf42l
Aug 14 07:25:39.059: INFO: Got endpoints: latency-svc-lf42l [19.635631ms]
Aug 14 07:25:39.060: INFO: Created: latency-svc-b9rfb
Aug 14 07:25:39.064: INFO: Created: latency-svc-9tcwk
Aug 14 07:25:39.064: INFO: Got endpoints: latency-svc-b9rfb [23.914283ms]
Aug 14 07:25:39.069: INFO: Got endpoints: latency-svc-9tcwk [28.047622ms]
Aug 14 07:25:39.069: INFO: Created: latency-svc-cfh8h
Aug 14 07:25:39.074: INFO: Created: latency-svc-g2c8c
Aug 14 07:25:39.079: INFO: Created: latency-svc-l8scr
Aug 14 07:25:39.084: INFO: Created: latency-svc-n9trv
Aug 14 07:25:39.089: INFO: Created: latency-svc-d67dg
Aug 14 07:25:39.095: INFO: Created: latency-svc-tg6kx
Aug 14 07:25:39.108: INFO: Created: latency-svc-8jgsw
Aug 14 07:25:39.108: INFO: Got endpoints: latency-svc-l8scr [66.069647ms]
Aug 14 07:25:39.108: INFO: Got endpoints: latency-svc-g2c8c [66.928526ms]
Aug 14 07:25:39.108: INFO: Got endpoints: latency-svc-cfh8h [67.041854ms]
Aug 14 07:25:39.140: INFO: Got endpoints: latency-svc-n9trv [97.294564ms]
Aug 14 07:25:39.142: INFO: Got endpoints: latency-svc-d67dg [96.444792ms]
Aug 14 07:25:39.144: INFO: Created: latency-svc-86nvc
Aug 14 07:25:39.151: INFO: Created: latency-svc-vc8l9
Aug 14 07:25:39.156: INFO: Created: latency-svc-jc9q8
Aug 14 07:25:39.161: INFO: Created: latency-svc-cszjt
Aug 14 07:25:39.166: INFO: Created: latency-svc-wrbtl
Aug 14 07:25:39.167: INFO: Got endpoints: latency-svc-tg6kx [121.388098ms]
Aug 14 07:25:39.171: INFO: Created: latency-svc-s4gw9
Aug 14 07:25:39.177: INFO: Created: latency-svc-5zmdz
Aug 14 07:25:39.183: INFO: Created: latency-svc-fm4dz
Aug 14 07:25:39.188: INFO: Created: latency-svc-7hs2v
Aug 14 07:25:39.194: INFO: Created: latency-svc-2rsds
Aug 14 07:25:39.199: INFO: Created: latency-svc-lmzjj
Aug 14 07:25:39.205: INFO: Created: latency-svc-r9jtl
Aug 14 07:25:39.219: INFO: Got endpoints: latency-svc-8jgsw [173.705382ms]
Aug 14 07:25:39.221: INFO: Created: latency-svc-lw777
Aug 14 07:25:39.226: INFO: Created: latency-svc-vpp5x
Aug 14 07:25:39.239: INFO: Created: latency-svc-9qr9r
Aug 14 07:25:39.268: INFO: Got endpoints: latency-svc-86nvc [222.289519ms]
Aug 14 07:25:39.285: INFO: Created: latency-svc-7lsfn
Aug 14 07:25:39.318: INFO: Got endpoints: latency-svc-vc8l9 [272.401635ms]
Aug 14 07:25:39.336: INFO: Created: latency-svc-s68qz
Aug 14 07:25:39.368: INFO: Got endpoints: latency-svc-jc9q8 [319.752824ms]
Aug 14 07:25:39.384: INFO: Created: latency-svc-2rhhq
Aug 14 07:25:39.418: INFO: Got endpoints: latency-svc-cszjt [369.902564ms]
Aug 14 07:25:39.434: INFO: Created: latency-svc-xl8rm
Aug 14 07:25:39.468: INFO: Got endpoints: latency-svc-wrbtl [420.747162ms]
Aug 14 07:25:39.486: INFO: Created: latency-svc-s8bbd
Aug 14 07:25:39.517: INFO: Got endpoints: latency-svc-s4gw9 [457.657777ms]
Aug 14 07:25:39.535: INFO: Created: latency-svc-w4v5w
Aug 14 07:25:39.568: INFO: Got endpoints: latency-svc-5zmdz [503.544361ms]
Aug 14 07:25:39.585: INFO: Created: latency-svc-4hrvb
Aug 14 07:25:39.618: INFO: Got endpoints: latency-svc-fm4dz [549.302218ms]
Aug 14 07:25:39.638: INFO: Created: latency-svc-w4lw4
Aug 14 07:25:39.668: INFO: Got endpoints: latency-svc-7hs2v [559.776094ms]
Aug 14 07:25:39.685: INFO: Created: latency-svc-j7xp4
Aug 14 07:25:39.718: INFO: Got endpoints: latency-svc-2rsds [609.959923ms]
Aug 14 07:25:39.743: INFO: Created: latency-svc-4ccnd
Aug 14 07:25:39.768: INFO: Got endpoints: latency-svc-lmzjj [659.847104ms]
Aug 14 07:25:39.785: INFO: Created: latency-svc-pz9vq
Aug 14 07:25:39.818: INFO: Got endpoints: latency-svc-r9jtl [677.88821ms]
Aug 14 07:25:39.835: INFO: Created: latency-svc-ncqs2
Aug 14 07:25:39.868: INFO: Got endpoints: latency-svc-lw777 [726.262473ms]
Aug 14 07:25:39.885: INFO: Created: latency-svc-2rc57
Aug 14 07:25:39.918: INFO: Got endpoints: latency-svc-vpp5x [751.392104ms]
Aug 14 07:25:39.935: INFO: Created: latency-svc-c7jps
Aug 14 07:25:39.968: INFO: Got endpoints: latency-svc-9qr9r [748.772706ms]
Aug 14 07:25:39.985: INFO: Created: latency-svc-f5bsb
Aug 14 07:25:40.018: INFO: Got endpoints: latency-svc-7lsfn [750.32829ms]
Aug 14 07:25:40.036: INFO: Created: latency-svc-jsh9v
Aug 14 07:25:40.068: INFO: Got endpoints: latency-svc-s68qz [750.094961ms]
Aug 14 07:25:40.085: INFO: Created: latency-svc-d7nm9
Aug 14 07:25:40.117: INFO: Got endpoints: latency-svc-2rhhq [749.457659ms]
Aug 14 07:25:40.135: INFO: Created: latency-svc-jxpgx
Aug 14 07:25:40.168: INFO: Got endpoints: latency-svc-xl8rm [750.108653ms]
Aug 14 07:25:40.185: INFO: Created: latency-svc-5wksb
Aug 14 07:25:40.218: INFO: Got endpoints: latency-svc-s8bbd [749.632871ms]
Aug 14 07:25:40.234: INFO: Created: latency-svc-9n2fm
Aug 14 07:25:40.268: INFO: Got endpoints: latency-svc-w4v5w [751.11288ms]
Aug 14 07:25:40.286: INFO: Created: latency-svc-nt2bj
Aug 14 07:25:40.318: INFO: Got endpoints: latency-svc-4hrvb [749.666096ms]
Aug 14 07:25:40.334: INFO: Created: latency-svc-6d5fq
Aug 14 07:25:40.370: INFO: Got endpoints: latency-svc-w4lw4 [751.876035ms]
Aug 14 07:25:40.388: INFO: Created: latency-svc-5xz2n
Aug 14 07:25:40.418: INFO: Got endpoints: latency-svc-j7xp4 [749.868756ms]
Aug 14 07:25:40.434: INFO: Created: latency-svc-f7flw
Aug 14 07:25:40.468: INFO: Got endpoints: latency-svc-4ccnd [749.646063ms]
Aug 14 07:25:40.484: INFO: Created: latency-svc-cvvtd
Aug 14 07:25:40.518: INFO: Got endpoints: latency-svc-pz9vq [750.352351ms]
Aug 14 07:25:40.534: INFO: Created: latency-svc-vxrpn
Aug 14 07:25:40.568: INFO: Got endpoints: latency-svc-ncqs2 [750.231116ms]
Aug 14 07:25:40.586: INFO: Created: latency-svc-mrj7g
Aug 14 07:25:40.618: INFO: Got endpoints: latency-svc-2rc57 [750.010065ms]
Aug 14 07:25:40.635: INFO: Created: latency-svc-d7c5d
Aug 14 07:25:40.668: INFO: Got endpoints: latency-svc-c7jps [749.429219ms]
Aug 14 07:25:40.689: INFO: Created: latency-svc-nl5hs
Aug 14 07:25:40.718: INFO: Got endpoints: latency-svc-f5bsb [749.780707ms]
Aug 14 07:25:40.736: INFO: Created: latency-svc-h5xhd
Aug 14 07:25:40.768: INFO: Got endpoints: latency-svc-jsh9v [749.572033ms]
Aug 14 07:25:40.789: INFO: Created: latency-svc-clkv4
Aug 14 07:25:40.818: INFO: Got endpoints: latency-svc-d7nm9 [749.734239ms]
Aug 14 07:25:40.835: INFO: Created: latency-svc-p72kg
Aug 14 07:25:40.868: INFO: Got endpoints: latency-svc-jxpgx [750.512995ms]
Aug 14 07:25:40.885: INFO: Created: latency-svc-7fzlj
Aug 14 07:25:40.918: INFO: Got endpoints: latency-svc-5wksb [749.877128ms]
Aug 14 07:25:40.936: INFO: Created: latency-svc-xpxrh
Aug 14 07:25:40.968: INFO: Got endpoints: latency-svc-9n2fm [750.351634ms]
Aug 14 07:25:40.985: INFO: Created: latency-svc-vfxkw
Aug 14 07:25:41.018: INFO: Got endpoints: latency-svc-nt2bj [749.445725ms]
Aug 14 07:25:41.034: INFO: Created: latency-svc-dtz4s
Aug 14 07:25:41.068: INFO: Got endpoints: latency-svc-6d5fq [749.897876ms]
Aug 14 07:25:41.085: INFO: Created: latency-svc-5whcr
Aug 14 07:25:41.119: INFO: Got endpoints: latency-svc-5xz2n [748.470643ms]
Aug 14 07:25:41.135: INFO: Created: latency-svc-hs8pm
Aug 14 07:25:41.168: INFO: Got endpoints: latency-svc-f7flw [750.039598ms]
Aug 14 07:25:41.207: INFO: Created: latency-svc-cv9pl
Aug 14 07:25:41.217: INFO: Got endpoints: latency-svc-cvvtd [749.548083ms]
Aug 14 07:25:41.234: INFO: Created: latency-svc-88md9
Aug 14 07:25:41.268: INFO: Got endpoints: latency-svc-vxrpn [749.744577ms]
Aug 14 07:25:41.286: INFO: Created: latency-svc-hjzb9
Aug 14 07:25:41.318: INFO: Got endpoints: latency-svc-mrj7g [749.534356ms]
Aug 14 07:25:41.334: INFO: Created: latency-svc-c4tl6
Aug 14 07:25:41.368: INFO: Got endpoints: latency-svc-d7c5d [749.549702ms]
Aug 14 07:25:41.385: INFO: Created: latency-svc-8jflb
Aug 14 07:25:41.418: INFO: Got endpoints: latency-svc-nl5hs [750.152603ms]
Aug 14 07:25:41.435: INFO: Created: latency-svc-hdhss
Aug 14 07:25:41.468: INFO: Got endpoints: latency-svc-h5xhd [749.68857ms]
Aug 14 07:25:41.484: INFO: Created: latency-svc-c5hvv
Aug 14 07:25:41.521: INFO: Got endpoints: latency-svc-clkv4 [753.544191ms]
Aug 14 07:25:41.540: INFO: Created: latency-svc-5j8fc
Aug 14 07:25:41.568: INFO: Got endpoints: latency-svc-p72kg [750.082798ms]
Aug 14 07:25:41.587: INFO: Created: latency-svc-2lmqq
Aug 14 07:25:41.618: INFO: Got endpoints: latency-svc-7fzlj [749.711404ms]
Aug 14 07:25:41.635: INFO: Created: latency-svc-rw9cg
Aug 14 07:25:41.668: INFO: Got endpoints: latency-svc-xpxrh [750.143674ms]
Aug 14 07:25:41.684: INFO: Created: latency-svc-v6svc
Aug 14 07:25:41.718: INFO: Got endpoints: latency-svc-vfxkw [750.320939ms]
Aug 14 07:25:41.739: INFO: Created: latency-svc-45tln
Aug 14 07:25:41.768: INFO: Got endpoints: latency-svc-dtz4s [749.885795ms]
Aug 14 07:25:41.785: INFO: Created: latency-svc-t96rm
Aug 14 07:25:41.818: INFO: Got endpoints: latency-svc-5whcr [750.100588ms]
Aug 14 07:25:42.038: INFO: Created: latency-svc-kcx7p
Aug 14 07:25:42.038: INFO: Got endpoints: latency-svc-hs8pm [919.366226ms]
Aug 14 07:25:42.038: INFO: Got endpoints: latency-svc-cv9pl [870.174188ms]
Aug 14 07:25:42.040: INFO: Got endpoints: latency-svc-88md9 [822.566368ms]
Aug 14 07:25:42.044: INFO: Got endpoints: latency-svc-hjzb9 [775.313785ms]
Aug 14 07:25:42.057: INFO: Created: latency-svc-m9qpk
Aug 14 07:25:42.092: INFO: Got endpoints: latency-svc-c4tl6 [773.72357ms]
Aug 14 07:25:42.144: INFO: Got endpoints: latency-svc-8jflb [775.965191ms]
Aug 14 07:25:42.144: INFO: Created: latency-svc-9ckcz
Aug 14 07:25:42.155: INFO: Created: latency-svc-vr5pd
Aug 14 07:25:42.160: INFO: Created: latency-svc-dpwqv
Aug 14 07:25:42.168: INFO: Got endpoints: latency-svc-hdhss [750.250709ms]
Aug 14 07:25:42.169: INFO: Created: latency-svc-rnpjd
Aug 14 07:25:42.173: INFO: Created: latency-svc-zcb6w
Aug 14 07:25:42.185: INFO: Created: latency-svc-pc4xg
Aug 14 07:25:42.218: INFO: Got endpoints: latency-svc-c5hvv [749.905652ms]
Aug 14 07:25:42.233: INFO: Created: latency-svc-gs7qd
Aug 14 07:25:42.268: INFO: Got endpoints: latency-svc-5j8fc [746.343385ms]
Aug 14 07:25:42.284: INFO: Created: latency-svc-vvfnj
Aug 14 07:25:42.318: INFO: Got endpoints: latency-svc-2lmqq [749.682109ms]
Aug 14 07:25:42.334: INFO: Created: latency-svc-r2s7d
Aug 14 07:25:42.368: INFO: Got endpoints: latency-svc-rw9cg [750.013076ms]
Aug 14 07:25:42.385: INFO: Created: latency-svc-gbdlp
Aug 14 07:25:42.418: INFO: Got endpoints: latency-svc-v6svc [749.707897ms]
Aug 14 07:25:42.434: INFO: Created: latency-svc-pc2s4
Aug 14 07:25:42.468: INFO: Got endpoints: latency-svc-45tln [749.517769ms]
Aug 14 07:25:42.485: INFO: Created: latency-svc-trvgm
Aug 14 07:25:42.518: INFO: Got endpoints: latency-svc-t96rm [750.010478ms]
Aug 14 07:25:42.534: INFO: Created: latency-svc-h6rw2
Aug 14 07:25:42.568: INFO: Got endpoints: latency-svc-kcx7p [750.15753ms]
Aug 14 07:25:42.585: INFO: Created: latency-svc-tgjzk
Aug 14 07:25:42.618: INFO: Got endpoints: latency-svc-m9qpk [580.497161ms]
Aug 14 07:25:42.635: INFO: Created: latency-svc-d6lhf
Aug 14 07:25:42.667: INFO: Got endpoints: latency-svc-9ckcz [628.732152ms]
Aug 14 07:25:42.684: INFO: Created: latency-svc-5fvsj
Aug 14 07:25:42.718: INFO: Got endpoints: latency-svc-vr5pd [678.091855ms]
Aug 14 07:25:42.736: INFO: Created: latency-svc-csml4
Aug 14 07:25:42.768: INFO: Got endpoints: latency-svc-dpwqv [724.49008ms]
Aug 14 07:25:42.785: INFO: Created: latency-svc-dfnqh
Aug 14 07:25:42.818: INFO: Got endpoints: latency-svc-rnpjd [725.770499ms]
Aug 14 07:25:42.834: INFO: Created: latency-svc-g47wq
Aug 14 07:25:42.868: INFO: Got endpoints: latency-svc-zcb6w [724.7662ms]
Aug 14 07:25:42.887: INFO: Created: latency-svc-lj5qf
Aug 14 07:25:42.918: INFO: Got endpoints: latency-svc-pc4xg [749.66875ms]
Aug 14 07:25:42.935: INFO: Created: latency-svc-cm5k8
Aug 14 07:25:42.968: INFO: Got endpoints: latency-svc-gs7qd [749.965638ms]
Aug 14 07:25:42.987: INFO: Created: latency-svc-q24rh
Aug 14 07:25:43.018: INFO: Got endpoints: latency-svc-vvfnj [750.173738ms]
Aug 14 07:25:43.036: INFO: Created: latency-svc-rr9fm
Aug 14 07:25:43.068: INFO: Got endpoints: latency-svc-r2s7d [750.343078ms]
Aug 14 07:25:43.091: INFO: Created: latency-svc-czc7z
Aug 14 07:25:43.118: INFO: Got endpoints: latency-svc-gbdlp [750.125921ms]
Aug 14 07:25:43.135: INFO: Created: latency-svc-5fj9w
Aug 14 07:25:43.168: INFO: Got endpoints: latency-svc-pc2s4 [750.110573ms]
Aug 14 07:25:43.184: INFO: Created: latency-svc-fxrbh
Aug 14 07:25:43.218: INFO: Got endpoints: latency-svc-trvgm [749.875067ms]
Aug 14 07:25:43.235: INFO: Created: latency-svc-v4z8g
Aug 14 07:25:43.268: INFO: Got endpoints: latency-svc-h6rw2 [750.178563ms]
Aug 14 07:25:43.289: INFO: Created: latency-svc-2fw9v
Aug 14 07:25:43.318: INFO: Got endpoints: latency-svc-tgjzk [749.73214ms]
Aug 14 07:25:43.334: INFO: Created: latency-svc-9m9d5
Aug 14 07:25:43.368: INFO: Got endpoints: latency-svc-d6lhf [749.146875ms]
Aug 14 07:25:43.385: INFO: Created: latency-svc-xjm4r
Aug 14 07:25:43.418: INFO: Got endpoints: latency-svc-5fvsj [751.31016ms]
Aug 14 07:25:43.435: INFO: Created: latency-svc-47bt7
Aug 14 07:25:43.468: INFO: Got endpoints: latency-svc-csml4 [750.127075ms]
Aug 14 07:25:43.485: INFO: Created: latency-svc-x98bv
Aug 14 07:25:43.518: INFO: Got endpoints: latency-svc-dfnqh [749.971105ms]
Aug 14 07:25:43.536: INFO: Created: latency-svc-jxspz
Aug 14 07:25:43.568: INFO: Got endpoints: latency-svc-g47wq [750.295545ms]
Aug 14 07:25:43.584: INFO: Created: latency-svc-nxd8x
Aug 14 07:25:43.618: INFO: Got endpoints: latency-svc-lj5qf [749.647863ms]
Aug 14 07:25:43.636: INFO: Created: latency-svc-4d6nw
Aug 14 07:25:43.668: INFO: Got endpoints: latency-svc-cm5k8 [749.863275ms]
Aug 14 07:25:43.684: INFO: Created: latency-svc-fjqzf
Aug 14 07:25:43.722: INFO: Got endpoints: latency-svc-q24rh [753.908842ms]
Aug 14 07:25:43.739: INFO: Created: latency-svc-cn7dd
Aug 14 07:25:43.768: INFO: Got endpoints: latency-svc-rr9fm [749.776761ms]
Aug 14 07:25:43.785: INFO: Created: latency-svc-wtcxz
Aug 14 07:25:43.819: INFO: Got endpoints: latency-svc-czc7z [750.367504ms]
Aug 14 07:25:43.835: INFO: Created: latency-svc-hqfpm
Aug 14 07:25:43.868: INFO: Got endpoints: latency-svc-5fj9w [749.911856ms]
Aug 14 07:25:43.885: INFO: Created: latency-svc-xw2q4
Aug 14 07:25:43.918: INFO: Got endpoints: latency-svc-fxrbh [749.963289ms]
Aug 14 07:25:43.938: INFO: Created: latency-svc-rs688
Aug 14 07:25:43.968: INFO: Got endpoints: latency-svc-v4z8g [750.029805ms]
Aug 14 07:25:43.986: INFO: Created: latency-svc-pvqmv
Aug 14 07:25:44.018: INFO: Got endpoints: latency-svc-2fw9v [749.721292ms]
Aug 14 07:25:44.038: INFO: Created: latency-svc-wf9hf
Aug 14 07:25:44.068: INFO: Got endpoints: latency-svc-9m9d5 [750.01901ms]
Aug 14 07:25:44.089: INFO: Created: latency-svc-79x84
Aug 14 07:25:44.123: INFO: Got endpoints: latency-svc-xjm4r [755.000442ms]
Aug 14 07:25:44.146: INFO: Created: latency-svc-cscsq
Aug 14 07:25:44.168: INFO: Got endpoints: latency-svc-47bt7 [749.224958ms]
Aug 14 07:25:44.189: INFO: Created: latency-svc-7jl7g
Aug 14 07:25:44.218: INFO: Got endpoints: latency-svc-x98bv [749.967962ms]
Aug 14 07:25:44.234: INFO: Created: latency-svc-452nz
Aug 14 07:25:44.268: INFO: Got endpoints: latency-svc-jxspz [749.767155ms]
Aug 14 07:25:44.285: INFO: Created: latency-svc-cwfbs
Aug 14 07:25:44.318: INFO: Got endpoints: latency-svc-nxd8x [749.984363ms]
Aug 14 07:25:44.334: INFO: Created: latency-svc-6m2c7
Aug 14 07:25:44.368: INFO: Got endpoints: latency-svc-4d6nw [749.729161ms]
Aug 14 07:25:44.385: INFO: Created: latency-svc-n7h82
Aug 14 07:25:44.418: INFO: Got endpoints: latency-svc-fjqzf [749.884438ms]
Aug 14 07:25:44.435: INFO: Created: latency-svc-xlhjf
Aug 14 07:25:44.468: INFO: Got endpoints: latency-svc-cn7dd [746.047547ms]
Aug 14 07:25:44.485: INFO: Created: latency-svc-2qn9q
Aug 14 07:25:44.518: INFO: Got endpoints: latency-svc-wtcxz [750.16485ms]
Aug 14 07:25:44.535: INFO: Created: latency-svc-l6fsb
Aug 14 07:25:44.568: INFO: Got endpoints: latency-svc-hqfpm [748.86229ms]
Aug 14 07:25:44.583: INFO: Created: latency-svc-5f7lc
Aug 14 07:25:44.618: INFO: Got endpoints: latency-svc-xw2q4 [749.754581ms]
Aug 14 07:25:44.637: INFO: Created: latency-svc-2dbqr
Aug 14 07:25:44.668: INFO: Got endpoints: latency-svc-rs688 [749.807524ms]
Aug 14 07:25:44.685: INFO: Created: latency-svc-t7bbz
Aug 14 07:25:44.718: INFO: Got endpoints: latency-svc-pvqmv [749.73821ms]
Aug 14 07:25:44.735: INFO: Created: latency-svc-dr264
Aug 14 07:25:44.768: INFO: Got endpoints: latency-svc-wf9hf [749.827546ms]
Aug 14 07:25:44.784: INFO: Created: latency-svc-9jp8k
Aug 14 07:25:44.818: INFO: Got endpoints: latency-svc-79x84 [750.071684ms]
Aug 14 07:25:44.836: INFO: Created: latency-svc-lk7rq
Aug 14 07:25:44.873: INFO: Got endpoints: latency-svc-cscsq [750.601856ms]
Aug 14 07:25:44.891: INFO: Created: latency-svc-zn6j6
Aug 14 07:25:44.918: INFO: Got endpoints: latency-svc-7jl7g [750.024536ms]
Aug 14 07:25:44.934: INFO: Created: latency-svc-hxrwb
Aug 14 07:25:44.968: INFO: Got endpoints: latency-svc-452nz [749.659948ms]
Aug 14 07:25:44.986: INFO: Created: latency-svc-d442t
Aug 14 07:25:45.019: INFO: Got endpoints: latency-svc-cwfbs [750.624843ms]
Aug 14 07:25:45.036: INFO: Created: latency-svc-h4tqr
Aug 14 07:25:45.141: INFO: Got endpoints: latency-svc-6m2c7 [822.863008ms]
Aug 14 07:25:45.159: INFO: Created: latency-svc-rnz66
Aug 14 07:25:45.240: INFO: Got endpoints: latency-svc-n7h82 [872.258614ms]
Aug 14 07:25:45.241: INFO: Got endpoints: latency-svc-2qn9q [772.812231ms]
Aug 14 07:25:45.241: INFO: Got endpoints: latency-svc-xlhjf [822.886184ms]
Aug 14 07:25:45.257: INFO: Created: latency-svc-cfz5m
Aug 14 07:25:45.263: INFO: Created: latency-svc-srfrd
Aug 14 07:25:45.268: INFO: Got endpoints: latency-svc-l6fsb [749.649531ms]
Aug 14 07:25:45.268: INFO: Created: latency-svc-vd9js
Aug 14 07:25:45.284: INFO: Created: latency-svc-5jlcg
Aug 14 07:25:45.340: INFO: Got endpoints: latency-svc-5f7lc [772.679274ms]
Aug 14 07:25:45.358: INFO: Created: latency-svc-h8z2t
Aug 14 07:25:45.468: INFO: Got endpoints: latency-svc-dr264 [750.17527ms]
Aug 14 07:25:45.485: INFO: Created: latency-svc-zrfrg
Aug 14 07:25:45.518: INFO: Got endpoints: latency-svc-9jp8k [750.245097ms]
Aug 14 07:25:45.536: INFO: Created: latency-svc-tbkrq
Aug 14 07:25:45.539: INFO: Got endpoints: latency-svc-t7bbz [871.417463ms]
Aug 14 07:25:45.540: INFO: Got endpoints: latency-svc-2dbqr [921.926821ms]
Aug 14 07:25:45.556: INFO: Created: latency-svc-7mh7p
Aug 14 07:25:45.562: INFO: Created: latency-svc-rj29c
Aug 14 07:25:45.642: INFO: Got endpoints: latency-svc-zn6j6 [768.131496ms]
Aug 14 07:25:45.643: INFO: Got endpoints: latency-svc-lk7rq [824.225192ms]
Aug 14 07:25:45.659: INFO: Created: latency-svc-kdxlz
Aug 14 07:25:45.664: INFO: Created: latency-svc-p9km7
Aug 14 07:25:45.667: INFO: Got endpoints: latency-svc-hxrwb [749.51876ms]
Aug 14 07:25:45.684: INFO: Created: latency-svc-9ct54
Aug 14 07:25:45.720: INFO: Got endpoints: latency-svc-d442t [751.813497ms]
Aug 14 07:25:45.737: INFO: Created: latency-svc-h7427
Aug 14 07:25:45.768: INFO: Got endpoints: latency-svc-h4tqr [749.532595ms]
Aug 14 07:25:45.785: INFO: Created: latency-svc-j7jzb
Aug 14 07:25:45.819: INFO: Got endpoints: latency-svc-rnz66 [677.651369ms]
Aug 14 07:25:45.836: INFO: Created: latency-svc-sr7xf
Aug 14 07:25:45.868: INFO: Got endpoints: latency-svc-cfz5m [627.576816ms]
Aug 14 07:25:45.885: INFO: Created: latency-svc-qxkgj
Aug 14 07:25:45.918: INFO: Got endpoints: latency-svc-srfrd [677.009515ms]
Aug 14 07:25:45.936: INFO: Created: latency-svc-jp6wt
Aug 14 07:25:45.968: INFO: Got endpoints: latency-svc-vd9js [727.199994ms]
Aug 14 07:25:45.986: INFO: Created: latency-svc-bmjqk
Aug 14 07:25:46.018: INFO: Got endpoints: latency-svc-5jlcg [750.114285ms]
Aug 14 07:25:46.039: INFO: Created: latency-svc-6qwbc
Aug 14 07:25:46.068: INFO: Got endpoints: latency-svc-h8z2t [727.266951ms]
Aug 14 07:25:46.085: INFO: Created: latency-svc-mdc5n
Aug 14 07:25:46.118: INFO: Got endpoints: latency-svc-zrfrg [649.378229ms]
Aug 14 07:25:46.139: INFO: Created: latency-svc-gvvjv
Aug 14 07:25:46.168: INFO: Got endpoints: latency-svc-tbkrq [649.761252ms]
Aug 14 07:25:46.186: INFO: Created: latency-svc-vncwd
Aug 14 07:25:46.218: INFO: Got endpoints: latency-svc-7mh7p [678.556052ms]
Aug 14 07:25:46.239: INFO: Created: latency-svc-47cjh
Aug 14 07:25:46.268: INFO: Got endpoints: latency-svc-rj29c [728.136884ms]
Aug 14 07:25:46.285: INFO: Created: latency-svc-4bjl5
Aug 14 07:25:46.318: INFO: Got endpoints: latency-svc-kdxlz [675.883537ms]
Aug 14 07:25:46.334: INFO: Created: latency-svc-zdczl
Aug 14 07:25:46.368: INFO: Got endpoints: latency-svc-p9km7 [725.546212ms]
Aug 14 07:25:46.385: INFO: Created: latency-svc-wgmtj
Aug 14 07:25:46.419: INFO: Got endpoints: latency-svc-9ct54 [751.232894ms]
Aug 14 07:25:46.436: INFO: Created: latency-svc-5znxn
Aug 14 07:25:46.468: INFO: Got endpoints: latency-svc-h7427 [748.075662ms]
Aug 14 07:25:46.485: INFO: Created: latency-svc-kzzn8
Aug 14 07:25:46.519: INFO: Got endpoints: latency-svc-j7jzb [750.208498ms]
Aug 14 07:25:46.535: INFO: Created: latency-svc-zwjst
Aug 14 07:25:46.568: INFO: Got endpoints: latency-svc-sr7xf [749.500247ms]
Aug 14 07:25:46.589: INFO: Created: latency-svc-h5hmj
Aug 14 07:25:46.618: INFO: Got endpoints: latency-svc-qxkgj [749.779826ms]
Aug 14 07:25:46.634: INFO: Created: latency-svc-nk274
Aug 14 07:25:46.668: INFO: Got endpoints: latency-svc-jp6wt [749.994717ms]
Aug 14 07:25:46.687: INFO: Created: latency-svc-gcxlk
Aug 14 07:25:46.719: INFO: Got endpoints: latency-svc-bmjqk [750.24285ms]
Aug 14 07:25:46.768: INFO: Got endpoints: latency-svc-6qwbc [749.964581ms]
Aug 14 07:25:46.819: INFO: Got endpoints: latency-svc-mdc5n [750.63527ms]
Aug 14 07:25:46.868: INFO: Got endpoints: latency-svc-gvvjv [750.475608ms]
Aug 14 07:25:46.918: INFO: Got endpoints: latency-svc-vncwd [749.827304ms]
Aug 14 07:25:46.968: INFO: Got endpoints: latency-svc-47cjh [750.211991ms]
Aug 14 07:25:47.018: INFO: Got endpoints: latency-svc-4bjl5 [750.215821ms]
Aug 14 07:25:47.068: INFO: Got endpoints: latency-svc-zdczl [750.68835ms]
Aug 14 07:25:47.119: INFO: Got endpoints: latency-svc-wgmtj [750.59429ms]
Aug 14 07:25:47.168: INFO: Got endpoints: latency-svc-5znxn [749.095914ms]
Aug 14 07:25:47.219: INFO: Got endpoints: latency-svc-kzzn8 [750.517694ms]
Aug 14 07:25:47.268: INFO: Got endpoints: latency-svc-zwjst [749.593838ms]
Aug 14 07:25:47.318: INFO: Got endpoints: latency-svc-h5hmj [749.740068ms]
Aug 14 07:25:47.369: INFO: Got endpoints: latency-svc-nk274 [750.502714ms]
Aug 14 07:25:47.418: INFO: Got endpoints: latency-svc-gcxlk [749.828078ms]
Aug 14 07:25:47.418: INFO: Latencies: [19.635631ms 20.740516ms 23.914283ms 25.796981ms 28.047622ms 35.663202ms 39.876372ms 44.561418ms 46.51ms 51.927682ms 66.069647ms 66.928526ms 67.041854ms 70.628538ms 71.209132ms 71.425414ms 73.411126ms 96.444792ms 97.294564ms 106.230862ms 106.384505ms 107.728054ms 108.041763ms 121.388098ms 125.091491ms 130.383929ms 132.69624ms 134.604498ms 141.048145ms 148.066905ms 151.69223ms 171.474416ms 172.376631ms 172.777239ms 172.786468ms 173.705382ms 222.289519ms 272.401635ms 319.752824ms 369.902564ms 420.747162ms 457.657777ms 503.544361ms 549.302218ms 559.776094ms 580.497161ms 609.959923ms 627.576816ms 628.732152ms 649.378229ms 649.761252ms 659.847104ms 675.883537ms 677.009515ms 677.651369ms 677.88821ms 678.091855ms 678.556052ms 724.49008ms 724.7662ms 725.546212ms 725.770499ms 726.262473ms 727.199994ms 727.266951ms 728.136884ms 746.047547ms 746.343385ms 748.075662ms 748.470643ms 748.772706ms 748.86229ms 749.095914ms 749.146875ms 749.224958ms 749.429219ms 749.445725ms 749.457659ms 749.500247ms 749.517769ms 749.51876ms 749.532595ms 749.534356ms 749.548083ms 749.549702ms 749.572033ms 749.593838ms 749.632871ms 749.646063ms 749.647863ms 749.649531ms 749.659948ms 749.666096ms 749.66875ms 749.682109ms 749.68857ms 749.707897ms 749.711404ms 749.721292ms 749.729161ms 749.73214ms 749.734239ms 749.73821ms 749.740068ms 749.744577ms 749.754581ms 749.767155ms 749.776761ms 749.779826ms 749.780707ms 749.807524ms 749.827304ms 749.827546ms 749.828078ms 749.863275ms 749.868756ms 749.875067ms 749.877128ms 749.884438ms 749.885795ms 749.897876ms 749.905652ms 749.911856ms 749.963289ms 749.964581ms 749.965638ms 749.967962ms 749.971105ms 749.984363ms 749.994717ms 750.010065ms 750.010478ms 750.013076ms 750.01901ms 750.024536ms 750.029805ms 750.039598ms 750.071684ms 750.082798ms 750.094961ms 750.100588ms 750.108653ms 750.110573ms 750.114285ms 750.125921ms 750.127075ms 750.143674ms 750.152603ms 750.15753ms 750.16485ms 750.173738ms 750.17527ms 750.178563ms 750.208498ms 750.211991ms 750.215821ms 750.231116ms 750.24285ms 750.245097ms 750.250709ms 750.295545ms 750.320939ms 750.32829ms 750.343078ms 750.351634ms 750.352351ms 750.367504ms 750.475608ms 750.502714ms 750.512995ms 750.517694ms 750.59429ms 750.601856ms 750.624843ms 750.63527ms 750.68835ms 751.11288ms 751.232894ms 751.31016ms 751.392104ms 751.813497ms 751.876035ms 753.544191ms 753.908842ms 755.000442ms 768.131496ms 772.679274ms 772.812231ms 773.72357ms 775.313785ms 775.965191ms 822.566368ms 822.863008ms 822.886184ms 824.225192ms 870.174188ms 871.417463ms 872.258614ms 919.366226ms 921.926821ms]
Aug 14 07:25:47.418: INFO: 50 %ile: 749.73214ms
Aug 14 07:25:47.418: INFO: 90 %ile: 751.813497ms
Aug 14 07:25:47.418: INFO: 99 %ile: 919.366226ms
Aug 14 07:25:47.418: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:25:47.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-1775" for this suite.
Aug 14 07:25:59.464: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:25:59.846: INFO: namespace svc-latency-1775 deletion completed in 12.415957057s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:25:59.846: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8269
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 14 07:26:00.098: INFO: Waiting up to 5m0s for pod "downwardapi-volume-55f1d365-5d39-4662-859a-c4f1169e0168" in namespace "downward-api-8269" to be "success or failure"
Aug 14 07:26:00.108: INFO: Pod "downwardapi-volume-55f1d365-5d39-4662-859a-c4f1169e0168": Phase="Pending", Reason="", readiness=false. Elapsed: 10.013089ms
Aug 14 07:26:02.119: INFO: Pod "downwardapi-volume-55f1d365-5d39-4662-859a-c4f1169e0168": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021420754s
STEP: Saw pod success
Aug 14 07:26:02.119: INFO: Pod "downwardapi-volume-55f1d365-5d39-4662-859a-c4f1169e0168" satisfied condition "success or failure"
Aug 14 07:26:02.130: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod downwardapi-volume-55f1d365-5d39-4662-859a-c4f1169e0168 container client-container: <nil>
STEP: delete the pod
Aug 14 07:26:02.165: INFO: Waiting for pod downwardapi-volume-55f1d365-5d39-4662-859a-c4f1169e0168 to disappear
Aug 14 07:26:02.175: INFO: Pod downwardapi-volume-55f1d365-5d39-4662-859a-c4f1169e0168 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:26:02.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8269" for this suite.
Aug 14 07:26:08.227: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:26:08.662: INFO: namespace downward-api-8269 deletion completed in 6.468031495s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:26:08.663: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7192
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-941d1720-e621-45d8-89e5-70d2bd89fdae
STEP: Creating a pod to test consume configMaps
Aug 14 07:26:09.006: INFO: Waiting up to 5m0s for pod "pod-configmaps-2207dfb0-6ee3-4e17-ad28-6b31fa0f7a3d" in namespace "configmap-7192" to be "success or failure"
Aug 14 07:26:09.016: INFO: Pod "pod-configmaps-2207dfb0-6ee3-4e17-ad28-6b31fa0f7a3d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.37113ms
Aug 14 07:26:11.028: INFO: Pod "pod-configmaps-2207dfb0-6ee3-4e17-ad28-6b31fa0f7a3d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022009411s
STEP: Saw pod success
Aug 14 07:26:11.028: INFO: Pod "pod-configmaps-2207dfb0-6ee3-4e17-ad28-6b31fa0f7a3d" satisfied condition "success or failure"
Aug 14 07:26:11.038: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod pod-configmaps-2207dfb0-6ee3-4e17-ad28-6b31fa0f7a3d container configmap-volume-test: <nil>
STEP: delete the pod
Aug 14 07:26:11.071: INFO: Waiting for pod pod-configmaps-2207dfb0-6ee3-4e17-ad28-6b31fa0f7a3d to disappear
Aug 14 07:26:11.082: INFO: Pod pod-configmaps-2207dfb0-6ee3-4e17-ad28-6b31fa0f7a3d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:26:11.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7192" for this suite.
Aug 14 07:26:17.136: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:26:17.536: INFO: namespace configmap-7192 deletion completed in 6.434808643s
•SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:26:17.536: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9189
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1457
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 14 07:26:17.876: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-9189'
Aug 14 07:26:18.233: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 14 07:26:18.233: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Aug 14 07:26:18.254: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-njdgk]
Aug 14 07:26:18.254: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-njdgk" in namespace "kubectl-9189" to be "running and ready"
Aug 14 07:26:18.265: INFO: Pod "e2e-test-nginx-rc-njdgk": Phase="Pending", Reason="", readiness=false. Elapsed: 10.812851ms
Aug 14 07:26:20.277: INFO: Pod "e2e-test-nginx-rc-njdgk": Phase="Running", Reason="", readiness=true. Elapsed: 2.022692389s
Aug 14 07:26:20.277: INFO: Pod "e2e-test-nginx-rc-njdgk" satisfied condition "running and ready"
Aug 14 07:26:20.277: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-njdgk]
Aug 14 07:26:20.277: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs rc/e2e-test-nginx-rc --namespace=kubectl-9189'
Aug 14 07:26:20.438: INFO: stderr: ""
Aug 14 07:26:20.438: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1462
Aug 14 07:26:20.438: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete rc e2e-test-nginx-rc --namespace=kubectl-9189'
Aug 14 07:26:20.563: INFO: stderr: ""
Aug 14 07:26:20.563: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:26:20.563: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9189" for this suite.
Aug 14 07:26:26.617: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:26:27.051: INFO: namespace kubectl-9189 deletion completed in 6.468421328s
•SSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:26:27.051: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3767
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-c71bff00-89fa-477f-81a8-8990d5d26066
STEP: Creating a pod to test consume secrets
Aug 14 07:26:27.313: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-1d20e9c2-1ceb-4c5b-9346-770c89fc2227" in namespace "projected-3767" to be "success or failure"
Aug 14 07:26:27.323: INFO: Pod "pod-projected-secrets-1d20e9c2-1ceb-4c5b-9346-770c89fc2227": Phase="Pending", Reason="", readiness=false. Elapsed: 10.34735ms
Aug 14 07:26:29.335: INFO: Pod "pod-projected-secrets-1d20e9c2-1ceb-4c5b-9346-770c89fc2227": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021975263s
STEP: Saw pod success
Aug 14 07:26:29.335: INFO: Pod "pod-projected-secrets-1d20e9c2-1ceb-4c5b-9346-770c89fc2227" satisfied condition "success or failure"
Aug 14 07:26:29.346: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod pod-projected-secrets-1d20e9c2-1ceb-4c5b-9346-770c89fc2227 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 14 07:26:29.380: INFO: Waiting for pod pod-projected-secrets-1d20e9c2-1ceb-4c5b-9346-770c89fc2227 to disappear
Aug 14 07:26:29.391: INFO: Pod pod-projected-secrets-1d20e9c2-1ceb-4c5b-9346-770c89fc2227 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:26:29.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3767" for this suite.
Aug 14 07:26:35.446: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:26:35.847: INFO: namespace projected-3767 deletion completed in 6.437221734s
•SSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:26:35.847: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3290
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Aug 14 07:26:36.193: INFO: Waiting up to 5m0s for pod "downward-api-7714c697-8cd0-49d5-b2b4-0ecc2e5d9d43" in namespace "downward-api-3290" to be "success or failure"
Aug 14 07:26:36.203: INFO: Pod "downward-api-7714c697-8cd0-49d5-b2b4-0ecc2e5d9d43": Phase="Pending", Reason="", readiness=false. Elapsed: 10.07523ms
Aug 14 07:26:38.215: INFO: Pod "downward-api-7714c697-8cd0-49d5-b2b4-0ecc2e5d9d43": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021970272s
STEP: Saw pod success
Aug 14 07:26:38.215: INFO: Pod "downward-api-7714c697-8cd0-49d5-b2b4-0ecc2e5d9d43" satisfied condition "success or failure"
Aug 14 07:26:38.226: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod downward-api-7714c697-8cd0-49d5-b2b4-0ecc2e5d9d43 container dapi-container: <nil>
STEP: delete the pod
Aug 14 07:26:38.260: INFO: Waiting for pod downward-api-7714c697-8cd0-49d5-b2b4-0ecc2e5d9d43 to disappear
Aug 14 07:26:38.270: INFO: Pod downward-api-7714c697-8cd0-49d5-b2b4-0ecc2e5d9d43 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:26:38.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3290" for this suite.
Aug 14 07:26:44.323: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:26:44.729: INFO: namespace downward-api-3290 deletion completed in 6.439806876s
•SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:26:44.729: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3412
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-9d668f52-e116-4697-bc0d-88ee2e5f0db3
STEP: Creating a pod to test consume configMaps
Aug 14 07:26:45.102: INFO: Waiting up to 5m0s for pod "pod-configmaps-5afa711d-de85-4c94-ba03-efb049078bf9" in namespace "configmap-3412" to be "success or failure"
Aug 14 07:26:45.113: INFO: Pod "pod-configmaps-5afa711d-de85-4c94-ba03-efb049078bf9": Phase="Pending", Reason="", readiness=false. Elapsed: 10.360182ms
Aug 14 07:26:47.127: INFO: Pod "pod-configmaps-5afa711d-de85-4c94-ba03-efb049078bf9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024346847s
STEP: Saw pod success
Aug 14 07:26:47.127: INFO: Pod "pod-configmaps-5afa711d-de85-4c94-ba03-efb049078bf9" satisfied condition "success or failure"
Aug 14 07:26:47.137: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod pod-configmaps-5afa711d-de85-4c94-ba03-efb049078bf9 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 14 07:26:47.172: INFO: Waiting for pod pod-configmaps-5afa711d-de85-4c94-ba03-efb049078bf9 to disappear
Aug 14 07:26:47.183: INFO: Pod pod-configmaps-5afa711d-de85-4c94-ba03-efb049078bf9 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:26:47.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3412" for this suite.
Aug 14 07:26:53.238: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:26:53.634: INFO: namespace configmap-3412 deletion completed in 6.430676208s
•S
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:26:53.634: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-4473
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service multi-endpoint-test in namespace services-4473
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4473 to expose endpoints map[]
Aug 14 07:26:54.005: INFO: successfully validated that service multi-endpoint-test in namespace services-4473 exposes endpoints map[] (9.938832ms elapsed)
STEP: Creating pod pod1 in namespace services-4473
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4473 to expose endpoints map[pod1:[100]]
Aug 14 07:26:56.085: INFO: successfully validated that service multi-endpoint-test in namespace services-4473 exposes endpoints map[pod1:[100]] (2.065021169s elapsed)
STEP: Creating pod pod2 in namespace services-4473
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4473 to expose endpoints map[pod1:[100] pod2:[101]]
Aug 14 07:26:58.196: INFO: successfully validated that service multi-endpoint-test in namespace services-4473 exposes endpoints map[pod1:[100] pod2:[101]] (2.098453706s elapsed)
STEP: Deleting pod pod1 in namespace services-4473
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4473 to expose endpoints map[pod2:[101]]
Aug 14 07:26:58.229: INFO: successfully validated that service multi-endpoint-test in namespace services-4473 exposes endpoints map[pod2:[101]] (20.874317ms elapsed)
STEP: Deleting pod pod2 in namespace services-4473
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4473 to expose endpoints map[]
Aug 14 07:26:58.253: INFO: successfully validated that service multi-endpoint-test in namespace services-4473 exposes endpoints map[] (10.876179ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:26:58.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4473" for this suite.
Aug 14 07:27:22.334: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:27:22.725: INFO: namespace services-4473 deletion completed in 24.425255489s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:27:22.726: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5485
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-44f81c47-6222-4ed4-9876-e1d6646af7e2
STEP: Creating a pod to test consume secrets
Aug 14 07:27:23.108: INFO: Waiting up to 5m0s for pod "pod-secrets-48b876fa-f308-4ffb-94cb-39305e1925d5" in namespace "secrets-5485" to be "success or failure"
Aug 14 07:27:23.119: INFO: Pod "pod-secrets-48b876fa-f308-4ffb-94cb-39305e1925d5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.547966ms
Aug 14 07:27:25.131: INFO: Pod "pod-secrets-48b876fa-f308-4ffb-94cb-39305e1925d5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022727591s
STEP: Saw pod success
Aug 14 07:27:25.131: INFO: Pod "pod-secrets-48b876fa-f308-4ffb-94cb-39305e1925d5" satisfied condition "success or failure"
Aug 14 07:27:25.142: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod pod-secrets-48b876fa-f308-4ffb-94cb-39305e1925d5 container secret-volume-test: <nil>
STEP: delete the pod
Aug 14 07:27:25.179: INFO: Waiting for pod pod-secrets-48b876fa-f308-4ffb-94cb-39305e1925d5 to disappear
Aug 14 07:27:25.189: INFO: Pod pod-secrets-48b876fa-f308-4ffb-94cb-39305e1925d5 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:27:25.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5485" for this suite.
Aug 14 07:27:31.244: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:27:31.684: INFO: namespace secrets-5485 deletion completed in 6.476041203s
•SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:27:31.685: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5500
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-4acd65f9-2000-42fc-8fdd-24f3f8b90200
STEP: Creating a pod to test consume secrets
Aug 14 07:27:32.001: INFO: Waiting up to 5m0s for pod "pod-secrets-75cf2553-af8a-429e-a0e9-6dfe0e6ecec3" in namespace "secrets-5500" to be "success or failure"
Aug 14 07:27:32.011: INFO: Pod "pod-secrets-75cf2553-af8a-429e-a0e9-6dfe0e6ecec3": Phase="Pending", Reason="", readiness=false. Elapsed: 10.376502ms
Aug 14 07:27:34.023: INFO: Pod "pod-secrets-75cf2553-af8a-429e-a0e9-6dfe0e6ecec3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022475166s
STEP: Saw pod success
Aug 14 07:27:34.023: INFO: Pod "pod-secrets-75cf2553-af8a-429e-a0e9-6dfe0e6ecec3" satisfied condition "success or failure"
Aug 14 07:27:34.034: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod pod-secrets-75cf2553-af8a-429e-a0e9-6dfe0e6ecec3 container secret-volume-test: <nil>
STEP: delete the pod
Aug 14 07:27:34.067: INFO: Waiting for pod pod-secrets-75cf2553-af8a-429e-a0e9-6dfe0e6ecec3 to disappear
Aug 14 07:27:34.077: INFO: Pod pod-secrets-75cf2553-af8a-429e-a0e9-6dfe0e6ecec3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:27:34.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5500" for this suite.
Aug 14 07:27:40.141: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:27:40.545: INFO: namespace secrets-5500 deletion completed in 6.448760519s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:27:40.546: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-6581
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-bbda0ccc-e7cd-4706-8fa9-071bf63bcab0 in namespace container-probe-6581
Aug 14 07:27:42.919: INFO: Started pod busybox-bbda0ccc-e7cd-4706-8fa9-071bf63bcab0 in namespace container-probe-6581
STEP: checking the pod's current state and verifying that restartCount is present
Aug 14 07:27:42.930: INFO: Initial restart count of pod busybox-bbda0ccc-e7cd-4706-8fa9-071bf63bcab0 is 0
Aug 14 07:28:35.244: INFO: Restart count of pod container-probe-6581/busybox-bbda0ccc-e7cd-4706-8fa9-071bf63bcab0 is now 1 (52.313286477s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:28:35.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6581" for this suite.
Aug 14 07:28:41.313: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:28:41.712: INFO: namespace container-probe-6581 deletion completed in 6.433963506s
•SS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:28:41.713: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4112
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Aug 14 07:28:42.002: INFO: Waiting up to 5m0s for pod "downward-api-b97e0a4f-06d5-45ed-a376-cc284761cc7d" in namespace "downward-api-4112" to be "success or failure"
Aug 14 07:28:42.012: INFO: Pod "downward-api-b97e0a4f-06d5-45ed-a376-cc284761cc7d": Phase="Pending", Reason="", readiness=false. Elapsed: 9.942126ms
Aug 14 07:28:44.023: INFO: Pod "downward-api-b97e0a4f-06d5-45ed-a376-cc284761cc7d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02124189s
STEP: Saw pod success
Aug 14 07:28:44.023: INFO: Pod "downward-api-b97e0a4f-06d5-45ed-a376-cc284761cc7d" satisfied condition "success or failure"
Aug 14 07:28:44.034: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod downward-api-b97e0a4f-06d5-45ed-a376-cc284761cc7d container dapi-container: <nil>
STEP: delete the pod
Aug 14 07:28:44.070: INFO: Waiting for pod downward-api-b97e0a4f-06d5-45ed-a376-cc284761cc7d to disappear
Aug 14 07:28:44.081: INFO: Pod downward-api-b97e0a4f-06d5-45ed-a376-cc284761cc7d no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:28:44.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4112" for this suite.
Aug 14 07:28:52.136: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:28:52.533: INFO: namespace downward-api-4112 deletion completed in 8.43184194s
•
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:28:52.533: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4792
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-79496871-af17-4e26-bc69-0534287ede70
STEP: Creating a pod to test consume secrets
Aug 14 07:28:52.907: INFO: Waiting up to 5m0s for pod "pod-secrets-705ce422-b55c-4b07-9574-e1947e663fe2" in namespace "secrets-4792" to be "success or failure"
Aug 14 07:28:52.916: INFO: Pod "pod-secrets-705ce422-b55c-4b07-9574-e1947e663fe2": Phase="Pending", Reason="", readiness=false. Elapsed: 9.73533ms
Aug 14 07:28:54.928: INFO: Pod "pod-secrets-705ce422-b55c-4b07-9574-e1947e663fe2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020987163s
STEP: Saw pod success
Aug 14 07:28:54.928: INFO: Pod "pod-secrets-705ce422-b55c-4b07-9574-e1947e663fe2" satisfied condition "success or failure"
Aug 14 07:28:54.938: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod pod-secrets-705ce422-b55c-4b07-9574-e1947e663fe2 container secret-volume-test: <nil>
STEP: delete the pod
Aug 14 07:28:54.971: INFO: Waiting for pod pod-secrets-705ce422-b55c-4b07-9574-e1947e663fe2 to disappear
Aug 14 07:28:54.981: INFO: Pod pod-secrets-705ce422-b55c-4b07-9574-e1947e663fe2 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:28:54.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4792" for this suite.
Aug 14 07:29:01.032: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:29:01.440: INFO: namespace secrets-4792 deletion completed in 6.440567965s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:29:01.441: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-5744
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override all
Aug 14 07:29:01.791: INFO: Waiting up to 5m0s for pod "client-containers-69de1a49-3ba9-4d8d-9c81-ed15d4fa2648" in namespace "containers-5744" to be "success or failure"
Aug 14 07:29:01.801: INFO: Pod "client-containers-69de1a49-3ba9-4d8d-9c81-ed15d4fa2648": Phase="Pending", Reason="", readiness=false. Elapsed: 10.338736ms
Aug 14 07:29:03.814: INFO: Pod "client-containers-69de1a49-3ba9-4d8d-9c81-ed15d4fa2648": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02303757s
STEP: Saw pod success
Aug 14 07:29:03.814: INFO: Pod "client-containers-69de1a49-3ba9-4d8d-9c81-ed15d4fa2648" satisfied condition "success or failure"
Aug 14 07:29:03.825: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod client-containers-69de1a49-3ba9-4d8d-9c81-ed15d4fa2648 container test-container: <nil>
STEP: delete the pod
Aug 14 07:29:03.858: INFO: Waiting for pod client-containers-69de1a49-3ba9-4d8d-9c81-ed15d4fa2648 to disappear
Aug 14 07:29:03.869: INFO: Pod client-containers-69de1a49-3ba9-4d8d-9c81-ed15d4fa2648 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:29:03.869: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5744" for this suite.
Aug 14 07:29:09.922: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:29:10.315: INFO: namespace containers-5744 deletion completed in 6.427233036s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:29:10.317: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-5130
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-5130
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-5130
STEP: Creating statefulset with conflicting port in namespace statefulset-5130
STEP: Waiting until pod test-pod will start running in namespace statefulset-5130
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-5130
Aug 14 07:29:12.765: INFO: Observed stateful pod in namespace: statefulset-5130, name: ss-0, uid: f37e8fee-d887-4f38-8876-238acdd2be9f, status phase: Failed. Waiting for statefulset controller to delete.
Aug 14 07:29:12.790: INFO: Observed stateful pod in namespace: statefulset-5130, name: ss-0, uid: f37e8fee-d887-4f38-8876-238acdd2be9f, status phase: Failed. Waiting for statefulset controller to delete.
Aug 14 07:29:12.792: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-5130
STEP: Removing pod with conflicting port in namespace statefulset-5130
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-5130 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Aug 14 07:29:14.832: INFO: Deleting all statefulset in ns statefulset-5130
Aug 14 07:29:14.843: INFO: Scaling statefulset ss to 0
Aug 14 07:29:34.888: INFO: Waiting for statefulset status.replicas updated to 0
Aug 14 07:29:34.898: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:29:34.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5130" for this suite.
Aug 14 07:29:40.979: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:29:41.374: INFO: namespace statefulset-5130 deletion completed in 6.427064094s
•S
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:29:41.375: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-3899
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Aug 14 07:29:41.585: INFO: PodSpec: initContainers in spec.initContainers
Aug 14 07:30:28.974: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-df85c82a-b011-4e55-913a-24ae5ac3d037", GenerateName:"", Namespace:"init-container-3899", SelfLink:"/api/v1/namespaces/init-container-3899/pods/pod-init-df85c82a-b011-4e55-913a-24ae5ac3d037", UID:"605eee50-39c5-4888-962b-8d8dd0efbc4d", ResourceVersion:"17019", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63701364581, loc:(*time.Location)(0x80bfa40)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"585518784"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"100.96.1.180/32", "kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-pdwnh", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc00272a540), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-pdwnh", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-pdwnh", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-pdwnh", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc003695348), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc003231b00), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0036953c0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0036953e0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0036953e8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0036953ec), PreemptionPolicy:(*v1.PreemptionPolicy)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701364581, loc:(*time.Location)(0x80bfa40)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701364581, loc:(*time.Location)(0x80bfa40)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701364581, loc:(*time.Location)(0x80bfa40)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701364581, loc:(*time.Location)(0x80bfa40)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.250.0.3", PodIP:"100.96.1.180", StartTime:(*v1.Time)(0xc001f64800), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001efe620)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001efe690)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://ec07aee80c5e4a711c2305e063db5d340929f1d92f1ce9d48b9f3342bcb5b393"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001f64880), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001f64820), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:30:28.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-3899" for this suite.
Aug 14 07:30:51.027: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:30:51.419: INFO: namespace init-container-3899 deletion completed in 22.425370088s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:30:51.419: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2377
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name projected-secret-test-b4b37a92-86c7-4f86-8107-c36b6c87876e
STEP: Creating a pod to test consume secrets
Aug 14 07:30:51.716: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d78c01d7-9784-42d2-9515-f80d0e889bfd" in namespace "projected-2377" to be "success or failure"
Aug 14 07:30:51.726: INFO: Pod "pod-projected-secrets-d78c01d7-9784-42d2-9515-f80d0e889bfd": Phase="Pending", Reason="", readiness=false. Elapsed: 10.107373ms
Aug 14 07:30:53.738: INFO: Pod "pod-projected-secrets-d78c01d7-9784-42d2-9515-f80d0e889bfd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022167421s
STEP: Saw pod success
Aug 14 07:30:53.739: INFO: Pod "pod-projected-secrets-d78c01d7-9784-42d2-9515-f80d0e889bfd" satisfied condition "success or failure"
Aug 14 07:30:53.749: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod pod-projected-secrets-d78c01d7-9784-42d2-9515-f80d0e889bfd container secret-volume-test: <nil>
STEP: delete the pod
Aug 14 07:30:53.781: INFO: Waiting for pod pod-projected-secrets-d78c01d7-9784-42d2-9515-f80d0e889bfd to disappear
Aug 14 07:30:53.791: INFO: Pod pod-projected-secrets-d78c01d7-9784-42d2-9515-f80d0e889bfd no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:30:53.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2377" for this suite.
Aug 14 07:30:59.843: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:31:00.277: INFO: namespace projected-2377 deletion completed in 6.467054402s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:31:00.277: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3707
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 14 07:31:00.503: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2699f8c3-3c22-4aaa-a25d-ac2cb4dce2c0" in namespace "projected-3707" to be "success or failure"
Aug 14 07:31:00.513: INFO: Pod "downwardapi-volume-2699f8c3-3c22-4aaa-a25d-ac2cb4dce2c0": Phase="Pending", Reason="", readiness=false. Elapsed: 10.336967ms
Aug 14 07:31:02.525: INFO: Pod "downwardapi-volume-2699f8c3-3c22-4aaa-a25d-ac2cb4dce2c0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0220002s
STEP: Saw pod success
Aug 14 07:31:02.525: INFO: Pod "downwardapi-volume-2699f8c3-3c22-4aaa-a25d-ac2cb4dce2c0" satisfied condition "success or failure"
Aug 14 07:31:02.536: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod downwardapi-volume-2699f8c3-3c22-4aaa-a25d-ac2cb4dce2c0 container client-container: <nil>
STEP: delete the pod
Aug 14 07:31:02.572: INFO: Waiting for pod downwardapi-volume-2699f8c3-3c22-4aaa-a25d-ac2cb4dce2c0 to disappear
Aug 14 07:31:02.582: INFO: Pod downwardapi-volume-2699f8c3-3c22-4aaa-a25d-ac2cb4dce2c0 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:31:02.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3707" for this suite.
Aug 14 07:31:08.634: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:31:09.066: INFO: namespace projected-3707 deletion completed in 6.465639249s
•SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:31:09.067: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-3743
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-3743
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-3743
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-3743
Aug 14 07:31:09.330: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Aug 14 07:31:19.344: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Aug 14 07:31:19.355: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-3743 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 14 07:31:19.984: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 14 07:31:19.984: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 14 07:31:19.984: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 14 07:31:19.995: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Aug 14 07:31:30.008: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 14 07:31:30.008: INFO: Waiting for statefulset status.replicas updated to 0
Aug 14 07:31:30.052: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999603s
Aug 14 07:31:31.063: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.98947867s
Aug 14 07:31:32.075: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.978103985s
Aug 14 07:31:33.087: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.966528213s
Aug 14 07:31:34.099: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.954400488s
Aug 14 07:31:35.111: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.94252822s
Aug 14 07:31:36.122: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.930601113s
Aug 14 07:31:37.134: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.91868907s
Aug 14 07:31:38.146: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.906932016s
Aug 14 07:31:39.158: INFO: Verifying statefulset ss doesn't scale past 1 for another 895.166569ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-3743
Aug 14 07:31:40.170: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-3743 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 14 07:31:40.730: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug 14 07:31:40.730: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 14 07:31:40.730: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 14 07:31:40.741: INFO: Found 1 stateful pods, waiting for 3
Aug 14 07:31:50.755: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 14 07:31:50.755: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 14 07:31:50.755: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Aug 14 07:31:50.775: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-3743 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 14 07:31:51.384: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 14 07:31:51.384: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 14 07:31:51.384: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 14 07:31:51.384: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-3743 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 14 07:31:51.942: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 14 07:31:51.942: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 14 07:31:51.942: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 14 07:31:51.942: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-3743 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 14 07:31:52.537: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 14 07:31:52.537: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 14 07:31:52.537: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 14 07:31:52.537: INFO: Waiting for statefulset status.replicas updated to 0
Aug 14 07:31:52.548: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Aug 14 07:32:02.573: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 14 07:32:02.573: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Aug 14 07:32:02.573: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Aug 14 07:32:02.606: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999537s
Aug 14 07:32:03.618: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.988187177s
Aug 14 07:32:04.630: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.97629958s
Aug 14 07:32:05.643: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.964083049s
Aug 14 07:32:06.655: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.951739342s
Aug 14 07:32:07.666: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.939601905s
Aug 14 07:32:08.679: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.927898257s
Aug 14 07:32:09.692: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.915225425s
Aug 14 07:32:10.703: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.902822803s
Aug 14 07:32:11.716: INFO: Verifying statefulset ss doesn't scale past 3 for another 891.303385ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-3743
Aug 14 07:32:12.728: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-3743 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 14 07:32:13.288: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug 14 07:32:13.288: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 14 07:32:13.288: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 14 07:32:13.288: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-3743 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 14 07:32:13.841: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug 14 07:32:13.841: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 14 07:32:13.841: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 14 07:32:13.841: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-3743 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 14 07:32:14.437: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug 14 07:32:14.437: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 14 07:32:14.437: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 14 07:32:14.437: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Aug 14 07:32:44.483: INFO: Deleting all statefulset in ns statefulset-3743
Aug 14 07:32:44.493: INFO: Scaling statefulset ss to 0
Aug 14 07:32:44.526: INFO: Waiting for statefulset status.replicas updated to 0
Aug 14 07:32:44.537: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:32:44.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3743" for this suite.
Aug 14 07:32:50.623: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:32:51.140: INFO: namespace statefulset-3743 deletion completed in 6.550546638s
•SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:32:51.140: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-8295
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-downwardapi-cz28
STEP: Creating a pod to test atomic-volume-subpath
Aug 14 07:32:51.510: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-cz28" in namespace "subpath-8295" to be "success or failure"
Aug 14 07:32:51.520: INFO: Pod "pod-subpath-test-downwardapi-cz28": Phase="Pending", Reason="", readiness=false. Elapsed: 10.208741ms
Aug 14 07:32:53.532: INFO: Pod "pod-subpath-test-downwardapi-cz28": Phase="Running", Reason="", readiness=true. Elapsed: 2.022060709s
Aug 14 07:32:55.544: INFO: Pod "pod-subpath-test-downwardapi-cz28": Phase="Running", Reason="", readiness=true. Elapsed: 4.034130504s
Aug 14 07:32:57.556: INFO: Pod "pod-subpath-test-downwardapi-cz28": Phase="Running", Reason="", readiness=true. Elapsed: 6.045713279s
Aug 14 07:32:59.567: INFO: Pod "pod-subpath-test-downwardapi-cz28": Phase="Running", Reason="", readiness=true. Elapsed: 8.057185172s
Aug 14 07:33:01.579: INFO: Pod "pod-subpath-test-downwardapi-cz28": Phase="Running", Reason="", readiness=true. Elapsed: 10.069149127s
Aug 14 07:33:03.591: INFO: Pod "pod-subpath-test-downwardapi-cz28": Phase="Running", Reason="", readiness=true. Elapsed: 12.081071339s
Aug 14 07:33:05.603: INFO: Pod "pod-subpath-test-downwardapi-cz28": Phase="Running", Reason="", readiness=true. Elapsed: 14.092900293s
Aug 14 07:33:07.614: INFO: Pod "pod-subpath-test-downwardapi-cz28": Phase="Running", Reason="", readiness=true. Elapsed: 16.104252739s
Aug 14 07:33:09.626: INFO: Pod "pod-subpath-test-downwardapi-cz28": Phase="Running", Reason="", readiness=true. Elapsed: 18.115723995s
Aug 14 07:33:11.637: INFO: Pod "pod-subpath-test-downwardapi-cz28": Phase="Running", Reason="", readiness=true. Elapsed: 20.127224027s
Aug 14 07:33:13.649: INFO: Pod "pod-subpath-test-downwardapi-cz28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.139307018s
STEP: Saw pod success
Aug 14 07:33:13.649: INFO: Pod "pod-subpath-test-downwardapi-cz28" satisfied condition "success or failure"
Aug 14 07:33:13.660: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod pod-subpath-test-downwardapi-cz28 container test-container-subpath-downwardapi-cz28: <nil>
STEP: delete the pod
Aug 14 07:33:13.696: INFO: Waiting for pod pod-subpath-test-downwardapi-cz28 to disappear
Aug 14 07:33:13.707: INFO: Pod pod-subpath-test-downwardapi-cz28 no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-cz28
Aug 14 07:33:13.707: INFO: Deleting pod "pod-subpath-test-downwardapi-cz28" in namespace "subpath-8295"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:33:13.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8295" for this suite.
Aug 14 07:33:19.772: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:33:20.172: INFO: namespace subpath-8295 deletion completed in 6.434425957s
•SSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:33:20.172: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-4684
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 14 07:33:20.405: INFO: (0) /api/v1/nodes/shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 14.468169ms)
Aug 14 07:33:20.447: INFO: (1) /api/v1/nodes/shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 41.883709ms)
Aug 14 07:33:20.460: INFO: (2) /api/v1/nodes/shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.840687ms)
Aug 14 07:33:20.472: INFO: (3) /api/v1/nodes/shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.252321ms)
Aug 14 07:33:20.491: INFO: (4) /api/v1/nodes/shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 18.5774ms)
Aug 14 07:33:20.504: INFO: (5) /api/v1/nodes/shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.704447ms)
Aug 14 07:33:20.516: INFO: (6) /api/v1/nodes/shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.782705ms)
Aug 14 07:33:20.529: INFO: (7) /api/v1/nodes/shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.90886ms)
Aug 14 07:33:20.542: INFO: (8) /api/v1/nodes/shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.567766ms)
Aug 14 07:33:20.555: INFO: (9) /api/v1/nodes/shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.496423ms)
Aug 14 07:33:20.568: INFO: (10) /api/v1/nodes/shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.955137ms)
Aug 14 07:33:20.581: INFO: (11) /api/v1/nodes/shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 13.173314ms)
Aug 14 07:33:20.594: INFO: (12) /api/v1/nodes/shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.945736ms)
Aug 14 07:33:20.607: INFO: (13) /api/v1/nodes/shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.758858ms)
Aug 14 07:33:20.620: INFO: (14) /api/v1/nodes/shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 13.0965ms)
Aug 14 07:33:20.632: INFO: (15) /api/v1/nodes/shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.441139ms)
Aug 14 07:33:20.645: INFO: (16) /api/v1/nodes/shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.71045ms)
Aug 14 07:33:20.658: INFO: (17) /api/v1/nodes/shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.793177ms)
Aug 14 07:33:20.670: INFO: (18) /api/v1/nodes/shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 11.720661ms)
Aug 14 07:33:20.682: INFO: (19) /api/v1/nodes/shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.33427ms)
[AfterEach] version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:33:20.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-4684" for this suite.
Aug 14 07:33:28.733: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:33:29.164: INFO: namespace proxy-4684 deletion completed in 8.470586912s
•SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:33:29.164: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1117
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1613
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 14 07:33:29.378: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-1117'
Aug 14 07:33:29.509: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 14 07:33:29.509: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1618
Aug 14 07:33:29.519: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete jobs e2e-test-nginx-job --namespace=kubectl-1117'
Aug 14 07:33:29.646: INFO: stderr: ""
Aug 14 07:33:29.646: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:33:29.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1117" for this suite.
Aug 14 07:33:53.690: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:33:54.087: INFO: namespace kubectl-1117 deletion completed in 24.429507378s
•SS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:33:54.087: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-7954
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Aug 14 07:33:58.391: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 14 07:33:58.403: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 14 07:34:00.403: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 14 07:34:00.415: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 14 07:34:02.403: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 14 07:34:02.415: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 14 07:34:04.403: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 14 07:34:04.416: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 14 07:34:06.403: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 14 07:34:06.415: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 14 07:34:08.403: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 14 07:34:08.415: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 14 07:34:10.403: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 14 07:34:10.415: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 14 07:34:12.403: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 14 07:34:12.414: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 14 07:34:14.403: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 14 07:34:14.414: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 14 07:34:16.403: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 14 07:34:16.415: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 14 07:34:18.403: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 14 07:34:18.415: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 14 07:34:20.403: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 14 07:34:20.415: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 14 07:34:22.403: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 14 07:34:22.415: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 14 07:34:24.403: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 14 07:34:24.415: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 14 07:34:26.403: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 14 07:34:26.414: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:34:26.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-7954" for this suite.
Aug 14 07:34:48.484: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:34:48.912: INFO: namespace container-lifecycle-hook-7954 deletion completed in 22.461136433s
•SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:34:48.912: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6008
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-5a76a6d2-c016-4c13-ab7f-2d3bdb63f228
STEP: Creating secret with name s-test-opt-upd-9abba070-58d9-428c-8a9c-223a251f6602
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-5a76a6d2-c016-4c13-ab7f-2d3bdb63f228
STEP: Updating secret s-test-opt-upd-9abba070-58d9-428c-8a9c-223a251f6602
STEP: Creating secret with name s-test-opt-create-347cda25-d18b-4ccc-a787-3ac406b70e73
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:34:53.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6008" for this suite.
Aug 14 07:35:15.755: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:35:16.157: INFO: namespace projected-6008 deletion completed in 22.435396682s
•SSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:35:16.157: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-9178
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-9f4167e5-2d27-499b-a1c3-0b805d7c3b98 in namespace container-probe-9178
Aug 14 07:35:18.506: INFO: Started pod busybox-9f4167e5-2d27-499b-a1c3-0b805d7c3b98 in namespace container-probe-9178
STEP: checking the pod's current state and verifying that restartCount is present
Aug 14 07:35:18.517: INFO: Initial restart count of pod busybox-9f4167e5-2d27-499b-a1c3-0b805d7c3b98 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:39:19.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9178" for this suite.
Aug 14 07:39:25.956: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:39:26.350: INFO: namespace container-probe-9178 deletion completed in 6.425542184s
•SSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:39:26.351: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9384
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating pod
Aug 14 07:39:28.621: INFO: Pod pod-hostip-0adda3b2-4c81-43df-bf3c-12bfb1fa46f3 has hostIP: 10.250.0.3
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:39:28.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9384" for this suite.
Aug 14 07:39:50.677: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:39:51.095: INFO: namespace pods-9384 deletion completed in 22.454285102s
•SSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:39:51.095: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-3158
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-3158
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 14 07:39:51.363: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug 14 07:40:07.547: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.96.1.192:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3158 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 07:40:07.547: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Aug 14 07:40:07.994: INFO: Found all expected endpoints: [netserver-0]
Aug 14 07:40:08.005: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.96.0.71:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3158 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 07:40:08.005: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Aug 14 07:40:13.438: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:40:13.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3158" for this suite.
Aug 14 07:40:37.491: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:40:37.924: INFO: namespace pod-network-test-3158 deletion completed in 24.466856279s
•SSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:40:37.924: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-9782
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9782.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9782.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 14 07:40:40.776: INFO: DNS probes using dns-9782/dns-test-cc0c45f0-b6d8-45de-8477-fd4dfe0cfd04 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:40:40.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9782" for this suite.
Aug 14 07:40:46.844: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:40:47.232: INFO: namespace dns-9782 deletion completed in 6.420531683s
•SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:40:47.232: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8758
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-321d9e35-1c5f-4d1c-ad46-154bb380525c
STEP: Creating a pod to test consume secrets
Aug 14 07:40:47.579: INFO: Waiting up to 5m0s for pod "pod-secrets-3c13996a-fde4-4013-9c9d-3a49b7bf260a" in namespace "secrets-8758" to be "success or failure"
Aug 14 07:40:47.590: INFO: Pod "pod-secrets-3c13996a-fde4-4013-9c9d-3a49b7bf260a": Phase="Pending", Reason="", readiness=false. Elapsed: 10.556468ms
Aug 14 07:40:49.601: INFO: Pod "pod-secrets-3c13996a-fde4-4013-9c9d-3a49b7bf260a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021965553s
STEP: Saw pod success
Aug 14 07:40:49.602: INFO: Pod "pod-secrets-3c13996a-fde4-4013-9c9d-3a49b7bf260a" satisfied condition "success or failure"
Aug 14 07:40:49.612: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod pod-secrets-3c13996a-fde4-4013-9c9d-3a49b7bf260a container secret-volume-test: <nil>
STEP: delete the pod
Aug 14 07:40:49.647: INFO: Waiting for pod pod-secrets-3c13996a-fde4-4013-9c9d-3a49b7bf260a to disappear
Aug 14 07:40:49.658: INFO: Pod pod-secrets-3c13996a-fde4-4013-9c9d-3a49b7bf260a no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:40:49.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8758" for this suite.
Aug 14 07:40:55.709: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:40:56.141: INFO: namespace secrets-8758 deletion completed in 6.464416971s
•SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:40:56.142: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-2053
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:40:58.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2053" for this suite.
Aug 14 07:41:52.613: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:41:53.021: INFO: namespace kubelet-test-2053 deletion completed in 54.444024554s
•SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:41:53.021: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5862
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Aug 14 07:41:53.382: INFO: Waiting up to 5m0s for pod "pod-7285afaa-3f95-43ed-91f0-f55211446d4d" in namespace "emptydir-5862" to be "success or failure"
Aug 14 07:41:53.393: INFO: Pod "pod-7285afaa-3f95-43ed-91f0-f55211446d4d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.905365ms
Aug 14 07:41:55.420: INFO: Pod "pod-7285afaa-3f95-43ed-91f0-f55211446d4d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.038113043s
STEP: Saw pod success
Aug 14 07:41:55.421: INFO: Pod "pod-7285afaa-3f95-43ed-91f0-f55211446d4d" satisfied condition "success or failure"
Aug 14 07:41:55.434: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod pod-7285afaa-3f95-43ed-91f0-f55211446d4d container test-container: <nil>
STEP: delete the pod
Aug 14 07:41:55.467: INFO: Waiting for pod pod-7285afaa-3f95-43ed-91f0-f55211446d4d to disappear
Aug 14 07:41:55.477: INFO: Pod pod-7285afaa-3f95-43ed-91f0-f55211446d4d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:41:55.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5862" for this suite.
Aug 14 07:42:03.544: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:42:03.971: INFO: namespace emptydir-5862 deletion completed in 8.475162971s
•SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:42:03.971: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8396
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 14 07:42:04.269: INFO: Waiting up to 5m0s for pod "downwardapi-volume-69e9838a-7c7c-496f-a317-e0893547b9b7" in namespace "projected-8396" to be "success or failure"
Aug 14 07:42:04.279: INFO: Pod "downwardapi-volume-69e9838a-7c7c-496f-a317-e0893547b9b7": Phase="Pending", Reason="", readiness=false. Elapsed: 10.045263ms
Aug 14 07:42:06.291: INFO: Pod "downwardapi-volume-69e9838a-7c7c-496f-a317-e0893547b9b7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021502985s
STEP: Saw pod success
Aug 14 07:42:06.291: INFO: Pod "downwardapi-volume-69e9838a-7c7c-496f-a317-e0893547b9b7" satisfied condition "success or failure"
Aug 14 07:42:06.301: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod downwardapi-volume-69e9838a-7c7c-496f-a317-e0893547b9b7 container client-container: <nil>
STEP: delete the pod
Aug 14 07:42:06.336: INFO: Waiting for pod downwardapi-volume-69e9838a-7c7c-496f-a317-e0893547b9b7 to disappear
Aug 14 07:42:06.346: INFO: Pod downwardapi-volume-69e9838a-7c7c-496f-a317-e0893547b9b7 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:42:06.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8396" for this suite.
Aug 14 07:42:12.396: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:42:12.785: INFO: namespace projected-8396 deletion completed in 6.421378384s
•S
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:42:12.785: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1334
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Aug 14 07:42:15.139: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec pod-sharedvolume-b407b868-de59-4cb0-8113-4cf3f4822932 -c busybox-main-container --namespace=emptydir-1334 -- cat /usr/share/volumeshare/shareddata.txt'
Aug 14 07:42:16.059: INFO: stderr: ""
Aug 14 07:42:16.059: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:42:16.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1334" for this suite.
Aug 14 07:42:24.119: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:42:24.824: INFO: namespace emptydir-1334 deletion completed in 8.74558475s
•S
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:42:24.824: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-1842
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Aug 14 07:42:26.469: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:42:29.998: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1842" for this suite.
Aug 14 07:42:36.051: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:42:36.470: INFO: namespace init-container-1842 deletion completed in 6.452204984s
•SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:42:36.470: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3037
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-a07c91bc-2b49-4cc2-9d7f-035a6b426532
STEP: Creating a pod to test consume configMaps
Aug 14 07:42:36.878: INFO: Waiting up to 5m0s for pod "pod-configmaps-05323b7c-24e1-43af-9d2b-1fff887a763a" in namespace "configmap-3037" to be "success or failure"
Aug 14 07:42:36.888: INFO: Pod "pod-configmaps-05323b7c-24e1-43af-9d2b-1fff887a763a": Phase="Pending", Reason="", readiness=false. Elapsed: 9.601606ms
Aug 14 07:42:38.901: INFO: Pod "pod-configmaps-05323b7c-24e1-43af-9d2b-1fff887a763a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022635496s
STEP: Saw pod success
Aug 14 07:42:38.901: INFO: Pod "pod-configmaps-05323b7c-24e1-43af-9d2b-1fff887a763a" satisfied condition "success or failure"
Aug 14 07:42:38.911: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod pod-configmaps-05323b7c-24e1-43af-9d2b-1fff887a763a container configmap-volume-test: <nil>
STEP: delete the pod
Aug 14 07:42:38.943: INFO: Waiting for pod pod-configmaps-05323b7c-24e1-43af-9d2b-1fff887a763a to disappear
Aug 14 07:42:38.953: INFO: Pod pod-configmaps-05323b7c-24e1-43af-9d2b-1fff887a763a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:42:38.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3037" for this suite.
Aug 14 07:42:45.003: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:42:45.398: INFO: namespace configmap-3037 deletion completed in 6.426988832s
•SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:42:45.398: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7604
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-74f326fd-1c22-4279-bf10-6348f2046785
STEP: Creating a pod to test consume configMaps
Aug 14 07:42:46.177: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e3d38132-5f35-443f-bb1d-e14c200da132" in namespace "projected-7604" to be "success or failure"
Aug 14 07:42:46.187: INFO: Pod "pod-projected-configmaps-e3d38132-5f35-443f-bb1d-e14c200da132": Phase="Pending", Reason="", readiness=false. Elapsed: 10.104624ms
Aug 14 07:42:48.199: INFO: Pod "pod-projected-configmaps-e3d38132-5f35-443f-bb1d-e14c200da132": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021748441s
STEP: Saw pod success
Aug 14 07:42:48.199: INFO: Pod "pod-projected-configmaps-e3d38132-5f35-443f-bb1d-e14c200da132" satisfied condition "success or failure"
Aug 14 07:42:48.210: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod pod-projected-configmaps-e3d38132-5f35-443f-bb1d-e14c200da132 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 14 07:42:48.243: INFO: Waiting for pod pod-projected-configmaps-e3d38132-5f35-443f-bb1d-e14c200da132 to disappear
Aug 14 07:42:48.253: INFO: Pod pod-projected-configmaps-e3d38132-5f35-443f-bb1d-e14c200da132 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:42:48.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7604" for this suite.
Aug 14 07:42:54.304: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:42:54.735: INFO: namespace projected-7604 deletion completed in 6.463003566s
•SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:42:54.736: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-1904
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Aug 14 07:42:55.123: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-1904,SelfLink:/api/v1/namespaces/watch-1904/configmaps/e2e-watch-test-label-changed,UID:dc2012d7-da9d-4fe8-9363-1eaedc849bd6,ResourceVersion:19573,Generation:0,CreationTimestamp:2019-08-14 07:42:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 14 07:42:55.123: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-1904,SelfLink:/api/v1/namespaces/watch-1904/configmaps/e2e-watch-test-label-changed,UID:dc2012d7-da9d-4fe8-9363-1eaedc849bd6,ResourceVersion:19574,Generation:0,CreationTimestamp:2019-08-14 07:42:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Aug 14 07:42:55.123: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-1904,SelfLink:/api/v1/namespaces/watch-1904/configmaps/e2e-watch-test-label-changed,UID:dc2012d7-da9d-4fe8-9363-1eaedc849bd6,ResourceVersion:19575,Generation:0,CreationTimestamp:2019-08-14 07:42:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Aug 14 07:43:05.203: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-1904,SelfLink:/api/v1/namespaces/watch-1904/configmaps/e2e-watch-test-label-changed,UID:dc2012d7-da9d-4fe8-9363-1eaedc849bd6,ResourceVersion:19599,Generation:0,CreationTimestamp:2019-08-14 07:42:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 14 07:43:05.204: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-1904,SelfLink:/api/v1/namespaces/watch-1904/configmaps/e2e-watch-test-label-changed,UID:dc2012d7-da9d-4fe8-9363-1eaedc849bd6,ResourceVersion:19600,Generation:0,CreationTimestamp:2019-08-14 07:42:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Aug 14 07:43:05.204: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-1904,SelfLink:/api/v1/namespaces/watch-1904/configmaps/e2e-watch-test-label-changed,UID:dc2012d7-da9d-4fe8-9363-1eaedc849bd6,ResourceVersion:19601,Generation:0,CreationTimestamp:2019-08-14 07:42:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:43:05.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1904" for this suite.
Aug 14 07:43:11.258: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:43:11.667: INFO: namespace watch-1904 deletion completed in 6.443848455s
•SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:43:11.667: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2813
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-0f420c26-a9ef-465b-bae5-dd8673370927
STEP: Creating a pod to test consume configMaps
Aug 14 07:43:11.890: INFO: Waiting up to 5m0s for pod "pod-configmaps-b6d8cc1d-8159-4ca5-8400-7c43d7f8bafd" in namespace "configmap-2813" to be "success or failure"
Aug 14 07:43:11.901: INFO: Pod "pod-configmaps-b6d8cc1d-8159-4ca5-8400-7c43d7f8bafd": Phase="Pending", Reason="", readiness=false. Elapsed: 10.869342ms
Aug 14 07:43:13.912: INFO: Pod "pod-configmaps-b6d8cc1d-8159-4ca5-8400-7c43d7f8bafd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022017617s
STEP: Saw pod success
Aug 14 07:43:13.912: INFO: Pod "pod-configmaps-b6d8cc1d-8159-4ca5-8400-7c43d7f8bafd" satisfied condition "success or failure"
Aug 14 07:43:13.923: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod pod-configmaps-b6d8cc1d-8159-4ca5-8400-7c43d7f8bafd container configmap-volume-test: <nil>
STEP: delete the pod
Aug 14 07:43:13.956: INFO: Waiting for pod pod-configmaps-b6d8cc1d-8159-4ca5-8400-7c43d7f8bafd to disappear
Aug 14 07:43:13.967: INFO: Pod pod-configmaps-b6d8cc1d-8159-4ca5-8400-7c43d7f8bafd no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:43:13.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2813" for this suite.
Aug 14 07:43:20.019: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:43:20.407: INFO: namespace configmap-2813 deletion completed in 6.421705131s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:43:20.408: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2832
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-e77cad9c-02be-4fe9-ab7c-59c38fa6153d
STEP: Creating a pod to test consume secrets
Aug 14 07:43:20.690: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a89c6cde-17d2-4d18-8dde-28dcef17aa73" in namespace "projected-2832" to be "success or failure"
Aug 14 07:43:20.700: INFO: Pod "pod-projected-secrets-a89c6cde-17d2-4d18-8dde-28dcef17aa73": Phase="Pending", Reason="", readiness=false. Elapsed: 9.956208ms
Aug 14 07:43:22.711: INFO: Pod "pod-projected-secrets-a89c6cde-17d2-4d18-8dde-28dcef17aa73": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021300836s
STEP: Saw pod success
Aug 14 07:43:22.711: INFO: Pod "pod-projected-secrets-a89c6cde-17d2-4d18-8dde-28dcef17aa73" satisfied condition "success or failure"
Aug 14 07:43:22.722: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod pod-projected-secrets-a89c6cde-17d2-4d18-8dde-28dcef17aa73 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 14 07:43:22.756: INFO: Waiting for pod pod-projected-secrets-a89c6cde-17d2-4d18-8dde-28dcef17aa73 to disappear
Aug 14 07:43:22.766: INFO: Pod pod-projected-secrets-a89c6cde-17d2-4d18-8dde-28dcef17aa73 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:43:22.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2832" for this suite.
Aug 14 07:43:28.817: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:43:29.214: INFO: namespace projected-2832 deletion completed in 6.429040838s
•SSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:43:29.214: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9909
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 14 07:43:31.640: INFO: Waiting up to 5m0s for pod "client-envvars-9b65cbee-c220-409d-8e79-c191ae3be9a5" in namespace "pods-9909" to be "success or failure"
Aug 14 07:43:31.650: INFO: Pod "client-envvars-9b65cbee-c220-409d-8e79-c191ae3be9a5": Phase="Pending", Reason="", readiness=false. Elapsed: 9.904319ms
Aug 14 07:43:33.661: INFO: Pod "client-envvars-9b65cbee-c220-409d-8e79-c191ae3be9a5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021086707s
STEP: Saw pod success
Aug 14 07:43:33.661: INFO: Pod "client-envvars-9b65cbee-c220-409d-8e79-c191ae3be9a5" satisfied condition "success or failure"
Aug 14 07:43:33.672: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod client-envvars-9b65cbee-c220-409d-8e79-c191ae3be9a5 container env3cont: <nil>
STEP: delete the pod
Aug 14 07:43:33.706: INFO: Waiting for pod client-envvars-9b65cbee-c220-409d-8e79-c191ae3be9a5 to disappear
Aug 14 07:43:33.716: INFO: Pod client-envvars-9b65cbee-c220-409d-8e79-c191ae3be9a5 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:43:33.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9909" for this suite.
Aug 14 07:44:13.767: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:44:14.165: INFO: namespace pods-9909 deletion completed in 40.430683902s
•SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:44:14.165: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7972
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Starting the proxy
Aug 14 07:44:14.453: INFO: Asynchronously running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config proxy --unix-socket=/tmp/kubectl-proxy-unix149920084/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:44:14.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7972" for this suite.
Aug 14 07:44:20.589: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:44:20.979: INFO: namespace kubectl-7972 deletion completed in 6.423139407s
•SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:44:20.979: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9110
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 14 07:44:21.177: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ae46d0bf-4ea0-4402-9552-276155784532" in namespace "projected-9110" to be "success or failure"
Aug 14 07:44:21.187: INFO: Pod "downwardapi-volume-ae46d0bf-4ea0-4402-9552-276155784532": Phase="Pending", Reason="", readiness=false. Elapsed: 9.810969ms
Aug 14 07:44:23.198: INFO: Pod "downwardapi-volume-ae46d0bf-4ea0-4402-9552-276155784532": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021200887s
STEP: Saw pod success
Aug 14 07:44:23.198: INFO: Pod "downwardapi-volume-ae46d0bf-4ea0-4402-9552-276155784532" satisfied condition "success or failure"
Aug 14 07:44:23.209: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod downwardapi-volume-ae46d0bf-4ea0-4402-9552-276155784532 container client-container: <nil>
STEP: delete the pod
Aug 14 07:44:23.242: INFO: Waiting for pod downwardapi-volume-ae46d0bf-4ea0-4402-9552-276155784532 to disappear
Aug 14 07:44:23.252: INFO: Pod downwardapi-volume-ae46d0bf-4ea0-4402-9552-276155784532 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:44:23.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9110" for this suite.
Aug 14 07:44:29.303: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:44:29.691: INFO: namespace projected-9110 deletion completed in 6.420284419s
•SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:44:29.691: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1678
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 14 07:44:30.068: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-1678'
Aug 14 07:44:30.464: INFO: stderr: ""
Aug 14 07:44:30.464: INFO: stdout: "replicationcontroller/redis-master created\n"
Aug 14 07:44:30.464: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-1678'
Aug 14 07:44:30.842: INFO: stderr: ""
Aug 14 07:44:30.843: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Aug 14 07:44:31.854: INFO: Selector matched 1 pods for map[app:redis]
Aug 14 07:44:31.854: INFO: Found 0 / 1
Aug 14 07:44:32.854: INFO: Selector matched 1 pods for map[app:redis]
Aug 14 07:44:32.854: INFO: Found 1 / 1
Aug 14 07:44:32.854: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug 14 07:44:32.865: INFO: Selector matched 1 pods for map[app:redis]
Aug 14 07:44:32.865: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug 14 07:44:32.865: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config describe pod redis-master-ppdj5 --namespace=kubectl-1678'
Aug 14 07:44:33.107: INFO: stderr: ""
Aug 14 07:44:33.107: INFO: stdout: "Name:           redis-master-ppdj5\nNamespace:      kubectl-1678\nPriority:       0\nNode:           shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp/10.250.0.3\nStart Time:     Wed, 14 Aug 2019 07:44:30 +0000\nLabels:         app=redis\n                role=master\nAnnotations:    cni.projectcalico.org/podIP: 100.96.1.208/32\n                kubernetes.io/psp: e2e-test-privileged-psp\nStatus:         Running\nIP:             100.96.1.208\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://a03ab7a80d993db9caf5419d8fdd0f211ce692425408cbd19a2207119a581551\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 14 Aug 2019 07:44:31 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-48sls (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-48sls:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-48sls\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                                        Message\n  ----    ------     ----  ----                                                        -------\n  Normal  Scheduled  3s    default-scheduler                                           Successfully assigned kubectl-1678/redis-master-ppdj5 to shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp\n  Normal  Pulled     2s    kubelet, shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    2s    kubelet, shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp  Created container redis-master\n  Normal  Started    2s    kubelet, shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp  Started container redis-master\n"
Aug 14 07:44:33.107: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config describe rc redis-master --namespace=kubectl-1678'
Aug 14 07:44:33.358: INFO: stderr: ""
Aug 14 07:44:33.358: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-1678\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-ppdj5\n"
Aug 14 07:44:33.359: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config describe service redis-master --namespace=kubectl-1678'
Aug 14 07:44:33.596: INFO: stderr: ""
Aug 14 07:44:33.596: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-1678\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                100.70.7.18\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         100.96.1.208:6379\nSession Affinity:  None\nEvents:            <none>\n"
Aug 14 07:44:33.615: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config describe node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw'
Aug 14 07:44:33.874: INFO: stderr: ""
Aug 14 07:44:33.874: INFO: stdout: "Name:               shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=n1-standard-4\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=europe-west1\n                    failure-domain.beta.kubernetes.io/zone=europe-west1-b\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw\n                    kubernetes.io/os=linux\n                    node.kubernetes.io/role=node\n                    worker.garden.sapcloud.io/group=cpu-worker\n                    worker.gardener.cloud/pool=cpu-worker\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 10.250.0.2/32\n                    projectcalico.org/IPv4IPIPTunnelAddr: 100.99.44.64\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Wed, 14 Aug 2019 06:26:55 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Wed, 14 Aug 2019 06:27:14 +0000   Wed, 14 Aug 2019 06:27:14 +0000   CalicoIsUp                   Calico is running on this node\n  MemoryPressure       False   Wed, 14 Aug 2019 07:44:32 +0000   Wed, 14 Aug 2019 06:26:55 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Wed, 14 Aug 2019 07:44:32 +0000   Wed, 14 Aug 2019 06:26:55 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Wed, 14 Aug 2019 07:44:32 +0000   Wed, 14 Aug 2019 06:26:55 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Wed, 14 Aug 2019 07:44:32 +0000   Wed, 14 Aug 2019 06:27:05 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:   10.250.0.2\n  ExternalIP:   35.205.63.81\n  InternalDNS:  shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw.c.sap-gcp-k8s-canary-custom.internal\n  Hostname:     shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw.c.sap-gcp-k8s-canary-custom.internal\nCapacity:\n attachable-volumes-gce-pd:  128\n cpu:                        4\n ephemeral-storage:          17897500Ki\n hugepages-1Gi:              0\n hugepages-2Mi:              0\n memory:                     15393528Ki\n pods:                       110\nAllocatable:\n attachable-volumes-gce-pd:  128\n cpu:                        3920m\n ephemeral-storage:          17410687987\n hugepages-1Gi:              0\n hugepages-2Mi:              0\n memory:                     13296376Ki\n pods:                       110\nSystem Info:\n Machine ID:                 d13c66415ba95585953a1ffa6c34394d\n System UUID:                d13c6641-5ba9-5585-953a-1ffa6c34394d\n Boot ID:                    db5ab5dd-efb9-413c-83e7-16f77daf8d9d\n Kernel Version:             4.19.56-coreos-r1\n OS Image:                   Container Linux by CoreOS 2135.6.0 (Rhyolite)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.3\n Kubelet Version:            v1.15.2\n Kube-Proxy Version:         v1.15.2\nPodCIDR:                     100.96.0.0/24\nProviderID:                  gce://sap-gcp-k8s-canary-custom/europe-west1-b/shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw\nNon-terminated Pods:         (12 in total)\n  Namespace                  Name                                                              CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                              ------------  ----------  ---------------  -------------  ---\n  kube-system                addons-kubernetes-dashboard-5c8d9945bc-8t28x                      50m (1%)      100m (2%)   50Mi (0%)        256Mi (1%)     78m\n  kube-system                addons-nginx-ingress-controller-6496d947df-dqs5z                  100m (2%)     2 (51%)     100Mi (0%)       800Mi (6%)     78m\n  kube-system                addons-nginx-ingress-nginx-ingress-k8s-backend-88d6cff74-rw8q9    0 (0%)        0 (0%)      0 (0%)           0 (0%)         78m\n  kube-system                blackbox-exporter-954dd954b-8xcv9                                 5m (0%)       10m (0%)    5Mi (0%)         35Mi (0%)      78m\n  kube-system                calico-kube-controllers-5f4b46ffb5-m6pdj                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         78m\n  kube-system                calico-node-gb7zk                                                 100m (2%)     500m (12%)  100Mi (0%)       700Mi (5%)     77m\n  kube-system                coredns-85cc454dd8-l4hk9                                          50m (1%)      100m (2%)   15Mi (0%)        100Mi (0%)     78m\n  kube-system                coredns-85cc454dd8-zsj57                                          50m (1%)      100m (2%)   15Mi (0%)        100Mi (0%)     77m\n  kube-system                kube-proxy-n2x65                                                  20m (0%)      0 (0%)      64Mi (0%)        0 (0%)         77m\n  kube-system                metrics-server-f5b59f6cc-xc2ch                                    20m (0%)      80m (2%)    100Mi (0%)       400Mi (3%)     78m\n  kube-system                node-exporter-hmlnc                                               5m (0%)       25m (0%)    10Mi (0%)        100Mi (0%)     77m\n  kube-system                vpn-shoot-7d7bc8fd7d-997f6                                        100m (2%)     1 (25%)     100Mi (0%)       1000Mi (7%)    78m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                   Requests    Limits\n  --------                   --------    ------\n  cpu                        500m (12%)  3915m (99%)\n  memory                     559Mi (4%)  3491Mi (26%)\n  ephemeral-storage          0 (0%)      0 (0%)\n  attachable-volumes-gce-pd  0           0\nEvents:                      <none>\n"
Aug 14 07:44:33.874: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config describe namespace kubectl-1678'
Aug 14 07:44:34.109: INFO: stderr: ""
Aug 14 07:44:34.109: INFO: stdout: "Name:         kubectl-1678\nLabels:       e2e-framework=kubectl\n              e2e-run=d3f05482-845a-4a68-9b16-f4516f4d69e1\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:44:34.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1678" for this suite.
Aug 14 07:44:56.162: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:44:56.604: INFO: namespace kubectl-1678 deletion completed in 22.474747947s
•S
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:44:56.604: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9870
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 14 07:44:57.074: INFO: Waiting up to 5m0s for pod "downwardapi-volume-88dbb002-6124-40bf-b0de-30749bc698ac" in namespace "downward-api-9870" to be "success or failure"
Aug 14 07:44:57.084: INFO: Pod "downwardapi-volume-88dbb002-6124-40bf-b0de-30749bc698ac": Phase="Pending", Reason="", readiness=false. Elapsed: 10.685456ms
Aug 14 07:44:59.096: INFO: Pod "downwardapi-volume-88dbb002-6124-40bf-b0de-30749bc698ac": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022530429s
STEP: Saw pod success
Aug 14 07:44:59.096: INFO: Pod "downwardapi-volume-88dbb002-6124-40bf-b0de-30749bc698ac" satisfied condition "success or failure"
Aug 14 07:44:59.107: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod downwardapi-volume-88dbb002-6124-40bf-b0de-30749bc698ac container client-container: <nil>
STEP: delete the pod
Aug 14 07:44:59.141: INFO: Waiting for pod downwardapi-volume-88dbb002-6124-40bf-b0de-30749bc698ac to disappear
Aug 14 07:44:59.152: INFO: Pod downwardapi-volume-88dbb002-6124-40bf-b0de-30749bc698ac no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:44:59.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9870" for this suite.
Aug 14 07:45:05.205: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:45:05.676: INFO: namespace downward-api-9870 deletion completed in 6.504426988s
•SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:45:05.676: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-2837
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Aug 14 07:45:45.952: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
W0814 07:45:45.952877    4167 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 14 07:45:45.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2837" for this suite.
Aug 14 07:45:51.996: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:45:52.433: INFO: namespace gc-2837 deletion completed in 6.469529215s
•SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:45:52.434: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-8278
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Aug 14 07:46:02.832: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0814 07:46:02.832312    4167 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:46:02.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8278" for this suite.
Aug 14 07:46:08.876: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:46:09.278: INFO: namespace gc-8278 deletion completed in 6.435283694s
•SSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:46:09.279: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-9702
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:46:09.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9702" for this suite.
Aug 14 07:46:15.621: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:46:16.018: INFO: namespace services-9702 deletion completed in 6.430496528s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92
•SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:46:16.018: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5800
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 14 07:46:16.369: INFO: Waiting up to 5m0s for pod "downwardapi-volume-191dbb73-71fb-4a87-a130-b9161ae3f7a2" in namespace "projected-5800" to be "success or failure"
Aug 14 07:46:16.379: INFO: Pod "downwardapi-volume-191dbb73-71fb-4a87-a130-b9161ae3f7a2": Phase="Pending", Reason="", readiness=false. Elapsed: 10.035581ms
Aug 14 07:46:18.390: INFO: Pod "downwardapi-volume-191dbb73-71fb-4a87-a130-b9161ae3f7a2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02064789s
STEP: Saw pod success
Aug 14 07:46:18.390: INFO: Pod "downwardapi-volume-191dbb73-71fb-4a87-a130-b9161ae3f7a2" satisfied condition "success or failure"
Aug 14 07:46:18.401: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod downwardapi-volume-191dbb73-71fb-4a87-a130-b9161ae3f7a2 container client-container: <nil>
STEP: delete the pod
Aug 14 07:46:18.437: INFO: Waiting for pod downwardapi-volume-191dbb73-71fb-4a87-a130-b9161ae3f7a2 to disappear
Aug 14 07:46:18.447: INFO: Pod downwardapi-volume-191dbb73-71fb-4a87-a130-b9161ae3f7a2 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:46:18.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5800" for this suite.
Aug 14 07:46:24.504: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:46:24.900: INFO: namespace projected-5800 deletion completed in 6.431222363s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:46:24.901: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7085
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 14 07:46:25.270: INFO: Waiting up to 5m0s for pod "downwardapi-volume-07dbb93a-37f4-4df8-91de-95512bc9c941" in namespace "projected-7085" to be "success or failure"
Aug 14 07:46:25.280: INFO: Pod "downwardapi-volume-07dbb93a-37f4-4df8-91de-95512bc9c941": Phase="Pending", Reason="", readiness=false. Elapsed: 10.03262ms
Aug 14 07:46:27.291: INFO: Pod "downwardapi-volume-07dbb93a-37f4-4df8-91de-95512bc9c941": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021551822s
STEP: Saw pod success
Aug 14 07:46:27.292: INFO: Pod "downwardapi-volume-07dbb93a-37f4-4df8-91de-95512bc9c941" satisfied condition "success or failure"
Aug 14 07:46:27.302: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod downwardapi-volume-07dbb93a-37f4-4df8-91de-95512bc9c941 container client-container: <nil>
STEP: delete the pod
Aug 14 07:46:27.340: INFO: Waiting for pod downwardapi-volume-07dbb93a-37f4-4df8-91de-95512bc9c941 to disappear
Aug 14 07:46:27.350: INFO: Pod downwardapi-volume-07dbb93a-37f4-4df8-91de-95512bc9c941 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:46:27.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7085" for this suite.
Aug 14 07:46:33.402: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:46:33.790: INFO: namespace projected-7085 deletion completed in 6.421105139s
•SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:46:33.791: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-7176
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Aug 14 07:46:34.202: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-7176,SelfLink:/api/v1/namespaces/watch-7176/configmaps/e2e-watch-test-watch-closed,UID:e16595d2-5435-4fa2-ad06-9d125daa8560,ResourceVersion:20492,Generation:0,CreationTimestamp:2019-08-14 07:46:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 14 07:46:34.202: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-7176,SelfLink:/api/v1/namespaces/watch-7176/configmaps/e2e-watch-test-watch-closed,UID:e16595d2-5435-4fa2-ad06-9d125daa8560,ResourceVersion:20494,Generation:0,CreationTimestamp:2019-08-14 07:46:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Aug 14 07:46:34.246: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-7176,SelfLink:/api/v1/namespaces/watch-7176/configmaps/e2e-watch-test-watch-closed,UID:e16595d2-5435-4fa2-ad06-9d125daa8560,ResourceVersion:20495,Generation:0,CreationTimestamp:2019-08-14 07:46:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 14 07:46:34.246: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-7176,SelfLink:/api/v1/namespaces/watch-7176/configmaps/e2e-watch-test-watch-closed,UID:e16595d2-5435-4fa2-ad06-9d125daa8560,ResourceVersion:20496,Generation:0,CreationTimestamp:2019-08-14 07:46:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:46:34.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7176" for this suite.
Aug 14 07:46:40.291: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:46:40.677: INFO: namespace watch-7176 deletion completed in 6.418587505s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:46:40.679: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-7618
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:47:40.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7618" for this suite.
Aug 14 07:48:03.030: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:48:03.460: INFO: namespace container-probe-7618 deletion completed in 22.462139546s
•SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:48:03.461: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9909
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Aug 14 07:48:03.665: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-9909'
Aug 14 07:48:04.055: INFO: stderr: ""
Aug 14 07:48:04.055: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 14 07:48:04.055: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9909'
Aug 14 07:48:04.218: INFO: stderr: ""
Aug 14 07:48:04.218: INFO: stdout: "update-demo-nautilus-22gkc update-demo-nautilus-8gm29 "
Aug 14 07:48:04.218: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-22gkc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9909'
Aug 14 07:48:04.382: INFO: stderr: ""
Aug 14 07:48:04.382: INFO: stdout: ""
Aug 14 07:48:04.382: INFO: update-demo-nautilus-22gkc is created but not running
Aug 14 07:48:09.382: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9909'
Aug 14 07:48:09.553: INFO: stderr: ""
Aug 14 07:48:09.553: INFO: stdout: "update-demo-nautilus-22gkc update-demo-nautilus-8gm29 "
Aug 14 07:48:09.553: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-22gkc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9909'
Aug 14 07:48:09.715: INFO: stderr: ""
Aug 14 07:48:09.715: INFO: stdout: "true"
Aug 14 07:48:09.715: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-22gkc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9909'
Aug 14 07:48:09.877: INFO: stderr: ""
Aug 14 07:48:09.877: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 14 07:48:09.877: INFO: validating pod update-demo-nautilus-22gkc
Aug 14 07:48:09.972: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 14 07:48:09.972: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 14 07:48:09.972: INFO: update-demo-nautilus-22gkc is verified up and running
Aug 14 07:48:09.972: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-8gm29 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9909'
Aug 14 07:48:10.144: INFO: stderr: ""
Aug 14 07:48:10.144: INFO: stdout: "true"
Aug 14 07:48:10.144: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-8gm29 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9909'
Aug 14 07:48:10.307: INFO: stderr: ""
Aug 14 07:48:10.307: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 14 07:48:10.307: INFO: validating pod update-demo-nautilus-8gm29
Aug 14 07:48:10.403: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 14 07:48:10.403: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 14 07:48:10.403: INFO: update-demo-nautilus-8gm29 is verified up and running
STEP: scaling down the replication controller
Aug 14 07:48:10.406: INFO: scanned /root for discovery docs: <nil>
Aug 14 07:48:10.406: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-9909'
Aug 14 07:48:10.654: INFO: stderr: ""
Aug 14 07:48:10.654: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 14 07:48:10.654: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9909'
Aug 14 07:48:10.826: INFO: stderr: ""
Aug 14 07:48:10.826: INFO: stdout: "update-demo-nautilus-22gkc update-demo-nautilus-8gm29 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Aug 14 07:48:15.826: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9909'
Aug 14 07:48:16.039: INFO: stderr: ""
Aug 14 07:48:16.039: INFO: stdout: "update-demo-nautilus-22gkc "
Aug 14 07:48:16.039: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-22gkc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9909'
Aug 14 07:48:16.259: INFO: stderr: ""
Aug 14 07:48:16.259: INFO: stdout: "true"
Aug 14 07:48:16.259: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-22gkc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9909'
Aug 14 07:48:16.435: INFO: stderr: ""
Aug 14 07:48:16.435: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 14 07:48:16.435: INFO: validating pod update-demo-nautilus-22gkc
Aug 14 07:48:16.447: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 14 07:48:16.447: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 14 07:48:16.447: INFO: update-demo-nautilus-22gkc is verified up and running
STEP: scaling up the replication controller
Aug 14 07:48:16.450: INFO: scanned /root for discovery docs: <nil>
Aug 14 07:48:16.450: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-9909'
Aug 14 07:48:16.663: INFO: stderr: ""
Aug 14 07:48:16.664: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 14 07:48:16.664: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9909'
Aug 14 07:48:16.832: INFO: stderr: ""
Aug 14 07:48:16.832: INFO: stdout: "update-demo-nautilus-22gkc update-demo-nautilus-xkfsf "
Aug 14 07:48:16.832: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-22gkc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9909'
Aug 14 07:48:16.983: INFO: stderr: ""
Aug 14 07:48:16.983: INFO: stdout: "true"
Aug 14 07:48:16.983: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-22gkc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9909'
Aug 14 07:48:17.152: INFO: stderr: ""
Aug 14 07:48:17.152: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 14 07:48:17.152: INFO: validating pod update-demo-nautilus-22gkc
Aug 14 07:48:17.165: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 14 07:48:17.165: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 14 07:48:17.165: INFO: update-demo-nautilus-22gkc is verified up and running
Aug 14 07:48:17.165: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-xkfsf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9909'
Aug 14 07:48:17.340: INFO: stderr: ""
Aug 14 07:48:17.340: INFO: stdout: ""
Aug 14 07:48:17.340: INFO: update-demo-nautilus-xkfsf is created but not running
Aug 14 07:48:22.340: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9909'
Aug 14 07:48:22.490: INFO: stderr: ""
Aug 14 07:48:22.490: INFO: stdout: "update-demo-nautilus-22gkc update-demo-nautilus-xkfsf "
Aug 14 07:48:22.490: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-22gkc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9909'
Aug 14 07:48:22.650: INFO: stderr: ""
Aug 14 07:48:22.650: INFO: stdout: "true"
Aug 14 07:48:22.650: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-22gkc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9909'
Aug 14 07:48:22.807: INFO: stderr: ""
Aug 14 07:48:22.807: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 14 07:48:22.807: INFO: validating pod update-demo-nautilus-22gkc
Aug 14 07:48:22.822: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 14 07:48:22.822: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 14 07:48:22.822: INFO: update-demo-nautilus-22gkc is verified up and running
Aug 14 07:48:22.822: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-xkfsf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9909'
Aug 14 07:48:22.978: INFO: stderr: ""
Aug 14 07:48:22.978: INFO: stdout: "true"
Aug 14 07:48:22.978: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-xkfsf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9909'
Aug 14 07:48:23.152: INFO: stderr: ""
Aug 14 07:48:23.153: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 14 07:48:23.153: INFO: validating pod update-demo-nautilus-xkfsf
Aug 14 07:48:23.249: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 14 07:48:23.249: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 14 07:48:23.249: INFO: update-demo-nautilus-xkfsf is verified up and running
STEP: using delete to clean up resources
Aug 14 07:48:23.249: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-9909'
Aug 14 07:48:23.452: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 14 07:48:23.452: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Aug 14 07:48:23.452: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get rc,svc -l name=update-demo --no-headers --namespace=kubectl-9909'
Aug 14 07:48:23.641: INFO: stderr: "No resources found.\n"
Aug 14 07:48:23.641: INFO: stdout: ""
Aug 14 07:48:23.641: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -l name=update-demo --namespace=kubectl-9909 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 14 07:48:23.796: INFO: stderr: ""
Aug 14 07:48:23.797: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:48:23.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9909" for this suite.
Aug 14 07:48:45.850: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:48:46.247: INFO: namespace kubectl-9909 deletion completed in 22.430699458s
•SSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:48:46.247: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-1972
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-secret-jq9z
STEP: Creating a pod to test atomic-volume-subpath
Aug 14 07:48:46.503: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-jq9z" in namespace "subpath-1972" to be "success or failure"
Aug 14 07:48:46.514: INFO: Pod "pod-subpath-test-secret-jq9z": Phase="Pending", Reason="", readiness=false. Elapsed: 11.243631ms
Aug 14 07:48:48.526: INFO: Pod "pod-subpath-test-secret-jq9z": Phase="Running", Reason="", readiness=true. Elapsed: 2.022680644s
Aug 14 07:48:50.537: INFO: Pod "pod-subpath-test-secret-jq9z": Phase="Running", Reason="", readiness=true. Elapsed: 4.033789519s
Aug 14 07:48:52.548: INFO: Pod "pod-subpath-test-secret-jq9z": Phase="Running", Reason="", readiness=true. Elapsed: 6.044791295s
Aug 14 07:48:54.559: INFO: Pod "pod-subpath-test-secret-jq9z": Phase="Running", Reason="", readiness=true. Elapsed: 8.055792879s
Aug 14 07:48:56.571: INFO: Pod "pod-subpath-test-secret-jq9z": Phase="Running", Reason="", readiness=true. Elapsed: 10.067844383s
Aug 14 07:48:58.582: INFO: Pod "pod-subpath-test-secret-jq9z": Phase="Running", Reason="", readiness=true. Elapsed: 12.079652664s
Aug 14 07:49:00.594: INFO: Pod "pod-subpath-test-secret-jq9z": Phase="Running", Reason="", readiness=true. Elapsed: 14.091408663s
Aug 14 07:49:02.606: INFO: Pod "pod-subpath-test-secret-jq9z": Phase="Running", Reason="", readiness=true. Elapsed: 16.102813575s
Aug 14 07:49:04.617: INFO: Pod "pod-subpath-test-secret-jq9z": Phase="Running", Reason="", readiness=true. Elapsed: 18.114507617s
Aug 14 07:49:06.629: INFO: Pod "pod-subpath-test-secret-jq9z": Phase="Running", Reason="", readiness=true. Elapsed: 20.125900433s
Aug 14 07:49:08.640: INFO: Pod "pod-subpath-test-secret-jq9z": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.137076705s
STEP: Saw pod success
Aug 14 07:49:08.640: INFO: Pod "pod-subpath-test-secret-jq9z" satisfied condition "success or failure"
Aug 14 07:49:08.650: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod pod-subpath-test-secret-jq9z container test-container-subpath-secret-jq9z: <nil>
STEP: delete the pod
Aug 14 07:49:08.682: INFO: Waiting for pod pod-subpath-test-secret-jq9z to disappear
Aug 14 07:49:08.692: INFO: Pod pod-subpath-test-secret-jq9z no longer exists
STEP: Deleting pod pod-subpath-test-secret-jq9z
Aug 14 07:49:08.692: INFO: Deleting pod "pod-subpath-test-secret-jq9z" in namespace "subpath-1972"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:49:08.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1972" for this suite.
Aug 14 07:49:16.754: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:49:17.141: INFO: namespace subpath-1972 deletion completed in 8.420091025s
•SSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:49:17.142: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-2050
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-2050
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 14 07:49:17.366: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug 14 07:49:37.555: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.96.1.224 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2050 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 07:49:37.555: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Aug 14 07:49:39.001: INFO: Found all expected endpoints: [netserver-0]
Aug 14 07:49:39.012: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.96.0.77 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2050 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 14 07:49:39.012: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Aug 14 07:49:40.464: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:49:40.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-2050" for this suite.
Aug 14 07:50:02.518: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:50:02.939: INFO: namespace pod-network-test-2050 deletion completed in 22.454528898s
•SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:50:02.939: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-1048
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 14 07:50:03.249: INFO: Creating deployment "test-recreate-deployment"
Aug 14 07:50:03.260: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Aug 14 07:50:03.280: INFO: Waiting deployment "test-recreate-deployment" to complete
Aug 14 07:50:03.290: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701365803, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701365803, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701365803, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701365803, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-6df85df6b9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 14 07:50:05.305: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Aug 14 07:50:05.327: INFO: Updating deployment test-recreate-deployment
Aug 14 07:50:05.327: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Aug 14 07:50:05.832: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-1048,SelfLink:/apis/apps/v1/namespaces/deployment-1048/deployments/test-recreate-deployment,UID:13e661fd-8bfd-4d97-8cf5-a466c3979fe6,ResourceVersion:21249,Generation:2,CreationTimestamp:2019-08-14 07:50:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-08-14 07:50:05 +0000 UTC 2019-08-14 07:50:05 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-08-14 07:50:05 +0000 UTC 2019-08-14 07:50:03 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-5c8c9cc69d" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Aug 14 07:50:05.843: INFO: New ReplicaSet "test-recreate-deployment-5c8c9cc69d" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d,GenerateName:,Namespace:deployment-1048,SelfLink:/apis/apps/v1/namespaces/deployment-1048/replicasets/test-recreate-deployment-5c8c9cc69d,UID:9ccd796f-ea42-4376-ac57-1816d032847d,ResourceVersion:21248,Generation:1,CreationTimestamp:2019-08-14 07:50:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 13e661fd-8bfd-4d97-8cf5-a466c3979fe6 0xc003311317 0xc003311318}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 14 07:50:05.843: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Aug 14 07:50:05.843: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-6df85df6b9,GenerateName:,Namespace:deployment-1048,SelfLink:/apis/apps/v1/namespaces/deployment-1048/replicasets/test-recreate-deployment-6df85df6b9,UID:321777c5-cd90-4707-a6ae-c4ede9446346,ResourceVersion:21240,Generation:2,CreationTimestamp:2019-08-14 07:50:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 13e661fd-8bfd-4d97-8cf5-a466c3979fe6 0xc0033113e7 0xc0033113e8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 14 07:50:05.855: INFO: Pod "test-recreate-deployment-5c8c9cc69d-fxxgn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d-fxxgn,GenerateName:test-recreate-deployment-5c8c9cc69d-,Namespace:deployment-1048,SelfLink:/api/v1/namespaces/deployment-1048/pods/test-recreate-deployment-5c8c9cc69d-fxxgn,UID:96274c47-9fcd-4687-8b9f-b9c33ffcd19b,ResourceVersion:21244,Generation:0,CreationTimestamp:2019-08-14 07:50:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-5c8c9cc69d 9ccd796f-ea42-4376-ac57-1816d032847d 0xc003311ce7 0xc003311ce8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-dzbfj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dzbfj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dzbfj true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003311d50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003311d70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:50:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:50:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:50:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 07:50:05 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:,StartTime:2019-08-14 07:50:05 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:50:05.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1048" for this suite.
Aug 14 07:50:11.908: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:50:12.317: INFO: namespace deployment-1048 deletion completed in 6.443727112s
•SSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:50:12.318: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-9679
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Aug 14 07:50:12.734: INFO: Number of nodes with available pods: 0
Aug 14 07:50:12.734: INFO: Node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw is running more than one daemon pod
Aug 14 07:50:13.765: INFO: Number of nodes with available pods: 1
Aug 14 07:50:13.765: INFO: Node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp is running more than one daemon pod
Aug 14 07:50:14.765: INFO: Number of nodes with available pods: 2
Aug 14 07:50:14.765: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Aug 14 07:50:14.830: INFO: Number of nodes with available pods: 1
Aug 14 07:50:14.830: INFO: Node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw is running more than one daemon pod
Aug 14 07:50:15.860: INFO: Number of nodes with available pods: 1
Aug 14 07:50:15.860: INFO: Node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw is running more than one daemon pod
Aug 14 07:50:16.860: INFO: Number of nodes with available pods: 1
Aug 14 07:50:16.860: INFO: Node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw is running more than one daemon pod
Aug 14 07:50:17.860: INFO: Number of nodes with available pods: 1
Aug 14 07:50:17.860: INFO: Node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw is running more than one daemon pod
Aug 14 07:50:18.864: INFO: Number of nodes with available pods: 2
Aug 14 07:50:18.864: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9679, will wait for the garbage collector to delete the pods
Aug 14 07:50:18.949: INFO: Deleting DaemonSet.extensions daemon-set took: 13.463433ms
Aug 14 07:50:19.049: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.252936ms
Aug 14 07:50:25.460: INFO: Number of nodes with available pods: 0
Aug 14 07:50:25.460: INFO: Number of running nodes: 0, number of available pods: 0
Aug 14 07:50:25.471: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9679/daemonsets","resourceVersion":"21350"},"items":null}

Aug 14 07:50:25.482: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9679/pods","resourceVersion":"21350"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:50:25.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9679" for this suite.
Aug 14 07:50:31.594: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:50:31.976: INFO: namespace daemonsets-9679 deletion completed in 6.416657801s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:50:31.976: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-6200
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating server pod server in namespace prestop-6200
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-6200
STEP: Deleting pre-stop pod
Aug 14 07:50:43.437: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:50:43.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-6200" for this suite.
Aug 14 07:51:19.502: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:51:19.888: INFO: namespace prestop-6200 deletion completed in 36.420092936s
•SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:51:19.888: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-4056
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Aug 14 07:51:30.457: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
W0814 07:51:30.457860    4167 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 14 07:51:30.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4056" for this suite.
Aug 14 07:51:38.502: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:51:38.895: INFO: namespace gc-4056 deletion completed in 8.426246396s
•SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:51:38.895: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3549
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 14 07:51:39.268: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a2d40c9f-f55f-4476-ad96-134b987f6ecd" in namespace "projected-3549" to be "success or failure"
Aug 14 07:51:39.277: INFO: Pod "downwardapi-volume-a2d40c9f-f55f-4476-ad96-134b987f6ecd": Phase="Pending", Reason="", readiness=false. Elapsed: 9.766826ms
Aug 14 07:51:41.289: INFO: Pod "downwardapi-volume-a2d40c9f-f55f-4476-ad96-134b987f6ecd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021324294s
STEP: Saw pod success
Aug 14 07:51:41.289: INFO: Pod "downwardapi-volume-a2d40c9f-f55f-4476-ad96-134b987f6ecd" satisfied condition "success or failure"
Aug 14 07:51:41.300: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod downwardapi-volume-a2d40c9f-f55f-4476-ad96-134b987f6ecd container client-container: <nil>
STEP: delete the pod
Aug 14 07:51:41.337: INFO: Waiting for pod downwardapi-volume-a2d40c9f-f55f-4476-ad96-134b987f6ecd to disappear
Aug 14 07:51:41.348: INFO: Pod downwardapi-volume-a2d40c9f-f55f-4476-ad96-134b987f6ecd no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:51:41.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3549" for this suite.
Aug 14 07:51:47.403: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:51:47.788: INFO: namespace projected-3549 deletion completed in 6.421564404s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:51:47.789: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-8694
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-bj55
STEP: Creating a pod to test atomic-volume-subpath
Aug 14 07:51:48.185: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-bj55" in namespace "subpath-8694" to be "success or failure"
Aug 14 07:51:48.195: INFO: Pod "pod-subpath-test-configmap-bj55": Phase="Pending", Reason="", readiness=false. Elapsed: 9.91505ms
Aug 14 07:51:50.207: INFO: Pod "pod-subpath-test-configmap-bj55": Phase="Running", Reason="", readiness=true. Elapsed: 2.021502909s
Aug 14 07:51:52.220: INFO: Pod "pod-subpath-test-configmap-bj55": Phase="Running", Reason="", readiness=true. Elapsed: 4.034054227s
Aug 14 07:51:54.231: INFO: Pod "pod-subpath-test-configmap-bj55": Phase="Running", Reason="", readiness=true. Elapsed: 6.045124933s
Aug 14 07:51:56.242: INFO: Pod "pod-subpath-test-configmap-bj55": Phase="Running", Reason="", readiness=true. Elapsed: 8.056162779s
Aug 14 07:51:58.253: INFO: Pod "pod-subpath-test-configmap-bj55": Phase="Running", Reason="", readiness=true. Elapsed: 10.067350582s
Aug 14 07:52:00.265: INFO: Pod "pod-subpath-test-configmap-bj55": Phase="Running", Reason="", readiness=true. Elapsed: 12.079222841s
Aug 14 07:52:02.276: INFO: Pod "pod-subpath-test-configmap-bj55": Phase="Running", Reason="", readiness=true. Elapsed: 14.090453503s
Aug 14 07:52:04.287: INFO: Pod "pod-subpath-test-configmap-bj55": Phase="Running", Reason="", readiness=true. Elapsed: 16.10187805s
Aug 14 07:52:06.302: INFO: Pod "pod-subpath-test-configmap-bj55": Phase="Running", Reason="", readiness=true. Elapsed: 18.116056667s
Aug 14 07:52:08.313: INFO: Pod "pod-subpath-test-configmap-bj55": Phase="Running", Reason="", readiness=true. Elapsed: 20.127534466s
Aug 14 07:52:10.325: INFO: Pod "pod-subpath-test-configmap-bj55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.138939985s
STEP: Saw pod success
Aug 14 07:52:10.325: INFO: Pod "pod-subpath-test-configmap-bj55" satisfied condition "success or failure"
Aug 14 07:52:10.335: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod pod-subpath-test-configmap-bj55 container test-container-subpath-configmap-bj55: <nil>
STEP: delete the pod
Aug 14 07:52:10.374: INFO: Waiting for pod pod-subpath-test-configmap-bj55 to disappear
Aug 14 07:52:10.385: INFO: Pod pod-subpath-test-configmap-bj55 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-bj55
Aug 14 07:52:10.385: INFO: Deleting pod "pod-subpath-test-configmap-bj55" in namespace "subpath-8694"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:52:10.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8694" for this suite.
Aug 14 07:52:16.447: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:52:16.831: INFO: namespace subpath-8694 deletion completed in 6.417289033s
•SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:52:16.831: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7404
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Aug 14 07:52:17.170: INFO: Waiting up to 5m0s for pod "pod-4ed2dd67-4371-4b3e-96ac-4d4bff587996" in namespace "emptydir-7404" to be "success or failure"
Aug 14 07:52:17.181: INFO: Pod "pod-4ed2dd67-4371-4b3e-96ac-4d4bff587996": Phase="Pending", Reason="", readiness=false. Elapsed: 10.23915ms
Aug 14 07:52:19.192: INFO: Pod "pod-4ed2dd67-4371-4b3e-96ac-4d4bff587996": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021409736s
STEP: Saw pod success
Aug 14 07:52:19.192: INFO: Pod "pod-4ed2dd67-4371-4b3e-96ac-4d4bff587996" satisfied condition "success or failure"
Aug 14 07:52:19.203: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod pod-4ed2dd67-4371-4b3e-96ac-4d4bff587996 container test-container: <nil>
STEP: delete the pod
Aug 14 07:52:19.237: INFO: Waiting for pod pod-4ed2dd67-4371-4b3e-96ac-4d4bff587996 to disappear
Aug 14 07:52:19.247: INFO: Pod pod-4ed2dd67-4371-4b3e-96ac-4d4bff587996 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:52:19.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7404" for this suite.
Aug 14 07:52:25.305: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:52:26.286: INFO: namespace emptydir-7404 deletion completed in 7.021038118s
•SSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:52:26.287: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-8128
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod test-webserver-dcdc3db6-91d9-4413-b5c5-8e46106428ff in namespace container-probe-8128
Aug 14 07:52:28.593: INFO: Started pod test-webserver-dcdc3db6-91d9-4413-b5c5-8e46106428ff in namespace container-probe-8128
STEP: checking the pod's current state and verifying that restartCount is present
Aug 14 07:52:28.604: INFO: Initial restart count of pod test-webserver-dcdc3db6-91d9-4413-b5c5-8e46106428ff is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:56:30.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8128" for this suite.
Aug 14 07:56:36.399: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:56:37.572: INFO: namespace container-probe-8128 deletion completed in 7.327671915s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:56:37.572: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-8534
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Aug 14 07:56:46.449: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 14 07:56:46.472: INFO: Pod pod-with-poststart-http-hook still exists
Aug 14 07:56:48.472: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 14 07:56:48.570: INFO: Pod pod-with-poststart-http-hook still exists
Aug 14 07:56:50.472: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 14 07:56:50.532: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:56:50.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8534" for this suite.
Aug 14 07:57:38.677: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:57:39.494: INFO: namespace container-lifecycle-hook-8534 deletion completed in 48.898992985s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:57:39.494: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-1776
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 14 07:57:39.975: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Aug 14 07:57:40.010: INFO: Number of nodes with available pods: 0
Aug 14 07:57:40.010: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Aug 14 07:57:40.077: INFO: Number of nodes with available pods: 0
Aug 14 07:57:40.077: INFO: Node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw is running more than one daemon pod
Aug 14 07:57:41.103: INFO: Number of nodes with available pods: 0
Aug 14 07:57:41.103: INFO: Node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw is running more than one daemon pod
Aug 14 07:57:42.093: INFO: Number of nodes with available pods: 1
Aug 14 07:57:42.093: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Aug 14 07:57:42.179: INFO: Number of nodes with available pods: 0
Aug 14 07:57:42.179: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Aug 14 07:57:42.240: INFO: Number of nodes with available pods: 0
Aug 14 07:57:42.240: INFO: Node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw is running more than one daemon pod
Aug 14 07:57:43.261: INFO: Number of nodes with available pods: 0
Aug 14 07:57:43.261: INFO: Node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw is running more than one daemon pod
Aug 14 07:57:44.263: INFO: Number of nodes with available pods: 0
Aug 14 07:57:44.263: INFO: Node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw is running more than one daemon pod
Aug 14 07:57:45.260: INFO: Number of nodes with available pods: 0
Aug 14 07:57:45.260: INFO: Node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw is running more than one daemon pod
Aug 14 07:57:46.264: INFO: Number of nodes with available pods: 0
Aug 14 07:57:46.264: INFO: Node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw is running more than one daemon pod
Aug 14 07:57:47.256: INFO: Number of nodes with available pods: 0
Aug 14 07:57:47.256: INFO: Node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw is running more than one daemon pod
Aug 14 07:57:48.313: INFO: Number of nodes with available pods: 1
Aug 14 07:57:48.313: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1776, will wait for the garbage collector to delete the pods
Aug 14 07:57:48.535: INFO: Deleting DaemonSet.extensions daemon-set took: 30.611597ms
Aug 14 07:57:48.635: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.337252ms
Aug 14 07:57:52.264: INFO: Number of nodes with available pods: 0
Aug 14 07:57:52.264: INFO: Number of running nodes: 0, number of available pods: 0
Aug 14 07:57:52.304: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1776/daemonsets","resourceVersion":"22889"},"items":null}

Aug 14 07:57:52.329: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1776/pods","resourceVersion":"22889"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:57:52.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1776" for this suite.
Aug 14 07:58:00.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:58:01.561: INFO: namespace daemonsets-1776 deletion completed in 9.05516159s
•SSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:58:01.561: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2416
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 14 07:58:01.816: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:58:03.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2416" for this suite.
Aug 14 07:58:44.134: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:58:45.632: INFO: namespace pods-2416 deletion completed in 41.618818456s
•SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:58:45.632: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-204
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Aug 14 07:58:46.252: INFO: Waiting up to 5m0s for pod "pod-cb149812-3372-4f54-97a4-6f67b812bfe9" in namespace "emptydir-204" to be "success or failure"
Aug 14 07:58:46.314: INFO: Pod "pod-cb149812-3372-4f54-97a4-6f67b812bfe9": Phase="Pending", Reason="", readiness=false. Elapsed: 62.234991ms
Aug 14 07:58:48.348: INFO: Pod "pod-cb149812-3372-4f54-97a4-6f67b812bfe9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.096550923s
STEP: Saw pod success
Aug 14 07:58:48.348: INFO: Pod "pod-cb149812-3372-4f54-97a4-6f67b812bfe9" satisfied condition "success or failure"
Aug 14 07:58:48.376: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod pod-cb149812-3372-4f54-97a4-6f67b812bfe9 container test-container: <nil>
STEP: delete the pod
Aug 14 07:58:48.515: INFO: Waiting for pod pod-cb149812-3372-4f54-97a4-6f67b812bfe9 to disappear
Aug 14 07:58:48.556: INFO: Pod pod-cb149812-3372-4f54-97a4-6f67b812bfe9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:58:48.556: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-204" for this suite.
Aug 14 07:58:56.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:58:58.139: INFO: namespace emptydir-204 deletion completed in 9.526494774s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:58:58.140: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-4615
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:58:58.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4615" for this suite.
Aug 14 07:59:06.970: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:59:08.401: INFO: namespace kubelet-test-4615 deletion completed in 9.590849759s
•SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:59:08.402: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5700
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Aug 14 07:59:08.921: INFO: Waiting up to 5m0s for pod "pod-557f2b50-9ddd-4868-a6cf-95431cdffb96" in namespace "emptydir-5700" to be "success or failure"
Aug 14 07:59:08.959: INFO: Pod "pod-557f2b50-9ddd-4868-a6cf-95431cdffb96": Phase="Pending", Reason="", readiness=false. Elapsed: 38.357637ms
Aug 14 07:59:11.039: INFO: Pod "pod-557f2b50-9ddd-4868-a6cf-95431cdffb96": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.117615862s
STEP: Saw pod success
Aug 14 07:59:11.039: INFO: Pod "pod-557f2b50-9ddd-4868-a6cf-95431cdffb96" satisfied condition "success or failure"
Aug 14 07:59:11.062: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod pod-557f2b50-9ddd-4868-a6cf-95431cdffb96 container test-container: <nil>
STEP: delete the pod
Aug 14 07:59:11.245: INFO: Waiting for pod pod-557f2b50-9ddd-4868-a6cf-95431cdffb96 to disappear
Aug 14 07:59:11.310: INFO: Pod pod-557f2b50-9ddd-4868-a6cf-95431cdffb96 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:59:11.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5700" for this suite.
Aug 14 07:59:19.583: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:59:20.775: INFO: namespace emptydir-5700 deletion completed in 9.340563826s
•SSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:59:20.775: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6558
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Aug 14 07:59:26.037: INFO: Successfully updated pod "labelsupdate710db421-de9d-470e-940b-a63dd1d6195b"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:59:28.195: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6558" for this suite.
Aug 14 07:59:52.437: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 07:59:53.456: INFO: namespace downward-api-6558 deletion completed in 25.180813939s
•SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 07:59:53.456: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1892
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-7d9e3a60-25ac-4a68-a210-0d304049d841
STEP: Creating a pod to test consume configMaps
Aug 14 07:59:54.053: INFO: Waiting up to 5m0s for pod "pod-configmaps-54f135e2-4978-4a6c-8a90-e8bda0109fd5" in namespace "configmap-1892" to be "success or failure"
Aug 14 07:59:54.125: INFO: Pod "pod-configmaps-54f135e2-4978-4a6c-8a90-e8bda0109fd5": Phase="Pending", Reason="", readiness=false. Elapsed: 71.488834ms
Aug 14 07:59:56.156: INFO: Pod "pod-configmaps-54f135e2-4978-4a6c-8a90-e8bda0109fd5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.102540493s
STEP: Saw pod success
Aug 14 07:59:56.156: INFO: Pod "pod-configmaps-54f135e2-4978-4a6c-8a90-e8bda0109fd5" satisfied condition "success or failure"
Aug 14 07:59:56.178: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod pod-configmaps-54f135e2-4978-4a6c-8a90-e8bda0109fd5 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 14 07:59:56.291: INFO: Waiting for pod pod-configmaps-54f135e2-4978-4a6c-8a90-e8bda0109fd5 to disappear
Aug 14 07:59:56.314: INFO: Pod pod-configmaps-54f135e2-4978-4a6c-8a90-e8bda0109fd5 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 07:59:56.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1892" for this suite.
Aug 14 08:00:04.429: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 08:00:05.167: INFO: namespace configmap-1892 deletion completed in 8.809022016s
•SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 08:00:05.168: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7494
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 14 08:00:05.631: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3992f329-28e9-4e97-8d15-042d8aa3659e" in namespace "downward-api-7494" to be "success or failure"
Aug 14 08:00:05.691: INFO: Pod "downwardapi-volume-3992f329-28e9-4e97-8d15-042d8aa3659e": Phase="Pending", Reason="", readiness=false. Elapsed: 60.279823ms
Aug 14 08:00:07.712: INFO: Pod "downwardapi-volume-3992f329-28e9-4e97-8d15-042d8aa3659e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.081147417s
STEP: Saw pod success
Aug 14 08:00:07.712: INFO: Pod "downwardapi-volume-3992f329-28e9-4e97-8d15-042d8aa3659e" satisfied condition "success or failure"
Aug 14 08:00:07.732: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod downwardapi-volume-3992f329-28e9-4e97-8d15-042d8aa3659e container client-container: <nil>
STEP: delete the pod
Aug 14 08:00:07.860: INFO: Waiting for pod downwardapi-volume-3992f329-28e9-4e97-8d15-042d8aa3659e to disappear
Aug 14 08:00:07.876: INFO: Pod downwardapi-volume-3992f329-28e9-4e97-8d15-042d8aa3659e no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 08:00:07.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7494" for this suite.
Aug 14 08:00:14.000: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 08:00:14.661: INFO: namespace downward-api-7494 deletion completed in 6.757097975s
•SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 08:00:14.662: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6744
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name secret-emptykey-test-99ad78aa-d5ad-4297-8fe6-f8707d184e7e
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 08:00:14.999: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6744" for this suite.
Aug 14 08:00:21.108: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 08:00:21.798: INFO: namespace secrets-6744 deletion completed in 6.773191477s
•SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 08:00:21.798: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-3073
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Aug 14 08:00:24.349: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 08:00:24.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3073" for this suite.
Aug 14 08:00:30.539: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 08:00:31.267: INFO: namespace container-runtime-3073 deletion completed in 6.793295641s
•SSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 08:00:31.267: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-4389
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Aug 14 08:00:31.612: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 08:00:35.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4389" for this suite.
Aug 14 08:00:41.190: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 08:00:41.923: INFO: namespace init-container-4389 deletion completed in 6.79367789s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 08:00:41.925: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-992
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 14 08:00:42.326: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Aug 14 08:00:47.494: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Aug 14 08:00:47.494: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Aug 14 08:00:51.940: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-992,SelfLink:/apis/apps/v1/namespaces/deployment-992/deployments/test-cleanup-deployment,UID:d426d57b-8f84-4ae6-8afc-259da998e4a2,ResourceVersion:23597,Generation:1,CreationTimestamp:2019-08-14 08:00:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 1,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-08-14 08:00:47 +0000 UTC 2019-08-14 08:00:47 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-08-14 08:00:50 +0000 UTC 2019-08-14 08:00:47 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-cleanup-deployment-55bbcbc84c" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Aug 14 08:00:51.963: INFO: New ReplicaSet "test-cleanup-deployment-55bbcbc84c" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55bbcbc84c,GenerateName:,Namespace:deployment-992,SelfLink:/apis/apps/v1/namespaces/deployment-992/replicasets/test-cleanup-deployment-55bbcbc84c,UID:fc6b397c-acbd-48ac-a437-e838163f57d4,ResourceVersion:23564,Generation:1,CreationTimestamp:2019-08-14 08:00:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment d426d57b-8f84-4ae6-8afc-259da998e4a2 0xc00393b537 0xc00393b538}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Aug 14 08:00:51.978: INFO: Pod "test-cleanup-deployment-55bbcbc84c-bz4r9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55bbcbc84c-bz4r9,GenerateName:test-cleanup-deployment-55bbcbc84c-,Namespace:deployment-992,SelfLink:/api/v1/namespaces/deployment-992/pods/test-cleanup-deployment-55bbcbc84c-bz4r9,UID:95505034-27b5-46e2-b740-88b0132b96b3,ResourceVersion:23560,Generation:0,CreationTimestamp:2019-08-14 08:00:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.252/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-55bbcbc84c fc6b397c-acbd-48ac-a437-e838163f57d4 0xc00393bb37 0xc00393bb38}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-8mhd9 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-8mhd9,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-8mhd9 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00393bba0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00393bbc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 08:00:47 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 08:00:49 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 08:00:49 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-14 08:00:47 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:100.96.1.252,StartTime:2019-08-14 08:00:47 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-08-14 08:00:48 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://586287fde6e3792c8b0f1fc8c93d43e732ac29a249eecdf2b2d177786fbf9159}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 08:00:51.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-992" for this suite.
Aug 14 08:01:00.332: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 08:01:01.672: INFO: namespace deployment-992 deletion completed in 9.665758567s
•SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 08:01:01.672: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5365
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1517
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 14 08:01:02.384: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-5365'
Aug 14 08:01:02.818: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 14 08:01:02.818: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Aug 14 08:01:02.861: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Aug 14 08:01:02.890: INFO: scanned /root for discovery docs: <nil>
Aug 14 08:01:02.890: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-5365'
Aug 14 08:01:19.388: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Aug 14 08:01:19.389: INFO: stdout: "Created e2e-test-nginx-rc-148d02b8ee845182b38c823f5db49bc1\nScaling up e2e-test-nginx-rc-148d02b8ee845182b38c823f5db49bc1 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-148d02b8ee845182b38c823f5db49bc1 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-148d02b8ee845182b38c823f5db49bc1 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Aug 14 08:01:19.389: INFO: stdout: "Created e2e-test-nginx-rc-148d02b8ee845182b38c823f5db49bc1\nScaling up e2e-test-nginx-rc-148d02b8ee845182b38c823f5db49bc1 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-148d02b8ee845182b38c823f5db49bc1 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-148d02b8ee845182b38c823f5db49bc1 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Aug 14 08:01:19.389: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-5365'
Aug 14 08:01:19.524: INFO: stderr: ""
Aug 14 08:01:19.524: INFO: stdout: "e2e-test-nginx-rc-148d02b8ee845182b38c823f5db49bc1-rk484 "
Aug 14 08:01:19.524: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods e2e-test-nginx-rc-148d02b8ee845182b38c823f5db49bc1-rk484 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5365'
Aug 14 08:01:19.675: INFO: stderr: ""
Aug 14 08:01:19.675: INFO: stdout: "true"
Aug 14 08:01:19.675: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods e2e-test-nginx-rc-148d02b8ee845182b38c823f5db49bc1-rk484 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5365'
Aug 14 08:01:19.805: INFO: stderr: ""
Aug 14 08:01:19.805: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Aug 14 08:01:19.805: INFO: e2e-test-nginx-rc-148d02b8ee845182b38c823f5db49bc1-rk484 is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1523
Aug 14 08:01:19.806: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete rc e2e-test-nginx-rc --namespace=kubectl-5365'
Aug 14 08:01:20.010: INFO: stderr: ""
Aug 14 08:01:20.010: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 08:01:20.010: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5365" for this suite.
Aug 14 08:01:44.159: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 08:01:44.817: INFO: namespace kubectl-5365 deletion completed in 24.758163779s
•SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 08:01:44.817: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6402
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-d7ec8f93-4f64-4a62-87d6-a95cf4c6f5bd
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-d7ec8f93-4f64-4a62-87d6-a95cf4c6f5bd
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 08:01:49.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6402" for this suite.
Aug 14 08:03:08.291: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 08:03:08.681: INFO: namespace configmap-6402 deletion completed in 1m18.467868113s
•SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 08:03:08.682: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-722
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 14 08:03:08.880: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8a9317e2-5230-49b7-8a92-8cc33eb815c9" in namespace "projected-722" to be "success or failure"
Aug 14 08:03:08.890: INFO: Pod "downwardapi-volume-8a9317e2-5230-49b7-8a92-8cc33eb815c9": Phase="Pending", Reason="", readiness=false. Elapsed: 9.799072ms
Aug 14 08:03:10.901: INFO: Pod "downwardapi-volume-8a9317e2-5230-49b7-8a92-8cc33eb815c9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020868882s
STEP: Saw pod success
Aug 14 08:03:10.901: INFO: Pod "downwardapi-volume-8a9317e2-5230-49b7-8a92-8cc33eb815c9" satisfied condition "success or failure"
Aug 14 08:03:10.911: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod downwardapi-volume-8a9317e2-5230-49b7-8a92-8cc33eb815c9 container client-container: <nil>
STEP: delete the pod
Aug 14 08:03:10.992: INFO: Waiting for pod downwardapi-volume-8a9317e2-5230-49b7-8a92-8cc33eb815c9 to disappear
Aug 14 08:03:11.002: INFO: Pod downwardapi-volume-8a9317e2-5230-49b7-8a92-8cc33eb815c9 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 08:03:11.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-722" for this suite.
Aug 14 08:03:17.054: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 08:03:17.469: INFO: namespace projected-722 deletion completed in 6.448241957s
•SSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 08:03:17.469: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-4176
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Aug 14 08:03:17.751: INFO: Number of nodes with available pods: 0
Aug 14 08:03:17.751: INFO: Node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw is running more than one daemon pod
Aug 14 08:03:18.780: INFO: Number of nodes with available pods: 1
Aug 14 08:03:18.780: INFO: Node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp is running more than one daemon pod
Aug 14 08:03:19.782: INFO: Number of nodes with available pods: 2
Aug 14 08:03:19.782: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Aug 14 08:03:19.834: INFO: Number of nodes with available pods: 1
Aug 14 08:03:19.834: INFO: Node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw is running more than one daemon pod
Aug 14 08:03:20.863: INFO: Number of nodes with available pods: 2
Aug 14 08:03:20.863: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4176, will wait for the garbage collector to delete the pods
Aug 14 08:03:20.957: INFO: Deleting DaemonSet.extensions daemon-set took: 12.473374ms
Aug 14 08:03:21.357: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.400395ms
Aug 14 08:03:35.469: INFO: Number of nodes with available pods: 0
Aug 14 08:03:35.469: INFO: Number of running nodes: 0, number of available pods: 0
Aug 14 08:03:35.480: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-4176/daemonsets","resourceVersion":"24174"},"items":null}

Aug 14 08:03:35.490: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-4176/pods","resourceVersion":"24174"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 08:03:35.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4176" for this suite.
Aug 14 08:03:41.623: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 08:03:42.255: INFO: namespace daemonsets-4176 deletion completed in 6.712528233s
•
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 08:03:42.255: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8043
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1722
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 14 08:03:42.462: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-8043'
Aug 14 08:03:42.610: INFO: stderr: ""
Aug 14 08:03:42.610: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Aug 14 08:03:47.661: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pod e2e-test-nginx-pod --namespace=kubectl-8043 -o json'
Aug 14 08:03:47.779: INFO: stderr: ""
Aug 14 08:03:47.779: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"100.96.1.5/32\",\n            \"kubernetes.io/psp\": \"e2e-test-privileged-psp\"\n        },\n        \"creationTimestamp\": \"2019-08-14T08:03:42Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-8043\",\n        \"resourceVersion\": \"24208\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-8043/pods/e2e-test-nginx-pod\",\n        \"uid\": \"a68aa242-b962-4b28-b1c6-a9ebb77b75f7\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-7wp9h\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-7wp9h\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-7wp9h\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-08-14T08:03:42Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-08-14T08:03:43Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-08-14T08:03:43Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-08-14T08:03:42Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://babb8fe7e58ecc067a1a40e746e9062127a10bd4e847a5d2f109a9f8d5cf62b7\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-08-14T08:03:43Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.250.0.3\",\n        \"phase\": \"Running\",\n        \"podIP\": \"100.96.1.5\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-08-14T08:03:42Z\"\n    }\n}\n"
STEP: replace the image in the pod
Aug 14 08:03:47.780: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config replace -f - --namespace=kubectl-8043'
Aug 14 08:03:48.083: INFO: stderr: ""
Aug 14 08:03:48.083: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1727
Aug 14 08:03:48.093: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tm-6jaqb.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete pods e2e-test-nginx-pod --namespace=kubectl-8043'
Aug 14 08:03:56.365: INFO: stderr: ""
Aug 14 08:03:56.365: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 08:03:56.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8043" for this suite.
Aug 14 08:04:02.416: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 08:04:02.785: INFO: namespace kubectl-8043 deletion completed in 6.400120773s
•SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 08:04:02.785: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-844
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-f86d4569-ec37-4f4e-b7c0-d89419b805f1
STEP: Creating a pod to test consume configMaps
Aug 14 08:04:03.078: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c4430a51-50a0-4235-a27d-3f2073ec0d2d" in namespace "projected-844" to be "success or failure"
Aug 14 08:04:03.088: INFO: Pod "pod-projected-configmaps-c4430a51-50a0-4235-a27d-3f2073ec0d2d": Phase="Pending", Reason="", readiness=false. Elapsed: 9.847336ms
Aug 14 08:04:05.100: INFO: Pod "pod-projected-configmaps-c4430a51-50a0-4235-a27d-3f2073ec0d2d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021524934s
STEP: Saw pod success
Aug 14 08:04:05.100: INFO: Pod "pod-projected-configmaps-c4430a51-50a0-4235-a27d-3f2073ec0d2d" satisfied condition "success or failure"
Aug 14 08:04:05.110: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod pod-projected-configmaps-c4430a51-50a0-4235-a27d-3f2073ec0d2d container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 14 08:04:05.142: INFO: Waiting for pod pod-projected-configmaps-c4430a51-50a0-4235-a27d-3f2073ec0d2d to disappear
Aug 14 08:04:05.152: INFO: Pod pod-projected-configmaps-c4430a51-50a0-4235-a27d-3f2073ec0d2d no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 08:04:05.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-844" for this suite.
Aug 14 08:04:11.202: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 08:04:11.582: INFO: namespace projected-844 deletion completed in 6.411486882s
•SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 08:04:11.582: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9290
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Aug 14 08:04:11.779: INFO: Waiting up to 5m0s for pod "pod-0caf979b-c18c-4ca8-83ad-6b7e19239b56" in namespace "emptydir-9290" to be "success or failure"
Aug 14 08:04:11.788: INFO: Pod "pod-0caf979b-c18c-4ca8-83ad-6b7e19239b56": Phase="Pending", Reason="", readiness=false. Elapsed: 9.668895ms
Aug 14 08:04:13.799: INFO: Pod "pod-0caf979b-c18c-4ca8-83ad-6b7e19239b56": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020430084s
STEP: Saw pod success
Aug 14 08:04:13.799: INFO: Pod "pod-0caf979b-c18c-4ca8-83ad-6b7e19239b56" satisfied condition "success or failure"
Aug 14 08:04:13.809: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod pod-0caf979b-c18c-4ca8-83ad-6b7e19239b56 container test-container: <nil>
STEP: delete the pod
Aug 14 08:04:13.842: INFO: Waiting for pod pod-0caf979b-c18c-4ca8-83ad-6b7e19239b56 to disappear
Aug 14 08:04:13.852: INFO: Pod pod-0caf979b-c18c-4ca8-83ad-6b7e19239b56 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 08:04:13.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9290" for this suite.
Aug 14 08:04:19.902: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 08:04:20.287: INFO: namespace emptydir-9290 deletion completed in 6.416715349s
•SSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 08:04:20.287: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-3369
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Aug 14 08:04:20.554: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug 14 08:04:20.576: INFO: Waiting for terminating namespaces to be deleted...
Aug 14 08:04:20.586: INFO: 
Logging pods the kubelet thinks is on node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-dt9cw before test
Aug 14 08:04:20.612: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-88d6cff74-rw8q9 from kube-system started at 2019-08-14 06:27:10 +0000 UTC (1 container statuses recorded)
Aug 14 08:04:20.612: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Aug 14 08:04:20.612: INFO: metrics-server-f5b59f6cc-xc2ch from kube-system started at 2019-08-14 06:27:10 +0000 UTC (1 container statuses recorded)
Aug 14 08:04:20.612: INFO: 	Container metrics-server ready: true, restart count 0
Aug 14 08:04:20.612: INFO: coredns-85cc454dd8-l4hk9 from kube-system started at 2019-08-14 06:27:14 +0000 UTC (1 container statuses recorded)
Aug 14 08:04:20.612: INFO: 	Container coredns ready: true, restart count 0
Aug 14 08:04:20.612: INFO: coredns-85cc454dd8-zsj57 from kube-system started at 2019-08-14 06:27:10 +0000 UTC (1 container statuses recorded)
Aug 14 08:04:20.612: INFO: 	Container coredns ready: true, restart count 0
Aug 14 08:04:20.612: INFO: blackbox-exporter-954dd954b-8xcv9 from kube-system started at 2019-08-14 06:26:55 +0000 UTC (1 container statuses recorded)
Aug 14 08:04:20.612: INFO: 	Container blackbox-exporter ready: true, restart count 0
Aug 14 08:04:20.612: INFO: kube-proxy-n2x65 from kube-system started at 2019-08-14 06:26:55 +0000 UTC (1 container statuses recorded)
Aug 14 08:04:20.612: INFO: 	Container kube-proxy ready: true, restart count 0
Aug 14 08:04:20.612: INFO: calico-node-gb7zk from kube-system started at 2019-08-14 06:26:55 +0000 UTC (1 container statuses recorded)
Aug 14 08:04:20.612: INFO: 	Container calico-node ready: true, restart count 1
Aug 14 08:04:20.612: INFO: node-exporter-hmlnc from kube-system started at 2019-08-14 06:26:55 +0000 UTC (1 container statuses recorded)
Aug 14 08:04:20.612: INFO: 	Container node-exporter ready: true, restart count 0
Aug 14 08:04:20.612: INFO: vpn-shoot-7d7bc8fd7d-997f6 from kube-system started at 2019-08-14 06:27:10 +0000 UTC (1 container statuses recorded)
Aug 14 08:04:20.612: INFO: 	Container vpn-shoot ready: true, restart count 0
Aug 14 08:04:20.612: INFO: addons-kubernetes-dashboard-5c8d9945bc-8t28x from kube-system started at 2019-08-14 06:27:10 +0000 UTC (1 container statuses recorded)
Aug 14 08:04:20.612: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Aug 14 08:04:20.612: INFO: addons-nginx-ingress-controller-6496d947df-dqs5z from kube-system started at 2019-08-14 06:27:10 +0000 UTC (1 container statuses recorded)
Aug 14 08:04:20.612: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Aug 14 08:04:20.612: INFO: calico-kube-controllers-5f4b46ffb5-m6pdj from kube-system started at 2019-08-14 06:27:10 +0000 UTC (1 container statuses recorded)
Aug 14 08:04:20.612: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Aug 14 08:04:20.612: INFO: 
Logging pods the kubelet thinks is on node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp before test
Aug 14 08:04:20.647: INFO: node-exporter-wq6g7 from kube-system started at 2019-08-14 06:26:56 +0000 UTC (1 container statuses recorded)
Aug 14 08:04:20.647: INFO: 	Container node-exporter ready: true, restart count 0
Aug 14 08:04:20.647: INFO: kube-proxy-2nsfn from kube-system started at 2019-08-14 06:26:56 +0000 UTC (1 container statuses recorded)
Aug 14 08:04:20.647: INFO: 	Container kube-proxy ready: true, restart count 0
Aug 14 08:04:20.647: INFO: calico-node-ksxzt from kube-system started at 2019-08-14 06:26:56 +0000 UTC (1 container statuses recorded)
Aug 14 08:04:20.647: INFO: 	Container calico-node ready: true, restart count 1
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-9e6fc520-1429-461d-a491-c68f86169d1f 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-9e6fc520-1429-461d-a491-c68f86169d1f off the node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp
STEP: verifying the node doesn't have the label kubernetes.io/e2e-9e6fc520-1429-461d-a491-c68f86169d1f
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 08:04:24.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-3369" for this suite.
Aug 14 08:04:34.847: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 08:04:35.253: INFO: namespace sched-pred-3369 deletion completed in 10.43919814s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 08:04:35.254: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-8440
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
Aug 14 08:04:36.085: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
W0814 08:04:36.085428    4167 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 14 08:04:36.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8440" for this suite.
Aug 14 08:04:42.130: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 08:04:42.558: INFO: namespace gc-8440 deletion completed in 6.461607204s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 08:04:42.559: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-7497
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override arguments
Aug 14 08:04:42.873: INFO: Waiting up to 5m0s for pod "client-containers-768e9bdc-2cdb-411f-a4ab-513bf349a5a3" in namespace "containers-7497" to be "success or failure"
Aug 14 08:04:42.883: INFO: Pod "client-containers-768e9bdc-2cdb-411f-a4ab-513bf349a5a3": Phase="Pending", Reason="", readiness=false. Elapsed: 9.98819ms
Aug 14 08:04:44.924: INFO: Pod "client-containers-768e9bdc-2cdb-411f-a4ab-513bf349a5a3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.050663425s
STEP: Saw pod success
Aug 14 08:04:44.924: INFO: Pod "client-containers-768e9bdc-2cdb-411f-a4ab-513bf349a5a3" satisfied condition "success or failure"
Aug 14 08:04:45.024: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod client-containers-768e9bdc-2cdb-411f-a4ab-513bf349a5a3 container test-container: <nil>
STEP: delete the pod
Aug 14 08:04:45.057: INFO: Waiting for pod client-containers-768e9bdc-2cdb-411f-a4ab-513bf349a5a3 to disappear
Aug 14 08:04:45.067: INFO: Pod client-containers-768e9bdc-2cdb-411f-a4ab-513bf349a5a3 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 08:04:45.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7497" for this suite.
Aug 14 08:04:51.118: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 08:04:51.499: INFO: namespace containers-7497 deletion completed in 6.412725002s
•SSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 08:04:51.499: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-7183
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Aug 14 08:04:53.935: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 08:04:53.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-7183" for this suite.
Aug 14 08:05:18.018: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 08:05:18.401: INFO: namespace replicaset-7183 deletion completed in 24.415578242s
•SSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 08:05:18.401: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-9044
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 14 08:05:18.757: INFO: Creating ReplicaSet my-hostname-basic-f2f72f07-c5e3-4383-b2c4-4ff4a28b30b3
Aug 14 08:05:18.779: INFO: Pod name my-hostname-basic-f2f72f07-c5e3-4383-b2c4-4ff4a28b30b3: Found 1 pods out of 1
Aug 14 08:05:18.779: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-f2f72f07-c5e3-4383-b2c4-4ff4a28b30b3" is running
Aug 14 08:05:20.800: INFO: Pod "my-hostname-basic-f2f72f07-c5e3-4383-b2c4-4ff4a28b30b3-7fzb7" is running (conditions: [{Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-14 08:05:18 +0000 UTC Reason: Message:}])
Aug 14 08:05:20.800: INFO: Trying to dial the pod
Aug 14 08:05:25.917: INFO: Controller my-hostname-basic-f2f72f07-c5e3-4383-b2c4-4ff4a28b30b3: Got expected result from replica 1 [my-hostname-basic-f2f72f07-c5e3-4383-b2c4-4ff4a28b30b3-7fzb7]: "my-hostname-basic-f2f72f07-c5e3-4383-b2c4-4ff4a28b30b3-7fzb7", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 08:05:25.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9044" for this suite.
Aug 14 08:05:33.971: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 08:05:34.363: INFO: namespace replicaset-9044 deletion completed in 8.427351205s
•
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 08:05:34.363: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7004
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 14 08:05:34.673: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6c049bbd-dafe-4970-a2a7-8d0625c58b75" in namespace "projected-7004" to be "success or failure"
Aug 14 08:05:34.683: INFO: Pod "downwardapi-volume-6c049bbd-dafe-4970-a2a7-8d0625c58b75": Phase="Pending", Reason="", readiness=false. Elapsed: 10.230159ms
Aug 14 08:05:36.695: INFO: Pod "downwardapi-volume-6c049bbd-dafe-4970-a2a7-8d0625c58b75": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021906177s
STEP: Saw pod success
Aug 14 08:05:36.695: INFO: Pod "downwardapi-volume-6c049bbd-dafe-4970-a2a7-8d0625c58b75" satisfied condition "success or failure"
Aug 14 08:05:36.705: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod downwardapi-volume-6c049bbd-dafe-4970-a2a7-8d0625c58b75 container client-container: <nil>
STEP: delete the pod
Aug 14 08:05:36.740: INFO: Waiting for pod downwardapi-volume-6c049bbd-dafe-4970-a2a7-8d0625c58b75 to disappear
Aug 14 08:05:36.750: INFO: Pod downwardapi-volume-6c049bbd-dafe-4970-a2a7-8d0625c58b75 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 08:05:36.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7004" for this suite.
Aug 14 08:05:42.802: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 08:05:43.193: INFO: namespace projected-7004 deletion completed in 6.423777598s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 08:05:43.194: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-4433
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-wbbqx in namespace proxy-4433
I0814 08:05:43.585239    4167 runners.go:180] Created replication controller with name: proxy-service-wbbqx, namespace: proxy-4433, replica count: 1
I0814 08:05:44.635821    4167 runners.go:180] proxy-service-wbbqx Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0814 08:05:45.636188    4167 runners.go:180] proxy-service-wbbqx Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0814 08:05:46.636570    4167 runners.go:180] proxy-service-wbbqx Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0814 08:05:47.636867    4167 runners.go:180] proxy-service-wbbqx Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0814 08:05:48.637089    4167 runners.go:180] proxy-service-wbbqx Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0814 08:05:49.637451    4167 runners.go:180] proxy-service-wbbqx Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0814 08:05:50.637827    4167 runners.go:180] proxy-service-wbbqx Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0814 08:05:51.638325    4167 runners.go:180] proxy-service-wbbqx Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0814 08:05:52.638628    4167 runners.go:180] proxy-service-wbbqx Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0814 08:05:53.638908    4167 runners.go:180] proxy-service-wbbqx Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0814 08:05:54.639154    4167 runners.go:180] proxy-service-wbbqx Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 14 08:05:54.650: INFO: setup took 11.093125043s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Aug 14 08:05:54.706: INFO: (0) /api/v1/namespaces/proxy-4433/services/http:proxy-service-wbbqx:portname1/proxy/: foo (200; 55.569515ms)
Aug 14 08:05:54.706: INFO: (0) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:1080/proxy/rewriteme">test<... (200; 55.61575ms)
Aug 14 08:05:54.706: INFO: (0) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:162/proxy/: bar (200; 55.886448ms)
Aug 14 08:05:54.706: INFO: (0) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:160/proxy/: foo (200; 55.594809ms)
Aug 14 08:05:54.706: INFO: (0) /api/v1/namespaces/proxy-4433/services/proxy-service-wbbqx:portname2/proxy/: bar (200; 55.779309ms)
Aug 14 08:05:54.706: INFO: (0) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:162/proxy/: bar (200; 55.766434ms)
Aug 14 08:05:54.706: INFO: (0) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz/proxy/rewriteme">test</a> (200; 55.718713ms)
Aug 14 08:05:54.707: INFO: (0) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:160/proxy/: foo (200; 56.830499ms)
Aug 14 08:05:54.707: INFO: (0) /api/v1/namespaces/proxy-4433/services/http:proxy-service-wbbqx:portname2/proxy/: bar (200; 56.851755ms)
Aug 14 08:05:54.707: INFO: (0) /api/v1/namespaces/proxy-4433/services/proxy-service-wbbqx:portname1/proxy/: foo (200; 57.198363ms)
Aug 14 08:05:54.714: INFO: (0) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:460/proxy/: tls baz (200; 63.509325ms)
Aug 14 08:05:54.714: INFO: (0) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:1080/proxy/rewriteme">... (200; 63.335479ms)
Aug 14 08:05:54.715: INFO: (0) /api/v1/namespaces/proxy-4433/services/https:proxy-service-wbbqx:tlsportname1/proxy/: tls baz (200; 64.654697ms)
Aug 14 08:05:54.715: INFO: (0) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:443/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:443/proxy/tlsrewritem... (200; 64.595965ms)
Aug 14 08:05:54.715: INFO: (0) /api/v1/namespaces/proxy-4433/services/https:proxy-service-wbbqx:tlsportname2/proxy/: tls qux (200; 64.594196ms)
Aug 14 08:05:54.716: INFO: (0) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:462/proxy/: tls qux (200; 65.7027ms)
Aug 14 08:05:54.730: INFO: (1) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:1080/proxy/rewriteme">test<... (200; 13.2274ms)
Aug 14 08:05:54.730: INFO: (1) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:1080/proxy/rewriteme">... (200; 13.351337ms)
Aug 14 08:05:54.730: INFO: (1) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:160/proxy/: foo (200; 13.438409ms)
Aug 14 08:05:54.730: INFO: (1) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:162/proxy/: bar (200; 13.341699ms)
Aug 14 08:05:54.730: INFO: (1) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz/proxy/rewriteme">test</a> (200; 13.288833ms)
Aug 14 08:05:54.730: INFO: (1) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:443/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:443/proxy/tlsrewritem... (200; 13.335186ms)
Aug 14 08:05:54.730: INFO: (1) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:460/proxy/: tls baz (200; 13.386623ms)
Aug 14 08:05:54.730: INFO: (1) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:462/proxy/: tls qux (200; 13.424274ms)
Aug 14 08:05:54.730: INFO: (1) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:162/proxy/: bar (200; 13.447947ms)
Aug 14 08:05:54.730: INFO: (1) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:160/proxy/: foo (200; 13.617575ms)
Aug 14 08:05:54.730: INFO: (1) /api/v1/namespaces/proxy-4433/services/proxy-service-wbbqx:portname1/proxy/: foo (200; 13.898038ms)
Aug 14 08:05:54.730: INFO: (1) /api/v1/namespaces/proxy-4433/services/https:proxy-service-wbbqx:tlsportname1/proxy/: tls baz (200; 13.918939ms)
Aug 14 08:05:54.730: INFO: (1) /api/v1/namespaces/proxy-4433/services/https:proxy-service-wbbqx:tlsportname2/proxy/: tls qux (200; 13.967131ms)
Aug 14 08:05:54.731: INFO: (1) /api/v1/namespaces/proxy-4433/services/proxy-service-wbbqx:portname2/proxy/: bar (200; 14.378861ms)
Aug 14 08:05:54.731: INFO: (1) /api/v1/namespaces/proxy-4433/services/http:proxy-service-wbbqx:portname1/proxy/: foo (200; 14.758595ms)
Aug 14 08:05:54.731: INFO: (1) /api/v1/namespaces/proxy-4433/services/http:proxy-service-wbbqx:portname2/proxy/: bar (200; 14.434533ms)
Aug 14 08:05:54.744: INFO: (2) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:462/proxy/: tls qux (200; 12.892169ms)
Aug 14 08:05:54.744: INFO: (2) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:160/proxy/: foo (200; 13.199766ms)
Aug 14 08:05:54.744: INFO: (2) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:160/proxy/: foo (200; 12.91102ms)
Aug 14 08:05:54.744: INFO: (2) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:162/proxy/: bar (200; 13.08817ms)
Aug 14 08:05:54.744: INFO: (2) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:162/proxy/: bar (200; 13.331619ms)
Aug 14 08:05:54.744: INFO: (2) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:1080/proxy/rewriteme">... (200; 13.00246ms)
Aug 14 08:05:54.744: INFO: (2) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz/proxy/rewriteme">test</a> (200; 13.077317ms)
Aug 14 08:05:54.744: INFO: (2) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:1080/proxy/rewriteme">test<... (200; 13.256257ms)
Aug 14 08:05:54.744: INFO: (2) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:460/proxy/: tls baz (200; 13.171896ms)
Aug 14 08:05:54.744: INFO: (2) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:443/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:443/proxy/tlsrewritem... (200; 13.337581ms)
Aug 14 08:05:54.747: INFO: (2) /api/v1/namespaces/proxy-4433/services/https:proxy-service-wbbqx:tlsportname1/proxy/: tls baz (200; 16.09318ms)
Aug 14 08:05:54.747: INFO: (2) /api/v1/namespaces/proxy-4433/services/https:proxy-service-wbbqx:tlsportname2/proxy/: tls qux (200; 16.111373ms)
Aug 14 08:05:54.747: INFO: (2) /api/v1/namespaces/proxy-4433/services/proxy-service-wbbqx:portname1/proxy/: foo (200; 16.240699ms)
Aug 14 08:05:54.747: INFO: (2) /api/v1/namespaces/proxy-4433/services/http:proxy-service-wbbqx:portname1/proxy/: foo (200; 16.282705ms)
Aug 14 08:05:54.747: INFO: (2) /api/v1/namespaces/proxy-4433/services/http:proxy-service-wbbqx:portname2/proxy/: bar (200; 16.236567ms)
Aug 14 08:05:54.748: INFO: (2) /api/v1/namespaces/proxy-4433/services/proxy-service-wbbqx:portname2/proxy/: bar (200; 16.644093ms)
Aug 14 08:05:54.761: INFO: (3) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:162/proxy/: bar (200; 12.698075ms)
Aug 14 08:05:54.761: INFO: (3) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:162/proxy/: bar (200; 12.590053ms)
Aug 14 08:05:54.761: INFO: (3) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:443/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:443/proxy/tlsrewritem... (200; 12.241431ms)
Aug 14 08:05:54.761: INFO: (3) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz/proxy/rewriteme">test</a> (200; 12.611642ms)
Aug 14 08:05:54.761: INFO: (3) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:460/proxy/: tls baz (200; 12.538951ms)
Aug 14 08:05:54.761: INFO: (3) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:1080/proxy/rewriteme">test<... (200; 13.253333ms)
Aug 14 08:05:54.761: INFO: (3) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:1080/proxy/rewriteme">... (200; 13.2853ms)
Aug 14 08:05:54.761: INFO: (3) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:160/proxy/: foo (200; 13.236276ms)
Aug 14 08:05:54.762: INFO: (3) /api/v1/namespaces/proxy-4433/services/https:proxy-service-wbbqx:tlsportname1/proxy/: tls baz (200; 13.790344ms)
Aug 14 08:05:54.762: INFO: (3) /api/v1/namespaces/proxy-4433/services/proxy-service-wbbqx:portname2/proxy/: bar (200; 14.013261ms)
Aug 14 08:05:54.762: INFO: (3) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:160/proxy/: foo (200; 13.911624ms)
Aug 14 08:05:54.762: INFO: (3) /api/v1/namespaces/proxy-4433/services/https:proxy-service-wbbqx:tlsportname2/proxy/: tls qux (200; 13.914541ms)
Aug 14 08:05:54.762: INFO: (3) /api/v1/namespaces/proxy-4433/services/http:proxy-service-wbbqx:portname2/proxy/: bar (200; 13.969734ms)
Aug 14 08:05:54.762: INFO: (3) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:462/proxy/: tls qux (200; 13.894927ms)
Aug 14 08:05:54.763: INFO: (3) /api/v1/namespaces/proxy-4433/services/proxy-service-wbbqx:portname1/proxy/: foo (200; 14.819708ms)
Aug 14 08:05:54.763: INFO: (3) /api/v1/namespaces/proxy-4433/services/http:proxy-service-wbbqx:portname1/proxy/: foo (200; 15.170693ms)
Aug 14 08:05:54.782: INFO: (4) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:162/proxy/: bar (200; 18.913877ms)
Aug 14 08:05:54.782: INFO: (4) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:160/proxy/: foo (200; 19.032758ms)
Aug 14 08:05:54.782: INFO: (4) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:162/proxy/: bar (200; 18.94566ms)
Aug 14 08:05:54.782: INFO: (4) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:1080/proxy/rewriteme">... (200; 18.972204ms)
Aug 14 08:05:54.782: INFO: (4) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:1080/proxy/rewriteme">test<... (200; 19.063939ms)
Aug 14 08:05:54.786: INFO: (4) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:462/proxy/: tls qux (200; 22.49472ms)
Aug 14 08:05:54.786: INFO: (4) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:443/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:443/proxy/tlsrewritem... (200; 23.185947ms)
Aug 14 08:05:54.786: INFO: (4) /api/v1/namespaces/proxy-4433/services/https:proxy-service-wbbqx:tlsportname1/proxy/: tls baz (200; 22.887203ms)
Aug 14 08:05:54.786: INFO: (4) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:460/proxy/: tls baz (200; 22.840808ms)
Aug 14 08:05:54.786: INFO: (4) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz/proxy/rewriteme">test</a> (200; 23.217379ms)
Aug 14 08:05:54.786: INFO: (4) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:160/proxy/: foo (200; 22.953485ms)
Aug 14 08:05:54.787: INFO: (4) /api/v1/namespaces/proxy-4433/services/proxy-service-wbbqx:portname2/proxy/: bar (200; 23.639515ms)
Aug 14 08:05:54.788: INFO: (4) /api/v1/namespaces/proxy-4433/services/proxy-service-wbbqx:portname1/proxy/: foo (200; 24.089378ms)
Aug 14 08:05:54.788: INFO: (4) /api/v1/namespaces/proxy-4433/services/http:proxy-service-wbbqx:portname2/proxy/: bar (200; 24.213027ms)
Aug 14 08:05:54.788: INFO: (4) /api/v1/namespaces/proxy-4433/services/https:proxy-service-wbbqx:tlsportname2/proxy/: tls qux (200; 24.217036ms)
Aug 14 08:05:54.788: INFO: (4) /api/v1/namespaces/proxy-4433/services/http:proxy-service-wbbqx:portname1/proxy/: foo (200; 24.499103ms)
Aug 14 08:05:54.820: INFO: (5) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:162/proxy/: bar (200; 31.835803ms)
Aug 14 08:05:54.820: INFO: (5) /api/v1/namespaces/proxy-4433/services/https:proxy-service-wbbqx:tlsportname1/proxy/: tls baz (200; 31.636098ms)
Aug 14 08:05:54.820: INFO: (5) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:462/proxy/: tls qux (200; 31.818713ms)
Aug 14 08:05:54.820: INFO: (5) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:162/proxy/: bar (200; 32.006109ms)
Aug 14 08:05:54.820: INFO: (5) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz/proxy/rewriteme">test</a> (200; 31.706091ms)
Aug 14 08:05:54.820: INFO: (5) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:460/proxy/: tls baz (200; 31.806615ms)
Aug 14 08:05:54.820: INFO: (5) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:160/proxy/: foo (200; 32.056728ms)
Aug 14 08:05:54.820: INFO: (5) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:443/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:443/proxy/tlsrewritem... (200; 32.031783ms)
Aug 14 08:05:54.820: INFO: (5) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:1080/proxy/rewriteme">test<... (200; 32.073208ms)
Aug 14 08:05:54.821: INFO: (5) /api/v1/namespaces/proxy-4433/services/https:proxy-service-wbbqx:tlsportname2/proxy/: tls qux (200; 33.064153ms)
Aug 14 08:05:54.822: INFO: (5) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:160/proxy/: foo (200; 34.255506ms)
Aug 14 08:05:54.822: INFO: (5) /api/v1/namespaces/proxy-4433/services/proxy-service-wbbqx:portname1/proxy/: foo (200; 34.452554ms)
Aug 14 08:05:54.823: INFO: (5) /api/v1/namespaces/proxy-4433/services/http:proxy-service-wbbqx:portname2/proxy/: bar (200; 34.381124ms)
Aug 14 08:05:54.823: INFO: (5) /api/v1/namespaces/proxy-4433/services/proxy-service-wbbqx:portname2/proxy/: bar (200; 34.573028ms)
Aug 14 08:05:54.823: INFO: (5) /api/v1/namespaces/proxy-4433/services/http:proxy-service-wbbqx:portname1/proxy/: foo (200; 34.694485ms)
Aug 14 08:05:54.823: INFO: (5) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:1080/proxy/rewriteme">... (200; 35.234936ms)
Aug 14 08:05:54.837: INFO: (6) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:160/proxy/: foo (200; 13.137774ms)
Aug 14 08:05:54.837: INFO: (6) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:162/proxy/: bar (200; 13.140751ms)
Aug 14 08:05:54.837: INFO: (6) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:1080/proxy/rewriteme">test<... (200; 13.116592ms)
Aug 14 08:05:54.837: INFO: (6) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz/proxy/rewriteme">test</a> (200; 13.168751ms)
Aug 14 08:05:54.837: INFO: (6) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:162/proxy/: bar (200; 13.302889ms)
Aug 14 08:05:54.837: INFO: (6) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:462/proxy/: tls qux (200; 13.465527ms)
Aug 14 08:05:54.837: INFO: (6) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:460/proxy/: tls baz (200; 13.520794ms)
Aug 14 08:05:54.837: INFO: (6) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:1080/proxy/rewriteme">... (200; 13.688162ms)
Aug 14 08:05:54.837: INFO: (6) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:160/proxy/: foo (200; 13.578799ms)
Aug 14 08:05:54.838: INFO: (6) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:443/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:443/proxy/tlsrewritem... (200; 13.893605ms)
Aug 14 08:05:54.838: INFO: (6) /api/v1/namespaces/proxy-4433/services/https:proxy-service-wbbqx:tlsportname2/proxy/: tls qux (200; 13.931714ms)
Aug 14 08:05:54.838: INFO: (6) /api/v1/namespaces/proxy-4433/services/https:proxy-service-wbbqx:tlsportname1/proxy/: tls baz (200; 14.054467ms)
Aug 14 08:05:54.838: INFO: (6) /api/v1/namespaces/proxy-4433/services/proxy-service-wbbqx:portname2/proxy/: bar (200; 14.296748ms)
Aug 14 08:05:54.838: INFO: (6) /api/v1/namespaces/proxy-4433/services/http:proxy-service-wbbqx:portname2/proxy/: bar (200; 14.46091ms)
Aug 14 08:05:54.838: INFO: (6) /api/v1/namespaces/proxy-4433/services/http:proxy-service-wbbqx:portname1/proxy/: foo (200; 14.381391ms)
Aug 14 08:05:54.838: INFO: (6) /api/v1/namespaces/proxy-4433/services/proxy-service-wbbqx:portname1/proxy/: foo (200; 14.779728ms)
Aug 14 08:05:54.852: INFO: (7) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:1080/proxy/rewriteme">test<... (200; 13.19465ms)
Aug 14 08:05:54.852: INFO: (7) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:162/proxy/: bar (200; 13.151856ms)
Aug 14 08:05:54.852: INFO: (7) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:462/proxy/: tls qux (200; 13.210323ms)
Aug 14 08:05:54.852: INFO: (7) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:1080/proxy/rewriteme">... (200; 13.209921ms)
Aug 14 08:05:54.852: INFO: (7) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:162/proxy/: bar (200; 13.325821ms)
Aug 14 08:05:54.852: INFO: (7) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:443/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:443/proxy/tlsrewritem... (200; 13.161421ms)
Aug 14 08:05:54.852: INFO: (7) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:160/proxy/: foo (200; 13.216841ms)
Aug 14 08:05:54.852: INFO: (7) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz/proxy/rewriteme">test</a> (200; 13.371168ms)
Aug 14 08:05:54.852: INFO: (7) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:160/proxy/: foo (200; 13.567123ms)
Aug 14 08:05:54.852: INFO: (7) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:460/proxy/: tls baz (200; 13.56828ms)
Aug 14 08:05:54.853: INFO: (7) /api/v1/namespaces/proxy-4433/services/https:proxy-service-wbbqx:tlsportname2/proxy/: tls qux (200; 14.044285ms)
Aug 14 08:05:54.853: INFO: (7) /api/v1/namespaces/proxy-4433/services/http:proxy-service-wbbqx:portname1/proxy/: foo (200; 14.356632ms)
Aug 14 08:05:54.853: INFO: (7) /api/v1/namespaces/proxy-4433/services/https:proxy-service-wbbqx:tlsportname1/proxy/: tls baz (200; 14.328776ms)
Aug 14 08:05:54.853: INFO: (7) /api/v1/namespaces/proxy-4433/services/http:proxy-service-wbbqx:portname2/proxy/: bar (200; 14.420997ms)
Aug 14 08:05:54.853: INFO: (7) /api/v1/namespaces/proxy-4433/services/proxy-service-wbbqx:portname2/proxy/: bar (200; 14.53165ms)
Aug 14 08:05:54.853: INFO: (7) /api/v1/namespaces/proxy-4433/services/proxy-service-wbbqx:portname1/proxy/: foo (200; 14.659597ms)
Aug 14 08:05:54.866: INFO: (8) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz/proxy/rewriteme">test</a> (200; 13.167901ms)
Aug 14 08:05:54.867: INFO: (8) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:162/proxy/: bar (200; 13.088263ms)
Aug 14 08:05:54.867: INFO: (8) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:162/proxy/: bar (200; 13.072337ms)
Aug 14 08:05:54.867: INFO: (8) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:160/proxy/: foo (200; 13.198926ms)
Aug 14 08:05:54.867: INFO: (8) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:160/proxy/: foo (200; 13.143722ms)
Aug 14 08:05:54.867: INFO: (8) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:1080/proxy/rewriteme">... (200; 13.132602ms)
Aug 14 08:05:54.867: INFO: (8) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:1080/proxy/rewriteme">test<... (200; 13.285765ms)
Aug 14 08:05:54.867: INFO: (8) /api/v1/namespaces/proxy-4433/services/https:proxy-service-wbbqx:tlsportname2/proxy/: tls qux (200; 13.196652ms)
Aug 14 08:05:54.867: INFO: (8) /api/v1/namespaces/proxy-4433/services/https:proxy-service-wbbqx:tlsportname1/proxy/: tls baz (200; 13.289ms)
Aug 14 08:05:54.867: INFO: (8) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:443/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:443/proxy/tlsrewritem... (200; 13.217879ms)
Aug 14 08:05:54.867: INFO: (8) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:462/proxy/: tls qux (200; 13.22619ms)
Aug 14 08:05:54.867: INFO: (8) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:460/proxy/: tls baz (200; 13.322995ms)
Aug 14 08:05:54.909: INFO: (8) /api/v1/namespaces/proxy-4433/services/proxy-service-wbbqx:portname2/proxy/: bar (200; 55.782735ms)
Aug 14 08:05:54.909: INFO: (8) /api/v1/namespaces/proxy-4433/services/http:proxy-service-wbbqx:portname1/proxy/: foo (200; 55.761045ms)
Aug 14 08:05:54.909: INFO: (8) /api/v1/namespaces/proxy-4433/services/proxy-service-wbbqx:portname1/proxy/: foo (200; 55.897963ms)
Aug 14 08:05:54.909: INFO: (8) /api/v1/namespaces/proxy-4433/services/http:proxy-service-wbbqx:portname2/proxy/: bar (200; 56.017309ms)
Aug 14 08:05:54.922: INFO: (9) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz/proxy/rewriteme">test</a> (200; 12.732936ms)
Aug 14 08:05:54.923: INFO: (9) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:460/proxy/: tls baz (200; 13.373357ms)
Aug 14 08:05:54.923: INFO: (9) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:160/proxy/: foo (200; 13.538551ms)
Aug 14 08:05:54.923: INFO: (9) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:462/proxy/: tls qux (200; 13.518365ms)
Aug 14 08:05:54.923: INFO: (9) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:1080/proxy/rewriteme">test<... (200; 13.447029ms)
Aug 14 08:05:54.923: INFO: (9) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:443/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:443/proxy/tlsrewritem... (200; 13.446384ms)
Aug 14 08:05:54.923: INFO: (9) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:160/proxy/: foo (200; 13.492162ms)
Aug 14 08:05:54.923: INFO: (9) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:162/proxy/: bar (200; 13.549123ms)
Aug 14 08:05:54.923: INFO: (9) /api/v1/namespaces/proxy-4433/services/https:proxy-service-wbbqx:tlsportname1/proxy/: tls baz (200; 13.555999ms)
Aug 14 08:05:54.923: INFO: (9) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:162/proxy/: bar (200; 13.712053ms)
Aug 14 08:05:54.923: INFO: (9) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:1080/proxy/rewriteme">... (200; 13.605044ms)
Aug 14 08:05:54.924: INFO: (9) /api/v1/namespaces/proxy-4433/services/https:proxy-service-wbbqx:tlsportname2/proxy/: tls qux (200; 14.178732ms)
Aug 14 08:05:54.965: INFO: (9) /api/v1/namespaces/proxy-4433/services/proxy-service-wbbqx:portname1/proxy/: foo (200; 55.365079ms)
Aug 14 08:05:54.965: INFO: (9) /api/v1/namespaces/proxy-4433/services/http:proxy-service-wbbqx:portname1/proxy/: foo (200; 55.532499ms)
Aug 14 08:05:54.965: INFO: (9) /api/v1/namespaces/proxy-4433/services/proxy-service-wbbqx:portname2/proxy/: bar (200; 55.372285ms)
Aug 14 08:05:54.965: INFO: (9) /api/v1/namespaces/proxy-4433/services/http:proxy-service-wbbqx:portname2/proxy/: bar (200; 55.510859ms)
Aug 14 08:05:54.979: INFO: (10) /api/v1/namespaces/proxy-4433/services/http:proxy-service-wbbqx:portname2/proxy/: bar (200; 13.854919ms)
Aug 14 08:05:54.979: INFO: (10) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:160/proxy/: foo (200; 13.899234ms)
Aug 14 08:05:54.979: INFO: (10) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:443/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:443/proxy/tlsrewritem... (200; 13.85996ms)
Aug 14 08:05:54.979: INFO: (10) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:1080/proxy/rewriteme">test<... (200; 13.85435ms)
Aug 14 08:05:54.979: INFO: (10) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:162/proxy/: bar (200; 13.838419ms)
Aug 14 08:05:54.979: INFO: (10) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz/proxy/rewriteme">test</a> (200; 13.850541ms)
Aug 14 08:05:54.979: INFO: (10) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:1080/proxy/rewriteme">... (200; 14.051298ms)
Aug 14 08:05:54.979: INFO: (10) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:160/proxy/: foo (200; 13.950342ms)
Aug 14 08:05:54.979: INFO: (10) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:462/proxy/: tls qux (200; 13.928512ms)
Aug 14 08:05:54.979: INFO: (10) /api/v1/namespaces/proxy-4433/services/https:proxy-service-wbbqx:tlsportname1/proxy/: tls baz (200; 13.920618ms)
Aug 14 08:05:54.979: INFO: (10) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:460/proxy/: tls baz (200; 13.969159ms)
Aug 14 08:05:54.979: INFO: (10) /api/v1/namespaces/proxy-4433/services/https:proxy-service-wbbqx:tlsportname2/proxy/: tls qux (200; 13.90111ms)
Aug 14 08:05:55.022: INFO: (10) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:162/proxy/: bar (200; 56.976403ms)
Aug 14 08:05:55.022: INFO: (10) /api/v1/namespaces/proxy-4433/services/proxy-service-wbbqx:portname1/proxy/: foo (200; 57.002916ms)
Aug 14 08:05:55.022: INFO: (10) /api/v1/namespaces/proxy-4433/services/proxy-service-wbbqx:portname2/proxy/: bar (200; 57.226047ms)
Aug 14 08:05:55.022: INFO: (10) /api/v1/namespaces/proxy-4433/services/http:proxy-service-wbbqx:portname1/proxy/: foo (200; 57.0846ms)
Aug 14 08:05:55.036: INFO: (11) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:160/proxy/: foo (200; 13.646697ms)
Aug 14 08:05:55.036: INFO: (11) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:462/proxy/: tls qux (200; 13.579169ms)
Aug 14 08:05:55.036: INFO: (11) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:1080/proxy/rewriteme">... (200; 13.570745ms)
Aug 14 08:05:55.036: INFO: (11) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:162/proxy/: bar (200; 13.765807ms)
Aug 14 08:05:55.036: INFO: (11) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:162/proxy/: bar (200; 13.572732ms)
Aug 14 08:05:55.036: INFO: (11) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:1080/proxy/rewriteme">test<... (200; 13.746035ms)
Aug 14 08:05:55.036: INFO: (11) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz/proxy/rewriteme">test</a> (200; 13.673635ms)
Aug 14 08:05:55.037: INFO: (11) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:160/proxy/: foo (200; 13.63476ms)
Aug 14 08:05:55.037: INFO: (11) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:443/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:443/proxy/tlsrewritem... (200; 14.438335ms)
Aug 14 08:05:55.037: INFO: (11) /api/v1/namespaces/proxy-4433/services/https:proxy-service-wbbqx:tlsportname1/proxy/: tls baz (200; 14.38312ms)
Aug 14 08:05:55.037: INFO: (11) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:460/proxy/: tls baz (200; 14.764532ms)
Aug 14 08:05:55.037: INFO: (11) /api/v1/namespaces/proxy-4433/services/https:proxy-service-wbbqx:tlsportname2/proxy/: tls qux (200; 14.431397ms)
Aug 14 08:05:55.038: INFO: (11) /api/v1/namespaces/proxy-4433/services/http:proxy-service-wbbqx:portname1/proxy/: foo (200; 14.815522ms)
Aug 14 08:05:55.038: INFO: (11) /api/v1/namespaces/proxy-4433/services/http:proxy-service-wbbqx:portname2/proxy/: bar (200; 15.096686ms)
Aug 14 08:05:55.038: INFO: (11) /api/v1/namespaces/proxy-4433/services/proxy-service-wbbqx:portname1/proxy/: foo (200; 15.2596ms)
Aug 14 08:05:55.038: INFO: (11) /api/v1/namespaces/proxy-4433/services/proxy-service-wbbqx:portname2/proxy/: bar (200; 15.473495ms)
Aug 14 08:05:55.052: INFO: (12) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:1080/proxy/rewriteme">... (200; 13.165376ms)
Aug 14 08:05:55.052: INFO: (12) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:160/proxy/: foo (200; 13.265149ms)
Aug 14 08:05:55.052: INFO: (12) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:462/proxy/: tls qux (200; 13.210753ms)
Aug 14 08:05:55.052: INFO: (12) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:443/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:443/proxy/tlsrewritem... (200; 13.293365ms)
Aug 14 08:05:55.052: INFO: (12) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:162/proxy/: bar (200; 13.319653ms)
Aug 14 08:05:55.052: INFO: (12) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:460/proxy/: tls baz (200; 13.383875ms)
Aug 14 08:05:55.052: INFO: (12) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz/proxy/rewriteme">test</a> (200; 13.265199ms)
Aug 14 08:05:55.052: INFO: (12) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:160/proxy/: foo (200; 13.295259ms)
Aug 14 08:05:55.052: INFO: (12) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:162/proxy/: bar (200; 13.523764ms)
Aug 14 08:05:55.052: INFO: (12) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:1080/proxy/rewriteme">test<... (200; 13.397ms)
Aug 14 08:05:55.052: INFO: (12) /api/v1/namespaces/proxy-4433/services/https:proxy-service-wbbqx:tlsportname1/proxy/: tls baz (200; 13.633662ms)
Aug 14 08:05:55.053: INFO: (12) /api/v1/namespaces/proxy-4433/services/https:proxy-service-wbbqx:tlsportname2/proxy/: tls qux (200; 14.054907ms)
Aug 14 08:05:55.053: INFO: (12) /api/v1/namespaces/proxy-4433/services/proxy-service-wbbqx:portname2/proxy/: bar (200; 14.754037ms)
Aug 14 08:05:55.053: INFO: (12) /api/v1/namespaces/proxy-4433/services/http:proxy-service-wbbqx:portname1/proxy/: foo (200; 14.614395ms)
Aug 14 08:05:55.053: INFO: (12) /api/v1/namespaces/proxy-4433/services/proxy-service-wbbqx:portname1/proxy/: foo (200; 14.76376ms)
Aug 14 08:05:55.054: INFO: (12) /api/v1/namespaces/proxy-4433/services/http:proxy-service-wbbqx:portname2/proxy/: bar (200; 14.934412ms)
Aug 14 08:05:55.067: INFO: (13) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:160/proxy/: foo (200; 12.753305ms)
Aug 14 08:05:55.067: INFO: (13) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:443/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:443/proxy/tlsrewritem... (200; 12.784866ms)
Aug 14 08:05:55.067: INFO: (13) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:162/proxy/: bar (200; 12.894834ms)
Aug 14 08:05:55.067: INFO: (13) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:1080/proxy/rewriteme">test<... (200; 12.787206ms)
Aug 14 08:05:55.067: INFO: (13) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:462/proxy/: tls qux (200; 13.031642ms)
Aug 14 08:05:55.067: INFO: (13) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz/proxy/rewriteme">test</a> (200; 12.897942ms)
Aug 14 08:05:55.067: INFO: (13) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:160/proxy/: foo (200; 12.88898ms)
Aug 14 08:05:55.067: INFO: (13) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:162/proxy/: bar (200; 12.965948ms)
Aug 14 08:05:55.067: INFO: (13) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:1080/proxy/rewriteme">... (200; 12.930318ms)
Aug 14 08:05:55.067: INFO: (13) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:460/proxy/: tls baz (200; 12.920209ms)
Aug 14 08:05:55.067: INFO: (13) /api/v1/namespaces/proxy-4433/services/https:proxy-service-wbbqx:tlsportname1/proxy/: tls baz (200; 13.539ms)
Aug 14 08:05:55.068: INFO: (13) /api/v1/namespaces/proxy-4433/services/https:proxy-service-wbbqx:tlsportname2/proxy/: tls qux (200; 13.80393ms)
Aug 14 08:05:55.068: INFO: (13) /api/v1/namespaces/proxy-4433/services/proxy-service-wbbqx:portname2/proxy/: bar (200; 14.138373ms)
Aug 14 08:05:55.068: INFO: (13) /api/v1/namespaces/proxy-4433/services/http:proxy-service-wbbqx:portname2/proxy/: bar (200; 14.524711ms)
Aug 14 08:05:55.068: INFO: (13) /api/v1/namespaces/proxy-4433/services/proxy-service-wbbqx:portname1/proxy/: foo (200; 14.589211ms)
Aug 14 08:05:55.068: INFO: (13) /api/v1/namespaces/proxy-4433/services/http:proxy-service-wbbqx:portname1/proxy/: foo (200; 14.66831ms)
Aug 14 08:05:55.082: INFO: (14) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:1080/proxy/rewriteme">... (200; 13.355776ms)
Aug 14 08:05:55.082: INFO: (14) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:162/proxy/: bar (200; 13.410812ms)
Aug 14 08:05:55.082: INFO: (14) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:1080/proxy/rewriteme">test<... (200; 13.298711ms)
Aug 14 08:05:55.082: INFO: (14) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz/proxy/rewriteme">test</a> (200; 13.380847ms)
Aug 14 08:05:55.082: INFO: (14) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:160/proxy/: foo (200; 13.371296ms)
Aug 14 08:05:55.082: INFO: (14) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:443/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:443/proxy/tlsrewritem... (200; 13.530032ms)
Aug 14 08:05:55.083: INFO: (14) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:462/proxy/: tls qux (200; 13.86931ms)
Aug 14 08:05:55.083: INFO: (14) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:162/proxy/: bar (200; 13.873294ms)
Aug 14 08:05:55.083: INFO: (14) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:460/proxy/: tls baz (200; 13.870969ms)
Aug 14 08:05:55.083: INFO: (14) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:160/proxy/: foo (200; 13.921889ms)
Aug 14 08:05:55.083: INFO: (14) /api/v1/namespaces/proxy-4433/services/https:proxy-service-wbbqx:tlsportname1/proxy/: tls baz (200; 13.953237ms)
Aug 14 08:05:55.083: INFO: (14) /api/v1/namespaces/proxy-4433/services/https:proxy-service-wbbqx:tlsportname2/proxy/: tls qux (200; 13.948579ms)
Aug 14 08:05:55.083: INFO: (14) /api/v1/namespaces/proxy-4433/services/http:proxy-service-wbbqx:portname2/proxy/: bar (200; 14.315083ms)
Aug 14 08:05:55.126: INFO: (14) /api/v1/namespaces/proxy-4433/services/proxy-service-wbbqx:portname1/proxy/: foo (200; 57.421883ms)
Aug 14 08:05:55.126: INFO: (14) /api/v1/namespaces/proxy-4433/services/http:proxy-service-wbbqx:portname1/proxy/: foo (200; 57.260432ms)
Aug 14 08:05:55.126: INFO: (14) /api/v1/namespaces/proxy-4433/services/proxy-service-wbbqx:portname2/proxy/: bar (200; 57.272066ms)
Aug 14 08:05:55.144: INFO: (15) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:162/proxy/: bar (200; 17.11832ms)
Aug 14 08:05:55.144: INFO: (15) /api/v1/namespaces/proxy-4433/services/https:proxy-service-wbbqx:tlsportname1/proxy/: tls baz (200; 17.112598ms)
Aug 14 08:05:55.144: INFO: (15) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:1080/proxy/rewriteme">... (200; 17.154268ms)
Aug 14 08:05:55.144: INFO: (15) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz/proxy/rewriteme">test</a> (200; 17.148451ms)
Aug 14 08:05:55.144: INFO: (15) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:160/proxy/: foo (200; 17.273713ms)
Aug 14 08:05:55.144: INFO: (15) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:460/proxy/: tls baz (200; 17.153293ms)
Aug 14 08:05:55.144: INFO: (15) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:160/proxy/: foo (200; 17.12883ms)
Aug 14 08:05:55.144: INFO: (15) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:443/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:443/proxy/tlsrewritem... (200; 17.095926ms)
Aug 14 08:05:55.144: INFO: (15) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:462/proxy/: tls qux (200; 17.251066ms)
Aug 14 08:05:55.144: INFO: (15) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:1080/proxy/rewriteme">test<... (200; 17.130866ms)
Aug 14 08:05:55.144: INFO: (15) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:162/proxy/: bar (200; 17.037848ms)
Aug 14 08:05:55.144: INFO: (15) /api/v1/namespaces/proxy-4433/services/https:proxy-service-wbbqx:tlsportname2/proxy/: tls qux (200; 17.541503ms)
Aug 14 08:05:55.145: INFO: (15) /api/v1/namespaces/proxy-4433/services/http:proxy-service-wbbqx:portname1/proxy/: foo (200; 18.282464ms)
Aug 14 08:05:55.145: INFO: (15) /api/v1/namespaces/proxy-4433/services/proxy-service-wbbqx:portname2/proxy/: bar (200; 18.662796ms)
Aug 14 08:05:55.145: INFO: (15) /api/v1/namespaces/proxy-4433/services/proxy-service-wbbqx:portname1/proxy/: foo (200; 18.519019ms)
Aug 14 08:05:55.145: INFO: (15) /api/v1/namespaces/proxy-4433/services/http:proxy-service-wbbqx:portname2/proxy/: bar (200; 18.498217ms)
Aug 14 08:05:55.160: INFO: (16) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz/proxy/rewriteme">test</a> (200; 14.29493ms)
Aug 14 08:05:55.160: INFO: (16) /api/v1/namespaces/proxy-4433/services/https:proxy-service-wbbqx:tlsportname1/proxy/: tls baz (200; 14.404053ms)
Aug 14 08:05:55.160: INFO: (16) /api/v1/namespaces/proxy-4433/services/proxy-service-wbbqx:portname1/proxy/: foo (200; 14.472749ms)
Aug 14 08:05:55.160: INFO: (16) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:443/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:443/proxy/tlsrewritem... (200; 14.509127ms)
Aug 14 08:05:55.160: INFO: (16) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:460/proxy/: tls baz (200; 14.254893ms)
Aug 14 08:05:55.160: INFO: (16) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:462/proxy/: tls qux (200; 14.271307ms)
Aug 14 08:05:55.160: INFO: (16) /api/v1/namespaces/proxy-4433/services/http:proxy-service-wbbqx:portname2/proxy/: bar (200; 14.450169ms)
Aug 14 08:05:55.160: INFO: (16) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:1080/proxy/rewriteme">... (200; 14.351011ms)
Aug 14 08:05:55.160: INFO: (16) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:162/proxy/: bar (200; 14.576306ms)
Aug 14 08:05:55.160: INFO: (16) /api/v1/namespaces/proxy-4433/services/https:proxy-service-wbbqx:tlsportname2/proxy/: tls qux (200; 14.389462ms)
Aug 14 08:05:55.160: INFO: (16) /api/v1/namespaces/proxy-4433/services/http:proxy-service-wbbqx:portname1/proxy/: foo (200; 14.638313ms)
Aug 14 08:05:55.160: INFO: (16) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:1080/proxy/rewriteme">test<... (200; 14.361344ms)
Aug 14 08:05:55.201: INFO: (16) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:160/proxy/: foo (200; 55.687378ms)
Aug 14 08:05:55.201: INFO: (16) /api/v1/namespaces/proxy-4433/services/proxy-service-wbbqx:portname2/proxy/: bar (200; 55.809633ms)
Aug 14 08:05:55.201: INFO: (16) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:162/proxy/: bar (200; 55.753043ms)
Aug 14 08:05:55.201: INFO: (16) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:160/proxy/: foo (200; 55.776511ms)
Aug 14 08:05:55.215: INFO: (17) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:1080/proxy/rewriteme">... (200; 12.998167ms)
Aug 14 08:05:55.215: INFO: (17) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:443/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:443/proxy/tlsrewritem... (200; 13.384014ms)
Aug 14 08:05:55.215: INFO: (17) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz/proxy/rewriteme">test</a> (200; 13.354183ms)
Aug 14 08:05:55.215: INFO: (17) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:162/proxy/: bar (200; 13.454038ms)
Aug 14 08:05:55.215: INFO: (17) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:162/proxy/: bar (200; 13.433469ms)
Aug 14 08:05:55.215: INFO: (17) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:1080/proxy/rewriteme">test<... (200; 13.461617ms)
Aug 14 08:05:55.215: INFO: (17) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:160/proxy/: foo (200; 13.627878ms)
Aug 14 08:05:55.215: INFO: (17) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:460/proxy/: tls baz (200; 13.463251ms)
Aug 14 08:05:55.215: INFO: (17) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:462/proxy/: tls qux (200; 13.775972ms)
Aug 14 08:05:55.215: INFO: (17) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:160/proxy/: foo (200; 13.597059ms)
Aug 14 08:05:55.216: INFO: (17) /api/v1/namespaces/proxy-4433/services/https:proxy-service-wbbqx:tlsportname1/proxy/: tls baz (200; 14.154603ms)
Aug 14 08:05:55.216: INFO: (17) /api/v1/namespaces/proxy-4433/services/https:proxy-service-wbbqx:tlsportname2/proxy/: tls qux (200; 14.279814ms)
Aug 14 08:05:55.217: INFO: (17) /api/v1/namespaces/proxy-4433/services/http:proxy-service-wbbqx:portname1/proxy/: foo (200; 15.140069ms)
Aug 14 08:05:55.217: INFO: (17) /api/v1/namespaces/proxy-4433/services/proxy-service-wbbqx:portname1/proxy/: foo (200; 15.887323ms)
Aug 14 08:05:55.217: INFO: (17) /api/v1/namespaces/proxy-4433/services/proxy-service-wbbqx:portname2/proxy/: bar (200; 15.789201ms)
Aug 14 08:05:55.217: INFO: (17) /api/v1/namespaces/proxy-4433/services/http:proxy-service-wbbqx:portname2/proxy/: bar (200; 15.946824ms)
Aug 14 08:05:55.231: INFO: (18) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:160/proxy/: foo (200; 13.585385ms)
Aug 14 08:05:55.232: INFO: (18) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:160/proxy/: foo (200; 13.666043ms)
Aug 14 08:05:55.232: INFO: (18) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:1080/proxy/rewriteme">test<... (200; 13.68666ms)
Aug 14 08:05:55.232: INFO: (18) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:462/proxy/: tls qux (200; 13.684751ms)
Aug 14 08:05:55.232: INFO: (18) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:443/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:443/proxy/tlsrewritem... (200; 13.86922ms)
Aug 14 08:05:55.232: INFO: (18) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:460/proxy/: tls baz (200; 13.816581ms)
Aug 14 08:05:55.232: INFO: (18) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:162/proxy/: bar (200; 13.680917ms)
Aug 14 08:05:55.232: INFO: (18) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:1080/proxy/rewriteme">... (200; 13.744444ms)
Aug 14 08:05:55.232: INFO: (18) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz/proxy/rewriteme">test</a> (200; 13.858906ms)
Aug 14 08:05:55.232: INFO: (18) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:162/proxy/: bar (200; 13.993574ms)
Aug 14 08:05:55.232: INFO: (18) /api/v1/namespaces/proxy-4433/services/https:proxy-service-wbbqx:tlsportname1/proxy/: tls baz (200; 14.284271ms)
Aug 14 08:05:55.232: INFO: (18) /api/v1/namespaces/proxy-4433/services/https:proxy-service-wbbqx:tlsportname2/proxy/: tls qux (200; 14.416849ms)
Aug 14 08:05:55.232: INFO: (18) /api/v1/namespaces/proxy-4433/services/http:proxy-service-wbbqx:portname2/proxy/: bar (200; 14.693157ms)
Aug 14 08:05:55.232: INFO: (18) /api/v1/namespaces/proxy-4433/services/proxy-service-wbbqx:portname1/proxy/: foo (200; 14.659374ms)
Aug 14 08:05:55.233: INFO: (18) /api/v1/namespaces/proxy-4433/services/http:proxy-service-wbbqx:portname1/proxy/: foo (200; 14.845075ms)
Aug 14 08:05:55.233: INFO: (18) /api/v1/namespaces/proxy-4433/services/proxy-service-wbbqx:portname2/proxy/: bar (200; 15.037ms)
Aug 14 08:05:55.246: INFO: (19) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:1080/proxy/rewriteme">test<... (200; 12.64398ms)
Aug 14 08:05:55.246: INFO: (19) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:162/proxy/: bar (200; 12.858824ms)
Aug 14 08:05:55.246: INFO: (19) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:160/proxy/: foo (200; 12.897248ms)
Aug 14 08:05:55.246: INFO: (19) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz:162/proxy/: bar (200; 13.042974ms)
Aug 14 08:05:55.246: INFO: (19) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:1080/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:1080/proxy/rewriteme">... (200; 12.975217ms)
Aug 14 08:05:55.246: INFO: (19) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:443/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:443/proxy/tlsrewritem... (200; 13.150032ms)
Aug 14 08:05:55.246: INFO: (19) /api/v1/namespaces/proxy-4433/pods/http:proxy-service-wbbqx-xpphz:160/proxy/: foo (200; 12.981312ms)
Aug 14 08:05:55.246: INFO: (19) /api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz/proxy/: <a href="/api/v1/namespaces/proxy-4433/pods/proxy-service-wbbqx-xpphz/proxy/rewriteme">test</a> (200; 13.014842ms)
Aug 14 08:05:55.246: INFO: (19) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:462/proxy/: tls qux (200; 13.103862ms)
Aug 14 08:05:55.246: INFO: (19) /api/v1/namespaces/proxy-4433/services/https:proxy-service-wbbqx:tlsportname1/proxy/: tls baz (200; 13.293968ms)
Aug 14 08:05:55.246: INFO: (19) /api/v1/namespaces/proxy-4433/pods/https:proxy-service-wbbqx-xpphz:460/proxy/: tls baz (200; 13.180229ms)
Aug 14 08:05:55.246: INFO: (19) /api/v1/namespaces/proxy-4433/services/https:proxy-service-wbbqx:tlsportname2/proxy/: tls qux (200; 13.17422ms)
Aug 14 08:05:55.247: INFO: (19) /api/v1/namespaces/proxy-4433/services/proxy-service-wbbqx:portname2/proxy/: bar (200; 14.287377ms)
Aug 14 08:05:55.248: INFO: (19) /api/v1/namespaces/proxy-4433/services/proxy-service-wbbqx:portname1/proxy/: foo (200; 14.818026ms)
Aug 14 08:05:55.248: INFO: (19) /api/v1/namespaces/proxy-4433/services/http:proxy-service-wbbqx:portname2/proxy/: bar (200; 14.767385ms)
Aug 14 08:05:55.248: INFO: (19) /api/v1/namespaces/proxy-4433/services/http:proxy-service-wbbqx:portname1/proxy/: foo (200; 14.866063ms)
STEP: deleting ReplicationController proxy-service-wbbqx in namespace proxy-4433, will wait for the garbage collector to delete the pods
Aug 14 08:05:55.464: INFO: Deleting ReplicationController proxy-service-wbbqx took: 155.59922ms
Aug 14 08:05:56.065: INFO: Terminating ReplicationController proxy-service-wbbqx pods took: 600.307404ms
[AfterEach] version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 08:06:06.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-4433" for this suite.
Aug 14 08:06:12.418: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 08:06:12.837: INFO: namespace proxy-4433 deletion completed in 6.453064318s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 08:06:12.838: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1514
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 14 08:06:13.170: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0bfa6c07-0836-4f9d-942f-a6912562e446" in namespace "downward-api-1514" to be "success or failure"
Aug 14 08:06:13.180: INFO: Pod "downwardapi-volume-0bfa6c07-0836-4f9d-942f-a6912562e446": Phase="Pending", Reason="", readiness=false. Elapsed: 9.886128ms
Aug 14 08:06:15.191: INFO: Pod "downwardapi-volume-0bfa6c07-0836-4f9d-942f-a6912562e446": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020966185s
STEP: Saw pod success
Aug 14 08:06:15.191: INFO: Pod "downwardapi-volume-0bfa6c07-0836-4f9d-942f-a6912562e446" satisfied condition "success or failure"
Aug 14 08:06:15.201: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod downwardapi-volume-0bfa6c07-0836-4f9d-942f-a6912562e446 container client-container: <nil>
STEP: delete the pod
Aug 14 08:06:15.233: INFO: Waiting for pod downwardapi-volume-0bfa6c07-0836-4f9d-942f-a6912562e446 to disappear
Aug 14 08:06:15.243: INFO: Pod downwardapi-volume-0bfa6c07-0836-4f9d-942f-a6912562e446 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 08:06:15.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1514" for this suite.
Aug 14 08:06:21.298: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 08:06:21.687: INFO: namespace downward-api-1514 deletion completed in 6.424692607s
•SSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 14 08:06:21.687: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-2934
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test hostPath mode
Aug 14 08:06:21.975: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-2934" to be "success or failure"
Aug 14 08:06:21.985: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 10.225601ms
Aug 14 08:06:23.997: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021778793s
Aug 14 08:06:26.009: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033951797s
STEP: Saw pod success
Aug 14 08:06:26.009: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Aug 14 08:06:26.019: INFO: Trying to get logs from node shoot--it--tm-6jaqb-cpu-worker-z1-cf45c545f-f2rpp pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Aug 14 08:06:26.064: INFO: Waiting for pod pod-host-path-test to disappear
Aug 14 08:06:26.075: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 14 08:06:26.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-2934" for this suite.
Aug 14 08:06:32.128: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 14 08:06:32.524: INFO: namespace hostpath-2934 deletion completed in 6.430662059s
•Aug 14 08:06:32.524: INFO: Running AfterSuite actions on all nodes
Aug 14 08:06:32.538: INFO: Running AfterSuite actions on node 1
Aug 14 08:06:32.538: INFO: Skipping dumping logs from cluster

Ran 212 of 4413 Specs in 5377.672 seconds
SUCCESS! -- 212 Passed | 0 Failed | 0 Flaked | 0 Pending | 4201 Skipped
PASS

Ginkgo ran 1 suite in 1h30m19.008851271s
Test Suite Passed
