I0812 16:09:42.541591      15 test_context.go:406] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-213645099
I0812 16:09:42.548695      15 e2e.go:241] Starting e2e run "d3dd34f7-7819-46ed-9db3-33de185b0b94" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1565626180 - Will randomize all specs
Will run 215 of 4413 specs

Aug 12 16:09:42.936: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
Aug 12 16:09:42.938: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Aug 12 16:09:43.007: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Aug 12 16:09:43.063: INFO: 15 / 15 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Aug 12 16:09:43.063: INFO: expected 3 pod replicas in namespace 'kube-system', 3 are Running and Ready.
Aug 12 16:09:43.064: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Aug 12 16:09:43.077: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'cilium' (0 seconds elapsed)
Aug 12 16:09:43.077: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'csi-do-node' (0 seconds elapsed)
Aug 12 16:09:43.077: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'do-node-agent' (0 seconds elapsed)
Aug 12 16:09:43.077: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Aug 12 16:09:43.078: INFO: e2e test version: v1.15.2
Aug 12 16:09:43.081: INFO: kube-apiserver version: v1.15.2
S
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:09:43.084: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename proxy
Aug 12 16:09:43.189: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-kxrc2 in namespace proxy-6315
I0812 16:09:43.300053      15 runners.go:180] Created replication controller with name: proxy-service-kxrc2, namespace: proxy-6315, replica count: 1
I0812 16:09:44.357840      15 runners.go:180] proxy-service-kxrc2 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0812 16:09:45.358518      15 runners.go:180] proxy-service-kxrc2 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0812 16:09:46.358907      15 runners.go:180] proxy-service-kxrc2 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0812 16:09:47.359392      15 runners.go:180] proxy-service-kxrc2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0812 16:09:48.360343      15 runners.go:180] proxy-service-kxrc2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0812 16:09:49.361001      15 runners.go:180] proxy-service-kxrc2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0812 16:09:50.361501      15 runners.go:180] proxy-service-kxrc2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0812 16:09:51.362336      15 runners.go:180] proxy-service-kxrc2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0812 16:09:52.362975      15 runners.go:180] proxy-service-kxrc2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0812 16:09:53.363461      15 runners.go:180] proxy-service-kxrc2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0812 16:09:54.363943      15 runners.go:180] proxy-service-kxrc2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0812 16:09:55.364533      15 runners.go:180] proxy-service-kxrc2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0812 16:09:56.365010      15 runners.go:180] proxy-service-kxrc2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0812 16:09:57.365557      15 runners.go:180] proxy-service-kxrc2 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 12 16:09:57.372: INFO: setup took 14.18072289s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Aug 12 16:09:57.411: INFO: (0) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:1080/proxy/rewriteme">test<... (200; 33.767691ms)
Aug 12 16:09:57.412: INFO: (0) /api/v1/namespaces/proxy-6315/services/http:proxy-service-kxrc2:portname2/proxy/: bar (200; 38.757209ms)
Aug 12 16:09:57.412: INFO: (0) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m/proxy/rewriteme">test</a> (200; 34.609468ms)
Aug 12 16:09:57.415: INFO: (0) /api/v1/namespaces/proxy-6315/services/http:proxy-service-kxrc2:portname1/proxy/: foo (200; 40.816438ms)
Aug 12 16:09:57.416: INFO: (0) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:162/proxy/: bar (200; 41.022436ms)
Aug 12 16:09:57.416: INFO: (0) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:162/proxy/: bar (200; 41.824505ms)
Aug 12 16:09:57.417: INFO: (0) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:1080/proxy/rewriteme">... (200; 42.692757ms)
Aug 12 16:09:57.417: INFO: (0) /api/v1/namespaces/proxy-6315/services/proxy-service-kxrc2:portname1/proxy/: foo (200; 39.425055ms)
Aug 12 16:09:57.417: INFO: (0) /api/v1/namespaces/proxy-6315/services/proxy-service-kxrc2:portname2/proxy/: bar (200; 42.96128ms)
Aug 12 16:09:57.417: INFO: (0) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:160/proxy/: foo (200; 43.376943ms)
Aug 12 16:09:57.417: INFO: (0) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:160/proxy/: foo (200; 43.553401ms)
Aug 12 16:09:57.425: INFO: (0) /api/v1/namespaces/proxy-6315/services/https:proxy-service-kxrc2:tlsportname2/proxy/: tls qux (200; 50.33608ms)
Aug 12 16:09:57.425: INFO: (0) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:460/proxy/: tls baz (200; 46.94795ms)
Aug 12 16:09:57.426: INFO: (0) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:462/proxy/: tls qux (200; 47.35325ms)
Aug 12 16:09:57.427: INFO: (0) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:443/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:443/proxy/tlsrewritem... (200; 51.355999ms)
Aug 12 16:09:57.427: INFO: (0) /api/v1/namespaces/proxy-6315/services/https:proxy-service-kxrc2:tlsportname1/proxy/: tls baz (200; 54.929117ms)
Aug 12 16:09:57.442: INFO: (1) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:460/proxy/: tls baz (200; 13.745468ms)
Aug 12 16:09:57.443: INFO: (1) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m/proxy/rewriteme">test</a> (200; 14.905798ms)
Aug 12 16:09:57.443: INFO: (1) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:1080/proxy/rewriteme">test<... (200; 14.691633ms)
Aug 12 16:09:57.443: INFO: (1) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:462/proxy/: tls qux (200; 14.28357ms)
Aug 12 16:09:57.453: INFO: (1) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:160/proxy/: foo (200; 23.41965ms)
Aug 12 16:09:57.453: INFO: (1) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:162/proxy/: bar (200; 22.360065ms)
Aug 12 16:09:57.453: INFO: (1) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:443/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:443/proxy/tlsrewritem... (200; 22.084197ms)
Aug 12 16:09:57.454: INFO: (1) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:162/proxy/: bar (200; 22.403041ms)
Aug 12 16:09:57.454: INFO: (1) /api/v1/namespaces/proxy-6315/services/https:proxy-service-kxrc2:tlsportname1/proxy/: tls baz (200; 24.712536ms)
Aug 12 16:09:57.454: INFO: (1) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:160/proxy/: foo (200; 24.232267ms)
Aug 12 16:09:57.454: INFO: (1) /api/v1/namespaces/proxy-6315/services/http:proxy-service-kxrc2:portname2/proxy/: bar (200; 24.979446ms)
Aug 12 16:09:57.454: INFO: (1) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:1080/proxy/rewriteme">... (200; 24.172512ms)
Aug 12 16:09:57.455: INFO: (1) /api/v1/namespaces/proxy-6315/services/https:proxy-service-kxrc2:tlsportname2/proxy/: tls qux (200; 23.871705ms)
Aug 12 16:09:57.456: INFO: (1) /api/v1/namespaces/proxy-6315/services/proxy-service-kxrc2:portname1/proxy/: foo (200; 27.999247ms)
Aug 12 16:09:57.456: INFO: (1) /api/v1/namespaces/proxy-6315/services/proxy-service-kxrc2:portname2/proxy/: bar (200; 26.017816ms)
Aug 12 16:09:57.456: INFO: (1) /api/v1/namespaces/proxy-6315/services/http:proxy-service-kxrc2:portname1/proxy/: foo (200; 26.026166ms)
Aug 12 16:09:57.472: INFO: (2) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:162/proxy/: bar (200; 15.114588ms)
Aug 12 16:09:57.479: INFO: (2) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:460/proxy/: tls baz (200; 21.717785ms)
Aug 12 16:09:57.480: INFO: (2) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:462/proxy/: tls qux (200; 22.634075ms)
Aug 12 16:09:57.480: INFO: (2) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m/proxy/rewriteme">test</a> (200; 22.448076ms)
Aug 12 16:09:57.480: INFO: (2) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:160/proxy/: foo (200; 22.208633ms)
Aug 12 16:09:57.480: INFO: (2) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:160/proxy/: foo (200; 21.932687ms)
Aug 12 16:09:57.480: INFO: (2) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:1080/proxy/rewriteme">... (200; 21.836056ms)
Aug 12 16:09:57.480: INFO: (2) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:1080/proxy/rewriteme">test<... (200; 22.624137ms)
Aug 12 16:09:57.480: INFO: (2) /api/v1/namespaces/proxy-6315/services/proxy-service-kxrc2:portname2/proxy/: bar (200; 22.453891ms)
Aug 12 16:09:57.482: INFO: (2) /api/v1/namespaces/proxy-6315/services/https:proxy-service-kxrc2:tlsportname1/proxy/: tls baz (200; 25.21577ms)
Aug 12 16:09:57.483: INFO: (2) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:443/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:443/proxy/tlsrewritem... (200; 23.966922ms)
Aug 12 16:09:57.483: INFO: (2) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:162/proxy/: bar (200; 25.017801ms)
Aug 12 16:09:57.484: INFO: (2) /api/v1/namespaces/proxy-6315/services/http:proxy-service-kxrc2:portname2/proxy/: bar (200; 25.756776ms)
Aug 12 16:09:57.487: INFO: (2) /api/v1/namespaces/proxy-6315/services/http:proxy-service-kxrc2:portname1/proxy/: foo (200; 29.179665ms)
Aug 12 16:09:57.489: INFO: (2) /api/v1/namespaces/proxy-6315/services/https:proxy-service-kxrc2:tlsportname2/proxy/: tls qux (200; 30.106552ms)
Aug 12 16:09:57.490: INFO: (2) /api/v1/namespaces/proxy-6315/services/proxy-service-kxrc2:portname1/proxy/: foo (200; 31.000308ms)
Aug 12 16:09:57.503: INFO: (3) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:443/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:443/proxy/tlsrewritem... (200; 12.685373ms)
Aug 12 16:09:57.507: INFO: (3) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m/proxy/rewriteme">test</a> (200; 15.746206ms)
Aug 12 16:09:57.507: INFO: (3) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:462/proxy/: tls qux (200; 15.256067ms)
Aug 12 16:09:57.507: INFO: (3) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:1080/proxy/rewriteme">test<... (200; 15.668972ms)
Aug 12 16:09:57.507: INFO: (3) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:460/proxy/: tls baz (200; 15.516306ms)
Aug 12 16:09:57.514: INFO: (3) /api/v1/namespaces/proxy-6315/services/https:proxy-service-kxrc2:tlsportname1/proxy/: tls baz (200; 23.336597ms)
Aug 12 16:09:57.514: INFO: (3) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:160/proxy/: foo (200; 22.29588ms)
Aug 12 16:09:57.517: INFO: (3) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:162/proxy/: bar (200; 23.69205ms)
Aug 12 16:09:57.518: INFO: (3) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:1080/proxy/rewriteme">... (200; 25.0368ms)
Aug 12 16:09:57.518: INFO: (3) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:162/proxy/: bar (200; 24.717001ms)
Aug 12 16:09:57.518: INFO: (3) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:160/proxy/: foo (200; 25.850534ms)
Aug 12 16:09:57.520: INFO: (3) /api/v1/namespaces/proxy-6315/services/proxy-service-kxrc2:portname1/proxy/: foo (200; 27.291908ms)
Aug 12 16:09:57.521: INFO: (3) /api/v1/namespaces/proxy-6315/services/https:proxy-service-kxrc2:tlsportname2/proxy/: tls qux (200; 28.260143ms)
Aug 12 16:09:57.522: INFO: (3) /api/v1/namespaces/proxy-6315/services/proxy-service-kxrc2:portname2/proxy/: bar (200; 30.226288ms)
Aug 12 16:09:57.523: INFO: (3) /api/v1/namespaces/proxy-6315/services/http:proxy-service-kxrc2:portname2/proxy/: bar (200; 31.429456ms)
Aug 12 16:09:57.524: INFO: (3) /api/v1/namespaces/proxy-6315/services/http:proxy-service-kxrc2:portname1/proxy/: foo (200; 31.136024ms)
Aug 12 16:09:57.537: INFO: (4) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:460/proxy/: tls baz (200; 12.721415ms)
Aug 12 16:09:57.541: INFO: (4) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:160/proxy/: foo (200; 15.627544ms)
Aug 12 16:09:57.541: INFO: (4) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:1080/proxy/rewriteme">... (200; 15.135652ms)
Aug 12 16:09:57.542: INFO: (4) /api/v1/namespaces/proxy-6315/services/proxy-service-kxrc2:portname2/proxy/: bar (200; 17.341063ms)
Aug 12 16:09:57.546: INFO: (4) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:462/proxy/: tls qux (200; 19.2967ms)
Aug 12 16:09:57.547: INFO: (4) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:160/proxy/: foo (200; 21.758252ms)
Aug 12 16:09:57.548: INFO: (4) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:162/proxy/: bar (200; 21.684353ms)
Aug 12 16:09:57.549: INFO: (4) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:162/proxy/: bar (200; 22.730349ms)
Aug 12 16:09:57.550: INFO: (4) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m/proxy/rewriteme">test</a> (200; 23.016077ms)
Aug 12 16:09:57.551: INFO: (4) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:1080/proxy/rewriteme">test<... (200; 23.811093ms)
Aug 12 16:09:57.551: INFO: (4) /api/v1/namespaces/proxy-6315/services/http:proxy-service-kxrc2:portname2/proxy/: bar (200; 26.487882ms)
Aug 12 16:09:57.552: INFO: (4) /api/v1/namespaces/proxy-6315/services/http:proxy-service-kxrc2:portname1/proxy/: foo (200; 26.333081ms)
Aug 12 16:09:57.552: INFO: (4) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:443/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:443/proxy/tlsrewritem... (200; 26.116419ms)
Aug 12 16:09:57.552: INFO: (4) /api/v1/namespaces/proxy-6315/services/proxy-service-kxrc2:portname1/proxy/: foo (200; 26.367001ms)
Aug 12 16:09:57.552: INFO: (4) /api/v1/namespaces/proxy-6315/services/https:proxy-service-kxrc2:tlsportname1/proxy/: tls baz (200; 25.823865ms)
Aug 12 16:09:57.552: INFO: (4) /api/v1/namespaces/proxy-6315/services/https:proxy-service-kxrc2:tlsportname2/proxy/: tls qux (200; 26.341221ms)
Aug 12 16:09:57.573: INFO: (5) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:1080/proxy/rewriteme">... (200; 18.629735ms)
Aug 12 16:09:57.575: INFO: (5) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:162/proxy/: bar (200; 19.443968ms)
Aug 12 16:09:57.575: INFO: (5) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m/proxy/rewriteme">test</a> (200; 19.167932ms)
Aug 12 16:09:57.579: INFO: (5) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:162/proxy/: bar (200; 23.102545ms)
Aug 12 16:09:57.579: INFO: (5) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:160/proxy/: foo (200; 21.428489ms)
Aug 12 16:09:57.579: INFO: (5) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:1080/proxy/rewriteme">test<... (200; 22.269222ms)
Aug 12 16:09:57.580: INFO: (5) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:160/proxy/: foo (200; 23.188684ms)
Aug 12 16:09:57.581: INFO: (5) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:462/proxy/: tls qux (200; 23.889458ms)
Aug 12 16:09:57.582: INFO: (5) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:460/proxy/: tls baz (200; 25.241826ms)
Aug 12 16:09:57.582: INFO: (5) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:443/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:443/proxy/tlsrewritem... (200; 26.338818ms)
Aug 12 16:09:57.582: INFO: (5) /api/v1/namespaces/proxy-6315/services/http:proxy-service-kxrc2:portname2/proxy/: bar (200; 25.560266ms)
Aug 12 16:09:57.583: INFO: (5) /api/v1/namespaces/proxy-6315/services/http:proxy-service-kxrc2:portname1/proxy/: foo (200; 25.459849ms)
Aug 12 16:09:57.583: INFO: (5) /api/v1/namespaces/proxy-6315/services/proxy-service-kxrc2:portname1/proxy/: foo (200; 28.543036ms)
Aug 12 16:09:57.583: INFO: (5) /api/v1/namespaces/proxy-6315/services/proxy-service-kxrc2:portname2/proxy/: bar (200; 26.472752ms)
Aug 12 16:09:57.584: INFO: (5) /api/v1/namespaces/proxy-6315/services/https:proxy-service-kxrc2:tlsportname1/proxy/: tls baz (200; 27.816016ms)
Aug 12 16:09:57.584: INFO: (5) /api/v1/namespaces/proxy-6315/services/https:proxy-service-kxrc2:tlsportname2/proxy/: tls qux (200; 29.395708ms)
Aug 12 16:09:57.598: INFO: (6) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:1080/proxy/rewriteme">... (200; 12.897298ms)
Aug 12 16:09:57.608: INFO: (6) /api/v1/namespaces/proxy-6315/services/http:proxy-service-kxrc2:portname1/proxy/: foo (200; 23.501684ms)
Aug 12 16:09:57.609: INFO: (6) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:162/proxy/: bar (200; 23.605689ms)
Aug 12 16:09:57.609: INFO: (6) /api/v1/namespaces/proxy-6315/services/http:proxy-service-kxrc2:portname2/proxy/: bar (200; 24.688097ms)
Aug 12 16:09:57.609: INFO: (6) /api/v1/namespaces/proxy-6315/services/proxy-service-kxrc2:portname1/proxy/: foo (200; 23.995633ms)
Aug 12 16:09:57.610: INFO: (6) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:462/proxy/: tls qux (200; 23.95949ms)
Aug 12 16:09:57.610: INFO: (6) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:460/proxy/: tls baz (200; 24.373563ms)
Aug 12 16:09:57.610: INFO: (6) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m/proxy/rewriteme">test</a> (200; 24.272473ms)
Aug 12 16:09:57.611: INFO: (6) /api/v1/namespaces/proxy-6315/services/https:proxy-service-kxrc2:tlsportname2/proxy/: tls qux (200; 25.193199ms)
Aug 12 16:09:57.611: INFO: (6) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:160/proxy/: foo (200; 25.073212ms)
Aug 12 16:09:57.612: INFO: (6) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:443/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:443/proxy/tlsrewritem... (200; 26.325927ms)
Aug 12 16:09:57.612: INFO: (6) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:1080/proxy/rewriteme">test<... (200; 26.219481ms)
Aug 12 16:09:57.612: INFO: (6) /api/v1/namespaces/proxy-6315/services/proxy-service-kxrc2:portname2/proxy/: bar (200; 25.820242ms)
Aug 12 16:09:57.612: INFO: (6) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:162/proxy/: bar (200; 27.341412ms)
Aug 12 16:09:57.613: INFO: (6) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:160/proxy/: foo (200; 26.778087ms)
Aug 12 16:09:57.613: INFO: (6) /api/v1/namespaces/proxy-6315/services/https:proxy-service-kxrc2:tlsportname1/proxy/: tls baz (200; 27.404352ms)
Aug 12 16:09:57.626: INFO: (7) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:443/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:443/proxy/tlsrewritem... (200; 13.085123ms)
Aug 12 16:09:57.627: INFO: (7) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m/proxy/rewriteme">test</a> (200; 13.665845ms)
Aug 12 16:09:57.636: INFO: (7) /api/v1/namespaces/proxy-6315/services/https:proxy-service-kxrc2:tlsportname1/proxy/: tls baz (200; 22.678581ms)
Aug 12 16:09:57.636: INFO: (7) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:1080/proxy/rewriteme">test<... (200; 22.562314ms)
Aug 12 16:09:57.636: INFO: (7) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:460/proxy/: tls baz (200; 22.495447ms)
Aug 12 16:09:57.637: INFO: (7) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:462/proxy/: tls qux (200; 22.832661ms)
Aug 12 16:09:57.639: INFO: (7) /api/v1/namespaces/proxy-6315/services/https:proxy-service-kxrc2:tlsportname2/proxy/: tls qux (200; 24.023966ms)
Aug 12 16:09:57.639: INFO: (7) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:162/proxy/: bar (200; 24.50808ms)
Aug 12 16:09:57.640: INFO: (7) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:162/proxy/: bar (200; 25.402619ms)
Aug 12 16:09:57.641: INFO: (7) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:1080/proxy/rewriteme">... (200; 26.357323ms)
Aug 12 16:09:57.641: INFO: (7) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:160/proxy/: foo (200; 27.01753ms)
Aug 12 16:09:57.642: INFO: (7) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:160/proxy/: foo (200; 27.48597ms)
Aug 12 16:09:57.642: INFO: (7) /api/v1/namespaces/proxy-6315/services/http:proxy-service-kxrc2:portname1/proxy/: foo (200; 28.150027ms)
Aug 12 16:09:57.643: INFO: (7) /api/v1/namespaces/proxy-6315/services/http:proxy-service-kxrc2:portname2/proxy/: bar (200; 28.784896ms)
Aug 12 16:09:57.643: INFO: (7) /api/v1/namespaces/proxy-6315/services/proxy-service-kxrc2:portname2/proxy/: bar (200; 29.272142ms)
Aug 12 16:09:57.643: INFO: (7) /api/v1/namespaces/proxy-6315/services/proxy-service-kxrc2:portname1/proxy/: foo (200; 28.840673ms)
Aug 12 16:09:57.653: INFO: (8) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:160/proxy/: foo (200; 8.783807ms)
Aug 12 16:09:57.663: INFO: (8) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:1080/proxy/rewriteme">test<... (200; 18.050537ms)
Aug 12 16:09:57.664: INFO: (8) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:1080/proxy/rewriteme">... (200; 19.287405ms)
Aug 12 16:09:57.665: INFO: (8) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m/proxy/rewriteme">test</a> (200; 19.328248ms)
Aug 12 16:09:57.665: INFO: (8) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:443/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:443/proxy/tlsrewritem... (200; 19.792018ms)
Aug 12 16:09:57.665: INFO: (8) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:460/proxy/: tls baz (200; 19.82037ms)
Aug 12 16:09:57.666: INFO: (8) /api/v1/namespaces/proxy-6315/services/http:proxy-service-kxrc2:portname1/proxy/: foo (200; 20.885734ms)
Aug 12 16:09:57.666: INFO: (8) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:162/proxy/: bar (200; 20.612195ms)
Aug 12 16:09:57.666: INFO: (8) /api/v1/namespaces/proxy-6315/services/proxy-service-kxrc2:portname1/proxy/: foo (200; 20.778811ms)
Aug 12 16:09:57.666: INFO: (8) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:162/proxy/: bar (200; 20.702751ms)
Aug 12 16:09:57.667: INFO: (8) /api/v1/namespaces/proxy-6315/services/https:proxy-service-kxrc2:tlsportname1/proxy/: tls baz (200; 21.669001ms)
Aug 12 16:09:57.668: INFO: (8) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:462/proxy/: tls qux (200; 22.533881ms)
Aug 12 16:09:57.668: INFO: (8) /api/v1/namespaces/proxy-6315/services/https:proxy-service-kxrc2:tlsportname2/proxy/: tls qux (200; 23.242888ms)
Aug 12 16:09:57.670: INFO: (8) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:160/proxy/: foo (200; 24.59704ms)
Aug 12 16:09:57.671: INFO: (8) /api/v1/namespaces/proxy-6315/services/http:proxy-service-kxrc2:portname2/proxy/: bar (200; 25.579166ms)
Aug 12 16:09:57.671: INFO: (8) /api/v1/namespaces/proxy-6315/services/proxy-service-kxrc2:portname2/proxy/: bar (200; 25.921767ms)
Aug 12 16:09:57.691: INFO: (9) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:1080/proxy/rewriteme">... (200; 18.273963ms)
Aug 12 16:09:57.694: INFO: (9) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:162/proxy/: bar (200; 20.24393ms)
Aug 12 16:09:57.694: INFO: (9) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:162/proxy/: bar (200; 21.354122ms)
Aug 12 16:09:57.695: INFO: (9) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:443/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:443/proxy/tlsrewritem... (200; 20.8495ms)
Aug 12 16:09:57.700: INFO: (9) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:1080/proxy/rewriteme">test<... (200; 24.264846ms)
Aug 12 16:09:57.700: INFO: (9) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:160/proxy/: foo (200; 23.175365ms)
Aug 12 16:09:57.701: INFO: (9) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:460/proxy/: tls baz (200; 24.800149ms)
Aug 12 16:09:57.701: INFO: (9) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:160/proxy/: foo (200; 23.540049ms)
Aug 12 16:09:57.703: INFO: (9) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:462/proxy/: tls qux (200; 26.898196ms)
Aug 12 16:09:57.703: INFO: (9) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m/proxy/rewriteme">test</a> (200; 26.792674ms)
Aug 12 16:09:57.706: INFO: (9) /api/v1/namespaces/proxy-6315/services/https:proxy-service-kxrc2:tlsportname1/proxy/: tls baz (200; 30.119641ms)
Aug 12 16:09:57.707: INFO: (9) /api/v1/namespaces/proxy-6315/services/proxy-service-kxrc2:portname2/proxy/: bar (200; 29.480005ms)
Aug 12 16:09:57.707: INFO: (9) /api/v1/namespaces/proxy-6315/services/http:proxy-service-kxrc2:portname2/proxy/: bar (200; 29.71348ms)
Aug 12 16:09:57.709: INFO: (9) /api/v1/namespaces/proxy-6315/services/proxy-service-kxrc2:portname1/proxy/: foo (200; 34.991702ms)
Aug 12 16:09:57.710: INFO: (9) /api/v1/namespaces/proxy-6315/services/https:proxy-service-kxrc2:tlsportname2/proxy/: tls qux (200; 34.790482ms)
Aug 12 16:09:57.711: INFO: (9) /api/v1/namespaces/proxy-6315/services/http:proxy-service-kxrc2:portname1/proxy/: foo (200; 31.981645ms)
Aug 12 16:09:57.722: INFO: (10) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:1080/proxy/rewriteme">... (200; 11.37024ms)
Aug 12 16:09:57.727: INFO: (10) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:162/proxy/: bar (200; 16.185579ms)
Aug 12 16:09:57.730: INFO: (10) /api/v1/namespaces/proxy-6315/services/proxy-service-kxrc2:portname1/proxy/: foo (200; 18.682566ms)
Aug 12 16:09:57.732: INFO: (10) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:443/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:443/proxy/tlsrewritem... (200; 20.847707ms)
Aug 12 16:09:57.734: INFO: (10) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m/proxy/rewriteme">test</a> (200; 22.058831ms)
Aug 12 16:09:57.735: INFO: (10) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:1080/proxy/rewriteme">test<... (200; 23.271008ms)
Aug 12 16:09:57.735: INFO: (10) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:162/proxy/: bar (200; 23.713595ms)
Aug 12 16:09:57.736: INFO: (10) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:160/proxy/: foo (200; 23.386504ms)
Aug 12 16:09:57.736: INFO: (10) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:460/proxy/: tls baz (200; 24.469523ms)
Aug 12 16:09:57.737: INFO: (10) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:160/proxy/: foo (200; 24.402117ms)
Aug 12 16:09:57.737: INFO: (10) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:462/proxy/: tls qux (200; 25.122222ms)
Aug 12 16:09:57.738: INFO: (10) /api/v1/namespaces/proxy-6315/services/http:proxy-service-kxrc2:portname1/proxy/: foo (200; 25.350204ms)
Aug 12 16:09:57.739: INFO: (10) /api/v1/namespaces/proxy-6315/services/proxy-service-kxrc2:portname2/proxy/: bar (200; 26.429527ms)
Aug 12 16:09:57.739: INFO: (10) /api/v1/namespaces/proxy-6315/services/http:proxy-service-kxrc2:portname2/proxy/: bar (200; 26.76342ms)
Aug 12 16:09:57.741: INFO: (10) /api/v1/namespaces/proxy-6315/services/https:proxy-service-kxrc2:tlsportname1/proxy/: tls baz (200; 29.11061ms)
Aug 12 16:09:57.742: INFO: (10) /api/v1/namespaces/proxy-6315/services/https:proxy-service-kxrc2:tlsportname2/proxy/: tls qux (200; 30.673142ms)
Aug 12 16:09:57.763: INFO: (11) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:1080/proxy/rewriteme">... (200; 20.257028ms)
Aug 12 16:09:57.763: INFO: (11) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:160/proxy/: foo (200; 21.158992ms)
Aug 12 16:09:57.768: INFO: (11) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:462/proxy/: tls qux (200; 24.386457ms)
Aug 12 16:09:57.769: INFO: (11) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:443/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:443/proxy/tlsrewritem... (200; 26.098002ms)
Aug 12 16:09:57.769: INFO: (11) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:162/proxy/: bar (200; 26.642585ms)
Aug 12 16:09:57.772: INFO: (11) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:1080/proxy/rewriteme">test<... (200; 28.604314ms)
Aug 12 16:09:57.773: INFO: (11) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:162/proxy/: bar (200; 29.958331ms)
Aug 12 16:09:57.773: INFO: (11) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m/proxy/rewriteme">test</a> (200; 29.945658ms)
Aug 12 16:09:57.773: INFO: (11) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:160/proxy/: foo (200; 29.311897ms)
Aug 12 16:09:57.774: INFO: (11) /api/v1/namespaces/proxy-6315/services/http:proxy-service-kxrc2:portname2/proxy/: bar (200; 29.601049ms)
Aug 12 16:09:57.774: INFO: (11) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:460/proxy/: tls baz (200; 30.894007ms)
Aug 12 16:09:57.775: INFO: (11) /api/v1/namespaces/proxy-6315/services/http:proxy-service-kxrc2:portname1/proxy/: foo (200; 32.459713ms)
Aug 12 16:09:57.775: INFO: (11) /api/v1/namespaces/proxy-6315/services/https:proxy-service-kxrc2:tlsportname2/proxy/: tls qux (200; 32.319247ms)
Aug 12 16:09:57.775: INFO: (11) /api/v1/namespaces/proxy-6315/services/proxy-service-kxrc2:portname1/proxy/: foo (200; 32.771046ms)
Aug 12 16:09:57.775: INFO: (11) /api/v1/namespaces/proxy-6315/services/https:proxy-service-kxrc2:tlsportname1/proxy/: tls baz (200; 32.290441ms)
Aug 12 16:09:57.776: INFO: (11) /api/v1/namespaces/proxy-6315/services/proxy-service-kxrc2:portname2/proxy/: bar (200; 32.413396ms)
Aug 12 16:09:57.784: INFO: (12) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:160/proxy/: foo (200; 7.937342ms)
Aug 12 16:09:57.795: INFO: (12) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:1080/proxy/rewriteme">test<... (200; 17.824535ms)
Aug 12 16:09:57.798: INFO: (12) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:443/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:443/proxy/tlsrewritem... (200; 20.1774ms)
Aug 12 16:09:57.798: INFO: (12) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:162/proxy/: bar (200; 20.441075ms)
Aug 12 16:09:57.798: INFO: (12) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:1080/proxy/rewriteme">... (200; 20.787417ms)
Aug 12 16:09:57.798: INFO: (12) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m/proxy/rewriteme">test</a> (200; 20.128496ms)
Aug 12 16:09:57.798: INFO: (12) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:160/proxy/: foo (200; 19.004557ms)
Aug 12 16:09:57.800: INFO: (12) /api/v1/namespaces/proxy-6315/services/proxy-service-kxrc2:portname1/proxy/: foo (200; 22.628294ms)
Aug 12 16:09:57.800: INFO: (12) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:162/proxy/: bar (200; 22.874027ms)
Aug 12 16:09:57.800: INFO: (12) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:462/proxy/: tls qux (200; 22.275206ms)
Aug 12 16:09:57.801: INFO: (12) /api/v1/namespaces/proxy-6315/services/https:proxy-service-kxrc2:tlsportname2/proxy/: tls qux (200; 23.521982ms)
Aug 12 16:09:57.801: INFO: (12) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:460/proxy/: tls baz (200; 23.128068ms)
Aug 12 16:09:57.801: INFO: (12) /api/v1/namespaces/proxy-6315/services/https:proxy-service-kxrc2:tlsportname1/proxy/: tls baz (200; 23.497327ms)
Aug 12 16:09:57.802: INFO: (12) /api/v1/namespaces/proxy-6315/services/http:proxy-service-kxrc2:portname2/proxy/: bar (200; 22.964862ms)
Aug 12 16:09:57.802: INFO: (12) /api/v1/namespaces/proxy-6315/services/http:proxy-service-kxrc2:portname1/proxy/: foo (200; 25.021406ms)
Aug 12 16:09:57.802: INFO: (12) /api/v1/namespaces/proxy-6315/services/proxy-service-kxrc2:portname2/proxy/: bar (200; 23.560457ms)
Aug 12 16:09:57.814: INFO: (13) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m/proxy/rewriteme">test</a> (200; 11.689646ms)
Aug 12 16:09:57.825: INFO: (13) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:460/proxy/: tls baz (200; 22.593246ms)
Aug 12 16:09:57.826: INFO: (13) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:162/proxy/: bar (200; 21.77565ms)
Aug 12 16:09:57.826: INFO: (13) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:1080/proxy/rewriteme">test<... (200; 23.447995ms)
Aug 12 16:09:57.826: INFO: (13) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:160/proxy/: foo (200; 22.937114ms)
Aug 12 16:09:57.827: INFO: (13) /api/v1/namespaces/proxy-6315/services/https:proxy-service-kxrc2:tlsportname1/proxy/: tls baz (200; 23.561497ms)
Aug 12 16:09:57.827: INFO: (13) /api/v1/namespaces/proxy-6315/services/proxy-service-kxrc2:portname2/proxy/: bar (200; 23.161143ms)
Aug 12 16:09:57.827: INFO: (13) /api/v1/namespaces/proxy-6315/services/proxy-service-kxrc2:portname1/proxy/: foo (200; 24.410045ms)
Aug 12 16:09:57.827: INFO: (13) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:462/proxy/: tls qux (200; 23.768998ms)
Aug 12 16:09:57.827: INFO: (13) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:443/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:443/proxy/tlsrewritem... (200; 22.530063ms)
Aug 12 16:09:57.827: INFO: (13) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:160/proxy/: foo (200; 23.452288ms)
Aug 12 16:09:57.828: INFO: (13) /api/v1/namespaces/proxy-6315/services/http:proxy-service-kxrc2:portname2/proxy/: bar (200; 24.75013ms)
Aug 12 16:09:57.828: INFO: (13) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:1080/proxy/rewriteme">... (200; 24.543901ms)
Aug 12 16:09:57.828: INFO: (13) /api/v1/namespaces/proxy-6315/services/https:proxy-service-kxrc2:tlsportname2/proxy/: tls qux (200; 24.56753ms)
Aug 12 16:09:57.829: INFO: (13) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:162/proxy/: bar (200; 24.680556ms)
Aug 12 16:09:57.829: INFO: (13) /api/v1/namespaces/proxy-6315/services/http:proxy-service-kxrc2:portname1/proxy/: foo (200; 25.059378ms)
Aug 12 16:09:57.840: INFO: (14) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:462/proxy/: tls qux (200; 11.206261ms)
Aug 12 16:09:57.849: INFO: (14) /api/v1/namespaces/proxy-6315/services/http:proxy-service-kxrc2:portname2/proxy/: bar (200; 19.546449ms)
Aug 12 16:09:57.850: INFO: (14) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:160/proxy/: foo (200; 20.556857ms)
Aug 12 16:09:57.850: INFO: (14) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:1080/proxy/rewriteme">... (200; 20.21356ms)
Aug 12 16:09:57.855: INFO: (14) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:160/proxy/: foo (200; 25.754344ms)
Aug 12 16:09:57.857: INFO: (14) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:443/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:443/proxy/tlsrewritem... (200; 26.61165ms)
Aug 12 16:09:57.857: INFO: (14) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:1080/proxy/rewriteme">test<... (200; 26.611811ms)
Aug 12 16:09:57.868: INFO: (14) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:162/proxy/: bar (200; 37.640264ms)
Aug 12 16:09:57.869: INFO: (14) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m/proxy/rewriteme">test</a> (200; 38.095558ms)
Aug 12 16:09:57.869: INFO: (14) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:162/proxy/: bar (200; 39.081121ms)
Aug 12 16:09:57.869: INFO: (14) /api/v1/namespaces/proxy-6315/services/proxy-service-kxrc2:portname2/proxy/: bar (200; 40.230741ms)
Aug 12 16:09:57.869: INFO: (14) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:460/proxy/: tls baz (200; 38.681115ms)
Aug 12 16:09:57.870: INFO: (14) /api/v1/namespaces/proxy-6315/services/https:proxy-service-kxrc2:tlsportname1/proxy/: tls baz (200; 39.076206ms)
Aug 12 16:09:57.870: INFO: (14) /api/v1/namespaces/proxy-6315/services/https:proxy-service-kxrc2:tlsportname2/proxy/: tls qux (200; 39.530162ms)
Aug 12 16:09:57.870: INFO: (14) /api/v1/namespaces/proxy-6315/services/proxy-service-kxrc2:portname1/proxy/: foo (200; 39.664725ms)
Aug 12 16:09:57.870: INFO: (14) /api/v1/namespaces/proxy-6315/services/http:proxy-service-kxrc2:portname1/proxy/: foo (200; 39.972998ms)
Aug 12 16:09:57.894: INFO: (15) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:160/proxy/: foo (200; 20.492958ms)
Aug 12 16:09:57.894: INFO: (15) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:1080/proxy/rewriteme">test<... (200; 21.227997ms)
Aug 12 16:09:57.900: INFO: (15) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:460/proxy/: tls baz (200; 24.63808ms)
Aug 12 16:09:57.901: INFO: (15) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:160/proxy/: foo (200; 27.189208ms)
Aug 12 16:09:57.902: INFO: (15) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:462/proxy/: tls qux (200; 26.221078ms)
Aug 12 16:09:57.904: INFO: (15) /api/v1/namespaces/proxy-6315/services/proxy-service-kxrc2:portname2/proxy/: bar (200; 30.866421ms)
Aug 12 16:09:57.905: INFO: (15) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m/proxy/rewriteme">test</a> (200; 28.921785ms)
Aug 12 16:09:57.905: INFO: (15) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:443/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:443/proxy/tlsrewritem... (200; 30.165612ms)
Aug 12 16:09:57.906: INFO: (15) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:1080/proxy/rewriteme">... (200; 31.186154ms)
Aug 12 16:09:57.906: INFO: (15) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:162/proxy/: bar (200; 30.354717ms)
Aug 12 16:09:57.907: INFO: (15) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:162/proxy/: bar (200; 32.350753ms)
Aug 12 16:09:57.908: INFO: (15) /api/v1/namespaces/proxy-6315/services/http:proxy-service-kxrc2:portname2/proxy/: bar (200; 34.796835ms)
Aug 12 16:09:57.909: INFO: (15) /api/v1/namespaces/proxy-6315/services/proxy-service-kxrc2:portname1/proxy/: foo (200; 33.907681ms)
Aug 12 16:09:57.910: INFO: (15) /api/v1/namespaces/proxy-6315/services/https:proxy-service-kxrc2:tlsportname1/proxy/: tls baz (200; 33.788883ms)
Aug 12 16:09:57.910: INFO: (15) /api/v1/namespaces/proxy-6315/services/http:proxy-service-kxrc2:portname1/proxy/: foo (200; 35.560267ms)
Aug 12 16:09:57.910: INFO: (15) /api/v1/namespaces/proxy-6315/services/https:proxy-service-kxrc2:tlsportname2/proxy/: tls qux (200; 34.663981ms)
Aug 12 16:09:57.922: INFO: (16) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:1080/proxy/rewriteme">... (200; 11.681171ms)
Aug 12 16:09:57.923: INFO: (16) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:443/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:443/proxy/tlsrewritem... (200; 11.954549ms)
Aug 12 16:09:57.923: INFO: (16) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:162/proxy/: bar (200; 12.274643ms)
Aug 12 16:09:57.926: INFO: (16) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:160/proxy/: foo (200; 14.760604ms)
Aug 12 16:09:57.927: INFO: (16) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:162/proxy/: bar (200; 16.008473ms)
Aug 12 16:09:57.929: INFO: (16) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:462/proxy/: tls qux (200; 17.544974ms)
Aug 12 16:09:57.931: INFO: (16) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:160/proxy/: foo (200; 18.69711ms)
Aug 12 16:09:57.931: INFO: (16) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:460/proxy/: tls baz (200; 19.902615ms)
Aug 12 16:09:57.933: INFO: (16) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m/proxy/rewriteme">test</a> (200; 21.750445ms)
Aug 12 16:09:57.933: INFO: (16) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:1080/proxy/rewriteme">test<... (200; 21.712391ms)
Aug 12 16:09:57.935: INFO: (16) /api/v1/namespaces/proxy-6315/services/proxy-service-kxrc2:portname2/proxy/: bar (200; 23.060805ms)
Aug 12 16:09:57.935: INFO: (16) /api/v1/namespaces/proxy-6315/services/proxy-service-kxrc2:portname1/proxy/: foo (200; 24.076185ms)
Aug 12 16:09:57.935: INFO: (16) /api/v1/namespaces/proxy-6315/services/https:proxy-service-kxrc2:tlsportname2/proxy/: tls qux (200; 24.142959ms)
Aug 12 16:09:57.935: INFO: (16) /api/v1/namespaces/proxy-6315/services/https:proxy-service-kxrc2:tlsportname1/proxy/: tls baz (200; 23.980506ms)
Aug 12 16:09:57.936: INFO: (16) /api/v1/namespaces/proxy-6315/services/http:proxy-service-kxrc2:portname2/proxy/: bar (200; 23.877938ms)
Aug 12 16:09:57.937: INFO: (16) /api/v1/namespaces/proxy-6315/services/http:proxy-service-kxrc2:portname1/proxy/: foo (200; 24.797868ms)
Aug 12 16:09:57.948: INFO: (17) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:443/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:443/proxy/tlsrewritem... (200; 10.677873ms)
Aug 12 16:09:57.948: INFO: (17) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:1080/proxy/rewriteme">... (200; 11.235459ms)
Aug 12 16:09:57.955: INFO: (17) /api/v1/namespaces/proxy-6315/services/proxy-service-kxrc2:portname1/proxy/: foo (200; 17.549571ms)
Aug 12 16:09:57.957: INFO: (17) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m/proxy/rewriteme">test</a> (200; 18.961524ms)
Aug 12 16:09:57.957: INFO: (17) /api/v1/namespaces/proxy-6315/services/https:proxy-service-kxrc2:tlsportname2/proxy/: tls qux (200; 20.111643ms)
Aug 12 16:09:57.957: INFO: (17) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:162/proxy/: bar (200; 20.004059ms)
Aug 12 16:09:57.958: INFO: (17) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:1080/proxy/rewriteme">test<... (200; 19.897155ms)
Aug 12 16:09:57.958: INFO: (17) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:462/proxy/: tls qux (200; 20.18719ms)
Aug 12 16:09:57.958: INFO: (17) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:460/proxy/: tls baz (200; 19.903262ms)
Aug 12 16:09:57.961: INFO: (17) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:162/proxy/: bar (200; 23.563527ms)
Aug 12 16:09:57.961: INFO: (17) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:160/proxy/: foo (200; 22.738498ms)
Aug 12 16:09:57.961: INFO: (17) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:160/proxy/: foo (200; 22.681318ms)
Aug 12 16:09:57.961: INFO: (17) /api/v1/namespaces/proxy-6315/services/proxy-service-kxrc2:portname2/proxy/: bar (200; 23.24812ms)
Aug 12 16:09:57.961: INFO: (17) /api/v1/namespaces/proxy-6315/services/https:proxy-service-kxrc2:tlsportname1/proxy/: tls baz (200; 23.725024ms)
Aug 12 16:09:57.964: INFO: (17) /api/v1/namespaces/proxy-6315/services/http:proxy-service-kxrc2:portname2/proxy/: bar (200; 26.321516ms)
Aug 12 16:09:57.965: INFO: (17) /api/v1/namespaces/proxy-6315/services/http:proxy-service-kxrc2:portname1/proxy/: foo (200; 26.606077ms)
Aug 12 16:09:57.989: INFO: (18) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m/proxy/rewriteme">test</a> (200; 21.91629ms)
Aug 12 16:09:57.989: INFO: (18) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:443/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:443/proxy/tlsrewritem... (200; 23.054075ms)
Aug 12 16:09:57.989: INFO: (18) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:1080/proxy/rewriteme">test<... (200; 21.646978ms)
Aug 12 16:09:57.996: INFO: (18) /api/v1/namespaces/proxy-6315/services/https:proxy-service-kxrc2:tlsportname1/proxy/: tls baz (200; 29.56786ms)
Aug 12 16:09:57.996: INFO: (18) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:460/proxy/: tls baz (200; 28.439335ms)
Aug 12 16:09:57.999: INFO: (18) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:162/proxy/: bar (200; 28.87404ms)
Aug 12 16:09:58.000: INFO: (18) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:462/proxy/: tls qux (200; 31.865081ms)
Aug 12 16:09:58.000: INFO: (18) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:160/proxy/: foo (200; 31.025158ms)
Aug 12 16:09:58.000: INFO: (18) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:1080/proxy/rewriteme">... (200; 30.613258ms)
Aug 12 16:09:58.001: INFO: (18) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:160/proxy/: foo (200; 31.388249ms)
Aug 12 16:09:58.001: INFO: (18) /api/v1/namespaces/proxy-6315/services/http:proxy-service-kxrc2:portname2/proxy/: bar (200; 32.154774ms)
Aug 12 16:09:58.001: INFO: (18) /api/v1/namespaces/proxy-6315/services/https:proxy-service-kxrc2:tlsportname2/proxy/: tls qux (200; 31.193929ms)
Aug 12 16:09:58.008: INFO: (18) /api/v1/namespaces/proxy-6315/services/proxy-service-kxrc2:portname1/proxy/: foo (200; 38.110744ms)
Aug 12 16:09:58.009: INFO: (18) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:162/proxy/: bar (200; 38.194837ms)
Aug 12 16:09:58.009: INFO: (18) /api/v1/namespaces/proxy-6315/services/http:proxy-service-kxrc2:portname1/proxy/: foo (200; 39.456697ms)
Aug 12 16:09:58.011: INFO: (18) /api/v1/namespaces/proxy-6315/services/proxy-service-kxrc2:portname2/proxy/: bar (200; 42.896572ms)
Aug 12 16:09:58.030: INFO: (19) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:162/proxy/: bar (200; 17.570559ms)
Aug 12 16:09:58.030: INFO: (19) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:1080/proxy/rewriteme">... (200; 18.618463ms)
Aug 12 16:09:58.032: INFO: (19) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:443/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:443/proxy/tlsrewritem... (200; 18.446388ms)
Aug 12 16:09:58.032: INFO: (19) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:460/proxy/: tls baz (200; 17.822016ms)
Aug 12 16:09:58.035: INFO: (19) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:162/proxy/: bar (200; 21.985985ms)
Aug 12 16:09:58.036: INFO: (19) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m/proxy/rewriteme">test</a> (200; 22.022871ms)
Aug 12 16:09:58.036: INFO: (19) /api/v1/namespaces/proxy-6315/pods/https:proxy-service-kxrc2-ppw2m:462/proxy/: tls qux (200; 21.523735ms)
Aug 12 16:09:58.036: INFO: (19) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:1080/proxy/: <a href="/api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:1080/proxy/rewriteme">test<... (200; 21.995382ms)
Aug 12 16:09:58.038: INFO: (19) /api/v1/namespaces/proxy-6315/services/proxy-service-kxrc2:portname1/proxy/: foo (200; 25.375547ms)
Aug 12 16:09:58.039: INFO: (19) /api/v1/namespaces/proxy-6315/services/https:proxy-service-kxrc2:tlsportname1/proxy/: tls baz (200; 25.132047ms)
Aug 12 16:09:58.039: INFO: (19) /api/v1/namespaces/proxy-6315/services/http:proxy-service-kxrc2:portname2/proxy/: bar (200; 24.266292ms)
Aug 12 16:09:58.039: INFO: (19) /api/v1/namespaces/proxy-6315/pods/http:proxy-service-kxrc2-ppw2m:160/proxy/: foo (200; 23.747406ms)
Aug 12 16:09:58.039: INFO: (19) /api/v1/namespaces/proxy-6315/services/https:proxy-service-kxrc2:tlsportname2/proxy/: tls qux (200; 26.765122ms)
Aug 12 16:09:58.039: INFO: (19) /api/v1/namespaces/proxy-6315/pods/proxy-service-kxrc2-ppw2m:160/proxy/: foo (200; 24.022452ms)
Aug 12 16:09:58.039: INFO: (19) /api/v1/namespaces/proxy-6315/services/http:proxy-service-kxrc2:portname1/proxy/: foo (200; 23.277147ms)
Aug 12 16:09:58.039: INFO: (19) /api/v1/namespaces/proxy-6315/services/proxy-service-kxrc2:portname2/proxy/: bar (200; 24.722648ms)
STEP: deleting ReplicationController proxy-service-kxrc2 in namespace proxy-6315, will wait for the garbage collector to delete the pods
Aug 12 16:09:58.107: INFO: Deleting ReplicationController proxy-service-kxrc2 took: 7.866506ms
Aug 12 16:09:58.513: INFO: Terminating ReplicationController proxy-service-kxrc2 pods took: 405.583912ms
[AfterEach] version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:10:09.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-6315" for this suite.
Aug 12 16:10:17.433: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:10:17.573: INFO: namespace proxy-6315 deletion completed in 8.154224643s

 [SLOW TEST:34.490 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:10:17.576: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Aug 12 16:10:25.682: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 12 16:10:25.901: INFO: Pod pod-with-prestop-http-hook still exists
Aug 12 16:10:27.901: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 12 16:10:27.907: INFO: Pod pod-with-prestop-http-hook still exists
Aug 12 16:10:29.901: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 12 16:10:29.905: INFO: Pod pod-with-prestop-http-hook still exists
Aug 12 16:10:31.901: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 12 16:10:31.912: INFO: Pod pod-with-prestop-http-hook still exists
Aug 12 16:10:33.901: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 12 16:10:33.908: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:10:33.924: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2410" for this suite.
Aug 12 16:10:55.944: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:10:56.083: INFO: namespace container-lifecycle-hook-2410 deletion completed in 22.152580926s

 [SLOW TEST:38.507 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:10:56.089: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Aug 12 16:10:56.244: INFO: Number of nodes with available pods: 0
Aug 12 16:10:56.244: INFO: Node conformance-1-15-2-do-0-default-pool-rxf2 is running more than one daemon pod
Aug 12 16:10:57.275: INFO: Number of nodes with available pods: 0
Aug 12 16:10:57.325: INFO: Node conformance-1-15-2-do-0-default-pool-rxf2 is running more than one daemon pod
Aug 12 16:10:58.253: INFO: Number of nodes with available pods: 0
Aug 12 16:10:58.254: INFO: Node conformance-1-15-2-do-0-default-pool-rxf2 is running more than one daemon pod
Aug 12 16:10:59.256: INFO: Number of nodes with available pods: 2
Aug 12 16:10:59.257: INFO: Node conformance-1-15-2-do-0-default-pool-rxf2 is running more than one daemon pod
Aug 12 16:11:00.394: INFO: Number of nodes with available pods: 3
Aug 12 16:11:00.394: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Aug 12 16:11:00.720: INFO: Number of nodes with available pods: 2
Aug 12 16:11:00.720: INFO: Node conformance-1-15-2-do-0-default-pool-rxfp is running more than one daemon pod
Aug 12 16:11:01.733: INFO: Number of nodes with available pods: 2
Aug 12 16:11:01.733: INFO: Node conformance-1-15-2-do-0-default-pool-rxfp is running more than one daemon pod
Aug 12 16:11:02.728: INFO: Number of nodes with available pods: 2
Aug 12 16:11:02.729: INFO: Node conformance-1-15-2-do-0-default-pool-rxfp is running more than one daemon pod
Aug 12 16:11:03.730: INFO: Number of nodes with available pods: 2
Aug 12 16:11:03.731: INFO: Node conformance-1-15-2-do-0-default-pool-rxfp is running more than one daemon pod
Aug 12 16:11:04.740: INFO: Number of nodes with available pods: 2
Aug 12 16:11:04.741: INFO: Node conformance-1-15-2-do-0-default-pool-rxfp is running more than one daemon pod
Aug 12 16:11:05.731: INFO: Number of nodes with available pods: 2
Aug 12 16:11:05.731: INFO: Node conformance-1-15-2-do-0-default-pool-rxfp is running more than one daemon pod
Aug 12 16:11:06.730: INFO: Number of nodes with available pods: 2
Aug 12 16:11:06.730: INFO: Node conformance-1-15-2-do-0-default-pool-rxfp is running more than one daemon pod
Aug 12 16:11:07.729: INFO: Number of nodes with available pods: 2
Aug 12 16:11:07.729: INFO: Node conformance-1-15-2-do-0-default-pool-rxfp is running more than one daemon pod
Aug 12 16:11:08.738: INFO: Number of nodes with available pods: 2
Aug 12 16:11:08.738: INFO: Node conformance-1-15-2-do-0-default-pool-rxfp is running more than one daemon pod
Aug 12 16:11:09.734: INFO: Number of nodes with available pods: 2
Aug 12 16:11:09.734: INFO: Node conformance-1-15-2-do-0-default-pool-rxfp is running more than one daemon pod
Aug 12 16:11:10.730: INFO: Number of nodes with available pods: 3
Aug 12 16:11:10.730: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6794, will wait for the garbage collector to delete the pods
Aug 12 16:11:10.824: INFO: Deleting DaemonSet.extensions daemon-set took: 37.57178ms
Aug 12 16:11:11.225: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.467162ms
Aug 12 16:11:16.932: INFO: Number of nodes with available pods: 0
Aug 12 16:11:16.932: INFO: Number of running nodes: 0, number of available pods: 0
Aug 12 16:11:16.941: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-6794/daemonsets","resourceVersion":"36722"},"items":null}

Aug 12 16:11:16.945: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-6794/pods","resourceVersion":"36722"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:11:16.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6794" for this suite.
Aug 12 16:11:22.986: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:11:23.154: INFO: namespace daemonsets-6794 deletion completed in 6.183141276s

 [SLOW TEST:27.066 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:11:23.163: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Aug 12 16:11:23.248: INFO: PodSpec: initContainers in spec.initContainers
Aug 12 16:12:11.089: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-8064a2e5-4f88-4f88-86a2-d67125ed35d6", GenerateName:"", Namespace:"init-container-6428", SelfLink:"/api/v1/namespaces/init-container-6428/pods/pod-init-8064a2e5-4f88-4f88-86a2-d67125ed35d6", UID:"a303890d-4520-4d6a-82fa-e156247e3ffc", ResourceVersion:"36876", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63701223083, loc:(*time.Location)(0x80bfa40)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"248277497"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-t7668", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc002678180), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-t7668", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-t7668", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-t7668", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0024922b8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"conformance-1-15-2-do-0-default-pool-rxf2", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0036500c0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002492330)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002492350)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc002492358), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00249235c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701223083, loc:(*time.Location)(0x80bfa40)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701223083, loc:(*time.Location)(0x80bfa40)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701223083, loc:(*time.Location)(0x80bfa40)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701223083, loc:(*time.Location)(0x80bfa40)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.138.15.94", PodIP:"10.244.2.126", StartTime:(*v1.Time)(0xc002736820), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002ea01c0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002ea0230)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://968c21e140f584167312ff135da79515a644af9af5e971bcb5828414bc87ce65"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002736980), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0027368c0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:12:11.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6428" for this suite.
Aug 12 16:12:33.162: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:12:33.295: INFO: namespace init-container-6428 deletion completed in 22.183540429s

 [SLOW TEST:70.133 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:12:33.300: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 12 16:12:33.339: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c8428202-d788-4959-8582-483b0aea876d" in namespace "projected-7448" to be "success or failure"
Aug 12 16:12:33.348: INFO: Pod "downwardapi-volume-c8428202-d788-4959-8582-483b0aea876d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.992768ms
Aug 12 16:12:35.352: INFO: Pod "downwardapi-volume-c8428202-d788-4959-8582-483b0aea876d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012061286s
Aug 12 16:12:37.357: INFO: Pod "downwardapi-volume-c8428202-d788-4959-8582-483b0aea876d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016983386s
STEP: Saw pod success
Aug 12 16:12:37.357: INFO: Pod "downwardapi-volume-c8428202-d788-4959-8582-483b0aea876d" satisfied condition "success or failure"
Aug 12 16:12:37.360: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxfp pod downwardapi-volume-c8428202-d788-4959-8582-483b0aea876d container client-container: <nil>
STEP: delete the pod
Aug 12 16:12:37.391: INFO: Waiting for pod downwardapi-volume-c8428202-d788-4959-8582-483b0aea876d to disappear
Aug 12 16:12:37.393: INFO: Pod downwardapi-volume-c8428202-d788-4959-8582-483b0aea876d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:12:37.394: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7448" for this suite.
Aug 12 16:12:43.411: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:12:43.605: INFO: namespace projected-7448 deletion completed in 6.207392641s

 [SLOW TEST:10.305 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:12:43.610: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Aug 12 16:12:43.714: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:12:49.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7693" for this suite.
Aug 12 16:13:11.297: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:13:11.453: INFO: namespace init-container-7693 deletion completed in 22.173078427s

 [SLOW TEST:27.844 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:13:11.460: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-bafb69f9-388d-4e4a-9801-842497f6f8e1
STEP: Creating a pod to test consume configMaps
Aug 12 16:13:11.516: INFO: Waiting up to 5m0s for pod "pod-configmaps-fad53faa-b978-40ca-a94b-fddf73106c5d" in namespace "configmap-1906" to be "success or failure"
Aug 12 16:13:11.527: INFO: Pod "pod-configmaps-fad53faa-b978-40ca-a94b-fddf73106c5d": Phase="Pending", Reason="", readiness=false. Elapsed: 11.368148ms
Aug 12 16:13:13.533: INFO: Pod "pod-configmaps-fad53faa-b978-40ca-a94b-fddf73106c5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01703236s
Aug 12 16:13:15.539: INFO: Pod "pod-configmaps-fad53faa-b978-40ca-a94b-fddf73106c5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023324807s
STEP: Saw pod success
Aug 12 16:13:15.540: INFO: Pod "pod-configmaps-fad53faa-b978-40ca-a94b-fddf73106c5d" satisfied condition "success or failure"
Aug 12 16:13:15.546: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxfs pod pod-configmaps-fad53faa-b978-40ca-a94b-fddf73106c5d container configmap-volume-test: <nil>
STEP: delete the pod
Aug 12 16:13:15.575: INFO: Waiting for pod pod-configmaps-fad53faa-b978-40ca-a94b-fddf73106c5d to disappear
Aug 12 16:13:15.579: INFO: Pod pod-configmaps-fad53faa-b978-40ca-a94b-fddf73106c5d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:13:15.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1906" for this suite.
Aug 12 16:13:21.597: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:13:21.760: INFO: namespace configmap-1906 deletion completed in 6.17507481s

 [SLOW TEST:10.301 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:13:21.765: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:13:25.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2044" for this suite.
Aug 12 16:14:03.935: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:14:04.090: INFO: namespace kubelet-test-2044 deletion completed in 38.177868746s

 [SLOW TEST:42.325 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command in a pod
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:14:04.100: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Aug 12 16:14:04.282: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-1646,SelfLink:/api/v1/namespaces/watch-1646/configmaps/e2e-watch-test-resource-version,UID:b60fa9c1-70e3-440c-89ee-c7666229fb8f,ResourceVersion:37239,Generation:0,CreationTimestamp:2019-08-12 16:14:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 12 16:14:04.283: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-1646,SelfLink:/api/v1/namespaces/watch-1646/configmaps/e2e-watch-test-resource-version,UID:b60fa9c1-70e3-440c-89ee-c7666229fb8f,ResourceVersion:37240,Generation:0,CreationTimestamp:2019-08-12 16:14:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:14:04.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1646" for this suite.
Aug 12 16:14:10.343: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:14:10.589: INFO: namespace watch-1646 deletion completed in 6.28184099s

 [SLOW TEST:6.489 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:14:10.589: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-2ff0f2fd-48b5-45f7-b0bc-df08f76da04a
STEP: Creating a pod to test consume configMaps
Aug 12 16:14:11.064: INFO: Waiting up to 5m0s for pod "pod-configmaps-608ca974-5e31-4f92-8d3d-f9066f2e5494" in namespace "configmap-7526" to be "success or failure"
Aug 12 16:14:11.074: INFO: Pod "pod-configmaps-608ca974-5e31-4f92-8d3d-f9066f2e5494": Phase="Pending", Reason="", readiness=false. Elapsed: 9.691277ms
Aug 12 16:14:13.078: INFO: Pod "pod-configmaps-608ca974-5e31-4f92-8d3d-f9066f2e5494": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013207865s
Aug 12 16:14:15.083: INFO: Pod "pod-configmaps-608ca974-5e31-4f92-8d3d-f9066f2e5494": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017913044s
STEP: Saw pod success
Aug 12 16:14:15.083: INFO: Pod "pod-configmaps-608ca974-5e31-4f92-8d3d-f9066f2e5494" satisfied condition "success or failure"
Aug 12 16:14:15.085: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxf2 pod pod-configmaps-608ca974-5e31-4f92-8d3d-f9066f2e5494 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 12 16:14:15.105: INFO: Waiting for pod pod-configmaps-608ca974-5e31-4f92-8d3d-f9066f2e5494 to disappear
Aug 12 16:14:15.109: INFO: Pod pod-configmaps-608ca974-5e31-4f92-8d3d-f9066f2e5494 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:14:15.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7526" for this suite.
Aug 12 16:14:21.137: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:14:21.267: INFO: namespace configmap-7526 deletion completed in 6.153930797s

 [SLOW TEST:10.679 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:14:21.271: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Aug 12 16:14:21.374: INFO: Waiting up to 5m0s for pod "downward-api-dfebc465-bd77-456b-8a2d-d0217bdb4fa7" in namespace "downward-api-520" to be "success or failure"
Aug 12 16:14:21.383: INFO: Pod "downward-api-dfebc465-bd77-456b-8a2d-d0217bdb4fa7": Phase="Pending", Reason="", readiness=false. Elapsed: 8.486355ms
Aug 12 16:14:23.394: INFO: Pod "downward-api-dfebc465-bd77-456b-8a2d-d0217bdb4fa7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018873337s
Aug 12 16:14:25.398: INFO: Pod "downward-api-dfebc465-bd77-456b-8a2d-d0217bdb4fa7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02325494s
STEP: Saw pod success
Aug 12 16:14:25.398: INFO: Pod "downward-api-dfebc465-bd77-456b-8a2d-d0217bdb4fa7" satisfied condition "success or failure"
Aug 12 16:14:25.401: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxf2 pod downward-api-dfebc465-bd77-456b-8a2d-d0217bdb4fa7 container dapi-container: <nil>
STEP: delete the pod
Aug 12 16:14:25.448: INFO: Waiting for pod downward-api-dfebc465-bd77-456b-8a2d-d0217bdb4fa7 to disappear
Aug 12 16:14:25.457: INFO: Pod downward-api-dfebc465-bd77-456b-8a2d-d0217bdb4fa7 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:14:25.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-520" for this suite.
Aug 12 16:14:31.478: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:14:31.623: INFO: namespace downward-api-520 deletion completed in 6.160669592s

 [SLOW TEST:10.352 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:14:31.625: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-6224.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-6224.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6224.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-6224.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-6224.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6224.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 12 16:14:35.824: INFO: DNS probes using dns-6224/dns-test-728dde7d-2d42-4533-9b60-bf88bbf3660c succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:14:35.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6224" for this suite.
Aug 12 16:14:41.887: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:14:42.058: INFO: namespace dns-6224 deletion completed in 6.19567867s

 [SLOW TEST:10.433 seconds]
[sig-network] DNS
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:14:42.062: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-0c77021a-7d95-49c8-9b52-d44f3b205065
STEP: Creating a pod to test consume configMaps
Aug 12 16:14:42.170: INFO: Waiting up to 5m0s for pod "pod-configmaps-ec93b37c-30e1-4cc6-b751-5ab8d33dcdad" in namespace "configmap-6478" to be "success or failure"
Aug 12 16:14:42.184: INFO: Pod "pod-configmaps-ec93b37c-30e1-4cc6-b751-5ab8d33dcdad": Phase="Pending", Reason="", readiness=false. Elapsed: 14.439448ms
Aug 12 16:14:44.189: INFO: Pod "pod-configmaps-ec93b37c-30e1-4cc6-b751-5ab8d33dcdad": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018718279s
Aug 12 16:14:46.194: INFO: Pod "pod-configmaps-ec93b37c-30e1-4cc6-b751-5ab8d33dcdad": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023646558s
STEP: Saw pod success
Aug 12 16:14:46.194: INFO: Pod "pod-configmaps-ec93b37c-30e1-4cc6-b751-5ab8d33dcdad" satisfied condition "success or failure"
Aug 12 16:14:46.198: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxf2 pod pod-configmaps-ec93b37c-30e1-4cc6-b751-5ab8d33dcdad container configmap-volume-test: <nil>
STEP: delete the pod
Aug 12 16:14:46.231: INFO: Waiting for pod pod-configmaps-ec93b37c-30e1-4cc6-b751-5ab8d33dcdad to disappear
Aug 12 16:14:46.235: INFO: Pod pod-configmaps-ec93b37c-30e1-4cc6-b751-5ab8d33dcdad no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:14:46.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6478" for this suite.
Aug 12 16:14:52.258: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:14:52.454: INFO: namespace configmap-6478 deletion completed in 6.21215392s

 [SLOW TEST:10.392 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:14:52.460: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:14:56.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4782" for this suite.
Aug 12 16:15:34.645: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:15:34.810: INFO: namespace kubelet-test-4782 deletion completed in 38.183222579s

 [SLOW TEST:42.351 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:15:34.823: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0812 16:16:15.999675      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 12 16:16:16.000: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:16:16.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4700" for this suite.
Aug 12 16:16:22.019: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:16:22.111: INFO: namespace gc-4700 deletion completed in 6.104967454s

 [SLOW TEST:47.288 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:16:22.112: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 12 16:16:22.209: INFO: Waiting up to 5m0s for pod "downwardapi-volume-48ec8fad-6320-418a-a022-7d24ac5479a1" in namespace "downward-api-6676" to be "success or failure"
Aug 12 16:16:22.217: INFO: Pod "downwardapi-volume-48ec8fad-6320-418a-a022-7d24ac5479a1": Phase="Pending", Reason="", readiness=false. Elapsed: 8.063807ms
Aug 12 16:16:24.224: INFO: Pod "downwardapi-volume-48ec8fad-6320-418a-a022-7d24ac5479a1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014934092s
Aug 12 16:16:26.229: INFO: Pod "downwardapi-volume-48ec8fad-6320-418a-a022-7d24ac5479a1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019726368s
STEP: Saw pod success
Aug 12 16:16:26.229: INFO: Pod "downwardapi-volume-48ec8fad-6320-418a-a022-7d24ac5479a1" satisfied condition "success or failure"
Aug 12 16:16:26.233: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxf2 pod downwardapi-volume-48ec8fad-6320-418a-a022-7d24ac5479a1 container client-container: <nil>
STEP: delete the pod
Aug 12 16:16:26.279: INFO: Waiting for pod downwardapi-volume-48ec8fad-6320-418a-a022-7d24ac5479a1 to disappear
Aug 12 16:16:26.285: INFO: Pod downwardapi-volume-48ec8fad-6320-418a-a022-7d24ac5479a1 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:16:26.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6676" for this suite.
Aug 12 16:16:32.309: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:16:32.458: INFO: namespace downward-api-6676 deletion completed in 6.16498392s

 [SLOW TEST:10.347 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:16:32.460: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap that has name configmap-test-emptyKey-d073fb04-05c0-462f-9034-6c88939b721f
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:16:32.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1634" for this suite.
Aug 12 16:16:38.598: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:16:38.734: INFO: namespace configmap-1634 deletion completed in 6.15227978s

 [SLOW TEST:6.274 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:16:38.742: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 12 16:16:38.853: INFO: Waiting up to 5m0s for pod "downwardapi-volume-16d82306-4577-48b9-ad35-473cce428a2b" in namespace "projected-3198" to be "success or failure"
Aug 12 16:16:38.864: INFO: Pod "downwardapi-volume-16d82306-4577-48b9-ad35-473cce428a2b": Phase="Pending", Reason="", readiness=false. Elapsed: 10.720681ms
Aug 12 16:16:40.869: INFO: Pod "downwardapi-volume-16d82306-4577-48b9-ad35-473cce428a2b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01550344s
Aug 12 16:16:42.872: INFO: Pod "downwardapi-volume-16d82306-4577-48b9-ad35-473cce428a2b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018827738s
STEP: Saw pod success
Aug 12 16:16:42.872: INFO: Pod "downwardapi-volume-16d82306-4577-48b9-ad35-473cce428a2b" satisfied condition "success or failure"
Aug 12 16:16:42.876: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxfs pod downwardapi-volume-16d82306-4577-48b9-ad35-473cce428a2b container client-container: <nil>
STEP: delete the pod
Aug 12 16:16:42.929: INFO: Waiting for pod downwardapi-volume-16d82306-4577-48b9-ad35-473cce428a2b to disappear
Aug 12 16:16:42.936: INFO: Pod downwardapi-volume-16d82306-4577-48b9-ad35-473cce428a2b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:16:42.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3198" for this suite.
Aug 12 16:16:48.965: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:16:49.250: INFO: namespace projected-3198 deletion completed in 6.308073234s

 [SLOW TEST:10.509 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:16:49.261: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-75acb1cc-06b6-413d-8206-cd9469528709
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:16:53.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7547" for this suite.
Aug 12 16:17:15.740: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:17:15.901: INFO: namespace configmap-7547 deletion completed in 22.17242808s

 [SLOW TEST:26.640 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:17:15.904: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-24320149-7034-4983-8ab5-88b9e1cd8c9c
STEP: Creating a pod to test consume secrets
Aug 12 16:17:15.958: INFO: Waiting up to 5m0s for pod "pod-secrets-925bb10b-75dd-4bd6-93e0-74767bc77fe5" in namespace "secrets-8780" to be "success or failure"
Aug 12 16:17:15.965: INFO: Pod "pod-secrets-925bb10b-75dd-4bd6-93e0-74767bc77fe5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.881829ms
Aug 12 16:17:17.971: INFO: Pod "pod-secrets-925bb10b-75dd-4bd6-93e0-74767bc77fe5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012544869s
Aug 12 16:17:19.978: INFO: Pod "pod-secrets-925bb10b-75dd-4bd6-93e0-74767bc77fe5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019943561s
STEP: Saw pod success
Aug 12 16:17:19.978: INFO: Pod "pod-secrets-925bb10b-75dd-4bd6-93e0-74767bc77fe5" satisfied condition "success or failure"
Aug 12 16:17:19.984: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxf2 pod pod-secrets-925bb10b-75dd-4bd6-93e0-74767bc77fe5 container secret-volume-test: <nil>
STEP: delete the pod
Aug 12 16:17:20.021: INFO: Waiting for pod pod-secrets-925bb10b-75dd-4bd6-93e0-74767bc77fe5 to disappear
Aug 12 16:17:20.025: INFO: Pod pod-secrets-925bb10b-75dd-4bd6-93e0-74767bc77fe5 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:17:20.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8780" for this suite.
Aug 12 16:17:26.042: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:17:26.182: INFO: namespace secrets-8780 deletion completed in 6.152327267s

 [SLOW TEST:10.279 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:17:26.183: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-3521/configmap-test-5f2ded22-d1c0-40a4-bcd1-bc55469d209d
STEP: Creating a pod to test consume configMaps
Aug 12 16:17:26.240: INFO: Waiting up to 5m0s for pod "pod-configmaps-94276cb6-b648-4070-ae86-a807f88bf5f0" in namespace "configmap-3521" to be "success or failure"
Aug 12 16:17:26.250: INFO: Pod "pod-configmaps-94276cb6-b648-4070-ae86-a807f88bf5f0": Phase="Pending", Reason="", readiness=false. Elapsed: 10.079143ms
Aug 12 16:17:28.254: INFO: Pod "pod-configmaps-94276cb6-b648-4070-ae86-a807f88bf5f0": Phase="Running", Reason="", readiness=true. Elapsed: 2.014096424s
Aug 12 16:17:30.267: INFO: Pod "pod-configmaps-94276cb6-b648-4070-ae86-a807f88bf5f0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027423257s
STEP: Saw pod success
Aug 12 16:17:30.267: INFO: Pod "pod-configmaps-94276cb6-b648-4070-ae86-a807f88bf5f0" satisfied condition "success or failure"
Aug 12 16:17:30.273: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxfs pod pod-configmaps-94276cb6-b648-4070-ae86-a807f88bf5f0 container env-test: <nil>
STEP: delete the pod
Aug 12 16:17:30.317: INFO: Waiting for pod pod-configmaps-94276cb6-b648-4070-ae86-a807f88bf5f0 to disappear
Aug 12 16:17:30.320: INFO: Pod pod-configmaps-94276cb6-b648-4070-ae86-a807f88bf5f0 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:17:30.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3521" for this suite.
Aug 12 16:17:36.342: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:17:36.515: INFO: namespace configmap-3521 deletion completed in 6.188535552s

 [SLOW TEST:10.334 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:17:36.525: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Aug 12 16:17:36.578: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Aug 12 16:17:45.650: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:17:45.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6157" for this suite.
Aug 12 16:17:51.682: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:17:51.828: INFO: namespace pods-6157 deletion completed in 6.161170461s

 [SLOW TEST:15.304 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:17:51.831: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1686
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 12 16:17:51.949: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-4090'
Aug 12 16:17:52.509: INFO: stderr: ""
Aug 12 16:17:52.509: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1691
Aug 12 16:17:52.511: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 delete pods e2e-test-nginx-pod --namespace=kubectl-4090'
Aug 12 16:18:04.144: INFO: stderr: ""
Aug 12 16:18:04.144: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:18:04.144: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4090" for this suite.
Aug 12 16:18:10.166: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:18:10.298: INFO: namespace kubectl-4090 deletion completed in 6.149269232s

 [SLOW TEST:18.468 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:18:10.301: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-919
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 12 16:18:10.396: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug 12 16:18:36.753: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.0.172:8080/dial?request=hostName&protocol=http&host=10.244.1.93&port=8080&tries=1'] Namespace:pod-network-test-919 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 12 16:18:36.753: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
Aug 12 16:18:37.021: INFO: Waiting for endpoints: map[]
Aug 12 16:18:37.026: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.0.172:8080/dial?request=hostName&protocol=http&host=10.244.2.169&port=8080&tries=1'] Namespace:pod-network-test-919 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 12 16:18:37.026: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
Aug 12 16:18:37.358: INFO: Waiting for endpoints: map[]
Aug 12 16:18:37.363: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.0.172:8080/dial?request=hostName&protocol=http&host=10.244.0.159&port=8080&tries=1'] Namespace:pod-network-test-919 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 12 16:18:37.364: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
Aug 12 16:18:37.702: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:18:37.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-919" for this suite.
Aug 12 16:19:01.723: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:19:01.872: INFO: namespace pod-network-test-919 deletion completed in 24.16410892s

 [SLOW TEST:51.572 seconds]
[sig-network] Networking
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:19:01.880: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-4a812c53-16d6-4e66-a983-2d1a9caa899d
STEP: Creating a pod to test consume secrets
Aug 12 16:19:01.989: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-c17cb980-7874-40be-a57c-b8bbc9d79d98" in namespace "projected-1922" to be "success or failure"
Aug 12 16:19:01.999: INFO: Pod "pod-projected-secrets-c17cb980-7874-40be-a57c-b8bbc9d79d98": Phase="Pending", Reason="", readiness=false. Elapsed: 9.384497ms
Aug 12 16:19:04.004: INFO: Pod "pod-projected-secrets-c17cb980-7874-40be-a57c-b8bbc9d79d98": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014436375s
Aug 12 16:19:06.009: INFO: Pod "pod-projected-secrets-c17cb980-7874-40be-a57c-b8bbc9d79d98": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019214814s
STEP: Saw pod success
Aug 12 16:19:06.010: INFO: Pod "pod-projected-secrets-c17cb980-7874-40be-a57c-b8bbc9d79d98" satisfied condition "success or failure"
Aug 12 16:19:06.015: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxf2 pod pod-projected-secrets-c17cb980-7874-40be-a57c-b8bbc9d79d98 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 12 16:19:06.071: INFO: Waiting for pod pod-projected-secrets-c17cb980-7874-40be-a57c-b8bbc9d79d98 to disappear
Aug 12 16:19:06.074: INFO: Pod pod-projected-secrets-c17cb980-7874-40be-a57c-b8bbc9d79d98 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:19:06.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1922" for this suite.
Aug 12 16:19:12.092: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:19:12.236: INFO: namespace projected-1922 deletion completed in 6.157198471s

 [SLOW TEST:10.356 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:19:12.237: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Aug 12 16:19:12.341: INFO: Waiting up to 5m0s for pod "pod-7a9db9ab-ccf6-4363-9ad8-b6b757357225" in namespace "emptydir-6547" to be "success or failure"
Aug 12 16:19:12.352: INFO: Pod "pod-7a9db9ab-ccf6-4363-9ad8-b6b757357225": Phase="Pending", Reason="", readiness=false. Elapsed: 10.394823ms
Aug 12 16:19:14.357: INFO: Pod "pod-7a9db9ab-ccf6-4363-9ad8-b6b757357225": Phase="Running", Reason="", readiness=true. Elapsed: 2.015444926s
Aug 12 16:19:16.362: INFO: Pod "pod-7a9db9ab-ccf6-4363-9ad8-b6b757357225": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019787813s
STEP: Saw pod success
Aug 12 16:19:16.362: INFO: Pod "pod-7a9db9ab-ccf6-4363-9ad8-b6b757357225" satisfied condition "success or failure"
Aug 12 16:19:16.366: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxfs pod pod-7a9db9ab-ccf6-4363-9ad8-b6b757357225 container test-container: <nil>
STEP: delete the pod
Aug 12 16:19:16.410: INFO: Waiting for pod pod-7a9db9ab-ccf6-4363-9ad8-b6b757357225 to disappear
Aug 12 16:19:16.417: INFO: Pod pod-7a9db9ab-ccf6-4363-9ad8-b6b757357225 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:19:16.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6547" for this suite.
Aug 12 16:19:22.440: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:19:22.574: INFO: namespace emptydir-6547 deletion completed in 6.149891207s

 [SLOW TEST:10.338 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:19:22.577: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-d2f10fa8-4fb0-4c4b-91f8-5a7d4de0ae2e
STEP: Creating a pod to test consume secrets
Aug 12 16:19:22.707: INFO: Waiting up to 5m0s for pod "pod-secrets-8e290bd1-dc93-4051-9ef1-a95372599a4d" in namespace "secrets-3370" to be "success or failure"
Aug 12 16:19:22.723: INFO: Pod "pod-secrets-8e290bd1-dc93-4051-9ef1-a95372599a4d": Phase="Pending", Reason="", readiness=false. Elapsed: 8.337061ms
Aug 12 16:19:24.727: INFO: Pod "pod-secrets-8e290bd1-dc93-4051-9ef1-a95372599a4d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013088891s
Aug 12 16:19:26.733: INFO: Pod "pod-secrets-8e290bd1-dc93-4051-9ef1-a95372599a4d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018938308s
STEP: Saw pod success
Aug 12 16:19:26.734: INFO: Pod "pod-secrets-8e290bd1-dc93-4051-9ef1-a95372599a4d" satisfied condition "success or failure"
Aug 12 16:19:26.742: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxfp pod pod-secrets-8e290bd1-dc93-4051-9ef1-a95372599a4d container secret-volume-test: <nil>
STEP: delete the pod
Aug 12 16:19:27.042: INFO: Waiting for pod pod-secrets-8e290bd1-dc93-4051-9ef1-a95372599a4d to disappear
Aug 12 16:19:27.045: INFO: Pod pod-secrets-8e290bd1-dc93-4051-9ef1-a95372599a4d no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:19:27.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3370" for this suite.
Aug 12 16:19:33.064: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:19:33.265: INFO: namespace secrets-3370 deletion completed in 6.215858525s

 [SLOW TEST:10.689 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:19:33.268: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Aug 12 16:19:33.596: INFO: Pod name wrapped-volume-race-01dccc1d-dad7-49bc-8e5e-bd2c70188569: Found 0 pods out of 5
Aug 12 16:19:38.611: INFO: Pod name wrapped-volume-race-01dccc1d-dad7-49bc-8e5e-bd2c70188569: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-01dccc1d-dad7-49bc-8e5e-bd2c70188569 in namespace emptydir-wrapper-7806, will wait for the garbage collector to delete the pods
Aug 12 16:20:02.700: INFO: Deleting ReplicationController wrapped-volume-race-01dccc1d-dad7-49bc-8e5e-bd2c70188569 took: 15.63268ms
Aug 12 16:20:03.101: INFO: Terminating ReplicationController wrapped-volume-race-01dccc1d-dad7-49bc-8e5e-bd2c70188569 pods took: 400.767301ms
STEP: Creating RC which spawns configmap-volume pods
Aug 12 16:20:44.427: INFO: Pod name wrapped-volume-race-05926f39-6b03-4fb9-bfe2-b5c0ac7786bb: Found 0 pods out of 5
Aug 12 16:20:49.440: INFO: Pod name wrapped-volume-race-05926f39-6b03-4fb9-bfe2-b5c0ac7786bb: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-05926f39-6b03-4fb9-bfe2-b5c0ac7786bb in namespace emptydir-wrapper-7806, will wait for the garbage collector to delete the pods
Aug 12 16:21:05.556: INFO: Deleting ReplicationController wrapped-volume-race-05926f39-6b03-4fb9-bfe2-b5c0ac7786bb took: 17.496066ms
Aug 12 16:21:05.956: INFO: Terminating ReplicationController wrapped-volume-race-05926f39-6b03-4fb9-bfe2-b5c0ac7786bb pods took: 400.675122ms
STEP: Creating RC which spawns configmap-volume pods
Aug 12 16:21:44.680: INFO: Pod name wrapped-volume-race-719bbf0b-ffdc-4691-9fa8-6ee46aecb1da: Found 0 pods out of 5
Aug 12 16:21:49.687: INFO: Pod name wrapped-volume-race-719bbf0b-ffdc-4691-9fa8-6ee46aecb1da: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-719bbf0b-ffdc-4691-9fa8-6ee46aecb1da in namespace emptydir-wrapper-7806, will wait for the garbage collector to delete the pods
Aug 12 16:22:07.798: INFO: Deleting ReplicationController wrapped-volume-race-719bbf0b-ffdc-4691-9fa8-6ee46aecb1da took: 29.096656ms
Aug 12 16:22:08.399: INFO: Terminating ReplicationController wrapped-volume-race-719bbf0b-ffdc-4691-9fa8-6ee46aecb1da pods took: 600.601218ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:22:54.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-7806" for this suite.
Aug 12 16:23:02.296: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:23:02.447: INFO: namespace emptydir-wrapper-7806 deletion completed in 8.165880729s

 [SLOW TEST:209.179 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:23:02.449: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1293
STEP: creating an rc
Aug 12 16:23:02.551: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 create -f - --namespace=kubectl-5007'
Aug 12 16:23:02.852: INFO: stderr: ""
Aug 12 16:23:02.852: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Waiting for Redis master to start.
Aug 12 16:23:03.892: INFO: Selector matched 1 pods for map[app:redis]
Aug 12 16:23:03.892: INFO: Found 0 / 1
Aug 12 16:23:04.858: INFO: Selector matched 1 pods for map[app:redis]
Aug 12 16:23:04.858: INFO: Found 0 / 1
Aug 12 16:23:05.858: INFO: Selector matched 1 pods for map[app:redis]
Aug 12 16:23:05.858: INFO: Found 0 / 1
Aug 12 16:23:06.859: INFO: Selector matched 1 pods for map[app:redis]
Aug 12 16:23:06.859: INFO: Found 1 / 1
Aug 12 16:23:06.860: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug 12 16:23:06.869: INFO: Selector matched 1 pods for map[app:redis]
Aug 12 16:23:06.869: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Aug 12 16:23:06.869: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 logs redis-master-mmj6q redis-master --namespace=kubectl-5007'
Aug 12 16:23:07.004: INFO: stderr: ""
Aug 12 16:23:07.004: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 12 Aug 16:23:04.823 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 12 Aug 16:23:04.823 # Server started, Redis version 3.2.12\n1:M 12 Aug 16:23:04.823 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 12 Aug 16:23:04.823 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Aug 12 16:23:07.004: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 log redis-master-mmj6q redis-master --namespace=kubectl-5007 --tail=1'
Aug 12 16:23:07.147: INFO: stderr: ""
Aug 12 16:23:07.147: INFO: stdout: "1:M 12 Aug 16:23:04.823 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Aug 12 16:23:07.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 log redis-master-mmj6q redis-master --namespace=kubectl-5007 --limit-bytes=1'
Aug 12 16:23:07.293: INFO: stderr: ""
Aug 12 16:23:07.293: INFO: stdout: " "
STEP: exposing timestamps
Aug 12 16:23:07.293: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 log redis-master-mmj6q redis-master --namespace=kubectl-5007 --tail=1 --timestamps'
Aug 12 16:23:07.414: INFO: stderr: ""
Aug 12 16:23:07.414: INFO: stdout: "2019-08-12T16:23:04.824084117Z 1:M 12 Aug 16:23:04.823 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Aug 12 16:23:09.915: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 log redis-master-mmj6q redis-master --namespace=kubectl-5007 --since=1s'
Aug 12 16:23:10.034: INFO: stderr: ""
Aug 12 16:23:10.034: INFO: stdout: ""
Aug 12 16:23:10.034: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 log redis-master-mmj6q redis-master --namespace=kubectl-5007 --since=24h'
Aug 12 16:23:10.179: INFO: stderr: ""
Aug 12 16:23:10.179: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 12 Aug 16:23:04.823 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 12 Aug 16:23:04.823 # Server started, Redis version 3.2.12\n1:M 12 Aug 16:23:04.823 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 12 Aug 16:23:04.823 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1299
STEP: using delete to clean up resources
Aug 12 16:23:10.179: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 delete --grace-period=0 --force -f - --namespace=kubectl-5007'
Aug 12 16:23:10.298: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 12 16:23:10.298: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Aug 12 16:23:10.298: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 get rc,svc -l name=nginx --no-headers --namespace=kubectl-5007'
Aug 12 16:23:10.725: INFO: stderr: "No resources found.\n"
Aug 12 16:23:10.725: INFO: stdout: ""
Aug 12 16:23:10.725: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 get pods -l name=nginx --namespace=kubectl-5007 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 12 16:23:10.977: INFO: stderr: ""
Aug 12 16:23:10.977: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:23:10.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5007" for this suite.
Aug 12 16:23:32.992: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:23:33.177: INFO: namespace kubectl-5007 deletion completed in 22.196087774s

 [SLOW TEST:30.728 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:23:33.181: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1457
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 12 16:23:33.218: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-4688'
Aug 12 16:23:33.347: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 12 16:23:33.347: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Aug 12 16:23:33.365: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-fqwnj]
Aug 12 16:23:33.366: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-fqwnj" in namespace "kubectl-4688" to be "running and ready"
Aug 12 16:23:33.372: INFO: Pod "e2e-test-nginx-rc-fqwnj": Phase="Pending", Reason="", readiness=false. Elapsed: 6.175166ms
Aug 12 16:23:35.377: INFO: Pod "e2e-test-nginx-rc-fqwnj": Phase="Running", Reason="", readiness=true. Elapsed: 2.010454664s
Aug 12 16:23:35.377: INFO: Pod "e2e-test-nginx-rc-fqwnj" satisfied condition "running and ready"
Aug 12 16:23:35.377: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-fqwnj]
Aug 12 16:23:35.377: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 logs rc/e2e-test-nginx-rc --namespace=kubectl-4688'
Aug 12 16:23:35.531: INFO: stderr: ""
Aug 12 16:23:35.531: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1462
Aug 12 16:23:35.531: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 delete rc e2e-test-nginx-rc --namespace=kubectl-4688'
Aug 12 16:23:35.647: INFO: stderr: ""
Aug 12 16:23:35.647: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:23:35.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4688" for this suite.
Aug 12 16:23:57.665: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:23:57.807: INFO: namespace kubectl-4688 deletion completed in 22.155615521s

 [SLOW TEST:24.627 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:23:57.811: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 12 16:23:57.918: INFO: Creating ReplicaSet my-hostname-basic-d54d0a71-9ee3-4b59-8b65-ed050422ea6e
Aug 12 16:23:57.926: INFO: Pod name my-hostname-basic-d54d0a71-9ee3-4b59-8b65-ed050422ea6e: Found 0 pods out of 1
Aug 12 16:24:02.934: INFO: Pod name my-hostname-basic-d54d0a71-9ee3-4b59-8b65-ed050422ea6e: Found 1 pods out of 1
Aug 12 16:24:02.934: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-d54d0a71-9ee3-4b59-8b65-ed050422ea6e" is running
Aug 12 16:24:02.938: INFO: Pod "my-hostname-basic-d54d0a71-9ee3-4b59-8b65-ed050422ea6e-86sfx" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-12 16:23:57 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-12 16:24:02 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-12 16:24:02 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-12 16:23:57 +0000 UTC Reason: Message:}])
Aug 12 16:24:02.938: INFO: Trying to dial the pod
Aug 12 16:24:07.956: INFO: Controller my-hostname-basic-d54d0a71-9ee3-4b59-8b65-ed050422ea6e: Got expected result from replica 1 [my-hostname-basic-d54d0a71-9ee3-4b59-8b65-ed050422ea6e-86sfx]: "my-hostname-basic-d54d0a71-9ee3-4b59-8b65-ed050422ea6e-86sfx", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:24:07.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-1188" for this suite.
Aug 12 16:24:14.069: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:24:14.542: INFO: namespace replicaset-1188 deletion completed in 6.576813925s

 [SLOW TEST:16.731 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:24:14.544: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:24:20.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-5457" for this suite.
Aug 12 16:24:26.808: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:24:26.955: INFO: namespace namespaces-5457 deletion completed in 6.161975229s
STEP: Destroying namespace "nsdeletetest-4075" for this suite.
Aug 12 16:24:26.958: INFO: Namespace nsdeletetest-4075 was already deleted
STEP: Destroying namespace "nsdeletetest-6696" for this suite.
Aug 12 16:24:32.974: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:24:33.110: INFO: namespace nsdeletetest-6696 deletion completed in 6.15116948s

 [SLOW TEST:18.567 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:24:33.115: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating server pod server in namespace prestop-229
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-229
STEP: Deleting pre-stop pod
Aug 12 16:24:44.281: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:24:44.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-229" for this suite.
Aug 12 16:25:16.331: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:25:16.481: INFO: namespace prestop-229 deletion completed in 32.172171647s

 [SLOW TEST:43.367 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:25:16.485: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-2456
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 12 16:25:16.576: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug 12 16:25:42.731: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.2.95 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2456 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 12 16:25:42.731: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
Aug 12 16:25:44.343: INFO: Found all expected endpoints: [netserver-0]
Aug 12 16:25:44.347: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.1.238 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2456 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 12 16:25:44.347: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
Aug 12 16:25:45.574: INFO: Found all expected endpoints: [netserver-1]
Aug 12 16:25:45.579: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.0.193 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2456 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 12 16:25:45.580: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
Aug 12 16:25:46.876: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:25:46.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-2456" for this suite.
Aug 12 16:26:08.900: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:26:09.069: INFO: namespace pod-network-test-2456 deletion completed in 22.186375726s

 [SLOW TEST:52.585 seconds]
[sig-network] Networking
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:26:09.074: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Aug 12 16:26:17.409: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 12 16:26:17.470: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 12 16:26:19.470: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 12 16:26:19.479: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 12 16:26:21.470: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 12 16:26:21.475: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 12 16:26:23.470: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 12 16:26:23.476: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 12 16:26:25.470: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 12 16:26:25.475: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 12 16:26:27.470: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 12 16:26:27.478: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 12 16:26:29.470: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 12 16:26:29.474: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 12 16:26:31.470: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 12 16:26:31.475: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 12 16:26:33.470: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 12 16:26:33.474: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 12 16:26:35.470: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 12 16:26:35.474: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 12 16:26:37.470: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 12 16:26:37.475: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:26:37.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2876" for this suite.
Aug 12 16:26:59.506: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:26:59.690: INFO: namespace container-lifecycle-hook-2876 deletion completed in 22.20752764s

 [SLOW TEST:50.617 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:26:59.694: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0812 16:27:29.823338      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 12 16:27:29.823: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:27:29.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8154" for this suite.
Aug 12 16:27:35.851: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:27:36.022: INFO: namespace gc-8154 deletion completed in 6.192925164s

 [SLOW TEST:36.328 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:27:36.025: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Aug 12 16:27:36.140: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 create -f - --namespace=kubectl-1658'
Aug 12 16:27:36.406: INFO: stderr: ""
Aug 12 16:27:36.407: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 12 16:27:36.407: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1658'
Aug 12 16:27:36.536: INFO: stderr: ""
Aug 12 16:27:36.536: INFO: stdout: "update-demo-nautilus-h6sgz update-demo-nautilus-kx7pz "
Aug 12 16:27:36.536: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 get pods update-demo-nautilus-h6sgz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1658'
Aug 12 16:27:36.671: INFO: stderr: ""
Aug 12 16:27:36.671: INFO: stdout: ""
Aug 12 16:27:36.671: INFO: update-demo-nautilus-h6sgz is created but not running
Aug 12 16:27:41.671: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1658'
Aug 12 16:27:41.786: INFO: stderr: ""
Aug 12 16:27:41.786: INFO: stdout: "update-demo-nautilus-h6sgz update-demo-nautilus-kx7pz "
Aug 12 16:27:41.786: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 get pods update-demo-nautilus-h6sgz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1658'
Aug 12 16:27:41.890: INFO: stderr: ""
Aug 12 16:27:41.890: INFO: stdout: "true"
Aug 12 16:27:41.890: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 get pods update-demo-nautilus-h6sgz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1658'
Aug 12 16:27:42.011: INFO: stderr: ""
Aug 12 16:27:42.011: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 12 16:27:42.011: INFO: validating pod update-demo-nautilus-h6sgz
Aug 12 16:27:42.024: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 12 16:27:42.024: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 12 16:27:42.024: INFO: update-demo-nautilus-h6sgz is verified up and running
Aug 12 16:27:42.024: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 get pods update-demo-nautilus-kx7pz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1658'
Aug 12 16:27:42.136: INFO: stderr: ""
Aug 12 16:27:42.136: INFO: stdout: "true"
Aug 12 16:27:42.136: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 get pods update-demo-nautilus-kx7pz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1658'
Aug 12 16:27:42.236: INFO: stderr: ""
Aug 12 16:27:42.236: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 12 16:27:42.236: INFO: validating pod update-demo-nautilus-kx7pz
Aug 12 16:27:42.243: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 12 16:27:42.244: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 12 16:27:42.244: INFO: update-demo-nautilus-kx7pz is verified up and running
STEP: scaling down the replication controller
Aug 12 16:27:42.248: INFO: scanned /root for discovery docs: <nil>
Aug 12 16:27:42.248: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-1658'
Aug 12 16:27:43.430: INFO: stderr: ""
Aug 12 16:27:43.430: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 12 16:27:43.430: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1658'
Aug 12 16:27:43.535: INFO: stderr: ""
Aug 12 16:27:43.535: INFO: stdout: "update-demo-nautilus-h6sgz update-demo-nautilus-kx7pz "
STEP: Replicas for name=update-demo: expected=1 actual=2
Aug 12 16:27:48.536: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1658'
Aug 12 16:27:48.687: INFO: stderr: ""
Aug 12 16:27:48.687: INFO: stdout: "update-demo-nautilus-h6sgz "
Aug 12 16:27:48.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 get pods update-demo-nautilus-h6sgz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1658'
Aug 12 16:27:48.986: INFO: stderr: ""
Aug 12 16:27:48.986: INFO: stdout: "true"
Aug 12 16:27:48.986: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 get pods update-demo-nautilus-h6sgz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1658'
Aug 12 16:27:49.122: INFO: stderr: ""
Aug 12 16:27:49.122: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 12 16:27:49.122: INFO: validating pod update-demo-nautilus-h6sgz
Aug 12 16:27:49.127: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 12 16:27:49.127: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 12 16:27:49.127: INFO: update-demo-nautilus-h6sgz is verified up and running
STEP: scaling up the replication controller
Aug 12 16:27:49.129: INFO: scanned /root for discovery docs: <nil>
Aug 12 16:27:49.129: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-1658'
Aug 12 16:27:50.401: INFO: stderr: ""
Aug 12 16:27:50.401: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 12 16:27:50.401: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1658'
Aug 12 16:27:50.570: INFO: stderr: ""
Aug 12 16:27:50.570: INFO: stdout: "update-demo-nautilus-h6sgz update-demo-nautilus-ts8jr "
Aug 12 16:27:50.570: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 get pods update-demo-nautilus-h6sgz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1658'
Aug 12 16:27:50.681: INFO: stderr: ""
Aug 12 16:27:50.681: INFO: stdout: "true"
Aug 12 16:27:50.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 get pods update-demo-nautilus-h6sgz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1658'
Aug 12 16:27:50.814: INFO: stderr: ""
Aug 12 16:27:50.814: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 12 16:27:50.814: INFO: validating pod update-demo-nautilus-h6sgz
Aug 12 16:27:50.820: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 12 16:27:50.820: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 12 16:27:50.820: INFO: update-demo-nautilus-h6sgz is verified up and running
Aug 12 16:27:50.820: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 get pods update-demo-nautilus-ts8jr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1658'
Aug 12 16:27:50.977: INFO: stderr: ""
Aug 12 16:27:50.977: INFO: stdout: ""
Aug 12 16:27:50.977: INFO: update-demo-nautilus-ts8jr is created but not running
Aug 12 16:27:55.977: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1658'
Aug 12 16:27:56.494: INFO: stderr: ""
Aug 12 16:27:56.494: INFO: stdout: "update-demo-nautilus-h6sgz update-demo-nautilus-ts8jr "
Aug 12 16:27:56.494: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 get pods update-demo-nautilus-h6sgz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1658'
Aug 12 16:27:56.591: INFO: stderr: ""
Aug 12 16:27:56.591: INFO: stdout: "true"
Aug 12 16:27:56.592: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 get pods update-demo-nautilus-h6sgz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1658'
Aug 12 16:27:56.690: INFO: stderr: ""
Aug 12 16:27:56.690: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 12 16:27:56.690: INFO: validating pod update-demo-nautilus-h6sgz
Aug 12 16:27:56.698: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 12 16:27:56.698: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 12 16:27:56.698: INFO: update-demo-nautilus-h6sgz is verified up and running
Aug 12 16:27:56.698: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 get pods update-demo-nautilus-ts8jr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1658'
Aug 12 16:27:56.832: INFO: stderr: ""
Aug 12 16:27:56.832: INFO: stdout: "true"
Aug 12 16:27:56.832: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 get pods update-demo-nautilus-ts8jr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1658'
Aug 12 16:27:56.962: INFO: stderr: ""
Aug 12 16:27:56.962: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 12 16:27:56.963: INFO: validating pod update-demo-nautilus-ts8jr
Aug 12 16:27:56.975: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 12 16:27:56.975: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 12 16:27:56.975: INFO: update-demo-nautilus-ts8jr is verified up and running
STEP: using delete to clean up resources
Aug 12 16:27:56.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 delete --grace-period=0 --force -f - --namespace=kubectl-1658'
Aug 12 16:27:57.103: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 12 16:27:57.103: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Aug 12 16:27:57.103: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-1658'
Aug 12 16:27:57.195: INFO: stderr: "No resources found.\n"
Aug 12 16:27:57.195: INFO: stdout: ""
Aug 12 16:27:57.195: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 get pods -l name=update-demo --namespace=kubectl-1658 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 12 16:27:57.289: INFO: stderr: ""
Aug 12 16:27:57.289: INFO: stdout: "update-demo-nautilus-h6sgz\nupdate-demo-nautilus-ts8jr\n"
Aug 12 16:27:57.789: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-1658'
Aug 12 16:27:57.917: INFO: stderr: "No resources found.\n"
Aug 12 16:27:57.917: INFO: stdout: ""
Aug 12 16:27:57.917: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 get pods -l name=update-demo --namespace=kubectl-1658 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 12 16:27:58.047: INFO: stderr: ""
Aug 12 16:27:58.047: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:27:58.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1658" for this suite.
Aug 12 16:28:04.069: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:28:04.233: INFO: namespace kubectl-1658 deletion completed in 6.180537495s

 [SLOW TEST:28.209 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:28:04.238: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1211
STEP: creating the pod
Aug 12 16:28:04.312: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 create -f - --namespace=kubectl-957'
Aug 12 16:28:04.569: INFO: stderr: ""
Aug 12 16:28:04.569: INFO: stdout: "pod/pause created\n"
Aug 12 16:28:04.569: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Aug 12 16:28:04.570: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-957" to be "running and ready"
Aug 12 16:28:04.575: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 5.159452ms
Aug 12 16:28:06.579: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009707823s
Aug 12 16:28:08.584: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.014501299s
Aug 12 16:28:08.584: INFO: Pod "pause" satisfied condition "running and ready"
Aug 12 16:28:08.584: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: adding the label testing-label with value testing-label-value to a pod
Aug 12 16:28:08.584: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 label pods pause testing-label=testing-label-value --namespace=kubectl-957'
Aug 12 16:28:08.697: INFO: stderr: ""
Aug 12 16:28:08.697: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Aug 12 16:28:08.698: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 get pod pause -L testing-label --namespace=kubectl-957'
Aug 12 16:28:08.835: INFO: stderr: ""
Aug 12 16:28:08.836: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Aug 12 16:28:08.836: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 label pods pause testing-label- --namespace=kubectl-957'
Aug 12 16:28:08.963: INFO: stderr: ""
Aug 12 16:28:08.963: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Aug 12 16:28:08.963: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 get pod pause -L testing-label --namespace=kubectl-957'
Aug 12 16:28:09.060: INFO: stderr: ""
Aug 12 16:28:09.060: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1218
STEP: using delete to clean up resources
Aug 12 16:28:09.060: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 delete --grace-period=0 --force -f - --namespace=kubectl-957'
Aug 12 16:28:09.186: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 12 16:28:09.186: INFO: stdout: "pod \"pause\" force deleted\n"
Aug 12 16:28:09.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 get rc,svc -l name=pause --no-headers --namespace=kubectl-957'
Aug 12 16:28:09.392: INFO: stderr: "No resources found.\n"
Aug 12 16:28:09.392: INFO: stdout: ""
Aug 12 16:28:09.392: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 get pods -l name=pause --namespace=kubectl-957 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 12 16:28:09.578: INFO: stderr: ""
Aug 12 16:28:09.578: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:28:09.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-957" for this suite.
Aug 12 16:28:15.625: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:28:15.790: INFO: namespace kubectl-957 deletion completed in 6.187499409s

 [SLOW TEST:11.553 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:28:15.794: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Aug 12 16:28:18.957: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:28:18.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5890" for this suite.
Aug 12 16:28:25.090: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:28:25.437: INFO: namespace container-runtime-5890 deletion completed in 6.452272314s

 [SLOW TEST:9.644 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:28:25.451: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-3608
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating stateful set ss in namespace statefulset-3608
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-3608
Aug 12 16:28:25.584: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Aug 12 16:28:35.593: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Aug 12 16:28:35.599: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 exec --namespace=statefulset-3608 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 12 16:28:36.009: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 12 16:28:36.009: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 12 16:28:36.010: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 12 16:28:36.017: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Aug 12 16:28:46.090: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 12 16:28:46.091: INFO: Waiting for statefulset status.replicas updated to 0
Aug 12 16:28:46.933: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Aug 12 16:28:46.933: INFO: ss-0  conformance-1-15-2-do-0-default-pool-rxfs  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:28:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:28:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:28:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:28:25 +0000 UTC  }]
Aug 12 16:28:46.933: INFO: 
Aug 12 16:28:46.933: INFO: StatefulSet ss has not reached scale 3, at 1
Aug 12 16:28:48.161: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.770972109s
Aug 12 16:28:49.170: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.762257681s
Aug 12 16:28:50.177: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.752974755s
Aug 12 16:28:51.596: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.745731929s
Aug 12 16:28:52.601: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.326942168s
Aug 12 16:28:53.607: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.321455592s
Aug 12 16:28:54.613: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.316481637s
Aug 12 16:28:55.619: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.309852429s
Aug 12 16:28:56.626: INFO: Verifying statefulset ss doesn't scale past 3 for another 304.329149ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-3608
Aug 12 16:28:57.634: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 exec --namespace=statefulset-3608 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 12 16:28:58.034: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug 12 16:28:58.034: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 12 16:28:58.034: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 12 16:28:58.034: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 exec --namespace=statefulset-3608 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 12 16:28:58.466: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Aug 12 16:28:58.466: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 12 16:28:58.466: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 12 16:28:58.466: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 exec --namespace=statefulset-3608 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 12 16:28:58.840: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Aug 12 16:28:58.840: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 12 16:28:58.840: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 12 16:28:58.851: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Aug 12 16:29:08.859: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 12 16:29:08.859: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 12 16:29:08.859: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Aug 12 16:29:08.866: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 exec --namespace=statefulset-3608 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 12 16:29:09.262: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 12 16:29:09.262: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 12 16:29:09.262: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 12 16:29:09.262: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 exec --namespace=statefulset-3608 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 12 16:29:09.802: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 12 16:29:09.802: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 12 16:29:09.802: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 12 16:29:09.802: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 exec --namespace=statefulset-3608 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 12 16:29:11.398: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 12 16:29:11.398: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 12 16:29:11.398: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 12 16:29:11.398: INFO: Waiting for statefulset status.replicas updated to 0
Aug 12 16:29:11.403: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Aug 12 16:29:21.415: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 12 16:29:21.416: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Aug 12 16:29:21.416: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Aug 12 16:29:21.433: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Aug 12 16:29:21.433: INFO: ss-0  conformance-1-15-2-do-0-default-pool-rxfs  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:28:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:29:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:29:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:28:25 +0000 UTC  }]
Aug 12 16:29:21.433: INFO: ss-1  conformance-1-15-2-do-0-default-pool-rxf2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:28:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:29:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:29:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:28:46 +0000 UTC  }]
Aug 12 16:29:21.434: INFO: ss-2  conformance-1-15-2-do-0-default-pool-rxfp  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:28:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:29:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:29:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:28:46 +0000 UTC  }]
Aug 12 16:29:21.434: INFO: 
Aug 12 16:29:21.434: INFO: StatefulSet ss has not reached scale 0, at 3
Aug 12 16:29:22.438: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Aug 12 16:29:22.438: INFO: ss-0  conformance-1-15-2-do-0-default-pool-rxfs  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:28:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:29:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:29:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:28:25 +0000 UTC  }]
Aug 12 16:29:22.438: INFO: ss-1  conformance-1-15-2-do-0-default-pool-rxf2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:28:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:29:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:29:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:28:46 +0000 UTC  }]
Aug 12 16:29:22.438: INFO: ss-2  conformance-1-15-2-do-0-default-pool-rxfp  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:28:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:29:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:29:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:28:46 +0000 UTC  }]
Aug 12 16:29:22.438: INFO: 
Aug 12 16:29:22.438: INFO: StatefulSet ss has not reached scale 0, at 3
Aug 12 16:29:23.449: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Aug 12 16:29:23.449: INFO: ss-0  conformance-1-15-2-do-0-default-pool-rxfs  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:28:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:29:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:29:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:28:25 +0000 UTC  }]
Aug 12 16:29:23.449: INFO: ss-1  conformance-1-15-2-do-0-default-pool-rxf2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:28:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:29:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:29:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:28:46 +0000 UTC  }]
Aug 12 16:29:23.450: INFO: ss-2  conformance-1-15-2-do-0-default-pool-rxfp  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:28:46 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:29:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:29:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:28:46 +0000 UTC  }]
Aug 12 16:29:23.450: INFO: 
Aug 12 16:29:23.450: INFO: StatefulSet ss has not reached scale 0, at 3
Aug 12 16:29:24.458: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Aug 12 16:29:24.458: INFO: ss-0  conformance-1-15-2-do-0-default-pool-rxfs  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:28:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:29:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:29:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:28:25 +0000 UTC  }]
Aug 12 16:29:24.458: INFO: 
Aug 12 16:29:24.458: INFO: StatefulSet ss has not reached scale 0, at 1
Aug 12 16:29:25.464: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Aug 12 16:29:25.464: INFO: ss-0  conformance-1-15-2-do-0-default-pool-rxfs  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:28:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:29:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:29:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:28:25 +0000 UTC  }]
Aug 12 16:29:25.464: INFO: 
Aug 12 16:29:25.464: INFO: StatefulSet ss has not reached scale 0, at 1
Aug 12 16:29:26.473: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Aug 12 16:29:26.473: INFO: ss-0  conformance-1-15-2-do-0-default-pool-rxfs  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:28:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:29:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:29:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:28:25 +0000 UTC  }]
Aug 12 16:29:26.474: INFO: 
Aug 12 16:29:26.474: INFO: StatefulSet ss has not reached scale 0, at 1
Aug 12 16:29:27.479: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Aug 12 16:29:27.479: INFO: ss-0  conformance-1-15-2-do-0-default-pool-rxfs  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:28:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:29:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:29:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:28:25 +0000 UTC  }]
Aug 12 16:29:27.479: INFO: 
Aug 12 16:29:27.480: INFO: StatefulSet ss has not reached scale 0, at 1
Aug 12 16:29:28.484: INFO: POD   NODE                                       PHASE    GRACE  CONDITIONS
Aug 12 16:29:28.484: INFO: ss-0  conformance-1-15-2-do-0-default-pool-rxfs  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:28:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:29:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:29:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:28:25 +0000 UTC  }]
Aug 12 16:29:28.484: INFO: 
Aug 12 16:29:28.484: INFO: StatefulSet ss has not reached scale 0, at 1
Aug 12 16:29:29.490: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.940751757s
Aug 12 16:29:30.498: INFO: Verifying statefulset ss doesn't scale past 0 for another 934.561113ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-3608
Aug 12 16:29:31.504: INFO: Scaling statefulset ss to 0
Aug 12 16:29:31.516: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Aug 12 16:29:31.519: INFO: Deleting all statefulset in ns statefulset-3608
Aug 12 16:29:31.522: INFO: Scaling statefulset ss to 0
Aug 12 16:29:31.530: INFO: Waiting for statefulset status.replicas updated to 0
Aug 12 16:29:31.533: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:29:31.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3608" for this suite.
Aug 12 16:29:37.569: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:29:37.751: INFO: namespace statefulset-3608 deletion completed in 6.196104063s

 [SLOW TEST:72.300 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:29:37.764: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name projected-secret-test-15b188d9-48d1-438b-b1b2-51cb78b999f5
STEP: Creating a pod to test consume secrets
Aug 12 16:29:37.893: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e0c80a32-f9fd-4edb-abe6-6c07d0bd6e35" in namespace "projected-438" to be "success or failure"
Aug 12 16:29:37.900: INFO: Pod "pod-projected-secrets-e0c80a32-f9fd-4edb-abe6-6c07d0bd6e35": Phase="Pending", Reason="", readiness=false. Elapsed: 5.651636ms
Aug 12 16:29:39.904: INFO: Pod "pod-projected-secrets-e0c80a32-f9fd-4edb-abe6-6c07d0bd6e35": Phase="Running", Reason="", readiness=true. Elapsed: 2.009412059s
Aug 12 16:29:41.909: INFO: Pod "pod-projected-secrets-e0c80a32-f9fd-4edb-abe6-6c07d0bd6e35": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014914212s
STEP: Saw pod success
Aug 12 16:29:41.909: INFO: Pod "pod-projected-secrets-e0c80a32-f9fd-4edb-abe6-6c07d0bd6e35" satisfied condition "success or failure"
Aug 12 16:29:41.915: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxfs pod pod-projected-secrets-e0c80a32-f9fd-4edb-abe6-6c07d0bd6e35 container secret-volume-test: <nil>
STEP: delete the pod
Aug 12 16:29:41.949: INFO: Waiting for pod pod-projected-secrets-e0c80a32-f9fd-4edb-abe6-6c07d0bd6e35 to disappear
Aug 12 16:29:41.953: INFO: Pod pod-projected-secrets-e0c80a32-f9fd-4edb-abe6-6c07d0bd6e35 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:29:41.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-438" for this suite.
Aug 12 16:29:47.971: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:29:48.113: INFO: namespace projected-438 deletion completed in 6.155307597s

 [SLOW TEST:10.350 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:29:48.116: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override command
Aug 12 16:29:48.181: INFO: Waiting up to 5m0s for pod "client-containers-399cfdc6-eea2-4eb3-816f-ae6a2a8d5efc" in namespace "containers-836" to be "success or failure"
Aug 12 16:29:48.192: INFO: Pod "client-containers-399cfdc6-eea2-4eb3-816f-ae6a2a8d5efc": Phase="Pending", Reason="", readiness=false. Elapsed: 10.351557ms
Aug 12 16:29:50.201: INFO: Pod "client-containers-399cfdc6-eea2-4eb3-816f-ae6a2a8d5efc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019706191s
Aug 12 16:29:52.205: INFO: Pod "client-containers-399cfdc6-eea2-4eb3-816f-ae6a2a8d5efc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023605296s
STEP: Saw pod success
Aug 12 16:29:52.206: INFO: Pod "client-containers-399cfdc6-eea2-4eb3-816f-ae6a2a8d5efc" satisfied condition "success or failure"
Aug 12 16:29:52.208: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxfp pod client-containers-399cfdc6-eea2-4eb3-816f-ae6a2a8d5efc container test-container: <nil>
STEP: delete the pod
Aug 12 16:29:52.236: INFO: Waiting for pod client-containers-399cfdc6-eea2-4eb3-816f-ae6a2a8d5efc to disappear
Aug 12 16:29:52.239: INFO: Pod client-containers-399cfdc6-eea2-4eb3-816f-ae6a2a8d5efc no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:29:52.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-836" for this suite.
Aug 12 16:29:58.279: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:29:58.550: INFO: namespace containers-836 deletion completed in 6.299243472s

 [SLOW TEST:10.434 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:29:58.554: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 12 16:29:58.624: INFO: Waiting up to 5m0s for pod "downwardapi-volume-41525cab-67f3-46ed-8d5e-be1e391ece0a" in namespace "downward-api-7848" to be "success or failure"
Aug 12 16:29:58.641: INFO: Pod "downwardapi-volume-41525cab-67f3-46ed-8d5e-be1e391ece0a": Phase="Pending", Reason="", readiness=false. Elapsed: 15.771533ms
Aug 12 16:30:00.645: INFO: Pod "downwardapi-volume-41525cab-67f3-46ed-8d5e-be1e391ece0a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020146707s
Aug 12 16:30:02.655: INFO: Pod "downwardapi-volume-41525cab-67f3-46ed-8d5e-be1e391ece0a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029868139s
STEP: Saw pod success
Aug 12 16:30:02.655: INFO: Pod "downwardapi-volume-41525cab-67f3-46ed-8d5e-be1e391ece0a" satisfied condition "success or failure"
Aug 12 16:30:02.662: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxf2 pod downwardapi-volume-41525cab-67f3-46ed-8d5e-be1e391ece0a container client-container: <nil>
STEP: delete the pod
Aug 12 16:30:02.695: INFO: Waiting for pod downwardapi-volume-41525cab-67f3-46ed-8d5e-be1e391ece0a to disappear
Aug 12 16:30:02.702: INFO: Pod downwardapi-volume-41525cab-67f3-46ed-8d5e-be1e391ece0a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:30:02.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7848" for this suite.
Aug 12 16:30:08.726: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:30:08.897: INFO: namespace downward-api-7848 deletion completed in 6.190924619s

 [SLOW TEST:10.343 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:30:08.898: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:30:08.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3555" for this suite.
Aug 12 16:30:31.005: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:30:31.149: INFO: namespace kubelet-test-3555 deletion completed in 22.1853116s

 [SLOW TEST:22.251 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:30:31.153: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override all
Aug 12 16:30:31.295: INFO: Waiting up to 5m0s for pod "client-containers-1692d989-5353-48c8-af72-b2374fa12abd" in namespace "containers-2763" to be "success or failure"
Aug 12 16:30:31.312: INFO: Pod "client-containers-1692d989-5353-48c8-af72-b2374fa12abd": Phase="Pending", Reason="", readiness=false. Elapsed: 17.020662ms
Aug 12 16:30:33.316: INFO: Pod "client-containers-1692d989-5353-48c8-af72-b2374fa12abd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020820167s
Aug 12 16:30:35.320: INFO: Pod "client-containers-1692d989-5353-48c8-af72-b2374fa12abd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024572789s
STEP: Saw pod success
Aug 12 16:30:35.320: INFO: Pod "client-containers-1692d989-5353-48c8-af72-b2374fa12abd" satisfied condition "success or failure"
Aug 12 16:30:35.323: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxfp pod client-containers-1692d989-5353-48c8-af72-b2374fa12abd container test-container: <nil>
STEP: delete the pod
Aug 12 16:30:35.354: INFO: Waiting for pod client-containers-1692d989-5353-48c8-af72-b2374fa12abd to disappear
Aug 12 16:30:35.359: INFO: Pod client-containers-1692d989-5353-48c8-af72-b2374fa12abd no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:30:35.359: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-2763" for this suite.
Aug 12 16:30:41.379: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:30:41.535: INFO: namespace containers-2763 deletion completed in 6.17205827s

 [SLOW TEST:10.383 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:30:41.538: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-8bc5e083-3fa2-4a11-8d48-ba417437381c
STEP: Creating a pod to test consume configMaps
Aug 12 16:30:41.602: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2882b7fa-453a-4799-b143-29fb92d6df47" in namespace "projected-2395" to be "success or failure"
Aug 12 16:30:41.612: INFO: Pod "pod-projected-configmaps-2882b7fa-453a-4799-b143-29fb92d6df47": Phase="Pending", Reason="", readiness=false. Elapsed: 9.841664ms
Aug 12 16:30:43.619: INFO: Pod "pod-projected-configmaps-2882b7fa-453a-4799-b143-29fb92d6df47": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016211328s
Aug 12 16:30:45.624: INFO: Pod "pod-projected-configmaps-2882b7fa-453a-4799-b143-29fb92d6df47": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02144437s
STEP: Saw pod success
Aug 12 16:30:45.624: INFO: Pod "pod-projected-configmaps-2882b7fa-453a-4799-b143-29fb92d6df47" satisfied condition "success or failure"
Aug 12 16:30:45.629: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxf2 pod pod-projected-configmaps-2882b7fa-453a-4799-b143-29fb92d6df47 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 12 16:30:45.659: INFO: Waiting for pod pod-projected-configmaps-2882b7fa-453a-4799-b143-29fb92d6df47 to disappear
Aug 12 16:30:45.666: INFO: Pod pod-projected-configmaps-2882b7fa-453a-4799-b143-29fb92d6df47 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:30:45.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2395" for this suite.
Aug 12 16:30:51.688: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:30:51.880: INFO: namespace projected-2395 deletion completed in 6.208044613s

 [SLOW TEST:10.342 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:30:51.883: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Aug 12 16:30:51.953: INFO: Pod name pod-release: Found 0 pods out of 1
Aug 12 16:30:56.958: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:30:56.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-4531" for this suite.
Aug 12 16:31:03.045: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:31:03.180: INFO: namespace replication-controller-4531 deletion completed in 6.174084903s

 [SLOW TEST:11.298 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:31:03.183: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:31:07.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6280" for this suite.
Aug 12 16:31:13.506: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:31:13.867: INFO: namespace kubelet-test-6280 deletion completed in 6.492482363s

 [SLOW TEST:10.685 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:31:13.875: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Aug 12 16:31:17.101: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:31:17.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5604" for this suite.
Aug 12 16:31:23.163: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:31:23.334: INFO: namespace container-runtime-5604 deletion completed in 6.193464609s

 [SLOW TEST:9.459 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:31:23.338: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:31:27.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7751" for this suite.
Aug 12 16:32:05.538: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:32:05.701: INFO: namespace kubelet-test-7751 deletion completed in 38.187071077s

 [SLOW TEST:42.363 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a read only busybox container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:32:05.704: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-8623, will wait for the garbage collector to delete the pods
Aug 12 16:32:09.826: INFO: Deleting Job.batch foo took: 7.047643ms
Aug 12 16:32:10.226: INFO: Terminating Job.batch foo pods took: 400.430787ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:32:49.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-8623" for this suite.
Aug 12 16:32:55.456: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:32:55.593: INFO: namespace job-8623 deletion completed in 6.155223217s

 [SLOW TEST:49.890 seconds]
[sig-apps] Job
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:32:55.605: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-ec83f39b-e01d-413d-b70c-da1520c38dd5 in namespace container-probe-4528
Aug 12 16:32:59.666: INFO: Started pod liveness-ec83f39b-e01d-413d-b70c-da1520c38dd5 in namespace container-probe-4528
STEP: checking the pod's current state and verifying that restartCount is present
Aug 12 16:32:59.671: INFO: Initial restart count of pod liveness-ec83f39b-e01d-413d-b70c-da1520c38dd5 is 0
Aug 12 16:33:11.710: INFO: Restart count of pod container-probe-4528/liveness-ec83f39b-e01d-413d-b70c-da1520c38dd5 is now 1 (12.0392501s elapsed)
Aug 12 16:33:31.772: INFO: Restart count of pod container-probe-4528/liveness-ec83f39b-e01d-413d-b70c-da1520c38dd5 is now 2 (32.100823176s elapsed)
Aug 12 16:33:49.823: INFO: Restart count of pod container-probe-4528/liveness-ec83f39b-e01d-413d-b70c-da1520c38dd5 is now 3 (50.15208619s elapsed)
Aug 12 16:34:11.913: INFO: Restart count of pod container-probe-4528/liveness-ec83f39b-e01d-413d-b70c-da1520c38dd5 is now 4 (1m12.242302183s elapsed)
Aug 12 16:35:22.230: INFO: Restart count of pod container-probe-4528/liveness-ec83f39b-e01d-413d-b70c-da1520c38dd5 is now 5 (2m22.559433264s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:35:22.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4528" for this suite.
Aug 12 16:35:28.269: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:35:28.487: INFO: namespace container-probe-4528 deletion completed in 6.241432855s

 [SLOW TEST:152.883 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:35:28.496: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-1b843132-5500-425e-9766-30a1da0f59af
STEP: Creating a pod to test consume configMaps
Aug 12 16:35:28.609: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-fd512357-cee4-4ce6-ade1-91e2983596f7" in namespace "projected-7963" to be "success or failure"
Aug 12 16:35:28.631: INFO: Pod "pod-projected-configmaps-fd512357-cee4-4ce6-ade1-91e2983596f7": Phase="Pending", Reason="", readiness=false. Elapsed: 22.101342ms
Aug 12 16:35:30.644: INFO: Pod "pod-projected-configmaps-fd512357-cee4-4ce6-ade1-91e2983596f7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035246095s
Aug 12 16:35:32.652: INFO: Pod "pod-projected-configmaps-fd512357-cee4-4ce6-ade1-91e2983596f7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.042783762s
STEP: Saw pod success
Aug 12 16:35:32.652: INFO: Pod "pod-projected-configmaps-fd512357-cee4-4ce6-ade1-91e2983596f7" satisfied condition "success or failure"
Aug 12 16:35:32.654: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxf2 pod pod-projected-configmaps-fd512357-cee4-4ce6-ade1-91e2983596f7 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 12 16:35:32.682: INFO: Waiting for pod pod-projected-configmaps-fd512357-cee4-4ce6-ade1-91e2983596f7 to disappear
Aug 12 16:35:32.687: INFO: Pod pod-projected-configmaps-fd512357-cee4-4ce6-ade1-91e2983596f7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:35:32.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7963" for this suite.
Aug 12 16:35:38.708: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:35:38.835: INFO: namespace projected-7963 deletion completed in 6.138292012s

 [SLOW TEST:10.340 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:35:38.840: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Aug 12 16:35:43.456: INFO: Successfully updated pod "annotationupdatec736977c-c533-4455-9814-3fd5994671b4"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:35:45.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9792" for this suite.
Aug 12 16:36:07.516: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:36:07.653: INFO: namespace downward-api-9792 deletion completed in 22.158623568s

 [SLOW TEST:28.814 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:36:07.668: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Aug 12 16:36:07.789: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-7594,SelfLink:/api/v1/namespaces/watch-7594/configmaps/e2e-watch-test-label-changed,UID:e4573ae2-9708-4988-ae45-bafc3133e7fc,ResourceVersion:42949,Generation:0,CreationTimestamp:2019-08-12 16:36:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 12 16:36:07.796: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-7594,SelfLink:/api/v1/namespaces/watch-7594/configmaps/e2e-watch-test-label-changed,UID:e4573ae2-9708-4988-ae45-bafc3133e7fc,ResourceVersion:42950,Generation:0,CreationTimestamp:2019-08-12 16:36:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Aug 12 16:36:07.796: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-7594,SelfLink:/api/v1/namespaces/watch-7594/configmaps/e2e-watch-test-label-changed,UID:e4573ae2-9708-4988-ae45-bafc3133e7fc,ResourceVersion:42951,Generation:0,CreationTimestamp:2019-08-12 16:36:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Aug 12 16:36:17.840: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-7594,SelfLink:/api/v1/namespaces/watch-7594/configmaps/e2e-watch-test-label-changed,UID:e4573ae2-9708-4988-ae45-bafc3133e7fc,ResourceVersion:42969,Generation:0,CreationTimestamp:2019-08-12 16:36:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 12 16:36:17.841: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-7594,SelfLink:/api/v1/namespaces/watch-7594/configmaps/e2e-watch-test-label-changed,UID:e4573ae2-9708-4988-ae45-bafc3133e7fc,ResourceVersion:42970,Generation:0,CreationTimestamp:2019-08-12 16:36:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Aug 12 16:36:17.841: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-7594,SelfLink:/api/v1/namespaces/watch-7594/configmaps/e2e-watch-test-label-changed,UID:e4573ae2-9708-4988-ae45-bafc3133e7fc,ResourceVersion:42971,Generation:0,CreationTimestamp:2019-08-12 16:36:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:36:17.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7594" for this suite.
Aug 12 16:36:23.879: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:36:23.996: INFO: namespace watch-7594 deletion completed in 6.144871968s

 [SLOW TEST:16.328 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:36:24.003: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-587b6de5-7de3-40f2-a335-96275a66e7a6
STEP: Creating a pod to test consume configMaps
Aug 12 16:36:24.124: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-83a2ce65-f3db-47fa-a7fe-13aa42241e09" in namespace "projected-3753" to be "success or failure"
Aug 12 16:36:24.135: INFO: Pod "pod-projected-configmaps-83a2ce65-f3db-47fa-a7fe-13aa42241e09": Phase="Pending", Reason="", readiness=false. Elapsed: 11.239677ms
Aug 12 16:36:26.140: INFO: Pod "pod-projected-configmaps-83a2ce65-f3db-47fa-a7fe-13aa42241e09": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015729474s
Aug 12 16:36:28.146: INFO: Pod "pod-projected-configmaps-83a2ce65-f3db-47fa-a7fe-13aa42241e09": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022320989s
STEP: Saw pod success
Aug 12 16:36:28.147: INFO: Pod "pod-projected-configmaps-83a2ce65-f3db-47fa-a7fe-13aa42241e09" satisfied condition "success or failure"
Aug 12 16:36:28.150: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxfp pod pod-projected-configmaps-83a2ce65-f3db-47fa-a7fe-13aa42241e09 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 12 16:36:28.177: INFO: Waiting for pod pod-projected-configmaps-83a2ce65-f3db-47fa-a7fe-13aa42241e09 to disappear
Aug 12 16:36:28.180: INFO: Pod pod-projected-configmaps-83a2ce65-f3db-47fa-a7fe-13aa42241e09 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:36:28.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3753" for this suite.
Aug 12 16:36:34.199: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:36:34.331: INFO: namespace projected-3753 deletion completed in 6.146477792s

 [SLOW TEST:10.329 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:36:34.337: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Aug 12 16:36:34.459: INFO: Waiting up to 5m0s for pod "pod-945405f2-1002-40eb-ac94-93440c1bfac5" in namespace "emptydir-5471" to be "success or failure"
Aug 12 16:36:34.467: INFO: Pod "pod-945405f2-1002-40eb-ac94-93440c1bfac5": Phase="Pending", Reason="", readiness=false. Elapsed: 7.009602ms
Aug 12 16:36:36.474: INFO: Pod "pod-945405f2-1002-40eb-ac94-93440c1bfac5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013957375s
Aug 12 16:36:38.482: INFO: Pod "pod-945405f2-1002-40eb-ac94-93440c1bfac5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022724023s
STEP: Saw pod success
Aug 12 16:36:38.483: INFO: Pod "pod-945405f2-1002-40eb-ac94-93440c1bfac5" satisfied condition "success or failure"
Aug 12 16:36:38.488: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxf2 pod pod-945405f2-1002-40eb-ac94-93440c1bfac5 container test-container: <nil>
STEP: delete the pod
Aug 12 16:36:38.541: INFO: Waiting for pod pod-945405f2-1002-40eb-ac94-93440c1bfac5 to disappear
Aug 12 16:36:38.544: INFO: Pod pod-945405f2-1002-40eb-ac94-93440c1bfac5 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:36:38.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5471" for this suite.
Aug 12 16:36:44.576: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:36:44.729: INFO: namespace emptydir-5471 deletion completed in 6.179740606s

 [SLOW TEST:10.393 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:36:44.733: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 12 16:36:44.845: INFO: Creating deployment "test-recreate-deployment"
Aug 12 16:36:44.853: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Aug 12 16:36:44.877: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Aug 12 16:36:46.888: INFO: Waiting deployment "test-recreate-deployment" to complete
Aug 12 16:36:46.892: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701224604, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701224604, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701224604, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701224604, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-6df85df6b9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 12 16:36:48.897: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Aug 12 16:36:48.906: INFO: Updating deployment test-recreate-deployment
Aug 12 16:36:48.906: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Aug 12 16:36:49.037: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-1781,SelfLink:/apis/apps/v1/namespaces/deployment-1781/deployments/test-recreate-deployment,UID:b536619e-8f67-4669-aa9d-93cbfe3d3f2d,ResourceVersion:43145,Generation:2,CreationTimestamp:2019-08-12 16:36:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-08-12 16:36:48 +0000 UTC 2019-08-12 16:36:48 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-08-12 16:36:49 +0000 UTC 2019-08-12 16:36:44 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-5c8c9cc69d" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Aug 12 16:36:49.042: INFO: New ReplicaSet "test-recreate-deployment-5c8c9cc69d" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d,GenerateName:,Namespace:deployment-1781,SelfLink:/apis/apps/v1/namespaces/deployment-1781/replicasets/test-recreate-deployment-5c8c9cc69d,UID:06ee49cf-9c81-4977-b501-ff90e9ee5ff2,ResourceVersion:43144,Generation:1,CreationTimestamp:2019-08-12 16:36:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment b536619e-8f67-4669-aa9d-93cbfe3d3f2d 0xc000a229c7 0xc000a229c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 12 16:36:49.043: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Aug 12 16:36:49.043: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-6df85df6b9,GenerateName:,Namespace:deployment-1781,SelfLink:/apis/apps/v1/namespaces/deployment-1781/replicasets/test-recreate-deployment-6df85df6b9,UID:618d7f9f-a969-473a-aa5d-d0dd42a1c6b3,ResourceVersion:43134,Generation:2,CreationTimestamp:2019-08-12 16:36:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment b536619e-8f67-4669-aa9d-93cbfe3d3f2d 0xc000a23067 0xc000a23068}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 12 16:36:49.054: INFO: Pod "test-recreate-deployment-5c8c9cc69d-cbpmd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d-cbpmd,GenerateName:test-recreate-deployment-5c8c9cc69d-,Namespace:deployment-1781,SelfLink:/api/v1/namespaces/deployment-1781/pods/test-recreate-deployment-5c8c9cc69d-cbpmd,UID:fa7231d9-db47-4db1-88d1-4bbd83d5db74,ResourceVersion:43146,Generation:0,CreationTimestamp:2019-08-12 16:36:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-5c8c9cc69d 06ee49cf-9c81-4977-b501-ff90e9ee5ff2 0xc000aecc27 0xc000aecc28}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-v6tcn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-v6tcn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-v6tcn true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-1-15-2-do-0-default-pool-rxfp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000aecd40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000aecd70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:36:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:36:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:36:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:36:48 +0000 UTC  }],Message:,Reason:,HostIP:10.138.15.72,PodIP:,StartTime:2019-08-12 16:36:49 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:36:49.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1781" for this suite.
Aug 12 16:36:55.082: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:36:55.222: INFO: namespace deployment-1781 deletion completed in 6.156970879s

 [SLOW TEST:10.489 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:36:55.226: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:37:21.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-3611" for this suite.
Aug 12 16:37:27.597: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:37:27.786: INFO: namespace namespaces-3611 deletion completed in 6.205139851s
STEP: Destroying namespace "nsdeletetest-6209" for this suite.
Aug 12 16:37:27.791: INFO: Namespace nsdeletetest-6209 was already deleted
STEP: Destroying namespace "nsdeletetest-5606" for this suite.
Aug 12 16:37:33.807: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:37:33.950: INFO: namespace nsdeletetest-5606 deletion completed in 6.15887669s

 [SLOW TEST:38.724 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:37:33.952: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0812 16:37:40.153712      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 12 16:37:40.153: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:37:40.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7572" for this suite.
Aug 12 16:37:46.175: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:37:46.318: INFO: namespace gc-7572 deletion completed in 6.160725429s

 [SLOW TEST:12.367 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:37:46.322: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-3517ebd4-beea-4151-95df-fe2828440ef7 in namespace container-probe-4364
Aug 12 16:37:50.453: INFO: Started pod busybox-3517ebd4-beea-4151-95df-fe2828440ef7 in namespace container-probe-4364
STEP: checking the pod's current state and verifying that restartCount is present
Aug 12 16:37:50.457: INFO: Initial restart count of pod busybox-3517ebd4-beea-4151-95df-fe2828440ef7 is 0
Aug 12 16:38:44.710: INFO: Restart count of pod container-probe-4364/busybox-3517ebd4-beea-4151-95df-fe2828440ef7 is now 1 (54.253602241s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:38:44.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4364" for this suite.
Aug 12 16:38:50.857: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:38:51.047: INFO: namespace container-probe-4364 deletion completed in 6.309732823s

 [SLOW TEST:64.725 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:38:51.052: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Aug 12 16:38:55.676: INFO: Successfully updated pod "labelsupdateaf169d49-9aff-43e1-af58-58d68da98738"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:38:57.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2621" for this suite.
Aug 12 16:39:19.752: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:39:19.913: INFO: namespace downward-api-2621 deletion completed in 22.1812056s

 [SLOW TEST:28.862 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:39:19.916: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Aug 12 16:39:20.009: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 create -f - --namespace=kubectl-2218'
Aug 12 16:39:20.701: INFO: stderr: ""
Aug 12 16:39:20.701: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 12 16:39:20.701: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2218'
Aug 12 16:39:20.877: INFO: stderr: ""
Aug 12 16:39:20.877: INFO: stdout: "update-demo-nautilus-8cbg8 update-demo-nautilus-mw25s "
Aug 12 16:39:20.877: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 get pods update-demo-nautilus-8cbg8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2218'
Aug 12 16:39:20.971: INFO: stderr: ""
Aug 12 16:39:20.971: INFO: stdout: ""
Aug 12 16:39:20.971: INFO: update-demo-nautilus-8cbg8 is created but not running
Aug 12 16:39:25.971: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2218'
Aug 12 16:39:26.071: INFO: stderr: ""
Aug 12 16:39:26.071: INFO: stdout: "update-demo-nautilus-8cbg8 update-demo-nautilus-mw25s "
Aug 12 16:39:26.071: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 get pods update-demo-nautilus-8cbg8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2218'
Aug 12 16:39:26.164: INFO: stderr: ""
Aug 12 16:39:26.164: INFO: stdout: "true"
Aug 12 16:39:26.164: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 get pods update-demo-nautilus-8cbg8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2218'
Aug 12 16:39:26.272: INFO: stderr: ""
Aug 12 16:39:26.272: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 12 16:39:26.272: INFO: validating pod update-demo-nautilus-8cbg8
Aug 12 16:39:26.291: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 12 16:39:26.291: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 12 16:39:26.291: INFO: update-demo-nautilus-8cbg8 is verified up and running
Aug 12 16:39:26.291: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 get pods update-demo-nautilus-mw25s -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2218'
Aug 12 16:39:26.393: INFO: stderr: ""
Aug 12 16:39:26.393: INFO: stdout: "true"
Aug 12 16:39:26.393: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 get pods update-demo-nautilus-mw25s -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2218'
Aug 12 16:39:26.487: INFO: stderr: ""
Aug 12 16:39:26.487: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 12 16:39:26.487: INFO: validating pod update-demo-nautilus-mw25s
Aug 12 16:39:26.494: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 12 16:39:26.494: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 12 16:39:26.494: INFO: update-demo-nautilus-mw25s is verified up and running
STEP: using delete to clean up resources
Aug 12 16:39:26.494: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 delete --grace-period=0 --force -f - --namespace=kubectl-2218'
Aug 12 16:39:26.632: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 12 16:39:26.632: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Aug 12 16:39:26.632: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-2218'
Aug 12 16:39:26.761: INFO: stderr: "No resources found.\n"
Aug 12 16:39:26.761: INFO: stdout: ""
Aug 12 16:39:26.761: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 get pods -l name=update-demo --namespace=kubectl-2218 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 12 16:39:26.920: INFO: stderr: ""
Aug 12 16:39:26.920: INFO: stdout: "update-demo-nautilus-8cbg8\nupdate-demo-nautilus-mw25s\n"
Aug 12 16:39:27.420: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-2218'
Aug 12 16:39:27.550: INFO: stderr: "No resources found.\n"
Aug 12 16:39:27.550: INFO: stdout: ""
Aug 12 16:39:27.550: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 get pods -l name=update-demo --namespace=kubectl-2218 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 12 16:39:27.658: INFO: stderr: ""
Aug 12 16:39:27.658: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:39:27.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2218" for this suite.
Aug 12 16:39:49.677: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:39:49.805: INFO: namespace kubectl-2218 deletion completed in 22.141371518s

 [SLOW TEST:29.890 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:39:49.810: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Aug 12 16:39:53.881: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-213645099 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Aug 12 16:39:58.992: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:39:58.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3253" for this suite.
Aug 12 16:40:05.015: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:40:05.134: INFO: namespace pods-3253 deletion completed in 6.13184207s

 [SLOW TEST:15.325 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:40:05.137: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-81600eec-feb9-4bf8-a6f0-31c134061dd3
STEP: Creating a pod to test consume configMaps
Aug 12 16:40:05.244: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ff8996b6-40a8-4f3f-9e3b-8cc78639611a" in namespace "projected-5962" to be "success or failure"
Aug 12 16:40:05.256: INFO: Pod "pod-projected-configmaps-ff8996b6-40a8-4f3f-9e3b-8cc78639611a": Phase="Pending", Reason="", readiness=false. Elapsed: 11.505358ms
Aug 12 16:40:07.268: INFO: Pod "pod-projected-configmaps-ff8996b6-40a8-4f3f-9e3b-8cc78639611a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023300347s
Aug 12 16:40:09.273: INFO: Pod "pod-projected-configmaps-ff8996b6-40a8-4f3f-9e3b-8cc78639611a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028239237s
STEP: Saw pod success
Aug 12 16:40:09.274: INFO: Pod "pod-projected-configmaps-ff8996b6-40a8-4f3f-9e3b-8cc78639611a" satisfied condition "success or failure"
Aug 12 16:40:09.278: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxfs pod pod-projected-configmaps-ff8996b6-40a8-4f3f-9e3b-8cc78639611a container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 12 16:40:09.320: INFO: Waiting for pod pod-projected-configmaps-ff8996b6-40a8-4f3f-9e3b-8cc78639611a to disappear
Aug 12 16:40:09.325: INFO: Pod pod-projected-configmaps-ff8996b6-40a8-4f3f-9e3b-8cc78639611a no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:40:09.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5962" for this suite.
Aug 12 16:40:15.377: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:40:15.523: INFO: namespace projected-5962 deletion completed in 6.19208306s

 [SLOW TEST:10.387 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:40:15.527: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service endpoint-test2 in namespace services-9725
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9725 to expose endpoints map[]
Aug 12 16:40:15.724: INFO: successfully validated that service endpoint-test2 in namespace services-9725 exposes endpoints map[] (4.333056ms elapsed)
STEP: Creating pod pod1 in namespace services-9725
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9725 to expose endpoints map[pod1:[80]]
Aug 12 16:40:19.130: INFO: successfully validated that service endpoint-test2 in namespace services-9725 exposes endpoints map[pod1:[80]] (3.392695778s elapsed)
STEP: Creating pod pod2 in namespace services-9725
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9725 to expose endpoints map[pod1:[80] pod2:[80]]
Aug 12 16:40:22.206: INFO: successfully validated that service endpoint-test2 in namespace services-9725 exposes endpoints map[pod1:[80] pod2:[80]] (3.065844933s elapsed)
STEP: Deleting pod pod1 in namespace services-9725
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9725 to expose endpoints map[pod2:[80]]
Aug 12 16:40:22.290: INFO: successfully validated that service endpoint-test2 in namespace services-9725 exposes endpoints map[pod2:[80]] (8.875705ms elapsed)
STEP: Deleting pod pod2 in namespace services-9725
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9725 to expose endpoints map[]
Aug 12 16:40:22.371: INFO: successfully validated that service endpoint-test2 in namespace services-9725 exposes endpoints map[] (72.854686ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:40:22.497: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9725" for this suite.
Aug 12 16:40:28.516: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:40:28.679: INFO: namespace services-9725 deletion completed in 6.176009047s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

 [SLOW TEST:13.153 seconds]
[sig-network] Services
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:40:28.687: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Aug 12 16:40:28.804: INFO: Waiting up to 5m0s for pod "pod-5d60e7da-d061-4d29-a39c-556a140be46e" in namespace "emptydir-9948" to be "success or failure"
Aug 12 16:40:28.815: INFO: Pod "pod-5d60e7da-d061-4d29-a39c-556a140be46e": Phase="Pending", Reason="", readiness=false. Elapsed: 10.731696ms
Aug 12 16:40:30.820: INFO: Pod "pod-5d60e7da-d061-4d29-a39c-556a140be46e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015587228s
Aug 12 16:40:32.826: INFO: Pod "pod-5d60e7da-d061-4d29-a39c-556a140be46e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022249332s
STEP: Saw pod success
Aug 12 16:40:32.827: INFO: Pod "pod-5d60e7da-d061-4d29-a39c-556a140be46e" satisfied condition "success or failure"
Aug 12 16:40:32.831: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxfs pod pod-5d60e7da-d061-4d29-a39c-556a140be46e container test-container: <nil>
STEP: delete the pod
Aug 12 16:40:32.873: INFO: Waiting for pod pod-5d60e7da-d061-4d29-a39c-556a140be46e to disappear
Aug 12 16:40:32.883: INFO: Pod pod-5d60e7da-d061-4d29-a39c-556a140be46e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:40:32.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9948" for this suite.
Aug 12 16:40:38.908: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:40:39.071: INFO: namespace emptydir-9948 deletion completed in 6.184094354s

 [SLOW TEST:10.385 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:40:39.076: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 12 16:40:39.124: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:40:41.060: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-9895" for this suite.
Aug 12 16:40:47.085: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:40:47.242: INFO: namespace custom-resource-definition-9895 deletion completed in 6.174044049s

 [SLOW TEST:8.167 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:40:47.249: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Aug 12 16:40:51.378: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-627679eb-3f10-49f9-8409-defa3f54a004,GenerateName:,Namespace:events-2266,SelfLink:/api/v1/namespaces/events-2266/pods/send-events-627679eb-3f10-49f9-8409-defa3f54a004,UID:6a48df80-9e39-4e3a-a80f-cd87d4cae375,ResourceVersion:44245,Generation:0,CreationTimestamp:2019-08-12 16:40:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 346965909,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-cp4jr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-cp4jr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-cp4jr true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-1-15-2-do-0-default-pool-rxfp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002998e90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002998eb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:40:47 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:40:50 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:40:50 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 16:40:47 +0000 UTC  }],Message:,Reason:,HostIP:10.138.15.72,PodIP:10.244.1.3,StartTime:2019-08-12 16:40:47 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-08-12 16:40:49 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://18ae902b8e320cace5e78b49c457f9af07be31bd91dd01ca9076bcab45923a99}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Aug 12 16:40:53.387: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Aug 12 16:40:55.392: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:40:55.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-2266" for this suite.
Aug 12 16:41:37.427: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:41:37.569: INFO: namespace events-2266 deletion completed in 42.165565429s

 [SLOW TEST:50.321 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:41:37.572: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1613
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 12 16:41:37.609: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-3991'
Aug 12 16:41:37.746: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 12 16:41:37.746: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1618
Aug 12 16:41:37.773: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 delete jobs e2e-test-nginx-job --namespace=kubectl-3991'
Aug 12 16:41:37.887: INFO: stderr: ""
Aug 12 16:41:37.887: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:41:37.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3991" for this suite.
Aug 12 16:41:43.910: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:41:44.060: INFO: namespace kubectl-3991 deletion completed in 6.167447401s

 [SLOW TEST:6.489 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:41:44.067: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Aug 12 16:41:44.109: INFO: Waiting up to 5m0s for pod "pod-18d790bd-5d9a-461f-bbe6-f7b389d08d45" in namespace "emptydir-8073" to be "success or failure"
Aug 12 16:41:44.127: INFO: Pod "pod-18d790bd-5d9a-461f-bbe6-f7b389d08d45": Phase="Pending", Reason="", readiness=false. Elapsed: 17.126339ms
Aug 12 16:41:46.256: INFO: Pod "pod-18d790bd-5d9a-461f-bbe6-f7b389d08d45": Phase="Pending", Reason="", readiness=false. Elapsed: 2.146362459s
Aug 12 16:41:48.273: INFO: Pod "pod-18d790bd-5d9a-461f-bbe6-f7b389d08d45": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.162976629s
STEP: Saw pod success
Aug 12 16:41:48.273: INFO: Pod "pod-18d790bd-5d9a-461f-bbe6-f7b389d08d45" satisfied condition "success or failure"
Aug 12 16:41:48.281: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxfs pod pod-18d790bd-5d9a-461f-bbe6-f7b389d08d45 container test-container: <nil>
STEP: delete the pod
Aug 12 16:41:48.314: INFO: Waiting for pod pod-18d790bd-5d9a-461f-bbe6-f7b389d08d45 to disappear
Aug 12 16:41:48.318: INFO: Pod pod-18d790bd-5d9a-461f-bbe6-f7b389d08d45 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:41:48.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8073" for this suite.
Aug 12 16:41:54.336: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:41:54.478: INFO: namespace emptydir-8073 deletion completed in 6.155632164s

 [SLOW TEST:10.412 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:41:54.480: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-755f0b28-a3fa-48ff-b6a4-0b8acc71420b
STEP: Creating a pod to test consume configMaps
Aug 12 16:41:54.600: INFO: Waiting up to 5m0s for pod "pod-configmaps-e28b7988-ed1e-403a-9d5d-f3977a3cbea0" in namespace "configmap-209" to be "success or failure"
Aug 12 16:41:54.609: INFO: Pod "pod-configmaps-e28b7988-ed1e-403a-9d5d-f3977a3cbea0": Phase="Pending", Reason="", readiness=false. Elapsed: 8.926073ms
Aug 12 16:41:56.621: INFO: Pod "pod-configmaps-e28b7988-ed1e-403a-9d5d-f3977a3cbea0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020420753s
Aug 12 16:41:58.631: INFO: Pod "pod-configmaps-e28b7988-ed1e-403a-9d5d-f3977a3cbea0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030638498s
STEP: Saw pod success
Aug 12 16:41:58.631: INFO: Pod "pod-configmaps-e28b7988-ed1e-403a-9d5d-f3977a3cbea0" satisfied condition "success or failure"
Aug 12 16:41:58.635: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxfp pod pod-configmaps-e28b7988-ed1e-403a-9d5d-f3977a3cbea0 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 12 16:41:58.663: INFO: Waiting for pod pod-configmaps-e28b7988-ed1e-403a-9d5d-f3977a3cbea0 to disappear
Aug 12 16:41:58.682: INFO: Pod pod-configmaps-e28b7988-ed1e-403a-9d5d-f3977a3cbea0 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:41:58.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-209" for this suite.
Aug 12 16:42:04.714: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:42:04.849: INFO: namespace configmap-209 deletion completed in 6.156597186s

 [SLOW TEST:10.370 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:42:04.853: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:76
Aug 12 16:42:04.892: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Registering the sample API server.
Aug 12 16:42:05.456: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Aug 12 16:42:07.612: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701224925, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701224925, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701224925, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701224925, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 12 16:42:09.620: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701224925, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701224925, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701224925, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701224925, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 12 16:42:11.618: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701224925, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701224925, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701224925, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701224925, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 12 16:42:13.618: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701224925, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701224925, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701224925, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701224925, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 12 16:42:15.622: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701224925, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701224925, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701224925, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701224925, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 12 16:42:19.871: INFO: Waited 2.241113704s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:67
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:42:20.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-5803" for this suite.
Aug 12 16:42:27.005: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:42:27.176: INFO: namespace aggregator-5803 deletion completed in 6.186151458s

 [SLOW TEST:22.323 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:42:27.178: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0812 16:42:37.494766      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 12 16:42:37.495: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:42:37.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1319" for this suite.
Aug 12 16:42:43.516: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:42:43.644: INFO: namespace gc-1319 deletion completed in 6.141211759s

 [SLOW TEST:16.466 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:42:43.645: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: executing a command with run --rm and attach with stdin
Aug 12 16:42:43.678: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 --namespace=kubectl-9807 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Aug 12 16:42:47.221: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Aug 12 16:42:47.221: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:42:49.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9807" for this suite.
Aug 12 16:42:55.252: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:42:55.398: INFO: namespace kubectl-9807 deletion completed in 6.16317456s

 [SLOW TEST:11.754 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:42:55.403: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 12 16:42:55.526: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1d2e472b-cf3f-4930-a149-7ea6a5afaa25" in namespace "downward-api-9693" to be "success or failure"
Aug 12 16:42:55.537: INFO: Pod "downwardapi-volume-1d2e472b-cf3f-4930-a149-7ea6a5afaa25": Phase="Pending", Reason="", readiness=false. Elapsed: 9.843014ms
Aug 12 16:42:57.541: INFO: Pod "downwardapi-volume-1d2e472b-cf3f-4930-a149-7ea6a5afaa25": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01436677s
Aug 12 16:42:59.548: INFO: Pod "downwardapi-volume-1d2e472b-cf3f-4930-a149-7ea6a5afaa25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021079566s
STEP: Saw pod success
Aug 12 16:42:59.548: INFO: Pod "downwardapi-volume-1d2e472b-cf3f-4930-a149-7ea6a5afaa25" satisfied condition "success or failure"
Aug 12 16:42:59.553: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxf2 pod downwardapi-volume-1d2e472b-cf3f-4930-a149-7ea6a5afaa25 container client-container: <nil>
STEP: delete the pod
Aug 12 16:42:59.589: INFO: Waiting for pod downwardapi-volume-1d2e472b-cf3f-4930-a149-7ea6a5afaa25 to disappear
Aug 12 16:42:59.596: INFO: Pod downwardapi-volume-1d2e472b-cf3f-4930-a149-7ea6a5afaa25 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:42:59.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9693" for this suite.
Aug 12 16:43:05.621: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:43:05.750: INFO: namespace downward-api-9693 deletion completed in 6.14477243s

 [SLOW TEST:10.347 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:43:05.755: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-463384bc-873a-40f9-b537-2ac8849d183a
STEP: Creating secret with name s-test-opt-upd-6b104c5c-b537-4f3d-b49c-06e0305962cf
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-463384bc-873a-40f9-b537-2ac8849d183a
STEP: Updating secret s-test-opt-upd-6b104c5c-b537-4f3d-b49c-06e0305962cf
STEP: Creating secret with name s-test-opt-create-840f59b9-db80-47d0-ba1a-e98ad0bf558e
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:43:14.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6019" for this suite.
Aug 12 16:43:36.199: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:43:36.410: INFO: namespace secrets-6019 deletion completed in 22.28608509s

 [SLOW TEST:30.656 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:43:36.416: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-c18e68f0-2d0b-4ccc-97a5-f13dff8de0b8
STEP: Creating a pod to test consume secrets
Aug 12 16:43:36.531: INFO: Waiting up to 5m0s for pod "pod-secrets-a91318cc-5cdb-4e90-b956-4b7ba09c2877" in namespace "secrets-3535" to be "success or failure"
Aug 12 16:43:36.558: INFO: Pod "pod-secrets-a91318cc-5cdb-4e90-b956-4b7ba09c2877": Phase="Pending", Reason="", readiness=false. Elapsed: 27.358183ms
Aug 12 16:43:38.562: INFO: Pod "pod-secrets-a91318cc-5cdb-4e90-b956-4b7ba09c2877": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031485238s
Aug 12 16:43:40.575: INFO: Pod "pod-secrets-a91318cc-5cdb-4e90-b956-4b7ba09c2877": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.04388273s
STEP: Saw pod success
Aug 12 16:43:40.575: INFO: Pod "pod-secrets-a91318cc-5cdb-4e90-b956-4b7ba09c2877" satisfied condition "success or failure"
Aug 12 16:43:40.581: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxfp pod pod-secrets-a91318cc-5cdb-4e90-b956-4b7ba09c2877 container secret-volume-test: <nil>
STEP: delete the pod
Aug 12 16:43:40.630: INFO: Waiting for pod pod-secrets-a91318cc-5cdb-4e90-b956-4b7ba09c2877 to disappear
Aug 12 16:43:40.648: INFO: Pod pod-secrets-a91318cc-5cdb-4e90-b956-4b7ba09c2877 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:43:40.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3535" for this suite.
Aug 12 16:43:46.667: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:43:46.794: INFO: namespace secrets-3535 deletion completed in 6.142200544s

 [SLOW TEST:10.378 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:43:46.802: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:44:14.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3205" for this suite.
Aug 12 16:44:20.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:44:21.154: INFO: namespace container-runtime-3205 deletion completed in 6.228743418s

 [SLOW TEST:34.353 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    when starting a container that exits
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:44:21.162: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-b07aa7b7-7a25-4025-8f54-67fa1d995eeb
STEP: Creating a pod to test consume secrets
Aug 12 16:44:21.292: INFO: Waiting up to 5m0s for pod "pod-secrets-06f0507b-bf2c-4abd-98e2-5888df509146" in namespace "secrets-653" to be "success or failure"
Aug 12 16:44:21.303: INFO: Pod "pod-secrets-06f0507b-bf2c-4abd-98e2-5888df509146": Phase="Pending", Reason="", readiness=false. Elapsed: 10.159243ms
Aug 12 16:44:23.311: INFO: Pod "pod-secrets-06f0507b-bf2c-4abd-98e2-5888df509146": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018158811s
Aug 12 16:44:25.318: INFO: Pod "pod-secrets-06f0507b-bf2c-4abd-98e2-5888df509146": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025618111s
STEP: Saw pod success
Aug 12 16:44:25.319: INFO: Pod "pod-secrets-06f0507b-bf2c-4abd-98e2-5888df509146" satisfied condition "success or failure"
Aug 12 16:44:25.324: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxf2 pod pod-secrets-06f0507b-bf2c-4abd-98e2-5888df509146 container secret-volume-test: <nil>
STEP: delete the pod
Aug 12 16:44:25.372: INFO: Waiting for pod pod-secrets-06f0507b-bf2c-4abd-98e2-5888df509146 to disappear
Aug 12 16:44:25.375: INFO: Pod pod-secrets-06f0507b-bf2c-4abd-98e2-5888df509146 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:44:25.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-653" for this suite.
Aug 12 16:44:31.401: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:44:31.559: INFO: namespace secrets-653 deletion completed in 6.172326127s

 [SLOW TEST:10.398 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:44:31.561: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-8833
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-8833
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-8833
Aug 12 16:44:31.678: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Aug 12 16:44:41.688: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Aug 12 16:44:41.695: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 exec --namespace=statefulset-8833 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 12 16:44:42.061: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 12 16:44:42.061: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 12 16:44:42.061: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 12 16:44:42.065: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Aug 12 16:44:52.074: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 12 16:44:52.074: INFO: Waiting for statefulset status.replicas updated to 0
Aug 12 16:44:52.122: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999254s
Aug 12 16:44:53.128: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.970111332s
Aug 12 16:44:54.133: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.964338525s
Aug 12 16:44:55.140: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.960052342s
Aug 12 16:44:56.146: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.953043678s
Aug 12 16:44:57.151: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.946917846s
Aug 12 16:44:58.159: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.941513686s
Aug 12 16:44:59.164: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.933251639s
Aug 12 16:45:00.172: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.927951198s
Aug 12 16:45:01.179: INFO: Verifying statefulset ss doesn't scale past 1 for another 920.996053ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-8833
Aug 12 16:45:02.184: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 exec --namespace=statefulset-8833 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 12 16:45:02.554: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug 12 16:45:02.554: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 12 16:45:02.554: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 12 16:45:02.561: INFO: Found 1 stateful pods, waiting for 3
Aug 12 16:45:12.571: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 12 16:45:12.571: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 12 16:45:12.571: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Aug 12 16:45:12.579: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 exec --namespace=statefulset-8833 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 12 16:45:12.959: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 12 16:45:12.959: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 12 16:45:12.959: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 12 16:45:12.959: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 exec --namespace=statefulset-8833 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 12 16:45:13.340: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 12 16:45:13.340: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 12 16:45:13.340: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 12 16:45:13.341: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 exec --namespace=statefulset-8833 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 12 16:45:13.828: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 12 16:45:13.828: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 12 16:45:13.828: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 12 16:45:13.828: INFO: Waiting for statefulset status.replicas updated to 0
Aug 12 16:45:13.832: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Aug 12 16:45:23.845: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 12 16:45:23.846: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Aug 12 16:45:23.846: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Aug 12 16:45:23.860: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999359s
Aug 12 16:45:24.868: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.993410974s
Aug 12 16:45:25.875: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.985815808s
Aug 12 16:45:26.884: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.978078212s
Aug 12 16:45:27.946: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.969615557s
Aug 12 16:45:28.956: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.906822522s
Aug 12 16:45:29.963: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.896804616s
Aug 12 16:45:30.970: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.889972382s
Aug 12 16:45:31.974: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.883168909s
Aug 12 16:45:32.980: INFO: Verifying statefulset ss doesn't scale past 3 for another 878.626373ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-8833
Aug 12 16:45:33.988: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 exec --namespace=statefulset-8833 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 12 16:45:34.333: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug 12 16:45:34.333: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 12 16:45:34.333: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 12 16:45:34.334: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 exec --namespace=statefulset-8833 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 12 16:45:34.736: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug 12 16:45:34.736: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 12 16:45:34.736: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 12 16:45:34.736: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 exec --namespace=statefulset-8833 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 12 16:45:35.105: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug 12 16:45:35.105: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 12 16:45:35.105: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 12 16:45:35.105: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Aug 12 16:46:05.132: INFO: Deleting all statefulset in ns statefulset-8833
Aug 12 16:46:05.135: INFO: Scaling statefulset ss to 0
Aug 12 16:46:05.146: INFO: Waiting for statefulset status.replicas updated to 0
Aug 12 16:46:05.149: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:46:05.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8833" for this suite.
Aug 12 16:46:11.187: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:46:11.354: INFO: namespace statefulset-8833 deletion completed in 6.181866945s

 [SLOW TEST:99.794 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:46:11.359: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 12 16:46:11.462: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ca7572d2-126c-4c60-9c8b-388dbeec0f1d" in namespace "downward-api-4161" to be "success or failure"
Aug 12 16:46:11.471: INFO: Pod "downwardapi-volume-ca7572d2-126c-4c60-9c8b-388dbeec0f1d": Phase="Pending", Reason="", readiness=false. Elapsed: 8.109419ms
Aug 12 16:46:13.475: INFO: Pod "downwardapi-volume-ca7572d2-126c-4c60-9c8b-388dbeec0f1d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012627891s
Aug 12 16:46:15.481: INFO: Pod "downwardapi-volume-ca7572d2-126c-4c60-9c8b-388dbeec0f1d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01869315s
STEP: Saw pod success
Aug 12 16:46:15.482: INFO: Pod "downwardapi-volume-ca7572d2-126c-4c60-9c8b-388dbeec0f1d" satisfied condition "success or failure"
Aug 12 16:46:15.488: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxfs pod downwardapi-volume-ca7572d2-126c-4c60-9c8b-388dbeec0f1d container client-container: <nil>
STEP: delete the pod
Aug 12 16:46:15.526: INFO: Waiting for pod downwardapi-volume-ca7572d2-126c-4c60-9c8b-388dbeec0f1d to disappear
Aug 12 16:46:15.531: INFO: Pod downwardapi-volume-ca7572d2-126c-4c60-9c8b-388dbeec0f1d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:46:15.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4161" for this suite.
Aug 12 16:46:21.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:46:21.733: INFO: namespace downward-api-4161 deletion completed in 6.196577939s

 [SLOW TEST:10.375 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:46:21.742: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-a9a6703c-89ce-4517-84f9-d064cfc613a9
STEP: Creating a pod to test consume secrets
Aug 12 16:46:21.872: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-28f3fa0f-cf88-40b1-bc85-392f5801adc0" in namespace "projected-3966" to be "success or failure"
Aug 12 16:46:21.881: INFO: Pod "pod-projected-secrets-28f3fa0f-cf88-40b1-bc85-392f5801adc0": Phase="Pending", Reason="", readiness=false. Elapsed: 8.19175ms
Aug 12 16:46:24.168: INFO: Pod "pod-projected-secrets-28f3fa0f-cf88-40b1-bc85-392f5801adc0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.295176373s
Aug 12 16:46:26.173: INFO: Pod "pod-projected-secrets-28f3fa0f-cf88-40b1-bc85-392f5801adc0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.300155341s
STEP: Saw pod success
Aug 12 16:46:26.173: INFO: Pod "pod-projected-secrets-28f3fa0f-cf88-40b1-bc85-392f5801adc0" satisfied condition "success or failure"
Aug 12 16:46:26.178: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxfp pod pod-projected-secrets-28f3fa0f-cf88-40b1-bc85-392f5801adc0 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 12 16:46:26.214: INFO: Waiting for pod pod-projected-secrets-28f3fa0f-cf88-40b1-bc85-392f5801adc0 to disappear
Aug 12 16:46:26.218: INFO: Pod pod-projected-secrets-28f3fa0f-cf88-40b1-bc85-392f5801adc0 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:46:26.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3966" for this suite.
Aug 12 16:46:32.273: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:46:32.404: INFO: namespace projected-3966 deletion completed in 6.174313205s

 [SLOW TEST:10.664 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:46:32.407: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 12 16:46:32.460: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3532b215-e813-439a-919a-e99e14519212" in namespace "projected-3139" to be "success or failure"
Aug 12 16:46:32.469: INFO: Pod "downwardapi-volume-3532b215-e813-439a-919a-e99e14519212": Phase="Pending", Reason="", readiness=false. Elapsed: 8.940371ms
Aug 12 16:46:34.476: INFO: Pod "downwardapi-volume-3532b215-e813-439a-919a-e99e14519212": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01537546s
Aug 12 16:46:36.482: INFO: Pod "downwardapi-volume-3532b215-e813-439a-919a-e99e14519212": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02207825s
STEP: Saw pod success
Aug 12 16:46:36.483: INFO: Pod "downwardapi-volume-3532b215-e813-439a-919a-e99e14519212" satisfied condition "success or failure"
Aug 12 16:46:36.491: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxf2 pod downwardapi-volume-3532b215-e813-439a-919a-e99e14519212 container client-container: <nil>
STEP: delete the pod
Aug 12 16:46:36.528: INFO: Waiting for pod downwardapi-volume-3532b215-e813-439a-919a-e99e14519212 to disappear
Aug 12 16:46:36.532: INFO: Pod downwardapi-volume-3532b215-e813-439a-919a-e99e14519212 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:46:36.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3139" for this suite.
Aug 12 16:46:42.549: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:46:42.709: INFO: namespace projected-3139 deletion completed in 6.172125812s

 [SLOW TEST:10.303 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:46:42.710: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 12 16:46:42.876: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0b27caa3-45bf-44c3-892c-07cefa48d521" in namespace "downward-api-887" to be "success or failure"
Aug 12 16:46:42.898: INFO: Pod "downwardapi-volume-0b27caa3-45bf-44c3-892c-07cefa48d521": Phase="Pending", Reason="", readiness=false. Elapsed: 22.214761ms
Aug 12 16:46:44.903: INFO: Pod "downwardapi-volume-0b27caa3-45bf-44c3-892c-07cefa48d521": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027305505s
Aug 12 16:46:46.911: INFO: Pod "downwardapi-volume-0b27caa3-45bf-44c3-892c-07cefa48d521": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034682409s
STEP: Saw pod success
Aug 12 16:46:46.911: INFO: Pod "downwardapi-volume-0b27caa3-45bf-44c3-892c-07cefa48d521" satisfied condition "success or failure"
Aug 12 16:46:46.917: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxf2 pod downwardapi-volume-0b27caa3-45bf-44c3-892c-07cefa48d521 container client-container: <nil>
STEP: delete the pod
Aug 12 16:46:46.943: INFO: Waiting for pod downwardapi-volume-0b27caa3-45bf-44c3-892c-07cefa48d521 to disappear
Aug 12 16:46:46.947: INFO: Pod downwardapi-volume-0b27caa3-45bf-44c3-892c-07cefa48d521 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:46:46.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-887" for this suite.
Aug 12 16:46:52.969: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:46:53.147: INFO: namespace downward-api-887 deletion completed in 6.19383848s

 [SLOW TEST:10.438 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:46:53.157: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-d9800f29-63eb-4af6-9ffd-72572880421b
STEP: Creating a pod to test consume secrets
Aug 12 16:46:53.271: INFO: Waiting up to 5m0s for pod "pod-secrets-99720643-c9fb-4b3a-bd1b-9bebffab72f5" in namespace "secrets-169" to be "success or failure"
Aug 12 16:46:53.282: INFO: Pod "pod-secrets-99720643-c9fb-4b3a-bd1b-9bebffab72f5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.616668ms
Aug 12 16:46:55.288: INFO: Pod "pod-secrets-99720643-c9fb-4b3a-bd1b-9bebffab72f5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016277493s
Aug 12 16:46:57.295: INFO: Pod "pod-secrets-99720643-c9fb-4b3a-bd1b-9bebffab72f5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023117519s
STEP: Saw pod success
Aug 12 16:46:57.295: INFO: Pod "pod-secrets-99720643-c9fb-4b3a-bd1b-9bebffab72f5" satisfied condition "success or failure"
Aug 12 16:46:57.301: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxfp pod pod-secrets-99720643-c9fb-4b3a-bd1b-9bebffab72f5 container secret-volume-test: <nil>
STEP: delete the pod
Aug 12 16:46:57.339: INFO: Waiting for pod pod-secrets-99720643-c9fb-4b3a-bd1b-9bebffab72f5 to disappear
Aug 12 16:46:57.344: INFO: Pod pod-secrets-99720643-c9fb-4b3a-bd1b-9bebffab72f5 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:46:57.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-169" for this suite.
Aug 12 16:47:03.372: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:47:03.528: INFO: namespace secrets-169 deletion completed in 6.178944529s

 [SLOW TEST:10.371 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:47:03.530: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating replication controller my-hostname-basic-f4db610e-f543-47a0-8b65-5962bdbd608b
Aug 12 16:47:03.617: INFO: Pod name my-hostname-basic-f4db610e-f543-47a0-8b65-5962bdbd608b: Found 0 pods out of 1
Aug 12 16:47:08.625: INFO: Pod name my-hostname-basic-f4db610e-f543-47a0-8b65-5962bdbd608b: Found 1 pods out of 1
Aug 12 16:47:08.625: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-f4db610e-f543-47a0-8b65-5962bdbd608b" are running
Aug 12 16:47:08.633: INFO: Pod "my-hostname-basic-f4db610e-f543-47a0-8b65-5962bdbd608b-zjpg6" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-12 16:47:03 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-12 16:47:06 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-12 16:47:06 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-12 16:47:03 +0000 UTC Reason: Message:}])
Aug 12 16:47:08.633: INFO: Trying to dial the pod
Aug 12 16:47:13.662: INFO: Controller my-hostname-basic-f4db610e-f543-47a0-8b65-5962bdbd608b: Got expected result from replica 1 [my-hostname-basic-f4db610e-f543-47a0-8b65-5962bdbd608b-zjpg6]: "my-hostname-basic-f4db610e-f543-47a0-8b65-5962bdbd608b-zjpg6", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:47:13.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-470" for this suite.
Aug 12 16:47:19.761: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:47:19.949: INFO: namespace replication-controller-470 deletion completed in 6.271556594s

 [SLOW TEST:16.420 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:47:19.953: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 12 16:47:20.054: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:47:24.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-43" for this suite.
Aug 12 16:48:14.164: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:48:14.361: INFO: namespace pods-43 deletion completed in 50.216365588s

 [SLOW TEST:54.409 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:48:14.364: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-2497cadf-2c29-4039-9f0c-0fde75ab22fe
STEP: Creating a pod to test consume secrets
Aug 12 16:48:14.518: INFO: Waiting up to 5m0s for pod "pod-secrets-6ce88374-b736-492d-8ac9-02fcc757c125" in namespace "secrets-5029" to be "success or failure"
Aug 12 16:48:14.527: INFO: Pod "pod-secrets-6ce88374-b736-492d-8ac9-02fcc757c125": Phase="Pending", Reason="", readiness=false. Elapsed: 8.55209ms
Aug 12 16:48:16.540: INFO: Pod "pod-secrets-6ce88374-b736-492d-8ac9-02fcc757c125": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020933626s
Aug 12 16:48:18.545: INFO: Pod "pod-secrets-6ce88374-b736-492d-8ac9-02fcc757c125": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026061825s
STEP: Saw pod success
Aug 12 16:48:18.545: INFO: Pod "pod-secrets-6ce88374-b736-492d-8ac9-02fcc757c125" satisfied condition "success or failure"
Aug 12 16:48:18.548: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxfp pod pod-secrets-6ce88374-b736-492d-8ac9-02fcc757c125 container secret-volume-test: <nil>
STEP: delete the pod
Aug 12 16:48:18.583: INFO: Waiting for pod pod-secrets-6ce88374-b736-492d-8ac9-02fcc757c125 to disappear
Aug 12 16:48:18.593: INFO: Pod pod-secrets-6ce88374-b736-492d-8ac9-02fcc757c125 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:48:18.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5029" for this suite.
Aug 12 16:48:24.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:48:24.765: INFO: namespace secrets-5029 deletion completed in 6.167260998s
STEP: Destroying namespace "secret-namespace-665" for this suite.
Aug 12 16:48:30.784: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:48:30.905: INFO: namespace secret-namespace-665 deletion completed in 6.138935273s

 [SLOW TEST:16.542 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:48:30.909: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod test-webserver-949b596c-d26b-4b07-b862-a23ee8e93262 in namespace container-probe-7863
Aug 12 16:48:35.096: INFO: Started pod test-webserver-949b596c-d26b-4b07-b862-a23ee8e93262 in namespace container-probe-7863
STEP: checking the pod's current state and verifying that restartCount is present
Aug 12 16:48:35.102: INFO: Initial restart count of pod test-webserver-949b596c-d26b-4b07-b862-a23ee8e93262 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:52:36.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7863" for this suite.
Aug 12 16:52:42.032: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:52:42.169: INFO: namespace container-probe-7863 deletion completed in 6.157099305s

 [SLOW TEST:251.261 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:52:42.172: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating api versions
Aug 12 16:52:42.289: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 api-versions'
Aug 12 16:52:42.408: INFO: stderr: ""
Aug 12 16:52:42.408: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncilium.io/v2\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nsnapshot.storage.k8s.io/v1alpha1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:52:42.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2294" for this suite.
Aug 12 16:52:48.439: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:52:48.610: INFO: namespace kubectl-2294 deletion completed in 6.192168761s

 [SLOW TEST:6.438 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:52:48.610: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6900.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-6900.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6900.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-6900.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 12 16:52:52.846: INFO: DNS probes using dns-test-afe06d71-d6fb-42fe-a96b-e30fa1bc25e4 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6900.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-6900.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6900.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-6900.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 12 16:52:56.952: INFO: File wheezy_udp@dns-test-service-3.dns-6900.svc.cluster.local from pod  dns-6900/dns-test-9918a36f-9b98-46b7-a452-bdcce66887af contains 'foo.example.com.
' instead of 'bar.example.com.'
Aug 12 16:52:56.958: INFO: File jessie_udp@dns-test-service-3.dns-6900.svc.cluster.local from pod  dns-6900/dns-test-9918a36f-9b98-46b7-a452-bdcce66887af contains 'foo.example.com.
' instead of 'bar.example.com.'
Aug 12 16:52:56.958: INFO: Lookups using dns-6900/dns-test-9918a36f-9b98-46b7-a452-bdcce66887af failed for: [wheezy_udp@dns-test-service-3.dns-6900.svc.cluster.local jessie_udp@dns-test-service-3.dns-6900.svc.cluster.local]

Aug 12 16:53:01.975: INFO: DNS probes using dns-test-9918a36f-9b98-46b7-a452-bdcce66887af succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6900.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-6900.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6900.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-6900.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 12 16:53:06.196: INFO: DNS probes using dns-test-30201f41-b1ac-44fc-99a7-7ed226d0a527 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:53:06.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6900" for this suite.
Aug 12 16:53:12.306: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:53:12.489: INFO: namespace dns-6900 deletion completed in 6.215338315s

 [SLOW TEST:23.879 seconds]
[sig-network] DNS
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:53:12.492: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-d90416d9-fcde-45c6-a2d8-42decf69c8c6
STEP: Creating configMap with name cm-test-opt-upd-3769562f-3abe-4345-9282-0757a88c64ff
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-d90416d9-fcde-45c6-a2d8-42decf69c8c6
STEP: Updating configmap cm-test-opt-upd-3769562f-3abe-4345-9282-0757a88c64ff
STEP: Creating configMap with name cm-test-opt-create-fe9cbe61-8b0b-456a-935d-c7ba48d1183f
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:54:29.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2971" for this suite.
Aug 12 16:54:51.674: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:54:51.834: INFO: namespace configmap-2971 deletion completed in 22.173053031s

 [SLOW TEST:99.343 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:54:51.845: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-cc19cffe-3fd7-4804-a25b-b980ff889493
STEP: Creating a pod to test consume configMaps
Aug 12 16:54:51.943: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-eb18ef6e-8011-4575-85df-5e084568c967" in namespace "projected-9726" to be "success or failure"
Aug 12 16:54:51.958: INFO: Pod "pod-projected-configmaps-eb18ef6e-8011-4575-85df-5e084568c967": Phase="Pending", Reason="", readiness=false. Elapsed: 14.472777ms
Aug 12 16:54:53.963: INFO: Pod "pod-projected-configmaps-eb18ef6e-8011-4575-85df-5e084568c967": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019103025s
Aug 12 16:54:55.969: INFO: Pod "pod-projected-configmaps-eb18ef6e-8011-4575-85df-5e084568c967": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025043173s
STEP: Saw pod success
Aug 12 16:54:55.969: INFO: Pod "pod-projected-configmaps-eb18ef6e-8011-4575-85df-5e084568c967" satisfied condition "success or failure"
Aug 12 16:54:55.976: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxfp pod pod-projected-configmaps-eb18ef6e-8011-4575-85df-5e084568c967 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 12 16:54:55.998: INFO: Waiting for pod pod-projected-configmaps-eb18ef6e-8011-4575-85df-5e084568c967 to disappear
Aug 12 16:54:56.003: INFO: Pod pod-projected-configmaps-eb18ef6e-8011-4575-85df-5e084568c967 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:54:56.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9726" for this suite.
Aug 12 16:55:02.018: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:55:02.132: INFO: namespace projected-9726 deletion completed in 6.125524529s

 [SLOW TEST:10.288 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:55:02.137: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-7c7e4779-5885-49dd-ba20-ec1f5c672504
STEP: Creating a pod to test consume secrets
Aug 12 16:55:02.198: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-dd8f8c51-88a8-4db7-8798-87d00ae24329" in namespace "projected-9945" to be "success or failure"
Aug 12 16:55:02.203: INFO: Pod "pod-projected-secrets-dd8f8c51-88a8-4db7-8798-87d00ae24329": Phase="Pending", Reason="", readiness=false. Elapsed: 5.064151ms
Aug 12 16:55:04.208: INFO: Pod "pod-projected-secrets-dd8f8c51-88a8-4db7-8798-87d00ae24329": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009971414s
Aug 12 16:55:06.213: INFO: Pod "pod-projected-secrets-dd8f8c51-88a8-4db7-8798-87d00ae24329": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014739326s
STEP: Saw pod success
Aug 12 16:55:06.213: INFO: Pod "pod-projected-secrets-dd8f8c51-88a8-4db7-8798-87d00ae24329" satisfied condition "success or failure"
Aug 12 16:55:06.217: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxf2 pod pod-projected-secrets-dd8f8c51-88a8-4db7-8798-87d00ae24329 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 12 16:55:06.245: INFO: Waiting for pod pod-projected-secrets-dd8f8c51-88a8-4db7-8798-87d00ae24329 to disappear
Aug 12 16:55:06.251: INFO: Pod pod-projected-secrets-dd8f8c51-88a8-4db7-8798-87d00ae24329 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:55:06.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9945" for this suite.
Aug 12 16:55:12.281: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:55:12.473: INFO: namespace projected-9945 deletion completed in 6.217604577s

 [SLOW TEST:10.336 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:55:12.478: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Aug 12 16:55:12.521: INFO: Waiting up to 5m0s for pod "downward-api-a9c1a88d-7efb-4602-9b72-305388ef69a4" in namespace "downward-api-1137" to be "success or failure"
Aug 12 16:55:12.531: INFO: Pod "downward-api-a9c1a88d-7efb-4602-9b72-305388ef69a4": Phase="Pending", Reason="", readiness=false. Elapsed: 9.60259ms
Aug 12 16:55:14.536: INFO: Pod "downward-api-a9c1a88d-7efb-4602-9b72-305388ef69a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015055208s
Aug 12 16:55:16.540: INFO: Pod "downward-api-a9c1a88d-7efb-4602-9b72-305388ef69a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019018174s
STEP: Saw pod success
Aug 12 16:55:16.540: INFO: Pod "downward-api-a9c1a88d-7efb-4602-9b72-305388ef69a4" satisfied condition "success or failure"
Aug 12 16:55:16.543: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxfs pod downward-api-a9c1a88d-7efb-4602-9b72-305388ef69a4 container dapi-container: <nil>
STEP: delete the pod
Aug 12 16:55:16.577: INFO: Waiting for pod downward-api-a9c1a88d-7efb-4602-9b72-305388ef69a4 to disappear
Aug 12 16:55:16.583: INFO: Pod downward-api-a9c1a88d-7efb-4602-9b72-305388ef69a4 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:55:16.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1137" for this suite.
Aug 12 16:55:22.610: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:55:22.764: INFO: namespace downward-api-1137 deletion completed in 6.174555841s

 [SLOW TEST:10.287 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:55:22.769: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Aug 12 16:55:22.874: INFO: Waiting up to 5m0s for pod "pod-1721bf53-4fd8-42f0-b199-af10344d5dbe" in namespace "emptydir-161" to be "success or failure"
Aug 12 16:55:22.885: INFO: Pod "pod-1721bf53-4fd8-42f0-b199-af10344d5dbe": Phase="Pending", Reason="", readiness=false. Elapsed: 10.188144ms
Aug 12 16:55:24.923: INFO: Pod "pod-1721bf53-4fd8-42f0-b199-af10344d5dbe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.048614961s
Aug 12 16:55:26.928: INFO: Pod "pod-1721bf53-4fd8-42f0-b199-af10344d5dbe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.05337459s
STEP: Saw pod success
Aug 12 16:55:26.928: INFO: Pod "pod-1721bf53-4fd8-42f0-b199-af10344d5dbe" satisfied condition "success or failure"
Aug 12 16:55:26.936: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxfp pod pod-1721bf53-4fd8-42f0-b199-af10344d5dbe container test-container: <nil>
STEP: delete the pod
Aug 12 16:55:26.968: INFO: Waiting for pod pod-1721bf53-4fd8-42f0-b199-af10344d5dbe to disappear
Aug 12 16:55:26.972: INFO: Pod pod-1721bf53-4fd8-42f0-b199-af10344d5dbe no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:55:26.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-161" for this suite.
Aug 12 16:55:33.060: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:55:33.564: INFO: namespace emptydir-161 deletion completed in 6.588012777s

 [SLOW TEST:10.796 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:55:33.567: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-5f8ec1e4-10d0-459c-b4f7-027715e50ffd
STEP: Creating a pod to test consume configMaps
Aug 12 16:55:33.691: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-037740e9-f79d-4c90-9315-648a7a5e60b9" in namespace "projected-5752" to be "success or failure"
Aug 12 16:55:33.701: INFO: Pod "pod-projected-configmaps-037740e9-f79d-4c90-9315-648a7a5e60b9": Phase="Pending", Reason="", readiness=false. Elapsed: 9.696471ms
Aug 12 16:55:35.709: INFO: Pod "pod-projected-configmaps-037740e9-f79d-4c90-9315-648a7a5e60b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017425093s
STEP: Saw pod success
Aug 12 16:55:35.709: INFO: Pod "pod-projected-configmaps-037740e9-f79d-4c90-9315-648a7a5e60b9" satisfied condition "success or failure"
Aug 12 16:55:35.714: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxf2 pod pod-projected-configmaps-037740e9-f79d-4c90-9315-648a7a5e60b9 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 12 16:55:35.752: INFO: Waiting for pod pod-projected-configmaps-037740e9-f79d-4c90-9315-648a7a5e60b9 to disappear
Aug 12 16:55:35.755: INFO: Pod pod-projected-configmaps-037740e9-f79d-4c90-9315-648a7a5e60b9 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:55:35.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5752" for this suite.
Aug 12 16:55:41.793: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:55:41.935: INFO: namespace projected-5752 deletion completed in 6.165732301s

 [SLOW TEST:8.369 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:55:41.940: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:55:44.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-7040" for this suite.
Aug 12 16:55:50.106: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:55:50.255: INFO: namespace emptydir-wrapper-7040 deletion completed in 6.172001504s

 [SLOW TEST:8.315 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:55:50.265: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-6367
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Aug 12 16:55:50.471: INFO: Found 1 stateful pods, waiting for 3
Aug 12 16:56:00.480: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 12 16:56:00.480: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 12 16:56:00.480: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Aug 12 16:56:10.507: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 12 16:56:10.507: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 12 16:56:10.507: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Aug 12 16:56:10.538: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Aug 12 16:56:10.584: INFO: Updating stateful set ss2
Aug 12 16:56:10.603: INFO: Waiting for Pod statefulset-6367/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Aug 12 16:56:20.617: INFO: Waiting for Pod statefulset-6367/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Restoring Pods to the correct revision when they are deleted
Aug 12 16:56:30.882: INFO: Found 2 stateful pods, waiting for 3
Aug 12 16:56:40.890: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 12 16:56:40.890: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 12 16:56:40.891: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Aug 12 16:56:40.929: INFO: Updating stateful set ss2
Aug 12 16:56:40.976: INFO: Waiting for Pod statefulset-6367/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Aug 12 16:56:51.031: INFO: Updating stateful set ss2
Aug 12 16:56:51.114: INFO: Waiting for StatefulSet statefulset-6367/ss2 to complete update
Aug 12 16:56:51.115: INFO: Waiting for Pod statefulset-6367/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Aug 12 16:57:01.124: INFO: Deleting all statefulset in ns statefulset-6367
Aug 12 16:57:01.127: INFO: Scaling statefulset ss2 to 0
Aug 12 16:57:31.146: INFO: Waiting for statefulset status.replicas updated to 0
Aug 12 16:57:31.153: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:57:31.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6367" for this suite.
Aug 12 16:57:37.196: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:57:37.354: INFO: namespace statefulset-6367 deletion completed in 6.17806834s

 [SLOW TEST:107.089 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:57:37.361: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Aug 12 16:57:37.412: INFO: Waiting up to 5m0s for pod "pod-883f72c7-df66-4e90-99cd-3f026cccb396" in namespace "emptydir-5100" to be "success or failure"
Aug 12 16:57:37.422: INFO: Pod "pod-883f72c7-df66-4e90-99cd-3f026cccb396": Phase="Pending", Reason="", readiness=false. Elapsed: 10.081338ms
Aug 12 16:57:39.428: INFO: Pod "pod-883f72c7-df66-4e90-99cd-3f026cccb396": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015257092s
Aug 12 16:57:41.434: INFO: Pod "pod-883f72c7-df66-4e90-99cd-3f026cccb396": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021573319s
STEP: Saw pod success
Aug 12 16:57:41.434: INFO: Pod "pod-883f72c7-df66-4e90-99cd-3f026cccb396" satisfied condition "success or failure"
Aug 12 16:57:41.438: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxfs pod pod-883f72c7-df66-4e90-99cd-3f026cccb396 container test-container: <nil>
STEP: delete the pod
Aug 12 16:57:41.473: INFO: Waiting for pod pod-883f72c7-df66-4e90-99cd-3f026cccb396 to disappear
Aug 12 16:57:41.477: INFO: Pod pod-883f72c7-df66-4e90-99cd-3f026cccb396 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:57:41.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5100" for this suite.
Aug 12 16:57:47.500: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:57:47.641: INFO: namespace emptydir-5100 deletion completed in 6.158054732s

 [SLOW TEST:10.280 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:57:47.644: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Aug 12 16:57:51.484: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:57:51.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1550" for this suite.
Aug 12 16:57:57.523: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:57:57.687: INFO: namespace container-runtime-1550 deletion completed in 6.177611933s

 [SLOW TEST:10.043 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:57:57.699: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Aug 12 16:57:57.841: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-3605,SelfLink:/api/v1/namespaces/watch-3605/configmaps/e2e-watch-test-watch-closed,UID:33b429be-7354-4a6e-a289-3f42f88265d6,ResourceVersion:48342,Generation:0,CreationTimestamp:2019-08-12 16:57:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 12 16:57:57.841: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-3605,SelfLink:/api/v1/namespaces/watch-3605/configmaps/e2e-watch-test-watch-closed,UID:33b429be-7354-4a6e-a289-3f42f88265d6,ResourceVersion:48343,Generation:0,CreationTimestamp:2019-08-12 16:57:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Aug 12 16:57:57.858: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-3605,SelfLink:/api/v1/namespaces/watch-3605/configmaps/e2e-watch-test-watch-closed,UID:33b429be-7354-4a6e-a289-3f42f88265d6,ResourceVersion:48344,Generation:0,CreationTimestamp:2019-08-12 16:57:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 12 16:57:57.858: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-3605,SelfLink:/api/v1/namespaces/watch-3605/configmaps/e2e-watch-test-watch-closed,UID:33b429be-7354-4a6e-a289-3f42f88265d6,ResourceVersion:48345,Generation:0,CreationTimestamp:2019-08-12 16:57:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:57:57.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3605" for this suite.
Aug 12 16:58:03.886: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:58:04.042: INFO: namespace watch-3605 deletion completed in 6.173072511s

 [SLOW TEST:6.345 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:58:04.052: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Aug 12 16:58:04.102: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-6427,SelfLink:/api/v1/namespaces/watch-6427/configmaps/e2e-watch-test-configmap-a,UID:a3581545-7054-455d-b27e-071361b22ada,ResourceVersion:48362,Generation:0,CreationTimestamp:2019-08-12 16:58:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 12 16:58:04.102: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-6427,SelfLink:/api/v1/namespaces/watch-6427/configmaps/e2e-watch-test-configmap-a,UID:a3581545-7054-455d-b27e-071361b22ada,ResourceVersion:48362,Generation:0,CreationTimestamp:2019-08-12 16:58:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Aug 12 16:58:14.128: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-6427,SelfLink:/api/v1/namespaces/watch-6427/configmaps/e2e-watch-test-configmap-a,UID:a3581545-7054-455d-b27e-071361b22ada,ResourceVersion:48378,Generation:0,CreationTimestamp:2019-08-12 16:58:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Aug 12 16:58:14.128: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-6427,SelfLink:/api/v1/namespaces/watch-6427/configmaps/e2e-watch-test-configmap-a,UID:a3581545-7054-455d-b27e-071361b22ada,ResourceVersion:48378,Generation:0,CreationTimestamp:2019-08-12 16:58:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Aug 12 16:58:24.139: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-6427,SelfLink:/api/v1/namespaces/watch-6427/configmaps/e2e-watch-test-configmap-a,UID:a3581545-7054-455d-b27e-071361b22ada,ResourceVersion:48400,Generation:0,CreationTimestamp:2019-08-12 16:58:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 12 16:58:24.140: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-6427,SelfLink:/api/v1/namespaces/watch-6427/configmaps/e2e-watch-test-configmap-a,UID:a3581545-7054-455d-b27e-071361b22ada,ResourceVersion:48400,Generation:0,CreationTimestamp:2019-08-12 16:58:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Aug 12 16:58:34.155: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-6427,SelfLink:/api/v1/namespaces/watch-6427/configmaps/e2e-watch-test-configmap-a,UID:a3581545-7054-455d-b27e-071361b22ada,ResourceVersion:48421,Generation:0,CreationTimestamp:2019-08-12 16:58:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 12 16:58:34.155: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-6427,SelfLink:/api/v1/namespaces/watch-6427/configmaps/e2e-watch-test-configmap-a,UID:a3581545-7054-455d-b27e-071361b22ada,ResourceVersion:48421,Generation:0,CreationTimestamp:2019-08-12 16:58:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Aug 12 16:58:44.171: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-6427,SelfLink:/api/v1/namespaces/watch-6427/configmaps/e2e-watch-test-configmap-b,UID:43095648-9f81-4662-a8c3-4de5cef9fdbd,ResourceVersion:48437,Generation:0,CreationTimestamp:2019-08-12 16:58:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 12 16:58:44.171: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-6427,SelfLink:/api/v1/namespaces/watch-6427/configmaps/e2e-watch-test-configmap-b,UID:43095648-9f81-4662-a8c3-4de5cef9fdbd,ResourceVersion:48437,Generation:0,CreationTimestamp:2019-08-12 16:58:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Aug 12 16:58:54.180: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-6427,SelfLink:/api/v1/namespaces/watch-6427/configmaps/e2e-watch-test-configmap-b,UID:43095648-9f81-4662-a8c3-4de5cef9fdbd,ResourceVersion:48452,Generation:0,CreationTimestamp:2019-08-12 16:58:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 12 16:58:54.180: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-6427,SelfLink:/api/v1/namespaces/watch-6427/configmaps/e2e-watch-test-configmap-b,UID:43095648-9f81-4662-a8c3-4de5cef9fdbd,ResourceVersion:48452,Generation:0,CreationTimestamp:2019-08-12 16:58:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:59:04.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6427" for this suite.
Aug 12 16:59:10.211: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:59:10.364: INFO: namespace watch-6427 deletion completed in 6.173144346s

 [SLOW TEST:66.312 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:59:10.365: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1421
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 12 16:59:10.407: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-9199'
Aug 12 16:59:11.174: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 12 16:59:11.174: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1427
Aug 12 16:59:13.192: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 delete deployment e2e-test-nginx-deployment --namespace=kubectl-9199'
Aug 12 16:59:13.314: INFO: stderr: ""
Aug 12 16:59:13.314: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 16:59:13.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9199" for this suite.
Aug 12 16:59:19.332: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 16:59:19.461: INFO: namespace kubectl-9199 deletion completed in 6.142965972s

 [SLOW TEST:9.097 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 16:59:19.476: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-2eaedfe7-1b41-4f6c-985d-e470fa13079a
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-2eaedfe7-1b41-4f6c-985d-e470fa13079a
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:00:26.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8083" for this suite.
Aug 12 17:00:48.337: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:00:48.504: INFO: namespace configmap-8083 deletion completed in 22.18525098s

 [SLOW TEST:89.028 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:00:48.505: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1558
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 12 17:00:48.538: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/apps.v1 --namespace=kubectl-110'
Aug 12 17:00:48.837: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 12 17:00:48.837: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
Aug 12 17:00:50.865: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 delete deployment e2e-test-nginx-deployment --namespace=kubectl-110'
Aug 12 17:00:50.983: INFO: stderr: ""
Aug 12 17:00:50.983: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:00:50.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-110" for this suite.
Aug 12 17:02:53.002: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:02:53.154: INFO: namespace kubectl-110 deletion completed in 2m2.166871787s

 [SLOW TEST:124.649 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:02:53.159: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:02:58.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9690" for this suite.
Aug 12 17:03:20.422: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:03:20.582: INFO: namespace replication-controller-9690 deletion completed in 22.205569793s

 [SLOW TEST:27.423 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:03:20.589: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on tmpfs
Aug 12 17:03:20.683: INFO: Waiting up to 5m0s for pod "pod-536f6c4f-e180-4dac-ad07-afa943882c56" in namespace "emptydir-3945" to be "success or failure"
Aug 12 17:03:20.696: INFO: Pod "pod-536f6c4f-e180-4dac-ad07-afa943882c56": Phase="Pending", Reason="", readiness=false. Elapsed: 11.955531ms
Aug 12 17:03:22.706: INFO: Pod "pod-536f6c4f-e180-4dac-ad07-afa943882c56": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021832384s
Aug 12 17:03:24.720: INFO: Pod "pod-536f6c4f-e180-4dac-ad07-afa943882c56": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036046183s
STEP: Saw pod success
Aug 12 17:03:24.720: INFO: Pod "pod-536f6c4f-e180-4dac-ad07-afa943882c56" satisfied condition "success or failure"
Aug 12 17:03:24.726: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxfs pod pod-536f6c4f-e180-4dac-ad07-afa943882c56 container test-container: <nil>
STEP: delete the pod
Aug 12 17:03:24.783: INFO: Waiting for pod pod-536f6c4f-e180-4dac-ad07-afa943882c56 to disappear
Aug 12 17:03:24.790: INFO: Pod pod-536f6c4f-e180-4dac-ad07-afa943882c56 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:03:24.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3945" for this suite.
Aug 12 17:03:30.828: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:03:30.961: INFO: namespace emptydir-3945 deletion completed in 6.157342844s

 [SLOW TEST:10.372 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:03:30.965: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Aug 12 17:03:31.078: INFO: Waiting up to 5m0s for pod "pod-b5c8e39d-aa0e-4f87-9ff2-70331f50df6e" in namespace "emptydir-9344" to be "success or failure"
Aug 12 17:03:31.091: INFO: Pod "pod-b5c8e39d-aa0e-4f87-9ff2-70331f50df6e": Phase="Pending", Reason="", readiness=false. Elapsed: 12.936491ms
Aug 12 17:03:33.097: INFO: Pod "pod-b5c8e39d-aa0e-4f87-9ff2-70331f50df6e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019084681s
Aug 12 17:03:35.108: INFO: Pod "pod-b5c8e39d-aa0e-4f87-9ff2-70331f50df6e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029370612s
STEP: Saw pod success
Aug 12 17:03:35.108: INFO: Pod "pod-b5c8e39d-aa0e-4f87-9ff2-70331f50df6e" satisfied condition "success or failure"
Aug 12 17:03:35.113: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxfp pod pod-b5c8e39d-aa0e-4f87-9ff2-70331f50df6e container test-container: <nil>
STEP: delete the pod
Aug 12 17:03:35.144: INFO: Waiting for pod pod-b5c8e39d-aa0e-4f87-9ff2-70331f50df6e to disappear
Aug 12 17:03:35.147: INFO: Pod pod-b5c8e39d-aa0e-4f87-9ff2-70331f50df6e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:03:35.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9344" for this suite.
Aug 12 17:03:41.164: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:03:41.312: INFO: namespace emptydir-9344 deletion completed in 6.160260817s

 [SLOW TEST:10.347 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:03:41.319: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-downwardapi-cr68
STEP: Creating a pod to test atomic-volume-subpath
Aug 12 17:03:41.438: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-cr68" in namespace "subpath-7689" to be "success or failure"
Aug 12 17:03:41.448: INFO: Pod "pod-subpath-test-downwardapi-cr68": Phase="Pending", Reason="", readiness=false. Elapsed: 9.836236ms
Aug 12 17:03:43.452: INFO: Pod "pod-subpath-test-downwardapi-cr68": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014084669s
Aug 12 17:03:45.460: INFO: Pod "pod-subpath-test-downwardapi-cr68": Phase="Pending", Reason="", readiness=false. Elapsed: 4.022217021s
Aug 12 17:03:47.466: INFO: Pod "pod-subpath-test-downwardapi-cr68": Phase="Running", Reason="", readiness=true. Elapsed: 6.028141997s
Aug 12 17:03:49.471: INFO: Pod "pod-subpath-test-downwardapi-cr68": Phase="Running", Reason="", readiness=true. Elapsed: 8.033048191s
Aug 12 17:03:51.475: INFO: Pod "pod-subpath-test-downwardapi-cr68": Phase="Running", Reason="", readiness=true. Elapsed: 10.037306658s
Aug 12 17:03:53.484: INFO: Pod "pod-subpath-test-downwardapi-cr68": Phase="Running", Reason="", readiness=true. Elapsed: 12.045456376s
Aug 12 17:03:55.488: INFO: Pod "pod-subpath-test-downwardapi-cr68": Phase="Running", Reason="", readiness=true. Elapsed: 14.049525926s
Aug 12 17:03:57.493: INFO: Pod "pod-subpath-test-downwardapi-cr68": Phase="Running", Reason="", readiness=true. Elapsed: 16.054988599s
Aug 12 17:03:59.499: INFO: Pod "pod-subpath-test-downwardapi-cr68": Phase="Running", Reason="", readiness=true. Elapsed: 18.060741271s
Aug 12 17:04:01.504: INFO: Pod "pod-subpath-test-downwardapi-cr68": Phase="Running", Reason="", readiness=true. Elapsed: 20.06549653s
Aug 12 17:04:03.509: INFO: Pod "pod-subpath-test-downwardapi-cr68": Phase="Running", Reason="", readiness=true. Elapsed: 22.071313873s
Aug 12 17:04:05.515: INFO: Pod "pod-subpath-test-downwardapi-cr68": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.077358898s
STEP: Saw pod success
Aug 12 17:04:05.516: INFO: Pod "pod-subpath-test-downwardapi-cr68" satisfied condition "success or failure"
Aug 12 17:04:05.522: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxf2 pod pod-subpath-test-downwardapi-cr68 container test-container-subpath-downwardapi-cr68: <nil>
STEP: delete the pod
Aug 12 17:04:05.558: INFO: Waiting for pod pod-subpath-test-downwardapi-cr68 to disappear
Aug 12 17:04:05.563: INFO: Pod pod-subpath-test-downwardapi-cr68 no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-cr68
Aug 12 17:04:05.564: INFO: Deleting pod "pod-subpath-test-downwardapi-cr68" in namespace "subpath-7689"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:04:05.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7689" for this suite.
Aug 12 17:04:11.596: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:04:11.775: INFO: namespace subpath-7689 deletion completed in 6.199286544s

 [SLOW TEST:30.456 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:04:11.780: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Aug 12 17:04:11.900: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug 12 17:04:11.912: INFO: Waiting for terminating namespaces to be deleted...
Aug 12 17:04:11.918: INFO: 
Logging pods the kubelet thinks is on node conformance-1-15-2-do-0-default-pool-rxf2 before test
Aug 12 17:04:11.929: INFO: do-node-agent-jsj6x from kube-system started at 2019-08-12 13:17:54 +0000 UTC (1 container statuses recorded)
Aug 12 17:04:11.930: INFO: 	Container do-node-agent ready: true, restart count 0
Aug 12 17:04:11.930: INFO: sonobuoy from heptio-sonobuoy started at 2019-08-12 16:09:30 +0000 UTC (1 container statuses recorded)
Aug 12 17:04:11.930: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug 12 17:04:11.930: INFO: sonobuoy-systemd-logs-daemon-set-a0296875de8f4bfa-l5d86 from heptio-sonobuoy started at 2019-08-12 16:09:33 +0000 UTC (2 container statuses recorded)
Aug 12 17:04:11.930: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 12 17:04:11.930: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 12 17:04:11.931: INFO: cilium-n97lp from kube-system started at 2019-08-12 13:17:34 +0000 UTC (1 container statuses recorded)
Aug 12 17:04:11.931: INFO: 	Container cilium-agent ready: true, restart count 1
Aug 12 17:04:11.931: INFO: csi-do-node-8hbn9 from kube-system started at 2019-08-12 13:17:34 +0000 UTC (2 container statuses recorded)
Aug 12 17:04:11.931: INFO: 	Container csi-do-plugin ready: true, restart count 0
Aug 12 17:04:11.931: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Aug 12 17:04:11.931: INFO: kube-proxy-bxfsv from kube-system started at 2019-08-12 13:17:34 +0000 UTC (1 container statuses recorded)
Aug 12 17:04:11.931: INFO: 	Container kube-proxy ready: true, restart count 0
Aug 12 17:04:11.932: INFO: 
Logging pods the kubelet thinks is on node conformance-1-15-2-do-0-default-pool-rxfp before test
Aug 12 17:04:11.950: INFO: kube-proxy-dkvd4 from kube-system started at 2019-08-12 13:17:27 +0000 UTC (1 container statuses recorded)
Aug 12 17:04:11.950: INFO: 	Container kube-proxy ready: true, restart count 0
Aug 12 17:04:11.950: INFO: cilium-6xm9z from kube-system started at 2019-08-12 13:17:27 +0000 UTC (1 container statuses recorded)
Aug 12 17:04:11.950: INFO: 	Container cilium-agent ready: true, restart count 1
Aug 12 17:04:11.950: INFO: csi-do-node-xqsbs from kube-system started at 2019-08-12 13:17:27 +0000 UTC (2 container statuses recorded)
Aug 12 17:04:11.951: INFO: 	Container csi-do-plugin ready: true, restart count 0
Aug 12 17:04:11.951: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Aug 12 17:04:11.951: INFO: sonobuoy-systemd-logs-daemon-set-a0296875de8f4bfa-wmb87 from heptio-sonobuoy started at 2019-08-12 16:09:33 +0000 UTC (2 container statuses recorded)
Aug 12 17:04:11.951: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 12 17:04:11.951: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 12 17:04:11.952: INFO: do-node-agent-f9wvg from kube-system started at 2019-08-12 13:17:47 +0000 UTC (1 container statuses recorded)
Aug 12 17:04:11.952: INFO: 	Container do-node-agent ready: true, restart count 0
Aug 12 17:04:11.952: INFO: sonobuoy-e2e-job-e176e22cbea8475f from heptio-sonobuoy started at 2019-08-12 16:09:32 +0000 UTC (2 container statuses recorded)
Aug 12 17:04:11.952: INFO: 	Container e2e ready: true, restart count 0
Aug 12 17:04:11.952: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 12 17:04:11.953: INFO: 
Logging pods the kubelet thinks is on node conformance-1-15-2-do-0-default-pool-rxfs before test
Aug 12 17:04:11.968: INFO: coredns-9d6bf9876-s2nng from kube-system started at 2019-08-12 13:16:58 +0000 UTC (1 container statuses recorded)
Aug 12 17:04:11.968: INFO: 	Container coredns ready: true, restart count 0
Aug 12 17:04:11.968: INFO: sonobuoy-systemd-logs-daemon-set-a0296875de8f4bfa-qlrgc from heptio-sonobuoy started at 2019-08-12 16:09:33 +0000 UTC (2 container statuses recorded)
Aug 12 17:04:11.968: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 12 17:04:11.968: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 12 17:04:11.968: INFO: kube-proxy-xbm78 from kube-system started at 2019-08-12 13:16:30 +0000 UTC (1 container statuses recorded)
Aug 12 17:04:11.969: INFO: 	Container kube-proxy ready: true, restart count 0
Aug 12 17:04:11.969: INFO: do-node-agent-qvjgl from kube-system started at 2019-08-12 13:16:50 +0000 UTC (1 container statuses recorded)
Aug 12 17:04:11.969: INFO: 	Container do-node-agent ready: true, restart count 0
Aug 12 17:04:11.969: INFO: cilium-76ggb from kube-system started at 2019-08-12 13:16:30 +0000 UTC (1 container statuses recorded)
Aug 12 17:04:11.969: INFO: 	Container cilium-agent ready: true, restart count 1
Aug 12 17:04:11.969: INFO: csi-do-node-hk2h2 from kube-system started at 2019-08-12 13:16:30 +0000 UTC (2 container statuses recorded)
Aug 12 17:04:11.969: INFO: 	Container csi-do-plugin ready: true, restart count 0
Aug 12 17:04:11.969: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Aug 12 17:04:11.970: INFO: coredns-9d6bf9876-p8wkw from kube-system started at 2019-08-12 13:16:50 +0000 UTC (1 container statuses recorded)
Aug 12 17:04:11.970: INFO: 	Container coredns ready: true, restart count 1
Aug 12 17:04:11.970: INFO: cilium-operator-57586bb7cb-phl6l from kube-system started at 2019-08-12 13:16:58 +0000 UTC (1 container statuses recorded)
Aug 12 17:04:11.970: INFO: 	Container cilium-operator ready: true, restart count 18
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15ba3bb10874804d], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:04:13.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7834" for this suite.
Aug 12 17:04:19.046: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:04:19.207: INFO: namespace sched-pred-7834 deletion completed in 6.183931413s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

 [SLOW TEST:7.428 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:04:19.215: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 12 17:04:19.335: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Aug 12 17:04:24.342: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Aug 12 17:04:24.342: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Aug 12 17:04:28.396: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-2093,SelfLink:/apis/apps/v1/namespaces/deployment-2093/deployments/test-cleanup-deployment,UID:e0219077-a303-4540-8c2b-db667783d84d,ResourceVersion:49459,Generation:1,CreationTimestamp:2019-08-12 17:04:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 1,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-08-12 17:04:24 +0000 UTC 2019-08-12 17:04:24 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-08-12 17:04:27 +0000 UTC 2019-08-12 17:04:24 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-cleanup-deployment-55bbcbc84c" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Aug 12 17:04:28.400: INFO: New ReplicaSet "test-cleanup-deployment-55bbcbc84c" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55bbcbc84c,GenerateName:,Namespace:deployment-2093,SelfLink:/apis/apps/v1/namespaces/deployment-2093/replicasets/test-cleanup-deployment-55bbcbc84c,UID:1de99142-055e-4546-ab4d-c1a50b7bbbc9,ResourceVersion:49448,Generation:1,CreationTimestamp:2019-08-12 17:04:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment e0219077-a303-4540-8c2b-db667783d84d 0xc002824da7 0xc002824da8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Aug 12 17:04:28.407: INFO: Pod "test-cleanup-deployment-55bbcbc84c-v7xcd" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55bbcbc84c-v7xcd,GenerateName:test-cleanup-deployment-55bbcbc84c-,Namespace:deployment-2093,SelfLink:/api/v1/namespaces/deployment-2093/pods/test-cleanup-deployment-55bbcbc84c-v7xcd,UID:f05d1536-16ed-41f2-9af2-f5b8c4cb2de5,ResourceVersion:49447,Generation:0,CreationTimestamp:2019-08-12 17:04:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-55bbcbc84c 1de99142-055e-4546-ab4d-c1a50b7bbbc9 0xc0028253f7 0xc0028253f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-mz949 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mz949,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-mz949 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-1-15-2-do-0-default-pool-rxfp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002825460} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002825480}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:04:24 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:04:27 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:04:27 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:04:24 +0000 UTC  }],Message:,Reason:,HostIP:10.138.15.72,PodIP:10.244.1.185,StartTime:2019-08-12 17:04:24 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-08-12 17:04:26 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://3979da93a8383af77af0f7ab4c15032254721a0c2e1bf74b85bb07027a09ae37}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:04:28.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2093" for this suite.
Aug 12 17:04:34.435: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:04:34.565: INFO: namespace deployment-2093 deletion completed in 6.152350911s

 [SLOW TEST:15.351 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:04:34.573: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Aug 12 17:04:39.237: INFO: Successfully updated pod "annotationupdate3b1661b9-b12f-42c3-8a8d-7e37eba733a8"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:04:41.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7596" for this suite.
Aug 12 17:04:59.295: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:04:59.420: INFO: namespace projected-7596 deletion completed in 18.14068857s

 [SLOW TEST:24.848 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:04:59.422: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 12 17:04:59.529: INFO: (0) /api/v1/nodes/conformance-1-15-2-do-0-default-pool-rxf2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.522565ms)
Aug 12 17:04:59.534: INFO: (1) /api/v1/nodes/conformance-1-15-2-do-0-default-pool-rxf2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.981755ms)
Aug 12 17:04:59.540: INFO: (2) /api/v1/nodes/conformance-1-15-2-do-0-default-pool-rxf2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 6.163762ms)
Aug 12 17:04:59.554: INFO: (3) /api/v1/nodes/conformance-1-15-2-do-0-default-pool-rxf2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 12.944216ms)
Aug 12 17:04:59.562: INFO: (4) /api/v1/nodes/conformance-1-15-2-do-0-default-pool-rxf2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 7.535112ms)
Aug 12 17:04:59.570: INFO: (5) /api/v1/nodes/conformance-1-15-2-do-0-default-pool-rxf2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 7.259621ms)
Aug 12 17:04:59.576: INFO: (6) /api/v1/nodes/conformance-1-15-2-do-0-default-pool-rxf2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 5.899115ms)
Aug 12 17:04:59.582: INFO: (7) /api/v1/nodes/conformance-1-15-2-do-0-default-pool-rxf2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 5.351302ms)
Aug 12 17:04:59.604: INFO: (8) /api/v1/nodes/conformance-1-15-2-do-0-default-pool-rxf2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 21.977057ms)
Aug 12 17:04:59.610: INFO: (9) /api/v1/nodes/conformance-1-15-2-do-0-default-pool-rxf2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 6.032543ms)
Aug 12 17:04:59.620: INFO: (10) /api/v1/nodes/conformance-1-15-2-do-0-default-pool-rxf2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 9.630822ms)
Aug 12 17:04:59.635: INFO: (11) /api/v1/nodes/conformance-1-15-2-do-0-default-pool-rxf2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 14.374124ms)
Aug 12 17:04:59.642: INFO: (12) /api/v1/nodes/conformance-1-15-2-do-0-default-pool-rxf2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 7.043835ms)
Aug 12 17:04:59.663: INFO: (13) /api/v1/nodes/conformance-1-15-2-do-0-default-pool-rxf2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 20.253902ms)
Aug 12 17:04:59.671: INFO: (14) /api/v1/nodes/conformance-1-15-2-do-0-default-pool-rxf2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 7.109129ms)
Aug 12 17:04:59.677: INFO: (15) /api/v1/nodes/conformance-1-15-2-do-0-default-pool-rxf2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 5.457319ms)
Aug 12 17:04:59.684: INFO: (16) /api/v1/nodes/conformance-1-15-2-do-0-default-pool-rxf2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 6.672068ms)
Aug 12 17:04:59.689: INFO: (17) /api/v1/nodes/conformance-1-15-2-do-0-default-pool-rxf2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.579963ms)
Aug 12 17:04:59.694: INFO: (18) /api/v1/nodes/conformance-1-15-2-do-0-default-pool-rxf2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.393893ms)
Aug 12 17:04:59.704: INFO: (19) /api/v1/nodes/conformance-1-15-2-do-0-default-pool-rxf2:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 9.79489ms)
[AfterEach] version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:04:59.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-7603" for this suite.
Aug 12 17:05:05.746: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:05:05.905: INFO: namespace proxy-7603 deletion completed in 6.190377606s

 [SLOW TEST:6.484 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:05:05.911: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Aug 12 17:05:05.963: INFO: Waiting up to 5m0s for pod "pod-66258a89-fe3b-4d5e-be99-ebf65070e515" in namespace "emptydir-9213" to be "success or failure"
Aug 12 17:05:05.975: INFO: Pod "pod-66258a89-fe3b-4d5e-be99-ebf65070e515": Phase="Pending", Reason="", readiness=false. Elapsed: 11.230903ms
Aug 12 17:05:07.980: INFO: Pod "pod-66258a89-fe3b-4d5e-be99-ebf65070e515": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016242422s
Aug 12 17:05:09.987: INFO: Pod "pod-66258a89-fe3b-4d5e-be99-ebf65070e515": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022847041s
STEP: Saw pod success
Aug 12 17:05:09.988: INFO: Pod "pod-66258a89-fe3b-4d5e-be99-ebf65070e515" satisfied condition "success or failure"
Aug 12 17:05:09.993: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxfs pod pod-66258a89-fe3b-4d5e-be99-ebf65070e515 container test-container: <nil>
STEP: delete the pod
Aug 12 17:05:10.033: INFO: Waiting for pod pod-66258a89-fe3b-4d5e-be99-ebf65070e515 to disappear
Aug 12 17:05:10.040: INFO: Pod pod-66258a89-fe3b-4d5e-be99-ebf65070e515 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:05:10.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9213" for this suite.
Aug 12 17:05:16.062: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:05:16.207: INFO: namespace emptydir-9213 deletion completed in 6.160285305s

 [SLOW TEST:10.296 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:05:16.209: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Aug 12 17:05:24.393: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 12 17:05:24.398: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 12 17:05:26.399: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 12 17:05:26.404: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 12 17:05:28.399: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 12 17:05:28.404: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 12 17:05:30.399: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 12 17:05:30.407: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 12 17:05:32.399: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 12 17:05:32.406: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 12 17:05:34.399: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 12 17:05:34.407: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 12 17:05:36.399: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 12 17:05:36.402: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 12 17:05:38.399: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 12 17:05:38.404: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 12 17:05:40.453: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 12 17:05:40.522: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 12 17:05:42.399: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 12 17:05:42.408: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 12 17:05:44.399: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 12 17:05:44.404: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 12 17:05:46.399: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 12 17:05:46.404: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 12 17:05:48.399: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 12 17:05:48.523: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 12 17:05:50.399: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 12 17:05:50.403: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 12 17:05:52.399: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 12 17:05:52.403: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 12 17:05:54.399: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 12 17:05:54.470: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:05:54.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5237" for this suite.
Aug 12 17:06:16.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:06:17.008: INFO: namespace container-lifecycle-hook-5237 deletion completed in 22.264235548s

 [SLOW TEST:60.799 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:06:17.018: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Aug 12 17:06:17.122: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:06:21.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9807" for this suite.
Aug 12 17:06:27.615: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:06:27.803: INFO: namespace init-container-9807 deletion completed in 6.210564929s

 [SLOW TEST:10.786 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:06:27.806: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 12 17:06:27.924: INFO: Waiting up to 5m0s for pod "downwardapi-volume-21f35477-90de-491f-bc1f-850dcb7bee25" in namespace "downward-api-8722" to be "success or failure"
Aug 12 17:06:27.932: INFO: Pod "downwardapi-volume-21f35477-90de-491f-bc1f-850dcb7bee25": Phase="Pending", Reason="", readiness=false. Elapsed: 8.08614ms
Aug 12 17:06:29.941: INFO: Pod "downwardapi-volume-21f35477-90de-491f-bc1f-850dcb7bee25": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017116792s
Aug 12 17:06:31.948: INFO: Pod "downwardapi-volume-21f35477-90de-491f-bc1f-850dcb7bee25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02424273s
STEP: Saw pod success
Aug 12 17:06:31.949: INFO: Pod "downwardapi-volume-21f35477-90de-491f-bc1f-850dcb7bee25" satisfied condition "success or failure"
Aug 12 17:06:31.955: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxfp pod downwardapi-volume-21f35477-90de-491f-bc1f-850dcb7bee25 container client-container: <nil>
STEP: delete the pod
Aug 12 17:06:32.002: INFO: Waiting for pod downwardapi-volume-21f35477-90de-491f-bc1f-850dcb7bee25 to disappear
Aug 12 17:06:32.005: INFO: Pod downwardapi-volume-21f35477-90de-491f-bc1f-850dcb7bee25 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:06:32.005: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8722" for this suite.
Aug 12 17:06:38.022: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:06:38.183: INFO: namespace downward-api-8722 deletion completed in 6.174111095s

 [SLOW TEST:10.378 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:06:38.187: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 12 17:06:38.324: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7dc44b96-93a0-4d15-adf9-a90056b9eeb2" in namespace "downward-api-4561" to be "success or failure"
Aug 12 17:06:38.330: INFO: Pod "downwardapi-volume-7dc44b96-93a0-4d15-adf9-a90056b9eeb2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.286816ms
Aug 12 17:06:40.336: INFO: Pod "downwardapi-volume-7dc44b96-93a0-4d15-adf9-a90056b9eeb2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011468356s
Aug 12 17:06:42.345: INFO: Pod "downwardapi-volume-7dc44b96-93a0-4d15-adf9-a90056b9eeb2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02050921s
STEP: Saw pod success
Aug 12 17:06:42.345: INFO: Pod "downwardapi-volume-7dc44b96-93a0-4d15-adf9-a90056b9eeb2" satisfied condition "success or failure"
Aug 12 17:06:42.349: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxf2 pod downwardapi-volume-7dc44b96-93a0-4d15-adf9-a90056b9eeb2 container client-container: <nil>
STEP: delete the pod
Aug 12 17:06:42.378: INFO: Waiting for pod downwardapi-volume-7dc44b96-93a0-4d15-adf9-a90056b9eeb2 to disappear
Aug 12 17:06:42.382: INFO: Pod downwardapi-volume-7dc44b96-93a0-4d15-adf9-a90056b9eeb2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:06:42.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4561" for this suite.
Aug 12 17:06:48.410: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:06:48.553: INFO: namespace downward-api-4561 deletion completed in 6.165219946s

 [SLOW TEST:10.367 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:06:48.554: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Aug 12 17:06:56.849: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 12 17:06:56.855: INFO: Pod pod-with-poststart-http-hook still exists
Aug 12 17:06:58.855: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 12 17:06:58.863: INFO: Pod pod-with-poststart-http-hook still exists
Aug 12 17:07:00.855: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 12 17:07:00.860: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:07:00.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9576" for this suite.
Aug 12 17:07:22.889: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:07:23.041: INFO: namespace container-lifecycle-hook-9576 deletion completed in 22.167265597s

 [SLOW TEST:34.487 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:07:23.042: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 12 17:07:23.220: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"3424eb5f-7352-4440-a750-ec222f71ac94", Controller:(*bool)(0xc0023d7826), BlockOwnerDeletion:(*bool)(0xc0023d7827)}}
Aug 12 17:07:23.232: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"b373ab00-2892-4068-bffc-cf77a681fbc0", Controller:(*bool)(0xc0023d7b3e), BlockOwnerDeletion:(*bool)(0xc0023d7b3f)}}
Aug 12 17:07:23.243: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"ec6b5926-0409-41cc-b820-f0e822c2f566", Controller:(*bool)(0xc0023d7dde), BlockOwnerDeletion:(*bool)(0xc0023d7ddf)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:07:28.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3192" for this suite.
Aug 12 17:07:34.316: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:07:34.445: INFO: namespace gc-3192 deletion completed in 6.15600215s

 [SLOW TEST:11.403 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:07:34.449: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-a62bce5f-ecb9-4c8f-af6c-0db4b5f7ba85 in namespace container-probe-3427
Aug 12 17:07:38.523: INFO: Started pod busybox-a62bce5f-ecb9-4c8f-af6c-0db4b5f7ba85 in namespace container-probe-3427
STEP: checking the pod's current state and verifying that restartCount is present
Aug 12 17:07:38.530: INFO: Initial restart count of pod busybox-a62bce5f-ecb9-4c8f-af6c-0db4b5f7ba85 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:11:39.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3427" for this suite.
Aug 12 17:11:45.631: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:11:45.775: INFO: namespace container-probe-3427 deletion completed in 6.16368975s

 [SLOW TEST:251.327 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:11:45.788: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 12 17:11:45.903: INFO: Waiting up to 5m0s for pod "downwardapi-volume-84eafc7a-224f-4ba1-a977-5a3df29ad001" in namespace "projected-3762" to be "success or failure"
Aug 12 17:11:45.913: INFO: Pod "downwardapi-volume-84eafc7a-224f-4ba1-a977-5a3df29ad001": Phase="Pending", Reason="", readiness=false. Elapsed: 9.774463ms
Aug 12 17:11:47.920: INFO: Pod "downwardapi-volume-84eafc7a-224f-4ba1-a977-5a3df29ad001": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016371609s
Aug 12 17:11:49.927: INFO: Pod "downwardapi-volume-84eafc7a-224f-4ba1-a977-5a3df29ad001": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023648891s
STEP: Saw pod success
Aug 12 17:11:49.927: INFO: Pod "downwardapi-volume-84eafc7a-224f-4ba1-a977-5a3df29ad001" satisfied condition "success or failure"
Aug 12 17:11:49.932: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxf2 pod downwardapi-volume-84eafc7a-224f-4ba1-a977-5a3df29ad001 container client-container: <nil>
STEP: delete the pod
Aug 12 17:11:49.972: INFO: Waiting for pod downwardapi-volume-84eafc7a-224f-4ba1-a977-5a3df29ad001 to disappear
Aug 12 17:11:49.977: INFO: Pod downwardapi-volume-84eafc7a-224f-4ba1-a977-5a3df29ad001 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:11:49.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3762" for this suite.
Aug 12 17:11:55.995: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:11:56.136: INFO: namespace projected-3762 deletion completed in 6.155607743s

 [SLOW TEST:10.349 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:11:56.138: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-eebc5bdc-d3c3-40f0-87e5-54396d01cf0a
STEP: Creating a pod to test consume secrets
Aug 12 17:11:56.193: INFO: Waiting up to 5m0s for pod "pod-secrets-7fc63b07-e1ff-4146-a2f9-38f7f3e5e35c" in namespace "secrets-1983" to be "success or failure"
Aug 12 17:11:56.205: INFO: Pod "pod-secrets-7fc63b07-e1ff-4146-a2f9-38f7f3e5e35c": Phase="Pending", Reason="", readiness=false. Elapsed: 11.509319ms
Aug 12 17:11:58.221: INFO: Pod "pod-secrets-7fc63b07-e1ff-4146-a2f9-38f7f3e5e35c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026939988s
Aug 12 17:12:00.226: INFO: Pod "pod-secrets-7fc63b07-e1ff-4146-a2f9-38f7f3e5e35c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032034299s
STEP: Saw pod success
Aug 12 17:12:00.226: INFO: Pod "pod-secrets-7fc63b07-e1ff-4146-a2f9-38f7f3e5e35c" satisfied condition "success or failure"
Aug 12 17:12:00.234: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxfp pod pod-secrets-7fc63b07-e1ff-4146-a2f9-38f7f3e5e35c container secret-volume-test: <nil>
STEP: delete the pod
Aug 12 17:12:00.300: INFO: Waiting for pod pod-secrets-7fc63b07-e1ff-4146-a2f9-38f7f3e5e35c to disappear
Aug 12 17:12:00.525: INFO: Pod pod-secrets-7fc63b07-e1ff-4146-a2f9-38f7f3e5e35c no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:12:00.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1983" for this suite.
Aug 12 17:12:06.548: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:12:06.690: INFO: namespace secrets-1983 deletion completed in 6.157664983s

 [SLOW TEST:10.552 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:12:06.691: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 12 17:12:06.781: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Aug 12 17:12:06.804: INFO: Number of nodes with available pods: 0
Aug 12 17:12:06.805: INFO: Node conformance-1-15-2-do-0-default-pool-rxf2 is running more than one daemon pod
Aug 12 17:12:08.097: INFO: Number of nodes with available pods: 0
Aug 12 17:12:08.097: INFO: Node conformance-1-15-2-do-0-default-pool-rxf2 is running more than one daemon pod
Aug 12 17:12:08.819: INFO: Number of nodes with available pods: 0
Aug 12 17:12:08.820: INFO: Node conformance-1-15-2-do-0-default-pool-rxf2 is running more than one daemon pod
Aug 12 17:12:09.826: INFO: Number of nodes with available pods: 3
Aug 12 17:12:09.826: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Aug 12 17:12:09.878: INFO: Wrong image for pod: daemon-set-27jzn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 12 17:12:09.878: INFO: Wrong image for pod: daemon-set-cp9cn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 12 17:12:09.878: INFO: Wrong image for pod: daemon-set-dwdcl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 12 17:12:10.888: INFO: Wrong image for pod: daemon-set-27jzn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 12 17:12:10.888: INFO: Wrong image for pod: daemon-set-cp9cn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 12 17:12:10.888: INFO: Wrong image for pod: daemon-set-dwdcl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 12 17:12:11.890: INFO: Wrong image for pod: daemon-set-27jzn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 12 17:12:11.890: INFO: Wrong image for pod: daemon-set-cp9cn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 12 17:12:11.890: INFO: Wrong image for pod: daemon-set-dwdcl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 12 17:12:12.888: INFO: Wrong image for pod: daemon-set-27jzn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 12 17:12:12.888: INFO: Pod daemon-set-27jzn is not available
Aug 12 17:12:12.888: INFO: Wrong image for pod: daemon-set-cp9cn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 12 17:12:12.888: INFO: Wrong image for pod: daemon-set-dwdcl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 12 17:12:13.901: INFO: Wrong image for pod: daemon-set-cp9cn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 12 17:12:13.901: INFO: Wrong image for pod: daemon-set-dwdcl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 12 17:12:13.901: INFO: Pod daemon-set-xqjkn is not available
Aug 12 17:12:14.891: INFO: Wrong image for pod: daemon-set-cp9cn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 12 17:12:14.891: INFO: Wrong image for pod: daemon-set-dwdcl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 12 17:12:14.891: INFO: Pod daemon-set-xqjkn is not available
Aug 12 17:12:15.904: INFO: Wrong image for pod: daemon-set-cp9cn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 12 17:12:15.904: INFO: Wrong image for pod: daemon-set-dwdcl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 12 17:12:16.890: INFO: Wrong image for pod: daemon-set-cp9cn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 12 17:12:16.890: INFO: Pod daemon-set-cp9cn is not available
Aug 12 17:12:16.890: INFO: Wrong image for pod: daemon-set-dwdcl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 12 17:12:17.894: INFO: Pod daemon-set-7sxpw is not available
Aug 12 17:12:17.895: INFO: Wrong image for pod: daemon-set-dwdcl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 12 17:12:18.892: INFO: Pod daemon-set-7sxpw is not available
Aug 12 17:12:18.892: INFO: Wrong image for pod: daemon-set-dwdcl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 12 17:12:19.889: INFO: Wrong image for pod: daemon-set-dwdcl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 12 17:12:20.890: INFO: Wrong image for pod: daemon-set-dwdcl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 12 17:12:21.895: INFO: Wrong image for pod: daemon-set-dwdcl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 12 17:12:21.895: INFO: Pod daemon-set-dwdcl is not available
Aug 12 17:12:22.889: INFO: Wrong image for pod: daemon-set-dwdcl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 12 17:12:22.889: INFO: Pod daemon-set-dwdcl is not available
Aug 12 17:12:23.889: INFO: Wrong image for pod: daemon-set-dwdcl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 12 17:12:23.890: INFO: Pod daemon-set-dwdcl is not available
Aug 12 17:12:24.889: INFO: Wrong image for pod: daemon-set-dwdcl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 12 17:12:24.889: INFO: Pod daemon-set-dwdcl is not available
Aug 12 17:12:25.889: INFO: Wrong image for pod: daemon-set-dwdcl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 12 17:12:25.889: INFO: Pod daemon-set-dwdcl is not available
Aug 12 17:12:26.893: INFO: Wrong image for pod: daemon-set-dwdcl. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 12 17:12:26.893: INFO: Pod daemon-set-dwdcl is not available
Aug 12 17:12:27.893: INFO: Pod daemon-set-6mgxt is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Aug 12 17:12:27.911: INFO: Number of nodes with available pods: 2
Aug 12 17:12:27.911: INFO: Node conformance-1-15-2-do-0-default-pool-rxfp is running more than one daemon pod
Aug 12 17:12:28.932: INFO: Number of nodes with available pods: 2
Aug 12 17:12:28.932: INFO: Node conformance-1-15-2-do-0-default-pool-rxfp is running more than one daemon pod
Aug 12 17:12:29.988: INFO: Number of nodes with available pods: 3
Aug 12 17:12:29.988: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9222, will wait for the garbage collector to delete the pods
Aug 12 17:12:30.073: INFO: Deleting DaemonSet.extensions daemon-set took: 11.972201ms
Aug 12 17:12:30.474: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.743722ms
Aug 12 17:12:43.400: INFO: Number of nodes with available pods: 0
Aug 12 17:12:43.400: INFO: Number of running nodes: 0, number of available pods: 0
Aug 12 17:12:43.412: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9222/daemonsets","resourceVersion":"51003"},"items":null}

Aug 12 17:12:43.416: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9222/pods","resourceVersion":"51003"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:12:43.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9222" for this suite.
Aug 12 17:12:49.470: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:12:49.643: INFO: namespace daemonsets-9222 deletion completed in 6.209715544s

 [SLOW TEST:42.953 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:12:49.648: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating secret secrets-3506/secret-test-64218b68-257b-4076-90ec-2ef282efa3b5
STEP: Creating a pod to test consume secrets
Aug 12 17:12:49.716: INFO: Waiting up to 5m0s for pod "pod-configmaps-a74a922b-2f86-49b1-ac4c-ed162071ef55" in namespace "secrets-3506" to be "success or failure"
Aug 12 17:12:49.725: INFO: Pod "pod-configmaps-a74a922b-2f86-49b1-ac4c-ed162071ef55": Phase="Pending", Reason="", readiness=false. Elapsed: 9.23835ms
Aug 12 17:12:51.731: INFO: Pod "pod-configmaps-a74a922b-2f86-49b1-ac4c-ed162071ef55": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015597398s
Aug 12 17:12:53.736: INFO: Pod "pod-configmaps-a74a922b-2f86-49b1-ac4c-ed162071ef55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019934253s
STEP: Saw pod success
Aug 12 17:12:53.736: INFO: Pod "pod-configmaps-a74a922b-2f86-49b1-ac4c-ed162071ef55" satisfied condition "success or failure"
Aug 12 17:12:53.739: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxf2 pod pod-configmaps-a74a922b-2f86-49b1-ac4c-ed162071ef55 container env-test: <nil>
STEP: delete the pod
Aug 12 17:12:53.795: INFO: Waiting for pod pod-configmaps-a74a922b-2f86-49b1-ac4c-ed162071ef55 to disappear
Aug 12 17:12:53.808: INFO: Pod pod-configmaps-a74a922b-2f86-49b1-ac4c-ed162071ef55 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:12:53.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3506" for this suite.
Aug 12 17:12:59.839: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:13:00.047: INFO: namespace secrets-3506 deletion completed in 6.233160681s

 [SLOW TEST:10.400 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:13:00.048: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-79c55d1a-d9e2-40a8-a195-11be14bb8064
STEP: Creating a pod to test consume secrets
Aug 12 17:13:00.107: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-73412e1f-25c4-4c12-9ba3-3186b14a538f" in namespace "projected-3906" to be "success or failure"
Aug 12 17:13:00.131: INFO: Pod "pod-projected-secrets-73412e1f-25c4-4c12-9ba3-3186b14a538f": Phase="Pending", Reason="", readiness=false. Elapsed: 23.126122ms
Aug 12 17:13:02.135: INFO: Pod "pod-projected-secrets-73412e1f-25c4-4c12-9ba3-3186b14a538f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027575944s
STEP: Saw pod success
Aug 12 17:13:02.136: INFO: Pod "pod-projected-secrets-73412e1f-25c4-4c12-9ba3-3186b14a538f" satisfied condition "success or failure"
Aug 12 17:13:02.139: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxfs pod pod-projected-secrets-73412e1f-25c4-4c12-9ba3-3186b14a538f container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 12 17:13:02.173: INFO: Waiting for pod pod-projected-secrets-73412e1f-25c4-4c12-9ba3-3186b14a538f to disappear
Aug 12 17:13:02.175: INFO: Pod pod-projected-secrets-73412e1f-25c4-4c12-9ba3-3186b14a538f no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:13:02.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3906" for this suite.
Aug 12 17:13:08.194: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:13:08.337: INFO: namespace projected-3906 deletion completed in 6.156658841s

 [SLOW TEST:8.289 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:13:08.342: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Aug 12 17:13:13.007: INFO: Successfully updated pod "labelsupdatee75975b6-a78e-4ea3-823a-60b430663a77"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:13:15.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6774" for this suite.
Aug 12 17:13:37.075: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:13:37.247: INFO: namespace projected-6774 deletion completed in 22.187816044s

 [SLOW TEST:28.906 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:13:37.251: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 12 17:13:37.373: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6e549f24-00ec-4d9c-a56e-9251b710fe00" in namespace "downward-api-1433" to be "success or failure"
Aug 12 17:13:37.388: INFO: Pod "downwardapi-volume-6e549f24-00ec-4d9c-a56e-9251b710fe00": Phase="Pending", Reason="", readiness=false. Elapsed: 14.137494ms
Aug 12 17:13:39.393: INFO: Pod "downwardapi-volume-6e549f24-00ec-4d9c-a56e-9251b710fe00": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019211544s
Aug 12 17:13:41.399: INFO: Pod "downwardapi-volume-6e549f24-00ec-4d9c-a56e-9251b710fe00": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025613038s
STEP: Saw pod success
Aug 12 17:13:41.399: INFO: Pod "downwardapi-volume-6e549f24-00ec-4d9c-a56e-9251b710fe00" satisfied condition "success or failure"
Aug 12 17:13:41.402: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxf2 pod downwardapi-volume-6e549f24-00ec-4d9c-a56e-9251b710fe00 container client-container: <nil>
STEP: delete the pod
Aug 12 17:13:41.432: INFO: Waiting for pod downwardapi-volume-6e549f24-00ec-4d9c-a56e-9251b710fe00 to disappear
Aug 12 17:13:41.436: INFO: Pod downwardapi-volume-6e549f24-00ec-4d9c-a56e-9251b710fe00 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:13:41.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1433" for this suite.
Aug 12 17:13:47.466: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:13:47.610: INFO: namespace downward-api-1433 deletion completed in 6.163574749s

 [SLOW TEST:10.360 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:13:47.617: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating cluster-info
Aug 12 17:13:47.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 cluster-info'
Aug 12 17:13:48.107: INFO: stderr: ""
Aug 12 17:13:48.107: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.245.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://10.245.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:13:48.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-768" for this suite.
Aug 12 17:13:54.127: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:13:54.290: INFO: namespace kubectl-768 deletion completed in 6.177506268s

 [SLOW TEST:6.674 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:13:54.293: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test hostPath mode
Aug 12 17:13:54.355: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-2783" to be "success or failure"
Aug 12 17:13:54.365: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 10.292484ms
Aug 12 17:13:56.370: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014869864s
Aug 12 17:13:58.374: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019095077s
STEP: Saw pod success
Aug 12 17:13:58.374: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Aug 12 17:13:58.379: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxfs pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Aug 12 17:13:58.411: INFO: Waiting for pod pod-host-path-test to disappear
Aug 12 17:13:58.419: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:13:58.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-2783" for this suite.
Aug 12 17:14:04.483: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:14:04.692: INFO: namespace hostpath-2783 deletion completed in 6.264586829s

 [SLOW TEST:10.400 seconds]
[sig-storage] HostPath
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:14:04.697: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Aug 12 17:14:04.739: INFO: namespace kubectl-866
Aug 12 17:14:04.739: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 create -f - --namespace=kubectl-866'
Aug 12 17:14:05.039: INFO: stderr: ""
Aug 12 17:14:05.039: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Aug 12 17:14:06.045: INFO: Selector matched 1 pods for map[app:redis]
Aug 12 17:14:06.045: INFO: Found 0 / 1
Aug 12 17:14:07.133: INFO: Selector matched 1 pods for map[app:redis]
Aug 12 17:14:07.133: INFO: Found 0 / 1
Aug 12 17:14:08.044: INFO: Selector matched 1 pods for map[app:redis]
Aug 12 17:14:08.044: INFO: Found 0 / 1
Aug 12 17:14:09.044: INFO: Selector matched 1 pods for map[app:redis]
Aug 12 17:14:09.045: INFO: Found 1 / 1
Aug 12 17:14:09.045: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug 12 17:14:09.049: INFO: Selector matched 1 pods for map[app:redis]
Aug 12 17:14:09.049: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug 12 17:14:09.049: INFO: wait on redis-master startup in kubectl-866 
Aug 12 17:14:09.049: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 logs redis-master-jmnp2 redis-master --namespace=kubectl-866'
Aug 12 17:14:09.167: INFO: stderr: ""
Aug 12 17:14:09.167: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 12 Aug 17:14:08.029 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 12 Aug 17:14:08.029 # Server started, Redis version 3.2.12\n1:M 12 Aug 17:14:08.029 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 12 Aug 17:14:08.029 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Aug 12 17:14:09.167: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-866'
Aug 12 17:14:09.343: INFO: stderr: ""
Aug 12 17:14:09.343: INFO: stdout: "service/rm2 exposed\n"
Aug 12 17:14:09.349: INFO: Service rm2 in namespace kubectl-866 found.
STEP: exposing service
Aug 12 17:14:11.357: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-866'
Aug 12 17:14:11.567: INFO: stderr: ""
Aug 12 17:14:11.567: INFO: stdout: "service/rm3 exposed\n"
Aug 12 17:14:11.572: INFO: Service rm3 in namespace kubectl-866 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:14:13.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-866" for this suite.
Aug 12 17:14:35.601: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:14:35.756: INFO: namespace kubectl-866 deletion completed in 22.173273706s

 [SLOW TEST:31.060 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create services for rc  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:14:35.759: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8444.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8444.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 12 17:14:39.947: INFO: DNS probes using dns-8444/dns-test-4ec4c693-0a74-4976-8578-ea3f4c81c887 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:14:39.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8444" for this suite.
Aug 12 17:14:46.018: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:14:46.162: INFO: namespace dns-8444 deletion completed in 6.163801851s

 [SLOW TEST:10.403 seconds]
[sig-network] DNS
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:14:46.166: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:14:51.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4730" for this suite.
Aug 12 17:14:57.846: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:14:58.002: INFO: namespace watch-4730 deletion completed in 6.260900281s

 [SLOW TEST:11.836 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:14:58.007: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 12 17:14:58.056: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0575546e-15fd-4f5d-b9ab-901d38f960d1" in namespace "projected-5481" to be "success or failure"
Aug 12 17:14:58.065: INFO: Pod "downwardapi-volume-0575546e-15fd-4f5d-b9ab-901d38f960d1": Phase="Pending", Reason="", readiness=false. Elapsed: 9.407228ms
Aug 12 17:15:00.071: INFO: Pod "downwardapi-volume-0575546e-15fd-4f5d-b9ab-901d38f960d1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014656649s
Aug 12 17:15:02.078: INFO: Pod "downwardapi-volume-0575546e-15fd-4f5d-b9ab-901d38f960d1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021877748s
STEP: Saw pod success
Aug 12 17:15:02.078: INFO: Pod "downwardapi-volume-0575546e-15fd-4f5d-b9ab-901d38f960d1" satisfied condition "success or failure"
Aug 12 17:15:02.083: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxfs pod downwardapi-volume-0575546e-15fd-4f5d-b9ab-901d38f960d1 container client-container: <nil>
STEP: delete the pod
Aug 12 17:15:02.121: INFO: Waiting for pod downwardapi-volume-0575546e-15fd-4f5d-b9ab-901d38f960d1 to disappear
Aug 12 17:15:02.124: INFO: Pod downwardapi-volume-0575546e-15fd-4f5d-b9ab-901d38f960d1 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:15:02.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5481" for this suite.
Aug 12 17:15:08.142: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:15:08.278: INFO: namespace projected-5481 deletion completed in 6.14804845s

 [SLOW TEST:10.272 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:15:08.282: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 12 17:15:08.349: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f6f9fbb6-22ec-402f-86ee-6e929a263c16" in namespace "projected-3133" to be "success or failure"
Aug 12 17:15:08.377: INFO: Pod "downwardapi-volume-f6f9fbb6-22ec-402f-86ee-6e929a263c16": Phase="Pending", Reason="", readiness=false. Elapsed: 27.839437ms
Aug 12 17:15:10.386: INFO: Pod "downwardapi-volume-f6f9fbb6-22ec-402f-86ee-6e929a263c16": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037184389s
Aug 12 17:15:12.692: INFO: Pod "downwardapi-volume-f6f9fbb6-22ec-402f-86ee-6e929a263c16": Phase="Pending", Reason="", readiness=false. Elapsed: 4.342711169s
Aug 12 17:15:14.696: INFO: Pod "downwardapi-volume-f6f9fbb6-22ec-402f-86ee-6e929a263c16": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.347177553s
STEP: Saw pod success
Aug 12 17:15:14.697: INFO: Pod "downwardapi-volume-f6f9fbb6-22ec-402f-86ee-6e929a263c16" satisfied condition "success or failure"
Aug 12 17:15:14.699: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxfp pod downwardapi-volume-f6f9fbb6-22ec-402f-86ee-6e929a263c16 container client-container: <nil>
STEP: delete the pod
Aug 12 17:15:14.728: INFO: Waiting for pod downwardapi-volume-f6f9fbb6-22ec-402f-86ee-6e929a263c16 to disappear
Aug 12 17:15:14.731: INFO: Pod downwardapi-volume-f6f9fbb6-22ec-402f-86ee-6e929a263c16 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:15:14.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3133" for this suite.
Aug 12 17:15:20.755: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:15:20.897: INFO: namespace projected-3133 deletion completed in 6.158016294s

 [SLOW TEST:12.616 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:15:20.903: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Aug 12 17:15:25.006: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:15:25.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8970" for this suite.
Aug 12 17:15:31.056: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:15:31.219: INFO: namespace container-runtime-8970 deletion completed in 6.175442387s

 [SLOW TEST:10.317 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:15:31.223: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Aug 12 17:15:33.807: INFO: Successfully updated pod "pod-update-activedeadlineseconds-be8c564f-1d89-4a88-8a0f-053e87009ca4"
Aug 12 17:15:33.807: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-be8c564f-1d89-4a88-8a0f-053e87009ca4" in namespace "pods-7149" to be "terminated due to deadline exceeded"
Aug 12 17:15:33.812: INFO: Pod "pod-update-activedeadlineseconds-be8c564f-1d89-4a88-8a0f-053e87009ca4": Phase="Running", Reason="", readiness=true. Elapsed: 4.500293ms
Aug 12 17:15:35.819: INFO: Pod "pod-update-activedeadlineseconds-be8c564f-1d89-4a88-8a0f-053e87009ca4": Phase="Running", Reason="", readiness=true. Elapsed: 2.011485366s
Aug 12 17:15:37.824: INFO: Pod "pod-update-activedeadlineseconds-be8c564f-1d89-4a88-8a0f-053e87009ca4": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.01661202s
Aug 12 17:15:37.825: INFO: Pod "pod-update-activedeadlineseconds-be8c564f-1d89-4a88-8a0f-053e87009ca4" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:15:37.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7149" for this suite.
Aug 12 17:15:43.850: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:15:44.011: INFO: namespace pods-7149 deletion completed in 6.177439967s

 [SLOW TEST:12.788 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:15:44.013: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Starting the proxy
Aug 12 17:15:44.113: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-213645099 proxy --unix-socket=/tmp/kubectl-proxy-unix326569890/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:15:44.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7948" for this suite.
Aug 12 17:15:50.307: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:15:50.525: INFO: namespace kubectl-7948 deletion completed in 6.332302452s

 [SLOW TEST:6.512 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:15:50.526: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service multi-endpoint-test in namespace services-2576
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2576 to expose endpoints map[]
Aug 12 17:15:50.675: INFO: successfully validated that service multi-endpoint-test in namespace services-2576 exposes endpoints map[] (6.822129ms elapsed)
STEP: Creating pod pod1 in namespace services-2576
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2576 to expose endpoints map[pod1:[100]]
Aug 12 17:15:53.739: INFO: successfully validated that service multi-endpoint-test in namespace services-2576 exposes endpoints map[pod1:[100]] (3.046697106s elapsed)
STEP: Creating pod pod2 in namespace services-2576
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2576 to expose endpoints map[pod1:[100] pod2:[101]]
Aug 12 17:15:55.804: INFO: successfully validated that service multi-endpoint-test in namespace services-2576 exposes endpoints map[pod1:[100] pod2:[101]] (2.057327061s elapsed)
STEP: Deleting pod pod1 in namespace services-2576
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2576 to expose endpoints map[pod2:[101]]
Aug 12 17:15:55.895: INFO: successfully validated that service multi-endpoint-test in namespace services-2576 exposes endpoints map[pod2:[101]] (80.466722ms elapsed)
STEP: Deleting pod pod2 in namespace services-2576
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2576 to expose endpoints map[]
Aug 12 17:15:55.977: INFO: successfully validated that service multi-endpoint-test in namespace services-2576 exposes endpoints map[] (65.577537ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:15:56.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2576" for this suite.
Aug 12 17:16:18.123: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:16:18.244: INFO: namespace services-2576 deletion completed in 22.138846882s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

 [SLOW TEST:27.718 seconds]
[sig-network] Services
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:16:18.246: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override arguments
Aug 12 17:16:18.370: INFO: Waiting up to 5m0s for pod "client-containers-dd8d8bac-c784-46b0-b9eb-9fe98ec32ed8" in namespace "containers-2841" to be "success or failure"
Aug 12 17:16:18.377: INFO: Pod "client-containers-dd8d8bac-c784-46b0-b9eb-9fe98ec32ed8": Phase="Pending", Reason="", readiness=false. Elapsed: 7.46283ms
Aug 12 17:16:20.440: INFO: Pod "client-containers-dd8d8bac-c784-46b0-b9eb-9fe98ec32ed8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.069597377s
Aug 12 17:16:22.444: INFO: Pod "client-containers-dd8d8bac-c784-46b0-b9eb-9fe98ec32ed8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.073611089s
Aug 12 17:16:24.453: INFO: Pod "client-containers-dd8d8bac-c784-46b0-b9eb-9fe98ec32ed8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.082988449s
STEP: Saw pod success
Aug 12 17:16:24.453: INFO: Pod "client-containers-dd8d8bac-c784-46b0-b9eb-9fe98ec32ed8" satisfied condition "success or failure"
Aug 12 17:16:24.458: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxfs pod client-containers-dd8d8bac-c784-46b0-b9eb-9fe98ec32ed8 container test-container: <nil>
STEP: delete the pod
Aug 12 17:16:24.514: INFO: Waiting for pod client-containers-dd8d8bac-c784-46b0-b9eb-9fe98ec32ed8 to disappear
Aug 12 17:16:24.519: INFO: Pod client-containers-dd8d8bac-c784-46b0-b9eb-9fe98ec32ed8 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:16:24.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-2841" for this suite.
Aug 12 17:16:30.547: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:16:30.722: INFO: namespace containers-2841 deletion completed in 6.195378665s

 [SLOW TEST:12.476 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:16:30.726: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting the proxy server
Aug 12 17:16:30.827: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-213645099 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:16:30.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7601" for this suite.
Aug 12 17:16:36.955: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:16:37.072: INFO: namespace kubectl-7601 deletion completed in 6.138919055s

 [SLOW TEST:6.347 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:16:37.077: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-661b1015-1fab-439c-82bc-ef63573c1668
STEP: Creating configMap with name cm-test-opt-upd-94c9af64-db20-44c6-8f1a-377664bc088e
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-661b1015-1fab-439c-82bc-ef63573c1668
STEP: Updating configmap cm-test-opt-upd-94c9af64-db20-44c6-8f1a-377664bc088e
STEP: Creating configMap with name cm-test-opt-create-fb0a3929-4657-4aa8-9de1-c85a2ecc8f9c
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:16:45.343: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6303" for this suite.
Aug 12 17:17:07.366: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:17:07.511: INFO: namespace projected-6303 deletion completed in 22.164237146s

 [SLOW TEST:30.435 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:17:07.520: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Aug 12 17:17:12.133: INFO: Successfully updated pod "pod-update-6e48d5b3-ae9b-406e-a200-a2228112ccc1"
STEP: verifying the updated pod is in kubernetes
Aug 12 17:17:12.182: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:17:12.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2500" for this suite.
Aug 12 17:17:34.218: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:17:34.366: INFO: namespace pods-2500 deletion completed in 22.1771864s

 [SLOW TEST:26.846 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:17:34.371: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Aug 12 17:17:34.469: INFO: Waiting up to 5m0s for pod "downward-api-75ab1586-6262-423f-91a6-d86c3c12662a" in namespace "downward-api-716" to be "success or failure"
Aug 12 17:17:34.479: INFO: Pod "downward-api-75ab1586-6262-423f-91a6-d86c3c12662a": Phase="Pending", Reason="", readiness=false. Elapsed: 9.541412ms
Aug 12 17:17:36.487: INFO: Pod "downward-api-75ab1586-6262-423f-91a6-d86c3c12662a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017622054s
Aug 12 17:17:38.493: INFO: Pod "downward-api-75ab1586-6262-423f-91a6-d86c3c12662a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024069018s
STEP: Saw pod success
Aug 12 17:17:38.494: INFO: Pod "downward-api-75ab1586-6262-423f-91a6-d86c3c12662a" satisfied condition "success or failure"
Aug 12 17:17:38.499: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxf2 pod downward-api-75ab1586-6262-423f-91a6-d86c3c12662a container dapi-container: <nil>
STEP: delete the pod
Aug 12 17:17:38.539: INFO: Waiting for pod downward-api-75ab1586-6262-423f-91a6-d86c3c12662a to disappear
Aug 12 17:17:38.542: INFO: Pod downward-api-75ab1586-6262-423f-91a6-d86c3c12662a no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:17:38.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-716" for this suite.
Aug 12 17:17:44.624: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:17:44.824: INFO: namespace downward-api-716 deletion completed in 6.274882108s

 [SLOW TEST:10.454 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:17:44.832: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 12 17:17:44.935: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7e5a5b96-cd5f-45dd-9b35-c5c6c9d3e05b" in namespace "projected-3782" to be "success or failure"
Aug 12 17:17:44.947: INFO: Pod "downwardapi-volume-7e5a5b96-cd5f-45dd-9b35-c5c6c9d3e05b": Phase="Pending", Reason="", readiness=false. Elapsed: 11.536473ms
Aug 12 17:17:46.960: INFO: Pod "downwardapi-volume-7e5a5b96-cd5f-45dd-9b35-c5c6c9d3e05b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02499226s
Aug 12 17:17:48.965: INFO: Pod "downwardapi-volume-7e5a5b96-cd5f-45dd-9b35-c5c6c9d3e05b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030334297s
STEP: Saw pod success
Aug 12 17:17:48.965: INFO: Pod "downwardapi-volume-7e5a5b96-cd5f-45dd-9b35-c5c6c9d3e05b" satisfied condition "success or failure"
Aug 12 17:17:48.969: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxfp pod downwardapi-volume-7e5a5b96-cd5f-45dd-9b35-c5c6c9d3e05b container client-container: <nil>
STEP: delete the pod
Aug 12 17:17:49.070: INFO: Waiting for pod downwardapi-volume-7e5a5b96-cd5f-45dd-9b35-c5c6c9d3e05b to disappear
Aug 12 17:17:49.075: INFO: Pod downwardapi-volume-7e5a5b96-cd5f-45dd-9b35-c5c6c9d3e05b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:17:49.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3782" for this suite.
Aug 12 17:17:55.095: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:17:55.253: INFO: namespace projected-3782 deletion completed in 6.173620417s

 [SLOW TEST:10.422 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:17:55.258: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on node default medium
Aug 12 17:17:55.339: INFO: Waiting up to 5m0s for pod "pod-4c5ff9cb-f823-4f02-bd34-9a24e9a6f37d" in namespace "emptydir-3492" to be "success or failure"
Aug 12 17:17:55.364: INFO: Pod "pod-4c5ff9cb-f823-4f02-bd34-9a24e9a6f37d": Phase="Pending", Reason="", readiness=false. Elapsed: 24.909669ms
Aug 12 17:17:57.372: INFO: Pod "pod-4c5ff9cb-f823-4f02-bd34-9a24e9a6f37d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032325401s
Aug 12 17:17:59.375: INFO: Pod "pod-4c5ff9cb-f823-4f02-bd34-9a24e9a6f37d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036271816s
STEP: Saw pod success
Aug 12 17:17:59.376: INFO: Pod "pod-4c5ff9cb-f823-4f02-bd34-9a24e9a6f37d" satisfied condition "success or failure"
Aug 12 17:17:59.379: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxf2 pod pod-4c5ff9cb-f823-4f02-bd34-9a24e9a6f37d container test-container: <nil>
STEP: delete the pod
Aug 12 17:17:59.407: INFO: Waiting for pod pod-4c5ff9cb-f823-4f02-bd34-9a24e9a6f37d to disappear
Aug 12 17:17:59.412: INFO: Pod pod-4c5ff9cb-f823-4f02-bd34-9a24e9a6f37d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:17:59.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3492" for this suite.
Aug 12 17:18:05.448: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:18:05.608: INFO: namespace emptydir-3492 deletion completed in 6.18472698s

 [SLOW TEST:10.351 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:18:05.613: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Aug 12 17:18:05.729: INFO: Waiting up to 5m0s for pod "pod-c6f4cbe0-bc2e-42f7-98d1-27de3a9df993" in namespace "emptydir-9882" to be "success or failure"
Aug 12 17:18:05.737: INFO: Pod "pod-c6f4cbe0-bc2e-42f7-98d1-27de3a9df993": Phase="Pending", Reason="", readiness=false. Elapsed: 7.898104ms
Aug 12 17:18:07.752: INFO: Pod "pod-c6f4cbe0-bc2e-42f7-98d1-27de3a9df993": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022473207s
STEP: Saw pod success
Aug 12 17:18:07.752: INFO: Pod "pod-c6f4cbe0-bc2e-42f7-98d1-27de3a9df993" satisfied condition "success or failure"
Aug 12 17:18:07.761: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxfs pod pod-c6f4cbe0-bc2e-42f7-98d1-27de3a9df993 container test-container: <nil>
STEP: delete the pod
Aug 12 17:18:07.815: INFO: Waiting for pod pod-c6f4cbe0-bc2e-42f7-98d1-27de3a9df993 to disappear
Aug 12 17:18:07.819: INFO: Pod pod-c6f4cbe0-bc2e-42f7-98d1-27de3a9df993 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:18:07.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9882" for this suite.
Aug 12 17:18:13.853: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:18:14.021: INFO: namespace emptydir-9882 deletion completed in 6.193056815s

 [SLOW TEST:8.409 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:18:14.027: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's command
Aug 12 17:18:14.137: INFO: Waiting up to 5m0s for pod "var-expansion-c55cf19d-4dd7-4177-9d56-c342f5afa931" in namespace "var-expansion-4879" to be "success or failure"
Aug 12 17:18:14.146: INFO: Pod "var-expansion-c55cf19d-4dd7-4177-9d56-c342f5afa931": Phase="Pending", Reason="", readiness=false. Elapsed: 9.050228ms
Aug 12 17:18:16.155: INFO: Pod "var-expansion-c55cf19d-4dd7-4177-9d56-c342f5afa931": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017418033s
Aug 12 17:18:18.159: INFO: Pod "var-expansion-c55cf19d-4dd7-4177-9d56-c342f5afa931": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021997929s
STEP: Saw pod success
Aug 12 17:18:18.159: INFO: Pod "var-expansion-c55cf19d-4dd7-4177-9d56-c342f5afa931" satisfied condition "success or failure"
Aug 12 17:18:18.163: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxfp pod var-expansion-c55cf19d-4dd7-4177-9d56-c342f5afa931 container dapi-container: <nil>
STEP: delete the pod
Aug 12 17:18:18.191: INFO: Waiting for pod var-expansion-c55cf19d-4dd7-4177-9d56-c342f5afa931 to disappear
Aug 12 17:18:18.203: INFO: Pod var-expansion-c55cf19d-4dd7-4177-9d56-c342f5afa931 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:18:18.203: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4879" for this suite.
Aug 12 17:18:24.224: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:18:24.394: INFO: namespace var-expansion-4879 deletion completed in 6.184497692s

 [SLOW TEST:10.368 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:18:24.396: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-0bb9bdfc-2add-49db-a0d3-759979efd4ba
STEP: Creating secret with name s-test-opt-upd-f45d7b99-3f82-46ac-a1f4-db423cbb4101
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-0bb9bdfc-2add-49db-a0d3-759979efd4ba
STEP: Updating secret s-test-opt-upd-f45d7b99-3f82-46ac-a1f4-db423cbb4101
STEP: Creating secret with name s-test-opt-create-bb520a70-bae0-45e4-a9e6-19da593a0955
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:18:30.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1036" for this suite.
Aug 12 17:18:52.891: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:18:53.068: INFO: namespace projected-1036 deletion completed in 22.189320166s

 [SLOW TEST:28.672 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:18:53.072: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 12 17:18:53.190: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Aug 12 17:18:53.201: INFO: Pod name sample-pod: Found 0 pods out of 1
Aug 12 17:18:58.218: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Aug 12 17:18:58.218: INFO: Creating deployment "test-rolling-update-deployment"
Aug 12 17:18:58.229: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Aug 12 17:18:58.254: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Aug 12 17:19:00.272: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Aug 12 17:19:00.276: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701227138, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701227138, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701227138, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701227138, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-79f6b9d75c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 12 17:19:02.281: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Aug 12 17:19:02.299: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-1764,SelfLink:/apis/apps/v1/namespaces/deployment-1764/deployments/test-rolling-update-deployment,UID:c45ef525-7c25-4300-a032-79172814ed3e,ResourceVersion:52805,Generation:1,CreationTimestamp:2019-08-12 17:18:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-08-12 17:18:58 +0000 UTC 2019-08-12 17:18:58 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-08-12 17:19:01 +0000 UTC 2019-08-12 17:18:58 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-79f6b9d75c" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Aug 12 17:19:02.302: INFO: New ReplicaSet "test-rolling-update-deployment-79f6b9d75c" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c,GenerateName:,Namespace:deployment-1764,SelfLink:/apis/apps/v1/namespaces/deployment-1764/replicasets/test-rolling-update-deployment-79f6b9d75c,UID:523ebdba-f4df-43fd-a5d7-f61b44c1992e,ResourceVersion:52794,Generation:1,CreationTimestamp:2019-08-12 17:18:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment c45ef525-7c25-4300-a032-79172814ed3e 0xc002dc63f7 0xc002dc63f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Aug 12 17:19:02.303: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Aug 12 17:19:02.303: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-1764,SelfLink:/apis/apps/v1/namespaces/deployment-1764/replicasets/test-rolling-update-controller,UID:2b436da7-7a92-4714-9208-178b01d3956d,ResourceVersion:52804,Generation:2,CreationTimestamp:2019-08-12 17:18:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment c45ef525-7c25-4300-a032-79172814ed3e 0xc002dc6317 0xc002dc6318}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 12 17:19:02.306: INFO: Pod "test-rolling-update-deployment-79f6b9d75c-fvnh7" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c-fvnh7,GenerateName:test-rolling-update-deployment-79f6b9d75c-,Namespace:deployment-1764,SelfLink:/api/v1/namespaces/deployment-1764/pods/test-rolling-update-deployment-79f6b9d75c-fvnh7,UID:bab5a441-95ab-492a-b4b5-eb5804ef8993,ResourceVersion:52793,Generation:0,CreationTimestamp:2019-08-12 17:18:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-79f6b9d75c 523ebdba-f4df-43fd-a5d7-f61b44c1992e 0xc002dc6ce7 0xc002dc6ce8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xg7tf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xg7tf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-xg7tf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-1-15-2-do-0-default-pool-rxfp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002dc6d50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002dc6d70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:18:58 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:19:01 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:19:01 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:18:58 +0000 UTC  }],Message:,Reason:,HostIP:10.138.15.72,PodIP:10.244.1.254,StartTime:2019-08-12 17:18:58 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-08-12 17:19:00 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://9b5b60f9b5e1f193e965b6d0dc28eb6ab4826609293ab47cb15a225c706e911a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:19:02.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1764" for this suite.
Aug 12 17:19:08.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:19:08.455: INFO: namespace deployment-1764 deletion completed in 6.145339838s

 [SLOW TEST:15.383 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:19:08.459: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-projected-all-test-volume-2b753154-b40f-44e1-9d83-ec61fc82f257
STEP: Creating secret with name secret-projected-all-test-volume-ed2ca802-dcb2-4ee7-8e1c-ea1b587e308a
STEP: Creating a pod to test Check all projections for projected volume plugin
Aug 12 17:19:08.576: INFO: Waiting up to 5m0s for pod "projected-volume-6caa9536-35e4-4a30-8b5c-91d965a8b29c" in namespace "projected-9507" to be "success or failure"
Aug 12 17:19:08.592: INFO: Pod "projected-volume-6caa9536-35e4-4a30-8b5c-91d965a8b29c": Phase="Pending", Reason="", readiness=false. Elapsed: 16.247952ms
Aug 12 17:19:10.603: INFO: Pod "projected-volume-6caa9536-35e4-4a30-8b5c-91d965a8b29c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026533876s
Aug 12 17:19:12.609: INFO: Pod "projected-volume-6caa9536-35e4-4a30-8b5c-91d965a8b29c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03283142s
STEP: Saw pod success
Aug 12 17:19:12.609: INFO: Pod "projected-volume-6caa9536-35e4-4a30-8b5c-91d965a8b29c" satisfied condition "success or failure"
Aug 12 17:19:12.614: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxf2 pod projected-volume-6caa9536-35e4-4a30-8b5c-91d965a8b29c container projected-all-volume-test: <nil>
STEP: delete the pod
Aug 12 17:19:12.645: INFO: Waiting for pod projected-volume-6caa9536-35e4-4a30-8b5c-91d965a8b29c to disappear
Aug 12 17:19:12.650: INFO: Pod projected-volume-6caa9536-35e4-4a30-8b5c-91d965a8b29c no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:19:12.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9507" for this suite.
Aug 12 17:19:18.766: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:19:18.912: INFO: namespace projected-9507 deletion completed in 6.257002427s

 [SLOW TEST:10.453 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:19:18.912: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Aug 12 17:19:19.025: INFO: Waiting up to 5m0s for pod "pod-b2ca8f43-e490-4ae0-a8d3-f24bb72a625a" in namespace "emptydir-8986" to be "success or failure"
Aug 12 17:19:19.032: INFO: Pod "pod-b2ca8f43-e490-4ae0-a8d3-f24bb72a625a": Phase="Pending", Reason="", readiness=false. Elapsed: 7.047812ms
Aug 12 17:19:21.042: INFO: Pod "pod-b2ca8f43-e490-4ae0-a8d3-f24bb72a625a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01679331s
Aug 12 17:19:23.051: INFO: Pod "pod-b2ca8f43-e490-4ae0-a8d3-f24bb72a625a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025729398s
STEP: Saw pod success
Aug 12 17:19:23.051: INFO: Pod "pod-b2ca8f43-e490-4ae0-a8d3-f24bb72a625a" satisfied condition "success or failure"
Aug 12 17:19:23.055: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxfs pod pod-b2ca8f43-e490-4ae0-a8d3-f24bb72a625a container test-container: <nil>
STEP: delete the pod
Aug 12 17:19:23.097: INFO: Waiting for pod pod-b2ca8f43-e490-4ae0-a8d3-f24bb72a625a to disappear
Aug 12 17:19:23.104: INFO: Pod pod-b2ca8f43-e490-4ae0-a8d3-f24bb72a625a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:19:23.104: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8986" for this suite.
Aug 12 17:19:29.127: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:19:29.242: INFO: namespace emptydir-8986 deletion completed in 6.13207063s

 [SLOW TEST:10.330 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:19:29.248: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-546bf843-aac4-43a3-8bcc-1f0150dcc445
STEP: Creating a pod to test consume configMaps
Aug 12 17:19:29.370: INFO: Waiting up to 5m0s for pod "pod-configmaps-858a4630-7980-42f4-af5e-c50fac8b86e3" in namespace "configmap-7956" to be "success or failure"
Aug 12 17:19:29.378: INFO: Pod "pod-configmaps-858a4630-7980-42f4-af5e-c50fac8b86e3": Phase="Pending", Reason="", readiness=false. Elapsed: 7.844334ms
Aug 12 17:19:31.387: INFO: Pod "pod-configmaps-858a4630-7980-42f4-af5e-c50fac8b86e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016554042s
Aug 12 17:19:33.393: INFO: Pod "pod-configmaps-858a4630-7980-42f4-af5e-c50fac8b86e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02261196s
STEP: Saw pod success
Aug 12 17:19:33.393: INFO: Pod "pod-configmaps-858a4630-7980-42f4-af5e-c50fac8b86e3" satisfied condition "success or failure"
Aug 12 17:19:33.400: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxfp pod pod-configmaps-858a4630-7980-42f4-af5e-c50fac8b86e3 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 12 17:19:33.472: INFO: Waiting for pod pod-configmaps-858a4630-7980-42f4-af5e-c50fac8b86e3 to disappear
Aug 12 17:19:33.475: INFO: Pod pod-configmaps-858a4630-7980-42f4-af5e-c50fac8b86e3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:19:33.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7956" for this suite.
Aug 12 17:19:39.497: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:19:39.806: INFO: namespace configmap-7956 deletion completed in 6.320949896s

 [SLOW TEST:10.558 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:19:39.806: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating all guestbook components
Aug 12 17:19:39.894: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Aug 12 17:19:39.895: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 create -f - --namespace=kubectl-6880'
Aug 12 17:19:40.260: INFO: stderr: ""
Aug 12 17:19:40.260: INFO: stdout: "service/redis-slave created\n"
Aug 12 17:19:40.260: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Aug 12 17:19:40.260: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 create -f - --namespace=kubectl-6880'
Aug 12 17:19:40.839: INFO: stderr: ""
Aug 12 17:19:40.839: INFO: stdout: "service/redis-master created\n"
Aug 12 17:19:40.839: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Aug 12 17:19:40.839: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 create -f - --namespace=kubectl-6880'
Aug 12 17:19:41.203: INFO: stderr: ""
Aug 12 17:19:41.203: INFO: stdout: "service/frontend created\n"
Aug 12 17:19:41.204: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Aug 12 17:19:41.204: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 create -f - --namespace=kubectl-6880'
Aug 12 17:19:41.541: INFO: stderr: ""
Aug 12 17:19:41.541: INFO: stdout: "deployment.apps/frontend created\n"
Aug 12 17:19:41.541: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Aug 12 17:19:41.541: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 create -f - --namespace=kubectl-6880'
Aug 12 17:19:41.816: INFO: stderr: ""
Aug 12 17:19:41.816: INFO: stdout: "deployment.apps/redis-master created\n"
Aug 12 17:19:41.816: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Aug 12 17:19:41.816: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 create -f - --namespace=kubectl-6880'
Aug 12 17:19:42.116: INFO: stderr: ""
Aug 12 17:19:42.116: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Aug 12 17:19:42.116: INFO: Waiting for all frontend pods to be Running.
Aug 12 17:19:47.167: INFO: Waiting for frontend to serve content.
Aug 12 17:19:47.185: INFO: Trying to add a new entry to the guestbook.
Aug 12 17:19:47.212: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Aug 12 17:19:47.240: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 delete --grace-period=0 --force -f - --namespace=kubectl-6880'
Aug 12 17:19:47.591: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 12 17:19:47.591: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Aug 12 17:19:47.592: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 delete --grace-period=0 --force -f - --namespace=kubectl-6880'
Aug 12 17:19:48.014: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 12 17:19:48.014: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Aug 12 17:19:48.014: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 delete --grace-period=0 --force -f - --namespace=kubectl-6880'
Aug 12 17:19:48.358: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 12 17:19:48.358: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Aug 12 17:19:48.358: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 delete --grace-period=0 --force -f - --namespace=kubectl-6880'
Aug 12 17:19:48.551: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 12 17:19:48.551: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Aug 12 17:19:48.551: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 delete --grace-period=0 --force -f - --namespace=kubectl-6880'
Aug 12 17:19:48.715: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 12 17:19:48.715: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Aug 12 17:19:48.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 delete --grace-period=0 --force -f - --namespace=kubectl-6880'
Aug 12 17:19:49.301: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 12 17:19:49.301: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:19:49.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6880" for this suite.
Aug 12 17:20:27.339: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:20:27.484: INFO: namespace kubectl-6880 deletion completed in 38.175465134s

 [SLOW TEST:47.678 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:20:27.490: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Aug 12 17:20:27.610: INFO: Waiting up to 5m0s for pod "pod-2737b2d6-6bc9-4c04-834f-d5374737a783" in namespace "emptydir-2718" to be "success or failure"
Aug 12 17:20:27.629: INFO: Pod "pod-2737b2d6-6bc9-4c04-834f-d5374737a783": Phase="Pending", Reason="", readiness=false. Elapsed: 19.155576ms
Aug 12 17:20:29.639: INFO: Pod "pod-2737b2d6-6bc9-4c04-834f-d5374737a783": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028754974s
Aug 12 17:20:31.644: INFO: Pod "pod-2737b2d6-6bc9-4c04-834f-d5374737a783": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033454434s
STEP: Saw pod success
Aug 12 17:20:31.644: INFO: Pod "pod-2737b2d6-6bc9-4c04-834f-d5374737a783" satisfied condition "success or failure"
Aug 12 17:20:31.650: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxf2 pod pod-2737b2d6-6bc9-4c04-834f-d5374737a783 container test-container: <nil>
STEP: delete the pod
Aug 12 17:20:31.688: INFO: Waiting for pod pod-2737b2d6-6bc9-4c04-834f-d5374737a783 to disappear
Aug 12 17:20:31.692: INFO: Pod pod-2737b2d6-6bc9-4c04-834f-d5374737a783 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:20:31.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2718" for this suite.
Aug 12 17:20:37.713: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:20:37.871: INFO: namespace emptydir-2718 deletion completed in 6.174563756s

 [SLOW TEST:10.382 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:20:37.880: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-6097d014-67a2-430e-9ab1-4a34ff7e96c9
STEP: Creating a pod to test consume secrets
Aug 12 17:20:37.961: INFO: Waiting up to 5m0s for pod "pod-secrets-aa9d0d03-de61-4e78-a2ee-7644a124a374" in namespace "secrets-5933" to be "success or failure"
Aug 12 17:20:37.972: INFO: Pod "pod-secrets-aa9d0d03-de61-4e78-a2ee-7644a124a374": Phase="Pending", Reason="", readiness=false. Elapsed: 11.629506ms
Aug 12 17:20:39.979: INFO: Pod "pod-secrets-aa9d0d03-de61-4e78-a2ee-7644a124a374": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018335634s
Aug 12 17:20:41.987: INFO: Pod "pod-secrets-aa9d0d03-de61-4e78-a2ee-7644a124a374": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026633513s
STEP: Saw pod success
Aug 12 17:20:41.988: INFO: Pod "pod-secrets-aa9d0d03-de61-4e78-a2ee-7644a124a374" satisfied condition "success or failure"
Aug 12 17:20:41.994: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxfs pod pod-secrets-aa9d0d03-de61-4e78-a2ee-7644a124a374 container secret-env-test: <nil>
STEP: delete the pod
Aug 12 17:20:42.032: INFO: Waiting for pod pod-secrets-aa9d0d03-de61-4e78-a2ee-7644a124a374 to disappear
Aug 12 17:20:42.036: INFO: Pod pod-secrets-aa9d0d03-de61-4e78-a2ee-7644a124a374 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:20:42.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5933" for this suite.
Aug 12 17:20:48.059: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:20:48.221: INFO: namespace secrets-5933 deletion completed in 6.178124081s

 [SLOW TEST:10.342 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:20:48.229: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-df9ac7f7-c016-4897-8387-695ce92dd977
STEP: Creating a pod to test consume configMaps
Aug 12 17:20:48.299: INFO: Waiting up to 5m0s for pod "pod-configmaps-2d3d5454-ab32-414e-ba87-2558c98f7d9d" in namespace "configmap-1732" to be "success or failure"
Aug 12 17:20:48.310: INFO: Pod "pod-configmaps-2d3d5454-ab32-414e-ba87-2558c98f7d9d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.042584ms
Aug 12 17:20:50.317: INFO: Pod "pod-configmaps-2d3d5454-ab32-414e-ba87-2558c98f7d9d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017415643s
Aug 12 17:20:52.324: INFO: Pod "pod-configmaps-2d3d5454-ab32-414e-ba87-2558c98f7d9d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024121008s
STEP: Saw pod success
Aug 12 17:20:52.324: INFO: Pod "pod-configmaps-2d3d5454-ab32-414e-ba87-2558c98f7d9d" satisfied condition "success or failure"
Aug 12 17:20:52.329: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxfp pod pod-configmaps-2d3d5454-ab32-414e-ba87-2558c98f7d9d container configmap-volume-test: <nil>
STEP: delete the pod
Aug 12 17:20:52.371: INFO: Waiting for pod pod-configmaps-2d3d5454-ab32-414e-ba87-2558c98f7d9d to disappear
Aug 12 17:20:52.377: INFO: Pod pod-configmaps-2d3d5454-ab32-414e-ba87-2558c98f7d9d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:20:52.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1732" for this suite.
Aug 12 17:20:58.393: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:20:58.555: INFO: namespace configmap-1732 deletion completed in 6.174827881s

 [SLOW TEST:10.327 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:20:58.558: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 12 17:20:58.655: INFO: Create a RollingUpdate DaemonSet
Aug 12 17:20:58.663: INFO: Check that daemon pods launch on every node of the cluster
Aug 12 17:20:58.693: INFO: Number of nodes with available pods: 0
Aug 12 17:20:58.693: INFO: Node conformance-1-15-2-do-0-default-pool-rxf2 is running more than one daemon pod
Aug 12 17:21:00.125: INFO: Number of nodes with available pods: 0
Aug 12 17:21:00.125: INFO: Node conformance-1-15-2-do-0-default-pool-rxf2 is running more than one daemon pod
Aug 12 17:21:00.709: INFO: Number of nodes with available pods: 0
Aug 12 17:21:00.709: INFO: Node conformance-1-15-2-do-0-default-pool-rxf2 is running more than one daemon pod
Aug 12 17:21:01.712: INFO: Number of nodes with available pods: 3
Aug 12 17:21:01.713: INFO: Number of running nodes: 3, number of available pods: 3
Aug 12 17:21:01.713: INFO: Update the DaemonSet to trigger a rollout
Aug 12 17:21:01.731: INFO: Updating DaemonSet daemon-set
Aug 12 17:21:13.754: INFO: Roll back the DaemonSet before rollout is complete
Aug 12 17:21:13.774: INFO: Updating DaemonSet daemon-set
Aug 12 17:21:13.774: INFO: Make sure DaemonSet rollback is complete
Aug 12 17:21:13.783: INFO: Wrong image for pod: daemon-set-bbp9l. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Aug 12 17:21:13.783: INFO: Pod daemon-set-bbp9l is not available
Aug 12 17:21:14.792: INFO: Wrong image for pod: daemon-set-bbp9l. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Aug 12 17:21:14.793: INFO: Pod daemon-set-bbp9l is not available
Aug 12 17:21:15.795: INFO: Wrong image for pod: daemon-set-bbp9l. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Aug 12 17:21:15.796: INFO: Pod daemon-set-bbp9l is not available
Aug 12 17:21:16.793: INFO: Pod daemon-set-57wrl is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2064, will wait for the garbage collector to delete the pods
Aug 12 17:21:16.876: INFO: Deleting DaemonSet.extensions daemon-set took: 17.356901ms
Aug 12 17:21:17.276: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.316331ms
Aug 12 17:21:20.384: INFO: Number of nodes with available pods: 0
Aug 12 17:21:20.384: INFO: Number of running nodes: 0, number of available pods: 0
Aug 12 17:21:20.389: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2064/daemonsets","resourceVersion":"53644"},"items":null}

Aug 12 17:21:20.394: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2064/pods","resourceVersion":"53644"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:21:20.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2064" for this suite.
Aug 12 17:21:26.439: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:21:26.565: INFO: namespace daemonsets-2064 deletion completed in 6.143969592s

 [SLOW TEST:28.008 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:21:26.571: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-3810
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Aug 12 17:21:26.696: INFO: Found 1 stateful pods, waiting for 3
Aug 12 17:21:36.704: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 12 17:21:36.705: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 12 17:21:36.705: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Aug 12 17:21:36.720: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 exec --namespace=statefulset-3810 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 12 17:21:37.096: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 12 17:21:37.096: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 12 17:21:37.096: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Aug 12 17:21:47.152: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Aug 12 17:21:57.215: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 exec --namespace=statefulset-3810 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 12 17:21:57.593: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug 12 17:21:57.593: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 12 17:21:57.593: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 12 17:22:07.629: INFO: Waiting for StatefulSet statefulset-3810/ss2 to complete update
Aug 12 17:22:07.629: INFO: Waiting for Pod statefulset-3810/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Rolling back to a previous revision
Aug 12 17:22:17.643: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 exec --namespace=statefulset-3810 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 12 17:22:17.995: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 12 17:22:17.995: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 12 17:22:17.995: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 12 17:22:28.034: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Aug 12 17:22:38.076: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 exec --namespace=statefulset-3810 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 12 17:22:38.462: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug 12 17:22:38.462: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 12 17:22:38.462: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 12 17:22:49.065: INFO: Waiting for StatefulSet statefulset-3810/ss2 to complete update
Aug 12 17:22:49.065: INFO: Waiting for Pod statefulset-3810/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Aug 12 17:22:49.065: INFO: Waiting for Pod statefulset-3810/ss2-1 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Aug 12 17:22:59.074: INFO: Waiting for StatefulSet statefulset-3810/ss2 to complete update
Aug 12 17:22:59.074: INFO: Waiting for Pod statefulset-3810/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Aug 12 17:23:09.073: INFO: Deleting all statefulset in ns statefulset-3810
Aug 12 17:23:09.077: INFO: Scaling statefulset ss2 to 0
Aug 12 17:23:39.099: INFO: Waiting for statefulset status.replicas updated to 0
Aug 12 17:23:39.103: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:23:39.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3810" for this suite.
Aug 12 17:23:45.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:23:45.392: INFO: namespace statefulset-3810 deletion completed in 6.264648081s

 [SLOW TEST:138.822 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:23:45.400: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 12 17:24:05.561: INFO: Container started at 2019-08-12 17:23:47 +0000 UTC, pod became ready at 2019-08-12 17:24:04 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:24:05.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4449" for this suite.
Aug 12 17:24:27.587: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:24:27.728: INFO: namespace container-probe-4449 deletion completed in 22.159251471s

 [SLOW TEST:42.329 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:24:27.737: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:24:27.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6006" for this suite.
Aug 12 17:24:33.817: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:24:33.939: INFO: namespace services-6006 deletion completed in 6.145988539s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

 [SLOW TEST:6.203 seconds]
[sig-network] Services
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:24:33.951: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 12 17:24:34.015: INFO: Waiting up to 5m0s for pod "downwardapi-volume-290b1791-cdc2-463a-bd9e-38b0be4f799c" in namespace "projected-8347" to be "success or failure"
Aug 12 17:24:34.025: INFO: Pod "downwardapi-volume-290b1791-cdc2-463a-bd9e-38b0be4f799c": Phase="Pending", Reason="", readiness=false. Elapsed: 9.724325ms
Aug 12 17:24:36.035: INFO: Pod "downwardapi-volume-290b1791-cdc2-463a-bd9e-38b0be4f799c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019717923s
Aug 12 17:24:38.042: INFO: Pod "downwardapi-volume-290b1791-cdc2-463a-bd9e-38b0be4f799c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026522837s
STEP: Saw pod success
Aug 12 17:24:38.042: INFO: Pod "downwardapi-volume-290b1791-cdc2-463a-bd9e-38b0be4f799c" satisfied condition "success or failure"
Aug 12 17:24:38.045: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxf2 pod downwardapi-volume-290b1791-cdc2-463a-bd9e-38b0be4f799c container client-container: <nil>
STEP: delete the pod
Aug 12 17:24:38.084: INFO: Waiting for pod downwardapi-volume-290b1791-cdc2-463a-bd9e-38b0be4f799c to disappear
Aug 12 17:24:38.089: INFO: Pod downwardapi-volume-290b1791-cdc2-463a-bd9e-38b0be4f799c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:24:38.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8347" for this suite.
Aug 12 17:24:44.109: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:24:44.298: INFO: namespace projected-8347 deletion completed in 6.204304772s

 [SLOW TEST:10.347 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:24:44.307: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Aug 12 17:24:44.347: INFO: Waiting up to 5m0s for pod "pod-72e42420-e4e1-4c0d-a652-1041774bddaf" in namespace "emptydir-6833" to be "success or failure"
Aug 12 17:24:44.360: INFO: Pod "pod-72e42420-e4e1-4c0d-a652-1041774bddaf": Phase="Pending", Reason="", readiness=false. Elapsed: 12.45766ms
Aug 12 17:24:46.366: INFO: Pod "pod-72e42420-e4e1-4c0d-a652-1041774bddaf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018612752s
Aug 12 17:24:48.370: INFO: Pod "pod-72e42420-e4e1-4c0d-a652-1041774bddaf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022415278s
STEP: Saw pod success
Aug 12 17:24:48.370: INFO: Pod "pod-72e42420-e4e1-4c0d-a652-1041774bddaf" satisfied condition "success or failure"
Aug 12 17:24:48.376: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxfp pod pod-72e42420-e4e1-4c0d-a652-1041774bddaf container test-container: <nil>
STEP: delete the pod
Aug 12 17:24:48.419: INFO: Waiting for pod pod-72e42420-e4e1-4c0d-a652-1041774bddaf to disappear
Aug 12 17:24:48.423: INFO: Pod pod-72e42420-e4e1-4c0d-a652-1041774bddaf no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:24:48.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6833" for this suite.
Aug 12 17:24:54.471: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:24:54.629: INFO: namespace emptydir-6833 deletion completed in 6.19921097s

 [SLOW TEST:10.322 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:24:54.629: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-f38dd519-f72c-4025-86f2-f9d7b5b84c7e
STEP: Creating a pod to test consume secrets
Aug 12 17:24:54.810: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f4c5f2c8-5498-4945-a17f-fb78103338d8" in namespace "projected-8928" to be "success or failure"
Aug 12 17:24:54.819: INFO: Pod "pod-projected-secrets-f4c5f2c8-5498-4945-a17f-fb78103338d8": Phase="Pending", Reason="", readiness=false. Elapsed: 9.316301ms
Aug 12 17:24:56.826: INFO: Pod "pod-projected-secrets-f4c5f2c8-5498-4945-a17f-fb78103338d8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015674767s
Aug 12 17:24:58.833: INFO: Pod "pod-projected-secrets-f4c5f2c8-5498-4945-a17f-fb78103338d8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023612798s
STEP: Saw pod success
Aug 12 17:24:58.834: INFO: Pod "pod-projected-secrets-f4c5f2c8-5498-4945-a17f-fb78103338d8" satisfied condition "success or failure"
Aug 12 17:24:58.839: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxf2 pod pod-projected-secrets-f4c5f2c8-5498-4945-a17f-fb78103338d8 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 12 17:24:58.877: INFO: Waiting for pod pod-projected-secrets-f4c5f2c8-5498-4945-a17f-fb78103338d8 to disappear
Aug 12 17:24:58.880: INFO: Pod pod-projected-secrets-f4c5f2c8-5498-4945-a17f-fb78103338d8 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:24:58.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8928" for this suite.
Aug 12 17:25:04.898: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:25:05.093: INFO: namespace projected-8928 deletion completed in 6.207632194s

 [SLOW TEST:10.464 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:25:05.100: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 12 17:25:05.202: INFO: Creating deployment "nginx-deployment"
Aug 12 17:25:05.207: INFO: Waiting for observed generation 1
Aug 12 17:25:07.373: INFO: Waiting for all required pods to come up
Aug 12 17:25:07.410: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Aug 12 17:25:11.446: INFO: Waiting for deployment "nginx-deployment" to complete
Aug 12 17:25:11.454: INFO: Updating deployment "nginx-deployment" with a non-existent image
Aug 12 17:25:11.462: INFO: Updating deployment nginx-deployment
Aug 12 17:25:11.462: INFO: Waiting for observed generation 2
Aug 12 17:25:13.781: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Aug 12 17:25:14.021: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Aug 12 17:25:14.230: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Aug 12 17:25:14.275: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Aug 12 17:25:14.276: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Aug 12 17:25:14.293: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Aug 12 17:25:14.299: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Aug 12 17:25:14.299: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Aug 12 17:25:14.307: INFO: Updating deployment nginx-deployment
Aug 12 17:25:14.307: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Aug 12 17:25:14.390: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Aug 12 17:25:16.438: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Aug 12 17:25:16.449: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-1348,SelfLink:/apis/apps/v1/namespaces/deployment-1348/deployments/nginx-deployment,UID:49b6ef46-af93-4e8b-b2ba-513db396d3c4,ResourceVersion:55058,Generation:3,CreationTimestamp:2019-08-12 17:25:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-08-12 17:25:14 +0000 UTC 2019-08-12 17:25:14 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-08-12 17:25:14 +0000 UTC 2019-08-12 17:25:05 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-55fb7cb77f" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Aug 12 17:25:16.481: INFO: New ReplicaSet "nginx-deployment-55fb7cb77f" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f,GenerateName:,Namespace:deployment-1348,SelfLink:/apis/apps/v1/namespaces/deployment-1348/replicasets/nginx-deployment-55fb7cb77f,UID:b7c94e05-9c2d-4267-9f22-4e1ed716a6e4,ResourceVersion:55049,Generation:3,CreationTimestamp:2019-08-12 17:25:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 49b6ef46-af93-4e8b-b2ba-513db396d3c4 0xc00235b987 0xc00235b988}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 12 17:25:16.482: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Aug 12 17:25:16.482: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498,GenerateName:,Namespace:deployment-1348,SelfLink:/apis/apps/v1/namespaces/deployment-1348/replicasets/nginx-deployment-7b8c6f4498,UID:ca7acd2b-baa2-47a3-86f8-5346a5ce9dc1,ResourceVersion:55056,Generation:3,CreationTimestamp:2019-08-12 17:25:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 49b6ef46-af93-4e8b-b2ba-513db396d3c4 0xc00235ba57 0xc00235ba58}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Aug 12 17:25:16.528: INFO: Pod "nginx-deployment-55fb7cb77f-58kjv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-58kjv,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1348,SelfLink:/api/v1/namespaces/deployment-1348/pods/nginx-deployment-55fb7cb77f-58kjv,UID:b35e7353-ec7e-4ebb-abc1-d404c91a017c,ResourceVersion:55092,Generation:0,CreationTimestamp:2019-08-12 17:25:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f b7c94e05-9c2d-4267-9f22-4e1ed716a6e4 0xc002b36427 0xc002b36428}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tn68h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tn68h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tn68h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-1-15-2-do-0-default-pool-rxfs,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b36490} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b364b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC  }],Message:,Reason:,HostIP:10.138.175.210,PodIP:,StartTime:2019-08-12 17:25:14 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 12 17:25:16.528: INFO: Pod "nginx-deployment-55fb7cb77f-72gk4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-72gk4,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1348,SelfLink:/api/v1/namespaces/deployment-1348/pods/nginx-deployment-55fb7cb77f-72gk4,UID:f7895204-5418-4a60-b85e-7126c74f6480,ResourceVersion:54956,Generation:0,CreationTimestamp:2019-08-12 17:25:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f b7c94e05-9c2d-4267-9f22-4e1ed716a6e4 0xc002b36700 0xc002b36701}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tn68h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tn68h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tn68h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-1-15-2-do-0-default-pool-rxfp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b367c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b367e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:11 +0000 UTC  }],Message:,Reason:,HostIP:10.138.15.72,PodIP:,StartTime:2019-08-12 17:25:11 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 12 17:25:16.529: INFO: Pod "nginx-deployment-55fb7cb77f-bnrvg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-bnrvg,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1348,SelfLink:/api/v1/namespaces/deployment-1348/pods/nginx-deployment-55fb7cb77f-bnrvg,UID:f602cb5a-074f-48b4-a00a-574f5890380d,ResourceVersion:54942,Generation:0,CreationTimestamp:2019-08-12 17:25:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f b7c94e05-9c2d-4267-9f22-4e1ed716a6e4 0xc002b369c0 0xc002b369c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tn68h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tn68h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tn68h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-1-15-2-do-0-default-pool-rxfs,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b36aa0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b36ac0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:11 +0000 UTC  }],Message:,Reason:,HostIP:10.138.175.210,PodIP:,StartTime:2019-08-12 17:25:11 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 12 17:25:16.529: INFO: Pod "nginx-deployment-55fb7cb77f-d2wb6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-d2wb6,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1348,SelfLink:/api/v1/namespaces/deployment-1348/pods/nginx-deployment-55fb7cb77f-d2wb6,UID:7f5e4738-8b0e-45e1-aa92-11d26a68a821,ResourceVersion:54959,Generation:0,CreationTimestamp:2019-08-12 17:25:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f b7c94e05-9c2d-4267-9f22-4e1ed716a6e4 0xc002b36c70 0xc002b36c71}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tn68h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tn68h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tn68h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-1-15-2-do-0-default-pool-rxfs,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b36e90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b36eb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:11 +0000 UTC  }],Message:,Reason:,HostIP:10.138.175.210,PodIP:,StartTime:2019-08-12 17:25:11 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 12 17:25:16.529: INFO: Pod "nginx-deployment-55fb7cb77f-fnh2x" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-fnh2x,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1348,SelfLink:/api/v1/namespaces/deployment-1348/pods/nginx-deployment-55fb7cb77f-fnh2x,UID:eca179ab-8326-4ad8-a185-66c36f5edd27,ResourceVersion:55078,Generation:0,CreationTimestamp:2019-08-12 17:25:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f b7c94e05-9c2d-4267-9f22-4e1ed716a6e4 0xc002b37010 0xc002b37011}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tn68h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tn68h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tn68h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-1-15-2-do-0-default-pool-rxfp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b37080} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b370a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC  }],Message:,Reason:,HostIP:10.138.15.72,PodIP:,StartTime:2019-08-12 17:25:14 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 12 17:25:16.529: INFO: Pod "nginx-deployment-55fb7cb77f-hg5ml" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-hg5ml,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1348,SelfLink:/api/v1/namespaces/deployment-1348/pods/nginx-deployment-55fb7cb77f-hg5ml,UID:e0fffc5d-2d1b-40b8-b306-bf55f68caae1,ResourceVersion:55077,Generation:0,CreationTimestamp:2019-08-12 17:25:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f b7c94e05-9c2d-4267-9f22-4e1ed716a6e4 0xc002b372e0 0xc002b372e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tn68h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tn68h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tn68h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-1-15-2-do-0-default-pool-rxf2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b37400} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b374a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC  }],Message:,Reason:,HostIP:10.138.15.94,PodIP:,StartTime:2019-08-12 17:25:14 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 12 17:25:16.529: INFO: Pod "nginx-deployment-55fb7cb77f-l8rvp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-l8rvp,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1348,SelfLink:/api/v1/namespaces/deployment-1348/pods/nginx-deployment-55fb7cb77f-l8rvp,UID:7da90894-709d-48eb-8e72-f131d54a29f3,ResourceVersion:55097,Generation:0,CreationTimestamp:2019-08-12 17:25:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f b7c94e05-9c2d-4267-9f22-4e1ed716a6e4 0xc002b375a0 0xc002b375a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tn68h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tn68h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tn68h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-1-15-2-do-0-default-pool-rxfp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b37610} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b37630}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC  }],Message:,Reason:,HostIP:10.138.15.72,PodIP:,StartTime:2019-08-12 17:25:14 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 12 17:25:16.530: INFO: Pod "nginx-deployment-55fb7cb77f-mmj5m" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-mmj5m,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1348,SelfLink:/api/v1/namespaces/deployment-1348/pods/nginx-deployment-55fb7cb77f-mmj5m,UID:c69fab78-6815-4d3a-a4ef-28c780858a05,ResourceVersion:55090,Generation:0,CreationTimestamp:2019-08-12 17:25:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f b7c94e05-9c2d-4267-9f22-4e1ed716a6e4 0xc002b37910 0xc002b37911}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tn68h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tn68h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tn68h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-1-15-2-do-0-default-pool-rxf2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b37990} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b379b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC  }],Message:,Reason:,HostIP:10.138.15.94,PodIP:,StartTime:2019-08-12 17:25:14 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 12 17:25:16.530: INFO: Pod "nginx-deployment-55fb7cb77f-rhr8j" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-rhr8j,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1348,SelfLink:/api/v1/namespaces/deployment-1348/pods/nginx-deployment-55fb7cb77f-rhr8j,UID:50a4f241-b561-4c59-8675-91ab9a566f02,ResourceVersion:55081,Generation:0,CreationTimestamp:2019-08-12 17:25:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f b7c94e05-9c2d-4267-9f22-4e1ed716a6e4 0xc002b37c40 0xc002b37c41}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tn68h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tn68h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tn68h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-1-15-2-do-0-default-pool-rxfs,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002b37d90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002b37db0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC  }],Message:,Reason:,HostIP:10.138.175.210,PodIP:,StartTime:2019-08-12 17:25:14 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 12 17:25:16.531: INFO: Pod "nginx-deployment-55fb7cb77f-sl548" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-sl548,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1348,SelfLink:/api/v1/namespaces/deployment-1348/pods/nginx-deployment-55fb7cb77f-sl548,UID:aea95e55-6d87-43a8-a18e-dc365a018afc,ResourceVersion:54930,Generation:0,CreationTimestamp:2019-08-12 17:25:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f b7c94e05-9c2d-4267-9f22-4e1ed716a6e4 0xc002b37f30 0xc002b37f31}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tn68h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tn68h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tn68h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-1-15-2-do-0-default-pool-rxfp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ed80e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ed8100}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:11 +0000 UTC  }],Message:,Reason:,HostIP:10.138.15.72,PodIP:,StartTime:2019-08-12 17:25:11 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 12 17:25:16.532: INFO: Pod "nginx-deployment-55fb7cb77f-t67wd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-t67wd,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1348,SelfLink:/api/v1/namespaces/deployment-1348/pods/nginx-deployment-55fb7cb77f-t67wd,UID:4e276efa-80c3-4fda-b9d8-278cf50c3c60,ResourceVersion:55071,Generation:0,CreationTimestamp:2019-08-12 17:25:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f b7c94e05-9c2d-4267-9f22-4e1ed716a6e4 0xc001ed82e0 0xc001ed82e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tn68h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tn68h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tn68h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-1-15-2-do-0-default-pool-rxfp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ed8360} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ed8380}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC  }],Message:,Reason:,HostIP:10.138.15.72,PodIP:,StartTime:2019-08-12 17:25:14 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 12 17:25:16.537: INFO: Pod "nginx-deployment-55fb7cb77f-tct2h" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-tct2h,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1348,SelfLink:/api/v1/namespaces/deployment-1348/pods/nginx-deployment-55fb7cb77f-tct2h,UID:a9a4a0e5-dd8b-4155-9514-48a469d47aea,ResourceVersion:54933,Generation:0,CreationTimestamp:2019-08-12 17:25:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f b7c94e05-9c2d-4267-9f22-4e1ed716a6e4 0xc001ed8470 0xc001ed8471}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tn68h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tn68h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tn68h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-1-15-2-do-0-default-pool-rxf2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ed84f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ed8510}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:11 +0000 UTC  }],Message:,Reason:,HostIP:10.138.15.94,PodIP:,StartTime:2019-08-12 17:25:11 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 12 17:25:16.537: INFO: Pod "nginx-deployment-55fb7cb77f-tmv45" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-tmv45,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1348,SelfLink:/api/v1/namespaces/deployment-1348/pods/nginx-deployment-55fb7cb77f-tmv45,UID:a3a5e218-0bdb-4608-b7c8-d7b24519e607,ResourceVersion:55070,Generation:0,CreationTimestamp:2019-08-12 17:25:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f b7c94e05-9c2d-4267-9f22-4e1ed716a6e4 0xc001ed85e0 0xc001ed85e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tn68h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tn68h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tn68h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-1-15-2-do-0-default-pool-rxf2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ed8660} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ed8680}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC  }],Message:,Reason:,HostIP:10.138.15.94,PodIP:,StartTime:2019-08-12 17:25:14 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 12 17:25:16.537: INFO: Pod "nginx-deployment-7b8c6f4498-244mj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-244mj,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1348,SelfLink:/api/v1/namespaces/deployment-1348/pods/nginx-deployment-7b8c6f4498-244mj,UID:130ba5c6-6132-48a9-91fa-338c1c67f15c,ResourceVersion:55110,Generation:0,CreationTimestamp:2019-08-12 17:25:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ca7acd2b-baa2-47a3-86f8-5346a5ce9dc1 0xc001ed8750 0xc001ed8751}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tn68h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tn68h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tn68h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-1-15-2-do-0-default-pool-rxf2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ed87b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ed87d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC  }],Message:,Reason:,HostIP:10.138.15.94,PodIP:,StartTime:2019-08-12 17:25:14 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 12 17:25:16.537: INFO: Pod "nginx-deployment-7b8c6f4498-8qt4x" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-8qt4x,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1348,SelfLink:/api/v1/namespaces/deployment-1348/pods/nginx-deployment-7b8c6f4498-8qt4x,UID:efe24764-0a44-47f4-85fb-fd4e18ab56ca,ResourceVersion:54891,Generation:0,CreationTimestamp:2019-08-12 17:25:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ca7acd2b-baa2-47a3-86f8-5346a5ce9dc1 0xc001ed8897 0xc001ed8898}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tn68h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tn68h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tn68h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-1-15-2-do-0-default-pool-rxfp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ed8900} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ed8920}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:05 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:10 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:10 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:05 +0000 UTC  }],Message:,Reason:,HostIP:10.138.15.72,PodIP:10.244.1.235,StartTime:2019-08-12 17:25:05 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-12 17:25:09 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://6e8216e681ffb61e6bbc3412f81824a6cb901b74b7dd9c823d08b31928832188}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 12 17:25:16.541: INFO: Pod "nginx-deployment-7b8c6f4498-8rv6b" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-8rv6b,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1348,SelfLink:/api/v1/namespaces/deployment-1348/pods/nginx-deployment-7b8c6f4498-8rv6b,UID:973516f1-21e9-487c-bcca-ee9dc92e2ab8,ResourceVersion:55029,Generation:0,CreationTimestamp:2019-08-12 17:25:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ca7acd2b-baa2-47a3-86f8-5346a5ce9dc1 0xc001ed89f7 0xc001ed89f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tn68h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tn68h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tn68h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-1-15-2-do-0-default-pool-rxf2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ed8a60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ed8a80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC  }],Message:,Reason:,HostIP:10.138.15.94,PodIP:,StartTime:2019-08-12 17:25:14 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 12 17:25:16.541: INFO: Pod "nginx-deployment-7b8c6f4498-8z867" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-8z867,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1348,SelfLink:/api/v1/namespaces/deployment-1348/pods/nginx-deployment-7b8c6f4498-8z867,UID:40ff0a22-5d51-4717-86aa-5c0b29ee0c5c,ResourceVersion:55059,Generation:0,CreationTimestamp:2019-08-12 17:25:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ca7acd2b-baa2-47a3-86f8-5346a5ce9dc1 0xc001ed8b47 0xc001ed8b48}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tn68h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tn68h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tn68h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-1-15-2-do-0-default-pool-rxfs,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ed8bb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ed8bd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC  }],Message:,Reason:,HostIP:10.138.175.210,PodIP:,StartTime:2019-08-12 17:25:14 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 12 17:25:16.541: INFO: Pod "nginx-deployment-7b8c6f4498-bsqjw" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-bsqjw,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1348,SelfLink:/api/v1/namespaces/deployment-1348/pods/nginx-deployment-7b8c6f4498-bsqjw,UID:98e81efd-7112-4e6d-b7f4-ae56f43ec786,ResourceVersion:54857,Generation:0,CreationTimestamp:2019-08-12 17:25:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ca7acd2b-baa2-47a3-86f8-5346a5ce9dc1 0xc001ed8c97 0xc001ed8c98}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tn68h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tn68h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tn68h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-1-15-2-do-0-default-pool-rxfs,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ed8d00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ed8d20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:05 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:09 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:09 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:05 +0000 UTC  }],Message:,Reason:,HostIP:10.138.175.210,PodIP:10.244.0.151,StartTime:2019-08-12 17:25:05 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-12 17:25:08 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://1deb0a51f42394ed584fca38c8889d9b61fae683805b84709f901a332cb98115}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 12 17:25:16.541: INFO: Pod "nginx-deployment-7b8c6f4498-g2m68" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-g2m68,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1348,SelfLink:/api/v1/namespaces/deployment-1348/pods/nginx-deployment-7b8c6f4498-g2m68,UID:628f1aef-dcb9-45bc-9ff9-0ae603fa0cca,ResourceVersion:55095,Generation:0,CreationTimestamp:2019-08-12 17:25:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ca7acd2b-baa2-47a3-86f8-5346a5ce9dc1 0xc001ed8df7 0xc001ed8df8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tn68h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tn68h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tn68h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-1-15-2-do-0-default-pool-rxf2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ed8e60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ed8e80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC  }],Message:,Reason:,HostIP:10.138.15.94,PodIP:,StartTime:2019-08-12 17:25:14 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 12 17:25:16.541: INFO: Pod "nginx-deployment-7b8c6f4498-h2w25" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-h2w25,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1348,SelfLink:/api/v1/namespaces/deployment-1348/pods/nginx-deployment-7b8c6f4498-h2w25,UID:12bee280-ad9b-4fcb-99e4-36bc8d97e44d,ResourceVersion:55062,Generation:0,CreationTimestamp:2019-08-12 17:25:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ca7acd2b-baa2-47a3-86f8-5346a5ce9dc1 0xc001ed8f47 0xc001ed8f48}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tn68h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tn68h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tn68h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-1-15-2-do-0-default-pool-rxfp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ed8fb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ed8fd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC  }],Message:,Reason:,HostIP:10.138.15.72,PodIP:,StartTime:2019-08-12 17:25:14 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 12 17:25:16.542: INFO: Pod "nginx-deployment-7b8c6f4498-lqhgl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-lqhgl,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1348,SelfLink:/api/v1/namespaces/deployment-1348/pods/nginx-deployment-7b8c6f4498-lqhgl,UID:fa9cd290-56db-44a1-8827-c563ed337166,ResourceVersion:55028,Generation:0,CreationTimestamp:2019-08-12 17:25:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ca7acd2b-baa2-47a3-86f8-5346a5ce9dc1 0xc001ed9097 0xc001ed9098}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tn68h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tn68h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tn68h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-1-15-2-do-0-default-pool-rxfp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ed9100} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ed9120}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC  }],Message:,Reason:,HostIP:10.138.15.72,PodIP:,StartTime:2019-08-12 17:25:14 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 12 17:25:16.542: INFO: Pod "nginx-deployment-7b8c6f4498-lws57" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-lws57,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1348,SelfLink:/api/v1/namespaces/deployment-1348/pods/nginx-deployment-7b8c6f4498-lws57,UID:d7148575-6042-46c2-8cba-e96cb30feabe,ResourceVersion:54904,Generation:0,CreationTimestamp:2019-08-12 17:25:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ca7acd2b-baa2-47a3-86f8-5346a5ce9dc1 0xc001ed91e7 0xc001ed91e8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tn68h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tn68h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tn68h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-1-15-2-do-0-default-pool-rxf2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ed9250} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ed9270}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:05 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:11 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:11 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:05 +0000 UTC  }],Message:,Reason:,HostIP:10.138.15.94,PodIP:10.244.2.103,StartTime:2019-08-12 17:25:05 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-12 17:25:10 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://8872d40c8ebfb707582bc41b542526bad45ee0e4eb9b99a19a01fcbe74db58c7}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 12 17:25:16.542: INFO: Pod "nginx-deployment-7b8c6f4498-m27b8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-m27b8,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1348,SelfLink:/api/v1/namespaces/deployment-1348/pods/nginx-deployment-7b8c6f4498-m27b8,UID:9faa1c55-fde4-4971-9825-e14507a9be18,ResourceVersion:55069,Generation:0,CreationTimestamp:2019-08-12 17:25:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ca7acd2b-baa2-47a3-86f8-5346a5ce9dc1 0xc001ed9377 0xc001ed9378}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tn68h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tn68h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tn68h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-1-15-2-do-0-default-pool-rxfs,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ed93e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ed9400}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC  }],Message:,Reason:,HostIP:10.138.175.210,PodIP:,StartTime:2019-08-12 17:25:14 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 12 17:25:16.542: INFO: Pod "nginx-deployment-7b8c6f4498-mhzsx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-mhzsx,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1348,SelfLink:/api/v1/namespaces/deployment-1348/pods/nginx-deployment-7b8c6f4498-mhzsx,UID:16400681-297f-4a2c-9a83-41c50b362827,ResourceVersion:55083,Generation:0,CreationTimestamp:2019-08-12 17:25:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ca7acd2b-baa2-47a3-86f8-5346a5ce9dc1 0xc001ed94c7 0xc001ed94c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tn68h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tn68h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tn68h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-1-15-2-do-0-default-pool-rxfp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ed9530} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ed9550}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC  }],Message:,Reason:,HostIP:10.138.15.72,PodIP:,StartTime:2019-08-12 17:25:14 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 12 17:25:16.543: INFO: Pod "nginx-deployment-7b8c6f4498-n7xl6" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-n7xl6,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1348,SelfLink:/api/v1/namespaces/deployment-1348/pods/nginx-deployment-7b8c6f4498-n7xl6,UID:d3fbea65-c782-4ae5-9fae-2778909cb093,ResourceVersion:54876,Generation:0,CreationTimestamp:2019-08-12 17:25:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ca7acd2b-baa2-47a3-86f8-5346a5ce9dc1 0xc001ed9617 0xc001ed9618}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tn68h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tn68h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tn68h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-1-15-2-do-0-default-pool-rxfs,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ed9680} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ed96a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:05 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:10 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:10 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:05 +0000 UTC  }],Message:,Reason:,HostIP:10.138.175.210,PodIP:10.244.0.184,StartTime:2019-08-12 17:25:05 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-12 17:25:09 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://ae4693e7295954880779e9e69a1eaaee8aad61a108d02b9b1c8f0a065ebe4ece}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 12 17:25:16.544: INFO: Pod "nginx-deployment-7b8c6f4498-pb4q6" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-pb4q6,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1348,SelfLink:/api/v1/namespaces/deployment-1348/pods/nginx-deployment-7b8c6f4498-pb4q6,UID:377fd116-ec72-4059-8bae-d832af560383,ResourceVersion:54889,Generation:0,CreationTimestamp:2019-08-12 17:25:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ca7acd2b-baa2-47a3-86f8-5346a5ce9dc1 0xc001ed9777 0xc001ed9778}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tn68h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tn68h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tn68h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-1-15-2-do-0-default-pool-rxfp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ed97e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ed9800}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:05 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:10 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:10 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:05 +0000 UTC  }],Message:,Reason:,HostIP:10.138.15.72,PodIP:10.244.1.228,StartTime:2019-08-12 17:25:05 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-12 17:25:09 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://472eb7e8c04b6966b964c41c447e5fef302756e6290770378937b3a7f626183c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 12 17:25:16.544: INFO: Pod "nginx-deployment-7b8c6f4498-qq28k" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-qq28k,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1348,SelfLink:/api/v1/namespaces/deployment-1348/pods/nginx-deployment-7b8c6f4498-qq28k,UID:d10aa094-7d45-4cf1-89bd-e4c91337d243,ResourceVersion:55084,Generation:0,CreationTimestamp:2019-08-12 17:25:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ca7acd2b-baa2-47a3-86f8-5346a5ce9dc1 0xc001ed98d7 0xc001ed98d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tn68h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tn68h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tn68h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-1-15-2-do-0-default-pool-rxf2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ed9940} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ed9960}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC  }],Message:,Reason:,HostIP:10.138.15.94,PodIP:,StartTime:2019-08-12 17:25:14 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 12 17:25:16.545: INFO: Pod "nginx-deployment-7b8c6f4498-rc2h4" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-rc2h4,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1348,SelfLink:/api/v1/namespaces/deployment-1348/pods/nginx-deployment-7b8c6f4498-rc2h4,UID:e7c85429-58e3-4b85-b72c-bdc811f02ec3,ResourceVersion:54895,Generation:0,CreationTimestamp:2019-08-12 17:25:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ca7acd2b-baa2-47a3-86f8-5346a5ce9dc1 0xc001ed9a47 0xc001ed9a48}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tn68h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tn68h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tn68h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-1-15-2-do-0-default-pool-rxfs,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ed9ae0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ed9b00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:05 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:11 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:11 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:05 +0000 UTC  }],Message:,Reason:,HostIP:10.138.175.210,PodIP:10.244.0.11,StartTime:2019-08-12 17:25:05 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-12 17:25:10 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://ac26053f31498b9528f29f4ee45fa4601b1407243489bfe9a7cd5db4b68406c7}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 12 17:25:16.545: INFO: Pod "nginx-deployment-7b8c6f4498-rhk4v" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-rhk4v,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1348,SelfLink:/api/v1/namespaces/deployment-1348/pods/nginx-deployment-7b8c6f4498-rhk4v,UID:f2f5e21c-eeff-4929-af11-e9ec3d653dca,ResourceVersion:55050,Generation:0,CreationTimestamp:2019-08-12 17:25:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ca7acd2b-baa2-47a3-86f8-5346a5ce9dc1 0xc001ed9db0 0xc001ed9db1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tn68h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tn68h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tn68h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-1-15-2-do-0-default-pool-rxfp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ed9e40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ed9e90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC  }],Message:,Reason:,HostIP:10.138.15.72,PodIP:,StartTime:2019-08-12 17:25:14 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 12 17:25:16.546: INFO: Pod "nginx-deployment-7b8c6f4498-rwq4t" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-rwq4t,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1348,SelfLink:/api/v1/namespaces/deployment-1348/pods/nginx-deployment-7b8c6f4498-rwq4t,UID:926f5eb8-d379-421a-9a45-b8361a66fb33,ResourceVersion:55089,Generation:0,CreationTimestamp:2019-08-12 17:25:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ca7acd2b-baa2-47a3-86f8-5346a5ce9dc1 0xc002f9a027 0xc002f9a028}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tn68h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tn68h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tn68h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-1-15-2-do-0-default-pool-rxfs,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f9a090} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f9a0b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC  }],Message:,Reason:,HostIP:10.138.175.210,PodIP:,StartTime:2019-08-12 17:25:14 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 12 17:25:16.546: INFO: Pod "nginx-deployment-7b8c6f4498-tfshd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-tfshd,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1348,SelfLink:/api/v1/namespaces/deployment-1348/pods/nginx-deployment-7b8c6f4498-tfshd,UID:78032b8a-6f3e-4be8-b5ec-fbfd2800c51f,ResourceVersion:55048,Generation:0,CreationTimestamp:2019-08-12 17:25:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ca7acd2b-baa2-47a3-86f8-5346a5ce9dc1 0xc002f9a177 0xc002f9a178}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tn68h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tn68h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tn68h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-1-15-2-do-0-default-pool-rxf2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f9a1f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f9a210}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:14 +0000 UTC  }],Message:,Reason:,HostIP:10.138.15.94,PodIP:,StartTime:2019-08-12 17:25:14 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 12 17:25:16.547: INFO: Pod "nginx-deployment-7b8c6f4498-w8xwq" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-w8xwq,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1348,SelfLink:/api/v1/namespaces/deployment-1348/pods/nginx-deployment-7b8c6f4498-w8xwq,UID:1b5c672b-ab43-4f54-9eb2-32dfba8810dd,ResourceVersion:54868,Generation:0,CreationTimestamp:2019-08-12 17:25:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ca7acd2b-baa2-47a3-86f8-5346a5ce9dc1 0xc002f9a2f7 0xc002f9a2f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tn68h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tn68h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tn68h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-1-15-2-do-0-default-pool-rxfp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f9a360} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f9a380}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:05 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:09 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:09 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:05 +0000 UTC  }],Message:,Reason:,HostIP:10.138.15.72,PodIP:10.244.1.206,StartTime:2019-08-12 17:25:05 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-12 17:25:08 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://7840e852713f4df9adf35eb1d1484077e225fb39ec8df0c8e6f8dc8e5f558f71}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 12 17:25:16.548: INFO: Pod "nginx-deployment-7b8c6f4498-zkqdd" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-zkqdd,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1348,SelfLink:/api/v1/namespaces/deployment-1348/pods/nginx-deployment-7b8c6f4498-zkqdd,UID:6810a8b0-aa07-469d-9091-c426efbde644,ResourceVersion:54907,Generation:0,CreationTimestamp:2019-08-12 17:25:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 ca7acd2b-baa2-47a3-86f8-5346a5ce9dc1 0xc002f9a487 0xc002f9a488}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tn68h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tn68h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tn68h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-1-15-2-do-0-default-pool-rxf2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f9a510} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f9a530}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:05 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:11 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:11 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:25:05 +0000 UTC  }],Message:,Reason:,HostIP:10.138.15.94,PodIP:10.244.2.209,StartTime:2019-08-12 17:25:05 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-12 17:25:10 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://946ff855c171576877b572812e23641743e514aa4faad272a144b32830b85204}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:25:16.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1348" for this suite.
Aug 12 17:25:28.690: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:25:30.075: INFO: namespace deployment-1348 deletion completed in 13.522266487s

 [SLOW TEST:25.275 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:25:31.367: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-1ffd4c3c-e665-4fa3-835e-65d3a3a1c013
STEP: Creating a pod to test consume configMaps
Aug 12 17:25:31.576: INFO: Waiting up to 5m0s for pod "pod-configmaps-2681338d-2e5f-4490-952b-02f549df255b" in namespace "configmap-1281" to be "success or failure"
Aug 12 17:25:31.647: INFO: Pod "pod-configmaps-2681338d-2e5f-4490-952b-02f549df255b": Phase="Pending", Reason="", readiness=false. Elapsed: 70.080233ms
Aug 12 17:25:33.653: INFO: Pod "pod-configmaps-2681338d-2e5f-4490-952b-02f549df255b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.076717535s
Aug 12 17:25:35.658: INFO: Pod "pod-configmaps-2681338d-2e5f-4490-952b-02f549df255b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.081045952s
STEP: Saw pod success
Aug 12 17:25:35.658: INFO: Pod "pod-configmaps-2681338d-2e5f-4490-952b-02f549df255b" satisfied condition "success or failure"
Aug 12 17:25:35.662: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxf2 pod pod-configmaps-2681338d-2e5f-4490-952b-02f549df255b container configmap-volume-test: <nil>
STEP: delete the pod
Aug 12 17:25:35.698: INFO: Waiting for pod pod-configmaps-2681338d-2e5f-4490-952b-02f549df255b to disappear
Aug 12 17:25:35.703: INFO: Pod pod-configmaps-2681338d-2e5f-4490-952b-02f549df255b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:25:35.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1281" for this suite.
Aug 12 17:25:41.727: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:25:41.880: INFO: namespace configmap-1281 deletion completed in 6.169187305s

 [SLOW TEST:10.514 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:25:41.887: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Aug 12 17:25:47.057: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:25:47.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-690" for this suite.
Aug 12 17:26:09.129: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:26:09.252: INFO: namespace replicaset-690 deletion completed in 22.146605376s

 [SLOW TEST:27.366 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:26:09.255: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Aug 12 17:26:09.355: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 create -f - --namespace=kubectl-356'
Aug 12 17:26:09.914: INFO: stderr: ""
Aug 12 17:26:09.914: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Aug 12 17:26:10.920: INFO: Selector matched 1 pods for map[app:redis]
Aug 12 17:26:10.920: INFO: Found 0 / 1
Aug 12 17:26:11.920: INFO: Selector matched 1 pods for map[app:redis]
Aug 12 17:26:11.920: INFO: Found 0 / 1
Aug 12 17:26:12.921: INFO: Selector matched 1 pods for map[app:redis]
Aug 12 17:26:12.921: INFO: Found 1 / 1
Aug 12 17:26:12.921: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Aug 12 17:26:12.924: INFO: Selector matched 1 pods for map[app:redis]
Aug 12 17:26:12.924: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug 12 17:26:12.924: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 patch pod redis-master-gv6h7 --namespace=kubectl-356 -p {"metadata":{"annotations":{"x":"y"}}}'
Aug 12 17:26:13.034: INFO: stderr: ""
Aug 12 17:26:13.034: INFO: stdout: "pod/redis-master-gv6h7 patched\n"
STEP: checking annotations
Aug 12 17:26:13.039: INFO: Selector matched 1 pods for map[app:redis]
Aug 12 17:26:13.039: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:26:13.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-356" for this suite.
Aug 12 17:26:35.067: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:26:35.278: INFO: namespace kubectl-356 deletion completed in 22.231478774s

 [SLOW TEST:26.023 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:26:35.293: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's args
Aug 12 17:26:35.351: INFO: Waiting up to 5m0s for pod "var-expansion-7248637d-2044-472f-9b5f-f1d460382a4e" in namespace "var-expansion-9964" to be "success or failure"
Aug 12 17:26:35.362: INFO: Pod "var-expansion-7248637d-2044-472f-9b5f-f1d460382a4e": Phase="Pending", Reason="", readiness=false. Elapsed: 10.768471ms
Aug 12 17:26:37.367: INFO: Pod "var-expansion-7248637d-2044-472f-9b5f-f1d460382a4e": Phase="Running", Reason="", readiness=true. Elapsed: 2.015844114s
Aug 12 17:26:39.372: INFO: Pod "var-expansion-7248637d-2044-472f-9b5f-f1d460382a4e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021037949s
STEP: Saw pod success
Aug 12 17:26:39.373: INFO: Pod "var-expansion-7248637d-2044-472f-9b5f-f1d460382a4e" satisfied condition "success or failure"
Aug 12 17:26:39.375: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxfs pod var-expansion-7248637d-2044-472f-9b5f-f1d460382a4e container dapi-container: <nil>
STEP: delete the pod
Aug 12 17:26:39.407: INFO: Waiting for pod var-expansion-7248637d-2044-472f-9b5f-f1d460382a4e to disappear
Aug 12 17:26:39.413: INFO: Pod var-expansion-7248637d-2044-472f-9b5f-f1d460382a4e no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:26:39.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-9964" for this suite.
Aug 12 17:26:45.436: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:26:45.599: INFO: namespace var-expansion-9964 deletion completed in 6.179927483s

 [SLOW TEST:10.306 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:26:45.604: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 12 17:26:45.662: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 create -f - --namespace=kubectl-2554'
Aug 12 17:26:45.950: INFO: stderr: ""
Aug 12 17:26:45.950: INFO: stdout: "replicationcontroller/redis-master created\n"
Aug 12 17:26:45.951: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 create -f - --namespace=kubectl-2554'
Aug 12 17:26:46.575: INFO: stderr: ""
Aug 12 17:26:46.575: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Aug 12 17:26:47.579: INFO: Selector matched 1 pods for map[app:redis]
Aug 12 17:26:47.580: INFO: Found 0 / 1
Aug 12 17:26:48.652: INFO: Selector matched 1 pods for map[app:redis]
Aug 12 17:26:48.652: INFO: Found 0 / 1
Aug 12 17:26:49.583: INFO: Selector matched 1 pods for map[app:redis]
Aug 12 17:26:49.583: INFO: Found 0 / 1
Aug 12 17:26:50.581: INFO: Selector matched 1 pods for map[app:redis]
Aug 12 17:26:50.581: INFO: Found 1 / 1
Aug 12 17:26:50.581: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug 12 17:26:50.586: INFO: Selector matched 1 pods for map[app:redis]
Aug 12 17:26:50.586: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug 12 17:26:50.586: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 describe pod redis-master-8t2z7 --namespace=kubectl-2554'
Aug 12 17:26:51.029: INFO: stderr: ""
Aug 12 17:26:51.029: INFO: stdout: "Name:           redis-master-8t2z7\nNamespace:      kubectl-2554\nPriority:       0\nNode:           conformance-1-15-2-do-0-default-pool-rxfp/10.138.15.72\nStart Time:     Mon, 12 Aug 2019 17:26:45 +0000\nLabels:         app=redis\n                role=master\nAnnotations:    <none>\nStatus:         Running\nIP:             10.244.1.68\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://5864f8ff55835c7585aa9bd9067330aaad2ef70ada7180ddf9cd384af49aedf3\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 12 Aug 2019 17:26:49 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-z8cn2 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-z8cn2:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-z8cn2\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                                Message\n  ----    ------     ----  ----                                                -------\n  Normal  Scheduled  6s    default-scheduler                                   Successfully assigned kubectl-2554/redis-master-8t2z7 to conformance-1-15-2-do-0-default-pool-rxfp\n  Normal  Pulled     3s    kubelet, conformance-1-15-2-do-0-default-pool-rxfp  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    3s    kubelet, conformance-1-15-2-do-0-default-pool-rxfp  Created container redis-master\n  Normal  Started    2s    kubelet, conformance-1-15-2-do-0-default-pool-rxfp  Started container redis-master\n"
Aug 12 17:26:51.029: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 describe rc redis-master --namespace=kubectl-2554'
Aug 12 17:26:51.238: INFO: stderr: ""
Aug 12 17:26:51.238: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-2554\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  6s    replication-controller  Created pod: redis-master-8t2z7\n"
Aug 12 17:26:51.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 describe service redis-master --namespace=kubectl-2554'
Aug 12 17:26:51.416: INFO: stderr: ""
Aug 12 17:26:51.416: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-2554\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.245.211.213\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.244.1.68:6379\nSession Affinity:  None\nEvents:            <none>\n"
Aug 12 17:26:51.422: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 describe node conformance-1-15-2-do-0-default-pool-rxf2'
Aug 12 17:26:51.560: INFO: stderr: ""
Aug 12 17:26:51.560: INFO: stdout: "Name:               conformance-1-15-2-do-0-default-pool-rxf2\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=s-1vcpu-2gb\n                    beta.kubernetes.io/os=linux\n                    doks.digitalocean.com/node-id=281ef11f-4c78-49d1-aff5-1699717712d2\n                    doks.digitalocean.com/node-pool=conformance-1-15-2-do-0-default-pool\n                    doks.digitalocean.com/node-pool-id=ab939232-f008-4eeb-8f63-6d68b5c1e72d\n                    failure-domain.beta.kubernetes.io/region=sfo2\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=conformance-1-15-2-do-0-default-pool-rxf2\n                    kubernetes.io/os=linux\n                    region=sfo2\nAnnotations:        csi.volume.kubernetes.io/nodeid: {\"dobs.csi.digitalocean.com\":\"154635750\"}\n                    io.cilium.network.ipv4-cilium-host: 10.244.2.1\n                    io.cilium.network.ipv4-health-ip: 10.244.2.226\n                    io.cilium.network.ipv4-pod-cidr: 10.244.2.0/24\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 12 Aug 2019 13:17:33 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Mon, 12 Aug 2019 14:09:45 +0000   Mon, 12 Aug 2019 14:09:45 +0000   CiliumIsUp                   Cilium is running on this node\n  MemoryPressure       False   Mon, 12 Aug 2019 17:26:45 +0000   Mon, 12 Aug 2019 13:17:33 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Mon, 12 Aug 2019 17:26:45 +0000   Mon, 12 Aug 2019 13:17:33 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Mon, 12 Aug 2019 17:26:45 +0000   Mon, 12 Aug 2019 13:17:33 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Mon, 12 Aug 2019 17:26:45 +0000   Mon, 12 Aug 2019 13:17:53 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  Hostname:    conformance-1-15-2-do-0-default-pool-rxf2\n  InternalIP:  10.138.15.94\n  ExternalIP:  167.71.113.3\nCapacity:\n attachable-volumes-csi-dobs.csi.digitalocean.com:  7\n cpu:                                               1\n ephemeral-storage:                                 51572172Ki\n hugepages-1Gi:                                     0\n hugepages-2Mi:                                     0\n memory:                                            2043364Ki\n pods:                                              110\nAllocatable:\n attachable-volumes-csi-dobs.csi.digitalocean.com:  7\n cpu:                                               1\n ephemeral-storage:                                 51572172Ki\n hugepages-1Gi:                                     0\n hugepages-2Mi:                                     0\n memory:                                            1574Mi\n pods:                                              110\nSystem Info:\n Machine ID:                 d68eec2fecb642cc95bab6c0f604906f\n System UUID:                d68eec2f-ecb6-42cc-95ba-b6c0f604906f\n Boot ID:                    a7282054-9b3b-47a0-bd19-23a9fb48b174\n Kernel Version:             4.19.0-0.bpo.5-amd64\n OS Image:                   Debian GNU/Linux 9 (stretch)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.9.2\n Kubelet Version:            v1.15.2\n Kube-Proxy Version:         v1.15.2\nPodCIDR:                     10.244.2.0/24\nProviderID:                  digitalocean://154635750\nNon-terminated Pods:         (6 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  heptio-sonobuoy            sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         77m\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-a0296875de8f4bfa-l5d86    0 (0%)        0 (0%)      0 (0%)           0 (0%)         77m\n  kube-system                cilium-n97lp                                               300m (30%)    0 (0%)      300Mi (19%)      0 (0%)         4h9m\n  kube-system                csi-do-node-8hbn9                                          0 (0%)        0 (0%)      70Mi (4%)        0 (0%)         4h9m\n  kube-system                do-node-agent-jsj6x                                        102m (10%)    102m (10%)  80Mi (5%)        100Mi (6%)     4h8m\n  kube-system                kube-proxy-bxfsv                                           0 (0%)        0 (0%)      125Mi (7%)       0 (0%)         4h9m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                                          Requests     Limits\n  --------                                          --------     ------\n  cpu                                               402m (40%)   102m (10%)\n  memory                                            575Mi (36%)  100Mi (6%)\n  ephemeral-storage                                 0 (0%)       0 (0%)\n  attachable-volumes-csi-dobs.csi.digitalocean.com  0            0\nEvents:                                             <none>\n"
Aug 12 17:26:51.561: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 describe namespace kubectl-2554'
Aug 12 17:26:51.692: INFO: stderr: ""
Aug 12 17:26:51.692: INFO: stdout: "Name:         kubectl-2554\nLabels:       e2e-framework=kubectl\n              e2e-run=d3dd34f7-7819-46ed-9db3-33de185b0b94\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:26:51.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2554" for this suite.
Aug 12 17:27:13.721: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:27:13.857: INFO: namespace kubectl-2554 deletion completed in 22.156113397s

 [SLOW TEST:28.254 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:27:13.863: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 12 17:27:13.976: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 version'
Aug 12 17:27:14.071: INFO: stderr: ""
Aug 12 17:27:14.071: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.2\", GitCommit:\"f6278300bebbb750328ac16ee6dd3aa7d3549568\", GitTreeState:\"clean\", BuildDate:\"2019-08-05T09:23:26Z\", GoVersion:\"go1.12.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.2\", GitCommit:\"f6278300bebbb750328ac16ee6dd3aa7d3549568\", GitTreeState:\"clean\", BuildDate:\"2019-08-05T09:15:22Z\", GoVersion:\"go1.12.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:27:14.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3963" for this suite.
Aug 12 17:27:20.097: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:27:20.237: INFO: namespace kubectl-3963 deletion completed in 6.157877105s

 [SLOW TEST:6.375 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:27:20.245: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Aug 12 17:27:24.342: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 exec pod-sharedvolume-60c0e3e4-46aa-48ad-95d9-5d2335995eb3 -c busybox-main-container --namespace=emptydir-6513 -- cat /usr/share/volumeshare/shareddata.txt'
Aug 12 17:27:24.676: INFO: stderr: ""
Aug 12 17:27:24.676: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:27:24.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6513" for this suite.
Aug 12 17:27:30.716: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:27:30.868: INFO: namespace emptydir-6513 deletion completed in 6.183466108s

 [SLOW TEST:10.623 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:27:30.868: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1517
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 12 17:27:30.927: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-6411'
Aug 12 17:27:31.053: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 12 17:27:31.053: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: rolling-update to same image controller
Aug 12 17:27:31.068: INFO: scanned /root for discovery docs: <nil>
Aug 12 17:27:31.068: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-6411'
Aug 12 17:27:46.953: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Aug 12 17:27:46.953: INFO: stdout: "Created e2e-test-nginx-rc-5341dad0ad62390c121f0272acd2777e\nScaling up e2e-test-nginx-rc-5341dad0ad62390c121f0272acd2777e from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-5341dad0ad62390c121f0272acd2777e up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-5341dad0ad62390c121f0272acd2777e to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Aug 12 17:27:46.953: INFO: stdout: "Created e2e-test-nginx-rc-5341dad0ad62390c121f0272acd2777e\nScaling up e2e-test-nginx-rc-5341dad0ad62390c121f0272acd2777e from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-5341dad0ad62390c121f0272acd2777e up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-5341dad0ad62390c121f0272acd2777e to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Aug 12 17:27:46.953: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-6411'
Aug 12 17:27:47.077: INFO: stderr: ""
Aug 12 17:27:47.077: INFO: stdout: "e2e-test-nginx-rc-5341dad0ad62390c121f0272acd2777e-jzq55 e2e-test-nginx-rc-crtt7 "
STEP: Replicas for run=e2e-test-nginx-rc: expected=1 actual=2
Aug 12 17:27:52.078: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-6411'
Aug 12 17:27:52.179: INFO: stderr: ""
Aug 12 17:27:52.179: INFO: stdout: "e2e-test-nginx-rc-5341dad0ad62390c121f0272acd2777e-jzq55 "
Aug 12 17:27:52.179: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 get pods e2e-test-nginx-rc-5341dad0ad62390c121f0272acd2777e-jzq55 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6411'
Aug 12 17:27:52.296: INFO: stderr: ""
Aug 12 17:27:52.296: INFO: stdout: "true"
Aug 12 17:27:52.296: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 get pods e2e-test-nginx-rc-5341dad0ad62390c121f0272acd2777e-jzq55 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6411'
Aug 12 17:27:52.439: INFO: stderr: ""
Aug 12 17:27:52.439: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Aug 12 17:27:52.439: INFO: e2e-test-nginx-rc-5341dad0ad62390c121f0272acd2777e-jzq55 is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1523
Aug 12 17:27:52.439: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 delete rc e2e-test-nginx-rc --namespace=kubectl-6411'
Aug 12 17:27:52.547: INFO: stderr: ""
Aug 12 17:27:52.547: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:27:52.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6411" for this suite.
Aug 12 17:27:58.567: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:27:58.721: INFO: namespace kubectl-6411 deletion completed in 6.169336697s

 [SLOW TEST:27.853 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:27:58.746: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Aug 12 17:27:58.857: INFO: Waiting up to 5m0s for pod "downward-api-a1843766-50a0-4e0a-b51d-fb5b25b9c1ff" in namespace "downward-api-20" to be "success or failure"
Aug 12 17:27:58.865: INFO: Pod "downward-api-a1843766-50a0-4e0a-b51d-fb5b25b9c1ff": Phase="Pending", Reason="", readiness=false. Elapsed: 7.827966ms
Aug 12 17:28:00.873: INFO: Pod "downward-api-a1843766-50a0-4e0a-b51d-fb5b25b9c1ff": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015916123s
Aug 12 17:28:02.880: INFO: Pod "downward-api-a1843766-50a0-4e0a-b51d-fb5b25b9c1ff": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023139512s
STEP: Saw pod success
Aug 12 17:28:02.880: INFO: Pod "downward-api-a1843766-50a0-4e0a-b51d-fb5b25b9c1ff" satisfied condition "success or failure"
Aug 12 17:28:02.885: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxf2 pod downward-api-a1843766-50a0-4e0a-b51d-fb5b25b9c1ff container dapi-container: <nil>
STEP: delete the pod
Aug 12 17:28:02.919: INFO: Waiting for pod downward-api-a1843766-50a0-4e0a-b51d-fb5b25b9c1ff to disappear
Aug 12 17:28:02.922: INFO: Pod downward-api-a1843766-50a0-4e0a-b51d-fb5b25b9c1ff no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:28:02.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-20" for this suite.
Aug 12 17:28:08.940: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:28:09.089: INFO: namespace downward-api-20 deletion completed in 6.163309008s

 [SLOW TEST:10.344 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:28:09.095: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 12 17:28:09.234: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Aug 12 17:28:09.254: INFO: Number of nodes with available pods: 0
Aug 12 17:28:09.254: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Aug 12 17:28:09.300: INFO: Number of nodes with available pods: 0
Aug 12 17:28:09.301: INFO: Node conformance-1-15-2-do-0-default-pool-rxf2 is running more than one daemon pod
Aug 12 17:28:10.305: INFO: Number of nodes with available pods: 0
Aug 12 17:28:10.305: INFO: Node conformance-1-15-2-do-0-default-pool-rxf2 is running more than one daemon pod
Aug 12 17:28:11.307: INFO: Number of nodes with available pods: 0
Aug 12 17:28:11.308: INFO: Node conformance-1-15-2-do-0-default-pool-rxf2 is running more than one daemon pod
Aug 12 17:28:12.307: INFO: Number of nodes with available pods: 0
Aug 12 17:28:12.308: INFO: Node conformance-1-15-2-do-0-default-pool-rxf2 is running more than one daemon pod
Aug 12 17:28:13.305: INFO: Number of nodes with available pods: 1
Aug 12 17:28:13.305: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Aug 12 17:28:13.331: INFO: Number of nodes with available pods: 1
Aug 12 17:28:13.331: INFO: Number of running nodes: 0, number of available pods: 1
Aug 12 17:28:14.335: INFO: Number of nodes with available pods: 0
Aug 12 17:28:14.336: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Aug 12 17:28:14.354: INFO: Number of nodes with available pods: 0
Aug 12 17:28:14.355: INFO: Node conformance-1-15-2-do-0-default-pool-rxf2 is running more than one daemon pod
Aug 12 17:28:15.360: INFO: Number of nodes with available pods: 0
Aug 12 17:28:15.360: INFO: Node conformance-1-15-2-do-0-default-pool-rxf2 is running more than one daemon pod
Aug 12 17:28:16.459: INFO: Number of nodes with available pods: 0
Aug 12 17:28:16.459: INFO: Node conformance-1-15-2-do-0-default-pool-rxf2 is running more than one daemon pod
Aug 12 17:28:17.360: INFO: Number of nodes with available pods: 0
Aug 12 17:28:17.360: INFO: Node conformance-1-15-2-do-0-default-pool-rxf2 is running more than one daemon pod
Aug 12 17:28:18.364: INFO: Number of nodes with available pods: 0
Aug 12 17:28:18.364: INFO: Node conformance-1-15-2-do-0-default-pool-rxf2 is running more than one daemon pod
Aug 12 17:28:19.359: INFO: Number of nodes with available pods: 0
Aug 12 17:28:19.359: INFO: Node conformance-1-15-2-do-0-default-pool-rxf2 is running more than one daemon pod
Aug 12 17:28:20.363: INFO: Number of nodes with available pods: 0
Aug 12 17:28:20.363: INFO: Node conformance-1-15-2-do-0-default-pool-rxf2 is running more than one daemon pod
Aug 12 17:28:21.359: INFO: Number of nodes with available pods: 0
Aug 12 17:28:21.359: INFO: Node conformance-1-15-2-do-0-default-pool-rxf2 is running more than one daemon pod
Aug 12 17:28:22.361: INFO: Number of nodes with available pods: 0
Aug 12 17:28:22.362: INFO: Node conformance-1-15-2-do-0-default-pool-rxf2 is running more than one daemon pod
Aug 12 17:28:23.364: INFO: Number of nodes with available pods: 0
Aug 12 17:28:23.365: INFO: Node conformance-1-15-2-do-0-default-pool-rxf2 is running more than one daemon pod
Aug 12 17:28:24.365: INFO: Number of nodes with available pods: 0
Aug 12 17:28:24.366: INFO: Node conformance-1-15-2-do-0-default-pool-rxf2 is running more than one daemon pod
Aug 12 17:28:25.361: INFO: Number of nodes with available pods: 0
Aug 12 17:28:25.361: INFO: Node conformance-1-15-2-do-0-default-pool-rxf2 is running more than one daemon pod
Aug 12 17:28:26.360: INFO: Number of nodes with available pods: 1
Aug 12 17:28:26.360: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5975, will wait for the garbage collector to delete the pods
Aug 12 17:28:26.431: INFO: Deleting DaemonSet.extensions daemon-set took: 7.642453ms
Aug 12 17:28:26.832: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.363194ms
Aug 12 17:28:29.838: INFO: Number of nodes with available pods: 0
Aug 12 17:28:29.838: INFO: Number of running nodes: 0, number of available pods: 0
Aug 12 17:28:29.846: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-5975/daemonsets","resourceVersion":"56223"},"items":null}

Aug 12 17:28:29.855: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-5975/pods","resourceVersion":"56223"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:28:29.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5975" for this suite.
Aug 12 17:28:35.904: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:28:36.056: INFO: namespace daemonsets-5975 deletion completed in 6.167315s

 [SLOW TEST:26.962 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:28:36.061: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 pods, got 2 pods
STEP: expected 0 rs, got 1 rs
STEP: Gathering metrics
W0812 17:28:36.777683      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 12 17:28:36.778: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:28:36.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6854" for this suite.
Aug 12 17:28:42.799: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:28:43.063: INFO: namespace gc-6854 deletion completed in 6.279933811s

 [SLOW TEST:7.002 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:28:43.070: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-2148
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-2148
STEP: Creating statefulset with conflicting port in namespace statefulset-2148
STEP: Waiting until pod test-pod will start running in namespace statefulset-2148
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-2148
Aug 12 17:28:49.441: INFO: Observed stateful pod in namespace: statefulset-2148, name: ss-0, uid: 90bea6df-3c5b-484d-bb33-8d04dd5b89b4, status phase: Pending. Waiting for statefulset controller to delete.
Aug 12 17:28:49.590: INFO: Observed stateful pod in namespace: statefulset-2148, name: ss-0, uid: 90bea6df-3c5b-484d-bb33-8d04dd5b89b4, status phase: Failed. Waiting for statefulset controller to delete.
Aug 12 17:28:49.605: INFO: Observed stateful pod in namespace: statefulset-2148, name: ss-0, uid: 90bea6df-3c5b-484d-bb33-8d04dd5b89b4, status phase: Failed. Waiting for statefulset controller to delete.
Aug 12 17:28:49.611: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-2148
STEP: Removing pod with conflicting port in namespace statefulset-2148
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-2148 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Aug 12 17:28:53.746: INFO: Deleting all statefulset in ns statefulset-2148
Aug 12 17:28:53.849: INFO: Scaling statefulset ss to 0
Aug 12 17:29:04.048: INFO: Waiting for statefulset status.replicas updated to 0
Aug 12 17:29:04.056: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:29:04.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2148" for this suite.
Aug 12 17:29:10.107: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:29:10.243: INFO: namespace statefulset-2148 deletion completed in 6.14959733s

 [SLOW TEST:27.174 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:29:10.244: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1722
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 12 17:29:10.302: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-7652'
Aug 12 17:29:10.650: INFO: stderr: ""
Aug 12 17:29:10.650: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Aug 12 17:29:15.700: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 get pod e2e-test-nginx-pod --namespace=kubectl-7652 -o json'
Aug 12 17:29:15.794: INFO: stderr: ""
Aug 12 17:29:15.794: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-08-12T17:29:10Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-7652\",\n        \"resourceVersion\": \"56544\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-7652/pods/e2e-test-nginx-pod\",\n        \"uid\": \"157992b8-5da4-47ec-8087-00c39266431e\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-zl7rf\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"conformance-1-15-2-do-0-default-pool-rxf2\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-zl7rf\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-zl7rf\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-08-12T17:29:10Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-08-12T17:29:12Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-08-12T17:29:12Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-08-12T17:29:10Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://0cec8f35b744b4186a1badbe2b684e36819d380397927772bc9dbda46d7f899b\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-08-12T17:29:12Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.138.15.94\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.244.2.160\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-08-12T17:29:10Z\"\n    }\n}\n"
STEP: replace the image in the pod
Aug 12 17:29:15.794: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 replace -f - --namespace=kubectl-7652'
Aug 12 17:29:16.021: INFO: stderr: ""
Aug 12 17:29:16.022: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1727
Aug 12 17:29:16.026: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 delete pods e2e-test-nginx-pod --namespace=kubectl-7652'
Aug 12 17:29:17.941: INFO: stderr: ""
Aug 12 17:29:17.941: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:29:17.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7652" for this suite.
Aug 12 17:29:23.967: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:29:24.127: INFO: namespace kubectl-7652 deletion completed in 6.181594532s

 [SLOW TEST:13.884 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:29:24.136: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
STEP: reading a file in the container
Aug 12 17:29:28.799: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-869 pod-service-account-ca817eaa-f0d2-4079-9588-e304422aa0ce -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Aug 12 17:29:29.179: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-869 pod-service-account-ca817eaa-f0d2-4079-9588-e304422aa0ce -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Aug 12 17:29:29.524: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-869 pod-service-account-ca817eaa-f0d2-4079-9588-e304422aa0ce -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:29:29.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-869" for this suite.
Aug 12 17:29:35.901: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:29:36.037: INFO: namespace svcaccounts-869 deletion completed in 6.153143723s

 [SLOW TEST:11.901 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:29:36.040: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-5848
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 12 17:29:36.138: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug 12 17:30:02.315: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.0.45:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5848 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 12 17:30:02.316: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
Aug 12 17:30:02.549: INFO: Found all expected endpoints: [netserver-0]
Aug 12 17:30:02.554: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.2.168:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5848 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 12 17:30:02.554: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
Aug 12 17:30:02.847: INFO: Found all expected endpoints: [netserver-1]
Aug 12 17:30:02.851: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.1.58:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5848 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 12 17:30:02.852: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
Aug 12 17:30:03.101: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:30:03.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5848" for this suite.
Aug 12 17:30:25.127: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:30:25.268: INFO: namespace pod-network-test-5848 deletion completed in 22.158470217s

 [SLOW TEST:49.228 seconds]
[sig-network] Networking
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:30:25.271: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7080.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-7080.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7080.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-7080.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7080.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-7080.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7080.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-7080.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7080.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-7080.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7080.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-7080.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7080.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 220.22.245.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.245.22.220_udp@PTR;check="$$(dig +tcp +noall +answer +search 220.22.245.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.245.22.220_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7080.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-7080.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7080.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-7080.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7080.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-7080.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7080.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-7080.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7080.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-7080.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7080.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-7080.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7080.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 220.22.245.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.245.22.220_udp@PTR;check="$$(dig +tcp +noall +answer +search 220.22.245.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.245.22.220_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 12 17:30:29.507: INFO: Unable to read wheezy_udp@dns-test-service.dns-7080.svc.cluster.local from pod dns-7080/dns-test-eba42e4e-acd5-4d91-8922-78b3ad15f467: the server could not find the requested resource (get pods dns-test-eba42e4e-acd5-4d91-8922-78b3ad15f467)
Aug 12 17:30:29.513: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7080.svc.cluster.local from pod dns-7080/dns-test-eba42e4e-acd5-4d91-8922-78b3ad15f467: the server could not find the requested resource (get pods dns-test-eba42e4e-acd5-4d91-8922-78b3ad15f467)
Aug 12 17:30:29.523: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7080.svc.cluster.local from pod dns-7080/dns-test-eba42e4e-acd5-4d91-8922-78b3ad15f467: the server could not find the requested resource (get pods dns-test-eba42e4e-acd5-4d91-8922-78b3ad15f467)
Aug 12 17:30:29.529: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7080.svc.cluster.local from pod dns-7080/dns-test-eba42e4e-acd5-4d91-8922-78b3ad15f467: the server could not find the requested resource (get pods dns-test-eba42e4e-acd5-4d91-8922-78b3ad15f467)
Aug 12 17:30:29.570: INFO: Unable to read jessie_udp@dns-test-service.dns-7080.svc.cluster.local from pod dns-7080/dns-test-eba42e4e-acd5-4d91-8922-78b3ad15f467: the server could not find the requested resource (get pods dns-test-eba42e4e-acd5-4d91-8922-78b3ad15f467)
Aug 12 17:30:29.580: INFO: Unable to read jessie_tcp@dns-test-service.dns-7080.svc.cluster.local from pod dns-7080/dns-test-eba42e4e-acd5-4d91-8922-78b3ad15f467: the server could not find the requested resource (get pods dns-test-eba42e4e-acd5-4d91-8922-78b3ad15f467)
Aug 12 17:30:29.588: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7080.svc.cluster.local from pod dns-7080/dns-test-eba42e4e-acd5-4d91-8922-78b3ad15f467: the server could not find the requested resource (get pods dns-test-eba42e4e-acd5-4d91-8922-78b3ad15f467)
Aug 12 17:30:29.596: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7080.svc.cluster.local from pod dns-7080/dns-test-eba42e4e-acd5-4d91-8922-78b3ad15f467: the server could not find the requested resource (get pods dns-test-eba42e4e-acd5-4d91-8922-78b3ad15f467)
Aug 12 17:30:29.652: INFO: Lookups using dns-7080/dns-test-eba42e4e-acd5-4d91-8922-78b3ad15f467 failed for: [wheezy_udp@dns-test-service.dns-7080.svc.cluster.local wheezy_tcp@dns-test-service.dns-7080.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7080.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-7080.svc.cluster.local jessie_udp@dns-test-service.dns-7080.svc.cluster.local jessie_tcp@dns-test-service.dns-7080.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-7080.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-7080.svc.cluster.local]

Aug 12 17:30:34.805: INFO: DNS probes using dns-7080/dns-test-eba42e4e-acd5-4d91-8922-78b3ad15f467 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:30:35.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7080" for this suite.
Aug 12 17:30:41.103: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:30:41.255: INFO: namespace dns-7080 deletion completed in 6.169570429s

 [SLOW TEST:15.985 seconds]
[sig-network] DNS
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:30:41.259: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-secret-qwrv
STEP: Creating a pod to test atomic-volume-subpath
Aug 12 17:30:41.346: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-qwrv" in namespace "subpath-9437" to be "success or failure"
Aug 12 17:30:41.357: INFO: Pod "pod-subpath-test-secret-qwrv": Phase="Pending", Reason="", readiness=false. Elapsed: 11.279971ms
Aug 12 17:30:43.365: INFO: Pod "pod-subpath-test-secret-qwrv": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019160067s
Aug 12 17:30:45.374: INFO: Pod "pod-subpath-test-secret-qwrv": Phase="Running", Reason="", readiness=true. Elapsed: 4.028069996s
Aug 12 17:30:47.379: INFO: Pod "pod-subpath-test-secret-qwrv": Phase="Running", Reason="", readiness=true. Elapsed: 6.032931344s
Aug 12 17:30:49.384: INFO: Pod "pod-subpath-test-secret-qwrv": Phase="Running", Reason="", readiness=true. Elapsed: 8.038148498s
Aug 12 17:30:51.389: INFO: Pod "pod-subpath-test-secret-qwrv": Phase="Running", Reason="", readiness=true. Elapsed: 10.042977041s
Aug 12 17:30:53.394: INFO: Pod "pod-subpath-test-secret-qwrv": Phase="Running", Reason="", readiness=true. Elapsed: 12.047683251s
Aug 12 17:30:55.398: INFO: Pod "pod-subpath-test-secret-qwrv": Phase="Running", Reason="", readiness=true. Elapsed: 14.052384537s
Aug 12 17:30:57.403: INFO: Pod "pod-subpath-test-secret-qwrv": Phase="Running", Reason="", readiness=true. Elapsed: 16.056584353s
Aug 12 17:30:59.407: INFO: Pod "pod-subpath-test-secret-qwrv": Phase="Running", Reason="", readiness=true. Elapsed: 18.060848176s
Aug 12 17:31:01.412: INFO: Pod "pod-subpath-test-secret-qwrv": Phase="Running", Reason="", readiness=true. Elapsed: 20.065902561s
Aug 12 17:31:03.425: INFO: Pod "pod-subpath-test-secret-qwrv": Phase="Running", Reason="", readiness=true. Elapsed: 22.078758863s
Aug 12 17:31:05.429: INFO: Pod "pod-subpath-test-secret-qwrv": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.082649625s
STEP: Saw pod success
Aug 12 17:31:05.429: INFO: Pod "pod-subpath-test-secret-qwrv" satisfied condition "success or failure"
Aug 12 17:31:05.434: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxfp pod pod-subpath-test-secret-qwrv container test-container-subpath-secret-qwrv: <nil>
STEP: delete the pod
Aug 12 17:31:05.467: INFO: Waiting for pod pod-subpath-test-secret-qwrv to disappear
Aug 12 17:31:05.472: INFO: Pod pod-subpath-test-secret-qwrv no longer exists
STEP: Deleting pod pod-subpath-test-secret-qwrv
Aug 12 17:31:05.472: INFO: Deleting pod "pod-subpath-test-secret-qwrv" in namespace "subpath-9437"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:31:05.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9437" for this suite.
Aug 12 17:31:11.490: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:31:11.651: INFO: namespace subpath-9437 deletion completed in 6.173377059s

 [SLOW TEST:30.392 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:31:11.658: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 12 17:31:11.740: INFO: (0) /api/v1/nodes/conformance-1-15-2-do-0-default-pool-rxf2/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 21.066614ms)
Aug 12 17:31:11.751: INFO: (1) /api/v1/nodes/conformance-1-15-2-do-0-default-pool-rxf2/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 10.387746ms)
Aug 12 17:31:11.759: INFO: (2) /api/v1/nodes/conformance-1-15-2-do-0-default-pool-rxf2/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 7.529063ms)
Aug 12 17:31:11.767: INFO: (3) /api/v1/nodes/conformance-1-15-2-do-0-default-pool-rxf2/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 7.945872ms)
Aug 12 17:31:11.776: INFO: (4) /api/v1/nodes/conformance-1-15-2-do-0-default-pool-rxf2/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 8.410839ms)
Aug 12 17:31:11.785: INFO: (5) /api/v1/nodes/conformance-1-15-2-do-0-default-pool-rxf2/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 7.405025ms)
Aug 12 17:31:11.798: INFO: (6) /api/v1/nodes/conformance-1-15-2-do-0-default-pool-rxf2/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 12.996398ms)
Aug 12 17:31:11.808: INFO: (7) /api/v1/nodes/conformance-1-15-2-do-0-default-pool-rxf2/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 8.997351ms)
Aug 12 17:31:11.814: INFO: (8) /api/v1/nodes/conformance-1-15-2-do-0-default-pool-rxf2/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 5.498376ms)
Aug 12 17:31:11.821: INFO: (9) /api/v1/nodes/conformance-1-15-2-do-0-default-pool-rxf2/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 6.365332ms)
Aug 12 17:31:11.827: INFO: (10) /api/v1/nodes/conformance-1-15-2-do-0-default-pool-rxf2/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 5.947331ms)
Aug 12 17:31:11.834: INFO: (11) /api/v1/nodes/conformance-1-15-2-do-0-default-pool-rxf2/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 6.365525ms)
Aug 12 17:31:11.844: INFO: (12) /api/v1/nodes/conformance-1-15-2-do-0-default-pool-rxf2/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 9.600666ms)
Aug 12 17:31:11.851: INFO: (13) /api/v1/nodes/conformance-1-15-2-do-0-default-pool-rxf2/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 5.820392ms)
Aug 12 17:31:11.856: INFO: (14) /api/v1/nodes/conformance-1-15-2-do-0-default-pool-rxf2/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.592275ms)
Aug 12 17:31:11.860: INFO: (15) /api/v1/nodes/conformance-1-15-2-do-0-default-pool-rxf2/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.350779ms)
Aug 12 17:31:11.866: INFO: (16) /api/v1/nodes/conformance-1-15-2-do-0-default-pool-rxf2/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 5.657247ms)
Aug 12 17:31:11.871: INFO: (17) /api/v1/nodes/conformance-1-15-2-do-0-default-pool-rxf2/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.548103ms)
Aug 12 17:31:11.876: INFO: (18) /api/v1/nodes/conformance-1-15-2-do-0-default-pool-rxf2/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.696269ms)
Aug 12 17:31:11.882: INFO: (19) /api/v1/nodes/conformance-1-15-2-do-0-default-pool-rxf2/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 5.057633ms)
[AfterEach] version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:31:11.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-6967" for this suite.
Aug 12 17:31:17.904: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:31:18.025: INFO: namespace proxy-6967 deletion completed in 6.134542919s

 [SLOW TEST:6.367 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:31:18.031: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating pod
Aug 12 17:31:22.161: INFO: Pod pod-hostip-e1362cad-ef95-4c39-a908-d7f7c901f316 has hostIP: 10.138.15.94
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:31:22.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4944" for this suite.
Aug 12 17:31:44.189: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:31:44.357: INFO: namespace pods-4944 deletion completed in 22.186312225s

 [SLOW TEST:26.326 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:31:44.367: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 12 17:31:44.428: INFO: Pod name rollover-pod: Found 0 pods out of 1
Aug 12 17:31:49.435: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Aug 12 17:31:49.435: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Aug 12 17:31:51.440: INFO: Creating deployment "test-rollover-deployment"
Aug 12 17:31:51.455: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Aug 12 17:31:53.464: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Aug 12 17:31:53.481: INFO: Ensure that both replica sets have 1 created replica
Aug 12 17:31:53.495: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Aug 12 17:31:53.509: INFO: Updating deployment test-rollover-deployment
Aug 12 17:31:53.510: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Aug 12 17:31:55.527: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Aug 12 17:31:55.537: INFO: Make sure deployment "test-rollover-deployment" is complete
Aug 12 17:31:55.546: INFO: all replica sets need to contain the pod-template-hash label
Aug 12 17:31:55.547: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701227911, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701227911, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701227913, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701227911, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 12 17:31:57.556: INFO: all replica sets need to contain the pod-template-hash label
Aug 12 17:31:57.556: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701227911, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701227911, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701227916, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701227911, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 12 17:31:59.566: INFO: all replica sets need to contain the pod-template-hash label
Aug 12 17:31:59.567: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701227911, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701227911, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701227916, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701227911, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 12 17:32:01.560: INFO: all replica sets need to contain the pod-template-hash label
Aug 12 17:32:01.560: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701227911, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701227911, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701227916, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701227911, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 12 17:32:03.555: INFO: all replica sets need to contain the pod-template-hash label
Aug 12 17:32:03.556: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701227911, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701227911, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701227916, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701227911, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 12 17:32:05.557: INFO: all replica sets need to contain the pod-template-hash label
Aug 12 17:32:05.558: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701227911, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701227911, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63701227916, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63701227911, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 12 17:32:07.555: INFO: 
Aug 12 17:32:07.555: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Aug 12 17:32:07.572: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-2054,SelfLink:/apis/apps/v1/namespaces/deployment-2054/deployments/test-rollover-deployment,UID:09cb339a-d454-447f-9cef-d55803f8d250,ResourceVersion:57274,Generation:2,CreationTimestamp:2019-08-12 17:31:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-08-12 17:31:51 +0000 UTC 2019-08-12 17:31:51 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-08-12 17:32:06 +0000 UTC 2019-08-12 17:31:51 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-854595fc44" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Aug 12 17:32:07.577: INFO: New ReplicaSet "test-rollover-deployment-854595fc44" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44,GenerateName:,Namespace:deployment-2054,SelfLink:/apis/apps/v1/namespaces/deployment-2054/replicasets/test-rollover-deployment-854595fc44,UID:02e7e7f1-9fc8-4244-9e2c-4bcd5048f287,ResourceVersion:57264,Generation:2,CreationTimestamp:2019-08-12 17:31:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 09cb339a-d454-447f-9cef-d55803f8d250 0xc00359da87 0xc00359da88}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Aug 12 17:32:07.578: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Aug 12 17:32:07.578: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-2054,SelfLink:/apis/apps/v1/namespaces/deployment-2054/replicasets/test-rollover-controller,UID:505e24fa-c35e-45a9-8cbc-f556967a4f1b,ResourceVersion:57273,Generation:2,CreationTimestamp:2019-08-12 17:31:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 09cb339a-d454-447f-9cef-d55803f8d250 0xc00359d9b7 0xc00359d9b8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 12 17:32:07.578: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-9b8b997cf,GenerateName:,Namespace:deployment-2054,SelfLink:/apis/apps/v1/namespaces/deployment-2054/replicasets/test-rollover-deployment-9b8b997cf,UID:6010d7f5-7359-4318-a2af-38ac92a8b767,ResourceVersion:57215,Generation:2,CreationTimestamp:2019-08-12 17:31:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 09cb339a-d454-447f-9cef-d55803f8d250 0xc00359db50 0xc00359db51}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 12 17:32:07.582: INFO: Pod "test-rollover-deployment-854595fc44-42djv" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44-42djv,GenerateName:test-rollover-deployment-854595fc44-,Namespace:deployment-2054,SelfLink:/api/v1/namespaces/deployment-2054/pods/test-rollover-deployment-854595fc44-42djv,UID:2b32aa55-b70b-4e79-ad96-9962a04e7e5b,ResourceVersion:57242,Generation:0,CreationTimestamp:2019-08-12 17:31:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-854595fc44 02e7e7f1-9fc8-4244-9e2c-4bcd5048f287 0xc002f9a827 0xc002f9a828}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5l778 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5l778,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-5l778 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-1-15-2-do-0-default-pool-rxf2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f9a8a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f9a8c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:31:53 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:31:56 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:31:56 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-12 17:31:53 +0000 UTC  }],Message:,Reason:,HostIP:10.138.15.94,PodIP:10.244.2.6,StartTime:2019-08-12 17:31:53 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-08-12 17:31:55 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://f70b2183a1eb3ce4bf68174c4b68666fd81cf78953683c0afe1a55bc4608b63f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:32:07.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2054" for this suite.
Aug 12 17:32:13.602: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:32:13.770: INFO: namespace deployment-2054 deletion completed in 6.1817002s

 [SLOW TEST:29.404 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:32:13.781: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-a81abbd9-cf78-4b0d-a581-ab92e8344f62
STEP: Creating a pod to test consume configMaps
Aug 12 17:32:13.921: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-26a05a6a-a775-4cb1-bf14-7487f0e92cac" in namespace "projected-5739" to be "success or failure"
Aug 12 17:32:13.933: INFO: Pod "pod-projected-configmaps-26a05a6a-a775-4cb1-bf14-7487f0e92cac": Phase="Pending", Reason="", readiness=false. Elapsed: 10.970676ms
Aug 12 17:32:15.940: INFO: Pod "pod-projected-configmaps-26a05a6a-a775-4cb1-bf14-7487f0e92cac": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018146764s
Aug 12 17:32:17.947: INFO: Pod "pod-projected-configmaps-26a05a6a-a775-4cb1-bf14-7487f0e92cac": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024836994s
STEP: Saw pod success
Aug 12 17:32:17.947: INFO: Pod "pod-projected-configmaps-26a05a6a-a775-4cb1-bf14-7487f0e92cac" satisfied condition "success or failure"
Aug 12 17:32:17.952: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxfs pod pod-projected-configmaps-26a05a6a-a775-4cb1-bf14-7487f0e92cac container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 12 17:32:17.993: INFO: Waiting for pod pod-projected-configmaps-26a05a6a-a775-4cb1-bf14-7487f0e92cac to disappear
Aug 12 17:32:17.997: INFO: Pod pod-projected-configmaps-26a05a6a-a775-4cb1-bf14-7487f0e92cac no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:32:17.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5739" for this suite.
Aug 12 17:32:24.016: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:32:24.177: INFO: namespace projected-5739 deletion completed in 6.17506706s

 [SLOW TEST:10.397 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:32:24.178: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0812 17:32:34.295549      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 12 17:32:34.295: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:32:34.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1883" for this suite.
Aug 12 17:32:40.325: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:32:40.462: INFO: namespace gc-1883 deletion completed in 6.16245062s

 [SLOW TEST:16.285 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:32:40.464: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-projected-klm8
STEP: Creating a pod to test atomic-volume-subpath
Aug 12 17:32:40.718: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-klm8" in namespace "subpath-7376" to be "success or failure"
Aug 12 17:32:40.726: INFO: Pod "pod-subpath-test-projected-klm8": Phase="Pending", Reason="", readiness=false. Elapsed: 8.344247ms
Aug 12 17:32:42.749: INFO: Pod "pod-subpath-test-projected-klm8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030917256s
Aug 12 17:32:44.754: INFO: Pod "pod-subpath-test-projected-klm8": Phase="Running", Reason="", readiness=true. Elapsed: 4.035938331s
Aug 12 17:32:46.760: INFO: Pod "pod-subpath-test-projected-klm8": Phase="Running", Reason="", readiness=true. Elapsed: 6.04195469s
Aug 12 17:32:48.795: INFO: Pod "pod-subpath-test-projected-klm8": Phase="Running", Reason="", readiness=true. Elapsed: 8.076539064s
Aug 12 17:32:50.801: INFO: Pod "pod-subpath-test-projected-klm8": Phase="Running", Reason="", readiness=true. Elapsed: 10.082909457s
Aug 12 17:32:52.807: INFO: Pod "pod-subpath-test-projected-klm8": Phase="Running", Reason="", readiness=true. Elapsed: 12.088960417s
Aug 12 17:32:54.812: INFO: Pod "pod-subpath-test-projected-klm8": Phase="Running", Reason="", readiness=true. Elapsed: 14.094206105s
Aug 12 17:32:56.819: INFO: Pod "pod-subpath-test-projected-klm8": Phase="Running", Reason="", readiness=true. Elapsed: 16.100881477s
Aug 12 17:32:58.826: INFO: Pod "pod-subpath-test-projected-klm8": Phase="Running", Reason="", readiness=true. Elapsed: 18.108254903s
Aug 12 17:33:00.830: INFO: Pod "pod-subpath-test-projected-klm8": Phase="Running", Reason="", readiness=true. Elapsed: 20.111649743s
Aug 12 17:33:02.837: INFO: Pod "pod-subpath-test-projected-klm8": Phase="Running", Reason="", readiness=true. Elapsed: 22.118693525s
Aug 12 17:33:04.845: INFO: Pod "pod-subpath-test-projected-klm8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.126557834s
STEP: Saw pod success
Aug 12 17:33:04.845: INFO: Pod "pod-subpath-test-projected-klm8" satisfied condition "success or failure"
Aug 12 17:33:04.850: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxfs pod pod-subpath-test-projected-klm8 container test-container-subpath-projected-klm8: <nil>
STEP: delete the pod
Aug 12 17:33:04.881: INFO: Waiting for pod pod-subpath-test-projected-klm8 to disappear
Aug 12 17:33:04.885: INFO: Pod pod-subpath-test-projected-klm8 no longer exists
STEP: Deleting pod pod-subpath-test-projected-klm8
Aug 12 17:33:04.885: INFO: Deleting pod "pod-subpath-test-projected-klm8" in namespace "subpath-7376"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:33:04.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7376" for this suite.
Aug 12 17:33:10.903: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:33:11.053: INFO: namespace subpath-7376 deletion completed in 6.161124276s

 [SLOW TEST:30.589 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:33:11.056: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:34:11.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3677" for this suite.
Aug 12 17:34:33.167: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:34:33.338: INFO: namespace container-probe-3677 deletion completed in 22.217262643s

 [SLOW TEST:82.283 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:34:33.352: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Aug 12 17:34:41.499: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-421 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 12 17:34:41.499: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
Aug 12 17:34:41.746: INFO: Exec stderr: ""
Aug 12 17:34:41.746: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-421 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 12 17:34:41.746: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
Aug 12 17:34:41.979: INFO: Exec stderr: ""
Aug 12 17:34:41.980: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-421 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 12 17:34:41.980: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
Aug 12 17:34:42.220: INFO: Exec stderr: ""
Aug 12 17:34:42.220: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-421 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 12 17:34:42.220: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
Aug 12 17:34:42.453: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Aug 12 17:34:42.454: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-421 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 12 17:34:42.454: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
Aug 12 17:34:42.688: INFO: Exec stderr: ""
Aug 12 17:34:42.688: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-421 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 12 17:34:42.689: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
Aug 12 17:34:43.206: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Aug 12 17:34:43.206: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-421 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 12 17:34:43.206: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
Aug 12 17:34:43.450: INFO: Exec stderr: ""
Aug 12 17:34:43.451: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-421 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 12 17:34:43.451: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
Aug 12 17:34:43.680: INFO: Exec stderr: ""
Aug 12 17:34:43.680: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-421 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 12 17:34:43.681: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
Aug 12 17:34:43.905: INFO: Exec stderr: ""
Aug 12 17:34:43.906: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-421 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 12 17:34:43.906: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
Aug 12 17:34:44.188: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:34:44.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-421" for this suite.
Aug 12 17:35:38.215: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:35:38.369: INFO: namespace e2e-kubelet-etc-hosts-421 deletion completed in 54.168320178s

 [SLOW TEST:65.018 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:35:38.373: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-7603
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 12 17:35:38.415: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug 12 17:36:04.606: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.254:8080/dial?request=hostName&protocol=udp&host=10.244.1.5&port=8081&tries=1'] Namespace:pod-network-test-7603 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 12 17:36:04.606: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
Aug 12 17:36:04.838: INFO: Waiting for endpoints: map[]
Aug 12 17:36:04.843: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.254:8080/dial?request=hostName&protocol=udp&host=10.244.0.36&port=8081&tries=1'] Namespace:pod-network-test-7603 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 12 17:36:04.844: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
Aug 12 17:36:05.088: INFO: Waiting for endpoints: map[]
Aug 12 17:36:05.094: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.254:8080/dial?request=hostName&protocol=udp&host=10.244.2.213&port=8081&tries=1'] Namespace:pod-network-test-7603 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 12 17:36:05.095: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
Aug 12 17:36:05.372: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:36:05.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7603" for this suite.
Aug 12 17:36:27.399: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:36:27.537: INFO: namespace pod-network-test-7603 deletion completed in 22.158126774s

 [SLOW TEST:49.165 seconds]
[sig-network] Networking
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:36:27.541: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test use defaults
Aug 12 17:36:27.644: INFO: Waiting up to 5m0s for pod "client-containers-cc0938c2-1f6d-4c68-adda-d9d08ef5c31f" in namespace "containers-1245" to be "success or failure"
Aug 12 17:36:27.652: INFO: Pod "client-containers-cc0938c2-1f6d-4c68-adda-d9d08ef5c31f": Phase="Pending", Reason="", readiness=false. Elapsed: 7.674376ms
Aug 12 17:36:29.656: INFO: Pod "client-containers-cc0938c2-1f6d-4c68-adda-d9d08ef5c31f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012453137s
Aug 12 17:36:31.661: INFO: Pod "client-containers-cc0938c2-1f6d-4c68-adda-d9d08ef5c31f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017461675s
STEP: Saw pod success
Aug 12 17:36:31.662: INFO: Pod "client-containers-cc0938c2-1f6d-4c68-adda-d9d08ef5c31f" satisfied condition "success or failure"
Aug 12 17:36:31.665: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxfs pod client-containers-cc0938c2-1f6d-4c68-adda-d9d08ef5c31f container test-container: <nil>
STEP: delete the pod
Aug 12 17:36:31.694: INFO: Waiting for pod client-containers-cc0938c2-1f6d-4c68-adda-d9d08ef5c31f to disappear
Aug 12 17:36:31.697: INFO: Pod client-containers-cc0938c2-1f6d-4c68-adda-d9d08ef5c31f no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:36:31.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1245" for this suite.
Aug 12 17:36:37.715: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:36:37.884: INFO: namespace containers-1245 deletion completed in 6.183507587s

 [SLOW TEST:10.344 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:36:37.888: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 12 17:36:38.082: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cf60cf16-6e2a-4d9e-ac9c-6af222fef2a7" in namespace "projected-4973" to be "success or failure"
Aug 12 17:36:38.111: INFO: Pod "downwardapi-volume-cf60cf16-6e2a-4d9e-ac9c-6af222fef2a7": Phase="Pending", Reason="", readiness=false. Elapsed: 27.562658ms
Aug 12 17:36:40.122: INFO: Pod "downwardapi-volume-cf60cf16-6e2a-4d9e-ac9c-6af222fef2a7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039167293s
Aug 12 17:36:42.131: INFO: Pod "downwardapi-volume-cf60cf16-6e2a-4d9e-ac9c-6af222fef2a7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.047538553s
STEP: Saw pod success
Aug 12 17:36:42.131: INFO: Pod "downwardapi-volume-cf60cf16-6e2a-4d9e-ac9c-6af222fef2a7" satisfied condition "success or failure"
Aug 12 17:36:42.135: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxf2 pod downwardapi-volume-cf60cf16-6e2a-4d9e-ac9c-6af222fef2a7 container client-container: <nil>
STEP: delete the pod
Aug 12 17:36:42.173: INFO: Waiting for pod downwardapi-volume-cf60cf16-6e2a-4d9e-ac9c-6af222fef2a7 to disappear
Aug 12 17:36:42.177: INFO: Pod downwardapi-volume-cf60cf16-6e2a-4d9e-ac9c-6af222fef2a7 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:36:42.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4973" for this suite.
Aug 12 17:36:48.217: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:36:48.403: INFO: namespace projected-4973 deletion completed in 6.220239935s

 [SLOW TEST:10.515 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:36:48.407: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Aug 12 17:36:48.512: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug 12 17:36:48.545: INFO: Waiting for terminating namespaces to be deleted...
Aug 12 17:36:48.550: INFO: 
Logging pods the kubelet thinks is on node conformance-1-15-2-do-0-default-pool-rxf2 before test
Aug 12 17:36:48.565: INFO: sonobuoy from heptio-sonobuoy started at 2019-08-12 16:09:30 +0000 UTC (1 container statuses recorded)
Aug 12 17:36:48.566: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug 12 17:36:48.566: INFO: sonobuoy-systemd-logs-daemon-set-a0296875de8f4bfa-l5d86 from heptio-sonobuoy started at 2019-08-12 16:09:33 +0000 UTC (2 container statuses recorded)
Aug 12 17:36:48.566: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug 12 17:36:48.566: INFO: 	Container systemd-logs ready: true, restart count 1
Aug 12 17:36:48.566: INFO: cilium-n97lp from kube-system started at 2019-08-12 13:17:34 +0000 UTC (1 container statuses recorded)
Aug 12 17:36:48.566: INFO: 	Container cilium-agent ready: true, restart count 1
Aug 12 17:36:48.566: INFO: csi-do-node-8hbn9 from kube-system started at 2019-08-12 13:17:34 +0000 UTC (2 container statuses recorded)
Aug 12 17:36:48.566: INFO: 	Container csi-do-plugin ready: true, restart count 0
Aug 12 17:36:48.566: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Aug 12 17:36:48.566: INFO: do-node-agent-jsj6x from kube-system started at 2019-08-12 13:17:54 +0000 UTC (1 container statuses recorded)
Aug 12 17:36:48.566: INFO: 	Container do-node-agent ready: true, restart count 0
Aug 12 17:36:48.566: INFO: kube-proxy-bxfsv from kube-system started at 2019-08-12 13:17:34 +0000 UTC (1 container statuses recorded)
Aug 12 17:36:48.566: INFO: 	Container kube-proxy ready: true, restart count 0
Aug 12 17:36:48.566: INFO: 
Logging pods the kubelet thinks is on node conformance-1-15-2-do-0-default-pool-rxfp before test
Aug 12 17:36:48.575: INFO: cilium-6xm9z from kube-system started at 2019-08-12 13:17:27 +0000 UTC (1 container statuses recorded)
Aug 12 17:36:48.575: INFO: 	Container cilium-agent ready: true, restart count 1
Aug 12 17:36:48.575: INFO: csi-do-node-xqsbs from kube-system started at 2019-08-12 13:17:27 +0000 UTC (2 container statuses recorded)
Aug 12 17:36:48.575: INFO: 	Container csi-do-plugin ready: true, restart count 0
Aug 12 17:36:48.575: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Aug 12 17:36:48.575: INFO: sonobuoy-systemd-logs-daemon-set-a0296875de8f4bfa-wmb87 from heptio-sonobuoy started at 2019-08-12 16:09:33 +0000 UTC (2 container statuses recorded)
Aug 12 17:36:48.575: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug 12 17:36:48.575: INFO: 	Container systemd-logs ready: true, restart count 1
Aug 12 17:36:48.575: INFO: kube-proxy-dkvd4 from kube-system started at 2019-08-12 13:17:27 +0000 UTC (1 container statuses recorded)
Aug 12 17:36:48.575: INFO: 	Container kube-proxy ready: true, restart count 0
Aug 12 17:36:48.575: INFO: sonobuoy-e2e-job-e176e22cbea8475f from heptio-sonobuoy started at 2019-08-12 16:09:32 +0000 UTC (2 container statuses recorded)
Aug 12 17:36:48.576: INFO: 	Container e2e ready: true, restart count 0
Aug 12 17:36:48.576: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 12 17:36:48.576: INFO: do-node-agent-f9wvg from kube-system started at 2019-08-12 13:17:47 +0000 UTC (1 container statuses recorded)
Aug 12 17:36:48.576: INFO: 	Container do-node-agent ready: true, restart count 0
Aug 12 17:36:48.576: INFO: 
Logging pods the kubelet thinks is on node conformance-1-15-2-do-0-default-pool-rxfs before test
Aug 12 17:36:48.588: INFO: cilium-operator-57586bb7cb-phl6l from kube-system started at 2019-08-12 13:16:58 +0000 UTC (1 container statuses recorded)
Aug 12 17:36:48.588: INFO: 	Container cilium-operator ready: true, restart count 18
Aug 12 17:36:48.588: INFO: cilium-76ggb from kube-system started at 2019-08-12 13:16:30 +0000 UTC (1 container statuses recorded)
Aug 12 17:36:48.588: INFO: 	Container cilium-agent ready: true, restart count 1
Aug 12 17:36:48.588: INFO: csi-do-node-hk2h2 from kube-system started at 2019-08-12 13:16:30 +0000 UTC (2 container statuses recorded)
Aug 12 17:36:48.588: INFO: 	Container csi-do-plugin ready: true, restart count 0
Aug 12 17:36:48.588: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Aug 12 17:36:48.588: INFO: coredns-9d6bf9876-p8wkw from kube-system started at 2019-08-12 13:16:50 +0000 UTC (1 container statuses recorded)
Aug 12 17:36:48.588: INFO: 	Container coredns ready: true, restart count 1
Aug 12 17:36:48.588: INFO: coredns-9d6bf9876-s2nng from kube-system started at 2019-08-12 13:16:58 +0000 UTC (1 container statuses recorded)
Aug 12 17:36:48.588: INFO: 	Container coredns ready: true, restart count 0
Aug 12 17:36:48.588: INFO: sonobuoy-systemd-logs-daemon-set-a0296875de8f4bfa-qlrgc from heptio-sonobuoy started at 2019-08-12 16:09:33 +0000 UTC (2 container statuses recorded)
Aug 12 17:36:48.588: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug 12 17:36:48.588: INFO: 	Container systemd-logs ready: true, restart count 1
Aug 12 17:36:48.588: INFO: kube-proxy-xbm78 from kube-system started at 2019-08-12 13:16:30 +0000 UTC (1 container statuses recorded)
Aug 12 17:36:48.588: INFO: 	Container kube-proxy ready: true, restart count 0
Aug 12 17:36:48.588: INFO: do-node-agent-qvjgl from kube-system started at 2019-08-12 13:16:50 +0000 UTC (1 container statuses recorded)
Aug 12 17:36:48.588: INFO: 	Container do-node-agent ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: verifying the node has the label node conformance-1-15-2-do-0-default-pool-rxf2
STEP: verifying the node has the label node conformance-1-15-2-do-0-default-pool-rxfp
STEP: verifying the node has the label node conformance-1-15-2-do-0-default-pool-rxfs
Aug 12 17:36:48.825: INFO: Pod sonobuoy requesting resource cpu=0m on Node conformance-1-15-2-do-0-default-pool-rxf2
Aug 12 17:36:48.825: INFO: Pod sonobuoy-e2e-job-e176e22cbea8475f requesting resource cpu=0m on Node conformance-1-15-2-do-0-default-pool-rxfp
Aug 12 17:36:48.825: INFO: Pod sonobuoy-systemd-logs-daemon-set-a0296875de8f4bfa-l5d86 requesting resource cpu=0m on Node conformance-1-15-2-do-0-default-pool-rxf2
Aug 12 17:36:48.825: INFO: Pod sonobuoy-systemd-logs-daemon-set-a0296875de8f4bfa-qlrgc requesting resource cpu=0m on Node conformance-1-15-2-do-0-default-pool-rxfs
Aug 12 17:36:48.825: INFO: Pod sonobuoy-systemd-logs-daemon-set-a0296875de8f4bfa-wmb87 requesting resource cpu=0m on Node conformance-1-15-2-do-0-default-pool-rxfp
Aug 12 17:36:48.825: INFO: Pod cilium-6xm9z requesting resource cpu=300m on Node conformance-1-15-2-do-0-default-pool-rxfp
Aug 12 17:36:48.825: INFO: Pod cilium-76ggb requesting resource cpu=300m on Node conformance-1-15-2-do-0-default-pool-rxfs
Aug 12 17:36:48.825: INFO: Pod cilium-n97lp requesting resource cpu=300m on Node conformance-1-15-2-do-0-default-pool-rxf2
Aug 12 17:36:48.825: INFO: Pod cilium-operator-57586bb7cb-phl6l requesting resource cpu=0m on Node conformance-1-15-2-do-0-default-pool-rxfs
Aug 12 17:36:48.825: INFO: Pod coredns-9d6bf9876-p8wkw requesting resource cpu=100m on Node conformance-1-15-2-do-0-default-pool-rxfs
Aug 12 17:36:48.825: INFO: Pod coredns-9d6bf9876-s2nng requesting resource cpu=100m on Node conformance-1-15-2-do-0-default-pool-rxfs
Aug 12 17:36:48.825: INFO: Pod csi-do-node-8hbn9 requesting resource cpu=0m on Node conformance-1-15-2-do-0-default-pool-rxf2
Aug 12 17:36:48.825: INFO: Pod csi-do-node-hk2h2 requesting resource cpu=0m on Node conformance-1-15-2-do-0-default-pool-rxfs
Aug 12 17:36:48.825: INFO: Pod csi-do-node-xqsbs requesting resource cpu=0m on Node conformance-1-15-2-do-0-default-pool-rxfp
Aug 12 17:36:48.825: INFO: Pod do-node-agent-f9wvg requesting resource cpu=102m on Node conformance-1-15-2-do-0-default-pool-rxfp
Aug 12 17:36:48.825: INFO: Pod do-node-agent-jsj6x requesting resource cpu=102m on Node conformance-1-15-2-do-0-default-pool-rxf2
Aug 12 17:36:48.825: INFO: Pod do-node-agent-qvjgl requesting resource cpu=102m on Node conformance-1-15-2-do-0-default-pool-rxfs
Aug 12 17:36:48.825: INFO: Pod kube-proxy-bxfsv requesting resource cpu=0m on Node conformance-1-15-2-do-0-default-pool-rxf2
Aug 12 17:36:48.825: INFO: Pod kube-proxy-dkvd4 requesting resource cpu=0m on Node conformance-1-15-2-do-0-default-pool-rxfp
Aug 12 17:36:48.825: INFO: Pod kube-proxy-xbm78 requesting resource cpu=0m on Node conformance-1-15-2-do-0-default-pool-rxfs
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-18e9f43b-4510-4003-bb80-eed8865bd885.15ba3d78a4bafd89], Reason = [Scheduled], Message = [Successfully assigned sched-pred-6311/filler-pod-18e9f43b-4510-4003-bb80-eed8865bd885 to conformance-1-15-2-do-0-default-pool-rxf2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-18e9f43b-4510-4003-bb80-eed8865bd885.15ba3d79092bd76e], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-18e9f43b-4510-4003-bb80-eed8865bd885.15ba3d790c799298], Reason = [Created], Message = [Created container filler-pod-18e9f43b-4510-4003-bb80-eed8865bd885]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-18e9f43b-4510-4003-bb80-eed8865bd885.15ba3d791c77313c], Reason = [Started], Message = [Started container filler-pod-18e9f43b-4510-4003-bb80-eed8865bd885]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9dbeb930-d202-41ee-91f2-9af65924526c.15ba3d78a5949ddc], Reason = [Scheduled], Message = [Successfully assigned sched-pred-6311/filler-pod-9dbeb930-d202-41ee-91f2-9af65924526c to conformance-1-15-2-do-0-default-pool-rxfp]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9dbeb930-d202-41ee-91f2-9af65924526c.15ba3d79085da9e4], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9dbeb930-d202-41ee-91f2-9af65924526c.15ba3d790b7da6b4], Reason = [Created], Message = [Created container filler-pod-9dbeb930-d202-41ee-91f2-9af65924526c]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9dbeb930-d202-41ee-91f2-9af65924526c.15ba3d7918652ba8], Reason = [Started], Message = [Started container filler-pod-9dbeb930-d202-41ee-91f2-9af65924526c]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-fdf4af3c-bedc-4947-8261-2cf3fa153bfc.15ba3d78a65758e6], Reason = [Scheduled], Message = [Successfully assigned sched-pred-6311/filler-pod-fdf4af3c-bedc-4947-8261-2cf3fa153bfc to conformance-1-15-2-do-0-default-pool-rxfs]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-fdf4af3c-bedc-4947-8261-2cf3fa153bfc.15ba3d7900d9da09], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-fdf4af3c-bedc-4947-8261-2cf3fa153bfc.15ba3d790425d349], Reason = [Created], Message = [Created container filler-pod-fdf4af3c-bedc-4947-8261-2cf3fa153bfc]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-fdf4af3c-bedc-4947-8261-2cf3fa153bfc.15ba3d79113fc2c5], Reason = [Started], Message = [Started container filler-pod-fdf4af3c-bedc-4947-8261-2cf3fa153bfc]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15ba3d7996b0204f], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node conformance-1-15-2-do-0-default-pool-rxfp
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node conformance-1-15-2-do-0-default-pool-rxfs
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node conformance-1-15-2-do-0-default-pool-rxf2
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:36:54.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-6311" for this suite.
Aug 12 17:37:00.027: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:37:00.168: INFO: namespace sched-pred-6311 deletion completed in 6.156498979s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

 [SLOW TEST:11.762 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:37:00.171: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with configMap that has name projected-configmap-test-upd-9c776745-15d9-45d3-b434-7eafdd710c28
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-9c776745-15d9-45d3-b434-7eafdd710c28
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:38:23.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7034" for this suite.
Aug 12 17:38:45.206: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:38:45.326: INFO: namespace projected-7034 deletion completed in 22.133758728s

 [SLOW TEST:105.156 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:38:45.331: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Aug 12 17:38:45.369: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug 12 17:38:45.376: INFO: Waiting for terminating namespaces to be deleted...
Aug 12 17:38:45.380: INFO: 
Logging pods the kubelet thinks is on node conformance-1-15-2-do-0-default-pool-rxf2 before test
Aug 12 17:38:45.387: INFO: csi-do-node-8hbn9 from kube-system started at 2019-08-12 13:17:34 +0000 UTC (2 container statuses recorded)
Aug 12 17:38:45.388: INFO: 	Container csi-do-plugin ready: true, restart count 0
Aug 12 17:38:45.388: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Aug 12 17:38:45.388: INFO: do-node-agent-jsj6x from kube-system started at 2019-08-12 13:17:54 +0000 UTC (1 container statuses recorded)
Aug 12 17:38:45.388: INFO: 	Container do-node-agent ready: true, restart count 0
Aug 12 17:38:45.388: INFO: sonobuoy from heptio-sonobuoy started at 2019-08-12 16:09:30 +0000 UTC (1 container statuses recorded)
Aug 12 17:38:45.388: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug 12 17:38:45.388: INFO: sonobuoy-systemd-logs-daemon-set-a0296875de8f4bfa-l5d86 from heptio-sonobuoy started at 2019-08-12 16:09:33 +0000 UTC (2 container statuses recorded)
Aug 12 17:38:45.388: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug 12 17:38:45.388: INFO: 	Container systemd-logs ready: true, restart count 1
Aug 12 17:38:45.388: INFO: cilium-n97lp from kube-system started at 2019-08-12 13:17:34 +0000 UTC (1 container statuses recorded)
Aug 12 17:38:45.389: INFO: 	Container cilium-agent ready: true, restart count 1
Aug 12 17:38:45.389: INFO: kube-proxy-bxfsv from kube-system started at 2019-08-12 13:17:34 +0000 UTC (1 container statuses recorded)
Aug 12 17:38:45.389: INFO: 	Container kube-proxy ready: true, restart count 0
Aug 12 17:38:45.389: INFO: 
Logging pods the kubelet thinks is on node conformance-1-15-2-do-0-default-pool-rxfp before test
Aug 12 17:38:45.397: INFO: cilium-6xm9z from kube-system started at 2019-08-12 13:17:27 +0000 UTC (1 container statuses recorded)
Aug 12 17:38:45.397: INFO: 	Container cilium-agent ready: true, restart count 1
Aug 12 17:38:45.397: INFO: csi-do-node-xqsbs from kube-system started at 2019-08-12 13:17:27 +0000 UTC (2 container statuses recorded)
Aug 12 17:38:45.397: INFO: 	Container csi-do-plugin ready: true, restart count 0
Aug 12 17:38:45.398: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Aug 12 17:38:45.398: INFO: sonobuoy-systemd-logs-daemon-set-a0296875de8f4bfa-wmb87 from heptio-sonobuoy started at 2019-08-12 16:09:33 +0000 UTC (2 container statuses recorded)
Aug 12 17:38:45.398: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug 12 17:38:45.398: INFO: 	Container systemd-logs ready: true, restart count 1
Aug 12 17:38:45.398: INFO: kube-proxy-dkvd4 from kube-system started at 2019-08-12 13:17:27 +0000 UTC (1 container statuses recorded)
Aug 12 17:38:45.398: INFO: 	Container kube-proxy ready: true, restart count 0
Aug 12 17:38:45.399: INFO: sonobuoy-e2e-job-e176e22cbea8475f from heptio-sonobuoy started at 2019-08-12 16:09:32 +0000 UTC (2 container statuses recorded)
Aug 12 17:38:45.399: INFO: 	Container e2e ready: true, restart count 0
Aug 12 17:38:45.399: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 12 17:38:45.399: INFO: do-node-agent-f9wvg from kube-system started at 2019-08-12 13:17:47 +0000 UTC (1 container statuses recorded)
Aug 12 17:38:45.399: INFO: 	Container do-node-agent ready: true, restart count 0
Aug 12 17:38:45.400: INFO: 
Logging pods the kubelet thinks is on node conformance-1-15-2-do-0-default-pool-rxfs before test
Aug 12 17:38:45.409: INFO: kube-proxy-xbm78 from kube-system started at 2019-08-12 13:16:30 +0000 UTC (1 container statuses recorded)
Aug 12 17:38:45.409: INFO: 	Container kube-proxy ready: true, restart count 0
Aug 12 17:38:45.409: INFO: do-node-agent-qvjgl from kube-system started at 2019-08-12 13:16:50 +0000 UTC (1 container statuses recorded)
Aug 12 17:38:45.409: INFO: 	Container do-node-agent ready: true, restart count 0
Aug 12 17:38:45.409: INFO: cilium-76ggb from kube-system started at 2019-08-12 13:16:30 +0000 UTC (1 container statuses recorded)
Aug 12 17:38:45.410: INFO: 	Container cilium-agent ready: true, restart count 1
Aug 12 17:38:45.410: INFO: csi-do-node-hk2h2 from kube-system started at 2019-08-12 13:16:30 +0000 UTC (2 container statuses recorded)
Aug 12 17:38:45.410: INFO: 	Container csi-do-plugin ready: true, restart count 0
Aug 12 17:38:45.410: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Aug 12 17:38:45.410: INFO: coredns-9d6bf9876-p8wkw from kube-system started at 2019-08-12 13:16:50 +0000 UTC (1 container statuses recorded)
Aug 12 17:38:45.410: INFO: 	Container coredns ready: true, restart count 1
Aug 12 17:38:45.410: INFO: cilium-operator-57586bb7cb-phl6l from kube-system started at 2019-08-12 13:16:58 +0000 UTC (1 container statuses recorded)
Aug 12 17:38:45.410: INFO: 	Container cilium-operator ready: true, restart count 18
Aug 12 17:38:45.410: INFO: coredns-9d6bf9876-s2nng from kube-system started at 2019-08-12 13:16:58 +0000 UTC (1 container statuses recorded)
Aug 12 17:38:45.410: INFO: 	Container coredns ready: true, restart count 0
Aug 12 17:38:45.410: INFO: sonobuoy-systemd-logs-daemon-set-a0296875de8f4bfa-qlrgc from heptio-sonobuoy started at 2019-08-12 16:09:33 +0000 UTC (2 container statuses recorded)
Aug 12 17:38:45.410: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug 12 17:38:45.411: INFO: 	Container systemd-logs ready: true, restart count 1
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-89b10296-54fe-4bc5-a93b-fa7f50ebb9f8 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-89b10296-54fe-4bc5-a93b-fa7f50ebb9f8 off the node conformance-1-15-2-do-0-default-pool-rxfs
STEP: verifying the node doesn't have the label kubernetes.io/e2e-89b10296-54fe-4bc5-a93b-fa7f50ebb9f8
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:38:53.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-6776" for this suite.
Aug 12 17:39:11.620: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:39:11.755: INFO: namespace sched-pred-6776 deletion completed in 18.152415371s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

 [SLOW TEST:26.424 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:39:11.759: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 12 17:39:18.128: INFO: Waiting up to 5m0s for pod "client-envvars-210dfa64-5583-4eeb-861f-48e582716023" in namespace "pods-2672" to be "success or failure"
Aug 12 17:39:18.174: INFO: Pod "client-envvars-210dfa64-5583-4eeb-861f-48e582716023": Phase="Pending", Reason="", readiness=false. Elapsed: 46.211567ms
Aug 12 17:39:20.182: INFO: Pod "client-envvars-210dfa64-5583-4eeb-861f-48e582716023": Phase="Pending", Reason="", readiness=false. Elapsed: 2.054299496s
Aug 12 17:39:22.189: INFO: Pod "client-envvars-210dfa64-5583-4eeb-861f-48e582716023": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.060810448s
STEP: Saw pod success
Aug 12 17:39:22.189: INFO: Pod "client-envvars-210dfa64-5583-4eeb-861f-48e582716023" satisfied condition "success or failure"
Aug 12 17:39:22.195: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxf2 pod client-envvars-210dfa64-5583-4eeb-861f-48e582716023 container env3cont: <nil>
STEP: delete the pod
Aug 12 17:39:22.303: INFO: Waiting for pod client-envvars-210dfa64-5583-4eeb-861f-48e582716023 to disappear
Aug 12 17:39:22.307: INFO: Pod client-envvars-210dfa64-5583-4eeb-861f-48e582716023 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:39:22.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2672" for this suite.
Aug 12 17:40:00.357: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:40:00.541: INFO: namespace pods-2672 deletion completed in 38.229213326s

 [SLOW TEST:48.783 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:40:00.549: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Aug 12 17:40:00.782: INFO: Number of nodes with available pods: 0
Aug 12 17:40:00.782: INFO: Node conformance-1-15-2-do-0-default-pool-rxf2 is running more than one daemon pod
Aug 12 17:40:02.428: INFO: Number of nodes with available pods: 0
Aug 12 17:40:02.428: INFO: Node conformance-1-15-2-do-0-default-pool-rxf2 is running more than one daemon pod
Aug 12 17:40:02.805: INFO: Number of nodes with available pods: 0
Aug 12 17:40:02.806: INFO: Node conformance-1-15-2-do-0-default-pool-rxf2 is running more than one daemon pod
Aug 12 17:40:03.797: INFO: Number of nodes with available pods: 1
Aug 12 17:40:03.798: INFO: Node conformance-1-15-2-do-0-default-pool-rxf2 is running more than one daemon pod
Aug 12 17:40:04.797: INFO: Number of nodes with available pods: 3
Aug 12 17:40:04.798: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Aug 12 17:40:04.849: INFO: Number of nodes with available pods: 2
Aug 12 17:40:04.849: INFO: Node conformance-1-15-2-do-0-default-pool-rxf2 is running more than one daemon pod
Aug 12 17:40:05.862: INFO: Number of nodes with available pods: 2
Aug 12 17:40:05.862: INFO: Node conformance-1-15-2-do-0-default-pool-rxf2 is running more than one daemon pod
Aug 12 17:40:06.860: INFO: Number of nodes with available pods: 2
Aug 12 17:40:06.860: INFO: Node conformance-1-15-2-do-0-default-pool-rxf2 is running more than one daemon pod
Aug 12 17:40:07.860: INFO: Number of nodes with available pods: 2
Aug 12 17:40:07.861: INFO: Node conformance-1-15-2-do-0-default-pool-rxf2 is running more than one daemon pod
Aug 12 17:40:08.859: INFO: Number of nodes with available pods: 3
Aug 12 17:40:08.859: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7148, will wait for the garbage collector to delete the pods
Aug 12 17:40:08.929: INFO: Deleting DaemonSet.extensions daemon-set took: 7.385813ms
Aug 12 17:40:09.329: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.492301ms
Aug 12 17:40:12.237: INFO: Number of nodes with available pods: 0
Aug 12 17:40:12.237: INFO: Number of running nodes: 0, number of available pods: 0
Aug 12 17:40:12.243: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7148/daemonsets","resourceVersion":"59084"},"items":null}

Aug 12 17:40:12.247: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7148/pods","resourceVersion":"59084"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:40:12.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7148" for this suite.
Aug 12 17:40:18.302: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:40:18.450: INFO: namespace daemonsets-7148 deletion completed in 6.160060405s

 [SLOW TEST:17.902 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:40:18.452: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-2408/configmap-test-1a6ceeb0-934e-40ad-be30-766b862f1309
STEP: Creating a pod to test consume configMaps
Aug 12 17:40:18.580: INFO: Waiting up to 5m0s for pod "pod-configmaps-c71b5e81-0875-4ade-ac53-a95363dfb591" in namespace "configmap-2408" to be "success or failure"
Aug 12 17:40:18.589: INFO: Pod "pod-configmaps-c71b5e81-0875-4ade-ac53-a95363dfb591": Phase="Pending", Reason="", readiness=false. Elapsed: 8.168986ms
Aug 12 17:40:20.596: INFO: Pod "pod-configmaps-c71b5e81-0875-4ade-ac53-a95363dfb591": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01576373s
Aug 12 17:40:22.611: INFO: Pod "pod-configmaps-c71b5e81-0875-4ade-ac53-a95363dfb591": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030198941s
STEP: Saw pod success
Aug 12 17:40:22.611: INFO: Pod "pod-configmaps-c71b5e81-0875-4ade-ac53-a95363dfb591" satisfied condition "success or failure"
Aug 12 17:40:22.614: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxfs pod pod-configmaps-c71b5e81-0875-4ade-ac53-a95363dfb591 container env-test: <nil>
STEP: delete the pod
Aug 12 17:40:22.642: INFO: Waiting for pod pod-configmaps-c71b5e81-0875-4ade-ac53-a95363dfb591 to disappear
Aug 12 17:40:22.656: INFO: Pod pod-configmaps-c71b5e81-0875-4ade-ac53-a95363dfb591 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:40:22.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2408" for this suite.
Aug 12 17:40:28.687: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:40:28.820: INFO: namespace configmap-2408 deletion completed in 6.15690282s

 [SLOW TEST:10.369 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:40:28.824: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-8nw7
STEP: Creating a pod to test atomic-volume-subpath
Aug 12 17:40:28.946: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-8nw7" in namespace "subpath-9811" to be "success or failure"
Aug 12 17:40:28.959: INFO: Pod "pod-subpath-test-configmap-8nw7": Phase="Pending", Reason="", readiness=false. Elapsed: 11.737758ms
Aug 12 17:40:30.963: INFO: Pod "pod-subpath-test-configmap-8nw7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015843147s
Aug 12 17:40:32.967: INFO: Pod "pod-subpath-test-configmap-8nw7": Phase="Running", Reason="", readiness=true. Elapsed: 4.020179278s
Aug 12 17:40:34.971: INFO: Pod "pod-subpath-test-configmap-8nw7": Phase="Running", Reason="", readiness=true. Elapsed: 6.02447137s
Aug 12 17:40:36.978: INFO: Pod "pod-subpath-test-configmap-8nw7": Phase="Running", Reason="", readiness=true. Elapsed: 8.031125093s
Aug 12 17:40:38.986: INFO: Pod "pod-subpath-test-configmap-8nw7": Phase="Running", Reason="", readiness=true. Elapsed: 10.039087965s
Aug 12 17:40:40.998: INFO: Pod "pod-subpath-test-configmap-8nw7": Phase="Running", Reason="", readiness=true. Elapsed: 12.050998076s
Aug 12 17:40:43.013: INFO: Pod "pod-subpath-test-configmap-8nw7": Phase="Running", Reason="", readiness=true. Elapsed: 14.065822542s
Aug 12 17:40:45.020: INFO: Pod "pod-subpath-test-configmap-8nw7": Phase="Running", Reason="", readiness=true. Elapsed: 16.073126024s
Aug 12 17:40:47.028: INFO: Pod "pod-subpath-test-configmap-8nw7": Phase="Running", Reason="", readiness=true. Elapsed: 18.080780483s
Aug 12 17:40:49.034: INFO: Pod "pod-subpath-test-configmap-8nw7": Phase="Running", Reason="", readiness=true. Elapsed: 20.087269411s
Aug 12 17:40:51.039: INFO: Pod "pod-subpath-test-configmap-8nw7": Phase="Running", Reason="", readiness=true. Elapsed: 22.092478466s
Aug 12 17:40:53.045: INFO: Pod "pod-subpath-test-configmap-8nw7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.098056071s
STEP: Saw pod success
Aug 12 17:40:53.045: INFO: Pod "pod-subpath-test-configmap-8nw7" satisfied condition "success or failure"
Aug 12 17:40:53.056: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxfp pod pod-subpath-test-configmap-8nw7 container test-container-subpath-configmap-8nw7: <nil>
STEP: delete the pod
Aug 12 17:40:53.103: INFO: Waiting for pod pod-subpath-test-configmap-8nw7 to disappear
Aug 12 17:40:53.108: INFO: Pod pod-subpath-test-configmap-8nw7 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-8nw7
Aug 12 17:40:53.108: INFO: Deleting pod "pod-subpath-test-configmap-8nw7" in namespace "subpath-9811"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:40:53.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9811" for this suite.
Aug 12 17:40:59.137: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:40:59.293: INFO: namespace subpath-9811 deletion completed in 6.176655309s

 [SLOW TEST:30.470 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:40:59.307: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
Aug 12 17:40:59.967: INFO: created pod pod-service-account-defaultsa
Aug 12 17:40:59.968: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Aug 12 17:40:59.980: INFO: created pod pod-service-account-mountsa
Aug 12 17:40:59.980: INFO: pod pod-service-account-mountsa service account token volume mount: true
Aug 12 17:40:59.991: INFO: created pod pod-service-account-nomountsa
Aug 12 17:40:59.992: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Aug 12 17:41:00.006: INFO: created pod pod-service-account-defaultsa-mountspec
Aug 12 17:41:00.007: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Aug 12 17:41:00.023: INFO: created pod pod-service-account-mountsa-mountspec
Aug 12 17:41:00.024: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Aug 12 17:41:00.036: INFO: created pod pod-service-account-nomountsa-mountspec
Aug 12 17:41:00.036: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Aug 12 17:41:00.048: INFO: created pod pod-service-account-defaultsa-nomountspec
Aug 12 17:41:00.048: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Aug 12 17:41:00.056: INFO: created pod pod-service-account-mountsa-nomountspec
Aug 12 17:41:00.056: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Aug 12 17:41:00.071: INFO: created pod pod-service-account-nomountsa-nomountspec
Aug 12 17:41:00.072: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:41:00.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4994" for this suite.
Aug 12 17:41:22.123: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:41:22.279: INFO: namespace svcaccounts-4994 deletion completed in 22.185258479s

 [SLOW TEST:22.973 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:41:22.287: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test env composition
Aug 12 17:41:22.388: INFO: Waiting up to 5m0s for pod "var-expansion-5c1ef58b-e3be-465c-8e66-20a5e48210eb" in namespace "var-expansion-783" to be "success or failure"
Aug 12 17:41:22.403: INFO: Pod "var-expansion-5c1ef58b-e3be-465c-8e66-20a5e48210eb": Phase="Pending", Reason="", readiness=false. Elapsed: 13.863921ms
Aug 12 17:41:24.411: INFO: Pod "var-expansion-5c1ef58b-e3be-465c-8e66-20a5e48210eb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022118982s
Aug 12 17:41:26.416: INFO: Pod "var-expansion-5c1ef58b-e3be-465c-8e66-20a5e48210eb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026967368s
STEP: Saw pod success
Aug 12 17:41:26.416: INFO: Pod "var-expansion-5c1ef58b-e3be-465c-8e66-20a5e48210eb" satisfied condition "success or failure"
Aug 12 17:41:26.419: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxf2 pod var-expansion-5c1ef58b-e3be-465c-8e66-20a5e48210eb container dapi-container: <nil>
STEP: delete the pod
Aug 12 17:41:26.449: INFO: Waiting for pod var-expansion-5c1ef58b-e3be-465c-8e66-20a5e48210eb to disappear
Aug 12 17:41:26.453: INFO: Pod var-expansion-5c1ef58b-e3be-465c-8e66-20a5e48210eb no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:41:26.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-783" for this suite.
Aug 12 17:41:32.475: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:41:32.697: INFO: namespace var-expansion-783 deletion completed in 6.237645609s

 [SLOW TEST:10.411 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:41:32.701: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 12 17:41:32.763: INFO: Waiting up to 5m0s for pod "downwardapi-volume-53fadad8-3c85-4a56-ac09-af88181e8cbb" in namespace "downward-api-3382" to be "success or failure"
Aug 12 17:41:32.775: INFO: Pod "downwardapi-volume-53fadad8-3c85-4a56-ac09-af88181e8cbb": Phase="Pending", Reason="", readiness=false. Elapsed: 11.948316ms
Aug 12 17:41:34.781: INFO: Pod "downwardapi-volume-53fadad8-3c85-4a56-ac09-af88181e8cbb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01813871s
Aug 12 17:41:36.786: INFO: Pod "downwardapi-volume-53fadad8-3c85-4a56-ac09-af88181e8cbb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023468439s
STEP: Saw pod success
Aug 12 17:41:36.787: INFO: Pod "downwardapi-volume-53fadad8-3c85-4a56-ac09-af88181e8cbb" satisfied condition "success or failure"
Aug 12 17:41:36.794: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxf2 pod downwardapi-volume-53fadad8-3c85-4a56-ac09-af88181e8cbb container client-container: <nil>
STEP: delete the pod
Aug 12 17:41:36.841: INFO: Waiting for pod downwardapi-volume-53fadad8-3c85-4a56-ac09-af88181e8cbb to disappear
Aug 12 17:41:36.847: INFO: Pod downwardapi-volume-53fadad8-3c85-4a56-ac09-af88181e8cbb no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:41:36.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3382" for this suite.
Aug 12 17:41:42.872: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:41:43.088: INFO: namespace downward-api-3382 deletion completed in 6.230347577s

 [SLOW TEST:10.388 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:41:43.097: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-4dsp
STEP: Creating a pod to test atomic-volume-subpath
Aug 12 17:41:43.236: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-4dsp" in namespace "subpath-553" to be "success or failure"
Aug 12 17:41:43.254: INFO: Pod "pod-subpath-test-configmap-4dsp": Phase="Pending", Reason="", readiness=false. Elapsed: 17.908314ms
Aug 12 17:41:45.262: INFO: Pod "pod-subpath-test-configmap-4dsp": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025497845s
Aug 12 17:41:47.269: INFO: Pod "pod-subpath-test-configmap-4dsp": Phase="Running", Reason="", readiness=true. Elapsed: 4.032938137s
Aug 12 17:41:49.276: INFO: Pod "pod-subpath-test-configmap-4dsp": Phase="Running", Reason="", readiness=true. Elapsed: 6.039535426s
Aug 12 17:41:51.280: INFO: Pod "pod-subpath-test-configmap-4dsp": Phase="Running", Reason="", readiness=true. Elapsed: 8.043813097s
Aug 12 17:41:53.285: INFO: Pod "pod-subpath-test-configmap-4dsp": Phase="Running", Reason="", readiness=true. Elapsed: 10.048903019s
Aug 12 17:41:55.291: INFO: Pod "pod-subpath-test-configmap-4dsp": Phase="Running", Reason="", readiness=true. Elapsed: 12.054918096s
Aug 12 17:41:57.296: INFO: Pod "pod-subpath-test-configmap-4dsp": Phase="Running", Reason="", readiness=true. Elapsed: 14.059322202s
Aug 12 17:41:59.300: INFO: Pod "pod-subpath-test-configmap-4dsp": Phase="Running", Reason="", readiness=true. Elapsed: 16.063686696s
Aug 12 17:42:01.305: INFO: Pod "pod-subpath-test-configmap-4dsp": Phase="Running", Reason="", readiness=true. Elapsed: 18.068637594s
Aug 12 17:42:03.319: INFO: Pod "pod-subpath-test-configmap-4dsp": Phase="Running", Reason="", readiness=true. Elapsed: 20.083033183s
Aug 12 17:42:05.323: INFO: Pod "pod-subpath-test-configmap-4dsp": Phase="Running", Reason="", readiness=true. Elapsed: 22.08685256s
Aug 12 17:42:07.328: INFO: Pod "pod-subpath-test-configmap-4dsp": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.09161265s
STEP: Saw pod success
Aug 12 17:42:07.328: INFO: Pod "pod-subpath-test-configmap-4dsp" satisfied condition "success or failure"
Aug 12 17:42:07.331: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxfp pod pod-subpath-test-configmap-4dsp container test-container-subpath-configmap-4dsp: <nil>
STEP: delete the pod
Aug 12 17:42:07.355: INFO: Waiting for pod pod-subpath-test-configmap-4dsp to disappear
Aug 12 17:42:07.361: INFO: Pod pod-subpath-test-configmap-4dsp no longer exists
STEP: Deleting pod pod-subpath-test-configmap-4dsp
Aug 12 17:42:07.361: INFO: Deleting pod "pod-subpath-test-configmap-4dsp" in namespace "subpath-553"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:42:07.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-553" for this suite.
Aug 12 17:42:13.389: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:42:13.519: INFO: namespace subpath-553 deletion completed in 6.145691429s

 [SLOW TEST:30.423 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:42:13.525: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name secret-emptykey-test-22d03728-0293-44fa-b7f1-2e92d0f36771
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:42:13.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-516" for this suite.
Aug 12 17:42:19.593: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:42:19.763: INFO: namespace secrets-516 deletion completed in 6.183788322s

 [SLOW TEST:6.238 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:42:19.774: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the initial replication controller
Aug 12 17:42:19.885: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 create -f - --namespace=kubectl-3916'
Aug 12 17:42:20.439: INFO: stderr: ""
Aug 12 17:42:20.439: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 12 17:42:20.439: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3916'
Aug 12 17:42:20.562: INFO: stderr: ""
Aug 12 17:42:20.562: INFO: stdout: "update-demo-nautilus-6hkfg update-demo-nautilus-zbrwr "
Aug 12 17:42:20.562: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 get pods update-demo-nautilus-6hkfg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3916'
Aug 12 17:42:20.686: INFO: stderr: ""
Aug 12 17:42:20.686: INFO: stdout: ""
Aug 12 17:42:20.686: INFO: update-demo-nautilus-6hkfg is created but not running
Aug 12 17:42:25.686: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3916'
Aug 12 17:42:25.815: INFO: stderr: ""
Aug 12 17:42:25.815: INFO: stdout: "update-demo-nautilus-6hkfg update-demo-nautilus-zbrwr "
Aug 12 17:42:25.815: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 get pods update-demo-nautilus-6hkfg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3916'
Aug 12 17:42:25.925: INFO: stderr: ""
Aug 12 17:42:25.925: INFO: stdout: "true"
Aug 12 17:42:25.925: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 get pods update-demo-nautilus-6hkfg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3916'
Aug 12 17:42:26.036: INFO: stderr: ""
Aug 12 17:42:26.036: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 12 17:42:26.036: INFO: validating pod update-demo-nautilus-6hkfg
Aug 12 17:42:26.044: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 12 17:42:26.044: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 12 17:42:26.044: INFO: update-demo-nautilus-6hkfg is verified up and running
Aug 12 17:42:26.044: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 get pods update-demo-nautilus-zbrwr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3916'
Aug 12 17:42:26.175: INFO: stderr: ""
Aug 12 17:42:26.175: INFO: stdout: "true"
Aug 12 17:42:26.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 get pods update-demo-nautilus-zbrwr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3916'
Aug 12 17:42:26.298: INFO: stderr: ""
Aug 12 17:42:26.298: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 12 17:42:26.298: INFO: validating pod update-demo-nautilus-zbrwr
Aug 12 17:42:26.314: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 12 17:42:26.314: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 12 17:42:26.314: INFO: update-demo-nautilus-zbrwr is verified up and running
STEP: rolling-update to new replication controller
Aug 12 17:42:26.319: INFO: scanned /root for discovery docs: <nil>
Aug 12 17:42:26.319: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-3916'
Aug 12 17:42:49.027: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Aug 12 17:42:49.027: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 12 17:42:49.027: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3916'
Aug 12 17:42:49.174: INFO: stderr: ""
Aug 12 17:42:49.174: INFO: stdout: "update-demo-kitten-97srb update-demo-kitten-ctxtt "
Aug 12 17:42:49.174: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 get pods update-demo-kitten-97srb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3916'
Aug 12 17:42:49.275: INFO: stderr: ""
Aug 12 17:42:49.275: INFO: stdout: "true"
Aug 12 17:42:49.275: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 get pods update-demo-kitten-97srb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3916'
Aug 12 17:42:49.400: INFO: stderr: ""
Aug 12 17:42:49.400: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Aug 12 17:42:49.400: INFO: validating pod update-demo-kitten-97srb
Aug 12 17:42:49.411: INFO: got data: {
  "image": "kitten.jpg"
}

Aug 12 17:42:49.411: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Aug 12 17:42:49.411: INFO: update-demo-kitten-97srb is verified up and running
Aug 12 17:42:49.411: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 get pods update-demo-kitten-ctxtt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3916'
Aug 12 17:42:49.516: INFO: stderr: ""
Aug 12 17:42:49.516: INFO: stdout: "true"
Aug 12 17:42:49.516: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-213645099 get pods update-demo-kitten-ctxtt -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3916'
Aug 12 17:42:49.632: INFO: stderr: ""
Aug 12 17:42:49.632: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Aug 12 17:42:49.632: INFO: validating pod update-demo-kitten-ctxtt
Aug 12 17:42:49.639: INFO: got data: {
  "image": "kitten.jpg"
}

Aug 12 17:42:49.639: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Aug 12 17:42:49.639: INFO: update-demo-kitten-ctxtt is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:42:49.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3916" for this suite.
Aug 12 17:43:11.658: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:43:11.840: INFO: namespace kubectl-3916 deletion completed in 22.196512592s

 [SLOW TEST:52.067 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:43:11.848: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-2830c9d9-5121-4edf-a1b9-caade32fde92 in namespace container-probe-2919
Aug 12 17:43:15.923: INFO: Started pod liveness-2830c9d9-5121-4edf-a1b9-caade32fde92 in namespace container-probe-2919
STEP: checking the pod's current state and verifying that restartCount is present
Aug 12 17:43:15.928: INFO: Initial restart count of pod liveness-2830c9d9-5121-4edf-a1b9-caade32fde92 is 0
Aug 12 17:43:29.983: INFO: Restart count of pod container-probe-2919/liveness-2830c9d9-5121-4edf-a1b9-caade32fde92 is now 1 (14.054827094s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:43:29.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2919" for this suite.
Aug 12 17:43:36.020: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:43:36.197: INFO: namespace container-probe-2919 deletion completed in 6.194622882s

 [SLOW TEST:24.349 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:43:36.201: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating replication controller svc-latency-rc in namespace svc-latency-6883
I0812 17:43:36.316364      15 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: svc-latency-6883, replica count: 1
I0812 17:43:37.605127      15 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0812 17:43:38.605845      15 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0812 17:43:39.606848      15 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 12 17:43:39.791: INFO: Created: latency-svc-n75ts
Aug 12 17:43:39.791: INFO: Got endpoints: latency-svc-n75ts [84.333289ms]
Aug 12 17:43:39.820: INFO: Created: latency-svc-l4rv4
Aug 12 17:43:40.202: INFO: Created: latency-svc-c2qkl
Aug 12 17:43:40.203: INFO: Created: latency-svc-twmn2
Aug 12 17:43:40.204: INFO: Created: latency-svc-vm9sb
Aug 12 17:43:40.204: INFO: Created: latency-svc-kqw5f
Aug 12 17:43:40.205: INFO: Created: latency-svc-sfhct
Aug 12 17:43:40.205: INFO: Created: latency-svc-phgsl
Aug 12 17:43:40.205: INFO: Created: latency-svc-sfxkg
Aug 12 17:43:40.205: INFO: Created: latency-svc-zb4zx
Aug 12 17:43:40.206: INFO: Created: latency-svc-6954d
Aug 12 17:43:40.206: INFO: Created: latency-svc-hfpmk
Aug 12 17:43:40.206: INFO: Created: latency-svc-x5zb9
Aug 12 17:43:40.206: INFO: Created: latency-svc-nrx5j
Aug 12 17:43:40.206: INFO: Created: latency-svc-l6svz
Aug 12 17:43:40.207: INFO: Created: latency-svc-cvw8q
Aug 12 17:43:40.207: INFO: Got endpoints: latency-svc-twmn2 [413.427691ms]
Aug 12 17:43:40.207: INFO: Got endpoints: latency-svc-l4rv4 [415.7448ms]
Aug 12 17:43:40.208: INFO: Got endpoints: latency-svc-c2qkl [415.452176ms]
Aug 12 17:43:40.208: INFO: Got endpoints: latency-svc-vm9sb [416.209615ms]
Aug 12 17:43:40.209: INFO: Got endpoints: latency-svc-kqw5f [416.071676ms]
Aug 12 17:43:40.209: INFO: Got endpoints: latency-svc-sfhct [415.674038ms]
Aug 12 17:43:40.209: INFO: Got endpoints: latency-svc-phgsl [416.674043ms]
Aug 12 17:43:40.210: INFO: Got endpoints: latency-svc-sfxkg [416.915967ms]
Aug 12 17:43:40.210: INFO: Got endpoints: latency-svc-zb4zx [417.128928ms]
Aug 12 17:43:40.210: INFO: Got endpoints: latency-svc-6954d [417.341728ms]
Aug 12 17:43:40.211: INFO: Got endpoints: latency-svc-hfpmk [417.553565ms]
Aug 12 17:43:40.211: INFO: Got endpoints: latency-svc-x5zb9 [417.773744ms]
Aug 12 17:43:40.211: INFO: Got endpoints: latency-svc-nrx5j [418.011029ms]
Aug 12 17:43:40.211: INFO: Got endpoints: latency-svc-l6svz [418.245892ms]
Aug 12 17:43:40.212: INFO: Got endpoints: latency-svc-cvw8q [418.443702ms]
Aug 12 17:43:40.237: INFO: Created: latency-svc-wzz9f
Aug 12 17:43:40.301: INFO: Created: latency-svc-bw5zx
Aug 12 17:43:40.301: INFO: Created: latency-svc-sm5w8
Aug 12 17:43:40.501: INFO: Got endpoints: latency-svc-wzz9f [293.635729ms]
Aug 12 17:43:40.501: INFO: Created: latency-svc-rxqzk
Aug 12 17:43:40.501: INFO: Got endpoints: latency-svc-sm5w8 [293.778033ms]
Aug 12 17:43:40.501: INFO: Created: latency-svc-x8spg
Aug 12 17:43:40.501: INFO: Created: latency-svc-fn7l5
Aug 12 17:43:40.501: INFO: Created: latency-svc-m2tg5
Aug 12 17:43:40.501: INFO: Created: latency-svc-9kcxn
Aug 12 17:43:40.502: INFO: Created: latency-svc-qzqq2
Aug 12 17:43:40.502: INFO: Created: latency-svc-k9vpv
Aug 12 17:43:40.502: INFO: Created: latency-svc-pb2x6
Aug 12 17:43:40.502: INFO: Created: latency-svc-gf6lq
Aug 12 17:43:40.502: INFO: Created: latency-svc-jk48z
Aug 12 17:43:40.502: INFO: Created: latency-svc-rsqr8
Aug 12 17:43:40.502: INFO: Got endpoints: latency-svc-rsqr8 [290.684329ms]
Aug 12 17:43:40.502: INFO: Got endpoints: latency-svc-bw5zx [293.883345ms]
Aug 12 17:43:40.502: INFO: Got endpoints: latency-svc-x8spg [290.09152ms]
Aug 12 17:43:40.502: INFO: Got endpoints: latency-svc-fn7l5 [293.719366ms]
Aug 12 17:43:40.502: INFO: Got endpoints: latency-svc-m2tg5 [293.361309ms]
Aug 12 17:43:40.502: INFO: Got endpoints: latency-svc-9kcxn [293.084055ms]
Aug 12 17:43:40.502: INFO: Got endpoints: latency-svc-qzqq2 [292.818186ms]
Aug 12 17:43:40.502: INFO: Got endpoints: latency-svc-k9vpv [292.549944ms]
Aug 12 17:43:40.503: INFO: Got endpoints: latency-svc-pb2x6 [292.323676ms]
Aug 12 17:43:40.503: INFO: Got endpoints: latency-svc-gf6lq [292.093609ms]
Aug 12 17:43:40.503: INFO: Got endpoints: latency-svc-jk48z [291.878952ms]
Aug 12 17:43:40.902: INFO: Created: latency-svc-g8s6r
Aug 12 17:43:40.893: INFO: Got endpoints: latency-svc-rxqzk [681.249355ms]
Aug 12 17:43:40.903: INFO: Created: latency-svc-fk4vx
Aug 12 17:43:40.903: INFO: Created: latency-svc-ldw2m
Aug 12 17:43:40.904: INFO: Got endpoints: latency-svc-ldw2m [402.96209ms]
Aug 12 17:43:40.904: INFO: Got endpoints: latency-svc-fk4vx [692.07029ms]
Aug 12 17:43:40.904: INFO: Created: latency-svc-77mfj
Aug 12 17:43:40.904: INFO: Got endpoints: latency-svc-77mfj [401.801014ms]
Aug 12 17:43:40.904: INFO: Got endpoints: latency-svc-g8s6r [401.783772ms]
Aug 12 17:43:40.905: INFO: Created: latency-svc-pgl54
Aug 12 17:43:40.905: INFO: Got endpoints: latency-svc-pgl54 [404.069707ms]
Aug 12 17:43:40.905: INFO: Created: latency-svc-hlrzn
Aug 12 17:43:40.906: INFO: Got endpoints: latency-svc-hlrzn [404.17386ms]
Aug 12 17:43:40.905: INFO: Created: latency-svc-qwxbg
Aug 12 17:43:40.906: INFO: Got endpoints: latency-svc-qwxbg [404.565491ms]
Aug 12 17:43:40.905: INFO: Created: latency-svc-9dtbg
Aug 12 17:43:40.907: INFO: Got endpoints: latency-svc-9dtbg [404.916621ms]
Aug 12 17:43:40.905: INFO: Created: latency-svc-zl6vw
Aug 12 17:43:40.908: INFO: Got endpoints: latency-svc-zl6vw [405.401108ms]
Aug 12 17:43:40.905: INFO: Created: latency-svc-wmtbs
Aug 12 17:43:40.908: INFO: Got endpoints: latency-svc-wmtbs [405.728748ms]
Aug 12 17:43:40.905: INFO: Created: latency-svc-gq6ns
Aug 12 17:43:40.908: INFO: Got endpoints: latency-svc-gq6ns [405.963141ms]
Aug 12 17:43:40.905: INFO: Created: latency-svc-gswxm
Aug 12 17:43:40.909: INFO: Got endpoints: latency-svc-gswxm [406.173641ms]
Aug 12 17:43:40.905: INFO: Created: latency-svc-qknkg
Aug 12 17:43:40.909: INFO: Got endpoints: latency-svc-qknkg [406.757749ms]
Aug 12 17:43:40.905: INFO: Created: latency-svc-p97q7
Aug 12 17:43:40.910: INFO: Got endpoints: latency-svc-p97q7 [407.089379ms]
Aug 12 17:43:42.054: INFO: Created: latency-svc-rz2qg
Aug 12 17:43:42.241: INFO: Created: latency-svc-thrkc
Aug 12 17:43:42.241: INFO: Got endpoints: latency-svc-rz2qg [1.338221753s]
Aug 12 17:43:42.274: INFO: Created: latency-svc-5rbpx
Aug 12 17:43:42.274: INFO: Created: latency-svc-t4gj5
Aug 12 17:43:42.274: INFO: Created: latency-svc-cxk69
Aug 12 17:43:42.275: INFO: Created: latency-svc-m5qdk
Aug 12 17:43:42.275: INFO: Created: latency-svc-jddth
Aug 12 17:43:42.275: INFO: Got endpoints: latency-svc-m5qdk [1.370546416s]
Aug 12 17:43:42.275: INFO: Got endpoints: latency-svc-thrkc [1.371636932s]
Aug 12 17:43:42.276: INFO: Got endpoints: latency-svc-t4gj5 [1.369059951s]
Aug 12 17:43:42.276: INFO: Got endpoints: latency-svc-cxk69 [1.372276081s]
Aug 12 17:43:42.321: INFO: Got endpoints: latency-svc-5rbpx [1.415366065s]
Aug 12 17:43:42.321: INFO: Got endpoints: latency-svc-jddth [1.416023739s]
Aug 12 17:43:42.493: INFO: Created: latency-svc-lcvnl
Aug 12 17:43:42.696: INFO: Created: latency-svc-khmjg
Aug 12 17:43:42.696: INFO: Created: latency-svc-r2n4z
Aug 12 17:43:42.697: INFO: Created: latency-svc-2xgxr
Aug 12 17:43:42.697: INFO: Created: latency-svc-p2dsj
Aug 12 17:43:42.697: INFO: Created: latency-svc-l8gqw
Aug 12 17:43:42.697: INFO: Created: latency-svc-4zr4r
Aug 12 17:43:42.697: INFO: Created: latency-svc-8tbp8
Aug 12 17:43:42.697: INFO: Created: latency-svc-gg7c6
Aug 12 17:43:42.697: INFO: Created: latency-svc-rklh8
Aug 12 17:43:42.697: INFO: Created: latency-svc-gthtc
Aug 12 17:43:42.697: INFO: Created: latency-svc-7524j
Aug 12 17:43:42.697: INFO: Created: latency-svc-9gb6x
Aug 12 17:43:42.698: INFO: Created: latency-svc-xkbvn
Aug 12 17:43:42.698: INFO: Created: latency-svc-6skf8
Aug 12 17:43:42.698: INFO: Got endpoints: latency-svc-khmjg [376.731339ms]
Aug 12 17:43:42.698: INFO: Got endpoints: latency-svc-lcvnl [1.792191779s]
Aug 12 17:43:42.699: INFO: Got endpoints: latency-svc-r2n4z [1.791427532s]
Aug 12 17:43:42.699: INFO: Got endpoints: latency-svc-2xgxr [1.789123917s]
Aug 12 17:43:42.699: INFO: Got endpoints: latency-svc-p2dsj [1.791627681s]
Aug 12 17:43:42.700: INFO: Got endpoints: latency-svc-l8gqw [1.791426625s]
Aug 12 17:43:42.700: INFO: Got endpoints: latency-svc-4zr4r [1.791183965s]
Aug 12 17:43:42.700: INFO: Got endpoints: latency-svc-8tbp8 [1.79116862s]
Aug 12 17:43:42.700: INFO: Got endpoints: latency-svc-gg7c6 [1.790991122s]
Aug 12 17:43:42.701: INFO: Got endpoints: latency-svc-rklh8 [459.854939ms]
Aug 12 17:43:42.701: INFO: Got endpoints: latency-svc-gthtc [425.464129ms]
Aug 12 17:43:42.701: INFO: Got endpoints: latency-svc-7524j [426.12727ms]
Aug 12 17:43:42.701: INFO: Got endpoints: latency-svc-9gb6x [425.57074ms]
Aug 12 17:43:42.702: INFO: Got endpoints: latency-svc-xkbvn [425.439602ms]
Aug 12 17:43:42.702: INFO: Got endpoints: latency-svc-6skf8 [380.91458ms]
Aug 12 17:43:43.037: INFO: Created: latency-svc-vmlsb
Aug 12 17:43:43.077: INFO: Got endpoints: latency-svc-vmlsb [374.71601ms]
Aug 12 17:43:43.065: INFO: Created: latency-svc-w9vq9
Aug 12 17:43:43.065: INFO: Created: latency-svc-4t2z6
Aug 12 17:43:43.065: INFO: Created: latency-svc-fdd47
Aug 12 17:43:43.065: INFO: Created: latency-svc-5gjg4
Aug 12 17:43:43.065: INFO: Created: latency-svc-t4qsj
Aug 12 17:43:43.065: INFO: Created: latency-svc-l4bf4
Aug 12 17:43:43.065: INFO: Created: latency-svc-lz7sg
Aug 12 17:43:43.066: INFO: Created: latency-svc-dgckq
Aug 12 17:43:43.066: INFO: Created: latency-svc-wdxd7
Aug 12 17:43:43.066: INFO: Created: latency-svc-kmh76
Aug 12 17:43:43.066: INFO: Created: latency-svc-k6w78
Aug 12 17:43:43.066: INFO: Created: latency-svc-jp9jd
Aug 12 17:43:43.121: INFO: Created: latency-svc-xjdxv
Aug 12 17:43:43.209: INFO: Created: latency-svc-n6mmh
Aug 12 17:43:43.232: INFO: Got endpoints: latency-svc-w9vq9 [534.006953ms]
Aug 12 17:43:43.233: INFO: Got endpoints: latency-svc-4t2z6 [534.675403ms]
Aug 12 17:43:43.233: INFO: Got endpoints: latency-svc-fdd47 [531.517557ms]
Aug 12 17:43:43.233: INFO: Got endpoints: latency-svc-5gjg4 [534.098153ms]
Aug 12 17:43:43.233: INFO: Got endpoints: latency-svc-t4qsj [533.862364ms]
Aug 12 17:43:43.233: INFO: Got endpoints: latency-svc-l4bf4 [533.56726ms]
Aug 12 17:43:43.233: INFO: Got endpoints: latency-svc-lz7sg [533.475655ms]
Aug 12 17:43:43.233: INFO: Got endpoints: latency-svc-dgckq [533.300953ms]
Aug 12 17:43:43.233: INFO: Got endpoints: latency-svc-wdxd7 [533.171347ms]
Aug 12 17:43:43.233: INFO: Got endpoints: latency-svc-kmh76 [533.028869ms]
Aug 12 17:43:43.234: INFO: Got endpoints: latency-svc-k6w78 [532.835796ms]
Aug 12 17:43:43.234: INFO: Got endpoints: latency-svc-jp9jd [532.703653ms]
Aug 12 17:43:43.234: INFO: Got endpoints: latency-svc-xjdxv [532.299256ms]
Aug 12 17:43:43.234: INFO: Got endpoints: latency-svc-n6mmh [532.171553ms]
Aug 12 17:43:43.402: INFO: Created: latency-svc-bzznd
Aug 12 17:43:43.403: INFO: Created: latency-svc-n7fsd
Aug 12 17:43:43.403: INFO: Got endpoints: latency-svc-bzznd [171.164506ms]
Aug 12 17:43:43.467: INFO: Created: latency-svc-qfk4s
Aug 12 17:43:43.467: INFO: Got endpoints: latency-svc-n7fsd [233.086215ms]
Aug 12 17:43:43.577: INFO: Got endpoints: latency-svc-qfk4s [341.445889ms]
Aug 12 17:43:43.680: INFO: Created: latency-svc-85sfc
Aug 12 17:43:43.725: INFO: Got endpoints: latency-svc-85sfc [490.465911ms]
Aug 12 17:43:43.873: INFO: Created: latency-svc-dxhvn
Aug 12 17:43:43.874: INFO: Got endpoints: latency-svc-dxhvn [638.924521ms]
Aug 12 17:43:43.875: INFO: Created: latency-svc-n9kw6
Aug 12 17:43:43.941: INFO: Got endpoints: latency-svc-n9kw6 [705.505685ms]
Aug 12 17:43:43.981: INFO: Created: latency-svc-2j6gn
Aug 12 17:43:44.102: INFO: Created: latency-svc-6bsbs
Aug 12 17:43:44.103: INFO: Got endpoints: latency-svc-2j6gn [867.127278ms]
Aug 12 17:43:44.113: INFO: Got endpoints: latency-svc-6bsbs [875.432811ms]
Aug 12 17:43:44.270: INFO: Created: latency-svc-fmx5q
Aug 12 17:43:44.270: INFO: Got endpoints: latency-svc-fmx5q [1.034103019s]
Aug 12 17:43:44.271: INFO: Created: latency-svc-bkwqp
Aug 12 17:43:44.427: INFO: Got endpoints: latency-svc-bkwqp [1.191208637s]
Aug 12 17:43:44.428: INFO: Created: latency-svc-cqxj4
Aug 12 17:43:44.546: INFO: Created: latency-svc-nhrm2
Aug 12 17:43:44.546: INFO: Got endpoints: latency-svc-cqxj4 [1.309680209s]
Aug 12 17:43:44.765: INFO: Got endpoints: latency-svc-nhrm2 [1.528017361s]
Aug 12 17:43:44.805: INFO: Created: latency-svc-s5p7j
Aug 12 17:43:44.951: INFO: Got endpoints: latency-svc-s5p7j [847.889028ms]
Aug 12 17:43:44.805: INFO: Created: latency-svc-hz5df
Aug 12 17:43:44.951: INFO: Got endpoints: latency-svc-hz5df [1.714574111s]
Aug 12 17:43:44.805: INFO: Created: latency-svc-96fvp
Aug 12 17:43:44.952: INFO: Got endpoints: latency-svc-96fvp [1.71478178s]
Aug 12 17:43:44.805: INFO: Created: latency-svc-qcqsq
Aug 12 17:43:44.952: INFO: Got endpoints: latency-svc-qcqsq [1.715079889s]
Aug 12 17:43:44.805: INFO: Created: latency-svc-hlk88
Aug 12 17:43:44.953: INFO: Got endpoints: latency-svc-hlk88 [1.550129013s]
Aug 12 17:43:44.805: INFO: Created: latency-svc-mtvwc
Aug 12 17:43:44.953: INFO: Got endpoints: latency-svc-mtvwc [1.486330295s]
Aug 12 17:43:44.805: INFO: Created: latency-svc-m5sfl
Aug 12 17:43:44.954: INFO: Got endpoints: latency-svc-m5sfl [1.274017346s]
Aug 12 17:43:44.805: INFO: Created: latency-svc-gd9b8
Aug 12 17:43:44.954: INFO: Got endpoints: latency-svc-gd9b8 [1.2291896s]
Aug 12 17:43:44.805: INFO: Created: latency-svc-fmrvt
Aug 12 17:43:44.955: INFO: Got endpoints: latency-svc-fmrvt [1.080637157s]
Aug 12 17:43:44.805: INFO: Created: latency-svc-5hjgb
Aug 12 17:43:44.955: INFO: Got endpoints: latency-svc-5hjgb [1.014312948s]
Aug 12 17:43:44.949: INFO: Created: latency-svc-5v4rv
Aug 12 17:43:44.955: INFO: Got endpoints: latency-svc-5v4rv [842.291502ms]
Aug 12 17:43:44.950: INFO: Created: latency-svc-rswkz
Aug 12 17:43:44.956: INFO: Got endpoints: latency-svc-rswkz [409.555965ms]
Aug 12 17:43:44.950: INFO: Created: latency-svc-cwsf5
Aug 12 17:43:44.956: INFO: Got endpoints: latency-svc-cwsf5 [685.727758ms]
Aug 12 17:43:44.950: INFO: Created: latency-svc-lxd8n
Aug 12 17:43:44.956: INFO: Got endpoints: latency-svc-lxd8n [528.520631ms]
Aug 12 17:43:45.085: INFO: Created: latency-svc-krtnh
Aug 12 17:43:45.385: INFO: Created: latency-svc-wsz69
Aug 12 17:43:45.385: INFO: Created: latency-svc-kl4qb
Aug 12 17:43:45.385: INFO: Created: latency-svc-nvhvq
Aug 12 17:43:45.385: INFO: Created: latency-svc-h6qfc
Aug 12 17:43:45.385: INFO: Created: latency-svc-zfnn6
Aug 12 17:43:45.385: INFO: Created: latency-svc-cg6h8
Aug 12 17:43:45.385: INFO: Created: latency-svc-22xd5
Aug 12 17:43:45.386: INFO: Created: latency-svc-fz5vg
Aug 12 17:43:45.386: INFO: Created: latency-svc-z62lt
Aug 12 17:43:45.386: INFO: Created: latency-svc-l6mwv
Aug 12 17:43:45.386: INFO: Created: latency-svc-qftw2
Aug 12 17:43:45.386: INFO: Created: latency-svc-pslwk
Aug 12 17:43:45.386: INFO: Created: latency-svc-qtl2j
Aug 12 17:43:45.386: INFO: Created: latency-svc-8cdqs
Aug 12 17:43:45.386: INFO: Got endpoints: latency-svc-8cdqs [430.082894ms]
Aug 12 17:43:45.386: INFO: Got endpoints: latency-svc-krtnh [435.856585ms]
Aug 12 17:43:45.386: INFO: Got endpoints: latency-svc-wsz69 [430.347385ms]
Aug 12 17:43:45.386: INFO: Got endpoints: latency-svc-kl4qb [435.500529ms]
Aug 12 17:43:45.387: INFO: Got endpoints: latency-svc-nvhvq [435.032001ms]
Aug 12 17:43:45.387: INFO: Got endpoints: latency-svc-h6qfc [434.696686ms]
Aug 12 17:43:45.387: INFO: Got endpoints: latency-svc-zfnn6 [434.272749ms]
Aug 12 17:43:45.387: INFO: Got endpoints: latency-svc-cg6h8 [433.714961ms]
Aug 12 17:43:45.387: INFO: Got endpoints: latency-svc-22xd5 [433.335657ms]
Aug 12 17:43:45.387: INFO: Got endpoints: latency-svc-fz5vg [433.004729ms]
Aug 12 17:43:45.387: INFO: Got endpoints: latency-svc-z62lt [432.828342ms]
Aug 12 17:43:45.387: INFO: Got endpoints: latency-svc-l6mwv [432.653549ms]
Aug 12 17:43:45.387: INFO: Got endpoints: latency-svc-qftw2 [432.34534ms]
Aug 12 17:43:45.388: INFO: Got endpoints: latency-svc-pslwk [431.39536ms]
Aug 12 17:43:45.388: INFO: Got endpoints: latency-svc-qtl2j [432.393703ms]
Aug 12 17:43:45.421: INFO: Created: latency-svc-7mnpg
Aug 12 17:43:45.441: INFO: Created: latency-svc-fkhr5
Aug 12 17:43:45.441: INFO: Got endpoints: latency-svc-7mnpg [55.169095ms]
Aug 12 17:43:45.513: INFO: Created: latency-svc-5ft4x
Aug 12 17:43:45.753: INFO: Created: latency-svc-w2dr5
Aug 12 17:43:45.781: INFO: Got endpoints: latency-svc-w2dr5 [394.48351ms]
Aug 12 17:43:45.777: INFO: Created: latency-svc-g9xc9
Aug 12 17:43:45.777: INFO: Got endpoints: latency-svc-fkhr5 [390.198432ms]
Aug 12 17:43:45.860: INFO: Got endpoints: latency-svc-g9xc9 [473.367261ms]
Aug 12 17:43:45.939: INFO: Created: latency-svc-mr5xt
Aug 12 17:43:45.940: INFO: Created: latency-svc-srlpn
Aug 12 17:43:45.940: INFO: Created: latency-svc-6c5qn
Aug 12 17:43:45.940: INFO: Created: latency-svc-7xjrl
Aug 12 17:43:45.941: INFO: Created: latency-svc-hbgvv
Aug 12 17:43:45.941: INFO: Created: latency-svc-h94cn
Aug 12 17:43:45.941: INFO: Created: latency-svc-jh6gc
Aug 12 17:43:45.941: INFO: Created: latency-svc-jl8gz
Aug 12 17:43:45.941: INFO: Created: latency-svc-9bh9b
Aug 12 17:43:45.942: INFO: Created: latency-svc-rlswj
Aug 12 17:43:45.942: INFO: Created: latency-svc-d88qz
Aug 12 17:43:45.942: INFO: Created: latency-svc-9vcbq
Aug 12 17:43:45.942: INFO: Got endpoints: latency-svc-mr5xt [133.701873ms]
Aug 12 17:43:45.943: INFO: Got endpoints: latency-svc-5ft4x [556.523503ms]
Aug 12 17:43:45.944: INFO: Got endpoints: latency-svc-srlpn [556.873473ms]
Aug 12 17:43:45.944: INFO: Got endpoints: latency-svc-6c5qn [556.150058ms]
Aug 12 17:43:45.944: INFO: Got endpoints: latency-svc-7xjrl [557.227709ms]
Aug 12 17:43:45.945: INFO: Got endpoints: latency-svc-hbgvv [558.180783ms]
Aug 12 17:43:45.945: INFO: Got endpoints: latency-svc-h94cn [558.592858ms]
Aug 12 17:43:45.946: INFO: Got endpoints: latency-svc-jh6gc [558.939543ms]
Aug 12 17:43:45.946: INFO: Got endpoints: latency-svc-jl8gz [559.242579ms]
Aug 12 17:43:45.946: INFO: Got endpoints: latency-svc-9bh9b [559.18031ms]
Aug 12 17:43:45.947: INFO: Got endpoints: latency-svc-rlswj [559.390112ms]
Aug 12 17:43:45.947: INFO: Got endpoints: latency-svc-d88qz [559.674768ms]
Aug 12 17:43:45.948: INFO: Got endpoints: latency-svc-9vcbq [506.784938ms]
Aug 12 17:43:45.965: INFO: Created: latency-svc-r7jnr
Aug 12 17:43:46.285: INFO: Created: latency-svc-67hfz
Aug 12 17:43:46.285: INFO: Got endpoints: latency-svc-67hfz [404.217729ms]
Aug 12 17:43:46.325: INFO: Got endpoints: latency-svc-r7jnr [202.371509ms]
Aug 12 17:43:46.438: INFO: Created: latency-svc-gqrcj
Aug 12 17:43:46.438: INFO: Created: latency-svc-bqg4j
Aug 12 17:43:46.439: INFO: Created: latency-svc-jf9pw
Aug 12 17:43:46.439: INFO: Created: latency-svc-tsxmh
Aug 12 17:43:46.439: INFO: Got endpoints: latency-svc-tsxmh [494.747094ms]
Aug 12 17:43:46.439: INFO: Created: latency-svc-brrz4
Aug 12 17:43:46.440: INFO: Got endpoints: latency-svc-brrz4 [496.215259ms]
Aug 12 17:43:46.439: INFO: Created: latency-svc-kb96x
Aug 12 17:43:46.440: INFO: Got endpoints: latency-svc-kb96x [496.14716ms]
Aug 12 17:43:46.439: INFO: Created: latency-svc-v5xs7
Aug 12 17:43:46.441: INFO: Got endpoints: latency-svc-v5xs7 [495.703321ms]
Aug 12 17:43:46.439: INFO: Created: latency-svc-n8s9l
Aug 12 17:43:46.441: INFO: Got endpoints: latency-svc-n8s9l [493.291881ms]
Aug 12 17:43:46.439: INFO: Created: latency-svc-2j68c
Aug 12 17:43:46.442: INFO: Got endpoints: latency-svc-2j68c [496.03565ms]
Aug 12 17:43:46.439: INFO: Created: latency-svc-5h655
Aug 12 17:43:46.442: INFO: Got endpoints: latency-svc-5h655 [495.95195ms]
Aug 12 17:43:46.439: INFO: Created: latency-svc-bsmgb
Aug 12 17:43:46.442: INFO: Got endpoints: latency-svc-bsmgb [496.020106ms]
Aug 12 17:43:46.439: INFO: Created: latency-svc-vv2cx
Aug 12 17:43:46.443: INFO: Got endpoints: latency-svc-vv2cx [496.077008ms]
Aug 12 17:43:46.439: INFO: Created: latency-svc-lzsh5
Aug 12 17:43:46.443: INFO: Got endpoints: latency-svc-lzsh5 [496.043819ms]
Aug 12 17:43:46.439: INFO: Got endpoints: latency-svc-gqrcj [491.849165ms]
Aug 12 17:43:46.439: INFO: Got endpoints: latency-svc-bqg4j [496.919972ms]
Aug 12 17:43:46.439: INFO: Got endpoints: latency-svc-jf9pw [496.063673ms]
Aug 12 17:43:46.865: INFO: Created: latency-svc-94ds4
Aug 12 17:43:46.987: INFO: Got endpoints: latency-svc-94ds4 [701.766382ms]
Aug 12 17:43:46.891: INFO: Created: latency-svc-khcdh
Aug 12 17:43:46.988: INFO: Got endpoints: latency-svc-khcdh [544.034192ms]
Aug 12 17:43:46.891: INFO: Created: latency-svc-dn5cc
Aug 12 17:43:46.988: INFO: Got endpoints: latency-svc-dn5cc [548.809647ms]
Aug 12 17:43:46.892: INFO: Created: latency-svc-tsbqq
Aug 12 17:43:46.989: INFO: Got endpoints: latency-svc-tsbqq [548.878881ms]
Aug 12 17:43:46.892: INFO: Created: latency-svc-q9md8
Aug 12 17:43:46.989: INFO: Got endpoints: latency-svc-q9md8 [549.046642ms]
Aug 12 17:43:46.892: INFO: Created: latency-svc-5d5jv
Aug 12 17:43:46.990: INFO: Got endpoints: latency-svc-5d5jv [545.946183ms]
Aug 12 17:43:46.892: INFO: Created: latency-svc-x7dmp
Aug 12 17:43:46.990: INFO: Got endpoints: latency-svc-x7dmp [549.343866ms]
Aug 12 17:43:46.892: INFO: Created: latency-svc-vrbrm
Aug 12 17:43:46.991: INFO: Got endpoints: latency-svc-vrbrm [549.403257ms]
Aug 12 17:43:46.892: INFO: Created: latency-svc-pf45g
Aug 12 17:43:46.991: INFO: Got endpoints: latency-svc-pf45g [549.496404ms]
Aug 12 17:43:46.892: INFO: Created: latency-svc-vxshr
Aug 12 17:43:46.992: INFO: Got endpoints: latency-svc-vxshr [549.678614ms]
Aug 12 17:43:46.892: INFO: Created: latency-svc-2h8b7
Aug 12 17:43:46.992: INFO: Got endpoints: latency-svc-2h8b7 [549.538668ms]
Aug 12 17:43:46.892: INFO: Created: latency-svc-49ttx
Aug 12 17:43:46.993: INFO: Got endpoints: latency-svc-49ttx [549.692079ms]
Aug 12 17:43:46.892: INFO: Created: latency-svc-4q4b5
Aug 12 17:43:46.993: INFO: Got endpoints: latency-svc-4q4b5 [549.752317ms]
Aug 12 17:43:46.892: INFO: Created: latency-svc-qfz4c
Aug 12 17:43:46.993: INFO: Got endpoints: latency-svc-qfz4c [549.888528ms]
Aug 12 17:43:46.892: INFO: Created: latency-svc-7ckz9
Aug 12 17:43:46.994: INFO: Got endpoints: latency-svc-7ckz9 [669.09377ms]
Aug 12 17:43:47.254: INFO: Created: latency-svc-zltgz
Aug 12 17:43:47.485: INFO: Created: latency-svc-sws25
Aug 12 17:43:47.640: INFO: Got endpoints: latency-svc-sws25 [652.146577ms]
Aug 12 17:43:47.501: INFO: Got endpoints: latency-svc-zltgz [513.769322ms]
Aug 12 17:43:47.501: INFO: Created: latency-svc-5f9mq
Aug 12 17:43:47.501: INFO: Created: latency-svc-f89xp
Aug 12 17:43:47.501: INFO: Created: latency-svc-2r4j5
Aug 12 17:43:47.501: INFO: Created: latency-svc-xz44k
Aug 12 17:43:47.501: INFO: Created: latency-svc-qgv87
Aug 12 17:43:47.501: INFO: Created: latency-svc-cvs69
Aug 12 17:43:47.501: INFO: Created: latency-svc-bjz5s
Aug 12 17:43:47.501: INFO: Created: latency-svc-nvwgx
Aug 12 17:43:47.501: INFO: Created: latency-svc-q2sgd
Aug 12 17:43:47.501: INFO: Created: latency-svc-8gs6v
Aug 12 17:43:47.501: INFO: Created: latency-svc-4x8gh
Aug 12 17:43:47.501: INFO: Created: latency-svc-vmkn4
Aug 12 17:43:47.502: INFO: Created: latency-svc-l9f8h
Aug 12 17:43:47.746: INFO: Got endpoints: latency-svc-5f9mq [752.117208ms]
Aug 12 17:43:47.746: INFO: Got endpoints: latency-svc-f89xp [757.255889ms]
Aug 12 17:43:47.746: INFO: Got endpoints: latency-svc-2r4j5 [756.843964ms]
Aug 12 17:43:47.746: INFO: Got endpoints: latency-svc-xz44k [755.181796ms]
Aug 12 17:43:47.746: INFO: Got endpoints: latency-svc-qgv87 [756.502542ms]
Aug 12 17:43:47.746: INFO: Got endpoints: latency-svc-cvs69 [756.285344ms]
Aug 12 17:43:47.746: INFO: Got endpoints: latency-svc-bjz5s [755.914577ms]
Aug 12 17:43:47.746: INFO: Got endpoints: latency-svc-nvwgx [755.114218ms]
Aug 12 17:43:47.746: INFO: Got endpoints: latency-svc-q2sgd [752.670233ms]
Aug 12 17:43:47.747: INFO: Got endpoints: latency-svc-8gs6v [754.809309ms]
Aug 12 17:43:47.747: INFO: Got endpoints: latency-svc-4x8gh [754.702886ms]
Aug 12 17:43:47.747: INFO: Got endpoints: latency-svc-vmkn4 [754.369572ms]
Aug 12 17:43:47.747: INFO: Got endpoints: latency-svc-l9f8h [754.085416ms]
Aug 12 17:43:47.855: INFO: Created: latency-svc-g668n
Aug 12 17:43:47.855: INFO: Got endpoints: latency-svc-g668n [111.678964ms]
Aug 12 17:43:48.497: INFO: Created: latency-svc-cr8nv
Aug 12 17:43:48.284: INFO: Created: latency-svc-dgxwq
Aug 12 17:43:48.497: INFO: Got endpoints: latency-svc-dgxwq [752.354463ms]
Aug 12 17:43:49.108: INFO: Created: latency-svc-8zrbw
Aug 12 17:43:49.113: INFO: Created: latency-svc-dxzrh
Aug 12 17:43:49.113: INFO: Created: latency-svc-xcx9h
Aug 12 17:43:49.113: INFO: Created: latency-svc-kxsd8
Aug 12 17:43:49.113: INFO: Created: latency-svc-s8v4w
Aug 12 17:43:49.113: INFO: Created: latency-svc-xjv5v
Aug 12 17:43:49.113: INFO: Created: latency-svc-6q772
Aug 12 17:43:49.113: INFO: Created: latency-svc-m2vrw
Aug 12 17:43:49.113: INFO: Created: latency-svc-txdd4
Aug 12 17:43:49.113: INFO: Created: latency-svc-2588l
Aug 12 17:43:49.113: INFO: Created: latency-svc-sf2qt
Aug 12 17:43:49.113: INFO: Created: latency-svc-pr2gc
Aug 12 17:43:49.114: INFO: Created: latency-svc-4x4df
Aug 12 17:43:49.114: INFO: Created: latency-svc-998bm
Aug 12 17:43:49.114: INFO: Got endpoints: latency-svc-pr2gc [617.07734ms]
Aug 12 17:43:49.114: INFO: Got endpoints: latency-svc-cr8nv [1.366703435s]
Aug 12 17:43:49.114: INFO: Got endpoints: latency-svc-4x4df [1.366218949s]
Aug 12 17:43:49.114: INFO: Got endpoints: latency-svc-998bm [1.362395273s]
Aug 12 17:43:49.114: INFO: Got endpoints: latency-svc-8zrbw [1.365718671s]
Aug 12 17:43:49.114: INFO: Got endpoints: latency-svc-dxzrh [1.365326456s]
Aug 12 17:43:49.114: INFO: Got endpoints: latency-svc-xcx9h [1.364937999s]
Aug 12 17:43:49.114: INFO: Got endpoints: latency-svc-kxsd8 [1.364579461s]
Aug 12 17:43:49.114: INFO: Got endpoints: latency-svc-s8v4w [1.364246927s]
Aug 12 17:43:49.114: INFO: Got endpoints: latency-svc-xjv5v [1.363926234s]
Aug 12 17:43:49.114: INFO: Got endpoints: latency-svc-6q772 [1.363610514s]
Aug 12 17:43:49.114: INFO: Got endpoints: latency-svc-m2vrw [1.363362254s]
Aug 12 17:43:49.114: INFO: Got endpoints: latency-svc-txdd4 [1.363108006s]
Aug 12 17:43:49.114: INFO: Got endpoints: latency-svc-2588l [1.362796719s]
Aug 12 17:43:49.114: INFO: Got endpoints: latency-svc-sf2qt [1.258668716s]
Aug 12 17:43:49.114: INFO: Latencies: [55.169095ms 111.678964ms 133.701873ms 171.164506ms 202.371509ms 233.086215ms 290.09152ms 290.684329ms 291.878952ms 292.093609ms 292.323676ms 292.549944ms 292.818186ms 293.084055ms 293.361309ms 293.635729ms 293.719366ms 293.778033ms 293.883345ms 341.445889ms 374.71601ms 376.731339ms 380.91458ms 390.198432ms 394.48351ms 401.783772ms 401.801014ms 402.96209ms 404.069707ms 404.17386ms 404.217729ms 404.565491ms 404.916621ms 405.401108ms 405.728748ms 405.963141ms 406.173641ms 406.757749ms 407.089379ms 409.555965ms 413.427691ms 415.452176ms 415.674038ms 415.7448ms 416.071676ms 416.209615ms 416.674043ms 416.915967ms 417.128928ms 417.341728ms 417.553565ms 417.773744ms 418.011029ms 418.245892ms 418.443702ms 425.439602ms 425.464129ms 425.57074ms 426.12727ms 430.082894ms 430.347385ms 431.39536ms 432.34534ms 432.393703ms 432.653549ms 432.828342ms 433.004729ms 433.335657ms 433.714961ms 434.272749ms 434.696686ms 435.032001ms 435.500529ms 435.856585ms 459.854939ms 473.367261ms 490.465911ms 491.849165ms 493.291881ms 494.747094ms 495.703321ms 495.95195ms 496.020106ms 496.03565ms 496.043819ms 496.063673ms 496.077008ms 496.14716ms 496.215259ms 496.919972ms 506.784938ms 513.769322ms 528.520631ms 531.517557ms 532.171553ms 532.299256ms 532.703653ms 532.835796ms 533.028869ms 533.171347ms 533.300953ms 533.475655ms 533.56726ms 533.862364ms 534.006953ms 534.098153ms 534.675403ms 544.034192ms 545.946183ms 548.809647ms 548.878881ms 549.046642ms 549.343866ms 549.403257ms 549.496404ms 549.538668ms 549.678614ms 549.692079ms 549.752317ms 549.888528ms 556.150058ms 556.523503ms 556.873473ms 557.227709ms 558.180783ms 558.592858ms 558.939543ms 559.18031ms 559.242579ms 559.390112ms 559.674768ms 617.07734ms 638.924521ms 652.146577ms 669.09377ms 681.249355ms 685.727758ms 692.07029ms 701.766382ms 705.505685ms 752.117208ms 752.354463ms 752.670233ms 754.085416ms 754.369572ms 754.702886ms 754.809309ms 755.114218ms 755.181796ms 755.914577ms 756.285344ms 756.502542ms 756.843964ms 757.255889ms 842.291502ms 847.889028ms 867.127278ms 875.432811ms 1.014312948s 1.034103019s 1.080637157s 1.191208637s 1.2291896s 1.258668716s 1.274017346s 1.309680209s 1.338221753s 1.362395273s 1.362796719s 1.363108006s 1.363362254s 1.363610514s 1.363926234s 1.364246927s 1.364579461s 1.364937999s 1.365326456s 1.365718671s 1.366218949s 1.366703435s 1.369059951s 1.370546416s 1.371636932s 1.372276081s 1.415366065s 1.416023739s 1.486330295s 1.528017361s 1.550129013s 1.714574111s 1.71478178s 1.715079889s 1.789123917s 1.790991122s 1.79116862s 1.791183965s 1.791426625s 1.791427532s 1.791627681s 1.792191779s]
Aug 12 17:43:49.114: INFO: 50 %ile: 533.300953ms
Aug 12 17:43:49.114: INFO: 90 %ile: 1.369059951s
Aug 12 17:43:49.114: INFO: 99 %ile: 1.791627681s
Aug 12 17:43:49.114: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:43:49.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-6883" for this suite.
Aug 12 17:44:07.135: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:44:07.279: INFO: namespace svc-latency-6883 deletion completed in 18.160965059s

 [SLOW TEST:31.079 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:44:07.288: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 12 17:44:07.453: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:44:11.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4184" for this suite.
Aug 12 17:44:57.800: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:44:57.955: INFO: namespace pods-4184 deletion completed in 46.171349553s

 [SLOW TEST:50.668 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:44:57.969: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 12 17:44:58.012: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Aug 12 17:45:00.081: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:45:00.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-4370" for this suite.
Aug 12 17:45:06.113: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:45:06.300: INFO: namespace replication-controller-4370 deletion completed in 6.207341765s

 [SLOW TEST:8.332 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:45:06.314: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Aug 12 17:45:06.431: INFO: Waiting up to 5m0s for pod "downward-api-b39e635c-454d-4891-92b9-b82fc6a11e6d" in namespace "downward-api-6020" to be "success or failure"
Aug 12 17:45:06.465: INFO: Pod "downward-api-b39e635c-454d-4891-92b9-b82fc6a11e6d": Phase="Pending", Reason="", readiness=false. Elapsed: 34.130618ms
Aug 12 17:45:08.470: INFO: Pod "downward-api-b39e635c-454d-4891-92b9-b82fc6a11e6d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038761682s
Aug 12 17:45:10.509: INFO: Pod "downward-api-b39e635c-454d-4891-92b9-b82fc6a11e6d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.077652677s
STEP: Saw pod success
Aug 12 17:45:10.509: INFO: Pod "downward-api-b39e635c-454d-4891-92b9-b82fc6a11e6d" satisfied condition "success or failure"
Aug 12 17:45:10.512: INFO: Trying to get logs from node conformance-1-15-2-do-0-default-pool-rxf2 pod downward-api-b39e635c-454d-4891-92b9-b82fc6a11e6d container dapi-container: <nil>
STEP: delete the pod
Aug 12 17:45:10.539: INFO: Waiting for pod downward-api-b39e635c-454d-4891-92b9-b82fc6a11e6d to disappear
Aug 12 17:45:10.542: INFO: Pod downward-api-b39e635c-454d-4891-92b9-b82fc6a11e6d no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:45:10.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6020" for this suite.
Aug 12 17:45:16.559: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:45:16.716: INFO: namespace downward-api-6020 deletion completed in 6.17090515s

 [SLOW TEST:10.404 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:45:16.730: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Aug 12 17:45:16.845: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:45:21.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1071" for this suite.
Aug 12 17:45:27.379: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:45:27.539: INFO: namespace init-container-1071 deletion completed in 6.181886071s

 [SLOW TEST:10.809 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 12 17:45:27.543: INFO: >>> kubeConfig: /tmp/kubeconfig-213645099
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 12 17:45:27.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7060" for this suite.
Aug 12 17:45:49.707: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 12 17:45:49.847: INFO: namespace pods-7060 deletion completed in 22.15779807s

 [SLOW TEST:22.305 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSAug 12 17:45:49.856: INFO: Running AfterSuite actions on all nodes
Aug 12 17:45:49.857: INFO: Running AfterSuite actions on node 1
Aug 12 17:45:49.858: INFO: Skipping dumping logs from cluster

Ran 215 of 4413 Specs in 5766.934 seconds
SUCCESS! -- 215 Passed | 0 Failed | 0 Pending | 4198 Skipped
PASS

Ginkgo ran 1 suite in 1h36m9.652347477s
Test Suite Passed
